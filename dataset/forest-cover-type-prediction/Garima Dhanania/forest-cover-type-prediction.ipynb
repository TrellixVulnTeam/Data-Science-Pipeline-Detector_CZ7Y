{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport logging\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_selection import mutual_info_classif\nfrom scipy.stats import chi2_contingency\nfrom sklearn.metrics import accuracy_score as acc\nfrom mlxtend.feature_selection import SequentialFeatureSelector as sfs\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_validate\nimport featuretools as ft\nimport xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_name = '/kaggle/input/forest-cover-type-prediction'\ntraining_file_name = \"train.csv\"\ntest_file_name = 'test.csv'\n\n\n#read data\ntrain_data = pd.read_csv(dir_name + \"/\" + training_file_name)\ntest_data = pd.read_csv(dir_name + \"/\" + test_file_name)\n#display(train_data)\n#display(test_data)\n\ntrain_data = train_data.drop(\"Id\", axis=1)\ntest_data_Id = test_data['Id']\ntest_data = test_data.drop(\"Id\", axis = 1)\n\ndisplay(train_data)\ndisplay(test_data)\n\n\n# fill in missing values appropriately\n#print(train_data.isnull().sum(axis = 0))\n#print(test_data.isnull().sum(axis = 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Road+Fire'] = train_data['Horizontal_Distance_To_Roadways'] + train_data['Horizontal_Distance_To_Fire_Points']\ntrain_data['Road-Fire'] = train_data['Horizontal_Distance_To_Roadways'] - train_data['Horizontal_Distance_To_Fire_Points']\ntrain_data['Road+Hydro'] = train_data['Horizontal_Distance_To_Roadways'] + train_data['Horizontal_Distance_To_Hydrology']\ntrain_data['Road-Hydro'] = train_data['Horizontal_Distance_To_Roadways'] - train_data['Horizontal_Distance_To_Hydrology']\ntrain_data['Hydro+Fire'] = train_data['Horizontal_Distance_To_Hydrology'] + train_data['Horizontal_Distance_To_Fire_Points']\ntrain_data['Hydro-Fire'] = train_data['Horizontal_Distance_To_Hydrology'] - train_data['Horizontal_Distance_To_Fire_Points']\n\ntrain_data['Road+Fire+Hydro'] = train_data['Horizontal_Distance_To_Roadways']  + train_data['Horizontal_Distance_To_Fire_Points'] + train_data['Horizontal_Distance_To_Hydrology']\n\ntrain_data['Ele+Road+Fire+Hydro'] = train_data['Elevation'] + train_data['Horizontal_Distance_To_Roadways']  + train_data['Horizontal_Distance_To_Fire_Points'] + train_data['Horizontal_Distance_To_Hydrology']\n\ntrain_data['Ele+road'] = train_data['Elevation'] + train_data['Horizontal_Distance_To_Roadways']\ntrain_data['Ele-road'] = train_data['Elevation'] - train_data['Horizontal_Distance_To_Roadways']\ntrain_data['Ele+fire'] = train_data['Elevation'] + train_data['Horizontal_Distance_To_Fire_Points']\ntrain_data['Ele-fire'] = train_data['Elevation'] - train_data['Horizontal_Distance_To_Fire_Points']\ntrain_data['Ele+hydro'] = train_data['Elevation'] + train_data['Horizontal_Distance_To_Hydrology']\ntrain_data['Ele-hydro'] = train_data['Elevation'] - train_data['Horizontal_Distance_To_Hydrology']\n\ntrain_data['distance-to-hydrology'] = (train_data['Horizontal_Distance_To_Hydrology']**2 + train_data['Vertical_Distance_To_Hydrology']**2)**0.5\n\ntest_data['Road+Fire'] = test_data['Horizontal_Distance_To_Roadways'] + test_data['Horizontal_Distance_To_Fire_Points']\ntest_data['Road-Fire'] = test_data['Horizontal_Distance_To_Roadways'] - test_data['Horizontal_Distance_To_Fire_Points']\ntest_data['Road+Hydro'] = test_data['Horizontal_Distance_To_Roadways'] + test_data['Horizontal_Distance_To_Hydrology']\ntest_data['Road-Hydro'] = test_data['Horizontal_Distance_To_Roadways'] - test_data['Horizontal_Distance_To_Hydrology']\ntest_data['Hydro+Fire'] = test_data['Horizontal_Distance_To_Hydrology'] + test_data['Horizontal_Distance_To_Fire_Points']\ntest_data['Hydro-Fire'] = test_data['Horizontal_Distance_To_Hydrology'] - test_data['Horizontal_Distance_To_Fire_Points']\n\ntest_data['Road+Fire+Hydro'] = test_data['Horizontal_Distance_To_Roadways']  + test_data['Horizontal_Distance_To_Fire_Points'] + test_data['Horizontal_Distance_To_Hydrology']\n\ntest_data['Ele+Road+Fire+Hydro'] = test_data['Elevation'] + test_data['Horizontal_Distance_To_Roadways']  + test_data['Horizontal_Distance_To_Fire_Points'] + test_data['Horizontal_Distance_To_Hydrology']\n\ntest_data['Ele+road'] = test_data['Elevation'] + test_data['Horizontal_Distance_To_Roadways']\ntest_data['Ele-road'] = test_data['Elevation'] - test_data['Horizontal_Distance_To_Roadways']\ntest_data['Ele+fire'] = test_data['Elevation'] + test_data['Horizontal_Distance_To_Fire_Points']\ntest_data['Ele-fire'] = test_data['Elevation'] - test_data['Horizontal_Distance_To_Fire_Points']\ntest_data['Ele+hydro'] = test_data['Elevation'] + test_data['Horizontal_Distance_To_Hydrology']\ntest_data['Ele-hydro'] = test_data['Elevation'] - test_data['Horizontal_Distance_To_Hydrology']\n\ntest_data['distance-to-hydrology'] = (test_data['Horizontal_Distance_To_Hydrology']**2 + test_data['Vertical_Distance_To_Hydrology']**2)**0.5\n\ndisplay(train_data)\ndisplay(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''removed_columns = ['Hillshade_3pm',\n 'Vertical_Distance_To_Hydrology',\n 'Hillshade_Noon',\n 'Wilderness_Area4',\n 'Soil_Type7',\n 'Soil_Type8',\n 'Soil_Type15',\n 'Soil_Type25',\n 'Soil_Type11',\n 'Soil_Type16',\n 'Soil_Type19',\n 'Soil_Type28',\n 'Soil_Type34']\n \nremoved_columns = ['Soil_Type7', 'Soil_Type15']\n\ntrain_data.drop(columns=removed_columns, axis=1, inplace=True)\ntest_data.drop(columns=removed_columns, axis=1, inplace=True)\n\ndisplay(train_data)\ndisplay(test_data)\n\n'''\n\nx = train_data.drop('Cover_Type', axis=1)\ny = train_data['Cover_Type']\n\ndisplay(x)\ndisplay(y)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=0)\n\ndisplay(x_train)\ndisplay(y_train)\ndisplay(x_test)\ndisplay(y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"x_scaled = x\ntest_scaled = test_data\n\nscaler = StandardScaler()\n\nscaler.fit(x_scaled)\n\nx_scaled = scaler.transform(x_scaled)\ntest_scaled = scaler.transform(test_scaled)\n\nx_scaled = pd.DataFrame(x_scaled, index = x.index, columns=x.columns)\ntest_scaled = pd.DataFrame(test_scaled, index = test_data.index, columns=test_data.columns)\n\ndisplay(x_scaled)\ndisplay(test_scaled)"},{"metadata":{},"cell_type":"raw","source":"model = LGBMClassifier(eval_metric = 'logloss', feature_fraction = 0.5, max_depth = 20, num_leaves= 1000)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(eval_metric = 'logloss', feature_fraction = 0.5, max_depth = 20, num_leaves= 1000)\nmodel.fit(x,y)\ny_pred = model.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred)\npredictions_test.columns = ['Cover_Type']\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('lgbm1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"model = LGBMClassifier(eval_metric = 'logloss')\nmodel"},{"metadata":{},"cell_type":"raw","source":"model = CatBoostClassifier(verbose=0, n_estimators=100)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"},{"metadata":{},"cell_type":"raw","source":"model = CatBoostClassifier(verbose=0, n_estimators=100)\nmodel.fit(x,y)\ny_pred = model.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred)\npredictions_test.columns = ['Cover_Type']\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('catboost.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"model = LGBMClassifier()\nmodel.fit(x,y)\ny_pred = model.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred)\npredictions_test.columns = ['Cover_Type']\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('lgbm.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"y_binary = y\n\ny_binary = y_binary.replace([1,2], 0)\ny_binary = y_binary.replace([3,4,5,6,7], 1)\n\ny_binary = pd.DataFrame(y_binary)\ny_binary.columns = ['Binary_CT']\n\ndisplay(y_binary)\n"},{"metadata":{},"cell_type":"raw","source":"y_binary.value_counts()"},{"metadata":{},"cell_type":"raw","source":"et_binary = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net_binary.fit(x_scaled, y_binary)\ny_pred_binary = et_binary.predict(test_scaled)"},{"metadata":{},"cell_type":"raw","source":"x_scaled_12 = x_scaled[y == 1].append(x_scaled[y == 2])\ntest_scaled_12 = test_scaled[y_pred_binary == 0]\n\ny_12 = y[y == 1].append(y[y == 2])\n\ndisplay(x_scaled_12)\ndisplay(y_12)\ndisplay(test_scaled_12)\n\nknn1 = KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)\n\nknn1.fit(x_scaled_12, y_12)\ny_pred_12 = knn1.predict(test_scaled_12)"},{"metadata":{},"cell_type":"raw","source":"x_scaled_37 = x_scaled[y.isin([3,4,5,6,7])]\ntest_scaled_37 = test_scaled[y_pred_binary == 1]\n\ny_37 = y[y.isin([3,4,5,6,7])]\n\ndisplay(x_scaled_37)\ndisplay(y_37)\ndisplay(test_scaled_37)\n\nknn2 = KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)\n\nknn2.fit(x_scaled_37, y_37)\ny_pred_37 = knn2.predict(test_scaled_37)"},{"metadata":{},"cell_type":"raw","source":"pred12 = pd.DataFrame(y_pred_12, index = test_scaled_12.index)\npred37 = pd.DataFrame(y_pred_37, index = test_scaled_37.index)\npred = pred12.append(pred37)\npred"},{"metadata":{},"cell_type":"raw","source":"predictions_test = pd.DataFrame(pred)\npredictions_test.columns = ['Cover_Type']\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('et-scaled-feature-engg-no-selection-12-sep-ada.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"x_train_scaled = x_train\nx_test_scaled = x_test\n\nscaler = StandardScaler()\n\nscaler.fit(x_train_scaled)\n\nx_train_scaled = scaler.transform(x_train_scaled)\nx_test_scaled = scaler.transform(x_test_scaled)\n\nx_train_scaled = pd.DataFrame(x_train_scaled, index = x_train.index, columns=x.columns)\nx_test_scaled = pd.DataFrame(x_test_scaled, index = x_test.index, columns=x.columns)\n\ndisplay(x_train_scaled)\ndisplay(x_test_scaled)"},{"metadata":{},"cell_type":"raw","source":"y_train_binary = y_train\ny_test_binary = y_test\n\ny_train_binary = y_train_binary.replace([1,2], 0)\ny_train_binary = y_train_binary.replace([3,4,5,6,7], 1)\n\ny_test_binary = y_test_binary.replace([1,2], 0)\ny_test_binary = y_test_binary.replace([3,4,5,6,7], 1)\n\ny_train_binary = pd.DataFrame(y_train_binary)\ny_train_binary.columns = ['Binary_CT']\ny_test_binary = pd.DataFrame(y_test_binary)\ny_test_binary.columns = ['Binary_CT']\n\ndisplay(y_train_binary)\ndisplay(y_test_binary)\n"},{"metadata":{},"cell_type":"raw","source":"y_train_binary.value_counts()"},{"metadata":{},"cell_type":"raw","source":"y_test_binary.value_counts()"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x_train_scaled, y_train_binary)\ny_pred = et.predict(x_test_scaled)\n\nconfusion_matrix(y_test_binary, y_pred, labels=list(range(0,2)))"},{"metadata":{},"cell_type":"raw","source":"accuracy_score(y_test_binary, y_pred)"},{"metadata":{},"cell_type":"raw","source":"x_train_scaled_12 = x_train_scaled[y_train == 1].append(x_train_scaled[y_train == 2])\nx_test_scaled_12 = x_test_scaled[y_test == 1].append(x_test_scaled[y_test == 2])\n\ny_train_12 = y_train[y_train == 1].append(y_train[y_train == 2])\ny_test_12 = y_test[y_test == 1].append(y_test[y_test == 2])\n\ndisplay(x_train_scaled_12)\ndisplay(y_train_12)\ndisplay(x_test_scaled_12)\ndisplay(y_test_12)"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x_train_scaled_12, y_train_12)\ny_pred_12 = et.predict(x_test_scaled_12)\n\nconfusion_matrix(y_test_12, y_pred_12, labels=list(range(1,3)))"},{"metadata":{},"cell_type":"raw","source":"accuracy_score(y_test_12, y_pred_12)"},{"metadata":{},"cell_type":"raw","source":"x_train_scaled_37 = x_train_scaled[y_train.isin([3,4,5,6,7])]\nx_test_scaled_37 = x_test_scaled[y_test.isin([3,4,5,6,7])]\n\ny_train_37 = y_train[y_train.isin([3,4,5,6,7])]\ny_test_37 = y_test[y_test.isin([3,4,5,6,7])]\n\ndisplay(x_train_scaled_37)\ndisplay(y_train_37)\ndisplay(x_test_scaled_37)\ndisplay(y_test_37)"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x_train_scaled_37, y_train_37)\ny_pred_37 = et.predict(x_test_scaled_37)\n\nconfusion_matrix(y_test_37, y_pred_37, labels=list(range(3,8)))"},{"metadata":{},"cell_type":"raw","source":"accuracy_score(y_test_37, y_pred_37)"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x_train_scaled, y_train)\ny_pred = et.predict(x_test_scaled)\n\nconfusion_matrix(y_test, y_pred, labels=list(range(1,8)))"},{"metadata":{},"cell_type":"raw","source":"cont_x_train = x_train[x_train.columns[0:7]]\ncont_x_test = x_test[x_test.columns[0:7]]\ncont_y_train = y_train\ncont_y_test = y_test\n\ndisplay(cont_x_train)\ndisplay(cont_x_test)\ndisplay(cont_y_train)\ndisplay(cont_y_test)"},{"metadata":{},"cell_type":"raw","source":"cont_x_train_ext = cont_x_train\ncont_x_test_ext = cont_x_test\n\ncont_x_train_ext['Road+Fire'] = cont_x_train_ext['Horizontal_Distance_To_Roadways'] + cont_x_train_ext['Horizontal_Distance_To_Fire_Points']\ncont_x_train_ext['Road-Fire'] = cont_x_train_ext['Horizontal_Distance_To_Roadways'] - cont_x_train_ext['Horizontal_Distance_To_Fire_Points']\ncont_x_train_ext['Road+Hydro'] = cont_x_train_ext['Horizontal_Distance_To_Roadways'] + cont_x_train_ext['Horizontal_Distance_To_Hydrology']\ncont_x_train_ext['Road-Hydro'] = cont_x_train_ext['Horizontal_Distance_To_Roadways'] - cont_x_train_ext['Horizontal_Distance_To_Hydrology']\ncont_x_train_ext['Hydro+Fire'] = cont_x_train_ext['Horizontal_Distance_To_Hydrology'] + cont_x_train_ext['Horizontal_Distance_To_Fire_Points']\ncont_x_train_ext['Hydro-Fire'] = cont_x_train_ext['Horizontal_Distance_To_Hydrology'] - cont_x_train_ext['Horizontal_Distance_To_Fire_Points']\n\ncont_x_test_ext['Road+Fire'] = cont_x_test_ext['Horizontal_Distance_To_Roadways'] + cont_x_test_ext['Horizontal_Distance_To_Fire_Points']\ncont_x_test_ext['Road-Fire'] = cont_x_test_ext['Horizontal_Distance_To_Roadways'] - cont_x_test_ext['Horizontal_Distance_To_Fire_Points']\ncont_x_test_ext['Road+Hydro'] = cont_x_test_ext['Horizontal_Distance_To_Roadways'] + cont_x_test_ext['Horizontal_Distance_To_Hydrology']\ncont_x_test_ext['Road-Hydro'] = cont_x_test_ext['Horizontal_Distance_To_Roadways'] - cont_x_test_ext['Horizontal_Distance_To_Hydrology']\ncont_x_test_ext['Hydro+Fire'] = cont_x_test_ext['Horizontal_Distance_To_Hydrology'] + cont_x_test_ext['Horizontal_Distance_To_Fire_Points']\ncont_x_test_ext['Hydro-Fire'] = cont_x_test_ext['Horizontal_Distance_To_Hydrology'] - cont_x_test_ext['Horizontal_Distance_To_Fire_Points']\n\ndisplay(cont_x_train)\ndisplay(cont_x_test)"},{"metadata":{},"cell_type":"raw","source":"rf = RandomForestClassifier(max_depth=4, random_state=4)\n\n\nrf.fit(cont_x_train, cont_y_train)\nprint(rf.score(cont_x_test, cont_y_test))\nfeature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = cont_x_train.columns,\n                                    columns=['importance']).sort_values('importance', ascending=False)\ndisplay(feature_importances)\n\nfeat_importances = pd.Series(rf.feature_importances_, index=cont_x_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')"},{"metadata":{},"cell_type":"raw","source":"rf = RandomForestClassifier(max_depth=4, random_state=4)\n\n\nrf.fit(cont_x_train, cont_y_train)\nprint(rf.score(cont_x_test, cont_y_test))\nfeature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = cont_x_train.columns,\n                                    columns=['importance']).sort_values('importance', ascending=False)\ndisplay(feature_importances)\n\nfeat_importances = pd.Series(rf.feature_importances_, index=cont_x_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')"},{"metadata":{},"cell_type":"raw","source":"rf = RandomForestClassifier(max_depth=4, random_state=4)\n\n\nrf.fit(cont_x_train, cont_y_train)\nprint(rf.score(cont_x_test, cont_y_test))\nfeature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = cont_x_train.columns,\n                                    columns=['importance']).sort_values('importance', ascending=False)\ndisplay(feature_importances)\n\nfeat_importances = pd.Series(rf.feature_importances_, index=cont_x_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')"},{"metadata":{},"cell_type":"raw","source":"rf = RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')\nscores = cross_validate(rf, x, y)\nprint(scores)"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\nscores = cross_validate(et, x_scaled, y)\nprint(scores)"},{"metadata":{},"cell_type":"raw","source":"knn = KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)\nscores = cross_validate(knn, x, y)\nprint(scores)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"# for Extra tree\nparams = dict(n_estimators = list(range(500, 650, 50)), \n              max_depth = list(range(35, 41, 1)),\n              criterion = ['gini', 'entropy'],\n              #max_features = [list(range(10, 15, 1))],\n              warm_start = [True, False],\n              random_state = list(range(1, 6, 1)),\n              bootstrap = [True, False]\n            )\ntotal = 1\nfor key in params.keys():\n    total = total * len(params[key])\nprint(total)\nn_iter = np.sqrt(total)\nprint(n_iter)\n\n\net = ExtraTreesClassifier(n_jobs=-1)\nclf = RandomizedSearchCV(et, params, random_state=0, n_iter=n_iter)\nclf.fit(x, y)\nclf.best_params_"},{"metadata":{},"cell_type":"raw","source":"params_knn = dict(n_neighbors = list(range(2, 10, 1)), \n                weights = ['uniform', 'distance'],\n              algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute'],\n              p = [1,2]\n            )\ntotal = 1\nfor key in params_knn.keys():\n    total = total * len(params_knn[key])\nprint(total)\nn_iter = total/4\nprint(n_iter)\n\nknn = KNeighborsClassifier(n_jobs=-1)\nclf = RandomizedSearchCV(knn, params_knn, random_state=0, n_iter=n_iter)\nclf.fit(x, y)\nclf.best_params_"},{"metadata":{},"cell_type":"raw","source":"params_gb = dict(n_estimators = list(range(400, 700, 25)),\n                 loss = ['deviance'],\n                 learning_rate=list(np.arange(0.1, 1.0, 0.1)),\n                 criterion = ['friedman_mse', 'mse', 'mae'],\n              max_depth = list(range(1, 6, 1)),\n              warm_start = [True, False],\n              random_state = list(range(1, 6, 1))\n            )\ntotal = 1\nfor key in params_gb.keys():\n    total = total * len(params_gb[key])\nn_iter = np.sqrt(total)/4\nprint(n_iter)\n\ngb = GradientBoostingClassifier()\nclf = RandomizedSearchCV(gb, params_gb, random_state=0, n_iter=n_iter)\nclf.fit(x, y)\nclf.best_params_"},{"metadata":{"trusted":true},"cell_type":"raw","source":"rf = RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')\nrf.fit(x, y)\ny_pred = rf.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('rf.csv', index=False)\n\npredictions_rf = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x, y)\ny_pred = et.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('et.csv', index=False)\n\npredictions_et = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"knn = KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)\n\nknn.fit(x_scaled, y)\ny_pred = knn.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('knn-scaled.csv', index=False)\n\npredictions_knn_sc = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n                                         max_depth=3, random_state=0)\ngb.fit(x, y)\ny_pred = gb.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('gb-02.csv', index=False)\n\npredictions_gb = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"clf = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100), max_iter=1000)\n\nclf.fit(x_scaled, y)\ny_pred = clf.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('mlp-sc_5_100.csv', index=False)\n\npredictions_mlp_sc = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"svc = SVC(decision_function_shape='ovo', gamma = 'scale',\n        kernel = 'rbf', C = 1.4, random_state = 3)\n\nsvc.fit(x_scaled, y)\ny_pred = svc.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('svc-scaled.csv', index=False)\n\npredictions_svc_sc = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"predictions_rf.rename(columns= {\"Cover_Type\" : \"RF\"}, inplace=True)\npredictions_et.rename(columns= {\"Cover_Type\" : \"ET\"}, inplace=True)\npredictions_knn_sc.rename(columns= {\"Cover_Type\" : \"KNN-SC\"}, inplace=True)\npredictions_gb.rename(columns= {\"Cover_Type\" : \"GB\"}, inplace=True)\npredictions_mlp_sc.rename(columns= {\"Cover_Type\" : \"MLP-SC\"}, inplace=True)\npredictions_svc_sc.rename(columns= {\"Cover_Type\" : \"SVC-SC\"}, inplace=True)\n\n\nresult = pd.concat([predictions_rf, predictions_et, predictions_knn_sc, predictions_gb, predictions_mlp_sc, predictions_svc_sc], axis=1)\ndisplay(result)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"result.corr()"},{"metadata":{"trusted":true},"cell_type":"raw","source":"mode = result.mode(axis=1)\ndisplay(mode[0])\n\nresult['Cover_Type'] = np.where(mode.isna().any(1), mode[0], result['ET'])\ndisplay(result)\n\n\npredictions_test = result['Cover_Type']\ndisplay(predictions_test)\n\nresult1 = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result1)\n\nresult1.to_csv('max-voting.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"knn = KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)\n\nknn.fit(x, y)\ny_pred = knn.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('knn.csv', index=False)\n\npredictions_knn = predictions_test"},{"metadata":{"trusted":true},"cell_type":"raw","source":"gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.7,\n                                         max_depth=3, random_state=0)\ngb.fit(x, y)\ny_pred = gb.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('gb.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"params_gb = dict(loss = ['deviance'],\n                 learning_rate=[0.6,0.7,0.8],\n                 criterion = ['friedman_mse', 'mse', 'mae'],\n              max_depth = list(range(1, 6, 1)),\n              warm_start = [True, False],\n              random_state = list(range(2, 4, 1))\n            )\ntotal = 1\nfor key in params_gb.keys():\n    total = total * len(params_gb[key])\nn_iter = np.sqrt(total)/2\nprint(n_iter)\n\ngb = GradientBoostingClassifier(n_estimators = 600)\nclf = RandomizedSearchCV(gb, params_gb, random_state=0, n_iter=n_iter, n_jobs=-1)\nclf.fit(x, y)\nclf.best_params_"},{"metadata":{},"cell_type":"raw","source":"gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.1,\n                                         max_depth=3, random_state=0)\ngb.fit(x, y)\ny_pred = gb.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('gb-01.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"estimators = [\n('rf', RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')),\n('et', ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)),\n('knn-sc', KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)),\n('gb', GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, max_depth=3, random_state=0)),\n('mlp-sc', MLPClassifier(hidden_layer_sizes=(100,100,100,100,100), max_iter=1000)),\n('svc-sc', SVC(decision_function_shape='ovo', gamma = 'scale',\n        kernel = 'rbf', C = 1.4, random_state = 3)),\n]\n\nfinal_estimator = xgb.XGBClassifier(learning_rate = 0.95,\n n_estimators= 5000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=1,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1,\nverbose=True)\n\nclf = StackingClassifier(\n    estimators=estimators, final_estimator=final_estimator, cv=10, n_jobs=-1, stack_method='predict')\n\nclf.fit(x_scaled, y)\n\ny_pred = clf.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('stacking.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"def Stacking(model,train,y,test,n_fold):\n    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n    #test_pred=np.empty((test.shape[0],1),float)\n    #print(test_pred)\n    train_pred=np.empty((0,1),int)\n    #print(train_pred)\n    for train_indices,val_indices in folds.split(train,y.values):\n        x_train_stack,x_val=train.iloc[train_indices],train.iloc[val_indices]\n        y_train_stack,y_val=y.iloc[train_indices],y.iloc[val_indices]\n\n        model.fit(x_train_stack,y_train_stack)\n        train_pred=np.append(train_pred,model.predict(x_val))\n        #print(train_pred)\n        #test_pred=np.append(test_pred,model.predict(test))\n    #print(\"testing\")\n    model.fit(train, y)\n    test_pred = model.predict(test)\n    #print(test_pred)\n    return test_pred,train_pred"},{"metadata":{"trusted":true},"cell_type":"raw","source":"rf = RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')\n\net = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\nknn_sc = KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)\n\ngb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, max_depth=3, random_state=0)\n\nmlp_sc = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100), max_iter=1000)\n\nsvc_sc = SVC(decision_function_shape='ovo', gamma = 'scale',\n        kernel = 'rbf', C = 1.4, random_state = 3)\n\n\nclf_list = [rf, et, knn_sc, gb, mlp_sc, svc_sc]\n\n\ndf_train = pd.DataFrame()\ndf_test = pd.DataFrame()\n\nfor clf in clf_list:                                   \n    test_pred_clf ,train_pred_clf = Stacking(model=clf, n_fold=10, train=x_scaled,test=test_scaled,y=y)\n    train_pred_clf = pd.DataFrame(train_pred_clf)\n    test_pred_clf = pd.DataFrame(test_pred_clf)\n    #display(train_pred_clf)\n    #display(test_pred_clf)\n    df_train = pd.concat([df_train, train_pred_clf], axis = 1)\n    df_test = pd.concat([df_test, test_pred_clf], axis = 1)\n               \ncols = ['RF', 'ET', 'KNN-SC', 'GB', 'MLP-SC', 'SVC-SC']\n\ndf_train.columns = cols\ndf_test.columns = cols\ndisplay(df_train)\ndisplay(df_test)\n\ngbm =  xgb.XGBClassifier(learning_rate = 0.95,\n n_estimators= 5000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=1,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1,\nverbose=True)\n\n\ngbm.fit(df_train, y)\ny_xgb = gbm.predict(df_test)\n\npredictions_test = pd.DataFrame(y_xgb, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('stacking-custom1.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"lr = LogisticRegression(multi_class='ovr', verbose=1, n_jobs=-1, max_iter=500, penalty='none')\nscores = cross_validate(lr, x_scaled, y)\nprint(scores)"},{"metadata":{},"cell_type":"raw","source":"estimators = [\n('rf', RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')),\n('et', ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)),\n('knn', KNeighborsClassifier(weights= 'distance', p=1, n_neighbors=2, algorithm='ball_tree', n_jobs=-1)),\n('gb', GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, max_depth=3, random_state=0)),\n('svc', )\n]\n\nclf = VotingClassifier(estimators=estimators, voting='hard')\nclf.fit(x_train, y_train)\nclf.score(x_test, y_test)"},{"metadata":{},"cell_type":"raw","source":"clf = VotingClassifier(estimators=estimators, voting='hard')\n\nclf.fit(x, y)\ny_pred = clf.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('voting.csv', index=False)\n\npredictions_vote = predictions_test"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x, y)\ny_pred = et.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('et-without-scaled.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"rf = RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')\nrf.fit(x, y)\ny_pred = rf.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('rf_without_scaled.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"rf = RandomForestClassifier(n_jobs=-1, max_features=10, \n                            warm_start =  False,\n                            random_state = 5,\n                            n_estimators = 550,\n                            max_depth = 20,\n                            criterion = 'entropy')\nrf.fit(x_scaled, y)\ny_pred = rf.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('rf-scaled.csv', index=False)"},{"metadata":{},"cell_type":"raw","source":"et = ExtraTreesClassifier(n_jobs=-1, \n                        warm_start=False,\n                        random_state=5,\n                          max_depth=37,\n                        n_estimators= 600,\n                        criterion= 'entropy',\n                        bootstrap= False)\n\net.fit(x_scaled, y)\ny_pred = et.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('et-scaled-feature-engg-no-selection.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n                                         max_depth=3, random_state=0)\ngb.fit(x, y)\ny_pred = gb.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('gb-without-scaled.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n                                         max_depth=3, random_state=0)\ngb.fit(x_scaled, y)\ny_pred = gb.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('gb-scaled.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"gbm = xgb.XGBClassifier(learning_rate = 0.95,\n n_estimators= 5000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=1,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1,\nverbose=True)\n\ngbm.fit(x, y)\ny_pred = gbm.predict(test_data)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('XGB-without-scaled.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"raw","source":"gbm = xgb.XGBClassifier(learning_rate = 0.95,\n n_estimators= 5000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=1,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1,\nverbose=True)\n\ngbm.fit(x_scaled, y)\ny_pred = gbm.predict(test_scaled)\n\npredictions_test = pd.DataFrame(y_pred, columns = ['Cover_Type'])\ndisplay(predictions_test)\n\nresult = pd.concat([test_data_Id, predictions_test], axis=1)\ndisplay(result)\n\nresult.to_csv('XGB-scaled.csv', index=False)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}