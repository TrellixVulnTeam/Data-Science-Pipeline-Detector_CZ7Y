{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install ensemble-boxes","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:55:43.530458Z","iopub.execute_input":"2022-05-15T11:55:43.531244Z","iopub.status.idle":"2022-05-15T11:55:43.534635Z","shell.execute_reply.started":"2022-05-15T11:55:43.531191Z","shell.execute_reply":"2022-05-15T11:55:43.533994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IMPORT LIBRARY**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport os\nimport pydicom\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom skimage import exposure\nimport cv2\nimport warnings\nfrom sklearn import preprocessing\nfrom scipy.stats import norm\nwarnings.filterwarnings('ignore')\n# PRESETS\nFIG_FONT = dict(family=\"Helvetica, Arial\", size=14, color=\"#7f7f7f\")\nLABEL_COLORS = [px.colors.label_rgb(px.colors.convert_to_RGB_255(x)) for x in sns.color_palette(\"Spectral\", 15)]\nLABEL_COLORS_WOUT_NO_FINDING = LABEL_COLORS[:8]+LABEL_COLORS[9:]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:56:02.304793Z","iopub.execute_input":"2022-05-15T11:56:02.305094Z","iopub.status.idle":"2022-05-15T11:56:02.316098Z","shell.execute_reply.started":"2022-05-15T11:56:02.305062Z","shell.execute_reply":"2022-05-15T11:56:02.315029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FUNCTION**","metadata":{}},{"cell_type":"code","source":"label2color = [[59, 238, 119], [222, 21, 229], [94, 49, 164], [206, 221, 133], [117, 75, 3],\n                 [210, 224, 119], [211, 176, 166], [63, 7, 197], [102, 65, 77], [194, 134, 175],\n                 [209, 219, 50], [255, 44, 47], [89, 125, 149], [110, 27, 100]]\n\nviz_labels =  [\"Aortic_enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\",\n            \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung_Opacity\", \"Nodule/Mass\",\n            \"Other_lesion\", \"Pleural_effusion\", \"Pleural_thickening\", \"Pneumothorax\",\n            \"Pulmonary_fibrosis\"]\n\ndef plot_img(img, size=(18, 18), is_rgb=True, title=\"\", cmap=None):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\ndef plot_imgs(imgs, cols=2, size=10, is_rgb=True, title=\"\", cmap=None, img_size=None):\n    rows = len(imgs)//cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    return fig\n    \ndef draw_bbox(image, box, label, color):   \n    alpha = 0.4\n    alpha_font = 0.6\n    thickness = 4\n    font_size = 2.0\n    font_weight = 2\n    overlay_bbox = image.copy()\n    overlay_text = image.copy()\n    output = image.copy()\n\n    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_weight)[0]\n    cv2.rectangle(overlay_bbox, (box[0], box[1]), (box[2], box[3]),\n                color, -1)\n    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n    cv2.rectangle(overlay_text, (box[0], box[1]-18-text_height), (box[0]+text_width+8, box[1]),\n                (0, 0, 0), -1)\n    cv2.addWeighted(overlay_text, alpha_font, output, 1 - alpha_font, 0, output)\n    cv2.rectangle(output, (box[0], box[1]), (box[2], box[3]),\n                    color, thickness)\n    cv2.putText(output, label.upper(), (box[0], box[1]-12),\n            cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 255, 255), font_weight, cv2.LINE_AA)\n    return output\n\ndef draw_bbox_small(image, box, label, color):   \n    alpha = 0.4\n    alpha_text = 0.4\n    thickness = 1\n    font_size = 0.4\n    overlay_bbox = image.copy()\n    overlay_text = image.copy()\n    output = image.copy()\n\n    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, font_size, thickness)[0]\n    cv2.rectangle(overlay_bbox, (box[0], box[1]), (box[2], box[3]),\n                color, -1)\n    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n    cv2.rectangle(overlay_text, (box[0], box[1]-7-text_height), (box[0]+text_width+2, box[1]),\n                (0, 0, 0), -1)\n    cv2.addWeighted(overlay_text, alpha_text, output, 1 - alpha_text, 0, output)\n    cv2.rectangle(output, (box[0], box[1]), (box[2], box[3]),\n                    color, thickness)\n    cv2.putText(output, label.upper(), (box[0], box[1]-5),\n            cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 255, 255), thickness, cv2.LINE_AA)\n    return output\ndef Visualize_class(df, feature, title):\n    num_image = df[feature].value_counts().rename_axis(feature).reset_index(name='num_image')\n    fig = px.bar(num_image[::-1], x='num_image', y=feature, orientation='h', color='num_image')\n    fig.update_layout(\n    title={\n        'text': title,\n        'y':0.95,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:56:04.128749Z","iopub.execute_input":"2022-05-15T11:56:04.129498Z","iopub.status.idle":"2022-05-15T11:56:04.160456Z","shell.execute_reply.started":"2022-05-15T11:56:04.129451Z","shell.execute_reply":"2022-05-15T11:56:04.159033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LOAD DATA**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/vinbigdata-512-image-dataset/vinbigdata/train.csv')\ntrain_df['image_path'] = f'/kaggle/input/vinbigdata-512-image-dataset/vinbigdata/train/'+train_df.image_id+'.png'\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:56:32.343474Z","iopub.execute_input":"2022-05-15T11:56:32.344181Z","iopub.status.idle":"2022-05-15T11:56:32.487975Z","shell.execute_reply.started":"2022-05-15T11:56:32.344143Z","shell.execute_reply":"2022-05-15T11:56:32.486987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"markdown","source":"**1.Class Distribution**","metadata":{}},{"cell_type":"code","source":"Visualize_class(train_df, feature='class_name', title='Types of thoracic abnormalities')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:56:35.715758Z","iopub.execute_input":"2022-05-15T11:56:35.716393Z","iopub.status.idle":"2022-05-15T11:56:35.797666Z","shell.execute_reply.started":"2022-05-15T11:56:35.716341Z","shell.execute_reply":"2022-05-15T11:56:35.796838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.Radius Distribution**","metadata":{}},{"cell_type":"markdown","source":"**From the histogram plotted below we can ascertain the following information**\n\n* 3 of the radiologists (R9, R10, & R8 in that order) are responsible for the vast majority of annotations (~40-50% of all annotations)\n* Among the other 14 radiologists there is some variation around the number of annotations made, however, these 14 radiologists all made between 3121 annotations and 812 annotations with the vast majority annotating 1800-2200 objects.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(train_df, x=\"rad_id\", color=\"rad_id\",opacity=0.85,\n                   labels={\"rad_id\":\"Radiologist ID\"},\n                   ).update_xaxes(categoryorder=\"total descending\")\nfig.update_layout(legend_title=\"<b>RADIOLOGIST ID</b>\",\n                  xaxis_title=\"<b>Radiologist ID</b>\",\n                  yaxis_title=\"<b>Number of Annotations Made</b>\",\n                  font=FIG_FONT,)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:56:39.676711Z","iopub.execute_input":"2022-05-15T11:56:39.677304Z","iopub.status.idle":"2022-05-15T11:56:40.542864Z","shell.execute_reply.started":"2022-05-15T11:56:39.677254Z","shell.execute_reply":"2022-05-15T11:56:40.542045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.TOTAL OBJECT ANNOTATIONS PER IMAGE**","metadata":{}},{"cell_type":"markdown","source":"**From the histogram plotted below we can ascertain the following information:**\n\n* Images contain at least 3 annotations (1 distinct object annotation by 3 radiologists)\n* Images contain at most 57 annotations (19 distinct object annotations by 3 radiologists)\n* The vast majority of images only have 3 annotations (~11,000 out of 15,000 images)\n* The distribution has a heavy skew (value=3.8687 # FROM --> scipy.stats.skew(train_df.image_id.value_counts().values)). Remember that a perfectly symetrical distribution would have a skew value of 0.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(train_df.image_id.value_counts(), \n                   log_y=True, color_discrete_sequence=['indianred'], opacity=0.7,\n                   labels={\"value\":\"Number of Annotations Per Image\"},\n                   )\nfig.update_layout(showlegend=False,\n                  xaxis_title=\"<b>Number of Unique Images</b>\",\n                  yaxis_title=\"<b>Count of All Object Annotations</b>\",)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:56:45.173957Z","iopub.execute_input":"2022-05-15T11:56:45.174289Z","iopub.status.idle":"2022-05-15T11:56:45.330146Z","shell.execute_reply.started":"2022-05-15T11:56:45.174254Z","shell.execute_reply":"2022-05-15T11:56:45.32897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the histogram plotted below we can ascertain the following information:**\n\n* Images contain no more than 10 unique abnormalities (out of a possible 14)\n* The more unique abnormalities present in an image, the rarer it is.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(train_df.groupby('image_id')[\"class_name\"].unique().apply(lambda x: len(x)), \n             log_y=True, color_discrete_sequence=['skyblue'], opacity=0.7,\n             labels={\"value\":\"Number of Unique Abnormalities\"},\n\n                   )\nfig.update_layout(showlegend=False,\n                  xaxis_title=\"<b>Number of Unique Abnormalities</b>\",\n                  yaxis_title=\"<b>Count of Unique Patients</b>\",\n                  font=FIG_FONT,)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:57:24.76769Z","iopub.execute_input":"2022-05-15T11:57:24.76805Z","iopub.status.idle":"2022-05-15T11:57:25.751452Z","shell.execute_reply.started":"2022-05-15T11:57:24.768014Z","shell.execute_reply":"2022-05-15T11:57:25.750904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualize Original vs Fused**","metadata":{}},{"cell_type":"code","source":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)\ntrain_df_wbf = pd.read_csv('../input/effdet-latestvinbigdata-wbf-fused/train_wbf_original.csv', index_col='Unnamed: 0')\ntrain_df_wbf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:55:44.686994Z","iopub.execute_input":"2022-05-15T11:55:44.687209Z","iopub.status.idle":"2022-05-15T11:55:44.782996Z","shell.execute_reply.started":"2022-05-15T11:55:44.687181Z","shell.execute_reply":"2022-05-15T11:55:44.782139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz_images = []\n\nfor img_id in train_df_wbf['image_id'].unique()[:2]:\n    img_path = train_df_wbf[train_df_wbf.image_id==img_id]['image_path'].iloc[0]\n#     print(img_path)\n    img_array  = cv2.imread(img_path)\n\n    img_annotations = train_df[train_df.image_id==img_id]\n    boxes_actual = img_annotations[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n    labels_actual = img_annotations['class_id'].to_numpy().tolist()\n    img_annotations_wbf = train_df_wbf[train_df_wbf.image_id==img_id]\n    boxes_wbf = img_annotations_wbf[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n    box_labels_wbf = img_annotations_wbf['class_id'].to_numpy().tolist()\n    \n    print(\"Bboxes before WBF:\\n\", boxes_actual)\n    print(\"Labels before WBF:\\n\", labels_actual)\n    \n    ## Visualize Original Bboxes\n    img_before = img_array.copy()\n    for box, label in zip(boxes_actual, labels_actual):\n        x_min, y_min, x_max, y_max = (box[0], box[1], box[2], box[3])\n        color = label2color[int(label)]\n        img_before = draw_bbox(img_before, list(np.int_(box)), viz_labels[label], color)\n    viz_images.append(img_before)\n\n    print(\"Bboxes after WBF:\\n\", boxes_wbf)\n    print(\"Labels after WBF:\\n\", box_labels_wbf)\n    \n    ## Visualize Bboxes after operation\n    img_after = img_array.copy()\n    for box, label in zip(boxes_wbf, box_labels_wbf):\n        color = label2color[int(label)]\n        img_after = draw_bbox(img_after, list(np.int_(box)), viz_labels[label], color)\n    viz_images.append(img_after)\n    print()\n        \nplot_imgs(viz_images, cmap=None)\nplt.figtext(0.3, 0.9,\"Original Bboxes\", va=\"top\", ha=\"center\", size=25)\nplt.figtext(0.73, 0.9,\"WBF\", va=\"top\", ha=\"center\", size=25)\nplt.savefig('wbf.png', bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:55:44.784181Z","iopub.execute_input":"2022-05-15T11:55:44.784393Z","iopub.status.idle":"2022-05-15T11:55:52.460269Z","shell.execute_reply.started":"2022-05-15T11:55:44.784369Z","shell.execute_reply":"2022-05-15T11:55:52.459444Z"},"trusted":true},"execution_count":null,"outputs":[]}]}