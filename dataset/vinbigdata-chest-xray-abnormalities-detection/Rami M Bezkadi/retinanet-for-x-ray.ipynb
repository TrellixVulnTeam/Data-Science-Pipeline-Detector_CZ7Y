{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"'''\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import math\nimport os\nimport shutil\nimport sys\nfrom keras.preprocessing.image import array_to_img\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.patches as ptc\nimport matplotlib\nimport seaborn as sns\nimport glob\nimport pydicom\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nlistfile=[]\nfiles=os.listdir(\"../input/dicom-to-512jpg-train\") \nfor file in files: \n    if os.path.isfile(\"../input/dicom-to-512jpg-train/\" + file):\n        listfile.append(file)\nlen(listfile)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#load data from dicom\nmy_annots=pd.read_csv(\"../input/dicom-to-jpg/2000_data_dim_convert.csv\")\nmy_annots=my_annots.iloc[:,1:]\nmy_annots.image_id= my_annots.image_id.apply(lambda x: '../../input/dicom-to-jpg/'+  x + '.jpg')\nannotations=my_annots[['image_id','x_min', 'y_min', 'x_max', 'y_max', 'class_name']]\nannotations.to_csv('annotations.csv')\nclasses=my_annots.class_name.unique()\nclass_id=my_annots.class_id.unique()\n\n\nwith open('classes.csv', mode='w') as file:\n    for  clss ,i in zip(classes,class_id ):\n        file.write('{},{}\\n'.format(clss, i))\namount_80 = int(0.8*len(annotations))\ntrain_data = annotations[:amount_80]\ntest_data = annotations[amount_80:]\nprint(len(train_data))\nprint(len(test_data))\n\ntrain_data.to_csv(path_or_buf='train_annotations.csv', index=False, header=None)\ntest_data.to_csv(path_or_buf='val_annotations.csv', index=False, header=None)\n\n'''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data=pd.read_csv(\"/kaggle/input/img-dim-train/train_img_dim.csv\")\nannots=train_data.copy()\nannots= annots[annots.class_id != 14] #drop NO Finding class\nIMG_SIZE=512\ndef norm_df(df):\n    df.x_min= ((df.x_min/ df.width)* IMG_SIZE).astype('int32')\n    df.x_max=( (df.x_max/ df.width)* IMG_SIZE).astype('int32')\n    \n    df.y_min= ((df.y_min/ df.height)* IMG_SIZE).astype('int32')\n    df.y_max= ((df.y_max/ df.height)* IMG_SIZE).astype('int32')\n    return df\nalldata=norm_df(annots.copy()).reset_index(drop = True)\n#smalldata = df[0:20000] # first 20000 \n#smalldata.to_csv('20000_data_dim_convert.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom matplotlib.pyplot import figure\nimport warnings\n\n#load data from dicom\n#my_annots=pd.read_csv(\"../../input/dicom-to-512jpg-train/20000_data_dim_convert.csv\")\n#my_annots=pd.read_csv(\"/kaggle/input/dicom-to-512jpg-train/20000_data_dim_convert.csv\")\nmy_annots=alldata\n#my_annots=my_annots.iloc[:,1:]\nmy_annots.image_id= my_annots.image_id.apply(lambda x: '../input/dicom-to-512jpg-train/'+  x + '.jpg')\nannotations=my_annots[['image_id','x_min', 'y_min', 'x_max', 'y_max', 'class_name']]\nannotations.to_csv('annotations.csv')\nclasses=my_annots.class_name.unique()\nclass_id=my_annots.class_id.unique()\n\nwith open('classes.csv', mode='w') as file:\n    for  clss ,i in zip(classes,class_id ):\n        file.write('{},{}\\n'.format(clss, i))\n#amount_80 = int(0.85*len(annotations))\n#train_data = annotations[:amount_80]\n#test_data = annotations[amount_80:]\n\n\nwarnings.filterwarnings('ignore')\n\n#df = pd.read_csv(r'../input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\ndf = pd.DataFrame(my_annots)\ndf = df[df['class_name'] != 'No finding']\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\ndf_folds = df[['image_id']].copy()\n\ndf_folds.loc[:, 'bbox_count'] = 1\ndf_folds = df_folds.groupby('image_id').count()\ndf_folds.loc[:, 'object_count'] = df.groupby('image_id')['class_id'].nunique()\n\ndf_folds.loc[:, 'stratify_group'] = np.char.add(\n    df_folds['object_count'].values.astype(str),\n    df_folds['bbox_count'].apply(lambda x: f'_{x // 15}').values.astype(str)\n)\n\ndf_folds.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds['stratify_group'])):\n    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = fold_number\n\n# example with fold 0\ndf_folds.reset_index(inplace=True)\n\ndf_valid = pd.merge(df, df_folds[df_folds['fold'] == 0], on='image_id')\n\ndf_train = pd.merge(df, df_folds[df_folds['fold'] != 0], on='image_id')\n\nfigure(num=None, figsize=(30, 8))\ndf_train['class_name'].hist()\ndf_valid['class_name'].hist()\nplt.show()\n\n'''\ntrain_data,test_data =train_test_split (annotations,test_size=0.15, random_state=42)\nprint(len(train_data))\nprint(len(test_data))\n\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data=df_train[['image_id','x_min', 'y_min', 'x_max', 'y_max', 'class_name']]\ntest_data=df_valid[['image_id','x_min', 'y_min', 'x_max', 'y_max', 'class_name']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data= train_data.drop(train_data[train_data.y_max== train_data.y_min].index[0])\ntest_data= test_data.drop(test_data[test_data.y_max== test_data.y_min].index[0])\ntrain_data.to_csv(path_or_buf='train_annotations.csv', index=False, header=None)\ntest_data.to_csv(path_or_buf='val_annotations.csv', index=False, header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5',\n'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet101_oid_v1.0.0.h5',\n'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet152_oid_v1.0.0.h5'\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!mkdir weights\n!wget -O /kaggle/working/weights/resnet50_coco_best_v2.h5 https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir /kaggle/working/snapshots\n!mkdir /kaggle/working/tensorboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd ~\n!git clone https://github.com/fizyr/keras-retinanet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!git clone 'https://github.com/fizyr/keras-retinanet.git'\n%cd keras-retinanet/\n!pip install .\n!python setup.py build_ext --inplace\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd ~\n%ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /kaggle/working/keras-retinanet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!keras_retinanet/bin/train.py --freeze-backbone \\\n  --random-transform \\\n  --workers 0 \\\n  --weights /kaggle/working/weights/resnet50_coco_best_v2.h5 \\\n  --batch-size 10 \\\n  --steps 352 \\\n  --image-min-side 512\\\n  --image-max-side 512\\\n  --epochs 50 \\\n  csv /kaggle/working/train_annotations.csv /kaggle/working/classes.csv\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nmodel_paths = glob('./snapshots/resnet50_csv_*.h5')\nlatest_path = sorted(model_paths)[-1]\nprint(\"path:\", latest_path)\n\n\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\n#\n#model = models.load_model(latest_path, backbone_name='resnet50')\n#model = models.convert_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!retinanet-convert-model ./snapshots/resnet50_csv_50.h5 \\\n/kaggle/working/weights/resnet50_csv_final.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\n# import keras_retinanet\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n#from keras_retinanet.keras_retinanet.utils.gpu import setup_gpu\n\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nimport cv2\nimport csv\nimport os\nimport numpy as np\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%cd ./keras-retinanet\n%ls\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = os.path.join('/kaggle/working/weights', 'resnet50_csv_final.h5')\n\n# load retinanet model\nmodel = models.load_model(model_path, backbone_name='resnet50')\n\n\n##########\n\nlabels_to_names = {\n    0: 'Aortic enlargement', \n    1: 'Atelectasis',\n    2: 'Calcification',\n    3: 'Cardiomegaly',\n    4: 'Consolidation',\n    5: 'ILD',\n    6: 'Infiltration',\n    7: 'Lung Opacity',\n    8: 'Nodule/Mass',\n    9:'Other lesion',\n    10: 'Pleural effusion',\n    11: 'Pleural thickening',\n    12: 'Pneumothorax',\n    13:'Pulmonary fibrosis'}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%cd /kaggle/\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1=pd.read_csv('./input/sample/sample_submission .csv')\nsub2=pd.read_csv('./input/test-img-dim/test.csv')\nsub=pd.DataFrame.merge(sub1,sub2,on='image_id')\nmysub=sub.copy()\nmysub['thispath']='./input/dicom-to-512jpg-test/'+mysub.image_id+'.jpg'\nmysub['score']=''\nmysub.head()\n#mysub['predictionstring']='14 1 0 0 1 1'\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## predict and submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"thr=0.5\n#mysub=mysub[:50].copy() \nfields = ['image_id', 'PredictionString','score'] \nwith open('submission.csv', mode='w') as csvfile:\n    csvwriter = csv.writer(csvfile) \n    csvwriter.writerow(fields)\n\n    for row in tqdm(mysub.values) :\n        imgpath=row[4]\n        width=row[2]\n        height=row[3]\n        #predictionstring=row[4]\n        \n        image = read_image_bgr(imgpath)\n        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n        \n        x= int(width)/512\n        y= int(height)/512\n        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n            row[5]=score\n            if score < thr:\n                #row[1]=\"14 1 0 0 1 1\"\n                csvfile.write('{},{},{}\\n'.format(row[0], row[1] ,row[5]))\n                break\n           \n            row[1]= '{} {:.2f} {} {} {} {} '.format(label ,score , int(box[0]*x), int(box[1]*y),int((box[2])*x), int((box[3])*y))\n            \n            csvfile.write('{},{},{}\\n'.format(row[0], row[1],row[5]))\npresubmission=pd.read_csv('submission.csv')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"presubmission.to_csv('/kaggle/working/presubmission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=presubmission.groupby('image_id')['PredictionString'].apply(' '.join).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv',index = False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!retinanet-evaluate csv /kaggle/working/val_annotations.csv /kaggle/working/classes.csv /kaggle/working/weights/resnet50_csv_final.h5\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}