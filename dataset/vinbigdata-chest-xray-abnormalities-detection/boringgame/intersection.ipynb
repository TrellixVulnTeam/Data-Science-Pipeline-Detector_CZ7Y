{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Version\n* `v13`: Fold4\n* `v12`: Fold3\n* `v10`: Fold2\n* `v09`: Fold1\n* `v03`: Fold0"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-01-01T09:44:43.843489Z","iopub.status.busy":"2021-01-01T09:44:43.842712Z","iopub.status.idle":"2021-01-01T09:44:53.448523Z","shell.execute_reply":"2021-01-01T09:44:53.447971Z"},"papermill":{"duration":9.633907,"end_time":"2021-01-01T09:44:53.448657","exception":false,"start_time":"2021-01-01T09:44:43.81475","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!pip install --upgrade seaborn\n!pip install ensemble_boxes","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:44:53.50848Z","iopub.status.busy":"2021-01-01T09:44:53.50769Z","iopub.status.idle":"2021-01-01T09:44:54.403472Z","shell.execute_reply":"2021-01-01T09:44:54.402433Z"},"papermill":{"duration":0.926929,"end_time":"2021-01-01T09:44:54.403588","exception":false,"start_time":"2021-01-01T09:44:53.476659","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dim = 512 #512, 256, 'original'\nfold = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 准备数据"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:44:54.468231Z","iopub.status.busy":"2021-01-01T09:44:54.467706Z","iopub.status.idle":"2021-01-01T09:44:54.690894Z","shell.execute_reply":"2021-01-01T09:44:54.69183Z"},"papermill":{"duration":0.262045,"end_time":"2021-01-01T09:44:54.691965","exception":false,"start_time":"2021-01-01T09:44:54.42992","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(f'../input/vinbigdata-{dim}-image-dataset/vinbigdata/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:44:54.7506Z","iopub.status.busy":"2021-01-01T09:44:54.749926Z","iopub.status.idle":"2021-01-01T09:44:54.80575Z","shell.execute_reply":"2021-01-01T09:44:54.804838Z"},"papermill":{"duration":0.086788,"end_time":"2021-01-01T09:44:54.805857","exception":false,"start_time":"2021-01-01T09:44:54.719069","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_df['image_path'] = f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/train/'+train_df.image_id+('.png' if dim!='original' else '.jpg')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.027478,"end_time":"2021-01-01T09:44:54.861374","exception":false,"start_time":"2021-01-01T09:44:54.833896","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Only 14 Class"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:44:54.922292Z","iopub.status.busy":"2021-01-01T09:44:54.921364Z","iopub.status.idle":"2021-01-01T09:44:54.943995Z","shell.execute_reply":"2021-01-01T09:44:54.943575Z"},"papermill":{"duration":0.05543,"end_time":"2021-01-01T09:44:54.944088","exception":false,"start_time":"2021-01-01T09:44:54.888658","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 将no finding去掉\ntrain_df = train_df[train_df.class_id!=14].reset_index(drop = True)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\n\n# df.head()\n\n# train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train_df[train_df[\"image_id\"] == '9a5094b2563a1ef3ff50dc5c7ff71345']\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n\n# from tqdm import tqdm\n# from ensemble_boxes import *\n\n# # ===============================\n# # Default WBF config (you can change these)\n# iou_thr = 0.5\n# skip_box_thr = 0.0001\n# sigma = 0.1\n# # ===============================\n\n# # Loading the train DF\n# # df = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\n# df = train_df\n# df.fillna(0, inplace=True)\n# # df.loc[df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\n# results = []\n# image_ids = df[\"image_id\"].unique()\n\n\n# count=3#\n\n\n# for image_id in tqdm(image_ids, total=len(image_ids)):\n#     count-=1\n#     print('count',count)\n#     if count==0:#\n#         break#\n    \n#     print('image_id',image_id)\n        \n#     # All annotations for the current image.\n#     data = df[df[\"image_id\"] == image_id]\n#     data = data.reset_index(drop=True)\n#     annotations = {}\n#     weights = []\n    \n    \n#     width=data.iloc[0].width\n#     height=data.iloc[0].height\n#     image_path=data.iloc[0].image_path\n#     class_name=data.iloc[0].class_name\n\n#     # WBF expects the coordinates in 0-1 range.\n#     max_value = data.iloc[:, 4:8].values.max()\n#     data.loc[:, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]] = data.iloc[:, 4:8] / max_value\n\n#     # Loop through all of the annotations\n#     for idx, row in data.iterrows():\n\n#         class_name_id = row[\"class_name\"]\n\n#         if class_name_id not in annotations:\n#             annotations[class_name_id] = {\n#                 \"boxes_list\": [],\n#                 \"scores_list\": [],\n#                 \"labels_list\": [],\n#             }\n\n#             # We consider all of the radiologists as equal.\n#             weights.append(1.0)\n\n#         annotations[class_name_id][\"boxes_list\"].append([row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]])\n# #         annotations[class_name_id][\"scores_list\"].append(1.0)\n#         annotations[class_name_id][\"labels_list\"].append(class_name_id)\n\n#     boxes_list = []\n#     scores_list = []\n#     labels_list = []\n    \n# #     print('annotations',annotations)\n\n#     for annotator in annotations.keys():\n#         boxes_list.append(annotations[annotator][\"boxes_list\"])\n#         scores_list.append(annotations[annotator][\"scores_list\"])\n#         labels_list.append(annotations[annotator][\"labels_list\"])\n        \n#     print()\n#     print('boxes_list',boxes_list)\n#     print()\n#     print('scores_list',scores_list)\n#     print()\n#     print('labels_list',labels_list)\n#     print()\n#     print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nfrom ensemble_boxes import *\n\n# ===============================\n# Default WBF config (you can change these)\niou_thr = 0.5\nskip_box_thr = 0.0001\nsigma = 0.1\n# ===============================\n\n# Loading the train DF\n# df = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\ndf = train_df\ndf.fillna(0, inplace=True)\n# df.loc[df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\nresults = []\nimage_ids = df[\"image_id\"].unique()\n\ncount=3#\n\n\nfor image_id in tqdm(image_ids, total=len(image_ids)):\n    count-=1\n    print('count',count)\n    if count==0:#\n        break#\n    \n    print('image_id',image_id)\n        \n    # All annotations for the current image.\n    data = df[df[\"image_id\"] == image_id]\n    data = data.reset_index(drop=True)\n    annotations = {}\n    weights = []\n    \n    \n    width=data.iloc[0].width\n    height=data.iloc[0].height\n    image_path=data.iloc[0].image_path\n    class_name=data.iloc[0].class_name\n\n    # WBF expects the coordinates in 0-1 range.\n    max_value = data.iloc[:, 4:8].values.max()\n    data.loc[:, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]] = data.iloc[:, 4:8] / max_value\n\n    # Loop through all of the annotations\n    for idx, row in data.iterrows():\n\n        rad_id = row[\"rad_id\"]\n\n        if rad_id not in annotations:\n            annotations[rad_id] = {\n                \"boxes_list\": [],\n                \"scores_list\": [],\n                \"labels_list\": [],\n            }\n\n            # We consider all of the radiologists as equal.\n            weights.append(1.0)\n\n        annotations[rad_id][\"boxes_list\"].append([row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]])\n        annotations[rad_id][\"scores_list\"].append(1.0)\n        annotations[rad_id][\"labels_list\"].append(row[\"class_id\"])\n\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    \n#     print('annotations',annotations)\n\n    for annotator in annotations.keys():\n        boxes_list.append(annotations[annotator][\"boxes_list\"])\n        scores_list.append(annotations[annotator][\"scores_list\"])\n        labels_list.append(annotations[annotator][\"labels_list\"])\n        \n#     print()\n#     print('boxes_list',boxes_list)\n#     print()\n#     print('scores_list',scores_list)\n#     print()\n#     print('labels_list',labels_list)\n#     print()\n#     print()\n    \n    # soft_nms\n    boxes, scores, labels = soft_nms(\n        boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr, sigma=sigma, thresh=skip_box_thr\n    )\n\n\n    for idx, box in enumerate(boxes):\n    results.append({\n        \"image_id\": image_id,\n        \"class_id\": int(labels[idx]),\n        \"rad_id\": \"wbf\",\n        \"x_min\": box[0] * max_value,\n        \"y_min\": box[1] * max_value,\n        \"x_max\": box[2] * max_value,\n        \"y_max\": box[3] * max_value,\n        \"width\": width,\n        \"height\": height,\n        \"image_path\": image_path,\n        \"class_name\": class_name\n    })\n\nresults = pd.DataFrame(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=results","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.027303,"end_time":"2021-01-01T09:44:54.999199","exception":false,"start_time":"2021-01-01T09:44:54.971896","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:44:55.070332Z","iopub.status.busy":"2021-01-01T09:44:55.068017Z","iopub.status.idle":"2021-01-01T09:45:02.853634Z","shell.execute_reply":"2021-01-01T09:45:02.854022Z"},"papermill":{"duration":7.821668,"end_time":"2021-01-01T09:45:02.854149","exception":false,"start_time":"2021-01-01T09:44:55.032481","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 做归一化，把左上右下四个点的坐标，计算成中心点坐标和w/h\ntrain_df['x_min'] = train_df.apply(lambda row: (row.x_min)/row.width, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)/row.height, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)/row.width, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)/row.height, axis =1)\n\ntrain_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)/2, axis =1)\ntrain_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)/2, axis =1)\n\ntrain_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain_df['area'] = train_df['w']*train_df['h']\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:45:03.000244Z","iopub.status.busy":"2021-01-01T09:45:02.999686Z","iopub.status.idle":"2021-01-01T09:45:03.002319Z","shell.execute_reply":"2021-01-01T09:45:03.002837Z"},"papermill":{"duration":0.050418,"end_time":"2021-01-01T09:45:03.002944","exception":false,"start_time":"2021-01-01T09:45:02.952526","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 类名改成str\nclass_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:45:02.917339Z","iopub.status.busy":"2021-01-01T09:45:02.916466Z","iopub.status.idle":"2021-01-01T09:45:02.923299Z","shell.execute_reply":"2021-01-01T09:45:02.922859Z"},"papermill":{"duration":0.040387,"end_time":"2021-01-01T09:45:02.923416","exception":false,"start_time":"2021-01-01T09:45:02.883029","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 取特征数据\nfeatures = ['x_min', 'y_min', 'x_max', 'y_max', 'x_mid', 'y_mid', 'w', 'h', 'area']\nX = train_df[features]\ny = train_df['class_id']\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028555,"end_time":"2021-01-01T09:45:03.060819","exception":false,"start_time":"2021-01-01T09:45:03.032264","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# t-SNE Visualization"},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-01-01T09:45:03.124237Z","iopub.status.busy":"2021-01-01T09:45:03.123599Z","iopub.status.idle":"2021-01-01T09:46:22.639291Z","shell.execute_reply":"2021-01-01T09:46:22.63991Z"},"papermill":{"duration":79.550362,"end_time":"2021-01-01T09:46:22.640073","exception":false,"start_time":"2021-01-01T09:45:03.089711","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# %%time\n# # 通过t-SNE看样本高维分布\n\n# from sklearn.manifold import TSNE\n\n# tsne = TSNE(n_components = 2, perplexity = 40, random_state=1, n_iter=5000)\n# data_X = X\n# data_y = y.loc[data_X.index]\n# embs = tsne.fit_transform(data_X)\n# # Add to dataframe for convenience\n# plot_x = embs[:, 0]\n# plot_y = embs[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:46:22.72465Z","iopub.status.busy":"2021-01-01T09:46:22.723973Z","iopub.status.idle":"2021-01-01T09:46:23.35312Z","shell.execute_reply":"2021-01-01T09:46:23.353568Z"},"papermill":{"duration":0.674101,"end_time":"2021-01-01T09:46:23.353693","exception":false,"start_time":"2021-01-01T09:46:22.679592","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize = (15, 15))\n# plt.axis('off')\n# scatter = plt.scatter(plot_x, plot_y, marker = 'o',s = 50, c=data_y.tolist(), alpha= 0.5,cmap='viridis')\n# plt.legend(handles=scatter.legend_elements()[0], labels=classes)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.043674,"end_time":"2021-01-01T09:46:23.441245","exception":false,"start_time":"2021-01-01T09:46:23.397571","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# BBox Location"},{"metadata":{"papermill":{"duration":0.041604,"end_time":"2021-01-01T09:46:23.525588","exception":false,"start_time":"2021-01-01T09:46:23.483984","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## x_mid Vs y_mid"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:46:23.61807Z","iopub.status.busy":"2021-01-01T09:46:23.617504Z","iopub.status.idle":"2021-01-01T09:46:54.970033Z","shell.execute_reply":"2021-01-01T09:46:54.970485Z"},"papermill":{"duration":31.402628,"end_time":"2021-01-01T09:46:54.970613","exception":false,"start_time":"2021-01-01T09:46:23.567985","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from scipy.stats import gaussian_kde\n\n\nx_val = train_df.x_mid.values\ny_val = train_df.y_mid.values\n\n# Calculate the point density\nxy = np.vstack([x_val,y_val])\nz = gaussian_kde(xy)(xy)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nax.axis('off')\nax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n# ax.set_xlabel('x_mid')\n# ax.set_ylabel('y_mid')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.046802,"end_time":"2021-01-01T09:46:55.064644","exception":false,"start_time":"2021-01-01T09:46:55.017842","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## bbox_w Vs bbox_h"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:46:55.166417Z","iopub.status.busy":"2021-01-01T09:46:55.165264Z","iopub.status.idle":"2021-01-01T09:47:25.595527Z","shell.execute_reply":"2021-01-01T09:47:25.59636Z"},"papermill":{"duration":30.485279,"end_time":"2021-01-01T09:47:25.596636","exception":false,"start_time":"2021-01-01T09:46:55.111357","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x_val = train_df.w.values\ny_val = train_df.h.values\n\n# Calculate the point density\nxy = np.vstack([x_val,y_val])\nz = gaussian_kde(xy)(xy)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nax.axis('off')\nax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n# ax.set_xlabel('bbox_width')\n# ax.set_ylabel('bbox_height')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.090619,"end_time":"2021-01-01T09:47:25.783368","exception":false,"start_time":"2021-01-01T09:47:25.692749","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Image Aspect Ratio\nbox的宽高"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:47:25.934898Z","iopub.status.busy":"2021-01-01T09:47:25.934095Z","iopub.status.idle":"2021-01-01T09:47:56.005305Z","shell.execute_reply":"2021-01-01T09:47:56.005822Z"},"papermill":{"duration":30.131145,"end_time":"2021-01-01T09:47:56.005954","exception":false,"start_time":"2021-01-01T09:47:25.874809","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x_val = train_df.width.values\ny_val = train_df.height.values\n\n# Calculate the point density\nxy = np.vstack([x_val,y_val])\nz = gaussian_kde(xy)(xy)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nax.axis('off')\nax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n# ax.set_xlabel('image_width')\n# ax.set_ylabel('image_height')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.052492,"end_time":"2021-01-01T09:47:56.110766","exception":false,"start_time":"2021-01-01T09:47:56.058274","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Split"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:47:56.234311Z","iopub.status.busy":"2021-01-01T09:47:56.233425Z","iopub.status.idle":"2021-01-01T09:47:56.297206Z","shell.execute_reply":"2021-01-01T09:47:56.297652Z"},"papermill":{"duration":0.134603,"end_time":"2021-01-01T09:47:56.297774","exception":false,"start_time":"2021-01-01T09:47:56.163171","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# K折验证\ngkf  = GroupKFold(n_splits = 5)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.image_id.tolist())):\n    train_df.loc[val_idx, 'fold'] = fold\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:47:56.420454Z","iopub.status.busy":"2021-01-01T09:47:56.419355Z","iopub.status.idle":"2021-01-01T09:47:56.443157Z","shell.execute_reply":"2021-01-01T09:47:56.443661Z"},"papermill":{"duration":0.086817,"end_time":"2021-01-01T09:47:56.443789","exception":false,"start_time":"2021-01-01T09:47:56.356972","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 拆分出一个训练和一个验证\ntrain_files = []\nval_files   = []\nval_files += list(train_df[train_df.fold==fold].image_path.unique())\ntrain_files += list(train_df[train_df.fold!=fold].image_path.unique())\nlen(train_files), len(val_files)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.083752,"end_time":"2021-01-01T09:47:56.584924","exception":false,"start_time":"2021-01-01T09:47:56.501172","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Copying Files"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:47:56.779532Z","iopub.status.busy":"2021-01-01T09:47:56.778609Z","iopub.status.idle":"2021-01-01T09:50:01.33093Z","shell.execute_reply":"2021-01-01T09:50:01.330431Z"},"papermill":{"duration":124.654777,"end_time":"2021-01-01T09:50:01.331041","exception":false,"start_time":"2021-01-01T09:47:56.676264","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 把标签和图片分别处理好，按照Yolov5的要求放到对应的文件夹里去\nos.makedirs('/kaggle/working/vinbigdata/labels/train', exist_ok = True)\nos.makedirs('/kaggle/working/vinbigdata/labels/val', exist_ok = True)\nos.makedirs('/kaggle/working/vinbigdata/images/train', exist_ok = True)\nos.makedirs('/kaggle/working/vinbigdata/images/val', exist_ok = True)\nlabel_dir = '/kaggle/input/vinbigdata-yolo-labels-dataset/labels'\nfor file in tqdm(train_files):\n    shutil.copy(file, '/kaggle/working/vinbigdata/images/train')\n    filename = file.split('/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/vinbigdata/labels/train')\n    \nfor file in tqdm(val_files):\n    shutil.copy(file, '/kaggle/working/vinbigdata/images/val')\n    filename = file.split('/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/vinbigdata/labels/val')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.068822,"end_time":"2021-01-01T09:50:01.458337","exception":false,"start_time":"2021-01-01T09:50:01.389515","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Get Class Name"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:50:01.595454Z","iopub.status.busy":"2021-01-01T09:50:01.594289Z","iopub.status.idle":"2021-01-01T09:50:01.60074Z","shell.execute_reply":"2021-01-01T09:50:01.601395Z"},"papermill":{"duration":0.082234,"end_time":"2021-01-01T09:50:01.601574","exception":false,"start_time":"2021-01-01T09:50:01.51934","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 获取类名\nclass_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=list(set(classes))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.056257,"end_time":"2021-01-01T09:50:01.716608","exception":false,"start_time":"2021-01-01T09:50:01.660351","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# [YOLOv5](https://github.com/ultralytics/yolov5)\n![](https://user-images.githubusercontent.com/26833433/98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg)\n![](https://user-images.githubusercontent.com/26833433/90187293-6773ba00-dd6e-11ea-8f90-cd94afc0427f.png)"},{"metadata":{"papermill":{"duration":0.055699,"end_time":"2021-01-01T09:50:01.82747","exception":false,"start_time":"2021-01-01T09:50:01.771771","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# YOLOv5 Stuff"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:50:01.950234Z","iopub.status.busy":"2021-01-01T09:50:01.949285Z","iopub.status.idle":"2021-01-01T09:50:01.995866Z","shell.execute_reply":"2021-01-01T09:50:01.996316Z"},"papermill":{"duration":0.113001,"end_time":"2021-01-01T09:50:01.996448","exception":false,"start_time":"2021-01-01T09:50:01.883447","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 做yolov5的配置文件\nfrom os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '/kaggle/working/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('/kaggle/working/vinbigdata/images/train/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('/kaggle/working/vinbigdata/images/val/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2021-01-01T09:50:02.170487Z","iopub.status.busy":"2021-01-01T09:50:02.169672Z","iopub.status.idle":"2021-01-01T09:50:08.782533Z","shell.execute_reply":"2021-01-01T09:50:08.783883Z"},"papermill":{"duration":6.702428,"end_time":"2021-01-01T09:50:08.784153","exception":false,"start_time":"2021-01-01T09:50:02.081725","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/ultralytics/yolov5\n# !git clone https://github.com/ultralytics/yolov5  # clone repo\n# %cd yolov5\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5')\n# %pip install -qr requirements.txt # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:50:08.996106Z","iopub.status.busy":"2021-01-01T09:50:08.995246Z","iopub.status.idle":"2021-01-01T09:50:19.303278Z","shell.execute_reply":"2021-01-01T09:50:19.302769Z"},"papermill":{"duration":10.410768,"end_time":"2021-01-01T09:50:19.303402","exception":false,"start_time":"2021-01-01T09:50:08.892634","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 测试官方的权重文件\n!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images/\nImage(filename='runs/detect/exp/zidane.jpg', width=600)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.064911,"end_time":"2021-01-01T09:50:19.435746","exception":false,"start_time":"2021-01-01T09:50:19.370835","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Pretrained Checkpoints:\n\n| Model | AP<sup>val</sup> | AP<sup>test</sup> | AP<sub>50</sub> | Speed<sub>GPU</sub> | FPS<sub>GPU</sub> || params | FLOPS |\n|---------- |------ |------ |------ | -------- | ------| ------ |------  |  :------: |\n| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | 37.0     | 37.0     | 56.2     | **2.4ms** | **416** || 7.5M   | 13.2B\n| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | 44.3     | 44.3     | 63.2     | 3.4ms     | 294     || 21.8M  | 39.4B\n| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | 47.7     | 47.7     | 66.5     | 4.4ms     | 227     || 47.8M  | 88.1B\n| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | **49.2** | **49.2** | **67.7** | 6.9ms     | 145     || 89.0M  | 166.4B\n| | | | | | || |\n| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/tag/v3.0) + TTA|**50.8**| **50.8** | **68.9** | 25.5ms    | 39      || 89.0M  | 354.3B\n| | | | | | || |\n| [YOLOv3-SPP](https://github.com/ultralytics/yolov5/releases/tag/v3.0) | 45.6     | 45.5     | 65.2     | 4.5ms     | 222     || 63.0M  | 118.0B"},{"metadata":{"papermill":{"duration":0.064016,"end_time":"2021-01-01T09:50:19.564859","exception":false,"start_time":"2021-01-01T09:50:19.500843","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Selecting Models\nIn this notebok I'm using `v5s`. To select your prefered model just replace `--cfg models/yolov5s.yaml --weights yolov5s.pt` with the following command:\n* `v5s` : `--cfg models/yolov5s.yaml --weights yolov5s.pt`\n* `v5m` : `--cfg models/yolov5m.yaml --weights yolov5m.pt`\n* `v5l` : `--cfg models/yolov5l.yaml --weights yolov5l.pt`\n* `v5x` : `--cfg models/yolov5x.yaml --weights yolov5x.pt`"},{"metadata":{"papermill":{"duration":0.064553,"end_time":"2021-01-01T09:50:19.6938","exception":false,"start_time":"2021-01-01T09:50:19.629247","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Train"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T09:50:19.916161Z","iopub.status.busy":"2021-01-01T09:50:19.915216Z","iopub.status.idle":"2021-01-01T15:22:16.288743Z","shell.execute_reply":"2021-01-01T15:22:16.289579Z"},"papermill":{"duration":19916.498298,"end_time":"2021-01-01T15:22:16.289734","exception":false,"start_time":"2021-01-01T09:50:19.791436","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache \n!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 8 --epochs 30 --data /kaggle/working/vinbigdata.yaml --weights yolov5m.pt --cache","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":4.919442,"end_time":"2021-01-01T15:22:26.398681","exception":false,"start_time":"2021-01-01T15:22:21.479239","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Class Distribution"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T15:22:36.714816Z","iopub.status.busy":"2021-01-01T15:22:36.713892Z","iopub.status.idle":"2021-01-01T15:22:37.752475Z","shell.execute_reply":"2021-01-01T15:22:37.752939Z"},"papermill":{"duration":6.511035,"end_time":"2021-01-01T15:22:37.753063","exception":false,"start_time":"2021-01-01T15:22:31.242028","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# xywh的分布\nplt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/labels_correlogram.jpg'));","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T15:22:47.848164Z","iopub.status.busy":"2021-01-01T15:22:47.847303Z","iopub.status.idle":"2021-01-01T15:22:48.613974Z","shell.execute_reply":"2021-01-01T15:22:48.614481Z"},"papermill":{"duration":5.977042,"end_time":"2021-01-01T15:22:48.614609","exception":false,"start_time":"2021-01-01T15:22:42.637567","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 类的分布，各类框的分布\nplt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/labels.jpg'));","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":5.378338,"end_time":"2021-01-01T15:22:59.482837","exception":false,"start_time":"2021-01-01T15:22:54.104499","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Batch Image"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T15:23:10.192425Z","iopub.status.busy":"2021-01-01T15:23:10.19175Z","iopub.status.idle":"2021-01-01T15:23:11.776947Z","shell.execute_reply":"2021-01-01T15:23:11.777415Z"},"papermill":{"duration":7.317416,"end_time":"2021-01-01T15:23:11.777544","exception":false,"start_time":"2021-01-01T15:23:04.460128","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 画出各个批次的标记图\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs/train/exp/train_batch0.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs/train/exp/train_batch1.jpg'))\n\nplt.figure(figsize = (15, 15)\nplt.imshow(plt.imread('runs/train/exp/train_batch2.jpg'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GT Vs Pred"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T15:23:22.104906Z","iopub.status.busy":"2021-01-01T15:23:22.10403Z","iopub.status.idle":"2021-01-01T15:23:23.51416Z","shell.execute_reply":"2021-01-01T15:23:23.514596Z"},"papermill":{"duration":6.453975,"end_time":"2021-01-01T15:23:23.514717","exception":false,"start_time":"2021-01-01T15:23:17.060742","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 看标记和预测的差别\nfig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'runs/train/exp/test_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'runs/train/exp/test_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'runs/train/exp/test_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'runs/train/exp/test_batch{row}_pred.jpg', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# (Loss, Map) Vs Epoch"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 看损失下降速度\nplt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/results.png'));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# 混淆矩阵\nplt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/confusion_matrix.png'));","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":4.941983,"end_time":"2021-01-01T15:23:33.765831","exception":false,"start_time":"2021-01-01T15:23:28.823848","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Inference"},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-01-01T15:23:44.50211Z","iopub.status.busy":"2021-01-01T15:23:44.501304Z","iopub.status.idle":"2021-01-01T15:23:49.800287Z","shell.execute_reply":"2021-01-01T15:23:49.799352Z"},"papermill":{"duration":10.763143,"end_time":"2021-01-01T15:23:49.800461","exception":false,"start_time":"2021-01-01T15:23:39.037318","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 用训练好的模型推理\n!python detect.py --weights 'runs/train/exp/weights/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source /kaggle/working/vinbigdata/images/val\\\n--exist-ok","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":5.225725,"end_time":"2021-01-01T15:24:00.706026","exception":false,"start_time":"2021-01-01T15:23:55.480301","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Inference Plot"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T15:24:10.963448Z","iopub.status.busy":"2021-01-01T15:24:10.962552Z","iopub.status.idle":"2021-01-01T15:24:11.210595Z","shell.execute_reply":"2021-01-01T15:24:11.211731Z"},"papermill":{"duration":5.31015,"end_time":"2021-01-01T15:24:11.211904","exception":false,"start_time":"2021-01-01T15:24:05.901754","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# 推断样本，并做标记图\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs/detect/exp/*')\nfor _ in range(3):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T15:24:21.60059Z","iopub.status.busy":"2021-01-01T15:24:21.599598Z","iopub.status.idle":"2021-01-01T15:24:22.413063Z","shell.execute_reply":"2021-01-01T15:24:22.411761Z"},"papermill":{"duration":5.709202,"end_time":"2021-01-01T15:24:22.413173","exception":false,"start_time":"2021-01-01T15:24:16.703971","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 删除一些文件夹，防止再次运行时报错\nshutil.rmtree('/kaggle/working/vinbigdata')\nshutil.rmtree('runs/detect')\nfor file in (glob('runs/train/exp/**/*.png', recursive = True)+glob('runs/train/exp/**/*.jpg', recursive = True)):\n    os.remove(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dim = 512 #1024, 256, 'original'\ntest_dir = f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/test'\nweights_dir = 'runs/train/exp/weights/best.pt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/test.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\n# shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', './yolov5')\n\nos.chdir('/kaggle/working/yolov5') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python detect.py --weights $weights_dir\\\n--img 640\\\n--conf 0.15\\\n--iou 0.4\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs/detect/exp/*png')\nfor _ in range(3):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_ids = []\nPredictionStrings = []\n\nfor file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df = sub_df[['image_id', 'PredictionString']]\nsub_df.to_csv('/kaggle/working/submission_wbf.csv',index = False)\nsub_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df = sub_df[['image_id', 'PredictionString']]\nsub_df.to_csv('/kaggle/working/submission_wbf.csv',index = False)\nsub_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}