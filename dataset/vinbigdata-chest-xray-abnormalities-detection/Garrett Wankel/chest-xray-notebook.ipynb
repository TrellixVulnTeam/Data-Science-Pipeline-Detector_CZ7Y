{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Basic CNN implementation\n\n## Dicoms\n### Reading and pulling information from .dicom files requires nuance, and is a computationally exhaustive. Thanks to a wonderful notebook by @raddar, (http://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way), I used this formatting along with a couple other functions to properly resize and compile the image data. \n\n##### update 1/15:\n#### functioning model, will link data preprocessing notebook once it's organized and cleaned"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import necessary libraries\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras import preprocessing, layers\nfrom keras.models import Model\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport os\nimport cv2\nfrom PIL import Image\nimport pickle\nfrom pathlib import Path\n\nimport imageio\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read in data / paths\n\ntest_img = ('../input/vinbigdata-chest-xray-abnormalities-detection/test/')\ntrain_img = ('../input/vinbigdata-chest-xray-abnormalities-detection/train/')\ntrain_data = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\nss = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = np.load('../input/unique-image-arrays/arrays.npz')\n\narrays = [files[key] for key in files]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nps=[]\n\nfor x in arrays:\n    new = np.resize(x,(256,256))\n    new = np.asarray(new)\n    new = keras.preprocessing.image.img_to_array(new)\n    nps.append(new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels = np.stack(labels)\nbbox_bound = np.stack(boxes)\ndata = np.stack(nps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_lab_train, y_lab_test, y_box_train, y_box_test =train_test_split(data, \n                                                                                     class_labels, \n                                                                                     bbox_bound.astype(int), \n                                                                                     test_size=0.2, \n                                                                                     shuffle=True, \n                                                                                     random_state=34)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = tf.keras.models.load_model('../input/cnn-model/model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(X_train, [y_lab_train, y_box_train], epochs=5, batch_size=50, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cls, b = model2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.evaluate(X_test, [y_lab_test, y_box_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels = []\n\nfor lab in cls:\n    lab = np.argmax(lab)\n    pred_labels.append(lab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for lab, box in zip(labels, b):\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Next Steps...\n\n##### for modeling notebook: \n### 1) implement KFold splitting to train & validate data \n### 2) create or manipulate sample_submission dataframe to efficiently read in output data\n### 3) create IoU def to find mAP (evaluation metric)\n##### current version_1.31"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}