{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport pandas as pd\nimport os\nimport torchvision.transforms as tr\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport pydicom\nimport glob\nimport collections\nfrom datetime import datetime\nfrom skimage import measure\nfrom skimage.measure import block_reduce\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage.transform import resize\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\nimport seaborn as sns\nfrom collections import defaultdict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_file = os.listdir('../input/vinbigdata-chest-xray-abnormalities-detection/train')\ninput_files = []\nfor ip in input_file:\n    input_files.append(ip.split('.')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_files[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['image_id']==input_files[3]].sort_values(by=['class_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class traindataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, file_list, transform):\n        super().__init__()\n        \n        self.file_list = file_list\n        self.df = df\n    \n    def __len__(self) :\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        \n        img_id = self.file_list[idx]\n        df = self.df\n        s = 1024\n        N = 15\n        d_f = df[df['image_id']==img_id]\n        dff = d_f.sort_values(by=['class_id'])\n        class_id = dff['class_id'].values.tolist()\n        img_pxl = pydicom.read_file('../input/vinbigdata-chest-xray-abnormalities-detection/train/'+img_id+'.dicom').pixel_array\n        img_res = resize(img_pxl,(s,s),anti_aliasing=True)\n        img_np = img_res.astype(np.float32())\n        img_tr = torch.from_numpy(img_np)\n        x_ = s/img_pxl.shape[1]\n        y_ = s/img_pxl.shape[0]\n        xmin = [x*x_ for x in dff['x_min'].values.tolist()]\n        ymin = [y*y_ for y in dff['y_min'].values.tolist()]\n        xmax = [x1*x_ for x1 in dff['x_max'].values.tolist()]\n        ymax = [y1*y_ for y1 in dff['y_max'].values.tolist()]\n        #bbox = []\n        #for z in range(len(xmin)):\n        #    bbox.append([xmin[z],ymin[z],xmax[z],ymax[z]])\n        mask = np.zeros((N,s,s))\n        for k,m in enumerate(class_id):\n            if m != 14:\n                x1,x2,y1,y2 = int(xmin[k]),int(xmax[k]),int(ymin[k]),int(ymax[k])\n                mask[m,y1:y2,x1:x2] = 1\n        mask_numpy = mask.astype(np.float32())\n        mask_tensor = torch.from_numpy(mask_numpy)\n        #mask_tensor = np.transpose(mask_tensor, (2,0,1))\n        return img_tr,mask_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = traindataset(file_list = input_files,df =df,transform = None)\ndata_loader = torch.utils.data.DataLoader(traindata, batch_size=1, shuffle=True, num_workers=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data_loader:\n    print(i)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from matplotlib.patches import Rectangle\nfor k,kk in enumerate(traindata):\n    plt.imshow(kk[0])\n    for org in kk[3]:\n        plt.gca().add_patch(Rectangle((org[0], org[1]), (org[2]-org[0]), (org[3]-org[1]),linewidth=1,edgecolor='b',facecolor='none'))\n    plt.show()\n    for j in kk[2]:\n        plt.imshow(j)\n        plt.show()\n    if k ==10:\n        break"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\nimport torch\nimport torch.nn as nn\n\nclass UNet(nn.Module):\n\n    def __init__(self, in_channels=1, out_channels=15, init_features=32):\n        super(UNet, self).__init__()\n\n        features = init_features\n        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n\n        self.upconv4 = nn.ConvTranspose2d(\n            features * 16, features * 8, kernel_size=2, stride=2\n        )\n        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n        self.upconv3 = nn.ConvTranspose2d(\n            features * 8, features * 4, kernel_size=2, stride=2\n        )\n        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n        self.upconv2 = nn.ConvTranspose2d(\n            features * 4, features * 2, kernel_size=2, stride=2\n        )\n        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n        self.upconv1 = nn.ConvTranspose2d(\n            features * 2, features, kernel_size=2, stride=2\n        )\n        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n\n        self.conv = nn.Conv2d(\n            in_channels=features, out_channels=out_channels, kernel_size=1\n        )\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool1(enc1))\n        enc3 = self.encoder3(self.pool2(enc2))\n        enc4 = self.encoder4(self.pool3(enc3))\n\n        bottleneck = self.bottleneck(self.pool4(enc4))\n\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.decoder4(dec4)\n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n        return torch.sigmoid(self.conv(dec1))\n\n    @staticmethod\n    def _block(in_channels, features, name):\n        return nn.Sequential(\n            OrderedDict(\n                [\n                    (\n                        name + \"conv1\",\n                        nn.Conv2d(\n                            in_channels=in_channels,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu1\", nn.ReLU(inplace=True)),\n                    (\n                        name + \"conv2\",\n                        nn.Conv2d(\n                            in_channels=features,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu2\", nn.ReLU(inplace=True)),\n                ]\n            )\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_unet = UNet(in_channels=1, out_channels=15, init_features=32)\nmodel_unet = model_unet.cuda()\ncalc = nn.MSELoss()\noptimizer = optim.Adamax(model_unet.parameters(), lr=0.0003)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_loss(pred, target, smooth = 1.):\n    pred = pred.contiguous()\n    target = target.contiguous()    \n\n    intersection = (pred * target).sum(dim=2).sum(dim=2)\n    \n    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n    \n    return loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_loss(pred, target, metrics, bce_weight=0.5):\n    bce = F.binary_cross_entropy_with_logits(pred, target)\n        \n    pred = F.sigmoid(pred)\n    dice = dice_loss(pred, target)\n    \n    loss = bce * bce_weight + dice * (1 - bce_weight)\n    \n    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n    \n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = defaultdict(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 1\nsteps = 0\nprint_every = 10\ntrain_losses, train_accuracy = [], []\n#model.load_state_dict(torch.load('./final_model.pth'))\nfor epoch in range(epochs):\n    model_unet.train()\n    size = 0\n    running_loss = 0\n    acc = 0\n    for a,(image_train, y_train) in enumerate(data_loader):\n        steps += 1\n        image_train, y_train = image_train.unsqueeze(0).cuda(), y_train.cuda()\n        image_train = Variable(image_train,requires_grad=True)\n        optimizer.zero_grad()\n        y_predtrain = model_unet.forward(image_train)\n        #y_train=y_train.type(torch.LongTensor)\n        #loss = calc_loss(y_predtrain, y_train,metrics)\n        loss = calc(y_predtrain, y_train)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        ps = torch.exp(y_predtrain)\n        top_p = torch.max(y_predtrain, 1)\n        top_class = torch.argmax(y_predtrain,dim = 1)\n        equals = top_class == y_train\n        print(torch.mean(equals.type(torch.FloatTensor)).item())\n        acc += torch.mean(equals.type(torch.FloatTensor)).item()\n        size += image_train.shape[0]\n        model_unet.eval()\n        print(f\"Epoch {epoch+1}/{epochs}.. \"\n              f\"Train loss: {running_loss/print_every:.3f}.. \"\n              f\"Train accuracy: {acc/len(data_loader):.3f}\")\n    #torch.save(model.state_dict(),'./'+str(epoch)+'model.pth')\n    #print('model saved')\n    torch.save(model_unet.state_dict(),'./'+str(epoch)+'unet_model.pth')\n    train_losses.append(float(running_loss)/float(size))\n    train_accuracy.append(float(acc)/float(size))\n    print('train_losses',epoch,train_losses)\n    print('train_accuracy',epoch,train_accuracy)\ntorch.save(model_unet.state_dict(),'./final_unet_model.pth')\nprint('model saved')\nprint('train_losses',epoch,train_losses)\nprint('train_accuracy',epoch,train_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_unet.load_state_dict(torch.load('../input/unet-op/60unet_model.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_pxl = pydicom.read_file('../input/vinbigdata-chest-xray-abnormalities-detection/train/000d68e42b71d3eac10ccc077aba07c1.dicom').pixel_array\nimg_res = resize(img_pxl,(1024,1024),anti_aliasing=True)\nimg_np = img_res.astype(np.float32())\nimg_tr = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).cuda()\noutput = model_unet(img_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = output.cpu().detach().squeeze()\nprint(predict.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in predict:\n    plt.imshow(i)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}