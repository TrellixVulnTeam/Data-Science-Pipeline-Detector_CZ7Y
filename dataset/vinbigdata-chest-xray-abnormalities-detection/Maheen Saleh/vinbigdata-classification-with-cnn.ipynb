{"cells":[{"metadata":{},"cell_type":"markdown","source":"**By using the output of this notebook, you are accepting the [competition rules](https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection/rules).**\n\n\n## References\n\n- Monochrome fix and scaling: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n- Resizing and saving image: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport torchvision.transforms as transforms\n\nimport torch\nfrom torch import nn\nimport glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### get train images"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id = []\ndim0 = []\ndim1 = []\nresized_train={}\n\n#add normalize also\nmy_transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n        \nload_train_dir = f'../input/vinbigdata-chest-xray-abnormalities-detection/train/*'\nsave_train_dir = \"./train/\"\n\ntrain_data = glob.glob(load_train_dir)\nprint(\"total labelled data count : {}\".format(len(train_data)))\nprint(\"sample path : {}\".format(train_data[0]))\n\n\nos.makedirs(save_train_dir, exist_ok=True)\n    \nfor file in train_data[0:20]:\n\n    # set keep_ratio=True to have original aspect ratio\n    xray = read_xray(file)\n    im = resize(xray, size=512) \n\n    img_id = file.split(\"/train/\")[1].split(\".\")\n    img_id = img_id[0]\n    print(img_id)\n    im.save(save_train_dir+img_id+'.png')\n    print(save_train_dir+img_id+'.png')\n\n\n    resized_train[img_id] = my_transform(im)\n\n    image_id.append(image_id)\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### get test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_id = []\ntest_dim0 = []\ntest_dim1 = []\nresized_test={}\n\n\n#add normalize also\nmy_test_transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n \n    \nload_test_dir = f'../input/vinbigdata-chest-xray-abnormalities-detection/train/*'\nsave_test_dir = f'./test/'\n\n# get test data path\ntest_data = glob.glob(load_test_dir)\n\n\nos.makedirs(save_test_dir, exist_ok=True)\n    \n# get last 1000 or 10 ( just for testing )\n\nfor file in test_data[-10:]:\n    \n#     print(\"file {}\".format(file))\n\n    # set keep_ratio=True to have original aspect ratio\n    xray = read_xray(file)\n    im = resize(xray, size=512) \n\n    test_img_id = file.split(\"/train/\")[1].split(\".\")\n    test_img_id = test_img_id[0]\n#     print(test_img_id)\n\n    im.save(save_test_dir + test_img_id + \".png\")\n    \n    resized_test[test_img_id] = my_transform(im)\n\n    test_image_id.append(test_img_id)\n    test_dim0.append(xray.shape[0])\n    test_dim1.append(xray.shape[1])\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test train count"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train images count : {}\".format(len(resized_train)))\n\nprint(\"test images count : {}\".format(len(resized_test)))\n    \nprint(resized_train.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### save train n test data in zip ( can be downloaded from output directory -> )"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n#save train resized images in zip\n!tar -zcf train.tar.gz -C \"./train/\" .\n\n\n#save test resized images in zip\n!tar -zcf train.tar.gz -C \"./test/\" .\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1})\n# df.to_csv('train_meta.csv', index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image datatype\n# resized_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = list(resized_train.keys())\nk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display\nk = list(resized_train.keys())\ndisplay(resized_train[k[1]])\nk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show imahge\n\nimport matplotlib.pyplot as plt\n\nimg = resized_train[list(resized_train.keys())[1]]\nplt.imshow(img.squeeze(), cmap=plt.cm.gray)\nplt.show()\n\n\nprint(img.shape)\nimg_unsq = img.unsqueeze(0)\nprint(img_unsq.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### get train labels ( just classes for now)\n\n### Will use fast rcnn for detection i,e bounding box"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.read_csv(\"/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\nprint(\"Train Data Size : {}\".format(labels.shape[0]))\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels = labels.iloc[:,[0,2]]\nclass_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels.iloc[:,0:2]\nclass_labels = class_labels.drop_duplicates(subset=[\"image_id\"])\nclass_labels.head()\nclass_labels.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### model : training, testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_on_gpu = False\n\nif torch.cuda.is_available():\n    train_on_gpu = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# define the CNN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # convolutional layer (sees 512x512x3 image tensor)\n        self.conv1 = nn.Conv2d(1, 4, 3, padding=1)\n\n        # convolutional layer (sees 256x256x4 tensor)\n        self.conv2 = nn.Conv2d(4, 8, 3, padding=1)\n        \n        # convolutional layer (sees 128x128x8 tensor)\n        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n        \n        # convolutional layer (sees 64x64x16 tensor)\n        self.conv4 = nn.Conv2d(16, 32, 3, padding=1)\n        \n        # convolutional layer (sees 32x32x32  tensor)\n        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n    \n        # max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # linear layer (64 * 4 * 4 -> 500)\n    \n        self.fc1 = nn.Linear(64 * 16 * 16, 1600)\n        # linear layer (500 -> 10)\n        self.fc2 = nn.Linear(1600, 512)\n        # dropout layer (p=0.25)\n        self.fc3 = nn.Linear(512,15)\n\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        # add sequence of convolutional and max pooling layers\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = self.pool(F.relu(self.conv5(x)))\n        # flatten image input\n\n        x = x.view(-1, 64 * 16 * 16)\n        # add dropout layer\n        \n        x = self.dropout(x)\n        # add 1st hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        # add dropout layer\n        \n        x = self.dropout(x)\n        # add 2nd hidden layer, with relu activation function\n        x = F.relu(self.fc2(x))\n\n        # add dropout layer\n        x = self.dropout(x)\n        # add 2nd hidden layer, with relu activation function\n        x = self.fc3(x)\n        \n        return x\n\n# create a complete CNN\nmodel = Net()\nprint(model)\n\n# move tensors to GPU if CUDA is available\nif torch.cuda.is_available():\n    model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# number of epochs to train the model\nn_epochs = 2\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n    print(\"********* FOR EPOCH : {} ****************\".format(epoch))\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data_id,data in resized_train.items():\n        # move tensors to GPU if CUDA is available\n        target = torch.tensor(int(class_labels.loc[class_labels[\"image_id\"]==data_id][\"class_id\"]))\n        target = target.unsqueeze(0)\n        data = data.unsqueeze(0)\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n#         output = torch.argmax(output)\n#         print(\"output : \",output.shape)\n#         print(\"target : \",target.shape)\n#         print(\"target item : \", target.item())\n        \n        loss = criterion(output, target)\n        print(\"H\",loss)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n#     model.eval()\n#     for data, target in valid_loader:\n#         # move tensors to GPU if CUDA is available\n#         if train_on_gpu:\n#             data, target = data.cuda(), target.cuda()\n#         # forward pass: compute predicted outputs by passing inputs to the model\n#         output = model(data)\n#         # calculate the batch loss\n#         loss = criterion(output, target)\n#         # update average validation loss \n#         valid_loss += loss.item()*data.size(0)\n    \n#     # calculate average losses\n#     train_loss = train_loss/len(train_loader.sampler)\n#     valid_loss = valid_loss/len(valid_loader.sampler)\n        \n#     # print training/validation statistics \n#     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n#         epoch, train_loss, valid_loss))\n    \n#     # save model if validation loss has decreased\n#     if valid_loss <= valid_loss_min:\n#         print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n#         valid_loss_min,\n#         valid_loss))\n#         torch.save(model.state_dict(), 'model_cifar.pt')\n#         valid_loss_min = valid_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# track test loss\nbatch_size = 1\ntest_loss = 0.0\nclass_correct = list(0. for i in range(15))\nclass_total = list(0. for i in range(15))\n\nmodel.eval()\n# iterate over test data\nfor data_id,data in resized_test.items():\n\n    target = torch.tensor(int(class_labels.loc[class_labels[\"image_id\"]==data_id][\"class_id\"]))\n    target = target.unsqueeze(0)\n    data = data.unsqueeze(0)\n    \n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    \n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    \n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1) ## returns max value as frst, and index of max value as second   \n    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    \n    print(\"\\n\",correct_tensor)\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    \n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        print(\"predicted label {}\".format(pred.item()))\n        print(\"actual label {}\".format(target.item()))\n        \n#         print(correct)\n#         print(correct[i].item())\n        class_correct[label] += correct\n        class_total[label] += 1\n\n# average test loss\n# test_loss = test_loss/len(test_loader.dataset)\ntest_loss = test_loss/10\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nclasses = range(0,15)\nfor i in range(15):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}