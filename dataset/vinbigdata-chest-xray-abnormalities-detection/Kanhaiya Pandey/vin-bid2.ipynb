{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pydicom as dicom\nimport pydicom\nfrom skimage.transform import resize\ntrain='/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train'\narr=[]\nfor img in os.listdir(train):\n    ds = pydicom.read_file(os.path.join(train,img))\n    \n    data=ds.pixel_array\n    arr.append(data)\n    resized_img = resize(data, (180, 180), anti_aliasing=True)\n    #print(resized_img.shape)\n    #print(label)\n    plt.imshow(data)\n    plt.show()\n    #print(len(arr))\n    break\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\ndf=pd.read_csv('/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\ndf.fillna(0,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['class_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import data, exposure, img_as_float\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib\nfrom PIL import Image\nimport cv2\ndata=arr[0]\nimg_size=512\n\nbbox = [df[df['image_id'] == '9a5094b2563a1ef3ff50dc5c7ff71345'].iloc[0,4],\n        df[df['image_id'] == '9a5094b2563a1ef3ff50dc5c7ff71345'].iloc[0,5],\n        df[df['image_id'] == '9a5094b2563a1ef3ff50dc5c7ff71345'].iloc[0,6],\n        df[df['image_id'] == '9a5094b2563a1ef3ff50dc5c7ff71345'].iloc[0,7]]\n\nimage_array = cv2.resize(data , (img_size,img_size), interpolation = cv2.INTER_AREA)\nimage_array=exposure.equalize_adapthist(image_array/np.max(image_array))\nfig, ax = plt.subplots(1, 1, figsize=(20, 4))\n\n\nax.imshow(image_array, cmap='gray')\n\n\nc_height, c_width = data.shape[:2]\nr_width = img_size / c_width\nr_height = img_size / c_height\n\n\nx = int(bbox[0] * r_width)\ny = int(bbox[1] * r_height)\nw = int((bbox[2]-bbox[0])* r_width)\nh = int((bbox[3]-bbox[1]) * r_height)\n\np = matplotlib.patches.Rectangle((x, y),\n                                 w,\n                                 h,\n                                 ec='g', fc='none', lw=2.)\n\ndata = exposure.equalize_hist(data/np.max(data))\nax.add_patch(p)\n#plt.imshow(data,'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x,y,w,h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = exposure.equalize_adapthist(data/np.max(data))\nplt.figure(figsize = (7,7))\nplt.imshow(img,'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pydicom import dcmread\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n        \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport tqdm\nimport pydicom\nimport cv2\nimport albumentations\nfrom skimage.transform import resize\nimport warnings\nimport os\nimport numpy as np\nwarnings.simplefilter(\"ignore\", UserWarning)\n# from pydicom.config import image_handlers\n# print(image_handlers)\n# image_handlers[2].have_pillow_jpeg2000_plugin = Fals\n\nimg_size=512\ndata_dir='../input/vinbigdata-chest-xray-abnormalities-detection/'\n\ndata_df=df\nclass_names = sorted(data_df['class_name'].unique())\nprint(f\"No. of classes read - {len(class_names)}\")\ntime.sleep(1)\n\nimages_list = sorted(os.listdir(os.path.join(data_dir, 'train')))\nX = []\nY = []\nb_box=[]\n\n\nfor image in tqdm.tqdm(images_list[:5000]):\n    cls_index = data_df[data_df['image_id'] == image[:-6]].iloc[0,2]\n    if cls_index !=14:\n        x_min=df[df['image_id'] == image[:-6]].iloc[0,4]\n        y_min=df[df['image_id'] == image[:-6]].iloc[0,5]\n        x_max=df[df['image_id'] == image[:-6]].iloc[0,6]\n        y_max=df[df['image_id'] == image[:-6]].iloc[0,7]\n        image_path = os.path.join(data_dir, 'train',image)\n        data=read_xray(image_path)\n        image_array = cv2.resize(data , (img_size,img_size), interpolation = cv2.INTER_AREA)\n#         image_array=exposure.equalize_adapthist(image_array/np.max(image_array))\n        bboxes=[x_min,y_min,x_max,y_max]\n        c_height, c_width = data.shape[:2]\n        r_width = img_size / c_width\n        r_height = img_size / c_height\n        x = int(bboxes[0] * r_width)\n        y = int(bboxes[1] * r_height)\n        w = int((bboxes[2]-bboxes[0]) * r_width)\n        h = int((bboxes[3]-bboxes[1]) * r_height)\n        new_box =[x, y, w, h]\n        b_box.append(new_box)\n        X.append(image_array)\n        Y.append(cls_index)\n    else:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image in tqdm.tqdm(images_list[5000:10000]):\n    cls_index = data_df[data_df['image_id'] == image[:-6]].iloc[0,2]\n    if cls_index !=14:\n        x_min=df[df['image_id'] == image[:-6]].iloc[0,4]\n        y_min=df[df['image_id'] == image[:-6]].iloc[0,5]\n        x_max=df[df['image_id'] == image[:-6]].iloc[0,6]\n        y_max=df[df['image_id'] == image[:-6]].iloc[0,7]\n        image_path = os.path.join(data_dir, 'train',image)\n        data=read_xray(image_path)\n        image_array = cv2.resize(data , (img_size,img_size), interpolation = cv2.INTER_AREA)\n#         image_array=exposure.equalize_adapthist(image_array/np.max(image_array))\n        bboxes=[x_min,y_min,x_max,y_max]\n        c_height, c_width = data.shape[:2]\n        r_width = img_size / c_width\n        r_height = img_size / c_height\n        x = int(bboxes[0] * r_width)\n        y = int(bboxes[1] * r_height)\n        w = int((bboxes[2]-bboxes[0]) * r_width)\n        h = int((bboxes[3]-bboxes[1]) * r_height)\n        new_box =[x, y, w, h]\n        b_box.append(new_box)\n        X.append(image_array)\n        Y.append(cls_index)\n    else:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image in tqdm.tqdm(images_list[10000:15000]):\n    cls_index = data_df[data_df['image_id'] == image[:-6]].iloc[0,2]\n    if cls_index !=14:\n        x_min=df[df['image_id'] == image[:-6]].iloc[0,4]\n        y_min=df[df['image_id'] == image[:-6]].iloc[0,5]\n        x_max=df[df['image_id'] == image[:-6]].iloc[0,6]\n        y_max=df[df['image_id'] == image[:-6]].iloc[0,7]\n        image_path = os.path.join(data_dir, 'train',image)\n        data=read_xray(image_path)\n        image_array = cv2.resize(data , (img_size,img_size), interpolation = cv2.INTER_AREA)\n#         image_array=exposure.equalize_adapthist(image_array/np.max(image_array))\n        bboxes=[x_min,y_min,x_max,y_max]\n        c_height, c_width = data.shape[:2]\n        r_width = img_size / c_width\n        r_height = img_size / c_height\n        x = int(bboxes[0] * r_width)\n        y = int(bboxes[1] * r_height)\n        w = int((bboxes[2]-bboxes[0]) * r_width)\n        h = int((bboxes[3]-bboxes[1]) * r_height)\n        new_box =[x, y, w, h]\n        b_box.append(new_box)\n        X.append(image_array)\n        Y.append(cls_index)\n    else:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n\n\nax.imshow(image_array, cmap='gray')\n\np = matplotlib.patches.Rectangle((x, y),\n                                 w,\n                                 h,\n                                 ec='g', fc='none', lw=2.)\n\n\nax.add_patch(p)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\nimport albumentations\ntransform=transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Grayscale(3),\n        transforms.ToTensor(),\n        ]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imgaug import augmenters as iaa\nimage_augmentations = iaa.Sequential( \n\n    [                                \n\n    iaa.Affine(scale=(0.5, 1.5)),\n\n    iaa.Affine(rotate=(-60, 60)),\n\n    iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n\n    iaa.Fliplr(1),\n\n    iaa.Multiply((0.5, 1.5)),\n\n    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n\n    # Add Gaussian Noise\n\n    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xarr = np.array(X,dtype=int)\nYarr = np.array(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(Y,  return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X), len(Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel(X)\nprint(Xarr.shape, Yarr.shape)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.utils import to_categorical\n# Yarr_hot = to_categorical(Y)\n# print(Xarr.shape, Yarr_hot.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import Flatten,MaxPooling2D,Activation, Conv2D,BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\nfrom tensorflow.keras.utils import to_categorical\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xarr=Xarr/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xarr = np.array(Xarr).reshape(-1, img_size, img_size,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xarr.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.applications.ResNet50( input_shape=(512,512,1), \n    include_top=False, \n    weights=None\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model=Sequential()\n# model.add(Conv2D(256, (3, 3),  input_shape= Xarr.shape[1:]))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(256, (3, 3)))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n\n# model.add(Flatten()) \n# model.add(Dense(240))\n\n# model.add(Dense(Yarr.shape[-1]))\n# model.add(Activation('softmax'))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_output=model.output\n\nflattened_output = Flatten()(base_model_output)\n\nclass_prediction = Dense(256, activation=\"relu\")(flattened_output)\nclass_prediction = Dense(256, activation=\"relu\")(class_prediction )\nclass_prediction = Dropout(0.2)(class_prediction)\nclass_prediction = Dense(256, activation=\"relu\")(class_prediction)\nclass_prediction = Dropout(0.2)(class_prediction )\nclass_prediction = Dense(128, activation=\"relu\")(class_prediction)\nclass_prediction = Dense(15, activation='softmax',\n                             name=\"class_output\")(class_prediction)\n\nbox_output = Dense(256, activation=\"relu\")(flattened_output)\nbox_output = Dense(256, activation=\"relu\")(box_output)\nbox_output = Dropout(0.2)(box_output )\nbox_output = Dense(256, activation=\"relu\")(box_output)\nbox_output = Dropout(0.2)(box_output )\nbox_output = Dense(32, activation=\"relu\")(box_output)\nbox_predictions = Dense(4, activation='sigmoid',name= \"box_output\")(box_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b_box=np.array(b_box).reshape( len(Y),-1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_images, val_images, train_labels, \\\nval_labels, train_boxes, val_boxes = train_test_split( Xarr, \n                Yarr, b_box, test_size = 0.1, \n                random_state = None)\n\nprint('Total Training Images: {}, Total Test Images: {}'.format(\n    len(train_images), \n    len(val_images)\n    ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op = Model(inputs=model.input, outputs= [box_predictions,class_prediction])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import EarlyStopping\nlosses = { \n    \"box_output\": \"MeanSquaredError\",\n    \"class_output\": \"sparse_categorical_crossentropy\"\n    }\n\nloss_weights = {\n    \"box_output\": 2.0, \n    \"class_output\": 2.0\n    }\n\nmetrics = {\n    'class_output': 'accuracy', \n    'box_output':  'mse'\n    }\n\nstop = EarlyStopping(monitor = \"val_loss\", min_delta = 0.001, patience = 3, \n                    restore_best_weights = True\n                     )\n\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.0002, \n                              patience = 30, min_lr = 1e-7, verbose = 1)\n\n\nopt = tf.keras.optimizers.Adam()\n\n\nop.compile(optimizer = opt, loss = losses, loss_weights = loss_weights, \n    metrics = metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import densenet\nchex=densenet.DenseNet121(include_top=False,weights=None,input_shape=Xarr.shape[1:],pooling='avg')\n# output=chex.output\nbase_model1_output=chex.output\n\nflattened_output = Flatten()(base_model1_output)\n\nclass_prediction = Dense(256, activation=\"relu\")(flattened_output)\nclass_prediction = Dense(256, activation=\"relu\")(class_prediction )\nclass_prediction = Dropout(0.2)(class_prediction)\nclass_prediction = Dense(256, activation=\"relu\")(class_prediction)\nclass_prediction = Dropout(0.2)(class_prediction )\nclass_prediction = Dense(128, activation=\"relu\")(class_prediction)\nclass_prediction = Dense(14, activation='softmax',\n                             name=\"class_output\")(class_prediction)\n\nbox_output = Dense(256, activation=\"relu\")(flattened_output)\nbox_output = Dense(256, activation=\"relu\")(box_output)\nbox_output = Dropout(0.2)(box_output )\nbox_output = Dense(256, activation=\"relu\")(box_output)\nbox_output = Dropout(0.2)(box_output )\nbox_output = Dense(32, activation=\"relu\")(box_output)\nbox_predictions = Dense(4, activation='sigmoid',name= \"box_output\")(box_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op1 = Model(inputs=chex.input, outputs= [box_predictions,class_prediction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import EarlyStopping\nlosses = { \n    \"box_output\": \"MeanSquaredError\",\n    \"class_output\": \"sparse_categorical_crossentropy\"\n    }\n\nloss_weights = {\n    \"box_output\": 1.0, \n    \"class_output\": 1.0\n    }\n\nmetrics = {\n    'class_output': 'accuracy', \n    'box_output':  'mse'\n    }\n\nstop = EarlyStopping(monitor = \"val_loss\", min_delta = 0.01, patience = 3, \n                    restore_best_weights = True\n                     )\n\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.0002, \n                              patience = 30, min_lr = 1e-7, verbose = 1)\n\n\nopt = tf.keras.optimizers.Adam()\n\n\nop1.compile(optimizer = opt, loss = losses, loss_weights = loss_weights, \n    metrics = metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_image22=ImageDataGenerator(image_augmentations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = op1.fit(x=train_images,\n                  y= ({\n                        \"box_output\": train_boxes, \n                        \"class_output\": train_labels\n                        }),\n                      \n                   \n                    validation_data=(\n                        val_images, \n                        {\n                          \"box_output\": val_boxes, \n                          \"class_output\": val_labels\n                          }), batch_size = 8, epochs = 10, \n                    callbacks=reduce_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history1.history.keys())\n#  \"Accuracy\"\nplt.plot(history1.history['class_output_accuracy'])\nplt.plot(history1.history['val_class_output_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# \"Loss\"\nplt.plot(history1.history['class_output_loss'])\nplt.plot(history1.history['val_class_output_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir='../input/vinbigdata-chest-xray-abnormalities-detection/'\n\n\nclass_names = sorted(data_df['class_name'].unique())\nprint(f\"No. of classes read - {len(class_names)}\")\ntime.sleep(1)\n\nimages_list = sorted(os.listdir(os.path.join(data_dir, 'test')))\ntest1 = []\ncs=[]\n\n\nfor image in tqdm.tqdm(images_list):\n    image_path = os.path.join(data_dir, 'test',image)\n    data=read_xray(image_path)\n#     real = exposure.equalize_adapthist(data/np.max(data))\n    image_array = cv2.resize(data , (img_size,img_size), interpolation = cv2.INTER_AREA)\n    test = np.array(image_array).reshape(-1, img_size, img_size,1)\n    test=test/255.0\n#     test1.append(test)\n    result=op1.predict(test)\n    result1=image[:-6],str(np.argmax(result[1]))+' '+str(np.max(result[1]))+' '+str(result[0][0][0])+' '+str(result[0][0][1])+' '+str(result[0][0][2])+' '+str(result[0][0][3])\n    cs.append(result1)\n#     print(result)\n#     test.append(image_array)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cs=[]\n# for i in test1:\n    \n#     result=op1.predict(i)\n#     result1=image[:-6],str(np.argmax(result[1]))+' '+str(np.max(result[1]))+' '+str(result[0][0][0])+' '+str(result[0][0][1])+' '+str(result[0][0][2])+' '+str(result[0][0][3])\n#     cs.append(result1)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cs=np.array(cs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import DataFrame\ncs = DataFrame (cs,columns=['image_id','PredictionString'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs.to_csv('./test1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xxx=pd.read_csv(\"./test1.csv\")\nxxx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv')\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}