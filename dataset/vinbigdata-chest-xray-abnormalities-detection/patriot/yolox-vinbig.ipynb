{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cp -r /kaggle/input/yolox-cots-models /kaggle/working/\n%cd /kaggle/working/yolox-cots-models/yolox-dep","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T19:35:14.158785Z","iopub.execute_input":"2021-12-11T19:35:14.159404Z","iopub.status.idle":"2021-12-11T19:35:32.613624Z","shell.execute_reply.started":"2021-12-11T19:35:14.159304Z","shell.execute_reply":"2021-12-11T19:35:32.612695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pip-21.3.1-py3-none-any.whl -f ./ --no-index\n!pip install loguru-0.5.3-py3-none-any.whl -f ./ --no-index\n!pip install ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl -f ./ --no-index\n!pip install onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl -f ./ --no-index\n!pip install onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl -f ./ --no-index\n!pip install onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl -f ./ --no-index\n!pip install thop-0.0.31.post2005241907-py3-none-any.whl -f ./ --no-index\n!pip install tabulate-0.8.9-py3-none-any.whl -f ./ --no-index","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:35:32.615821Z","iopub.execute_input":"2021-12-11T19:35:32.616452Z","iopub.status.idle":"2021-12-11T19:36:38.292727Z","shell.execute_reply.started":"2021-12-11T19:35:32.616411Z","shell.execute_reply":"2021-12-11T19:36:38.291933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install YOLOX\n%cd /kaggle/working/yolox-cots-models/YOLOX\n!pip install -r requirements.txt\n!pip install -v -e . ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:36:38.294223Z","iopub.execute_input":"2021-12-11T19:36:38.29448Z","iopub.status.idle":"2021-12-11T19:37:18.343627Z","shell.execute_reply.started":"2021-12-11T19:36:38.294443Z","shell.execute_reply":"2021-12-11T19:37:18.342812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yolox","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:37:18.347045Z","iopub.execute_input":"2021-12-11T19:37:18.347273Z","iopub.status.idle":"2021-12-11T19:37:19.347067Z","shell.execute_reply.started":"2021-12-11T19:37:18.347243Z","shell.execute_reply":"2021-12-11T19:37:19.346307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/yolox-cots-models/yolox-dep/cocoapi/PythonAPI\n\n!make\n!make install\n!python setup.py install\nimport pycocotools","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:37:19.348229Z","iopub.execute_input":"2021-12-11T19:37:19.349101Z","iopub.status.idle":"2021-12-11T19:37:42.254765Z","shell.execute_reply.started":"2021-12-11T19:37:19.349069Z","shell.execute_reply":"2021-12-11T19:37:42.253958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from yolox.exp import get_exp\nfrom yolox.utils import fuse_model, get_model_info, postprocess, vis","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:37:42.256184Z","iopub.execute_input":"2021-12-11T19:37:42.256751Z","iopub.status.idle":"2021-12-11T19:37:42.275654Z","shell.execute_reply.started":"2021-12-11T19:37:42.256706Z","shell.execute_reply":"2021-12-11T19:37:42.274938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os,importlib\nimport time,glob,sys\nimport numpy as np\nfrom loguru import logger\nfrom tqdm import tqdm\nimport cv2\n\nimport torch\n\nfrom yolox.data.data_augment import preproc\n\ndef make_parser():\n    parser = argparse.ArgumentParser(\"YOLOX Demo!\")\n    # parser.add_argument('demo', default='image', help='demo type, eg. image, video and webcam')\n    parser.add_argument(\"-expn\", \"--experiment-name\", type=str, default=None)\n    parser.add_argument(\"-n\", \"--name\", type=str, default=None, help=\"model name\")\n\n    parser.add_argument('--path', default='/kaggle/input/vinbigdata-512-image-dataset/vinbigdata/test/*png', help='path to images or video')\n    parser.add_argument('--wei_dir', default='YOLOX_outputs/yolox_weights/', help='weight location')\n    parser.add_argument(\n        '--save_result', action='store_true',\n        help='whether to save the inference result of image/video'\n    )\n\n    # exp file\n    parser.add_argument(\n        \"-f\",\n\n        \"--exp_file\",\n        default=\"../input/yoloxvinbigdebug/yolox_s.py\",\n        type=str,\n        help=\"\",\n    )\n    parser.add_argument(\"-out\", \"--outdir\", default=None, type=str, help=\"txtをおく\")\n    parser.add_argument(\"-c\", \"--ckpt\", default=None, type=str, help=\"ckpt for eval\")\n    parser.add_argument(\"--device\", default=\"cpu\", type=str, help=\"device to run our model, can either be cpu or gpu\")\n    parser.add_argument(\"--conf\", default=0.001, type=float, help=\"test conf\")\n    parser.add_argument(\"--nms\", default=0.4, type=float, help=\"test nms threshold\")\n    parser.add_argument(\"--tsize\", default=640, type=int, help=\"test img size\")\n    parser.add_argument(\n        \"--fp16\",\n        dest=\"fp16\",\n        default=False,\n        action=\"store_true\",\n        help=\"Adopting mix precision evaluating.\",\n    )\n    parser.add_argument(\n        \"--fuse\",\n        dest=\"fuse\",\n        default=False,\n        action=\"store_true\",\n        help=\"Fuse conv and bn for testing.\",\n    )\n    parser.add_argument(\n        \"--trt\",\n        dest=\"trt\",\n        default=False,\n        action=\"store_true\",\n        help=\"Using TensorRT model for testing.\",\n    )\n    return parser\n\n\nfrom torch.utils.data import  DataLoader, Dataset\nclass TestDataset(Dataset):\n    def __init__(self, image_paths, imgsz=384):\n        self.image_paths = image_paths\n        self.test_size = (imgsz, imgsz)\n        #self.rgb_means = (0.485, 0.456, 0.406) #legacy version\n        #self.std = (0.229, 0.224, 0.225) #legacy version\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        img, ratio = preproc(image, self.test_size)\n\n        return img, image_path, ratio\n\n\ndef main(exp, args):\n\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    if args.conf is not None:\n        exp.test_conf = args.conf\n    if args.nms is not None:\n        exp.nmsthre = args.nms\n    if args.tsize is not None:\n        exp.test_size = (args.tsize, args.tsize)\n\n\n    models = []\n    out_files = []\n\n    exp_files = [\"/kaggle/input/yoloxvinbigdebug/\"]\n\n    for exp_file in exp_files:\n        exp = get_exp(exp_file+\"yolox_s.py\", args.name)\n\n        model = exp.get_model()\n        model.to(device)\n        model.eval()\n        ckpt_file = f\"{exp_file}/best_ckpt.pth\"\n        ckpt = torch.load(ckpt_file, map_location=device)\n        model.load_state_dict(ckpt[\"model\"])\n\n        if args.fuse:\n            logger.info(\"\\tFusing model...\")\n            model = fuse_model(model)\n\n        out_path = f'/kaggle/working/inf.txt'\n\n        with open(out_path, 'w') as f:\n            pass\n        out_files.append(out_path)\n        models.append(model)\n\n    test_dataset = TestDataset(image_paths = glob.glob(args.path), imgsz = args.tsize)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,  num_workers=2, pin_memory=True)\n\n\n    bar = tqdm(test_loader)\n    with torch.no_grad():\n        for batch_idx, batch_data in enumerate(bar):\n            images, paths, ratios = batch_data \n            images = images.to(device)\n\n            for is_hflip in [0]:\n                if is_hflip:\n                    images = images.flip(-1)\n\n                for model, out_path in zip(models, out_files):\n                    outputs = model(images)\n                    \n                    outputs = postprocess(outputs, 14, args.conf, args.nms)\n                    #print(outputs)\n\n                    for img_path, output, ratio in zip(paths, outputs, ratios):\n                        img_id = img_path.split('/')[-1].split(\".\")[0]\n\n                        if output==None:continue\n\n                        output = output.to(\"cpu\").detach()\n                        bboxes = output[:, 0:4]\n                        bboxes /= ratio\n                        cls = output[:, 6]\n                        scores = output[:, 4] * output[:, 5]\n                            \n                        with open(out_path, 'a') as f:\n                            #print(img_id)\n                            for box,clas, score in zip(bboxes.numpy(),cls.numpy(),scores.numpy()):\n                                x1, y1, x2, y2 = box \n                                #print(box)\n                                if is_hflip:\n                                    f.write(f'{img_id} {int(clas)} {512-x2} {y1} {512-x1} {y2} {score}\\n')\n                                else:\n                                    f.write(f'{img_id} {int(clas)} {x1} {y1} {x2} {y2} {score}\\n')\n\n#python /home/u094724e/vinbig/src/YOLOX/yolox_inf.py -f /home/u094724e/vinbig/YOLOX_outputs/exp001/yolox_s.py\nif __name__ == \"__main__\":\n    args = make_parser().parse_args()\n    exp = get_exp(\"/kaggle/input/yoloxvinbigdebug/yolox_s.py\", args.name)\n\n    main(exp, args)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:37:42.277185Z","iopub.execute_input":"2021-12-11T19:37:42.277671Z","iopub.status.idle":"2021-12-11T19:38:40.782799Z","shell.execute_reply.started":"2021-12-11T19:37:42.277585Z","shell.execute_reply":"2021-12-11T19:38:40.781503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntest_df = pd.read_csv(\"/kaggle/input/vinbigdata-512-image-dataset/vinbigdata/test.csv\")\ndef post_process_bbox(cls_conf_bbox,width,height):\n    \"\"\"\n    x1, y1, x2, y2(512*512)\n\n\n    \n    \"\"\"\n    box = cls_conf_bbox[2:]\n    cls_conf = cls_conf_bbox[:2]\n\n    box = [box[0]*width/512,box[1]*height/512,box[2]*width/512,box[3]*height/512]\n    cls_conf_bbox = list(np.concatenate([cls_conf,box]))\n\n\n    for idx in range(len(cls_conf_bbox)):\n        cls_conf_bbox[idx] = str(int(float(cls_conf_bbox[idx]))) if idx%6!=1 else str(cls_conf_bbox[idx])\n\n    return cls_conf_bbox\n\n\nimage_ids = []\nPredictionStrings = []\nnow_id = None\nstring = \"\"\n\nwith open(\"/kaggle/working/inf.txt\") as f:\n    for s_line in f:\n        s_line = s_line.strip().split(\" \")\n        img_id = s_line[0]\n        cls_bbox_conf = np.array(s_line[1:]).astype(np.float64)\n        cls_conf_bbox = cls_bbox_conf[[0, 5, 1, 2, 3, 4]]\n\n        if now_id!=img_id:\n            now_id = img_id\n            image_ids.append(now_id)\n\n            tmp = test_df[test_df.image_id==img_id]\n            width = tmp[\"width\"].values[0]\n            height = tmp[\"height\"].values[0]\n            \n            if now_id!=None:\n                #print(string)\n                PredictionStrings.append(string)\n\n                string = \"\"\n        cls_conf_bbox = post_process_bbox(cls_conf_bbox,width,height)\n\n        #print(cls_bbox_conf)\n        #print(cls_conf_bbox)\n\n        if string!=\"\":\n            string += \" \"\n\n        string += ' '.join(cls_conf_bbox)\n        #print(string)\n        #if len(image_ids)==3:\n        #    break\n\nPredictionStrings.append(string)\nPredictionStrings =  PredictionStrings[1:]\n\npred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\n\nsub_df[['image_id', 'PredictionString']].to_csv(f'submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:38:40.785309Z","iopub.execute_input":"2021-12-11T19:38:40.785725Z","iopub.status.idle":"2021-12-11T19:38:49.651851Z","shell.execute_reply.started":"2021-12-11T19:38:40.785682Z","shell.execute_reply":"2021-12-11T19:38:49.651128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:38:49.653265Z","iopub.execute_input":"2021-12-11T19:38:49.653562Z","iopub.status.idle":"2021-12-11T19:38:49.670801Z","shell.execute_reply.started":"2021-12-11T19:38:49.653524Z","shell.execute_reply":"2021-12-11T19:38:49.670047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}