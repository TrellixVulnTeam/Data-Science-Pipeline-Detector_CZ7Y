{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Version\n\n* `v12`: Fold4\n* `v11`: Fold3\n* `v10`: Fold2\n* `v08`: Fold1\n* `v07`: Fold0\n"},{"metadata":{},"cell_type":"markdown","source":"# [Training Notebook](https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class)\n* Select `GPU` as the **Accelerator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dim = 512 #1024, 256, 'original'\ntest_dir = f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/test'\n# weights_dir = '/kaggle/input/vinbigdata-cxr-ad-yolov5-14-class-train/yolov5/runs/train/exp/weights/best.pt'\nweights_dir = f'/kaggle/input/softnms/best_softnms.pt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/test.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# YOLOv5 Stuff"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\n# shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', './yolov5')\n\nos.chdir('/kaggle/working/yolov5') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"!python detect.py --weights $weights_dir\\\n--img 640\\\n--conf 0.15\\\n--iou 0.4\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs/detect/exp/*png')\nfor _ in range(6):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process Submission"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n#     print('bboxes',bboxes)\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# image_ids = []\n# PredictionStrings = []\n\n# for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n#     image_id = file_path.split('/')[-1].split('.')[0]\n#     w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n#     f = open(file_path, 'r')\n#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n#     data = data[:, [0, 5, 1, 2, 3, 4]]\n    \n    \n#     list_classid_probility = data[:, :2]\n#     list_normalized_box = data[:, 2:]\n#     filtered_list_classid_probility=[]\n#     filtered_list_normalized_box=[]\n    \n#     for i in range(len(list_classid_probility)):\n#         if Hotmask_mid_value(list_classid_probility[i][0] , list_normalized_box[i])>0.1 or Hotmask_w_h_value(list_classid_probility[i][0] , list_normalized_box[i])>0.1 or list_classid_probility[i][0]==14:\n#             filtered_list_classid_probility.appendpend(list_classid_probility[i][0])\n#             filtered_list_normalized_box.appendpend(list_classid_probility[i][0])\n            \n#     bboxes = list(np.round(np.concatenate((filtered_list_classid_probility, np.round(yolo2voc(h, w, filtered_list_normalized_box))), axis =1).reshape(-1), 1).astype(str))\n#     print('data[:, 2:]',data[:, 2:])\n#     for idx in range(len(bboxes)):\n#         bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n#     image_ids.append(image_id)\n#     PredictionStrings.append(' '.join(bboxes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\ndim = 512 #512, 256, 'original'\nfold = 4\n\ntrain_df = pd.read_csv(f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/train.csv')\ntrain_df.head()\n\ntrain_df['x_min'] = train_df.apply(lambda row: (row.x_min)/row.width, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)/row.height, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)/row.width, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)/row.height, axis =1)\n\ntrain_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)/2, axis =1)\ntrain_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)/2, axis =1)\n\ntrain_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain_df['area'] = train_df['w']*train_df['h']\ntrain_df.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_mid_gaussian_kde=[]\nfor i in range(14):\n    \n\n    train_df_0 = train_df[train_df.class_id==i]\n    x_val = train_df_0.x_mid\n    y_val = train_df_0.y_mid\n    print(len(x_val))\n\n    # Calculate the point density\n    xy = np.vstack([x_val,y_val])\n    z = gaussian_kde(xy)(xy)\n\n    fig, ax = plt.subplots(figsize = (10, 10))\n    # ax.axis('off')\n    ax.axis([0,1,1,0])\n    ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n    # ax.set_xlabel('x_mid')\n    # ax.set_ylabel('y_mid')\n    plt.show()\n\n    evalutor=gaussian_kde(xy)\n    # evalutor.evaluate([[0.6],[0.4]])\n    list_mid_gaussian_kde.append(evalutor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_w_h_gaussian_kde=[]\nfor i in range(14):\n    \n\n    train_df_0 = train_df[train_df.class_id==i]\n    x_val = train_df_0.w\n    y_val = train_df_0.h\n    print(len(x_val))\n\n    # Calculate the point density\n    xy = np.vstack([x_val,y_val])\n    z = gaussian_kde(xy)(xy)\n\n    fig, ax = plt.subplots(figsize = (10, 10))\n    # ax.axis('off')\n    ax.axis([0,1,1,0])\n    ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n    # ax.set_xlabel('x_mid')\n    # ax.set_ylabel('y_mid')\n    plt.show()\n\n    evalutor=gaussian_kde(xy)\n    # evalutor.evaluate([[0.6],[0.4]])\n    list_w_h_gaussian_kde.append(evalutor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.pythonheidong.com/blog/article/436765/a0facf9464d9337dc1eb/\nlist_area_gaussian_kde=[]\nfor i in range(14):\n    train_df_0 = train_df[train_df.class_id==i]\n    data = train_df_0.w\n\n    density = gaussian_kde(data)\n    xs = np.linspace(0,1,200)\n    plt.plot(xs,density(xs))\n    plt.show()\n    list_area_gaussian_kde.append(density)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(density.evaluate(0.4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Hotmask_mid_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_mid_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate([[normalized_xmid_ymid_w_h[0]],[normalized_xmid_ymid_w_h[1]]])\n    \n    return value\n\ndef Hotmask_w_h_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_w_h_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate([[normalized_xmid_ymid_w_h[2]],[normalized_xmid_ymid_w_h[3]]])\n    \n    return value\n\ndef Hotmask_area_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_area_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate(normalized_xmid_ymid_w_h[2]*normalized_xmid_ymid_w_h[3])\n    \n    return value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_ids = []\nPredictionStrings = []\nsum_delte_on=0\n\n# threshold=0.001\nthreshold_mid=0.001\nthreshold_w_h=0.001\nthreshold_area=0.001\n\nfor file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n    delte_on=0\n    \n    image_id = file_path.split('/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n#     print('data',data.type)\n    \n    list_classid_probility = data[:, :2]\n    list_normalized_box = data[:, 2:]\n    delte_sign=[]\n#     filtered_list_classid_probility=[]\n#     filtered_list_normalized_box=[]\n    \n#     print('data[:, :2]',data[:, :2]) \n    \n    for i in range(len(list_classid_probility)):\n        if (Hotmask_mid_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_mid and Hotmask_w_h_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_w_h and Hotmask_area_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_area) or list_classid_probility[i][0]==14:\n            delte_sign.append(True)\n        else:\n            delte_sign.append(False)\n            delte_on+=1\n            \n#             filtered_list_classid_probility.append(list_classid_probility[i][0])\n#             filtered_list_normalized_box.append(list_classid_probility[i].tolist())\n            \n#     prin**t('filtered_list_normalized_box',filtered_list_normalized_box) \n    \n    print('delte_sign',delte_sign) \n    bboxes = list(np.round(np.concatenate((data[:, :2][delte_sign], np.round(yolo2voc(h, w, data[:, 2:][delte_sign]))), axis =1).reshape(-1), 1).astype(str))\n#     bboxes = np.array(list(np.round(np.concatenate((filtered_list_classid_probility, np.round(yolo2voc(h, w, filtered_list_normalized_box))), axis =1).reshape(-1), 1).astype(str)),dtype=np.float32)\n#     print('data[:, 2:]',data[:, 2:])\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))\n    \n    if delte_on!=0:\n        sum_delte_on+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_delte_on","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image_ids = []\n# PredictionStrings = []\n\n# for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n#     image_id = file_path.split('/')[-1].split('.')[0]\n#     w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n#     f = open(file_path, 'r')\n#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n#     data = data[:, [0, 5, 1, 2, 3, 4]]\n#     bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n# #     print('data[:, :2]',data[:, :2].type)\n#     for idx in range(len(bboxes)):\n#         bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n        \n#     print('after bboxes',bboxes)\n#     image_ids.append(image_id)\n#     PredictionStrings.append(' '.join(bboxes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df = sub_df[['image_id', 'PredictionString']]\n\nsub_df.loc[sub_df['PredictionString'] =='','PredictionString']=\"14 1 0 0 1 1\"\nsub_df.to_csv('/kaggle/working/submission_softnms.csv',index = False)\nsub_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df = pd.read_csv(f'/kaggle/input/vinbigdata-{dim}-image-dataset/vinbigdata/test.csv')\n# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imagepaths = test_df['image_id'].unique()\n# imagepaths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, name in tqdm(enumerate(imagepaths)):\n#     path=os.path.join('../input/vinbigdata-original-image-dataset/vinbigdata/train',name+'.jpg')\n#     img_array  = cv2.imread(path)\n#     print('name',name)\n#     print('shape',img_array.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data = np.array(sub_df)#np.ndarray()\n# train_x_list=train_data.tolist()#list\n# print(train_x_list)\n# print(type(train_x_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# shutil.rmtree('/kaggle/working/yolov5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}