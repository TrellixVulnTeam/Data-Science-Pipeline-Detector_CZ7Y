{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport pydicom \nimport os\nimport ast\nfrom tqdm import tqdm\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain_df = pd.read_csv('/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['image_id'].nunique() #omits missing values unlike unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(os.listdir(ROOT+'train')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_images = []\nfor i in os.listdir(ROOT+'train'):\n    i = i.split('.')[0]\n    list_images.append(i)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"act_images = []\nfor i in train_df['image_id']:\n    if i in list_images:\n        act_images.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = train_df[train_df['image_id'].isin(act_images)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.image_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(y='class_name',data=train_new,palette='deep')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(y='class_name',data=train_new[train_new['class_name']!='No finding'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.image_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new[train_new['image_id'] == 'ecf474d5d4f65d7a3e23370a68b8c6a0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.rad_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(y='rad_id',data=train_new)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new[train_new['class_name'] != 'No finding'].isna().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_new[train_new['class_name'] != 'No finding']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = ROOT + 'train/00dc70e84d141255f7fc6f8038bdd72e.dicom'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom = pydicom.dcmread(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dicom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom.Rows,dicom.Columns,dicom.PatientSex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows, columns, sex = [], [], []\nids = df['image_id'].unique()\nfor i in ids:\n    path = ROOT + 'train/' + i + '.dicom'\n    dicom = pydicom.dcmread(path, stop_before_pixels = True)\n    rows.append(dicom.Rows)\n    columns.append(dicom.Columns)\n    sex.append(dicom.PatientSex)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"info = pd.DataFrame({'image_id':ids, 'rows':rows, 'columns':columns, 'sex':sex})\ninfo.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,5))\nsns.countplot(info['sex'], palette ='dark')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain = pd.merge(df,info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nassert (train['x_min'] < train['columns']).all()\nassert (train['x_min'] < train['x_max']).all()\nassert (train['y_min'] < train['y_max']).all()\nassert (train['x_max'] <= train['columns']).all()\nassert (train['y_min'] < train['rows']).all()\nassert (train['y_max'] <= train['rows']).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.distplot(train['rows']*train['columns']);\nplt.title(\"total pixels in images\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myfile = pydicom.read_file(path)\nprint(myfile)\nplt.figure(figsize=(12,10))\nplt.imshow(myfile.pixel_array,plt.cm.bone)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path,voi_lut=True,fix_monochrome=True):\n    \n    dicom = pydicom.read_file(path)\n    \n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array,dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if fix_monochrome and dicom.PhotometricInterpretation == 'MONOCHROME1':\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    return (data * 255).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = plt.figure(figsize=(10,10))\nplt.imshow(read_xray(path),cmap='gray');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport matplotlib.patches as patches\n\n_,axes = plt.subplots(4,4,figsize=(20,20))\nfor i in range(4):\n    for j in range(4):\n        path = ROOT + 'train/' + train.iloc[random.randint(0,len(train))]['image_id'] + '.dicom'\n        \n        axes[i][j].imshow(read_xray(path),cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['class_name'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef plot(name):\n    ttrain = train[train['class_name'] == name]\n    fig, axes = plt.subplots(4,4, figsize=(20, 20))\n    fig.suptitle(name+\" examples\", fontsize=16)\n    for i in range(4):\n        for j in range(4):\n            row = ttrain.iloc[random.randint(0, len(ttrain))]\n            path = ROOT + 'train/' + row['image_id'] + '.dicom'\n            axes[i][j].imshow(read_xray(path), cmap='gray')\n            axes[i][j].add_patch(patches.Rectangle(\n                (row['x_min'], row['y_min']), \n                row['x_max'] - row['x_min'], \n                row['y_max'] - row['y_min'], \n                edgecolor='blue', \n                fill=False)\n            )\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in train['class_name'].unique():\n    plot(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}