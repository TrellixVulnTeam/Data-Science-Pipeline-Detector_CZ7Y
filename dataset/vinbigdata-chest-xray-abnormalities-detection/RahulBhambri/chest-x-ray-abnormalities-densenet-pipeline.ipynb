{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport cv2\nimport pydicom\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# from utilities_x_ray import read_xray,showXray\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\nss = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.image_id.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.class_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.rad_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reliable_annotators2 = ['R8', 'R9', 'R10']\nreliable_annotators = ['R9']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reliable = train[train.rad_id.isin(reliable_annotators)]\ntrain_reliable2 = train[train.rad_id.isin(reliable_annotators2)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reliable.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reliable2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reliable.class_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reliable2.class_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = train_reliable\ntrain = train_reliable2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of rows in train dataframe: {}\".format(train.shape[0]))\nprint(\"Number of Unique images in train set: {}\".format(train.image_id.nunique()))\nprint(\"Number of Classes: {}\\n\".format(train.class_name.nunique()))\nprint(\"Class Names: {}\".format(list(train.class_name.unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = sorted(train.class_name.unique())\ndel class_names[class_names.index('No finding')]\nclass_names = class_names+['No finding']\nclasses = dict(zip(list(range(15)),class_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareDataFrame(train_df= train):\n    train_df = train_df.fillna(0)\n#     train_df = train_df.head(10)\n    \n    cols = ['image_id','label']+list(range(4*len(class_names[:-1])))\n    return_df = pd.DataFrame(columns=cols)\n    \n    for image in tqdm(train_df.image_id.unique()):\n#         print('image=', image)\n        df = train_df.query(\"image_id==@image\")\n#         print('df=', df)\n\n        label = np.zeros(15)\n        for cls in df.class_id.unique():\n#             print('cls=', cls)\n            label[int(cls)]=1\n#             print('label=', label)\n            \n        bboxes_df = df.groupby('class_id')[['x_min','y_min','x_max','y_max']].mean().round()\n#         print('bboxes_df=', bboxes_df)\n        \n        bboxes_list = [0 for i in range(60)]\n        for ind in list(bboxes_df.index):\n            bboxes_list[4*ind:4*ind+4] = list(bboxes_df.loc[ind,:].values)\n        return_df.loc[len(return_df),:] = [image]+[label]+bboxes_list[:-4]\n        \n#         print('===========\\n')\n        \n    return return_df\ntrain_df = prepareDataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_cols = ['image_id',    'label']\ntrain_df = train_df[my_cols]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generateFolds(n_splits = None):\n    kf = KFold(n_splits= n_splits)\n    for id,(tr_,val_) in enumerate(kf.split(train_df[\"image_id\"],train_df[\"label\"])):\n        train_df.loc[val_,'kfold'] = int(id)\n    train_df[\"kfold\"].astype(int)\n\ngenerateFolds(n_splits=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataLoader:\n    def __init__(self,path = None,train_df=train_df,val_df=None):\n        self.path = path\n        self.df = train_df\n        self.val_df = val_df\n        self.train_list = [f'{img}.npy' for img in train_df[\"image_id\"].unique()]\n        np.random.shuffle(self.train_list)\n        self.test_list = [f'{img}.npy' for img in val_df[\"image_id\"].unique()]\n        np.random.shuffle(self.test_list)\n    \n    def read_image(self):\n        for img in self.train_list:\n            im_name = img.split('.npy')[0]\n            image = np.load(self.path+img)\n            temp = self.df[self.df.image_id==im_name]\n            c_label,bb = temp.iloc[0,1],temp.iloc[0,2:].values.astype('float')\n            yield image,c_label,bb\n    \n    \n    def batch_generator(self,items,batch_size):\n        a=[]\n        i=0\n        for item in items:\n            a.append(item)\n            i+=1\n\n            if i%batch_size==0:\n                yield a\n                a=[]\n        if len(a) is not 0:\n            yield a\n            \n    def flow(self,batch_size):\n        \"\"\"\n        flow from given directory in batches\n        ==========================================\n        batch_size: size of the batch\n        \"\"\"\n        while True:\n            for bat in self.batch_generator(self.read_image(),batch_size):\n                batch_images = []\n                batch_c_labels = []\n                batch_bb = []\n                for im,im_c_label,im_bb in bat:\n                    batch_images.append(im)\n                    batch_c_labels.append(im_c_label)\n                    batch_bb.append(im_bb)\n                batch_images = np.stack(batch_images,axis=0)\n\n#                 batch_labels =  (np.stack(batch_c_labels,axis=0),np.stack(batch_bb,axis=0))\n                batch_labels =  np.stack(batch_c_labels,axis=0)\n                yield batch_images,batch_labels\n    \n    def getVal(self):\n        images = []\n        c_labels = []\n        bb_labels = []\n        for img in self.test_list:\n            im_name = img.split('.npy')[0]\n            image = np.load(self.path+img)\n            temp = self.val_df[self.val_df.image_id==im_name]\n            c_label,bb = temp.iloc[0,1],temp.iloc[0,2:].values.astype('float')\n            images.append(image)\n            c_labels.append(c_label)\n            bb_labels.append(bb)\n\n#         return np.stack(images,axis=0),(np.stack(c_labels,axis=0),np.stack(bb_labels,axis=0))\n        return np.stack(images,axis=0),np.stack(c_labels,axis=0)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class_label = np.zeros((len(X_test),15))\n# bb_label = np.zeros((len(X_test),56))\n\nfor fold in range(3):\n    print(f'\\nFold: {fold}\\n')\n    \n#     X_train = train_df[train_df.kfold!=fold].drop('kfold',axis=1)\n#     X_val = train_df[train_df.kfold==fold].drop('kfold',axis=1)\n    X_train = train_df[train_df.kfold!=fold]\n    X_val = train_df[train_df.kfold==fold]\n    print('X_train.shape=',  X_train.shape)\n    print('X_train.head()=',  X_train.head())\n    \n    print('-----------\\n')\n    \n    print('X_val.shape=',  X_val.shape)\n    print('X_val.head()=',  X_val.head())\n\n    \n    print('-----------\\n')\n    dl = DataLoader('../input/xraynumpy/images/train/',X_train,X_val)\n    train_set = dl.flow(batch_size=32)\n\n    X_eval,Y_eval = dl.getVal()\n#     print('X_eval[0]=', X_eval[0])\n    print('X_eval.shape=', X_eval.shape)\n\n#     print('Y_eval[0]=', Y_eval[0])\n    print('Y_eval.shape=', Y_eval.shape)\n    \n    \n    break\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### now build densenet model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n# import tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.metrics import Recall, Precision","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### get perf metrics per class"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = Y_eval","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_true_pos(y, pred, th=0.5):\n    pred_t = (pred > th)\n    return np.sum((pred_t == True) & (y == 1))\n\n\ndef get_true_neg(y, pred, th=0.5):\n    pred_t = (pred > th)\n    return np.sum((pred_t == False) & (y == 0))\n\n\ndef get_false_neg(y, pred, th=0.5):\n    pred_t = (pred > th)\n    return np.sum((pred_t == False) & (y == 1))\n\n\ndef get_false_pos(y, pred, th=0.5):\n    pred_t = (pred > th)\n    return np.sum((pred_t == True) & (y == 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def true_positives(y, pred, th=0.5):\n    \"\"\"\n    Count true positives.\n\n    Args:\n        y (np.array): ground truth, size (n_examples)\n        pred (np.array): model output, size (n_examples)\n        th (float): cutoff value for positive prediction from model\n    Returns:\n        TP (int): true positives\n    \"\"\"\n    TP = 0\n    \n    # get thresholded predictions\n    thresholded_preds = pred >= th\n\n    # compute TP\n    TP = np.sum((y == 1) & (thresholded_preds == 1))\n    \n    return TP\n\ndef true_negatives(y, pred, th=0.5):\n    \"\"\"\n    Count true negatives.\n\n    Args:\n        y (np.array): ground truth, size (n_examples)\n        pred (np.array): model output, size (n_examples)\n        th (float): cutoff value for positive prediction from model\n    Returns:\n        TN (int): true negatives\n    \"\"\"\n    TN = 0\n    \n    # get thresholded predictions\n    thresholded_preds = pred >= th\n\n    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n    \n    # compute TN\n    TN = np.sum((y == 0) & (thresholded_preds == 0))\n\n    ### END CODE HERE ###\n    \n    return TN\n\ndef false_positives(y, pred, th=0.5):\n    \"\"\"\n    Count false positives.\n\n    Args:\n        y (np.array): ground truth, size (n_examples)\n        pred (np.array): model output, size (n_examples)\n        th (float): cutoff value for positive prediction from model\n    Returns:\n        FP (int): false positives\n    \"\"\"\n    FP = 0\n    \n    # get thresholded predictions\n    thresholded_preds = pred >= th\n    \n    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n\n    # compute FP\n    FP = np.sum((y == 0) & (thresholded_preds == 1))\n\n    ### END CODE HERE ###\n    \n    return FP\n\ndef false_negatives(y, pred, th=0.5):\n    \"\"\"\n    Count false positives.\n\n    Args:\n        y (np.array): ground truth, size (n_examples)\n        pred (np.array): model output, size (n_examples)\n        th (float): cutoff value for positive prediction from model\n    Returns:\n        FN (int): false negatives\n    \"\"\"\n    FN = 0\n    \n    # get thresholded predictions\n    thresholded_preds = pred >= th\n\n    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n    \n    # compute FN\n    FN = np.sum((y == 1) & (thresholded_preds == 0))\n\n    ### END CODE HERE ###\n    \n    return FN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_accuracy(y, pred, th=0.5):\n    \"\"\"\n    Compute accuracy of predictions at threshold.\n\n    Args:\n        y (np.array): ground truth, size (n_examples)\n        pred (np.array): model output, size (n_examples)\n        th (float): cutoff value for positive prediction from model\n    Returns:\n        accuracy (float): accuracy of predictions at threshold\n    \"\"\"\n    accuracy = 0.0\n    \n    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n    \n    # get TP, FP, TN, FN using our previously defined functions\n    TP = true_positives(y, pred, th)\n    FP = false_positives(y, pred, th)\n    TN = true_negatives(y, pred, th)\n    FN = false_negatives(y, pred, th)\n\n    # Compute accuracy using TP, FP, TN, FN\n    accuracy = (TP + TN) / (TP + TN + FP + FN) \n    \n    ### END CODE HERE ###\n    \n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_performance_metrics(y, \n                            pred, \n                            class_labels, \n                            tp=get_true_pos,\n                            tn=get_true_neg, \n                            fp=get_false_pos,\n                            fn=get_false_neg,\n                            acc=None, \n                            prevalence=None, \n                            spec=None,\n                            sens=None, \n                            ppv=None, \n                            npv=None, \n                            auc=None, \n                            f1=None,\n                            thresholds=[]):\n    if len(thresholds) != len(class_labels):\n        thresholds = [.5] * len(class_labels)\n\n    columns = [\"\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n               \"Sensitivity\",\n               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n    df = pd.DataFrame(columns=columns)\n    for i in range(len(class_labels)):\n        df.loc[i] = [\"\"] + [0] * (len(columns) - 1)\n        df.loc[i][0] = class_labels[i]\n        df.loc[i][1] = round(tp(y[:, i], pred[:, i]),\n                             3) if tp != None else \"Not Defined\"\n        df.loc[i][2] = round(tn(y[:, i], pred[:, i]),\n                             3) if tn != None else \"Not Defined\"\n        df.loc[i][3] = round(fp(y[:, i], pred[:, i]),\n                             3) if fp != None else \"Not Defined\"\n        df.loc[i][4] = round(fn(y[:, i], pred[:, i]),\n                             3) if fn != None else \"Not Defined\"\n        df.loc[i][5] = round(acc(y[:, i], pred[:, i], thresholds[i]),\n                             3) if acc != None else \"Not Defined\"\n        df.loc[i][6] = round(prevalence(y[:, i]),\n                             3) if prevalence != None else \"Not Defined\"\n        df.loc[i][7] = round(sens(y[:, i], pred[:, i], thresholds[i]),\n                             3) if sens != None else \"Not Defined\"\n        df.loc[i][8] = round(spec(y[:, i], pred[:, i], thresholds[i]),\n                             3) if spec != None else \"Not Defined\"\n        df.loc[i][9] = round(ppv(y[:, i], pred[:, i], thresholds[i]),\n                             3) if ppv != None else \"Not Defined\"\n        df.loc[i][10] = round(npv(y[:, i], pred[:, i], thresholds[i]),\n                              3) if npv != None else \"Not Defined\"\n        df.loc[i][11] = round(auc(y[:, i], pred[:, i]),\n                              3) if auc != None else \"Not Defined\"\n        df.loc[i][12] = round(f1(y[:, i], pred[:, i] > thresholds[i]),\n                              3) if f1 != None else \"Not Defined\"\n        df.loc[i][13] = round(thresholds[i], 3)\n\n    df = df.set_index(\"\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels = list(classes.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### need to improve this model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Densenet from Keras\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_densenet_model():\n    # get input layer\n    img_input = tf.keras.layers.Input(shape=(256, 256,1))\n\n    # change shape for compatibility\n    img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])     \n    \n    # load base model - transfer learned\n    base_model = DenseNet121(weights='../input/densenet-weights-nih-coursera-ai4m/densenet.hdf5', include_top=False, input_tensor=img_conc)\n    \n    # see last layer - customise it\n    x = base_model.output\n    \n    # Add a global spatial average pooling layer\n    x_pool = GlobalAveragePooling2D()(x)\n\n    # Add a logistic layer the same size as the number of classes you're trying to predict\n    n_classes = 15\n\n    predictions = Dense(n_classes, activation=\"sigmoid\")(x_pool)\n    print(f\"Predictions have {n_classes} units, one for each class\")\n\n    # Create an updated model\n    # model = Model(inputs=in1, outputs=predictions)\n    model = Model(inputs=img_input, outputs=predictions)\n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = build_densenet_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel2.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', tf.keras.metrics.AUC()]\n             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    chckpt = tf.keras.callbacks.ModelCheckpoint(f'./model2.1_march28.hdf5',\n                                                monitor='val_loss',\n                                                mode='min',\n                                                save_best_only=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k, v in dict(train_reliable2.class_name.value_counts()).items():\n    if v < 1000:\n        print('minority class=', k, v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = {0:1, \n           1:2, \n           2:2,\n           3:1,\n           4:2,\n           5:2,\n           6:1,\n           7:1,\n           8:1,\n           9:1,\n           10:1,\n           11:1,\n           12:2,\n           13:1,\n           14:1\n          }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    print('-----------\\n')\n    model2.fit(train_set,\n               epochs=5,\n               steps_per_epoch=int(7500/32),\n               validation_data = (X_eval,Y_eval),\n               callbacks = [chckpt],\n               class_weight=weights\n              )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ! ls ../input/chest-x-ray-abnormalities-densenet-pipeline\n! ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model2.load_weights('../input/chest-x-ray-abnormalities-densenet-pipeline/model2.hdf5')\nmodel2.load_weights('./model2.1_march28.hdf5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.evaluate(X_eval, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2 = model2.predict(X_eval)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_performance_metrics(y, \n                        y_pred2, \n                        class_labels, \n                        acc=get_accuracy, \n                        auc=roc_auc_score,\n                        f1=f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### new model - change metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"# model3 = build_densenet_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Compile the model\n# model3.compile(optimizer='adam',\n#                loss='binary_crossentropy',\n#                metrics=[tf.keras.metrics.AUC(), 'accuracy']\n#               )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#     chckpt = tf.keras.callbacks.ModelCheckpoint(f'./model3.hdf5',\n#                                                 monitor='val_loss',\n#                                                 mode='min',\n#                                                 save_best_only=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#     print('-----------\\n')\n#     model3.fit(train_set,\n#               epochs=5,\n#               steps_per_epoch=int(7500/32),\n#               validation_data = (X_eval,Y_eval),\n#               callbacks = [chckpt]\n#              )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model3.evaluate(X_eval, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model3.load_weights('./model3.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model3.evaluate(X_eval, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred3 = model3.predict(X_eval)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get_performance_metrics(y, \n#                         y_pred3, \n#                         class_labels, \n#                         acc=get_accuracy, \n#                         auc=roc_auc_score,\n#                         f1=f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### explore, eval predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filename = '03e6ecfa6f6fb33dfeac6ca4f9b459c9'\n# filename = '9a5094b2563a1ef3ff50dc5c7ff71345'\n# filename = '47ed17dcb2cbeec15182ed335a8b5a9e'\n# filename = 'c394eadea89e5795c8037280492d116d'\nfilename = '22b8e616a61bbc4caaed0cf23b7159df'\n# filename = '80caa435b6ab5edaff4a0a758ffaec6e'\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs0 = train[train.image_id == filename]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs = train_df[train_df.image_id == filename]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# docs[\"image_id\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for img in docs[\"image_id\"].unique():\n#     print(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list = [f'{img}.npy' for img in docs[\"image_id\"].unique()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/xraynumpy/images/train/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in docs[\"image_id\"].unique():\n    print(img)\n    image = np.load(path+img + '.npy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [image]\n\nX = np.stack(images,axis=0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op = model.predict(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list(op)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op = op[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ix, y_pred in enumerate(list(op)):\n    if y_pred > 0.5:\n        print(ix, y_pred, classes[ix])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ix, y in enumerate(list(docs.iloc[0].label)):\n    if y > 0:\n        print(ix, y, classes[ix])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs0.class_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}