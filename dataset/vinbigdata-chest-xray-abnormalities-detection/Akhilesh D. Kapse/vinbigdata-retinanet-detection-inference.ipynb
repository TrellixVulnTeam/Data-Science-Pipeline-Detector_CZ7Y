{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-family:verdana;\"> <center>RetinaNetðŸŽ– </center> </h1>\n\n<h3><center style=\"color:#159364; font-family:cursive;\">Validation and Submission Notebook</center></h3>\n\n\n#### 1. Check out Training [Notebook](https://www.kaggle.com/akhileshdkapse/vinbigdata-retinanet-detection-training)\n"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-family:verdana;\"> <center>Offline RetinaNet installation</center> </h1>\n\n#### 2. Check out for .WHL processing [Notebook](https://www.kaggle.com/akhileshdkapse/creating-whl-file-retinanet)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create 'RetinaNet' dir for zip extraction\n%mkdir RetinaNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!unzip ../input/vinbigdata-zip-data/Keras-Retinanet.zip -d ./RetinaNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n\n%cd RetinaNet/\n!pip install ../../input/creating-whl-file-retinanet/whlfiles/keras_resnet-0.2.0-py2.py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport cv2\n\n\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr ,preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\npath= '../../input/retinanet-50-th-epoch-model/resnet50_csv_50.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python setup.py build_ext --inplace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inference model\nmodel = models.load_model(path, backbone_name='resnet101')\nmodel = models.convert_model(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-family:verdana;\"> <center>Model Validation</center> </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_valid= pd.read_csv('annotations_test.csv', header=None)\ndf_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes= pd.read_csv('classes.csv', header=None)\n\nclasses= {}\nclasses_r= {}\nfor name, roll in zip(n_classes[0], n_classes[1]):\n    classes[name]= roll\n    classes_r[roll]=name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uniq= df_valid[0].unique().shape[0]\nclasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(path, th=0.3, draw=True, show_time=True):\n    \n    # load image\n    image = read_image_bgr(path)\n    # copy to draw on\n    image2 = image.copy()\n    #image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n    # preprocess image for network\n    image = preprocess_image(image)\n    image, scale = resize_image(image)\n    \n    # process image\n    start = time.time()\n    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n    if show_time:\n        print(\"processing time: \", time.time() - start)\n    # correct for image scale\n    boxes /= scale\n    \n    if draw:\n        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        # scores are sorted \n            if score < th:\n                break\n            color = label_color(label)\n            b = box.astype(int)\n            draw_box(image2, box, color=color)\n            draw_caption(image2, box, classes_r[label])\n        return image2\n    else:\n        return boxes[0], scores[0], labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grd_vs_pred(i, th= 0.3):\n    path= df_valid[0].unique()[i]\n    grd_img= read_image_bgr(path)\n\n    for r, row in df_valid[df_valid[0]==df_valid[0][i]].iterrows():\n        color= label_color(classes[row[5]])\n        grd_img= cv2.rectangle(np.array(grd_img), (row[1], row[2]), (row[3], row[4]), color, 2)\n        draw_caption(grd_img, row[1:5].values, row[5])\n    pred_img= predict(path, th=th)\n    \n    return grd_img, pred_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# f, ax= plt.subplots(2, 4, figsize=(24, 10))\n\n# for i in range(4):\n#     np.random.seed(i*49)\n#     grd, pred= grd_vs_pred(np.random.randint(uniq), th= 0.4)\n#     ax[0][i%4].imshow(grd); ax[1][i%4].imshow(pred)\n#     ax[0][i%4].set_title('Grd Truth')\n#     ax[1][i%4].set_title('Predicted')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-family:verdana;\"> <center>Result Submission</center> </h1>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/awsaf49\nclass_2= pd.read_csv('../input/vinbigdata-2class-prediction/2-cls test pred.csv')\nclass_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_512=pd.read_csv('../input/vinbigdata-512-image-dataset/vinbigdata/test.csv')\nsub_ex=pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv')\nsub_ex.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.DataFrame.merge(sub_ex,sub_512,on='image_id')\nsub['extra']= sub.image_id +'--'+ sub.width.astype(str) +'--'+ sub.height.astype(str)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perdict_string(label_id, th=0.5):\n    string= ''\n    label_id, w, h= label_id.split('--')\n    xfac= int(w)/512\n    yfac= int(h)/512\n    path='../input/vinbigdata-512-image-dataset/vinbigdata/test/'\n    path= path + label_id + '.png'\n    boxes, score, label= predict(path, th=0.2, draw=False, show_time=False)\n    \n    for l, s, b in zip(label, score, boxes):\n        if s <th:\n            break\n        string+= '{} {:.2f} {} {} {} {} '.format(l ,s , int(b[0]*xfac), int(b[1]*yfac),\n                                                 int((b[2])*xfac), int((b[3])*yfac))\n        \n    return string if len(string) else \"14 1 0 0 1 1\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['PredictionString']= sub.extra.apply(perdict_string)\nsub= sub[['image_id', 'PredictionString']]\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.merge(sub, class_2, on = 'image_id', how = 'left')\npred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_2cls(row, thr=0.1):\n    if row['target']<thr:\n        row['PredictionString'] = '14 1 0 0 1 1'\n    return row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub2 = pred.apply(filter_2cls, axis=1)\nsub2= sub2[['image_id', 'PredictionString']]\nsub2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('/kaggle/working/submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## ðŸŒ„ Thanks for Reading\n\n![](https://i.gifer.com/7ImI.gif)\n\n\n\n<div class=\"alert alert-block alert-info\" style=\"font-size:20px; font-family:verdana;\">\n <a target=\"_blank\" style=\"color:orange;\">Do UPVOTE for more MotivationðŸ¤ž</a>\n</div>\n\n\n\n<hr><hr><hr>\n\n<hr>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}