{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp ../input/hungry-geese-is-a-nlp-problem-part-2/model.h5 ./model.h5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile main.py\nimport tensorflow as tf\nimport os\nfrom tensorflow.keras.layers import Embedding, MultiHeadAttention, LayerNormalization, Dropout, Dense\n\ndef point_wise_feed_forward_network(d_model, dff):\n    return tf.keras.Sequential([\n        Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n        Dense(d_model)  # (batch_size, seq_len, d_model)\n    ])\n\nclass EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=0.1, training=True):\n        super(EncoderLayer, self).__init__()\n        self.training = training\n        \n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = Dropout(rate)\n        self.dropout2 = Dropout(rate)\n\n    def call(self, x):\n        attn_output = self.mha(x, x, x)  # (batch_size, input_seq_len, d_model)\n        attn_output = self.dropout1(attn_output, training=self.training)\n        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n\n        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n        ffn_output = self.dropout2(ffn_output, training=self.training)\n        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n\n        return out2\n\nclass Net(tf.keras.Model):\n    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1, training=True):\n        super(Net, self).__init__()\n        self.training = training\n        self.d_model = d_model\n        self.num_layers = num_layers\n        \n        self.emb = Embedding(input_dim=50, output_dim=128)\n        self.pos_emb = Embedding(input_dim=77, output_dim=128) # relative positional embedding\n        self.cls_token_emb = Embedding(input_dim=1, output_dim=256) # class token\n\n        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate, self.training)\n                           for _ in range(num_layers)]\n\n        self.dropout = tf.keras.layers.Dropout(rate)\n        \n        bs = 128 if self.training else 1\n        self.token = tf.zeros((bs,1),dtype=tf.int64)\n        self.policy_head = Dense(4, activation=None, use_bias=False)\n        \n    def call(self, sentence, positions):\n        h = self.emb(sentence)\n        h_pos = self.pos_emb(positions)\n        h = tf.concat((h_pos,h), 2)\n        \n        h_token = self.cls_token_emb(self.token)\n        h = tf.concat((h_token,h), 1)\n        \n        h = self.dropout(h, training=self.training)\n        \n        for i in range(self.num_layers):\n            h = self.enc_layers[i](h)\n        \n        action_token_h = h[:,0]\n\n        return self.policy_head(action_token_h)\n\nmodel_inf = Net(num_layers=6, d_model=256, num_heads=8, dff=2048, training=False)\nmodel_inf(tf.zeros((1,77),dtype=tf.int64),tf.zeros((1,77),dtype=tf.int64))\n\ntgz_agent_path = '/kaggle_simulations/agent/'\nnormal_agent_path = '/kaggle/working'\nmodel_name = \"model\"\n\nfile_name = os.path.join(normal_agent_path, f'{model_name}.h5')\nif not os.path.exists(file_name):\n    file_name = os.path.join(tgz_agent_path, f'{model_name}.h5')\nmodel_inf.load_weights(file_name)\n\nimport numpy as np\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Action\n\ndef find_last_player_action(new_obs,previous_obs=None):\n    last_actions = [\"NORTH\"]*4\n    \n    if previous_obs is None:\n        return last_actions\n    \n    for p in range(4):\n        if not len(previous_obs[\"geese\"][p]) or not len(new_obs[\"geese\"][p]):\n            continue\n        \n        previous_head = previous_obs[\"geese\"][p][0]\n        previous_head_x = previous_head % 11\n        previous_head_y = previous_head // 11\n        \n        new_head = new_obs[\"geese\"][p][0]\n        new_head_x = new_head % 11\n        new_head_y = new_head // 11\n        \n        if previous_head_x < new_head_x:\n            if previous_head_x == 0 and new_head_x == 10:\n                last_actions[p] = \"WEST\"\n            else:\n                last_actions[p] = \"EAST\"\n        elif previous_head_x > new_head_x:\n            if previous_head_x == 10 and new_head_x == 0:\n                last_actions[p] = \"EAST\"\n            else:\n                last_actions[p] = \"WEST\"\n        elif previous_head_y < new_head_y:\n            if previous_head_y == 0 and new_head_y == 6:\n                last_actions[p] = \"NORTH\"\n            else:\n                last_actions[p] = \"SOUTH\"\n        elif previous_head_y > new_head_y:\n            if previous_head_y == 6 and new_head_y == 0:\n                last_actions[p] = \"SOUTH\"\n            else:\n                last_actions[p] = \"NORTH\"\n            \n    return last_actions\n\ndef preprocess_map_obs(obs, previous_obs=None, p=None):\n    if p is None:\n        p = 0\n        \n    relativ_center = obs['geese'][p][0]\n    relativ_poss = np.roll(np.arange(77), relativ_center)\n    \n    previous_actions = find_last_player_action(obs,previous_obs)\n    sentence = []\n    positions = []\n    for pp in range(4):\n        real_player_index = pp\n        player_index = (pp - p) % 4\n        geese_length = len(obs['geese'][real_player_index])\n        for goose_body_position, goose_board_position in enumerate(obs['geese'][real_player_index]):\n            if goose_body_position == 0:\n                body_part = 0\n            elif goose_body_position == (geese_length-1):\n                body_part = 2\n            else:\n                body_part = 1\n\n            last_action = Action[previous_actions[pp]].value\n\n            index_player = 3*4 * player_index\n            index_bodypart = 4*body_part\n            \n            word_unique_index = index_player + index_bodypart + last_action + 1\n            sentence.append(word_unique_index)\n            \n            position = relativ_poss[goose_board_position]\n            positions.append(position)\n            \n\n    for food_board_position in obs['food']:\n        word_unique_index = 47 + 1 + 1\n        sentence.append(word_unique_index)\n        \n        position = relativ_poss[food_board_position]\n        positions.append(position)\n        \n    left_positions = set(range(0,77))-set(positions)\n    \n    positions = positions + list(left_positions)\n    sentence = sentence + [0]*(77-len(sentence))\n        \n    return sentence, positions\n\nobss = []\naction_mapping = ['NORTH', 'SOUTH', 'WEST', 'EAST']\n\ndef agent(obs, _):\n    previous_obs = obss[-1] if len(obss) else None\n    sentence, positions = preprocess_map_obs(obs, previous_obs=previous_obs, p=obs['index'])\n\n    sentence = tf.convert_to_tensor(sentence, dtype=tf.int64)\n    positions = tf.convert_to_tensor(positions, dtype=tf.int64)\n    preds = model_inf.call(tf.expand_dims(sentence,0),tf.expand_dims(positions,0))\n    pred = tf.math.argmax(preds,1).numpy()[0]\n    \n    action = action_mapping[pred]\n    \n    obss.append(obs)\n    return action","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\nenv = make(\"hungry_geese\", debug=True)\n\nenv.reset()\nenv.run(['main.py', 'main.py', 'main.py', 'main.py'])\nenv.render(mode=\"ipython\", width=800, height=700)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar cvzf submission.tar.gz main.py model.h5","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}