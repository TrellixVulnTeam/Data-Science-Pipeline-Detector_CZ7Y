{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# git clone libraries","metadata":{"papermill":{"duration":0.024523,"end_time":"2021-05-18T05:35:20.584294","exception":false,"start_time":"2021-05-18T05:35:20.559771","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"To submit to kaggle using TF-Agent ..\n\n1. Create a python file that describes the agent\n2. git cloned TF-Agent directory\n3. git cloned gin directory\n4. Learned weights file\n\nI found that I should make submiton.tar.gz by putting the four of them together with tar.\n\nBelow is a brief example.\n\n---\n\n- V1: init release\n- V2: changed params\n- V3: added conv_layer_param(CNN) ","metadata":{"papermill":{"duration":0.022578,"end_time":"2021-05-18T05:35:20.629514","exception":false,"start_time":"2021-05-18T05:35:20.606936","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!git clone https://github.com/tensorflow/agents.git\n!mv agents/tf_agents .\n!rm -rf agents","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:20.681565Z","iopub.status.busy":"2021-05-18T05:35:20.679763Z","iopub.status.idle":"2021-05-18T05:35:26.707377Z","shell.execute_reply":"2021-05-18T05:35:26.706673Z"},"papermill":{"duration":6.054346,"end_time":"2021-05-18T05:35:26.707563","exception":false,"start_time":"2021-05-18T05:35:20.653217","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/google/gin-config\n!mv gin-config/gin .\n!rm -rf gin-config","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:26.777461Z","iopub.status.busy":"2021-05-18T05:35:26.77653Z","iopub.status.idle":"2021-05-18T05:35:31.104819Z","shell.execute_reply":"2021-05-18T05:35:31.105517Z"},"papermill":{"duration":4.367099,"end_time":"2021-05-18T05:35:31.105724","exception":false,"start_time":"2021-05-18T05:35:26.738625","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{"papermill":{"duration":0.03313,"end_time":"2021-05-18T05:35:31.171789","exception":false,"start_time":"2021-05-18T05:35:31.138659","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\n\nimport tensorflow as tf\nprint('tf.version:', tf.version.VERSION)\n\nimport tf_agents\n\nfrom kaggle_environments import make","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:31.247646Z","iopub.status.busy":"2021-05-18T05:35:31.246911Z","iopub.status.idle":"2021-05-18T05:35:39.210717Z","shell.execute_reply":"2021-05-18T05:35:39.210098Z"},"papermill":{"duration":8.004339,"end_time":"2021-05-18T05:35:39.21087","exception":false,"start_time":"2021-05-18T05:35:31.206531","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\ndef seed_everything(seed=42):\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\nseed_everything()","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:39.286566Z","iopub.status.busy":"2021-05-18T05:35:39.28587Z","iopub.status.idle":"2021-05-18T05:35:39.289553Z","shell.execute_reply":"2021-05-18T05:35:39.288864Z"},"papermill":{"duration":0.044371,"end_time":"2021-05-18T05:35:39.289805","exception":false,"start_time":"2021-05-18T05:35:39.245434","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{"papermill":{"duration":0.033244,"end_time":"2021-05-18T05:35:39.358256","exception":false,"start_time":"2021-05-18T05:35:39.325012","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# for model\nfc_layer_params = (512, 256)\n# for training\nlearning_rate = 1e-5\nreplay_buffer_max_length = 10_000\nbatch_size = 64\nnum_eval_episodes = 10\n\nnum_iterations = 400_000\ncollect_steps_per_iteration = 1\neval_interval = 1_000","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:39.433861Z","iopub.status.busy":"2021-05-18T05:35:39.432868Z","iopub.status.idle":"2021-05-18T05:35:39.436481Z","shell.execute_reply":"2021-05-18T05:35:39.43582Z"},"papermill":{"duration":0.044665,"end_time":"2021-05-18T05:35:39.436621","exception":false,"start_time":"2021-05-18T05:35:39.391956","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mod observation function","metadata":{"papermill":{"duration":0.035636,"end_time":"2021-05-18T05:35:39.509347","exception":false,"start_time":"2021-05-18T05:35:39.473711","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_board(obs, config, last_position):\n    \"\"\"Convert `obs` dict to 1D array.\n    Dim : 0=mine, 1=inhibit, 2=food\n    Returns:\n        numpy array size (7, 11, 3)\n    \"\"\"\n    rows, columns = config['rows'], config['columns']\n    n_cells = rows * columns\n    center = 0\n    current_position = None\n    X = np.zeros((n_cells, 3))\n    if last_position:\n        X[last_position, 1] = 1\n    for n in range(4):\n        geese = obs['geese'][n]\n        if n==obs.index: # mine\n            X[geese, 0] = 1\n            if len(geese) > 0:\n                current_position = geese[0]\n                center = n_cells//2 + geese[0] + 1\n        else:\n            X[geese, 1] = 0.5\n            if len(geese) > 0:\n                X[geese[0], 1] = 1\n    X[obs['food'], 2] = 1\n    # centering board to my head\n    X = np.tile(X, (3, 1))[center:center+n_cells, :]\n    # reshape\n    X = X.reshape((rows, columns, 3))\n    X = np.array(X, dtype=np.float16)\n    return X, current_position","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:39.592102Z","iopub.status.busy":"2021-05-18T05:35:39.591354Z","iopub.status.idle":"2021-05-18T05:35:39.594472Z","shell.execute_reply":"2021-05-18T05:35:39.59392Z"},"papermill":{"duration":0.049999,"end_time":"2021-05-18T05:35:39.594609","exception":false,"start_time":"2021-05-18T05:35:39.54461","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom environment","metadata":{"papermill":{"duration":0.038241,"end_time":"2021-05-18T05:35:39.667382","exception":false,"start_time":"2021-05-18T05:35:39.629141","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tf_agents.environments import py_environment\nfrom tf_agents.specs import array_spec\nfrom tf_agents.trajectories import time_step as ts\n\nclass GeeseEnv(py_environment.PyEnvironment):\n    def __init__(self):\n        self.choices = ['NORTH', 'SOUTH', 'WEST', 'EAST']\n        self._env = make(\"hungry_geese\", debug=False)\n        self.env = self._env.train([\"greedy\", \"greedy\", \"greedy\", None])\n        self.config = self._env.configuration\n        self.last_position = None\n        self._episode_ended = False\n        self._action_spec = array_spec.BoundedArraySpec(\n            shape=(), dtype=np.int32, minimum=0, maximum=3, name='action')\n        \n        self._observation_spec = array_spec.BoundedArraySpec(\n            shape=(self.config.rows, self.config.columns, 3), \n            dtype=np.float16, minimum=0, maximum=1,\n            name='observation')\n        \n    def action_spec(self):\n        return self._action_spec\n\n    def observation_spec(self):\n        return self._observation_spec\n    \n    def _reset(self):\n        obs = self.env.reset()\n        state, self.last_position = get_board(obs, self.config, self.last_position)\n        self._episode_ended = False\n        return ts.restart(state)\n    \n    def _step(self, action):\n        if self._episode_ended:\n            return self.reset()\n        obs, reward, done, info = self.env.step(self.choices[action])\n        state, self.last_position = get_board(obs, self.config, self.last_position)\n        if self._env.done:\n            self._episode_ended = True\n        if self._episode_ended:\n            return ts.termination(state, reward)\n        else:\n            return ts.transition(state, reward, discount=0.9)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:39.751091Z","iopub.status.busy":"2021-05-18T05:35:39.750419Z","iopub.status.idle":"2021-05-18T05:35:39.754211Z","shell.execute_reply":"2021-05-18T05:35:39.753652Z"},"papermill":{"duration":0.053036,"end_time":"2021-05-18T05:35:39.754375","exception":false,"start_time":"2021-05-18T05:35:39.701339","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check environment\nfrom tf_agents.environments import utils\n\nutils.validate_py_environment(GeeseEnv(), episodes=5)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:39.828799Z","iopub.status.busy":"2021-05-18T05:35:39.828127Z","iopub.status.idle":"2021-05-18T05:35:41.906406Z","shell.execute_reply":"2021-05-18T05:35:41.906955Z"},"papermill":{"duration":2.117941,"end_time":"2021-05-18T05:35:41.90714","exception":false,"start_time":"2021-05-18T05:35:39.789199","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert python env to tensorflow env\nfrom tf_agents.environments import tf_py_environment\n\ntrain_env = tf_py_environment.TFPyEnvironment(GeeseEnv())\neval_env = tf_py_environment.TFPyEnvironment(GeeseEnv())","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:41.985315Z","iopub.status.busy":"2021-05-18T05:35:41.984641Z","iopub.status.idle":"2021-05-18T05:35:42.033217Z","shell.execute_reply":"2021-05-18T05:35:42.03263Z"},"papermill":{"duration":0.089208,"end_time":"2021-05-18T05:35:42.033396","exception":false,"start_time":"2021-05-18T05:35:41.944188","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Agent","metadata":{"papermill":{"duration":0.035971,"end_time":"2021-05-18T05:35:42.108968","exception":false,"start_time":"2021-05-18T05:35:42.072997","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tf_agents.networks import q_network\n\nq_net = q_network.QNetwork(\n    train_env.observation_spec(),\n    train_env.action_spec(),\n    fc_layer_params=fc_layer_params,\n    conv_layer_params=[(32,3,1),(64,3,1)],\n)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:42.190665Z","iopub.status.busy":"2021-05-18T05:35:42.189645Z","iopub.status.idle":"2021-05-18T05:35:42.226003Z","shell.execute_reply":"2021-05-18T05:35:42.225469Z"},"papermill":{"duration":0.079284,"end_time":"2021-05-18T05:35:42.226151","exception":false,"start_time":"2021-05-18T05:35:42.146867","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tf_agents.agents.dqn import dqn_agent\nfrom tf_agents.utils import common\n\noptimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n\ntrain_step_counter = tf.Variable(0)\n\nagent = dqn_agent.DqnAgent(\n    train_env.time_step_spec(),\n    train_env.action_spec(),\n    q_network=q_net,\n    optimizer=optimizer,\n    td_errors_loss_fn=common.element_wise_squared_loss,\n    train_step_counter=train_step_counter)\n\nagent.initialize()","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:42.315903Z","iopub.status.busy":"2021-05-18T05:35:42.313937Z","iopub.status.idle":"2021-05-18T05:35:42.522203Z","shell.execute_reply":"2021-05-18T05:35:42.521218Z"},"papermill":{"duration":0.259703,"end_time":"2021-05-18T05:35:42.522388","exception":false,"start_time":"2021-05-18T05:35:42.262685","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_avg_return(environment, policy, num_episodes=10):\n\n    total_return = 0.0\n    for _ in range(num_episodes):\n\n        time_step = environment.reset()\n        episode_return = 0.0\n\n    while not time_step.is_last():\n        action_step = policy.action(time_step)\n        time_step = environment.step(action_step.action)\n        episode_return += time_step.reward\n    total_return += episode_return\n\n    avg_return = total_return / num_episodes\n    return avg_return.numpy()[0]","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:42.603557Z","iopub.status.busy":"2021-05-18T05:35:42.602382Z","iopub.status.idle":"2021-05-18T05:35:42.604682Z","shell.execute_reply":"2021-05-18T05:35:42.605415Z"},"papermill":{"duration":0.047536,"end_time":"2021-05-18T05:35:42.605623","exception":false,"start_time":"2021-05-18T05:35:42.558087","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Collection\nhttps://www.tensorflow.org/agents/tutorials/10_checkpointer_policysaver_tutorial?hl=en#data_collection","metadata":{"papermill":{"duration":0.038051,"end_time":"2021-05-18T05:35:42.683389","exception":false,"start_time":"2021-05-18T05:35:42.645338","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tf_agents.replay_buffers import tf_uniform_replay_buffer\n\nreplay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n    data_spec=agent.collect_data_spec,\n    batch_size=train_env.batch_size,\n    max_length=replay_buffer_max_length)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:42.761678Z","iopub.status.busy":"2021-05-18T05:35:42.758852Z","iopub.status.idle":"2021-05-18T05:35:42.785371Z","shell.execute_reply":"2021-05-18T05:35:42.784279Z"},"papermill":{"duration":0.065342,"end_time":"2021-05-18T05:35:42.785527","exception":false,"start_time":"2021-05-18T05:35:42.720185","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tf_agents.drivers import dynamic_step_driver\n\ncollect_driver = dynamic_step_driver.DynamicStepDriver(\n    train_env,\n    agent.collect_policy,\n    observers=[replay_buffer.add_batch],\n    num_steps=collect_steps_per_iteration)\n\n# Initial data collection\n_ = collect_driver.run()","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:42.859567Z","iopub.status.busy":"2021-05-18T05:35:42.858881Z","iopub.status.idle":"2021-05-18T05:35:42.957043Z","shell.execute_reply":"2021-05-18T05:35:42.957593Z"},"papermill":{"duration":0.136757,"end_time":"2021-05-18T05:35:42.957774","exception":false,"start_time":"2021-05-18T05:35:42.821017","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = replay_buffer.as_dataset(\n    num_parallel_calls=3, \n    sample_batch_size=batch_size, \n    num_steps=2).prefetch(3)\n\niterator = iter(dataset)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:43.034511Z","iopub.status.busy":"2021-05-18T05:35:43.033833Z","iopub.status.idle":"2021-05-18T05:35:44.320037Z","shell.execute_reply":"2021-05-18T05:35:44.318927Z"},"papermill":{"duration":1.325259,"end_time":"2021-05-18T05:35:44.320197","exception":false,"start_time":"2021-05-18T05:35:42.994938","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"papermill":{"duration":0.038938,"end_time":"2021-05-18T05:35:44.394977","exception":false,"start_time":"2021-05-18T05:35:44.356039","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save model to ./model directory\nimport shutil\nfrom tf_agents.policies import policy_saver\n\nbest_return = 0\ndef save_model_if_best(agent, avg_return):\n    global best_return\n    if avg_return > best_return:\n        policy_dir = 'model'\n        shutil.rmtree(policy_dir, ignore_errors=True)\n        tf_policy_saver = policy_saver.PolicySaver(agent.policy, batch_size=None)\n        tf_policy_saver.save(policy_dir)\n        print(f'saved model, best return={avg_return:,.0f}')\n        best_return = avg_return","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:44.473401Z","iopub.status.busy":"2021-05-18T05:35:44.472407Z","iopub.status.idle":"2021-05-18T05:35:44.475677Z","shell.execute_reply":"2021-05-18T05:35:44.474964Z"},"papermill":{"duration":0.045168,"end_time":"2021-05-18T05:35:44.47585","exception":false,"start_time":"2021-05-18T05:35:44.430682","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# (Optional) Optimize by wrapping some of the code in a graph using TF function.\nagent.train = common.function(agent.train)\n\n# Reset the train step\nagent.train_step_counter.assign(0)\n\n# Evaluate the agent's policy once before training.\navg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\nreturns = [avg_return]\n\ndef train_one_iteration():\n\n    # Collect a few steps using collect_policy and save to the replay buffer.\n    collect_driver.run()\n\n    # Sample a batch of data from the buffer and update the agent's network.\n    experience, unused_info = next(iterator)\n    train_loss = agent.train(experience)\n\n    step = agent.train_step_counter.numpy()\n\n    if step % eval_interval == 0:\n        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n        print('step = {0}: Average Return = {1:,.0f}'.format(step, avg_return))\n        save_model_if_best(agent, avg_return)\n        returns.append(avg_return)\n\nfor _ in range(num_iterations):\n    train_one_iteration()","metadata":{"execution":{"iopub.execute_input":"2021-05-18T05:35:44.57842Z","iopub.status.busy":"2021-05-18T05:35:44.565978Z","iopub.status.idle":"2021-05-18T09:10:56.656607Z","shell.execute_reply":"2021-05-18T09:10:56.657324Z"},"papermill":{"duration":12912.146594,"end_time":"2021-05-18T09:10:56.657562","exception":false,"start_time":"2021-05-18T05:35:44.510968","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsteps = range(0, num_iterations + 1, eval_interval)\nplt.ylabel('Average Return')\nplt.xlabel('Step')\nplt.plot(steps, returns)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:10:56.996317Z","iopub.status.busy":"2021-05-18T09:10:56.995658Z","iopub.status.idle":"2021-05-18T09:10:57.197986Z","shell.execute_reply":"2021-05-18T09:10:57.198512Z"},"papermill":{"duration":0.385466,"end_time":"2021-05-18T09:10:57.198682","exception":false,"start_time":"2021-05-18T09:10:56.813216","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compute_avg_return(eval_env, agent.policy, num_eval_episodes)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:10:57.534737Z","iopub.status.busy":"2021-05-18T09:10:57.534054Z","iopub.status.idle":"2021-05-18T09:10:58.366398Z","shell.execute_reply":"2021-05-18T09:10:58.365817Z"},"papermill":{"duration":1.00986,"end_time":"2021-05-18T09:10:58.366549","exception":false,"start_time":"2021-05-18T09:10:57.356689","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission file","metadata":{"papermill":{"duration":0.160618,"end_time":"2021-05-18T09:10:58.691509","exception":false,"start_time":"2021-05-18T09:10:58.530891","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%writefile main.py\n\nimport sys\nfrom pathlib import Path\nimport numpy as np\nimport tensorflow as tf\n\np = Path('/kaggle_simulations/agent/')\nif p.exists():\n    sys.path.append(str(p))\nelse:\n    p = Path('__file__').resolve().parent\n    \n# tf_agents\nfrom tf_agents.networks import q_network\nfrom tf_agents.trajectories import time_step as ts\n","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:10:59.020101Z","iopub.status.busy":"2021-05-18T09:10:59.019326Z","iopub.status.idle":"2021-05-18T09:10:59.023639Z","shell.execute_reply":"2021-05-18T09:10:59.023062Z"},"papermill":{"duration":0.171515,"end_time":"2021-05-18T09:10:59.023783","exception":false,"start_time":"2021-05-18T09:10:58.852268","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save get_board function\nimport inspect\n\npath = 'main.py'\nwith open(path, 'a') as f:\n    s = inspect.getsource(get_board)\n    f.write(s)","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:10:59.355034Z","iopub.status.busy":"2021-05-18T09:10:59.354368Z","iopub.status.idle":"2021-05-18T09:10:59.358181Z","shell.execute_reply":"2021-05-18T09:10:59.357581Z"},"papermill":{"duration":0.171338,"end_time":"2021-05-18T09:10:59.358335","exception":false,"start_time":"2021-05-18T09:10:59.186997","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile -a main.py\n\nlast_position = None\nsaved_policy = tf.compat.v2.saved_model.load(str(p/'model'))\npolicy_state = saved_policy.get_initial_state(batch_size=1)\n\ndef main(obs, config):\n    global last_position\n    state, last_position = get_board(obs, config, last_position)\n    time_step = ts.TimeStep([0], [0], [0], [state])\n    action = saved_policy.action(time_step, policy_state)\n    action = ['NORTH', 'SOUTH', 'WEST', 'EAST'][int(action.action)]\n    return action","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:10:59.686817Z","iopub.status.busy":"2021-05-18T09:10:59.686109Z","iopub.status.idle":"2021-05-18T09:10:59.690559Z","shell.execute_reply":"2021-05-18T09:10:59.690031Z"},"papermill":{"duration":0.170676,"end_time":"2021-05-18T09:10:59.690701","exception":false,"start_time":"2021-05-18T09:10:59.520025","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = make(\"hungry_geese\", debug=True)\nenv.reset()\nsteps = env.run(['greedy', 'greedy', 'greedy', 'main.py'])\n[res.reward for res in steps[-1]]","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:11:00.044385Z","iopub.status.busy":"2021-05-18T09:11:00.041298Z","iopub.status.idle":"2021-05-18T09:11:01.217306Z","shell.execute_reply":"2021-05-18T09:11:01.217772Z"},"papermill":{"duration":1.367387,"end_time":"2021-05-18T09:11:01.217967","exception":false,"start_time":"2021-05-18T09:10:59.85058","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make submission.tar.gz\n!tar -czf submission.tar.gz model main.py gin tf_agents","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:11:01.630412Z","iopub.status.busy":"2021-05-18T09:11:01.55168Z","iopub.status.idle":"2021-05-18T09:11:02.884566Z","shell.execute_reply":"2021-05-18T09:11:02.883295Z"},"papermill":{"duration":1.503041,"end_time":"2021-05-18T09:11:02.884718","exception":false,"start_time":"2021-05-18T09:11:01.381677","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean up\n!rm -rf gin tf_agents model main.py\n!ls","metadata":{"execution":{"iopub.execute_input":"2021-05-18T09:11:03.219476Z","iopub.status.busy":"2021-05-18T09:11:03.218815Z","iopub.status.idle":"2021-05-18T09:11:04.921529Z","shell.execute_reply":"2021-05-18T09:11:04.922044Z"},"papermill":{"duration":1.873119,"end_time":"2021-05-18T09:11:04.922259","exception":false,"start_time":"2021-05-18T09:11:03.04914","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.16153,"end_time":"2021-05-18T09:11:05.246372","exception":false,"start_time":"2021-05-18T09:11:05.084842","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}