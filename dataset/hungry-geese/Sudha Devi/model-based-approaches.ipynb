{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, adjacent_positions, row_col, translate, min_distance\nfrom kaggle_environments import make\n\nimport gym\nfrom gym import spaces\n\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom enum import Enum, auto\nimport numpy as np\nimport os\nimport random as rand\n\n\nclass CellState(Enum):\n    EMPTY = 0\n    FOOD = auto()\n    HEAD = auto()\n    BODY = auto()\n    TAIL = auto()\n    MY_HEAD = auto()\n    MY_BODY = auto()\n    MY_TAIL = auto()\n    ANY_GOOSE = auto()\n    \n\nclass ObservationProcessor:\n    \n    def __init__(self, rows, columns, hunger_rate, min_food, debug=False, center_head=True):\n        self.debug = debug\n        self.rows, self.columns = rows, columns\n        self.hunger_rate = hunger_rate\n        self.min_food = min_food\n        self.previous_action = -1\n        self.last_action = -1\n        self.last_min_distance_to_food = self.rows*self.columns #initial max value to mark no food seen so far\n        self.center_head = center_head\n\n    #***** BEGIN: utility functions ******   \n    \n    def opposite(self, action):\n        if action == Action.NORTH:\n            return Action.SOUTH\n        if action == Action.SOUTH:\n            return Action.NORTH\n        if action == Action.EAST:\n            return Action.WEST\n        if action == Action.WEST:\n            return Action.EAST\n        raise TypeError(str(action) + \" is not a valid Action.\")\n        \n        \n    def _adjacent_positions(self, position):\n        return adjacent_positions(position, self.columns, self.rows)\n\n    \n    def _min_distance_to_food(self, position, food=None):\n        food = food if food!=None else self.food\n        return min_distance(position, food, self.columns)\n    \n    \n    def _row_col(self, position):\n        return row_col(position, self.columns)\n\n    \n    def _translate(self, position, direction):\n        return translate(position, direction, self.columns, self.rows)     \n\n    \n    def _preprocess_env(self, obs):\n        observation = Observation(obs)\n        \n        self.my_index = observation.index\n\n        if len (observation.geese[self.my_index])>0:\n            self.my_head = observation.geese[self.my_index][0]\n            self.my_tail = observation.geese[self.my_index][-1]        \n            self.my_body = [pos for pos in observation.geese[self.my_index][1:-1]]\n        else:\n            self.my_head = -1\n            self.my_tail = -1\n            self.my_body = []\n\n        \n        self.geese = [g for i,g in enumerate(observation.geese) if i!=self.my_index and len(g) > 0]\n        self.geese_cells = [pos for g in self.geese for pos in g if len(g) > 0]\n        \n        self.occupied = [p for p in self.geese_cells]\n        self.occupied.extend([p for p in observation.geese[self.my_index]])\n        \n        \n        self.heads = [g[0] for i,g in enumerate(observation.geese) if i!=self.my_index and len(g) > 0]\n        self.bodies = [pos  for i,g in enumerate(observation.geese) for pos in g[1:-1] if i!=self.my_index and len(g) > 2]\n        self.tails = [g[-1] for i,g in enumerate(observation.geese) if i!=self.my_index and len(g) > 1]\n        self.food = [f for f in observation.food]\n        \n        self.adjacent_to_heads = [pos for head in self.heads for pos in self._adjacent_positions(head)]\n        self.adjacent_to_bodies = [pos for body in self.bodies for pos in self._adjacent_positions(body)]\n        self.adjacent_to_tails = [pos for tail in self.tails for pos in self._adjacent_positions(tail)]\n        self.adjacent_to_geese = self.adjacent_to_heads + self.adjacent_to_bodies\n        self.danger_zone = self.adjacent_to_geese\n        \n        #Cell occupation\n        self.cell_states = [CellState.EMPTY.value for _ in range(self.rows*self.columns)]\n        for g in self.geese:\n            for pos in g:\n                self.cell_states[pos] = CellState.ANY_GOOSE.value\n        for pos in self.heads:\n                self.cell_states[pos] = CellState.ANY_GOOSE.value\n        for pos in self.my_body:\n            self.cell_states[pos] = CellState.ANY_GOOSE.value\n        self.cell_states[self.my_tail] = CellState.ANY_GOOSE.value\n                \n        #detect dead-ends\n        self.dead_ends = []\n        for pos_i,_ in enumerate(self.cell_states):\n            if self.cell_states[pos_i] != CellState.EMPTY.value:\n                continue\n            adjacent = self._adjacent_positions(pos_i)\n            adjacent_states = [self.cell_states[adj_pos] for adj_pos in adjacent if adj_pos!=self.my_head]\n            num_blocked = sum(adjacent_states)\n            if num_blocked>=(CellState.ANY_GOOSE.value*3):\n                self.dead_ends.append(pos_i)\n        \n        #check for extended dead-ends\n        new_dead_ends = [pos for pos in self.dead_ends]\n        while new_dead_ends!=[]:\n            for pos in new_dead_ends:\n                self.cell_states[pos]=CellState.ANY_GOOSE.value\n                self.dead_ends.append(pos)\n            \n            new_dead_ends = []\n            for pos_i,_ in enumerate(self.cell_states):\n                if self.cell_states[pos_i] != CellState.EMPTY.value:\n                    continue\n                adjacent = self._adjacent_positions(pos_i)\n                adjacent_states = [self.cell_states[adj_pos] for adj_pos in adjacent if adj_pos!=self.my_head]\n                num_blocked = sum(adjacent_states)\n                if num_blocked>=(CellState.ANY_GOOSE.value*3):\n                    new_dead_ends.append(pos_i)    \n                    \n                        \n    def safe_position(self, future_position):\n        return (future_position not in self.occupied) and (future_position not in self.adjacent_to_heads) and (future_position not in self.dead_ends)\n    \n    \n    def valid_position(self, future_position):\n        return (future_position not in self.occupied) and (future_position not in self.dead_ends)    \n\n    \n    def free_position(self, future_position):\n        return (future_position not in self.occupied)  \n    \n    #***** END: utility functions ******\n    \n    \n    def process_env_obs(self, obs):\n        self._preprocess_env(obs)\n        \n        EMPTY = .4\n        HEAD = -1\n        BODY = MY_BODY = -.8\n        TAIL = MY_TAIL = -.5\n        MY_HEAD = 0\n        FOOD = 1\n        RISK = -.5\n        \n        #Example: {'remainingOverageTime': 12, 'step': 0, 'geese': [[62], [50]], 'food': [7, 71], 'index': 0}\n        #observation = [[CellState.EMPTY.value for _ in range(self.columns)] for _ in range(self.rows)]\n        observation = [[EMPTY for _ in range(self.columns)] for _ in range(self.rows)]\n        \n        #Other agents\n        for pos in self.heads:\n            r, c = self._row_col(pos)\n            observation[r][c] = HEAD #CellState.HEAD.value\n        for pos in self.bodies:\n            r, c = self._row_col(pos)\n            observation[r][c] = BODY #CellState.BODY.value\n        for pos in self.tails:\n            r, c = self._row_col(pos)\n            observation[r][c] = TAIL #CellState.TAIL.value\n\n        #Me\n        r, c = self._row_col(self.my_head)\n        observation[r][c] = MY_HEAD #-1 #CellState.MY_HEAD.value\n        if self.my_head != self.my_tail:\n            r, c = self._row_col(self.my_tail)\n            observation[r][c] = MY_TAIL #CellState.MY_TAIL.value\n        for pos in self.my_body:\n            r, c = self._row_col(pos)\n            observation[r][c] = MY_BODY #CellState.MY_BODY.value\n            \n        #Food\n        for pos in self.food:\n            r, c = self._row_col(pos)\n            observation[r][c] = FOOD #CellState.FOOD.value\n        \n        \n        if (self.previous_action!=-1):\n            aux_previous_pos = self._translate(self.my_head, self.opposite(self.previous_action))\n            r, c = self._row_col(aux_previous_pos)\n            if observation[r][c]>0:\n                observation[r][c] = MY_BODY * .5 #Marked to avoid opposite moves\n        \n        #Add risk mark\n        for pos in self.adjacent_to_heads:\n            r, c = self._row_col(pos)\n            if observation[r][c] > 0:\n                    observation[r][c] = RISK\n\n        #Add risk mark\n        for pos in self.dead_ends:\n            r, c = self._row_col(pos)\n            if observation[r][c] > 0:\n                    observation[r][c] = RISK/2        \n        \n        if self.center_head:\n            #NOTE: assumes odd number of rows and columns\n            head_row, head_col = self._row_col(self.my_head)\n            v_center = (self.columns // 2) # col 5 on 0-10 (11 columns)\n            v_roll = v_center - head_col\n            h_center = (self.rows // 2) # row 3 on 0-7 (7 rows)\n            h_roll = h_center - head_row\n            observation = np.roll(observation, v_roll, axis=1)\n            observation = np.roll(observation, h_roll, axis=0)\n\n        return np.array([observation])\n    \n    \nclass MyNN(nn.Module):\n    def __init__(self):\n        super(MyNN, self).__init__()\n        \"\"\"use names generated on adapted saved_dict\n        dict_keys(['layer0.weight', 'layer0.bias', 'layer2.weight', 'layer2.bias', ...])\n\n        net_arch as seen before:\n          (q_net): QNetwork(\n            (features_extractor): FlattenExtractor(\n              (flatten): Flatten(start_dim=1, end_dim=-1)\n            )\n            (q_net): Sequential(\n              (0): Linear(...)\n              (1): ReLU()\n              ...\n            )\n          )\n        \"\"\"\n        #net_arch = [2000, 1000, 500, 1000, 500, 100]\n        self.layer0 = nn.Linear(77, 2000)\n        self.layer2 = nn.Linear(2000, 1000)\n        self.layer4 = nn.Linear(1000, 500)\n        self.layer6 = nn.Linear(500, 1000)\n        self.layer8 = nn.Linear(1000, 500)\n        self.layer10 = nn.Linear(500, 100)\n        self.layer12 = nn.Linear(100, 4)\n\n    def forward(self, x):\n        x = nn.Flatten()(x)  # no feature extractor means flatten (check policy arch on DQN creation)\n        for layer in [self.layer0, self.layer2, self.layer4, self.layer6, self.layer8, self.layer10]:\n            x = F.relu(layer(x))\n        x = self.layer12(x)\n        return x\n            \n        \ndef my_dqn(observation, configuration):\n    global model, obs_prep, last_action, last_observation, previous_observation\n\n    tgz_agent_path = '/kaggle_simulations/agent/'\n    normal_agent_path = '/kaggle/working'\n    model_name = \"dqnv1\"\n    num_previous_observations = 0\n    epsilon = 0\n    init = False\n    debug = False\n\n    try:\n        model\n    except NameError:\n        init=True\n    else:\n        if model==None:\n            init = True \n            initializing\n    if init:\n        #initializations\n        defaults = [configuration.rows,\n                    configuration.columns,\n                    configuration.hunger_rate,\n                    configuration.min_food]\n\n        model = MyNN()\n        last_action = -1\n        last_observation = []\n        previous_observation = []\n        \n        file_name = os.path.join(normal_agent_path, f'{model_name}.pt')\n        if not os.path.exists(file_name):\n            file_name = os.path.join(tgz_agent_path, f'{model_name}.pt')\n            \n        model.load_state_dict(th.load(file_name))\n        obs_prep = ObservationProcessor(configuration.rows, configuration.columns, configuration.hunger_rate, configuration.min_food)\n    \n    #maintaint list of  last observations\n    if num_previous_observations>0 and len(last_observation)>0:\n        #Not initial step, t=0\n        previous_observation.append(last_observation)\n        #Keep list constrained to max length\n        if len(previous_observation)>num_previous_observations:\n            del previous_observation[0]\n            \n    #Convert to grid encoded with CellState values\n    aux_observation = [obs_prep.process_env_obs(observation)] \n    last_observation = aux_observation\n\n    if num_previous_observations>0 and len(previous_observation)==0:\n        #Initial step, t=0\n        previous_observation = [last_observation for _ in range(num_previous_observations)]\n\n    if num_previous_observations>0:\n        aux_observation = np.concatenate((*previous_observation, last_observation), axis=0)\n    else:\n        aux_observation = last_observation\n        \n    #predict with aux_observation.shape = (last_observations x rows x cols)\n    tensor_obs = th.Tensor([aux_observation])\n    n_out = model(tensor_obs) #Example: tensor([[0.2742, 0.2653, 0.2301, 0.2303]], grad_fn=<SoftmaxBackward>) \n    \n    #choose probabilistic next move based on prediction outputs\n    #with epsilon probability of fully random, always avoid opposite of last move\n    actions = [action.value for action in Action]\n    weights = list(n_out[0].detach().numpy())\n    if last_action!=-1:\n        #Avoid dying by stupidity xD\n        remove_index = actions.index(obs_prep.opposite(Action(last_action)).value)\n        del actions[remove_index]\n        del weights[remove_index]    \n    random=False\n\n    min_value = abs(min(weights))\n    weights = [min_value+w+1e-5 for w in weights] #Total of weights must be greater than zero  \n\n    \n    #Reduce weight to penalize bad moves (collisions, etc...)\n    weights_changed = False\n    weights_before = [w for w in weights]\n    for index, action in enumerate(actions):\n        future_position = obs_prep._translate(obs_prep.my_head, Action(action))\n        if not obs_prep.free_position(future_position):\n            weights[index] = min(weights[index], 1e-8) #Collision is worst case\n            weights_changed = True\n        elif future_position in obs_prep.dead_ends:\n            weights[index] = min(weights[index],1e-2) #dead ends\n            weights_changed = True\n        elif future_position in obs_prep.adjacent_to_heads:\n            weights[index] = min(weights[index],1e-8) #adjacent to heads\n            weights_changed = True\n    \n    \n    \n    if debug and weights_changed:\n        print(aux_observation)\n        print(f'Adapted weights: before {weights_before} and after {weights} for actions {[Action(a).name for a in actions]}')\n    #elif debug and not weights_changed:\n    #    print(f'Action weights {weights}')\n\n    if rand.random() < epsilon:\n        prediction = rand.choice(actions)\n        random=True\n    else:\n        prediction = rand.choices(actions, weights=weights)[0] \n    action_predicted = Action(prediction).name\n    \n    #print(observation) #Uncomment to debug a bit too much...\n    #if (last_action!=-1) and debug:\n    #    print(last_observation)\n    #    print(f'valid_actions={actions}, w={weights}, chose={Action(prediction).name}, rand={random}',\n    #          f'previous={Action(last_action).name}, opposite={Action(obs_prep.opposite(Action(last_action)).value).name}') \n    \n    last_action = prediction\n    return action_predicted #return action\n\n\n#env.render(mode=\"ipython\", width=800, height=700)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import kaggle_environments\nfrom kaggle_environments import make, evaluate, utils\n\nenv = make(\"hungry_geese\", debug=False) #set debug to True to see agent internals each step\n\nenv.reset()\nenv.run([\"main.py\",\"greedy\",\"greedy\", \"greedy-goose.py\"])\nenv.render(mode=\"ipython\", width=700, height=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import kaggle_environments\nfrom kaggle_environments import make, evaluate, utils\n\nenv = make(\"hungry_geese\", debug=False) #set debug to True to see agent internals each step\n\nenv.reset()\nenv.run([\"main.py\",\"greedy\",\"greedy\", \"greedy-goose.py\"])\nenv.render(mode=\"ipython\", width=700, height=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}