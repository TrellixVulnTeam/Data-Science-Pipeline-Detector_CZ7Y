{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-23T20:16:25.047912Z","iopub.execute_input":"2021-06-23T20:16:25.048422Z","iopub.status.idle":"2021-06-23T20:16:25.057245Z","shell.execute_reply.started":"2021-06-23T20:16:25.048387Z","shell.execute_reply":"2021-06-23T20:16:25.056386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[link to original NB](https://www.kaggle.com/alexandraamidon/simple-hungry-geese-baseline-heuristic-agent/notebook)","metadata":{}},{"cell_type":"markdown","source":"# Play default agents\nJust to get a sense of how the game works, play two types of default agents against each other: a greedy agent and a random agent.","metadata":{}},{"cell_type":"code","source":"from kaggle_environments.envs.hungry_geese.hungry_geese import greedy_agent, random_agent\nfrom kaggle_environments import evaluate, make\nenv = make(\"hungry_geese\")\nenv.reset()\nenv.run([random_agent, random_agent, random_agent, random_agent])\nenv.render(mode=\"ipython\", width=800, height=700)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T20:16:25.074646Z","iopub.execute_input":"2021-06-23T20:16:25.075027Z","iopub.status.idle":"2021-06-23T20:16:25.146435Z","shell.execute_reply.started":"2021-06-23T20:16:25.074993Z","shell.execute_reply":"2021-06-23T20:16:25.145279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments.envs.hungry_geese.hungry_geese import greedy_agent, random_agent\nfrom kaggle_environments import evaluate, make\nenv = make(\"hungry_geese\")\nenv.reset()\nenv.run([greedy_agent, greedy_agent, greedy_agent, greedy_agent])\nenv.render(mode=\"ipython\", width=800, height=700)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T20:16:25.148569Z","iopub.execute_input":"2021-06-23T20:16:25.148904Z","iopub.status.idle":"2021-06-23T20:16:25.42943Z","shell.execute_reply.started":"2021-06-23T20:16:25.148872Z","shell.execute_reply":"2021-06-23T20:16:25.428481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Baseline: Improve Greedy Agent with 1-step lookahead\n\nAs a start, I will make a simple improvement to the greedy agent: have it look 1 step ahead. \n\n1. Don't get stuck. In the game matching greedy agents against eachother, agents often lost when they got \"stuck\" and couldn't avoid moving into an adversary or a body. We can look ahead 1 step and avoid doing that, if possible.\n\n2. Be adversarial. If agent can move to make another agent \"stuck\", do so.","metadata":{}},{"cell_type":"code","source":"%%writefile submission.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col, adjacent_positions, translate, min_distance\nimport numpy as np\nfrom random import choice\n\n\nclass StrategicGreedyAgent:\n    def __init__(self, configuration: Configuration):\n        self.configuration = configuration\n        self.last_action = None\n\n    def __call__(self, observation: Observation):\n        rows, columns = self.configuration.rows, self.configuration.columns\n\n        food = observation.food\n        geese = observation.geese\n        opponents = [\n            goose\n            for index, goose in enumerate(geese)\n            if index != observation.index and len(goose) > 0\n        ]\n\n        # Don't move adjacent to any heads\n        head_adjacent_positions = {\n            opponent_head_adjacent\n            for opponent in opponents\n            for opponent_head in [opponent[0]]\n            for opponent_head_adjacent in adjacent_positions(opponent_head, columns, rows)\n        }\n        # Don't move into any bodies\n        bodies = {position for goose in geese for position in goose}\n        \n        position = geese[observation.index][0] \n        \n        # Don't get stuck\n        stuck_actions = []\n        for action in Action:\n            new_position = translate(position, action, columns, rows)\n            next_actions = [next_action for next_action in Action if next_action != action.opposite()]\n            num_moves = 0\n            for next_action in next_actions:\n                next_position = translate(new_position, next_action, columns, rows)\n                if next_position not in head_adjacent_positions and next_position not in bodies:\n                    num_moves += 1\n            if num_moves <= 1:\n                stuck_actions.append(next_action)\n        # safety layer - make sure goose can do something!\n        if len(stuck_actions) == 4:\n            stuck_actions = []\n        \n        # Move to the closest food\n        actions = {\n            action: min_distance(new_position, food, columns)\n            for action in Action\n            for new_position in [translate(position, action, columns, rows)]\n            if (\n                new_position not in head_adjacent_positions and\n                new_position not in bodies and\n                action not in stuck_actions and \n                (self.last_action is None or action != self.last_action.opposite())\n            )\n        }\n        \n        action = min(actions, key=actions.get) if any(actions) else choice([action for action in Action])\n        self.last_action = action\n        return action.name\n\n\ncached_greedy_agents = {}\n\n\ndef agent(obs, config):\n    index = obs[\"index\"]\n    if index not in cached_greedy_agents:\n        cached_greedy_agents[index] = StrategicGreedyAgent(Configuration(config))\n    return cached_greedy_agents[index](Observation(obs))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T20:16:25.430917Z","iopub.execute_input":"2021-06-23T20:16:25.431329Z","iopub.status.idle":"2021-06-23T20:16:25.437697Z","shell.execute_reply.started":"2021-06-23T20:16:25.431298Z","shell.execute_reply":"2021-06-23T20:16:25.436609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments.envs.hungry_geese.hungry_geese import greedy_agent, random_agent\nfrom kaggle_environments import evaluate, make\nenv = make(\"hungry_geese\")\nenv.reset()\nenv.run(['submission.py', 'submission.py', 'submission.py', 'submission.py'])\nenv.render(mode=\"ipython\", width=500, height=400)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T20:16:25.439714Z","iopub.execute_input":"2021-06-23T20:16:25.440149Z","iopub.status.idle":"2021-06-23T20:16:25.588751Z","shell.execute_reply.started":"2021-06-23T20:16:25.44011Z","shell.execute_reply":"2021-06-23T20:16:25.587597Z"},"trusted":true},"execution_count":null,"outputs":[]}]}