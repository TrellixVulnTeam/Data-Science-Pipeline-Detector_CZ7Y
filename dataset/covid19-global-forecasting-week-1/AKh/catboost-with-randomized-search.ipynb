{"cells":[{"metadata":{"_uuid":"803a34b3-d629-42b5-9400-5d7ba17e005a","_cell_guid":"a3354b1b-5a17-4847-a85c-3192b654f4f3","trusted":true},"cell_type":"code","source":"import math\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport geopy.distance\n\nimport catboost as cb\n\ndataset_path = '/kaggle/input/covid19-global-forecasting-week-1/'\n\n\nprint ('catboost version', cb.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run on CPU for now"},{"metadata":{"trusted":true},"cell_type":"code","source":"task_type = 'CPU'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load data and perform simple preprocessing:\n\n1. Add 'Day' feature that counts days from the start of the epidemic\n2. Add 'WeekDay' feature\n3. Add 'Distance_to_Hubei' feature. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_hubei_coords(df):\n    for index, row in df.iterrows():\n        if row['Province/State'] == 'Hubei':\n            return (row['Lat'], row['Long'])\n\n    raise Exception('Hubei not found in data')\n\n\ndef preprocess(df, hubei_coords, first_date):\n    df.fillna({'Province/State': ''}, inplace=True)\n    \n    df['Day'] = (df['Date'] - first_date).dt.days.astype('int32')\n\n    hubei_coords = get_hubei_coords(df)\n    \n    distance_to_hubei = []\n    week_day = []\n        \n    for index, row in df.iterrows():\n        distance_to_hubei.append(geopy.distance.distance((row['Lat'], row['Long']), hubei_coords).km)\n        week_day.append(row['Date'].weekday())\n\n    df['Distance_to_Hubei'] = distance_to_hubei\n    df['WeekDay'] = week_day\n    \n    return df\n\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'), parse_dates=['Date'])\ndf.drop(columns=['Id'], inplace=True)\n\ntest_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'), parse_dates=['Date'])\n\nhubei_coords = get_hubei_coords(df)\nfirst_date = min(df['Date'])\n\n\ndf = preprocess(df, hubei_coords, first_date)\ntest_df = preprocess(test_df, hubei_coords, first_date)\n\nprint ('df.head', df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove the part of test data in train"},{"metadata":{"trusted":true},"cell_type":"code","source":"last_train_date = pd.Timestamp(2020,3,11)\ntrain_df = df[df['Date'] <= last_train_date].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data has time order, respect it"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sort_values(by=['Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform labels to logarithmic scale"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_types = ['ConfirmedCases', 'Fatalities']\n\n\ntrain_labels = dict([(prediction_type, np.log1p(train_df[prediction_type])) for prediction_type in prediction_types])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove label data from features dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(columns=['ConfirmedCases', 'Fatalities'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CatBoost Pool constructor won't recognize 'Date' data, we have 'Day' instead, so drop it"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(columns=['Date'], inplace=True)\ntest_df.drop(columns=['Date'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perform randomized search for each prediction type, print feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['Province/State', 'Country/Region', 'WeekDay']\n\n\ngrid = {\n    'learning_rate': [0.05, 0.07, 0.09, 0.3],\n    'depth': [5, 6, 7],\n    'l2_leaf_reg': [1, 3, 5, 7, 9],\n    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']\n}\n\nsubmissions = {'ForecastId': test_df['ForecastId'].values}\n\nfor prediction_type in prediction_types:\n    print ('prediction_type %s' % prediction_type)\n    \n    train_pool = cb.Pool(train_df, label=train_labels[prediction_type], cat_features=cat_features)\n    test_pool = cb.Pool(test_df, cat_features=cat_features)\n    \n    model = cb.CatBoostRegressor(\n        task_type=task_type,\n        loss_function='RMSE',   # RMSE with log1p-transformed labels is RMSLE\n        early_stopping_rounds=100,\n        has_time=True,\n        iterations=5000\n    )\n\n    model.randomized_search(grid, X=train_pool)\n    \n    feature_importance = model.get_feature_importance(prettified=True)\n    print ('feature_importance', feature_importance)\n    \n    # truncate negative predictions to 0 and round\n    # transform back from log1p using exp1m\n    # round to integers\n    submissions[prediction_type] = np.round(np.expm1(np.maximum(model.predict(test_pool), 0.0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check and save submissions"},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions_df = pd.DataFrame(submissions)\nprint ('submissions_df.head()', submissions_df.head())\n\nsubmissions_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}