{"cells":[{"metadata":{},"cell_type":"markdown","source":"- Add Day of week into model\n- Use Day numberring from start of the observation (for V7).\n- Set RandomTreeDessision\n- Change RFT to Tree Classifier\n\nSet the Data to integer. Before we converted Date to three columns: Year, Month, Day"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\n# pio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom pathlib import Path\ndata_dir = Path('../input/covid19-global-forecasting-week-1')\npio.templates.default = 'ggplot2'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.compose import ColumnTransformer\n# from sklearn.pipeline import Pipeline\n# from sklearn.impute import SimpleImputer\n# from sklearn.preprocessing import OneHotEncoder\n\n# # Preprocessing for numerical data\n# numerical_transformer = SimpleImputer(strategy='constant')\n\n# # Preprocessing for categorical data\n# categorical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='most_frequent')),\n#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n# ])\n\n# # Bundle preprocessing for numerical and categorical data\n# preprocessor = ColumnTransformer(\n#     transformers=[\n#         ('num', numerical_transformer, numerical_cols),\n#         ('cat', categorical_transformer, categorical_cols)\n#     ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Read the data\ndata = pd.read_csv(data_dir/'train.csv') #, index_col='Id') \ndata_test = pd.read_csv(data_dir/'test.csv') #, index_col='Id')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_min = pd.to_datetime( data['Date'].min(),format='%Y-%m-%d')\nt = (pd.DatetimeIndex(data['Date']) - day_min).days\npd.DatetimeIndex(data['Date']).dayofweek","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"l_use_date_int = True\nl_use_days_num = True\n\nmethods = ['use_date_int','use_days_num','use_converter']\nc_method = methods[1]\n\nif c_method == methods[0]:\n\n    data[\"Date\"] = data[\"Date\"].apply(lambda x: x.replace(\"-\",\"\"))\n    data[\"Date\"]  = data[\"Date\"].astype(int)\n\n    data_test[\"Date\"] = data_test[\"Date\"].apply(lambda x: x.replace(\"-\",\"\"))\n    data_test[\"Date\"]  = data_test[\"Date\"].astype(int)\n\n    features = ['Lat','Long','Date']\n\nelif c_method == methods[1]:\n    day_min = pd.to_datetime( data['Date'].min(),format='%Y-%m-%d')\n    t = (pd.DatetimeIndex(data['Date']) - day_min).days\n    \n    data.loc[:,'days'] = pd.Series(t)\n\n    t = (pd.DatetimeIndex(data_test['Date']) - day_min).days\n    \n    data_test.loc[:,'days'] = pd.Series(t)\n\n    features = ['Lat','Long','days']\nelif c_method == methods[2]:\n    # set the time observation \n    t = (pd.DatetimeIndex(data['Date']) - pd.DatetimeIndex([data_test['Date'].min()])[0]).days\n\n    # data_test = data[data['Date']<data_test['Date'].min()]\n    # data_valid = data[data['Date']>=data_test['Date'].min()]\n\n    data['year'] = pd.DatetimeIndex(data['Date']).year\n    data['month'] = pd.DatetimeIndex(data['Date']).month\n    data['day'] = pd.DatetimeIndex(data['Date']).day\n    data_test['year'] = pd.DatetimeIndex(data_test['Date']).year\n    data_test['month'] = pd.DatetimeIndex(data_test['Date']).month\n    data_test['day'] = pd.DatetimeIndex(data_test['Date']).day\n\n    features = ['Lat','Long','year','month','day']\n\n# Add day of week\n\nfeatures += ['dayofweek']\n\ndata['dayofweek'] = pd.DatetimeIndex(data['Date']).dayofweek\ndata_test['dayofweek'] = pd.DatetimeIndex(data_test['Date']).dayofweek\n\n\nX = data[features]\nX1 = data[features]\ny = data.ConfirmedCases\ny1 = data.Fatalities\n\nX_test = data_test[features]\n\n# Break off validation set from training data\n# X_train = X[t<0]\n# X_valid = X[t>=0]\n# y_train = y[t<0]\n# y_valid = y[t>=0]\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                      train_size=0.8, test_size=0.2,\n                                                      random_state=0)\n# Break off validation set from training data\nX1_train, X1_valid, y1_train, y1_valid = train_test_split(X1, y1,\n                                                      train_size=0.8, test_size=0.2,\n                                                      random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in data.columns if\n                    data[cname].nunique() < 10 and \n                    data[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\nprint(categorical_cols, numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[cname for cname in data.columns] # if\n#                     data[cname].nunique() < 10 and \n#                     data[cname].dtype == \"object\"]\n# data['Country/Region'].nunique()\nfor cname in data.columns:\n    print(cname, data[cname].nunique() < 10, data[cname].dtype == \"object\" )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor  \n\nmodel0 = RandomForestRegressor(n_estimators=110, random_state=0)\nmodel1 = RandomForestRegressor(n_estimators=50, random_state=0)\n\nmodel0 = DecisionTreeClassifier(criterion='entropy')\nmodel1 = DecisionTreeClassifier(criterion='entropy')\n\nmodel0 = DecisionTreeRegressor(random_state = 0) \nmodel1 = DecisionTreeRegressor(random_state = 0) \n\n\nmy_pipeline0 = Pipeline(steps=[\n    ('preprocessor', SimpleImputer()),\n    ('model', model0)\n])\n\nmy_pipeline1 = Pipeline(steps=[\n    ('preprocessor', SimpleImputer()),\n    ('model', model1)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline0, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"Average MAE score:\", scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline1, X, y1,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"Average MAE score:\", scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_score(yy, n_estimators):\n    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n    \n    Keyword argument:\n    n_estimators -- the number of trees in the forest\n    \"\"\"\n    # Replace this body with your own code\n    my_pipeline = Pipeline(steps=[\n                    ('preprocessor', SimpleImputer()),\n                    ('model',RandomForestRegressor(n_estimators=n_estimators,random_state=0))\n                    ])\n    score_cross_valids = -1 * cross_val_score(my_pipeline, X, yy,\n                              cv=3,\n                              scoring='neg_mean_absolute_error')\n    return score_cross_valids.mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# results0 = {i: get_score(y,i) for i in range(50,450,50)}\n# results1 = {i: get_score(y1,i) for i in range(50,450,50)}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(results0.keys(),results0.values() )\n# plt.plot(results1.keys(),results1.values() )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(50,170,20):\n#     print(i, get_score(y,i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(1,16):\n#     print(i, get_score(y1,i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# results1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline0.fit(X, y)\nmy_pipeline1.fit(X, y1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_predictions = my_pipeline0.predict(X_valid)\nrf_val_mae = mean_absolute_error(rf_predictions, y_valid)\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds = my_pipeline.predict(X_test)\ntest_preds0 = my_pipeline0.predict(X_test)\ntest_preds1 = my_pipeline1.predict(X_test)\n\nt0 = np.round(test_preds0).astype(int)\nt1 = np.round(test_preds1).astype(int)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_preds0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'ForecastId': data_test.ForecastId,\n                       'ConfirmedCases':t0,\n                       'Fatalities': t1})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Try to use RFT with log_Confirmed"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['log_ConfirmedCases'] = np.log(data['ConfirmedCases']+1)\ndata['log_Fatalities'] = np.log(data['Fatalities']+1)\ny_pred2 = data['log_ConfirmedCases']\ny1_pred2 = data['log_Fatalities']\n\n\n\n# Break off validation set from training data\n\nday_min = pd.to_datetime( data['Date'].min(),format='%Y-%m-%d')\nt = data['days'] < data_test['days'].min()\n\nX_train = X[t]\nX_valid = X[~t]\ny_train = y_pred2[t]\ny_valid = y_pred2[~t]\n\n# def RMSE(y_pred,y_valid):\n#     return np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model0 = RandomForestRegressor(n_estimators=300, random_state=0,verbose=True)\nmodel1 = RandomForestRegressor(n_estimators=100, random_state=0)\n\nmy_pipeline0 = Pipeline(steps=[\n    ('preprocessor', SimpleImputer()),\n    ('model', model0)\n])\n\nmy_pipeline1 = Pipeline(steps=[\n    ('preprocessor', SimpleImputer()),\n    ('model', model1)\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline0.fit(X_train, y_train) #,verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_predictions = my_pipeline0.predict(X_valid)\nrf_val_mae = mean_absolute_error(rf_predictions, y_valid)\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t0 = data['Country/Region']=='Spain'\n# lat,long = data[t0].iloc[0,:][['Lat','Long']].values\n\n# t = (X_train['Lat']== lat) & (X_train['Long']== long)\n# plt.plot(X_train[t]['days'],np.exp(y_train[t])+1)\n# t = (X_valid['Lat']== lat) & (X_valid['Long']== long)\n# plt.plot(X_valid[t]['days'],np.exp(y_valid[t])+1)\n# plt.plot(X_valid[t]['days'],np.exp(rf_predictions[t])+1)\n# # t = (X['Lat']== lat) & (X['Long']== long)\n# # plt.plot(X[t]['days'],test_preds0[t])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_score1(n_est):\n    model = RandomForestRegressor(n_estimators=n_est, random_state=0)\n\n    my_pipeline = Pipeline(steps=[\n                            ('preprocessor', SimpleImputer()),\n                            ('model', model)\n                            ])\n    score_cross_valids = -1 * cross_val_score(my_pipeline0, X_train, y_train,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n    return score_cross_valids.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# res = [get_score1(i) for i in [50,100,500,5000]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline0.fit(X, y_pred2) #,verbose=True)\nmy_pipeline1.fit(X, y1_pred2) #,verbose=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds = my_pipeline.predict(X_test)\ntest_preds2 = my_pipeline0.predict(X_test)\ntest_preds3 = my_pipeline1.predict(X_test)\n\nt0 = np.round(np.exp(test_preds2)-1).astype(int)\nt1 = np.round(np.exp(test_preds3)-1).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.hist(np.log(test_preds0+1),bins=30)\n# plt.hist(test_preds2,bins=30,alpha=0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'ForecastId': data_test.ForecastId,\n                       'ConfirmedCases':t0,\n                       'Fatalities': t1})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}