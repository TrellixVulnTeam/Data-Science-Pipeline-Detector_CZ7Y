{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom google.cloud import bigquery\nfrom scipy.spatial.distance import cdist\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# загружаем данные тренировочного набора\n\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем данные признаков из https://www.kaggle.com/davidbnn92/weather-data?scriptVersionId=30695168\nclient = bigquery.Client()\ndataset_ref = client.dataset(\"noaa_gsod\", project=\"bigquery-public-data\")\ndataset = client.get_dataset(dataset_ref)\n\ntables = list(client.list_tables(dataset))\n\ntable_ref = dataset_ref.table(\"stations\")\ntable = client.get_table(table_ref)\nstations_df = client.list_rows(table).to_dataframe()\n\ntable_ref = dataset_ref.table(\"gsod2020\")\ntable = client.get_table(table_ref)\ntwenty_twenty_df = client.list_rows(table).to_dataframe()\n\nstations_df['STN'] = stations_df['usaf'] + '-' + stations_df['wban']\ntwenty_twenty_df['STN'] = twenty_twenty_df['stn'] + '-' + twenty_twenty_df['wban']\n\ncols_1 = ['STN', 'mo', 'da', 'temp', 'min', 'max', 'stp', 'wdsp', 'prcp', 'fog']\ncols_2 = ['STN', 'country', 'state', 'call', 'lat', 'lon', 'elev']\nweather_df = twenty_twenty_df[cols_1].join(stations_df[cols_2].set_index('STN'), on='STN')\n\nweather_df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_df['day_from_jan_first'] = (weather_df['da'].apply(int)\n                                   + 31*(weather_df['mo']=='02') \n                                   + 60*(weather_df['mo']=='03')\n                                   + 91*(weather_df['mo']=='04')  \n                                   )\n\nmo = train['Date'].apply(lambda x: x[5:7])\nda = train['Date'].apply(lambda x: x[8:10])\ntrain['day_from_jan_first'] = (da.apply(int)\n                               + 31*(mo=='02') \n                               + 60*(mo=='03')\n                               + 91*(mo=='04')  \n                              )\n\nC = []\nfor j in train.index:\n    df = train.iloc[j:(j+1)]\n    mat = cdist(df[['Lat','Long', 'day_from_jan_first']],\n                weather_df[['lat','lon', 'day_from_jan_first']], \n                metric='euclidean')\n    new_df = pd.DataFrame(mat, index=df.Id, columns=weather_df.index)\n    arr = new_df.values\n    new_close = np.where(arr == np.nanmin(arr, axis=1)[:,None],new_df.columns,False)\n    L = [i[i.astype(bool)].tolist()[0] for i in new_close]\n    C.append(L[0])\n    \ntrain['closest_station'] = C\n\ntrain = train.set_index('closest_station').join(weather_df[['temp', 'min', 'max', 'stp', 'wdsp', 'prcp', 'fog']], ).reset_index().drop(['index'], axis=1)\ntrain.sort_values(by=['Id'], inplace=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загружаем тестовый набор данных\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_df['day_from_jan_first'] = (weather_df['da'].apply(int)\n                                   + 31*(weather_df['mo']=='02') \n                                   + 60*(weather_df['mo']=='03')\n                                   + 91*(weather_df['mo']=='04')  \n                                   )\n\nmo = test['Date'].apply(lambda x: x[5:7])\nda = test['Date'].apply(lambda x: x[8:10])\ntest['day_from_jan_first'] = (da.apply(int)\n                               + 31*(mo=='02') \n                               + 60*(mo=='03')\n                               + 91*(mo=='04')  \n                              )\n\nC = []\nfor j in test.index:\n    df = test.iloc[j:(j+1)]\n    mat = cdist(df[['Lat','Long', 'day_from_jan_first']],\n                weather_df[['lat','lon', 'day_from_jan_first']], \n                metric='euclidean')\n    new_df = pd.DataFrame(mat, index=df.ForecastId, columns=weather_df.index)\n    arr = new_df.values\n    new_close = np.where(arr == np.nanmin(arr, axis=1)[:,None],new_df.columns,False)\n    L = [i[i.astype(bool)].tolist()[0] for i in new_close]\n    C.append(L[0])\n    \ntest['closest_station'] = C\n\ntest = test.set_index('closest_station').join(weather_df[['temp', 'min', 'max', 'stp', 'wdsp', 'prcp', 'fog']], ).reset_index().drop(['index'], axis=1)\ntest.sort_values(by=['ForecastId'], inplace=True)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# изменяем тип столбцов wdsp\ntrain[\"wdsp\"] = pd.to_numeric(train[\"wdsp\"])\ntest[\"wdsp\"] = pd.to_numeric(test[\"wdsp\"])\n# изменяем тип столбцов fog\ntrain[\"fog\"] = pd.to_numeric(train[\"fog\"])\ntest[\"fog\"] = pd.to_numeric(test[\"fog\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# удалим из признаков столбцы для прогнозирования\nX_train = train.drop([\"Fatalities\", \"ConfirmedCases\", \"Id\"], axis=1)\nX_test = test.drop([\"ForecastId\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# приведем значение даты в тип datetime\nX_train['Date']= pd.to_datetime(X_train['Date']) \nX_test['Date']= pd.to_datetime(X_test['Date']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# установим индекс на дату\nX_train = X_train.set_index(['Date'])\nX_test = X_test.set_index(['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_time_features(df):\n    \"\"\"Создает элементы временного ряда из индекса даты и времени.\"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создает элементы временного ряда\ncreate_time_features(X_train)\ncreate_time_features(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# удалим столбецц с датой, так как мы уже создали данные временного ряда\nX_train.drop(\"date\", axis=1, inplace=True)\nX_test.drop(\"date\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-Hot-encoding для городов\nX_train = pd.concat([X_train,pd.get_dummies(X_train['Province/State'], prefix='ps')],axis=1)\nX_train.drop(['Province/State'],axis=1, inplace=True)\nX_test = pd.concat([X_test,pd.get_dummies(X_test['Province/State'], prefix='ps')],axis=1)\nX_test.drop(['Province/State'],axis=1, inplace=True)\n# One-Hot-encoding для стран\nX_train = pd.concat([X_train,pd.get_dummies(X_train['Country/Region'], prefix='cr')],axis=1)\nX_train.drop(['Country/Region'],axis=1, inplace=True)\nX_test = pd.concat([X_test,pd.get_dummies(X_test['Country/Region'], prefix='cr')],axis=1)\nX_test.drop(['Country/Region'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y1= train[\"ConfirmedCases\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y2 = train[\"Fatalities\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# определяем количество заболевших\nmodel = RandomForestClassifier(bootstrap=True,max_depth=None, max_features='auto', max_leaf_nodes=None, \n                      n_estimators=150, random_state=None, n_jobs=1, verbose=0)\nmodel.fit(X_train,Y1)\npred1 = model.predict(X_test)\npred1 = pd.DataFrame(pred1)\npred1.columns = [\"ConfirmedCases_prediction\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1[50:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# определяем количество умерших\nmodel = RandomForestClassifier(bootstrap=True,max_depth=None, max_features='auto', max_leaf_nodes=None, \n                      n_estimators=150, random_state=None, n_jobs=1, verbose=0)\nmodel.fit(X_train,Y2)\npred2 = model.predict(X_test)\npred2 = pd.DataFrame(pred2)\npred2.columns = [\"Death_prediction\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_submission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/submission.csv\")\ndata_submission.columns\nsub_new = data_submission[[\"ForecastId\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concat = pd.concat([pred1,pred2,sub_new],axis=1)\nconcat.head()\nconcat.columns = ['ConfirmedCases', 'Fatalities', 'ForecastId']\nconcat = concat[['ForecastId','ConfirmedCases', 'Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concat[\"ConfirmedCases\"] = concat[\"ConfirmedCases\"].astype(int)\nconcat[\"Fatalities\"] = concat[\"Fatalities\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concat.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}