{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nfrom pathlib import Path\nfrom google.cloud import bigquery\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\nimport seaborn as sns\n\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\nimport sklearn\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">** What is the weather like in the regions that were mostly affected by Covid? \nCan we draw any conclusion on which weather conditions favored Covid spread? \nCovid week 1 database provides geographical information (latitude and longitude) and number of Fatalities and Confirmed Cases in 284 location from 163 countries across the world from 22-Jan-2020 to 24-March-2020 (once a day for each lat and lon position). In the future I could address this using a time series approach, in this notebook I used a RandomForest predictive model.\n> Becasue I am treating the Covid information as non-serial (for the serial analysis I will need other approaches), the ConfirmedCases and Fatalities per day are non-cumulative and assumed independent. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv( '/kaggle/input/covid19-global-forecasting-week-1/train.csv')\ntrain=train.rename(columns={\"Lat\": \"lat\", \"Long\": \"lon\"})\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Id'].groupby(train[\"Country/Region\"]).agg(['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mo = train['Date'].apply(lambda x: x[5:7])\nda = train['Date'].apply(lambda x: x[8:10])\ntrain['day_from_jan_first'] = (da.apply(int)\n                               + 31*(mo=='02') \n                               + 60*(mo=='03')\n                               + 91*(mo=='04')  \n                              )\n\ntrain=train.rename(columns={'Country/Region': 'Country'})\nlist(train.Country[(train.day_from_jan_first==80)])\n# train[(train.day_from_jan_first==80)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geom= [Point(xy) for xy in zip(train['lon'], train['lat'])]\n\ncrs={'init': 'epsg:4326'}\ngeo_df= gpd.GeoDataFrame(train, crs=crs, geometry= geom)\nfig, ax= plt.subplots(figsize = (15,15))\ngeo_df.plot(ax= ax, markersize=20, marker= \"o\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **BigQuery Public Data offers the NOAA_GSOD database with weather information (GSOD2020 table) recorded in 29745 stations worldwide (stations table). Among the GSOD measures I selected 6 (mean temperature of the day, mean dewpoint, mean sealevel pressure, mean wind speed, total precipitation, snow depth). **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set your own project id here\nPROJECT_ID = 'your-google-cloud-project'\nfrom google.cloud import bigquery\nclient = bigquery.Client(project=PROJECT_ID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table1_stations = bigquery.TableReference.from_string(\n    \"bigquery-public-data.noaa_gsod.stations\"\n)\n\ndataframe_stations = client.list_rows(\n    table1_stations,\n    selected_fields=[\n        bigquery.SchemaField(\"usaf\", \"STRING\"), #station number, world metherorological org\n        bigquery.SchemaField(\"wban\", \"STRING\"), #wban number, weather bureau army\n        bigquery.SchemaField(\"country\", \"STRING\"),\n        bigquery.SchemaField(\"lat\", \"FLOAT\"),\n        bigquery.SchemaField(\"lon\", \"FLOAT\"),\n    ],\n).to_dataframe()\n\ndataframe_stations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table1_gsod2020 = bigquery.TableReference.from_string(\n    \"bigquery-public-data.noaa_gsod.gsod2020\"\n)\n\ndataframe_gsod2020= client.list_rows(table1_gsod2020,\n    selected_fields=[\n        bigquery.SchemaField(\"stn\", \"STRING\"), #station number\n        bigquery.SchemaField(\"wban\", \"STRING\"), #station number\n        bigquery.SchemaField(\"year\", \"INTEGER\"),\n        bigquery.SchemaField(\"mo\", \"INTEGER\"),\n        bigquery.SchemaField(\"da\", \"INTEGER\"),\n        bigquery.SchemaField(\"temp\", \"FLOAT\"), #mean temp of the day\n        bigquery.SchemaField(\"dewp\", \"FLOAT\"), #mean_dew_point\n        bigquery.SchemaField(\"slp\", \"FLOAT\"), #mean_sealevel_pressure\n        bigquery.SchemaField(\"wdsp\", \"FLOAT\"), #mean_wind_speed\n        bigquery.SchemaField(\"prcp\", \"FLOAT\"), #total_precipitation\n        bigquery.SchemaField(\"sndp\", \"FLOAT\"), #snow_depth\n    ],).to_dataframe()\n\ndataframe_gsod2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stations_df= dataframe_stations\ntwenty_twenty_df= dataframe_gsod2020","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">** I merged the two NOAA_GSOD database tables on the common columns (usaf and wban, which are stations identifiers)\n\n>Then I created two new weather measures: the relative humidity and the actual vapour pressure (in pascals), for source of these measures refer to notebook https://www.kaggle.com/davidbnn92/weather-data/  which is the inspiration to this analysis!\n\n>I will use the new column 'day_from_jan_first' to merge the new weather table with the Covid dataset. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"stations_df['STN'] = stations_df['usaf'] + '-' + stations_df['wban']\ntwenty_twenty_df['STN'] = twenty_twenty_df['stn'] + '-' + twenty_twenty_df['wban']\ncols_1= list(twenty_twenty_df.columns)\ncols_2= list(stations_df.columns)\nweather_df = twenty_twenty_df[cols_1].join(stations_df[cols_2].set_index('STN'), on='STN',  how='left', lsuffix='_left', rsuffix='_right')\n\nweather_df['temp'] = weather_df['temp'].apply(lambda x: np.nan if x==9999.9 else x)\nweather_df['slp'] = weather_df['slp'].apply(lambda x: np.nan if x==9999.9 else x)\nweather_df['dewp'] = weather_df['dewp'].apply(lambda x: np.nan if x==9999.9 else x)\nweather_df['wdsp'] = weather_df['wdsp'].apply(lambda x: np.nan if x==999.9 else x)\nweather_df['prcp'] = weather_df['prcp'].apply(lambda x: np.nan if x==999.9 else x)\nweather_df['sndp'] = weather_df['sndp'].apply(lambda x: np.nan if x==999.9 else x)\n\n# convert everything into celsius\ntemp = (weather_df['temp'] - 32) / 1.8\ndewp = (weather_df['dewp'] - 32) / 1.8\n    \n# compute relative humidity as ratio between actual vapour pressure (computed from dewpoint temperature)\n# and saturation vapour pressure (computed from temperature) (the constant 6.1121 cancels out)\nweather_df['rh'] = (np.exp((18.678*dewp)/(257.14+dewp))/np.exp((18.678*temp)/(257.14+temp)))\n\n# calculate actual vapour pressure (in pascals)\n# then use it to compute absolute humidity from the gas law of vapour \n# (ah = mass / volume = pressure / (constant * temperature))\nweather_df['ah'] = ((np.exp((18.678*dewp)/(257.14+dewp))) * 6.1121 * 100) / (461.5 * temp)\n\n\nweather_df['month']= weather_df['mo']\nweather_df['day']= weather_df['da']\nweather_df['Date']=pd.to_datetime(weather_df[['year','month','day']])\nweather_df['Date2']= weather_df['Date']\nweather_df['Date2']= weather_df['Date2'].astype('str')\nmo2 = weather_df['Date2'].apply(lambda x: x[5:7])\nda2 = weather_df['Date2'].apply(lambda x: x[8:10])\nweather_df['day_from_jan_first'] = (da2.apply(int)\n                               + 31*(mo2=='02') \n                               + 60*(mo2=='03')\n                               + 91*(mo2=='04')  \n                              )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geom= [Point(xy) for xy in zip(weather_df['lon'], weather_df['lat'])]\ncrs={'init': 'epsg:4326'}\ngeo_df= gpd.GeoDataFrame(weather_df, crs=crs, geometry= geom)\nfig, ax= plt.subplots(figsize = (15,15))\ngeo_df.plot(ax= ax, markersize=20, marker= \"o\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **The level of geospatial granularity for the Covid table is not as fine as the weather table. \nTherefore, I am selecting from the weather table only the locations in the Covid database: THIS APPROACH MIGHT LEAD TO INACCURATE PREDICTIONS WHEN THE COVID AREAS ARE VERY BROAD (COVERING DIFFERENT WEATHER REGIONS).\n\n> Also I am extracting from the weather table only the COVID days **"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_df= weather_df.dropna(subset = ['lat', 'lon'])\nweather_df = weather_df.reset_index(drop=True)\ntrain= train.dropna(subset = ['lat', 'lon'])\ntrain = train.reset_index(drop=True)\nweather_df.lon= weather_df.lon.astype(int)\nweather_df.lat= weather_df.lat.astype(int)\ntrain.lon= train.lon.astype(int)\ntrain.lat= train.lat.astype(int)\n\nCovidWeather=train.merge(weather_df, on=['lat', 'lon', 'day_from_jan_first'], how='left')\nCovidWeather","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Now I start creating the features and outcome split **"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_X = [\"lat\", \"lon\",\"temp\", \"dewp\", \"slp\", \"wdsp\", \"prcp\", \"sndp\", \"rh\", \"ah\"]\ncolumns_y= [ \"ConfirmedCases\", \"Fatalities\" ]\n\n\nweather_PerDay2=CovidWeather[[\"lat\", \"lon\",\"temp\", \"dewp\", \"slp\", \"wdsp\", \"prcp\", \"sndp\", \"rh\", \"ah\", \"ConfirmedCases\", \"Fatalities\"]]\nweather_PerDay2.replace([np.inf, -np.inf], np.nan, inplace=True)\n\nweather_PerDay2.data= CovidWeather[columns_X]\nweather_PerDay2.target= CovidWeather[columns_y]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **I also do the test train split on the resulting dataset. I made a lot of changes to the train dataset to integrate it with the weather tables and I do not feel like repeating those changes on the Test data provided by Kaggle. **\n\n> **I impute and scale the data and proceed with RandomForestRegressor**\n\n> **Finally I list the most important features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full, X_test, y_train_full, y_test = train_test_split(\n    weather_PerDay2.data, weather_PerDay2.target, random_state=42)\n\nX_test.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_train_full.replace([np.inf, -np.inf], np.nan, inplace=True)\n\nimputer = SimpleImputer(missing_values= np.nan, strategy='mean')\nimputer=imputer.fit(X_train_full)\nX_train_full = imputer.transform(X_train_full)\nX_train_full\n\nimputer = SimpleImputer(missing_values= np.nan, strategy='mean')\nimputer=imputer.fit(X_test)\nX_test = imputer.transform(X_test)\nX_test\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_full)\nX_test_scaled = scaler.transform(X_test)\n\n\nrnd_reg= RandomForestRegressor()\nrnd_reg.fit (X_train_scaled, y_train_full)\n\nimportances = list(rnd_reg.feature_importances_)\nimportances\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **As you can see longitude is the most important feature followed by dewpoint and latitude **\n\n> **the only weather-related predictor is dewpoint which represents the temperature to which air must be cooled to become saturated with water vapor. When further cooled, the airborne water vapour will condense to form liquid water.**\n\n>**Given the information that we have about the transmission of Coronavirus-19 it seems reasonable that the dew point level might be related to Covid spread**\n\n> **Of course we understand that trying to connect the daily dewpoint to the daily Covid cases is inappropriate: most likely the Confirmed Cases are the result of exposure to the virus several days before and Fatalities several weeks in advance **\n\n> **Let's indulge with this inappropriate analysis decision for the sake of learning and immediate rewarding!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list = list(weather_PerDay2.data.columns)\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **The mean squared error is below**\n> **Please help me out in understanding if this is acceptable or not**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= rnd_reg.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **The following figures are trying to visually show the dew point in areas that were more exposed to Covid. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(weather_PerDay2.dewp,weather_PerDay2.ConfirmedCases)\nplt.show()\nplt.scatter(weather_PerDay2.dewp,weather_PerDay2.Fatalities)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Which locations worldwide have dew point values between 30 and 60 °F? Answer: The places with a critical dew point are spread all over the globe but some places are safe :**\n\n> **This visualization includes all the locations worldwide that have a dew point between 30 and 60 °F.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Selectdf= weather_df[(weather_df['dewp'].apply(lambda x:x>=30 and x<=60))]\n# Selectdwep\ncrs={'init': 'epsg:4326'}\ngeom_Selectdf= [Point(xy) for xy in zip(Selectdf['lon'], Selectdf['lat'])]\ngeo_Selectdf= gpd.GeoDataFrame(Selectdf, crs=crs, geometry= geom_Selectdf) #the one with critical dewpoint\n\ngeom= [Point(xy) for xy in zip(weather_df['lon'], weather_df['lat'])]\ngeo_df= gpd.GeoDataFrame(weather_df, crs=crs, geometry= geom)\n\nfig, ax= plt.subplots(figsize = (15,15))\ngeo_df.plot(ax= ax, markersize=20, color= 'b', marker= \"o\")\ngeo_Selectdf.plot(ax= ax, markersize=20, color= 'r', marker= \"o\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **This visualization includes all the Covid locations worldwide that have a dew point between 30 and 60 °F.**\n\n> **If planning a vacation (when the travel ban is relieved), take into account this visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Selectdewp= weather_PerDay2[(weather_PerDay2['dewp'].apply(lambda x:x>=30 and x<=60))]\n# Selectdwep\n\ngeom_Selectdewp= [Point(xy) for xy in zip(Selectdewp['lon'], Selectdewp['lat'])]\ngeo_Selectdewp= gpd.GeoDataFrame(Selectdewp, crs=crs, geometry= geom_Selectdewp) #the one with critical dewpoint\n\ngeom= [Point(xy) for xy in zip(weather_PerDay2['lon'], weather_PerDay2['lat'])]\ngeo_df= gpd.GeoDataFrame(weather_PerDay2, crs=crs, geometry= geom) #all dataset\n\n\nfig, ax= plt.subplots(figsize = (15,15))\ngeo_df.plot(ax= ax, markersize=20, color= 'b', marker= \"o\")\ngeo_Selectdewp.plot(ax= ax, markersize=20, color= 'r', marker= \"o\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ** Let's tune some hyperparameters using GridSearch**"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = [{ \"n_estimators\": [9, 10] , \"max_features\" : [7, 10]}]\n        \nscore='neg_mean_squared_error'\n   \nclassifier= RandomForestRegressor()\ngridsearch = GridSearchCV(classifier,param_grid, scoring = score, cv = 5)\nmy_model= gridsearch.fit(X_train_scaled, y_train_full)\ncv_results= gridsearch.cv_results_\nfor mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n    print(np.sqrt(-mean_score), params)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= my_model.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_test, y_pred)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Also with these hyperparameters tuning the mean_squared_error is similar to the one above**"},{"metadata":{},"cell_type":"markdown","source":" "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}