{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Visualization of some Additional Statistics\nThis kernel is based on: \n- https://www.kaggle.com/jasonbenner/lets-try-xgboost-simple\n- https://www.kaggle.com/abhinand05/covid-19-digging-a-bit-deeper\n"},{"metadata":{},"cell_type":"markdown","source":"Compared to the aforementioned kernels, in this one we wish to especially inspect the following features:\n- Infections and fatalities worldwide\n- Normalized Infection ratio and death per infection ratio\n- ICU beds per 1000 People by Country\n- Temperature Data\n- Restrictive Measures\n\nFinally we wish to train a Random Forest Regressor with the following features:\n- Population Density\n- Fertility Rate\n- Median Age\n- ICU beds per 1000 People\n- Infection Ratio\n- Urban Percentage\n- Temperature\n- Humidity\n- Hours of Sunlight\n- Wind Speed"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\n\nfrom pathlib import Path\ndata_dir = Path('../input/covid19-global-forecasting-week-1')\n\nimport os\nos.listdir(data_dir)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the cleaned data from https://www.kaggle.com/imdevskp/corona-virus-report."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cleaned_data = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv', parse_dates=['Date'])\n\ncleaned_data.rename(columns={'ObservationDate': 'date', \n                     'Province/State':'state',\n                     'Country/Region':'country',\n                     'Last Update':'last_updated',\n                     'Confirmed': 'confirmed',\n                     'Deaths':'deaths',\n                     'Recovered':'recovered'\n                    }, inplace=True)\n\n# cases \ncases = ['confirmed', 'deaths', 'recovered', 'active']\n\n# Active Case = confirmed - deaths - recovered\ncleaned_data['active'] = cleaned_data['confirmed'] - cleaned_data['deaths'] - cleaned_data['recovered']\n\n# replacing Mainland china with just China\ncleaned_data['country'] = cleaned_data['country'].replace('Mainland China', 'China')\n\n# filling missing values \ncleaned_data[['state']] = cleaned_data[['state']].fillna('')\ncleaned_data[cases] = cleaned_data[cases].fillna(0)\ncleaned_data.rename(columns={'Date':'date'}, inplace=True)\n\ndata = cleaned_data\n\ndisplay(data.head())\ndisplay(data.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the data is updated\nprint(\"External Data\")\nprint(f\"Earliest Entry: {data['date'].min()}\")\nprint(f\"Last Entry:     {data['date'].max()}\")\nprint(f\"Total Days:     {data['date'].max() - data['date'].min()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Infections and Fatalities Worldwide"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"group = data.groupby('date')['date', 'confirmed', 'deaths'].sum().reset_index()\n\nfig = px.line(group, x=\"date\", y=\"confirmed\", \n              title=\"Worldwide Confirmed Cases Over Time\")\n\nfig.show()\n\nfig = px.line(group, x=\"date\", y=\"deaths\", \n              title=\"Worldwide Deaths Over Time\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the two plots above we can see the number of infected and deceased people across the world."},{"metadata":{},"cell_type":"markdown","source":"## 2. Normalized Infection and Fatality Ratio\nWe wish to have a closer look at the infection and fatality ratio, when normalized by country population size. This will surely give us an interesting perspective as to which countries are doing better and which ones are not."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def p2f(x):\n    \"\"\"\n    Convert urban percentage to float\n    \"\"\"\n    try:\n        return float(x.strip('%'))/100\n    except:\n        return np.nan\n\ndef age2int(x):\n    \"\"\"\n    Convert Age to integer\n    \"\"\"\n    try:\n        return int(x)\n    except:\n        return np.nan\n\ndef fert2float(x):\n    \"\"\"\n    Convert Fertility Rate to float\n    \"\"\"\n    try:\n        return float(x)\n    except:\n        return np.nan\n\n\ncountries_df = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\", converters={'Urban Pop %':p2f,\n                                                                                                             'Fert. Rate':fert2float,\n                                                                                                             'Med. Age':age2int})\ncountries_df.rename(columns={'Country (or dependency)': 'country',\n                             'Population (2020)' : 'population',\n                             'Density (P/KmÂ²)' : 'density',\n                             'Fert. Rate' : 'fertility',\n                             'Med. Age' : \"age\",\n                             'Urban Pop %' : 'urban_percentage'}, inplace=True)\n\n\n\ncountries_df['country'] = countries_df['country'].replace('United States', 'US')\ncountries_df = countries_df[[\"country\", \"population\", \"density\", \"fertility\", \"age\", \"urban_percentage\"]]\n\ncountries_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(data, countries_df, on='country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cleaned_latest = data[data['date'] == max(data['date'])]\nflg = cleaned_latest.groupby('country')['confirmed', 'population'].agg({'confirmed':'sum', 'population':'mean'}).reset_index()\n\nflg['infectionRate'] = round((flg['confirmed']/flg['population'])*100, 5)\ntemp = flg[flg['confirmed']>100]\ntemp = temp.sort_values('infectionRate', ascending=False)\n\nfig = px.bar(temp.sort_values(by=\"infectionRate\", ascending=False)[:10][::-1],\n             x = 'infectionRate', y = 'country', \n             title='% of infected people by country', text='infectionRate', height=800, orientation='h',\n             color_discrete_sequence=['red']\n            )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now this is interesting, because we can clearly see here in which countries the virus has infected most people.\nIt can clearly be seen that countries with a small population, such as San Marino, Andorra, Luxembourg and Switzerland have a relatively high percentage of infection ratio. Nonetheless, the infection percentage is still relatively low below 0.5%.\n\nLet's have a closer look at the World map of the normalized infection ratio by population:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"formated_gdf = data.groupby(['date', 'country'])['confirmed', 'population'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['date'] = pd.to_datetime(formated_gdf['date'])\nformated_gdf['date'] = formated_gdf['date'].dt.strftime('%m/%d/%Y')\nformated_gdf['infectionRate'] = round((formated_gdf['confirmed']/formated_gdf['population'])*100, 8)\n\nfig = px.scatter_geo(formated_gdf, locations=\"country\", locationmode='country names', \n                     color=\"infectionRate\", size='infectionRate', hover_name=\"country\", \n                     range_color= [0, 0.2], \n                     projection=\"natural earth\", animation_frame=\"date\", \n                     title='COVID-19: Spread Over Time (Normalized by Country Population)', color_continuous_scale=\"portland\")\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cleaned_latest = data[data['date'] == max(data['date'])]\nflg = cleaned_latest.groupby('country')['confirmed', 'deaths', 'recovered', 'active'].sum().reset_index()\n\nflg['mortalityRate'] = round((flg['deaths']/flg['confirmed'])*100, 2)\ntemp = flg[flg['confirmed']>100]\ntemp = temp.sort_values('mortalityRate', ascending=False)\n\nfig = px.bar(temp.sort_values(by=\"mortalityRate\", ascending=False)[:10][::-1],\n             x = 'mortalityRate', y = 'country', \n             title='Deaths per 100 Confirmed Cases', text='mortalityRate', height=800, orientation='h',\n             color_discrete_sequence=['darkred']\n            )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, let's have a look at the evolution of mortality rate."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"formated_gdf = data.groupby(['date', 'country'])['confirmed', 'deaths'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['date'] = pd.to_datetime(formated_gdf['date'])\nformated_gdf['date'] = formated_gdf['date'].dt.strftime('%m/%d/%Y')\nformated_gdf['mortalityRate'] = round((formated_gdf['deaths']/formated_gdf['confirmed'])*100, 2)\n\nfig = px.scatter_geo(formated_gdf.fillna(0), locations=\"country\", locationmode='country names', \n                     color=\"mortalityRate\", size='mortalityRate', hover_name=\"country\", \n                     range_color= [0, 10], \n                     projection=\"natural earth\", animation_frame=\"date\", \n                     title='COVID-19: Mortality Rate in % by country', color_continuous_scale=\"portland\")\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. ICU Beds per Country\nWe wish to further inspect the ratio of ICU beds per 1000 people that every country has readily available. Therefore we load the dataset from: https://www.kaggle.com/hamzael1/hospital-beds-by-country"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"icu_df = pd.read_csv(\"../input/hospital-beds-by-country/API_SH.MED.BEDS.ZS_DS2_en_csv_v2_887506.csv\")\nicu_df['Country Name'] = icu_df['Country Name'].replace('United States', 'US')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Russian Federation', 'Russia')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Iran, Islamic Rep.', 'Iran')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Egypt, Arab Rep.', 'Egypt')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Venezuela, RB', 'Venezuela')\ndata['country'] = data['country'].replace('Czechia', 'Czech Republic')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# We wish to have the most recent values, thus we need to go through every year and extract the most recent one, if it exists.\nicu_cleaned = pd.DataFrame()\nicu_cleaned[\"country\"] = icu_df[\"Country Name\"]\nicu_cleaned[\"icu\"] = np.nan\n\nfor year in range(1960, 2020):\n    year_df = icu_df[str(year)].dropna()\n    icu_cleaned[\"icu\"].loc[year_df.index] = year_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(data, icu_cleaned, on='country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data['state'] = data['state'].fillna('')\ntemp = data[[col for col in data.columns if col != 'state']]\n\nlatest = temp[temp['date'] == max(temp['date'])].reset_index()\nlatest_grouped = latest.groupby('country')['icu'].mean().reset_index()\n\n\nfig = px.bar(latest_grouped.sort_values('icu', ascending=False)[:10][::-1], \n             x='icu', y='country',\n             title='Ratio of ICU Beds per 1000 People', text='icu', orientation='h',color_discrete_sequence=['green'] )\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.choropleth(latest_grouped, locations=\"country\", \n                    locationmode='country names', color=\"icu\", \n                    hover_name=\"country\", range_color=[1,15], \n                    color_continuous_scale=\"algae\", \n                    title='Ratio of ICU beds per 1000 people')\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the interactive plot above we can see that with the latest data, Greenland, Monaco, and Japan are leading in the number of ICU beds per 1000 people. Of the developed countries, this might be one of the key factors why Japan is currently handling the situation better than others."},{"metadata":{},"cell_type":"markdown","source":"## 4. Temperature Data\nIn our next step, we wish to analyze the weather and temperature data of the respective countries since the outbreak of the virus. We have composed a dataset here: https://www.kaggle.com/winterpierre91/covid19-global-weather-data\n\nWe hope to find some colleration between certain weather metrics and the speed of the number of infections/deaths."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_temperature = pd.read_csv(\"../input/covid19-global-weather-data/temperature_dataframe.csv\")\ndf_temperature['country'] = df_temperature['country'].replace('USA', 'US')\ndf_temperature['country'] = df_temperature['country'].replace('UK', 'United Kingdom')\ndf_temperature = df_temperature[[\"country\", \"province\", \"date\", \"humidity\", \"sunHour\", \"tempC\", \"windspeedKmph\"]].reset_index()\ndf_temperature.rename(columns={'province': 'state'}, inplace=True)\ndf_temperature[\"date\"] = pd.to_datetime(df_temperature['date'])\ndf_temperature['state'] = df_temperature['state'].fillna('')\n\n\ndf_temperature.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.merge(df_temperature, on=['country','date', 'state'], how='inner')\ndata.to_csv(\"countries_icu_temp.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression Model\nBy implementing a regression model which tries to use the country input variables to predict the most recent number of infections and deaths as target, we can extract the relative feature importance. This can be done pretty well with a Random Forest Regressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = data\nprint(train_data.shape)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(We only wish to have a look at countries which already have an infection ratio higher than 0, because the ones that aren't infected yet, might bias the feature importance)"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0\ntrain_data['infectionRate'] = round((train_data['confirmed']/train_data['population'])*100, 5)\ntrain_data = train_data[train_data['infectionRate'] >= threshold]\nprint(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop([\n                     \"country\", \n                     \"active\", \n                     \"recovered\", \n                     \"infectionRate\",\n                     \"state\",\n                     \"Lat\",\n                     \"Long\",\n                     \"date\",\n                     \"index\"\n                    ], axis= 1).dropna()\n\ny = train_data[[\"confirmed\", \"deaths\"]]\nX = train_data.drop([\"confirmed\", \"deaths\"],axis=1)\n\ndisplay(X.head())\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncm = train_data.corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train and Evaluate Model (Random Forest)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n#X_scaled = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Split into training and evaluation data:\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\ndef rmsle(y_true, y_pred):\n    \"\"\"\n    Computes the Root Mean Squared Logarithmic Error of a prediction set.\n    params:\n        y_true: numpy array of ground truth\n        y_pred: numpy array of predictions\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n\nrmsle_scorer = make_scorer(rmsle)\n\nX_train, X_val, y_train, y_val = tts(X, y, test_size= 0.2, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_infected = DecisionTreeRegressor(random_state=42, criterion=\"mae\")\n\nscores = cross_val_score(model_infected, \n                      X_train,\n                      y_train[\"confirmed\"],\n                      cv=5, scoring=rmsle_scorer)\n\nprint(\"Cross Validation of Confirmed Cases: Mean = {}, std = {}\".format(scores.mean(), scores.std()))\nmodel_infected.fit(X_train, y_train[\"confirmed\"])\nresult_infected = rmsle(y_val[\"confirmed\"], model_infected.predict(X_val))\nprint(\"Validation Infected set RMSLE: {}\".format(result_infected))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_deaths = DecisionTreeRegressor(random_state=42, criterion=\"mae\")\n\nscores = cross_val_score(model_deaths, \n                      X_train,\n                      y_train[\"deaths\"],\n                      cv=5, scoring=rmsle_scorer)\n\nprint(\"Cross Validation of Fatal Cases: Mean = {}, std = {}\".format(scores.mean(), scores.std()))\nmodel_deaths.fit(X_train, y_train[\"deaths\"])\nresult_deaths = rmsle(y_val[\"deaths\"], model_deaths.predict(X_val))\nprint(\"Validation Death set RMSLE: {}\".format(result_deaths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final Evalutation\nprint(\"Final Validatio score: {}\".format(np.mean([result_infected, result_deaths])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Extract Features for Infections"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_infected = model_infected.fit(X, y[\"confirmed\"])\nmodel_deaths = model_deaths.fit(X, y[\"deaths\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_feature_importance(forest):\n    \"\"\"\n    Creates a sorted list of the feature importance of a decision tree algorithm.\n    Furthermore it plots it.\n    params:\n        forest: Decision Tree algorithm\n    \"\"\"\n    importances = forest.feature_importances_\n    indices = np.argsort(importances)[::-1]\n\n    # Print the feature ranking\n    print(\"Feature ranking:\")\n\n    for f in range(X.shape[1]):\n        print(\"{}, Feature: {}, Importance: {}\".format(f + 1, X.columns[indices[f]], importances[indices[f]]))\n\n    # Plot the feature importances of the forest\n    plt.figure(figsize=(20,10))\n    plt.title(\"Feature importances\")\n    plt.bar(range(X.shape[1]), importances[indices], color=\"r\", align=\"center\")\n    plt.xticks(range(X.shape[1]),  X.columns[indices], rotation='vertical')\n    plt.xlim([-1, X.shape[1]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_feature_importance(model_infected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above we can see that many variables are positively correlated to the number of COVID19 infections such as: temperature, hours of sunlight, population, wind speed, humidity, and age. \n\nThese variables should be analyzed carefully as they are not necessaril causal. In terms of population for example, the more people there are in a country, the more likely they are to get infected.\nAlso, is it possible, that older people are more likely to be infected? Maybe they are also more likely to be tested, and hence confirmed.\nWeather conditions can help the virus to spread faster, such as temperature and humidity. It could be that the more hours of sunlight in a country, the more that people will want to be out and interact with social groups.\nThe percentage of people living in an urban area also has some importance because it signifies a higher density of people, making it easier to transmit the virus."},{"metadata":{},"cell_type":"markdown","source":"## Extract Features for Deaths"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_feature_importance(model_deaths)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When inspecting the mortality, it appears as if weather conditions are more important than factors such as population, age, and urban percentage. Of course the standard deviation of prediction error should be taken into account, but from this data we can conclude that temperature and humidity are important features for predicting COVID19 mortality.\n\nFurthermore, with the current regression model, it does not seem that ICU beds per 1000 people are as important as expected."},{"metadata":{},"cell_type":"markdown","source":"## Create Submission\nThe test set for this week is from the 12th of March until the 23rd of April."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/covid19-global-forecasting-week-1/test.csv\")\ntest_df.rename(columns={'Date': 'date', \n                     'Province/State':'state',\n                     'Country/Region':'country',\n                    }, inplace=True)\ntest_df[\"date\"] = pd.to_datetime(test_df['date'])\ntest_df['state'] = test_df['state'].fillna('')\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_df = test_df.merge(df_temperature, on=['country','date', 'state'], how='left')\ntest_df = test_df.merge(countries_df, on=['country'], how='left')\ntest_df = test_df.merge(icu_cleaned, on=['country'], how='left')\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df.set_index(\"ForecastId\").drop([\"Lat\", \"Long\", \"date\", \"state\", \"country\", \"index\"], axis=1).fillna(0)\n#X_test = scaler.fit_transform(X_test)\ny_pred_confirmed = model_infected.predict(X_test)\ny_pred_deaths = model_deaths.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"ForecastId\"] = test_df[\"ForecastId\"]\nsubmission = submission.set_index(['ForecastId'])\nsubmission[\"ConfirmedCases\"] = y_pred_confirmed.astype(int)\nsubmission[\"Fatalities\"] = y_pred_deaths.astype(int)\nsubmission.to_csv(\"submission.csv\")\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis\nLet's now look into a time series analysis of the issue using Prophet and using the log of the confirmed cases in Italy as an example."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nm = Prophet()\nitaly_data = data[data['country']=='Italy']\nts_df = pd.concat([italy_data['date'], np.log(italy_data['confirmed']+1)], axis=1, keys=['ds', 'y'])\nts_df.head()\nm.fit(ts_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future = m.make_future_dataframe(periods=14)\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(m, forecast)  # This returns a plotly Figure\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = data\nts_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df['infectionRate'] = round((ts_df['confirmed']/ts_df['population'])*100, 5)\nts_df = ts_df[ts_df['infectionRate'] >= threshold]\nts_df.index = ts_df.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = ts_df.drop([\n                     \"country\", \n                     \"active\", \n                     \"recovered\", \n                     \"infectionRate\",\n                     \"state\",\n                     \"date\",\n                     \"Lat\",\n                     \"Long\",\n                     \"population\",\n                     \"density\",\n                     \"fertility\",\n                     \"age\",\n                     \"urban_percentage\",\n                     \"icu\",\n                     \"index\"\n                    ], axis= 1).dropna()\n\n#y = train_data[[\"confirmed\", \"deaths\"]]\n#X = train_data.drop([\"confirmed\", \"deaths\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = ts_df[:60]\nts_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_percentage = 0.75","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = ts_df[:int(train_percentage*(len(ts_df)))]\nvalid = ts_df[int((1-train_percentage)*(len(ts_df))):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.vector_ar.var_model import VAR\nmodel = VAR(endog=train)\nmodel_fit = model.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model_fit.forecast(model_fit.y, steps=len(valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(index=range(0,len(prediction)),columns=ts_df.columns)\nfor j in range(0,prediction.shape[1]):\n    for i in range(0, len(prediction)):\n        pred.iloc[i][j] = prediction[i][j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ts_df.columns:\n    print('rmse value for', i, 'is : ', np.sqrt(mean_squared_error(pred[i], valid[i])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_to_predict = 14\nfuture_dt = pd.date_range(ts_df.last_valid_index(), periods=days_to_predict)\n\nmodel = VAR(endog=ts_df)\nmodel_fit = model.fit()\nyhat = model_fit.forecast(model_fit.y, steps=days_to_predict)\n\npred_df = pd.DataFrame(yhat, columns=ts_df.columns)\npred_df = pred_df.drop([\n                     \"humidity\", \n                     \"sunHour\", \n                     \"tempC\", \n                     \"windspeedKmph\"\n                    ], axis=1)\npred_df['confirmed'] = pred_df['confirmed'].astype(int)\npred_df['deaths'] = pred_df['deaths'].astype(int)\npred_df.index = future_dt\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to see if we can actually use the time series temperature data to find time-related insights. To do this we are looking into multivariate time series regression tools such as Vector Auto Regression (VAR)..."},{"metadata":{},"cell_type":"markdown","source":"# Thanks!\nIf you like this kernel, give us an upvote :)\nStay healthy, you beautiful people!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}