{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport datetime\nimport tensorflow as tf\nimport math\ndata_dir = \"/kaggle/input/covid19-global-forecasting-week-1/\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T22:13:15.387568Z","iopub.execute_input":"2021-09-09T22:13:15.388405Z","iopub.status.idle":"2021-09-09T22:13:22.303324Z","shell.execute_reply.started":"2021-09-09T22:13:15.38829Z","shell.execute_reply":"2021-09-09T22:13:22.301948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_raw = pd.read_csv(data_dir+\"train.csv\")\ntest_df_raw = pd.read_csv(data_dir+\"test.csv\")\nall_df = train_df_raw\ntest_df = test_df_raw\nmaxlen = 30\nhidden_number = 32\ninput_number = 5\noutput_number = 2\nbatch_size = 32\nepochs = 50\nlr = 0.001\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:13:22.305209Z","iopub.execute_input":"2021-09-09T22:13:22.305555Z","iopub.status.idle":"2021-09-09T22:13:22.384158Z","shell.execute_reply.started":"2021-09-09T22:13:22.305521Z","shell.execute_reply":"2021-09-09T22:13:22.383044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_datetime(date):\n    return (date - datetime.datetime.strptime('2020-01-22', \"%Y-%m-%d\")).days\n\ndef to_datetime(date):\n    return datetime.datetime.strptime(date, \"%Y-%m-%d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:13:22.386334Z","iopub.execute_input":"2021-09-09T22:13:22.386698Z","iopub.status.idle":"2021-09-09T22:13:22.392632Z","shell.execute_reply.started":"2021-09-09T22:13:22.38665Z","shell.execute_reply":"2021-09-09T22:13:22.39144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.fillna({\"Province/State\": \"NAN\"})\nall_df = all_df.fillna({\"Province/State\": \"NAN\"})\n\nall_df[\"ConfirmedCases\"] = (all_df[\"ConfirmedCases\"] + 1).map(math.log10)\ncases_max = all_df[\"ConfirmedCases\"].max()\nfatal_max = all_df[\"Fatalities\"].max()\n\nall_df[\"Lat\"] = all_df[\"Lat\"]/180.\nall_df[\"Long\"] = all_df[\"Long\"]/180.\nall_df[\"ConfirmedCases\"] = all_df[\"ConfirmedCases\"] / cases_max\nall_df[\"Fatalities\"] = all_df[\"Fatalities\"] / fatal_max\n\nall_df[\"Date\"] = all_df[\"Date\"].map(to_datetime)\nall_df[\"Date_num\"] = all_df[\"Date\"].map(map_datetime)\ndate_max = all_df[\"Date_num\"].max()\nall_df[\"Date_num\"] = all_df[\"Date_num\"] / date_max\n\ndate_unit = all_df.iloc[1][\"Date_num\"] - all_df.iloc[0][\"Date_num\"]\n\nval_df = all_df[all_df[\"Date\"] > (all_df[\"Date\"].max() - datetime.timedelta(days=(maxlen+1)))]\ntrain_df = all_df.drop(all_df[all_df[\"Date_num\"] == all_df[\"Date_num\"].max()].index)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:13:22.394683Z","iopub.execute_input":"2021-09-09T22:13:22.395081Z","iopub.status.idle":"2021-09-09T22:13:23.363295Z","shell.execute_reply.started":"2021-09-09T22:13:22.395046Z","shell.execute_reply":"2021-09-09T22:13:23.362063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"Lat\"] = test_df[\"Lat\"]/180.\ntest_df[\"Long\"] = test_df[\"Long\"]/180.\ntest_df[\"Date\"] = test_df[\"Date\"].map(to_datetime)\ntest_df[\"Date_num\"] = test_df[\"Date\"].map(map_datetime)\ntest_df[\"Date_num\"] = test_df[\"Date_num\"] / date_max","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:13:23.364881Z","iopub.execute_input":"2021-09-09T22:13:23.365223Z","iopub.status.idle":"2021-09-09T22:13:23.980871Z","shell.execute_reply.started":"2021-09-09T22:13:23.36519Z","shell.execute_reply":"2021-09-09T22:13:23.979826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_sequences(train_df):\n    inputs = []\n    targets = []\n    for i in range(len(train_df) - maxlen - 1):\n        if train_df.iloc[i][\"Lat\"] == train_df.iloc[i+maxlen][\"Lat\"] and \\\n           train_df.iloc[i][\"Long\"] == train_df.iloc[i+maxlen][\"Long\"]:\n            inputs.append(np.array(train_df.iloc[i:i+maxlen][[\"Date_num\", \"Lat\", \"Long\", \"ConfirmedCases\", \"Fatalities\"]]).tolist())\n            targets.append(np.array(train_df.iloc[i+maxlen][[\"ConfirmedCases\", \"Fatalities\"]]).tolist())\n    return inputs, targets\n\ntrain_inputs, train_targets = make_sequences(train_df)\nval_inputs, val_targets = make_sequences(val_df)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:13:23.982283Z","iopub.execute_input":"2021-09-09T22:13:23.982611Z","iopub.status.idle":"2021-09-09T22:13:54.932999Z","shell.execute_reply.started":"2021-09-09T22:13:23.982568Z","shell.execute_reply":"2021-09-09T22:13:54.931894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(hidden_number, batch_input_shape=[None, maxlen, input_number], return_sequences=True))\nmodel.add(tf.keras.layers.LSTM(hidden_number))\nmodel.add(tf.keras.layers.Dense(output_number, activation=\"sigmoid\"))\n\noptimizer = tf.keras.optimizers.Adam(lr=lr)\nmodel.compile(loss=\"mean_squared_error\", optimizer=optimizer)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=5)\nhistory = model.fit(train_inputs, train_targets,\n                    batch_size=batch_size,\n                      epochs=epochs,\n                      validation_data=(val_inputs, val_targets),\n                      callbacks = [early_stopping]\n                      )","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:13:54.93444Z","iopub.execute_input":"2021-09-09T22:13:54.934806Z","iopub.status.idle":"2021-09-09T22:19:12.948528Z","shell.execute_reply.started":"2021-09-09T22:13:54.93477Z","shell.execute_reply":"2021-09-09T22:19:12.947101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nfor idx in test_df.groupby([\"Province/State\", \"Country/Region\"]).count().index:\n    test_df_on_idx = test_df[(test_df[\"Province/State\"] == idx[0]) &\n                             (test_df[\"Country/Region\"] == idx[1])]\n    train_df_on_idx = train_df[(all_df[\"Country/Region\"] == idx[1]) &\n                               (all_df[\"Province/State\"] == idx[0])]\n    inputs = np.array(train_df_on_idx[[\"Date_num\", \"Lat\", \"Long\", \"ConfirmedCases\", \"Fatalities\"]])[-maxlen:]\n    inputs = inputs.reshape(maxlen, input_number)\n    for day in range(43):\n        if int(1000000000*(datetime.timedelta(days=day) + test_df_on_idx[\"Date\"].min()).timestamp()) in train_df_on_idx[\"Date\"].values.tolist():\n            result = np.array(train_df_on_idx[train_df_on_idx[\"Date\"] == (datetime.timedelta(days=day) + test_df_on_idx[\"Date\"].min())][[\"Date\", \"Lat\", \"Long\", \"ConfirmedCases\", \"Fatalities\"]])[0, 3:]\n        else:\n            result = model.predict(np.array(inputs).reshape(1, maxlen, input_number)).reshape(-1)\n            inputs = np.concatenate((inputs[1:], np.append(inputs[-1, :3], result).reshape(1, input_number)), axis=0)\n        results.append([10**(result[0]*cases_max), result[1]*fatal_max])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:19:12.951892Z","iopub.execute_input":"2021-09-09T22:19:12.95235Z","iopub.status.idle":"2021-09-09T22:26:37.788455Z","shell.execute_reply.started":"2021-09-09T22:19:12.952303Z","shell.execute_reply":"2021-09-09T22:26:37.78717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df = pd.read_csv(data_dir+\"submission.csv\", index_col=0)\nsubmit_df","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:26:37.790256Z","iopub.execute_input":"2021-09-09T22:26:37.790582Z","iopub.status.idle":"2021-09-09T22:26:37.827056Z","shell.execute_reply.started":"2021-09-09T22:26:37.790552Z","shell.execute_reply":"2021-09-09T22:26:37.825832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cases = []\nfatals = []\nfor i in range(len(results)):\n    n = results[i][0] \n    f = results[i][1]\n    try:\n        cases.append(int(n))\n    except:\n        cases.append(0)\n    \n    try:\n        fatals.append(int(f))\n    except:\n        fatals.append(0)\nsubmit_df[\"ConfirmedCases\"] = cases\nsubmit_df[\"Fatalities\"] = fatals\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:26:37.82854Z","iopub.execute_input":"2021-09-09T22:26:37.828876Z","iopub.status.idle":"2021-09-09T22:26:37.866049Z","shell.execute_reply.started":"2021-09-09T22:26:37.828843Z","shell.execute_reply":"2021-09-09T22:26:37.864891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:26:37.867795Z","iopub.execute_input":"2021-09-09T22:26:37.868176Z","iopub.status.idle":"2021-09-09T22:26:37.907989Z","shell.execute_reply.started":"2021-09-09T22:26:37.868139Z","shell.execute_reply":"2021-09-09T22:26:37.906827Z"},"trusted":true},"execution_count":null,"outputs":[]}]}