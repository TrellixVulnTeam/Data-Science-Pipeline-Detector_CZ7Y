{"cells":[{"metadata":{"_uuid":"66f86116d95d6ab19d5221468af20dad9c2b3f91"},"cell_type":"markdown","source":"# Tabular models"},{"metadata":{"trusted":true,"_uuid":"be215bbbf440c26b35a770cc34d0a8422965673d"},"cell_type":"code","source":"from fastai.tabular import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input/covid19-global-forecasting-week-1/')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/submission.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check data"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data prep"},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge test set and training set and rename, som columns\nFull_data = pd.merge(test, train, on=['Lat','Long','Date','Country/Region','Province/State'])\nFull_data.rename(columns={'Province/State':'Province'}, inplace=True)\nFull_data.rename(columns={'Country/Region':'Country'}, inplace=True)\nFull_data.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)\nFull_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Full_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the above merge an not be used since the data set went from about 17600 to 3400 and the submission samle is about 12000"},{"metadata":{"trusted":true},"cell_type":"code","source":"#rename therefor the data columns\ntrain.rename(columns={'Province/State':'Province'}, inplace=True)\ntrain.rename(columns={'Country/Region':'Country'}, inplace=True)\ntrain.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#and we do the same for test set\ntest.rename(columns={'Province/State':'Province'}, inplace=True)\ntest.rename(columns={'Country/Region':'Country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label encoding\nlabel encode Date and country"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# creating initial dataframe\nbridge_types = ('Lat', 'Date', 'Province', 'Country', 'Long', 'Confirmed',\n       'ForecastId', 'Id')\ncountries = pd.DataFrame(train, columns=['Country'])\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ntrain['Countries'] = labelencoder.fit_transform(train['Country'])\ntrain['Countries'].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling dates "},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Date\"] = train[\"Date\"].apply(lambda x: x.replace(\"-\",\"\"))\ntrain[\"Date\"]  = train[\"Date\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#do the same for test set\ntest['Countries'] = labelencoder.fit_transform(test['Country'])\n\ntest[\"Date\"] = test[\"Date\"].apply(lambda x: x.replace(\"-\",\"\"))\ntest[\"Date\"]  = test[\"Date\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop useless columns for train and test set\ntrain.drop(['Country'], axis=1, inplace=True)\ntrain.drop(['Province'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['Country'], axis=1, inplace=True)\ntest.drop(['Province'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#slpit the data set in to from the merge dataframe called Full_data\ntrain_procent=int(((len(Full_data))/100)*50)\ntest_procent=int(((len(Full_data))/100)*50)\n\ntrain_df=Full_data.loc[train_procent:]\ntest_df=Full_data.loc[:test_procent]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train part 1\nSome of the above code was to try to merge data from to csv files. but this cant be used for submission, so we just to a few features in the submission section. but it gives a good idea of what model will predict well."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = train_df.copy()\nX_test_full = test_df.copy()\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['Fatalities'], inplace=True)\ny = X.Fatalities              \nX.drop(['Fatalities'], axis=1, inplace=True)\n   \n    \n    # Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n### for cname (every value, one at the time) in dataframe for columns return a value to 'numeric_cols' if the \n### dtype= int64 or float64. \n\n\n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# training models and predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom xgboost import XGBRegressor\n\n\n\nmodel2 = RandomForestClassifier(n_estimators=150, max_depth=4, random_state=1)\nmodel = GradientBoostingClassifier(random_state=1)\nmodel3 = DecisionTreeClassifier(random_state=1)\n#model=SGDClassifier(random_state=1)\n#model=ExtraTreesClassifier(random_state=1)\nmodel = XGBRegressor()\n# Define the models\nmodel_1 = RandomForestClassifier(n_estimators=50, random_state=0)\nmodel_2 = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel_3 = RandomForestClassifier(n_estimators=200, min_samples_split=20, random_state=0)\nmodel_4 = RandomForestClassifier(n_estimators=300, max_depth=6, random_state=1)\n\n\n\nmodel.fit(X_train, y_train)\ny_predictions = model.predict(X_valid)\n\nprint('model accuracy score',model.score(X_valid,y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=y_valid\nX_test=X_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model2.score(X_test, y_test)*100:.3f}%')\nmodel3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model3.score(X_test, y_test)*100:.3f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_1.score(X_test, y_test)*100:.3f}%')\nmodel_2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_2.score(X_test, y_test)*100:.3f}%')\nmodel_3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_3.score(X_test, y_test)*100:.3f}%')\nmodel_4.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_4.score(X_test, y_test)*100:.3f}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor  \nregressor = DecisionTreeRegressor(random_state = 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train part 2, start over for having enought rows for the submussion\nx = train[['Lat', 'Long', 'Date','Countries']]\ny1 = train[['Confirmed']]\ny2 = train[['Fatalities']]\nx_test = test[['Lat', 'Long', 'Date','Countries']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n# y1=np.ravel(y1)\n# y1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.fit(x,y1)\npredict_1 = regressor.predict(x_test)\npredict_1 = pd.DataFrame(predict_1)\npredict_1.columns = [\"Confirmed_predict\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y2=np.ravel(y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.fit(x,y2)\npredict_2 = regressor.predict(x_test)\npredict_2 = pd.DataFrame(predict_2)\npredict_2.columns = [\"Death_prediction\"]\npredict_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Samle_submission = pd.read_csv(\"../input/covid19-global-forecasting-week-1/submission.csv\")\nSamle_submission.columns\nsubmission = Samle_submission[[\"ForecastId\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission = pd.concat([predict_1,predict_2,submission],axis=1)\nFinal_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.columns = ['ConfirmedCases', 'Fatalities', 'ForecastId']\nFinal_submission = Final_submission[['ForecastId','ConfirmedCases', 'Fatalities']]\n\nFinal_submission[\"ConfirmedCases\"] = Final_submission[\"ConfirmedCases\"].astype(int)\nFinal_submission[\"Fatalities\"] = Final_submission[\"Fatalities\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.to_csv(\"submission.csv\",index=False)\nprint('Model ready for submission!')\n\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/test.csv\")\ncomplete_test= pd.merge(test, Final_submission, how=\"left\", on=\"ForecastId\")\ncomplete_test.to_csv('complete_test.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Below code is for later use, when I get the API block to work!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# procs = [FillMissing, Categorify, Normalize]\n\n# dep_var = 'Fatalities'\n# cat_names = ['Country', 'Province']\n# cont_names = ['Long','Lat', 'ForecastId']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = (TabularList.from_df(train_df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n#         .random_split_by_pct(0.2, seed=42)\n#         .label_from_df(cols=dep_var)\n#         .add_test(test_df)\n#         .databunch()\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.show_batch(rows=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# data = (TabularList.from_df(train_df, procs=procs, cont_names=cont_names, cat_names=cat_names)\n#         .split_by_idx(valid_idx=range(int(len(train_df)*0.9),len(train_df)))\n#         .label_from_df(cols=dep_var)\n#         .add_test(TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names, procs=procs))\n#         .databunch())\n# print(data.train_ds.cont_names)\n# print(data.train_ds.cat_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WE HAVE TO CHANGE ACC. se below reason and code\n\n# [quote=\"stephenjohnson, post:11, topic:33778\"]\n# targs stands for **t** arget **arg** ument **s** \n# It’s the values that are the truth values (the Y values) that are being compared to your model’s predicted values. \n# The accuracy metric above takes two arguments the input (predicted values) and targs (target values) and calculates the accuracy. \n# The error encountered above was due to the fact that the input had Long values but targs had Float values.\n# [/quote]\n\n\n# def accuracy_1(input:Tensor, targs:Tensor)->Rank0Tensor:\n# #     “Compute accuracy with targs when input is bs * n_classes.”\n#     targs = targs.view(-1).long()\n#     n = targs.shape[0]\n#     input = input.argmax(dim=-1).view(n,-1)\n#     targs = targs.view(n,-1)\n#     return (input==targs).float().mean()\n\n# # So use metrics=accuracy_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = tabular_learner(data, layers=[1000,500],metrics=accuracy,model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20b302ce2ac395f744b760cf52b4fefbe68ce92c"},"cell_type":"code","source":"#test = TabularList.from_df(train.iloc[800:1000].copy(), cat_names=cat_names, cont_names=cont_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92c39d61938b768ed9ac207379182212fc2d246"},"cell_type":"code","source":"#data = (TabularList.from_df(train, cat_names=cat_names, cont_names=cont_names, procs=procs)\n#                           .split_by_idx(list(range(800,1000)))\n#                           .label_from_df(cols=dep_var)\n#                           .add_test(X_test)\n#                           .databunch())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb4d5d03b2b7d665e6df4377407bf728e0cee136"},"cell_type":"code","source":"#data.show_batch(rows=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"096797a44057a297c7c143743a2fafad35d3d513"},"cell_type":"code","source":"#learn = tabular_learner(data, layers=[200,100], metrics=accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff857e6834b1a193c60791412ba0ce7f540fbc4"},"cell_type":"code","source":"# learn.fit(5, 1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.lr_find()\n# learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stop- learn.fit_one_cycle(20, slice(1e-3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aea275a859e6baebb3269812fffe039ebefd4cb1"},"cell_type":"markdown","source":"## Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"#output = pd.DataFrame({'id': sample_submission.id, 'target': y_predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n# pred_prob, pred_class = preds.max(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission = pd.DataFrame({'id':sample_submission['id'],'target':pred_class})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission-fastai.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.id = submission.id.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_submission = pd.read_csv('my_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3f527ca3315d0123a8bb31e11c7f69ec6bf9eb9"},"cell_type":"code","source":"#row = train.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2a752ee8bb0b3e6504091ca2246dbae631c0eaa"},"cell_type":"code","source":"#y_predictions=learn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_test['bin_0'].fillna(X_test['bin_0'].median(), inplace = True)\n# X_test['bin_1'].fillna(X_test['bin_1'].median(), inplace = True)\n# # X_test['bin_2'].fillna(X_test['bin_2'].median(), inplace = True)\n# X_test['ord_0'].fillna(X_test['ord_0'].median(), inplace = True)\n# X_test['day'].fillna(X_test['day'].median(), inplace = True)\n# X_test['month'].fillna(X_test['month'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#output.to_csv('my_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}