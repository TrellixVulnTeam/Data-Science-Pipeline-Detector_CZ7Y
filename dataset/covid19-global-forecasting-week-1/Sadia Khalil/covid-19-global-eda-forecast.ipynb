{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom itertools import cycle, islice\nimport seaborn as sb\nfrom matplotlib import dates\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets explore the input files, starting with training and testing files, and finally the required format/metadata for the submission file."},{"metadata":{},"cell_type":"markdown","source":"# Understanding the Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/train.csv\")#index_col=0\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loc[:, ['ConfirmedCases', 'Fatalities']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Data describes that maximum number of confirmed cases are 678800, and maximum number of fatalities are 6077."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/test.csv\")#index_col=0\ntest_data.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train = train_data.shape[0]\nn_train_col = train_data.shape[1]\nn_test = test_data.shape[0]\nn_test_col = test_data.shape[1]\nprint('number of training records:', n_train, ', number of columns:', n_train_col )\nprint('number of test records:', n_test, ', number of columns:', n_test_col )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are three main features as Province/State, Country/Region, and Date. The last two columns in training data are the observations, namely ConfirmedCases and Fatalities. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def getColumnInfo(df):\n    n_province =  df['Province/State'].nunique()\n    n_country  =  df['Country/Region'].nunique()\n    start_date =  df['Date'].unique()[0]\n    end_date   =  df['Date'].unique()[-1]\n    return n_province, n_country, start_date, end_date\n\nn_prov_train, n_count_train, start_date_train, end_date_train = getColumnInfo(train_data)\nn_prov_test,  n_count_test,  start_date_test,  end_date_test  = getColumnInfo(test_data)\n\nprint ('<=== Training data ===> \\n# of Province/State: '+str(n_prov_train),', # of Country/Region:'+str(n_count_train),', Time Period: '+start_date_train+' to '+end_date_train)\nprint ('<=== Testing  data ===> \\n# of Province/State: '+str(n_prov_test),', # of Country/Region:'+str(n_count_test),', Time Period: '+start_date_test+' to '+end_date_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The competition will end by 2020-03-25, meaning by then we will have an overlap of 14 days of training and test data. The predictions should start from 2020-03-26. "},{"metadata":{},"cell_type":"markdown","source":"## A look at the training data records\n\nLets have a look at the available record entries of Confirmed Cases and Fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_masked(threshold, df):\n    mask = df > threshold\n    tail_prob = df.loc[~mask].sum()\n    df = df.loc[mask]\n    df['all other'] = tail_prob\n    return df\n\ndef get_frequency_plot(df, ax, xlabel, title, color):\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel('Normalized Frequency')\n    ax.set_title(title)\n    df_mask = df_masked(0.01, df)\n    df_mask.plot(kind='bar', color=color)\n    plt.xticks(rotation=25)\n    xlocs, xlabs = plt.xticks()\n    for i, v in enumerate(df_mask):\n         plt.text(xlocs[i] - 0.255, v+0.01, str(round(v,2)))\n\n###############            \nprob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\nprob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\nplt.rcParams.update({'font.size': 16})\nfig = plt.figure(figsize=(15,5))\nax0 = fig.add_subplot(1,2,1)\nget_frequency_plot(prob_confirm_check_train, ax0, 'Number of Confirmed Cases', 'Confirmed Cases Record', 'orange')\nax1 = fig.add_subplot(1,2,2)\nget_frequency_plot(prob_fatal_check_train, ax1, 'Number of Fatalities', 'Fatalities Record','red')\n\nplt.show()\n\nn_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\nn_fatal_train = train_data.Fatalities.value_counts()[1:].sum()\n\nprint('=== Confirmed Cases in Training Dataset ===')\nprint('Percentage of 0 confirmed case records: {0:<2.1f}% \\n' \n      'Percentage of confirmed case records: {1:<2.1f}% \\n'\n      'Ratio of confirmed cases records: {2:<2.0f}/{3:<2.0f} '.format(prob_confirm_check_train[0]*100, prob_confirm_check_train[1:].sum()*100, n_confirm_train, n_train))\nprint('\\n=== Fatalities in Training Dataset ===')\nprint('Percentage of 0 fatalities: {0:<2.1f}% \\n' \n      'Percentage of fatalities: {1:<2.1f}% \\n'\n      'Ratio of fatality records: {2:<2.0f}/{3:<2.0f} '.format(prob_fatal_check_train[0]*100, prob_fatal_check_train[1:].sum()*100, n_fatal_train, n_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trend by Country/Region in Training Dataset\n\nLets look at the trend by Country/Region."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_country = train_data.groupby(['Country/Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\ntrain_data_by_country_confirm = train_data_by_country.sort_values(by=[\"ConfirmedCases\"], ascending=False)\ntrain_data_by_country_confirm.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import cycle, islice\ndiscrete_col = list(islice(cycle(['orange', 'r', 'g', 'k', 'b', 'c', 'm']), None, len(train_data_by_country_confirm.head(20))))\nplt.rcParams.update({'font.size': 22})\ntrain_data_by_country_confirm.head(20).plot(figsize=(15,10), kind='barh', color=discrete_col)\nplt.legend([\"Confirmed Cases\", \"Fatalities > 100\"]);\nplt.xlabel(\"Number of Covid-19 affectees\")\nplt.title(\"Confirmed Cases by Country in Training Data\")\nylocs, ylabs = plt.yticks()\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"ConfirmedCases\"][:]):\n    plt.text(v+0.01, ylocs[i]-0.25, str(int(v)), fontsize=12)\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"Fatalities\"][:]):\n    if v > 100: #disply for only >100 fatalities\n        plt.text(v+0.01,ylocs[i]+0.1,str(int(v)),fontsize=12)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Diagnostics\n"},{"metadata":{},"cell_type":"markdown","source":"Create a dataframe grouped by Date with global maximum ConfirmedCases and Fatalities on that date."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data_by_date = train_data.groupby(['Date'],as_index=False).agg({'ConfirmedCases': 'max','Fatalities': 'max'})\ntrain_data_by_date.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create a new dataframe subset with fatalities > 200, and sort it w.r.t max fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_country_fatal = train_data_by_country[train_data_by_country['Fatalities']>200]\ntrain_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\ntrain_data_by_country_fatal.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge the original training df with the fatal subset df, along the column:Country/Region. Next, group this table by columns Data and Country/Region, and find the total confirmed cases and fatalities. In this way all the entries of the Country/Region that have max fatalities < 200 are omitted. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country/Region'],on=['Country/Region'],how='inner')\ndf_max_fatality_country = df_merge_by_country.groupby([\"Date\",\"Country/Region\"],as_index=False).agg({'ConfirmedCases': 'sum','Fatalities': 'sum'})\ndf_max_fatality_country.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time Evolution of Global and National Fatality and Confirmed cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\ndate_list = train_data_by_date[\"Date\"].tolist()\nxticks = [dt.datetime.strftime(t,'%Y-%m-%d') for t in date_list]\nxticks = [tick for i,tick in enumerate(xticks) if i%4==0 ]# split labels into equally spaced ticks\n\ndef setCosmetics(ax, xticks, xLabel, yLabel, title):\n    ax.set_xticks(xticks)\n    ax.set_xticklabels([i for i in xticks])\n    plt.setp(ax.get_xticklabels(), rotation=90)\n    ax.set_xlabel(xLabel)\n    ax.set_ylabel(yLabel)\n    ax.set_title(title)\n    ax.yaxis.grid(linestyle='dotted')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['left'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n    ax.legend()\n    \nplt.rcParams.update({'font.size': 16})\n\nfig,(ax0,ax1) = plt.subplots(1,2,figsize=(15, 5),sharey=True)\n\nax0.plot(train_data_by_date['Date'],train_data_by_date['Fatalities'], color='r',marker='o',linewidth=2,label='Global')\nsetCosmetics(ax0,xticks,'Date','Fatalities','Time Evolution of Global Fatalities')\n\ncountries = df_max_fatality_country['Country/Region'].unique().tolist()\nfor country in countries:\n    match = df_max_fatality_country['Country/Region']==country\n    df_fatality_by_country = df_max_fatality_country[match]\n    ax1.plot(df_fatality_by_country[\"Date\"],df_fatality_by_country['Fatalities'],marker='o',linewidth=2,label=country)\n    setCosmetics(ax1,xticks,'Date','Fatalities','Time Evolution of National Fatalities')\n    \nfig,(ax2,ax3) = plt.subplots(1,2,figsize=(15,5),sharey=True)     \nax2.plot(train_data_by_date['Date'],train_data_by_date['ConfirmedCases'], color='orange',marker='o',linewidth=2,label='Global')\nsetCosmetics(ax2,xticks,'Date','ConfirmedCases','Time Evolution of Global Confirmed Cases')\n\nfor country in countries:\n    df_fatality_by_country = df_max_fatality_country[df_max_fatality_country['Country/Region']==country]\n    ax3.plot(df_fatality_by_country[\"Date\"],df_fatality_by_country['ConfirmedCases'],marker='o',linewidth=2,label=country)\n    setCosmetics(ax3,xticks,'Date','ConfirmedCases','Time Evolution of National Confirmed Cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a strange obervation in France data on March 23rd. Not sure if its an artifact caused by data unavailability."},{"metadata":{},"cell_type":"markdown","source":"# Prediction using Polynomial of degree n and Ridge Model\n\nBased on the natational fatalities trend in training data, I decide the fitting model as polynomial of degree n regulated by ridge regression. I tried several linear models along with polynomial regression, and found Ridge better here. In order to correctly get the n_degree of polynomial, I check my model for the countries with fatalities more than 100. First, I check my prediction against the last 10 days data in the training dataset, and once I believe that model is reasonable, I proceeded to apply it on all the countires and provinces. Same study was performed for the confirmed cases precdictions. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression, HuberRegressor\nfrom sklearn.metrics import r2_score \nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.pipeline import make_pipeline\nfrom tqdm import tqdm\n\nplt.rcParams.update({'font.size': 12})\nfig = plt.figure(figsize=(15,8)) \nax0 = fig.add_subplot(1,2,1)\nfor country in tqdm(countries): \n    df_country_train = df_max_fatality_country[df_max_fatality_country['Country/Region']==country] \n    df_country_test = test_data[test_data['Country/Region']==country]  \n    days_in_train_by_country = df_country_train.Date.nunique()\n    days_in_test_by_country  = df_country_test.Date.nunique()\n    x_train = np.array(range(days_in_train_by_country)).reshape((-1,1))   \n    y_train = df_country_train['Fatalities']   \n    x_test = (np.array(range(days_in_test_by_country))+45).reshape((-1,1)) #allow overlap of few days in training data       \n    model = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False))  \n    model = model.fit(x_train, y_train)       \n    y_predict = model.predict(x_test)  \n    ax0.plot(x_test , y_predict,linewidth=2, label='predict_'+country)\n    ax0.plot(x_train , y_train, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n    ax0.set_title(\"Prediction vs Training for Fatalities\")\n    ax0.set_xlabel(\"Number of days\")\n    ax0.set_ylabel(\"Fatalities\")\n    ax0.legend()\n    \nax1 = fig.add_subplot(1,2,2)\nfor country in tqdm(countries): \n    df_country_train = df_max_fatality_country[df_max_fatality_country['Country/Region']==country] \n    df_country_test = test_data[test_data['Country/Region']==country]  \n    days_in_train_by_country = df_country_train.Date.nunique()\n    days_in_test_by_country  = df_country_test.Date.nunique()\n    x_train = np.array(range(days_in_train_by_country)).reshape((-1,1))   \n    y_train = df_country_train['ConfirmedCases']   \n    x_test = (np.array(range(days_in_test_by_country))+45).reshape((-1,1)) #allow overlap of few days in training data       \n    model = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False))  \n    model = model.fit(x_train, y_train)       \n    y_predict = model.predict(x_test) \n    ax1.plot(x_test , y_predict,linewidth=2, label='predict_'+country)\n    ax1.plot(x_train , y_train, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n    ax1.set_title(\"Prediction vs Training for Confirmed Cases\")\n    ax1.set_xlabel(\"Number of days\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n    ax1.legend()    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best fit was found with **polynomial of degree = 4**, however it was giving quite depressing number of fatalities and confirmed-cases, that intuitively can't be correct for any pandemic model, thinking we will be over-training otherwise. Therefore, we have decided to stay with **polynomial of degree = 3**. There can be much better models as Italy should stablize like China, but this is quick and dirty check. A good modeling can be done by using the curve shape from China and fit it other countries for the prediction known as template fitting or even better using the SIR model. For now, let us proceed to submit our precitions for all the countires and states using this simple model of **polynomial of degree = 3** regulated by **Ridge**. We will continue with those model after the competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"nCountries= train_data['Country/Region'].unique()  \nfor country in tqdm(nCountries): \n    df_country_train = train_data[train_data['Country/Region']==country] \n    df_country_test = test_data[test_data['Country/Region']==country]\n    if df_country_train['Province/State'].isna().unique()==True:   \n        days_in_train_by_country = df_country_train.Date.nunique()\n        days_in_test_by_country  = df_country_test.Date.nunique()\n        x_train = np.array(range(days_in_train_by_country)).reshape((-1,1))    \n        y_train = df_country_train['Fatalities']        \n        model = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False))  \n        model = model.fit(x_train, y_train)\n        x_test = (np.array(range(days_in_test_by_country))+days_in_train_by_country-14).reshape((-1,1))  \n        y_predict = model.predict(x_test)   \n        test_data.loc[test_data['Country/Region']==country,'Fatalities'] = y_predict\n    else: # use Province/State data when available\n        for state in df_country_train['Province/State'].unique():\n            df_state_train = df_country_train[df_country_train['Province/State']==state] \n            df_state_test = df_country_test[df_country_test['Province/State']==state]                    \n            days_in_train_by_state = df_state_train.Date.nunique()\n            days_in_test_by_state  = df_state_test.Date.nunique()            \n            x_train = np.array(range(days_in_train_by_state)).reshape((-1,1))\n            y_train = df_state_train['Fatalities']\n            model = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False))\n            model = model.fit(x_train, y_train)  \n            x_test = (np.array(range(days_in_test_by_state))+days_in_train_by_state-14).reshape((-1,1)) \n            y_predict = model.predict(x_test) \n            y_predict = [ip if ip>=0 else 0 for ip in y_predict]\n            test_data.loc[(test_data['Country/Region']==country)&(test_data['Province/State']==state),'Fatalities'] = y_predict\n\n        \nfor country in tqdm(nCountries): \n    df_country_train = train_data[train_data['Country/Region']==country] \n    df_country_test = test_data[test_data['Country/Region']==country]\n    if df_country_train['Province/State'].isna().unique()==True:    \n        days_in_train_by_country = df_country_train.Date.nunique()\n        days_in_test_by_country  = df_country_test.Date.nunique()\n        x_train = np.array(range(days_in_train_by_country)).reshape((-1,1))    \n        y_train = df_country_train['ConfirmedCases']        \n        model = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False))  \n        model = model.fit(x_train, y_train)\n        x_test = (np.array(range(days_in_test_by_country))+days_in_train_by_country-14).reshape((-1,1)) \n        y_predict = model.predict(x_test)   \n        test_data.loc[test_data['Country/Region']==country,'ConfirmedCases'] = y_predict\n    else: # use Province/State data when available\n        for state in df_country_train['Province/State'].unique():\n            df_state_train = df_country_train[df_country_train['Province/State']==state] \n            df_state_test = df_country_test[df_country_test['Province/State']==state]                    \n            days_in_train_by_state = df_state_train.Date.nunique()\n            days_in_test_by_state  = df_state_test.Date.nunique()            \n            x_train = np.array(range(days_in_train_by_state)).reshape((-1,1))\n            y_train = df_state_train['ConfirmedCases']\n            model = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False))\n            model = model.fit(x_train, y_train)  \n            x_test = (np.array(range(days_in_test_by_state))+days_in_train_by_state-14).reshape((-1,1)) \n            #print(x_test)\n            y_predict = model.predict(x_test) \n            y_predict = [ip if ip>=0 else 0 for ip in y_predict]\n            test_data.loc[(test_data['Country/Region']==country)&(test_data['Province/State']==state),'ConfirmedCases'] = y_predict\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-1/submission.csv\")#, index_col=0)\nsubmit_data['Fatalities'] = test_data['Fatalities'].astype('int')\nsubmit_data['ConfirmedCases'] = test_data['ConfirmedCases'].astype('int')\nsubmit_data.to_csv('submission.csv', index=False)\nsubmit_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Therefore, according to this model, the prediction for next 43 days is maximum confirmed cases = 670233, and maximum fatalities = 67611 (~10 times more as of today). We truly wish this not to be true, and wish everyone good health. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}