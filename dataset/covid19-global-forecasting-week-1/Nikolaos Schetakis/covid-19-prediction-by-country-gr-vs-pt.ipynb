{"cells":[{"metadata":{},"cell_type":"markdown","source":"**NOTICE:**\n\nThe predict value is not accurate unless the confirm/deaths/recorverd has a huge increasement duration > 2-3 weeks, so please not be scared and keep patient. Figures are for reference only.\n\n**NOTE:**\n* The model inherited from this notebook : https://www.kaggle.com/alixmartin/covid-19-predictions\n* Use the Github data to predict newest case https://github.com/CSSEGISandData/COVID-19\n* Can prediction Confirmed / Deaths / Recovered / Active cases\n* Can prediction by specify Province and Country \n* World prediction (With China Data / Without China Data)\n* I will update the prediction every day (Last Update 2020/03/30 7:30 UCT)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the old format\nconfirmed_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\ndeath_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\nrecovered_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n\nconfirmed_table = confirmed_df.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Confirmed\").fillna('').drop(['Lat', 'Long'], axis=1)\ndeath_table = death_df.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Deaths\").fillna('').drop(['Lat', 'Long'], axis=1)\nrecovered_table = recovered_df.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Recovered\").fillna('').drop(['Lat', 'Long'], axis=1)\n\nfull_table = confirmed_table.merge(death_table).merge(recovered_table)\n\nfull_table['Date'] = pd.to_datetime(full_table['Date'])\nfull_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning Data"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# cases \n#cases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\nfull_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n\n# replacing Mainland china with just China\nfull_table['Country/Region'] = full_table['Country/Region'].replace('Mainland China', 'China')\n\n# filling missing values \nfull_table[['Province/State']] = full_table[['Province/State']].fillna('')\n# full_table[cases] = full_table[cases].fillna(0)\nfull_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_time_series(country):\n    # for some countries, data is spread over several Provinces\n    if full_table[full_table['Country/Region'] == country]['Province/State'].nunique() > 1:\n        country_table = full_table[full_table['Country/Region'] == country]\n        country_df = pd.DataFrame(pd.pivot_table(country_table, values = ['Confirmed', 'Deaths', 'Recovered', 'Active'],\n                              index='Date', aggfunc=sum).to_records())\n        return country_df.set_index('Date')[['Confirmed', 'Deaths', 'Recovered', 'Active']]\n    df = full_table[(full_table['Country/Region'] == country) \n                & (full_table['Province/State'].isin(['', country]))]\n    return df.set_index('Date')[['Confirmed', 'Deaths', 'Recovered', 'Active']]\n\n\ndef get_time_series_province(province):\n    # for some countries, data is spread over several Provinces\n    df = full_table[(full_table['Province/State'] == province)]\n    return df.set_index('Date')[['Confirmed', 'Deaths', 'Recovered', 'Active']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data looks a bit dirty, we might get an overly optimistic prediction because the last number is not the final one for instance.\n\nThe model is quite sensitive to this as it has only a handful of points to infer the dynamics from.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'Greece'\ndf = get_time_series(country)\nif len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n    df.drop(df.tail(1).index,inplace=True)\ndf.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'Portugal'\ndf = get_time_series(country)\nif len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n    df.drop(df.tail(1).index,inplace=True)\ndf.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{},"cell_type":"markdown","source":"I will use a model from a marketing paper by Emmanuelle Le Nagard and Alexandre Steyer, that attempts to reflect the social structure of a diffusion process. Their application was the diffusion of innovations, not epidemics. However, there are commonalities in both domains, as the number of contacts each infected person / innovation adopter has seems relevant. It also has the added benefit to allow fitting parameters to the beginning of a time series.\n\npaper is available (in French) [here](https://www.jstor.org/stable/40588987)\n\nThe model is also sensitive to when we define the origin of time for the epidemic process. Here, I just took the first point of the time series available, but adding a lag parameter could be attempted."},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef model_with_lag(N, a, alpha, lag, t):\n    # we enforce N, a and alpha to be positive numbers using min and max functions\n    lag = min(max(lag, -100), 100) # lag must be less than +/- 100 days \n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * (t - lag))) ** max(alpha, 0)\n\ndef model(N, a, alpha, t):\n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * t)) ** max(alpha, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_index = 0\n\ndef model_loss(params):\n#     N, a, alpha, lag = params\n    N, a, alpha = params\n    model_x = []\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, model_index]) ** 2\n#         r += (math.log(1 + model(N, a, alpha, t)) - math.log(1 + df.iloc[t, 0])) ** 2 \n#         r += (model_with_lag(N, a, alpha, lag, t) - df.iloc[t, 0]) ** 2\n#         print(model(N, a, alpha, t), df.iloc[t, 0])\n    return math.sqrt(r) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to explore the 3d parameter space to find a minimum, using gradient descent. There are a number of algorithms to do that in scipy.optimize, I stopped at the first one that seemed to work. Generalized Reduced Gradient as in Excel solver also works."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.optimize import minimize\nuse_lag_model = False\nif use_lag_model:\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15, 0]), method='Nelder-Mead', tol=1e-5).x\nelse:\n    model_index = 0\n    opt_confirmed = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 1\n    opt_deaths = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 2\n    opt_recovered = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\nopt_deaths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nmodel_x = []\nfor t in range(len(df)):\n    model_x.append([df.index[t], model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\nmodel_sim = pd.DataFrame(model_x, dtype=int)\nmodel_sim.set_index(0, inplace=True)\nmodel_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\n\nmodel_sim['Model-Active'] = model_sim['Model-Confirmed'] - model_sim['Model-Deaths'] - model_sim['Model-Recovered']\nmodel_sim.loc[model_sim['Model-Active']<0,'Model-Active'] = 0\nplot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\npd.concat([model_sim, df], axis=1).plot(color = plot_color)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Curve look perfect, let's extend the prediction curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_fit(df, opt_confirmed, opt_deaths, opt_recovered, ax):\n    model_x = []\n    \n    isValid = True\n    last_death_rate = 0\n    \n    for t in range(len(df)):\n        model_x.append([df.index[t], model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\n        \n        #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n        if (t > len(df)):\n            last_row = model_x[-1]\n            if (last_row[2] + last_row[3] > last_row[1]) or (last_row[2] > last_row[1]*0.05):\n                if (isValid):\n                    last_row2 = model_x[-2]\n                    last_death_rate = last_row2[2]/last_row2[1]\n                    isValid = False\n                    \n            if (last_row[2] > last_row[1]*0.05):\n                last_row[2] = last_row[1]*last_death_rate\n                \n            if (last_row[2] + last_row[3] > last_row[1]):\n                last_row[2] = last_row[1]*last_death_rate\n                last_row[3] = last_row[1]*(1-last_death_rate)\n                \n                \n    model_sim = pd.DataFrame(model_x, dtype=int)\n    model_sim.set_index(0, inplace=True)\n    model_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\n\n    model_sim['Model-Active'] = model_sim['Model-Confirmed'] - model_sim['Model-Deaths'] - model_sim['Model-Recovered']\n    model_sim.loc[model_sim['Model-Active']<0,'Model-Active'] = 0\n    plot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\n    return pd.concat([model_sim, df], axis=1).plot(ax=ax, figsize=(14, 10), color = plot_color)\n\ndef display_extended_curve(df, opt_confirmed, opt_deaths, opt_recovered, ax):\n    start_date = df.index[0]\n    n_days = len(df) + 40\n    extended_model_x = []\n    \n    isValid = True\n    last_death_rate = 0\n    \n    for t in range(n_days):\n        extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\n        \n        #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n        if (t > len(df)):\n            last_row = extended_model_x[-1]\n            if (last_row[2] + last_row[3] > last_row[1]) or (last_row[2] > last_row[1]*0.05):\n                if (isValid):\n                    last_row2 = extended_model_x[-2]\n                    last_death_rate = last_row2[2]/last_row2[1]\n                    isValid = False\n            \n            if (last_row[2] > last_row[1]*0.05):\n                last_row[2] = last_row[1]*last_death_rate\n                    \n            if (last_row[2] + last_row[3] > last_row[1]):\n                last_row[2] = last_row[1]*last_death_rate\n                last_row[3] = last_row[1]*(1-last_death_rate)\n                \n                \n    extended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\n    extended_model_sim.set_index(0, inplace=True)\n    extended_model_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\n\n    extended_model_sim['Model-Active'] = extended_model_sim['Model-Confirmed'] - extended_model_sim['Model-Deaths'] - extended_model_sim['Model-Recovered']\n    \n    extended_model_sim.loc[extended_model_sim['Model-Active']<0,'Model-Active'] = 0\n    plot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\n    return pd.concat([extended_model_sim, df], axis=1).plot(ax=ax, figsize=(14, 10), color = plot_color)\n\n\ndef opt_display_model(df, stats):\n    # if the last data point repeats the previous one, or is lower, drop it\n    if len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n        df.drop(df.tail(1).index,inplace=True)\n    global model_index\n    model_index = 0\n    opt_confirmed = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 1\n    opt_deaths = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 2\n    opt_recovered = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    if min(opt_confirmed) > 0:\n        stats.append([country, *opt_confirmed, *opt_deaths, *opt_recovered])\n        n_plot = len(stats)\n        plt.figure(1)\n        ax1 = plt.subplot(221)\n        display_fit(df, opt_confirmed, opt_deaths, opt_recovered, ax1)\n        ax2 = plt.subplot(222)\n        display_extended_curve(df, opt_confirmed, opt_deaths, opt_recovered, ax2)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# World COVID-19 Prediction"},{"metadata":{},"cell_type":"markdown","source":"* **Predict World (With China Data) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\n\ndf = full_table[['Province/State','Country/Region', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Active']].groupby('Date').sum()\nprint('World COVID-19 Prediction (With China Data)')\nopt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Predict World (Without China Data) **\n\nBecause china is ahead of world, so maybe exclude china data sounds resonable, the tend looks more worse!"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\n\ndf = full_table[full_table['Country/Region'] != 'China'][['Province/State','Country/Region', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Active']].groupby('Date').sum()\nprint('World COVID-19 Prediction(Without China Data)')\nopt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict by Specify Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country Specify\nstats = []\nfor country in ['Greece','Portugal']:\n\n    df = get_time_series(country)\n\n    print('{} COVID-19 Prediction'.format(country))\n    \n    opt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nstats_df = pd.DataFrame(stats)\n# stats_df.columns = ['country', 'N', 'a', 'alpha', 'lag']\nstats_df.columns = ['country', 'Confirmed-N', 'Confirmed-a', 'Confirmed-alpha', 'Deaths-N', 'Deaths-a', 'Deaths-alpha', 'Recorved-N', 'Recorved-a', 'Recorved-alpha']\nstats_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\npd.options.display.float_format = '{:20,.4f}'.format\nstats_df.astype({'Confirmed-N': 'int'}).sort_values(by='Confirmed-N', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"N is the potential spread in the country if the dynamics since the beginning of the epidemy persist. One problem is that sometimes we're measuring the spread of testing rather than of the epidemy. For instance New York allegedly started tesing a lot of people, which might explain the current explosive dynamic in the US numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}