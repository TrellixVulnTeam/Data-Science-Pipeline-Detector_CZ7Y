{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npd.options.display.float_format = '{:20,.2f}'.format\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom  warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/covid19-global-forecasting-week-1/train.csv')\ntest = pd.read_csv('../input/covid19-global-forecasting-week-1/test.csv')\nsubmission = pd.read_csv('../input/covid19-global-forecasting-week-1/submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting Date stored as object to datetime dtype"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date']=test.Date.astype('datetime64[ns]')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating ky for easy joins "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['key']=train['Province/State'].astype('str')+ \" \" + train['Country/Region'].astype('str')+ \" \" +train['Lat'].astype('str')+ \" \"  +train['Long'].astype('str')\n\ntest['key']=test['Province/State'].astype('str')+ \" \" + test['Country/Region'].astype('str')+ \" \" +test['Lat'].astype('str')+ \" \"  +test['Long'].astype('str')\n\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Global Total Numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_analysis=train.groupby(['Date']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_analysis[['ConfirmedCases','Fatalities']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy function "},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lag_1=train.groupby(['key']).shift(periods=1)\ntrain_lag_2=train.groupby(['key']).shift(periods=2)\ntrain_lag_3=train.groupby(['key']).shift(periods=3)\ntrain['lag_1_ConfirmedCases']=train_lag_1['ConfirmedCases']\ntrain['lag_1_Fatalities']=train_lag_1['Fatalities']\ntrain['lag_2_ConfirmedCases']=train_lag_2['ConfirmedCases']\ntrain['lag_2_Fatalities']=train_lag_2['Fatalities']\ntrain['lag_3_ConfirmedCases']=train_lag_3['ConfirmedCases']\ntrain['lag_3_Fatalities']=train_lag_3['Fatalities']\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Exponential and holt winter methods\n## Series only starts after first case is reported\nCurrently ConfirmedCases and Fatalities are sparately forecasted \n\n[Link to python ets](https://www.statsmodels.org/stable/examples/notebooks/generated/exponential_smoothing.html) \n\n[Details about ets method used ](https://robjhyndman.com/uwafiles/3-ExponentialSmoothing.pdf)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef pred_ets(fcastperiod,fcastperiod1,actual,ffcast,type_ck='ConfirmedCases',verbose=False):\n    \n    actual=actual[actual[type_ck]>0]\n    index=pd.date_range(start=ffcast.index[0], end=ffcast.index[-1], freq='D')\n    data=ffcast[type_ck].values\n    ffcast1 = pd.Series(data, index)\n    index=pd.date_range(start=actual.index[0], end=actual.index[-1], freq='D')\n    data=actual[type_ck].values\n    daily_analysis_dat = pd.Series(data, index)\n    livestock2=daily_analysis_dat\n    fit=[]\n    fcast=[]\n    fname=[]\n    try:\n        fit1 = SimpleExpSmoothing(livestock2).fit()\n        fcast1 = fit1.forecast(fcastperiod1).rename(\"SES\")\n        fit.append(fit1)\n        fcast.append(fcast1)\n        fname.append('SES')\n    except:\n        1==1\n    try:\n        fit2 = Holt(livestock2).fit()\n        fcast2 = fit2.forecast(fcastperiod1).rename(\"Holt\")\n        fit.append(fit2)\n        fcast.append(fcast2)\n        fname.append('Holt')\n    except:\n        1==1\n    try:\n        fit3 = Holt(livestock2, exponential=True).fit()\n        fcast3 = fit3.forecast(fcastperiod1).rename(\"Exponential\")\n        fit.append(fit3)\n        fcast.append(fcast3)\n        fname.append('Exponential')\n    except:\n        1==1\n    try:\n        fit4 = Holt(livestock2, damped=True).fit(damping_slope=0.98)\n        fcast4 = fit4.forecast(fcastperiod1).rename(\"AdditiveDamped\")\n        fit.append(fit4)\n        fcast.append(fcast4)\n        fname.append('AdditiveDamped')\n    except:\n        1==1\n    try:\n        fit5 = Holt(livestock2, exponential=True, damped=True).fit()\n        fcast5 = fit5.forecast(fcastperiod1).rename(\"MultiplicativeDamped\")\n        fit.append(fit5)\n        fcast.append(fcast5)\n        fname.append('MultiplicativeDamped')\n    except:\n        1==1\n    try:\n        fit6 = Holt(livestock2, damped=True).fit()\n        fcast6 = fit6.forecast(fcastperiod1).rename(\"AdditiveDampedC\")\n        fit.append(fit6)\n        fcast.append(fcast6)\n        fname.append('AdditiveDampedC')\n    except:\n        1==1\n\n\n    def RMSLE(pred,actual):\n        return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))\n    \n    pred_all_result=pd.concat([pd.DataFrame(k.fittedvalues) for k in fit],axis=1)\n    pred_all_result.columns=fname\n    all_result=pd.concat([pd.DataFrame(k) for k in fcast],axis=1)\n    col_chk=[]\n    vvvl=ffcast[type_ck].values.shape[0]\n    for k in all_result.columns:\n        if verbose: print(\"actual value for method %s  is = %s\" % (k,RMSLE(all_result[k].values,ffcast[type_ck].values)))\n        if RMSLE(all_result[k].values[:vvvl],ffcast[type_ck].values) is not np.nan:\n            col_chk.append(k)\n    col_chk_f=[]\n    min_acc=-1\n    for k in col_chk:\n        acc=RMSLE(pred_all_result[k].values,actual[type_ck].values)\n        #if k =='Exponential' and acc>0.01:\n                #acc=acc-0.01\n        if verbose: print(\"pred value for method %s  is = %s\" % (k,acc))\n        if acc is not np.nan:\n            col_chk_f.append(k)\n            if min_acc==-1:\n                min_acc=acc\n                model_select=k\n            elif acc<min_acc:\n                min_acc=acc\n                model_select=k\n    all_result=all_result.append(pred_all_result,sort=False)\n\n    all_result['best_model']=model_select\n    all_result['best_pred']=all_result[model_select]\n    return all_result\n    #return pred_all_result,all_result\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\norig_stdout = sys.stdout\n\nFatalities_all_result_final=pd.DataFrame()\nConfirmedCases_all_result_Final=pd.DataFrame()\nfor keys in train['key'].unique():\n    chk=train[train['key']==keys]\n    chk.index=chk.Date\n    fcastperiod=0\n    fcastperiod1=35\n    actual=chk[:chk.shape[0]-fcastperiod]\n    ffcast=chk[chk.shape[0]-fcastperiod-1:]\n    ffcast\n    try:\n        Fatalities_all_result_1=pred_ets(fcastperiod,fcastperiod1,actual,ffcast,'Fatalities').reset_index()\n        \n        \n    except:\n        Fatalities_all_result_1=pd.DataFrame(pd.date_range(start=chk.Date.min(), periods=60+fcastperiod1+1, freq='D')[1:])\n        Fatalities_all_result_1.columns=['index']\n        Fatalities_all_result_1['best_model']='naive'\n        Fatalities_all_result_1['best_pred']=0\n        \n    Fatalities_all_result_1['key']=keys\n    Fatalities_all_result_final=Fatalities_all_result_final.append(Fatalities_all_result_1,sort=True)\n    try:\n        ConfirmedCases_all_result_1=pred_ets(fcastperiod,fcastperiod1,actual,ffcast,'ConfirmedCases').reset_index()\n\n        \n    except:\n        ConfirmedCases_all_result_1=pd.DataFrame(pd.date_range(start=train.Date.min(), periods=60+fcastperiod1+1, freq='D')[1:])\n        ConfirmedCases_all_result_1.columns=['index']\n        ConfirmedCases_all_result_1['best_model']='naive'\n        ConfirmedCases_all_result_1['best_pred']=1\n    \n    ConfirmedCases_all_result_1['key']=keys\n    ConfirmedCases_all_result_Final=ConfirmedCases_all_result_Final.append(ConfirmedCases_all_result_1,sort=True)\n    print( ' done for %s' % keys)\nsys.stdout = orig_stdout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Skip warnings"},{"metadata":{"trusted":true},"cell_type":"code","source":"ConfirmedCases_all_result_Final.rename(columns={'index':'Date'},inplace=True)\nFatalities_all_result_final.rename(columns={'index':'Date'},inplace=True)\nConfirmedCases_all_result_Final['best_pred']=np.where(ConfirmedCases_all_result_Final['best_pred'] is np.nan , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred']=np.where(Fatalities_all_result_final['best_pred'] is np.nan , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )\nConfirmedCases_all_result_Final['best_pred']=np.where(ConfirmedCases_all_result_Final['best_pred'] <0 , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred']=np.where(Fatalities_all_result_final['best_pred'] <0 , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )\nConfirmedCases_all_result_Final['best_pred_1']=np.where(ConfirmedCases_all_result_Final['AdditiveDamped'] is np.nan , ConfirmedCases_all_result_Final['best_pred'] ,\n                                                       ConfirmedCases_all_result_Final['AdditiveDamped'] )\nFatalities_all_result_final['best_pred_1']=np.where(Fatalities_all_result_final['AdditiveDamped'] is np.nan , Fatalities_all_result_final['best_pred'] ,\n                                                       Fatalities_all_result_final['AdditiveDamped'] )\nConfirmedCases_all_result_Final['best_pred_1']=np.where(ConfirmedCases_all_result_Final['best_pred'] is np.nan , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred_1']=np.where(Fatalities_all_result_final['best_pred'] is np.nan , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )\nConfirmedCases_all_result_Final['best_pred_1']=np.where(ConfirmedCases_all_result_Final['best_pred'] <0 , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred_1']=np.where(Fatalities_all_result_final['best_pred'] <0 , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date']=test.Date.astype('datetime64[ns]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\neval1 = ConfirmedCases_all_result_Final[['key','Date','best_pred','best_pred_1']].merge(test, how='right', on=['key','Date'])\neval1.rename(columns={'best_pred':'ConfirmedCases'},inplace=True)\neval1['ConfirmedCases']=eval1['ConfirmedCases'].fillna(0)\neval1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval2 = Fatalities_all_result_final[['key','Date','best_pred','best_pred_1']].merge(test, how='right', on=['key','Date'])\n\neval2.rename(columns={'best_pred':'Fatalities'},inplace=True)\neval2['Fatalities']=eval2['Fatalities'].fillna(0)\neval2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_prep = eval1[['ForecastId','ConfirmedCases','key']].merge(eval2[['ForecastId','Fatalities']], on=['ForecastId'],  how='left')\nsub_prep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub_prep.merge(submission['ForecastId'], on=['ForecastId'],  how='right')\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=sub[['ForecastId','ConfirmedCases','Fatalities']]\nsub=sub.sort_values('ForecastId')\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',header=['ForecastId','ConfirmedCases','Fatalities'],index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub.to_csv('submission.csv')\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date']=train.Date.astype('datetime64[ns]')\nverify=train[['key','Date','ConfirmedCases','Fatalities']].merge(test[['key','Date','ForecastId']], how='inner', on=['key','Date'])\npred=verify[['ForecastId']].merge(sub, how='inner', on=['ForecastId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSLE(pred['Fatalities'].values,verify['Fatalities'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSLE(pred['ConfirmedCases'].values,verify['ConfirmedCases'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ConfirmedCases_all_result_Final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Next Steps\nRun the models at weekly level starting mid feb and see the best ETS model picked for each country. \nWe can understand at which week of breakout a country is growing by how much"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_key=ConfirmedCases_all_result_Final[['key','best_model']].drop_duplicates()\nmax_number_current=train.groupby('key').max()[['ConfirmedCases','Fatalities']].reset_index()\nbest_model_key=best_model_key.merge(max_number_current,on='key',how='left')\nbest_model_key=best_model_key.sort_values('ConfirmedCases',ascending=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in best_model_key.best_model.unique():\n    print('Top Countries/District currently under %s growth rate' % str (j))\n    print(best_model_key[best_model_key['best_model']==j].head())\n    print('-'*30)\n    print('-'*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_key.key.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Country level"},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ck=train.groupby(['Country/Region','Date']).sum().reset_index()\ntrain_ck['key']=train_ck['Country/Region']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forecast country level"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nFatalities_all_result_final=pd.DataFrame()\nConfirmedCases_all_result_Final=pd.DataFrame()\nfor keys in train_ck['key'].unique():\n    chk=train_ck[train_ck['key']==keys]\n    chk.index=chk.Date\n    fcastperiod=0\n    fcastperiod1=35\n    actual=chk[:chk.shape[0]-fcastperiod]\n    ffcast=chk[chk.shape[0]-fcastperiod-1:]\n    ffcast\n    try:\n        Fatalities_all_result_1=pred_ets(fcastperiod,fcastperiod1,actual,ffcast,'Fatalities').reset_index()\n        \n        \n    except:\n        Fatalities_all_result_1=pd.DataFrame(pd.date_range(start=train.Date.min(), periods=60+fcastperiod1+1, freq='D')[1:])\n        Fatalities_all_result_1.columns=['index']\n        Fatalities_all_result_1['best_model']='naive'\n        Fatalities_all_result_1['best_pred']=0\n        \n    Fatalities_all_result_1['key']=keys\n    Fatalities_all_result_final=Fatalities_all_result_final.append(Fatalities_all_result_1,sort=True)\n    try:\n        ConfirmedCases_all_result_1=pred_ets(fcastperiod,fcastperiod1,actual,ffcast,'ConfirmedCases').reset_index()\n\n        \n    except:\n        ConfirmedCases_all_result_1=pd.DataFrame(pd.date_range(start=train.Date.min(), periods=60+fcastperiod1+1, freq='D')[1:])\n        ConfirmedCases_all_result_1.columns=['index']\n        ConfirmedCases_all_result_1['best_model']='naive'\n        ConfirmedCases_all_result_1['best_pred']=1\n    \n    ConfirmedCases_all_result_1['key']=keys\n    ConfirmedCases_all_result_Final=ConfirmedCases_all_result_Final.append(ConfirmedCases_all_result_1,sort=True)\n    print( ' done for %s' % keys)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Skip for error"},{"metadata":{"trusted":true},"cell_type":"code","source":"ConfirmedCases_all_result_Final.rename(columns={'index':'Date'},inplace=True)\nFatalities_all_result_final.rename(columns={'index':'Date'},inplace=True)\nConfirmedCases_all_result_Final['best_pred']=np.where(ConfirmedCases_all_result_Final['best_pred'] is np.nan , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred']=np.where(Fatalities_all_result_final['best_pred'] is np.nan , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )\nConfirmedCases_all_result_Final['best_pred']=np.where(ConfirmedCases_all_result_Final['best_pred'] <0 , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred']=np.where(Fatalities_all_result_final['best_pred'] <0 , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )\nConfirmedCases_all_result_Final['best_pred_1']=np.where(ConfirmedCases_all_result_Final['AdditiveDamped'] is np.nan , ConfirmedCases_all_result_Final['best_pred'] ,\n                                                       ConfirmedCases_all_result_Final['AdditiveDamped'] )\nFatalities_all_result_final['best_pred_1']=np.where(Fatalities_all_result_final['AdditiveDamped'] is np.nan , Fatalities_all_result_final['best_pred'] ,\n                                                       Fatalities_all_result_final['AdditiveDamped'] )\nConfirmedCases_all_result_Final['best_pred_1']=np.where(ConfirmedCases_all_result_Final['best_pred'] is np.nan , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred_1']=np.where(Fatalities_all_result_final['best_pred'] is np.nan , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )\nConfirmedCases_all_result_Final['best_pred_1']=np.where(ConfirmedCases_all_result_Final['best_pred'] <0 , 0,\n                                                       ConfirmedCases_all_result_Final['best_pred'] )\nFatalities_all_result_final['best_pred_1']=np.where(Fatalities_all_result_final['best_pred'] <0 , 0 ,\n                                                       Fatalities_all_result_final['best_pred'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_key=ConfirmedCases_all_result_Final[['key','best_model']].drop_duplicates()\nmax_number_current=train_ck.groupby('key').max()[['ConfirmedCases','Fatalities']].reset_index()\nbest_model_key=best_model_key.merge(max_number_current,on='key',how='left')\nbest_model_key=best_model_key.sort_values('ConfirmedCases',ascending=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top country except china model state "},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_key=best_model_key[~(best_model_key['key']=='China')].reset_index()\nfor j in best_model_key.best_model.unique():\n    print('Top Countries/District currently under %s growth rate' % str (j))\n    print(best_model_key[best_model_key['best_model']==j].head(10))\n    print('-'*30)\n    print('\\n \\n')\n    print('-'*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}