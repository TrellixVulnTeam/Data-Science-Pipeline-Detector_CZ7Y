{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 and the Big 5 Personality Test\n\nFor this analysis, I pose the following question: \n\n> Does the growth in COVID-19 cases have anything to do with Big 5 Personality traits?\n\nTo answer this question, I will need country-level aggregates on the Big 5 test, and a country-level aggregate that represents for \"growth\" over time in coronavirus cases.\n\nHere's how I operationalize it: I take all the countries that reached at least 50 \"confirmed cases\" of the coronavirus, using data that's up to date as of March 20, 2020. Then I take the number of cases those countries had 14-days after reaching 50 confirmed cases. This gives an estimate of growth within a country that can be compared across countries, because it puts them all on a level playing-field.\n\nNext, I compute country-level averages on the Big 5 Personality Test using data from the Open Source Psychometrics Project, and I only include countries with at least 1000 observations. \n\nFinally, I look at the correlation between Confirmed Cases at Day 14 and average scores on each of the Big 5 personality traits (openness, conscientiousness, extraversion, agreeableness, neuroticism [a.k.a. emotional stability])."},{"metadata":{},"cell_type":"markdown","source":"For easy reference, the following datasets are used:\n\n- [COVID19 Global Forecasting (Week 1)](https://www.kaggle.com/c/covid19-global-forecasting-week-1/data)\n- [Big Five Personality Test](https://www.kaggle.com/tunguz/big-five-personality-test)\n- [Countries ISO Codes](https://www.kaggle.com/juanumusic/countries-iso-codes)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy.stats import pearsonr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Data\n\nFor the COVID-19 data, we'll get the number of cases at 2-weeks after the first 50 confirmed cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/test.csv')\n\n# Join the training and test sets\ncovid19 = pd.concat([train, test])\n# Sort by date\ncovid19.sort_values('Date')\n# Filter to the columns we need\ncovid19 = covid19.loc[:, ['Country/Region', 'Date', 'ConfirmedCases']]\n\ncovid19.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filter\n\nNext we'll filter to countries that reached at least 50 confirmed cases, and had at least 14 days of data beyond reaching that point."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19 = covid19[covid19.ConfirmedCases > 50]\ncovid19_numdays = covid19.loc[:, ['Country/Region', 'Date']]\\\n    .drop_duplicates()\\\n    .groupby('Country/Region')\\\n    .count()\\\n    .rename_axis('country')\\\n    .reset_index()\nprint(covid19_numdays.head())\n\ncovid19_mindays = covid19_numdays[covid19_numdays.Date >= 14]\ncovid19 = covid19[covid19['Country/Region'].isin(covid19_mindays.country)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What/how many countries does that leave us with?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(list(set(covid19['Country/Region'].values))))\nprint(set(covid19['Country/Region'].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obviously \"Cruise Ship\" isn't a country. I won't worry about it at this point, since it will get filtered out in later steps."},{"metadata":{},"cell_type":"markdown","source":"## Compute growth over 14 days\n\nNext, we'll compute the growth in cases for each country, from the date they reached 50 Confirmed Cases to the 14th day following that date. First we'll need to collapse over province, since some countries are represented multiple times under different provinces."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19[covid19['Country/Region'] == 'China'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_collapse_province = covid19\\\n    .groupby(['Country/Region', 'Date'])\\\n    .sum()\\\n    .reset_index()\ncovid19_collapse_province[covid19_collapse_province['Country/Region'] == 'China'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19 = covid19_collapse_province\\\n    .groupby('Country/Region')\\\n    .head(14)\\\n    .groupby('Country/Region')\\\n    .tail(1)\n\ncovid19","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Country Abbreviations\n\nNext we'll join in the country abbreviation codes. The source data here comes from the Kaggle [Countries ISO Codes dataset](https://www.kaggle.com/juanumusic/countries-iso-codes), and the original source is Wikipedia. This will allow us to join to the Big 5 dataset later."},{"metadata":{"trusted":true},"cell_type":"code","source":"country_isos = pd.read_csv('/kaggle/input/countries-iso-codes/wikipedia-iso-country-codes.csv')\ncountry_isos = country_isos.rename(columns={\"English short name lower case\": \"Country/Region\", \n                                            \"Alpha-2 code\": \"country_abbr\"})\ncountry_isos = country_isos.loc[:, ['Country/Region', 'country_abbr']]\ncountry_isos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19 = covid19.merge(country_isos, left_on='Country/Region', right_on='Country/Region')\ncovid19 = covid19.dropna()\ncovid19.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Big Five Personality Data\n\nNext, we'll fetch the [Big Five Personality Test data from Kaggle](https://www.kaggle.com/tunguz/big-five-personality-test). This dataset contains ~1M answers collected online by [Open Psychometrics](https://openpsychometrics.org/tests/IPIP-BFFM). I'm interested in this dataset because it also labels the country in which the respondant is located. We can use this dataset to get country-level aggregate data on personality traits, and then see if those traits map onto the COVID-19 outcomes that we're seeing."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5 = pd.read_csv('/kaggle/input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scoring the Big Five Personality Test items\n\nThe Big 5 personality inventory contains 5 factors. Like most personality scales, the Big 5 has a mix of items that positively and negatively load onto these personality factors. For example, the factor Extraversion describes someone who is outgoing, energetic, talkative, and enjoys human interaction. The first Extraversion item [`EXT1`] is \"I am the life of the party.\", a positively-keyed item; whereas the second item [`EXT2`] is \"I don't talk a lot.\", a negatively-keyed item.\n\nTo find out which items are positively or negatively keyed, we can look at the scale documentation on the IPIP website: https://ipip.ori.org/newBigFive5broadKey.htm\n\n## Reverse-coding\n\nBefore analyzing the data from a personality test, a psychologist will generally \"reverse-code\" the items that are negatively-keyed. This results in a dataset where the item values all have a common direction and interpretetion (i.e., a higher value corresponds with more of that trait). Mathematically, it allows you to then compute sums and averages for each of the factors. For example, after scoring the test items, we could compute an individual's average for Extraversion items to get their Extraversion score.\n\nThis version of the Big 5 scale asks individuals to rate their level of agreement from 1 to 5, where 1 is strong disagreement and 5 is strong agreement. Reverse-coding is as simple as subtracting 6 from every reverse-keyed item.\n\nThe code below will accomplish this task."},{"metadata":{"trusted":true},"cell_type":"code","source":"positively_keyed = ['EXT1', 'EXT3', 'EXT5', 'EXT7', 'EXT9',\n                    'EST1', 'EST3', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10',\n                    'AGR2', 'AGR4', 'AGR6', 'AGR8', 'AGR9', 'AGR10',\n                    'CSN1', 'CSN3', 'CSN5', 'CSN7', 'CSN9', 'CSN10', \n                    'OPN1', 'OPN3', 'OPN5', 'OPN7', 'OPN8', 'OPN9', 'OPN10']\n\nnegatively_keyed = ['EXT2', 'EXT4', 'EXT6', 'EXT8', 'EXT10',\n                    'EST2', 'EST4',\n                    'AGR1', 'AGR3', 'AGR5', 'AGR7', \n                    'CSN2', 'CSN4', 'CSN6', 'CSN8', \n                    'OPN2', 'OPN4', 'OPN6']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big5.loc[:, negatively_keyed] = 6 - big5.loc[:, negatively_keyed]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Country-Level Big 5 Aggregates"},{"metadata":{},"cell_type":"markdown","source":"First, we should eliminate any country that doesn't have very many observations. Somewhat arbitrarily, we'll draw a line at N = 1000."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5_country_count = big5.country\\\n    .value_counts()\\\n    .rename_axis('country')\\\n    .reset_index(name='counts')\n\nprint(len(big5_country_count[big5_country_count.counts > 1000]))\nprint(big5_country_count[big5_country_count.counts > 1000].country.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 58 countries with at least 1000 observations. Let's go with these."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5 = big5[big5.country.isin(big5_country_count[big5_country_count.counts > 1000].country.values)]\n\n# Filter on the columns we're going to use\nbig5 = big5.loc[:,['country'] + positively_keyed + negatively_keyed]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Factor aggregation\n\nNext, we'll compute averages for each of the five factors at the level of the individual."},{"metadata":{"trusted":true},"cell_type":"code","source":"EXT = ['EXT' + str(i) for i in range(1,11)]\nEST = ['EST' + str(i) for i in range(1,11)]\nAGR = ['AGR' + str(i) for i in range(1,11)]\nCSN = ['CSN' + str(i) for i in range(1,11)]\nOPN = ['OPN' + str(i) for i in range(1,11)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big5['EXT'] = big5.loc[:, EXT].mean(axis=1)\nbig5['EST'] = big5.loc[:, EST].mean(axis=1)\nbig5['AGR'] = big5.loc[:, AGR].mean(axis=1)\nbig5['CSN'] = big5.loc[:, CSN].mean(axis=1)\nbig5['OPN'] = big5.loc[:, OPN].mean(axis=1)\nbig5 = big5.loc[:, ['country', 'EXT', 'EST', 'AGR', 'CSN', 'OPN']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop NAs, and any with country = 'NONE'"},{"metadata":{"trusted":true},"cell_type":"code","source":"big5 = big5.dropna()\nbig5 = big5[big5.country != 'NONE']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Country-level averages\n\nNow we can calculate the country-level averages."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5_cavgs = big5.groupby('country')\\\n                    .mean()\\\n                    .rename_axis('country')\\\n                    .reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just to illustrate, these are the top 5 countries by country-level Extraversion scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5_cavgs.loc[:, ['country', 'EXT']]\\\n    .sort_values(by=['EXT'])\\\n    .tail()\\\n    .plot(x = 'country', \n          y = 'EXT', \n          kind='barh', \n          legend=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Joining Big 5 Country Data to COVID-19 Data\n\nNext we'll merge the COVID-19 dataset to the Big 5, country-level dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_big5 = covid19.merge(big5_cavgs, left_on='country_abbr', right_on='country')\ncovid19_big5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"factors = ['EXT', 'EST', 'AGR', 'CSN', 'OPN']\nfactor_names = ['Extraversion', 'Emotional Stability', 'Agreeableness', 'Conscientiousness', 'Openness']\n\nfor i, factor in enumerate(['EXT', 'EST', 'AGR', 'CSN', 'OPN']):\n    # Compute the correlation coefficient\n    corr = pearsonr(covid19_big5[factor], covid19_big5.ConfirmedCases)\n    corr = [np.round(c, 2) for c in corr]\n    text = 'r=%s, p=%s' % (corr[0], corr[1])\n    \n    ax = sns.regplot(x=factor, \n                y=\"ConfirmedCases\", \n                data=covid19_big5)\n    \n    ax.set_title(\"Confirmed cases at 14 days after first 50 cases \" + \n                 \"\\n by average score on Big 5 factor \" + factor_names[i] + \n                 \"\\n\" + text)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"China is perhaps an atypical outlier here because it was where the outbreak started.\n\nLet's see the plots again without China."},{"metadata":{"trusted":true},"cell_type":"code","source":"factors = ['EXT', 'EST', 'AGR', 'CSN', 'OPN']\nfactor_names = ['Extraversion', 'Emotional Stability', 'Agreeableness', 'Conscientiousness', 'Openness']\n\nfor i, factor in enumerate(['EXT', 'EST', 'AGR', 'CSN', 'OPN']):\n    # Compute the correlation coefficient\n    corr = pearsonr(covid19_big5[covid19_big5.country != 'CN'][factor], \n                    covid19_big5[covid19_big5.country != 'CN'].ConfirmedCases)\n    corr = [np.round(c, 2) for c in corr]\n    text = 'r=%s, p=%s' % (corr[0], corr[1])\n    \n    ax = sns.regplot(x=factor, \n                y=\"ConfirmedCases\", \n                data=covid19_big5[covid19_big5.country != 'CN'])\n    \n    ax.set_title(\"Confirmed cases at 14 days after first 50 cases \" + \n                 \"\\n by average score on Big 5 factor \" + factor_names[i] + \n                 \"\\n\" + text)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see here, the only Big 5 factor that seems to show a pattern was Openness: Countries with higher levels of openness saw more growth over the 14-day period. Although I think it could be argued that the countries lower on OPN may have had too much influence in the model, given how far they are set apart from the other data points."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_big5\\\n    .loc[:, ['country', 'OPN', 'ConfirmedCases']]\\\n    .sort_values('OPN', ascending=False)\\\n    .merge(country_isos, \n           left_on='country', \n           right_on='country_abbr')\\\n    .drop(['country_abbr', 'country'], axis=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":4}