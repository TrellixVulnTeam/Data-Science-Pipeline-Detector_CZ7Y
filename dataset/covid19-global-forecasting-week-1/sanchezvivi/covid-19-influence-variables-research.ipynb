{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Global Forecasting\n\n- Goal:\n\nFind variables that look like they impact the transmission rate for [this]() Kaggle competition.\n\n\n- Features:\n\n1. Days since first case and first death - 0, 1, 2, 3...\n2. Nc = Number of cases/deaths on a given day (total - previous day total)\n3. Growth factor: Nc/(Nc previous day) (inspired by this [video](https://www.youtube.com/watch?v=Kas0tIxDvrg))\n4. Average temperature for each place (january and february. My original intention was to analyse daily temperatures and see how that affected the number of new cases and deaths)\n5. Confirmed cases/Population size\n6. Other variables from [World Health Organization](https://data.worldbank.org/indicator)\n    * Population (total, female, urban)\n    * Land area\n    * GDP per Capita\n    * Smoking prevalence (total, female, male)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests, json\nimport pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup as bs\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport datetime as dt\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'], format='%Y/%m/%d') #adjusting format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Country/Region'] = df['Country/Region'].str.replace('*','') #adjusting Taiwan's name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking which countries have state\ndf['Country/Region'][df['Province/State'].notnull()].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Province/State'][df['Country/Region'] == 'Denmark'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for country in df['Country/Region'][df['Province/State'].notnull()].unique():\n    print ('Country:',country)\n    states = df['Province/State'][df['Country/Region'] == country].unique()\n    print('States:', states)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Since UK, Netherlands and France have regions that are outside the land territory, those will be treated separately.\n- Australia, Canada, China and US states will be grouped."},{"metadata":{"trusted":true},"cell_type":"code","source":"country = ['Denmark', 'France','Netherlands','United Kingdom']\ndf['Region'] = np.where(df['Country/Region'].isin(country),df['Province/State'],df['Country/Region'])\n#df['Region'] = np.select(conditions, choices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking those countries:\nfor country in df['Country/Region'][df['Province/State'].notnull()].unique():\n    print ('Country:', country)\n    region = df['Region'][df['Country/Region'] == country].unique()\n    print('Region:', region)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Grouping de dataset by date and country"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.groupby(['Date','Region'])[[\"ConfirmedCases\", \"Fatalities\"]].sum().reset_index() #id, latitude and longitude","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.sort_values(['Region','Date'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[df2['Region'] == 'US']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features"},{"metadata":{},"cell_type":"markdown","source":"1. Find out the date of the first case and first fatality for each country, so can normalize the spread from the first case and remove the delay effect."},{"metadata":{"trusted":true},"cell_type":"code","source":"def first_case(df,place_id,col,place):\n    min_cases = df[col][df[col] != 0][df[place] == place_id]\n    if len(min_cases) == 0:\n        min_cases = 0\n        date = df['Date'][df[place] == place_id].max()\n        #print('0:', place_id, date)\n    else:\n        min_cases = df[col][df[col] != 0][df[place] == place_id].min()\n        date = df['Date'][df[col] == min_cases][df[place] == place_id].min()\n        #print(min_cases, place_id, date)\n    return date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_cases = {}\ndeaths = {}\nplace = 'Region' # 'Province/State' or 'Country/Region'\nfor country in df[place].unique():\n    date = first_case(df2, country,'ConfirmedCases',place)\n    date_death = first_case(df2, country,'Fatalities',place)\n    first_cases[country] = date #where there's no case/death yet, the lastest date is considered\n    deaths[country] = date_death","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correcting the dates of the first case and first death of China","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first_cases['China'] = 2019-12-??","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['1st_case'] = df2[place].map(first_cases)\ndf2['1st_fatality'] = df2[place].map(deaths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['Days_since_1st_case'] = (df2['Date'] - df2['1st_case']).dt.days\ndf2['Days_since_1st_fatality'] = (df2['Date'] - df2['1st_fatality']).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='Days_since_1st_case', y=\"ConfirmedCases\",\n             hue=\"Region\", legend = False,\n             data = df2[df2['Days_since_1st_case'] >= 0])\n\nplt.title('Cases vs days since the first case')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.xticks(rotation=0)\n\n#As we can see, in some countries the spread took longer to break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='Days_since_1st_case', y=\"Fatalities\",\n             hue=\"Region\", legend = False,\n             data = df2[df2['Days_since_1st_case'] >= 0])\nplt.title('Fatalities vs days since the first case')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Daily new cases and fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"def daily_var(df, column_name, common_value,shift_value):\n    df[column_name] = np.where(df[common_value] == df[common_value].shift(1), df[shift_value].diff(1),0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_var(df2,'new_cases','Region','ConfirmedCases')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_var(df2,'new_fatalities','Region','Fatalities')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.barplot(x = 'Days_since_1st_case', y = 'new_cases', data = df2[df2['Region'] == 'Italy'])\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def daily_evolution(df,region):\n    labels = df['Days_since_1st_case'][df['Region'] == region].unique()\n    cases = df['new_cases'][df['Region'] == region]\n    #fatalities = df['new_fatalities'][df['Region'] == region]\n    width = 0.35       # the width of the bars: can also be len(x) sequence\n\n    fig, ax = plt.subplots()\n\n    ax.bar(labels, cases, width, label='Cases')\n    #ax.bar(labels, fatalities, width, bottom=cases,label='Fatalities')\n\n    ax.set_ylabel('Total')\n    ax.set_xlabel('Days since 1st case')\n    ax.set_title('New cases by day in ' + region)\n    ax.legend()\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_evolution(df2,'Spain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Growth Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"def growth_factor(df, column_name, place,shift_value):\n    df[column_name] = np.where(df[place] == df[place].shift(1), df[shift_value].div(df[shift_value].shift(1)),0)\n    df[column_name].replace([np.inf,-np.inf],np.nan, inplace = True)\n    df[column_name].fillna(method = 'ffill', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#growth factor moving average\ndef GFMA(df, column_name, place,shift_value, wndw):\n    df[column_name] = np.where(df[place] == df[place].shift(1), df[shift_value].rolling(window = wndw).mean(),0)\n    df[column_name].fillna(method = 'ffill', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_factor(df2,'growth_factor','Region','new_cases')\nGFMA(df2,'GFMA','Region','growth_factor',14) #14 days because theoretically that's how long it takes for the virus to be killed in our organism\ngrowth_factor(df2,'growth_factor_f','Region','new_fatalities')\nGFMA(df2,'GFMA_f','Region','growth_factor_f',14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.barplot(x = 'Days_since_1st_case', y = 'GFMA', hue = 'Region', data = df2[df2['Region'] == 'China'])\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"cell_type":"code","source":"def bar_n_line_graph(df,x_axis,bar_values, line_values,region):\n      \n    temp = df[df['Region'] == region]\n    \n    fig, ax = plt.subplots()\n    labels = temp[x_axis]\n    width = 0.35       # the width of the bars: can also be len(x) sequence\n    \n    ax2 = ax.twinx()\n    \n    bar = temp[bar_values]\n    line = temp[line_values]\n    \n    ax.plot(kind = 'bar', x = labels, height = bar, label='Growth Factor')\n    ax2.plot(labels, line, width, ax = ax2,label='GFMA')\n\n    #ax.set_ylabel('Total')\n    #ax.set_title('New cases by day in ' + region)\n    #ax.legend()\n    \n    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    #plt.xticks(rotation=45)\n    #plt.figure(figsize=(15, 10))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in China, at first the growth factor was very big, but eventually it decreased, making the curve stop The moving average helps us see that too."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[df2['Region'] == 'China'].plot(x = 'Days_since_1st_case', y = ['GFMA','GFMA_f'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outside Variables"},{"metadata":{},"cell_type":"markdown","source":"### 1. Weather\n\nMy original intention was to analyse daily weather and see how that affected the number of new cases and deaths. But giving that this is a very complex process that involves APIs and data tidying, I found it better to check if temperature would actually play a role in the spread. This could be replicated to wind speed, solar radiation, rain, etc. I got the temperatures from [Wikipedia.](https://en.wikipedia.org/wiki/List_of_cities_by_average_temperature) Feel free to gather data from other sources if you can."},{"metadata":{},"cell_type":"markdown","source":"1.1 Web Scraping"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_temp_url = 'https://en.wikipedia.org/wiki/List_of_cities_by_average_temperature'\nwiki_text = requests.get(avg_temp_url).text\nsoup = bs(wiki_text, 'html.parser')\ntables = soup.find_all('table')\ntable_str = str(tables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continents = []\nfor i in range (0,6):\n    t = pd.read_html(table_str)[i]\n    continents.append(t)\ntemps = pd.concat(continents)\ntemps.drop('Ref.', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adjusting names\ntemps['Country'].replace(['United States'],'US', inplace = True)\ntemps['Country'].replace(['United ArabEmirates'],'United Arab Emirates', inplace = True)\ntemps['Country'].replace(['South Korea'],'Korea, South', inplace = True)\ntemps['Country'].replace(['The '],'', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for month in temps.iloc[:,2:].columns:\n    temps[month] = temps[month].str.replace('−','-').str.split('(', expand = True)[0]\n    #temps[month] = temps[month].apply(pd.to_numeric, errors='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temps = temps.apply(pd.to_numeric, errors = 'ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_temps = temps.groupby('Country').mean() #monthly average for each country","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 10))\n\nsns.barplot(x = avg_temps.index, y = 'Year', data = avg_temps.sort_values('Year', ascending = False))\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. World Health Organization"},{"metadata":{},"cell_type":"markdown","source":"I selected random datasets from the WHO [database](https://data.worldbank.org/indicator) to check if any of those have any influence. Ideally, the model would check all of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_names_who(df):\n    df['Country Name'].replace(['United States'],'US', inplace = True)\n    #temps['Country'].replace(['United ArabEmirates'],'United Arab Emirates', inplace = True)\n    #temps['Country'].replace(['South Korea'],'Korea, South', inplace = True)\n    #temps['Country'].replace(['The '],'', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Consolidating variables and dataset"},{"metadata":{},"cell_type":"markdown","source":"Since all those variables are mostly a single value for each year, I've decided to aggregate the training dataset to the latest available date. This way we can measure the influence of each one considering how far the spread was at that point."},{"metadata":{"trusted":true},"cell_type":"code","source":"latest = df2['Date'].max()\nlatest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_latest = df2[df2['Date'] == latest].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_latest.sort_values('growth_factor', inplace = True, ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_latest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading all files..."},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir('/kaggle/input/world-health-organisation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, len(files)):\n    file = '/kaggle/input/world-health-organisation/' + files[i]\n    name = files[i][:-4]\n    temp = pd.read_csv(file, skiprows = 3)\n    replace_names_who(temp)\n    temp.head()\n    \n    #finds the column with the latest data\n    row = 2\n    while temp[temp.columns[-row]].notnull().mean() == 0:\n        col = temp.columns[-row]\n        #print(name,'row:',row, 'mean:' )\n        #print(temp[temp.columns[-row]].notnull().mean())\n        row += 1\n        #print('new row:',row)\n        \n    temp.set_index('Country Name', inplace = True)\n    col = temp.columns[-row]\n    #print('col:',col)\n    #print(temp[col])\n    \n    #consolidating dataset\n    df_latest[name] = df_latest['Region'].map(temp[col])\n    df_latest[name].fillna(temp.loc['World',col], inplace = True) #fills empty values with World mean\n    \n    df2[name] = df2['Region'].map(temp[col])\n    df2[name].fillna(temp.loc['World', col], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_latest['Avg_temp'] = df_latest['Region'].map(avg_temps[['Jan','Feb']].mean(axis = 1))\ndf_latest['Avg_temp'] = df_latest['Avg_temp'].fillna(df_latest['Avg_temp'].mean())#fills empty values with global mean\n\ndf2['Avg_temp'] = df2['Region'].map(avg_temps[['Jan','Feb']].mean(axis = 1))\ndf2['Avg_temp'] = df2['Avg_temp'].fillna(df2['Avg_temp'].mean())#fills empty values with global mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_latest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"sns.pairplot(df_latest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Output to csv"},{"metadata":{},"cell_type":"markdown","source":"As we can see from above, no significant relationship was found with confirmed cases or fatalities"},{"metadata":{},"cell_type":"markdown","source":"## Prediction Models"},{"metadata":{},"cell_type":"markdown","source":"### Processing test file"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_test(df):\n    df['Date'] = pd.to_datetime(df['Date'], format='%Y/%m/%d') #adjusting format\n    df['Country/Region'] = df['Country/Region'].str.replace('*','') #adjusting Taiwan's name\n    for country in df['Country/Region'][df['Province/State'].notnull()].unique():\n        #print ('Country:',country)\n        states = df['Province/State'][df['Country/Region'] == country].unique()\n        #print('States:', states)\n    country = ['Denmark', 'France','Netherlands','United Kingdom']\n    df['Region'] = np.where(df['Country/Region'].isin(country),df['Province/State'],df['Country/Region'])\n    #df['Region'] = np.select(conditions, choices)\n    df2 = df.groupby(['Date','Region'])[[\"Lat\", \"Long\"]].mean().reset_index() #id, latitude and longitude\n    df2.sort_values(['Region','Date'], inplace = True)\n    df2.drop(['Lat','Long'],axis = 1, inplace = True)\n    \n    df2['1st_case'] = df2[place].map(first_cases)\n    df2['1st_fatality'] = df2[place].map(deaths)\n    df2['Days_since_1st_case'] = (df2['Date'] - df2['1st_case']).dt.days\n    df2['Days_since_1st_fatality'] = (df2['Date'] - df2['1st_fatality']).dt.days\n    \n    return df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = preprocess_test(raw)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### [Times Series Smoothing](https://en.wikipedia.org/wiki/Exponential_smoothing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics import tsaplots\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_model import ARMA\nfrom statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forecast(df_train, df_test,col,country,period,training_size = 0.8):\n    \n    temp = df_train[df_train['Region'] == country].copy()\n    temp.set_index(pd.DatetimeIndex(temp['Date']), inplace = True)\n    #temp.drop('Date', axis = 1, inplace = True)\n    \n    temp_pred = df_test[df_test['Region'] == country].copy()\n    \n    total_days = temp['Days_since_1st_case'].max()\n    \n    #Time Series Properties\n    fig, ax = plt.subplots(1,2,figsize=(15,5))\n    tsaplots.plot_acf(temp[col], lags= 24, ax=ax[0])\n    tsaplots.plot_pacf(temp[col], lags= 24, ax=ax[1])\n    plt.show()\n    \n    decomposition = sm.tsa.seasonal_decompose(temp[col], period = 12)\n    fig = decomposition.plot()\n    plt.show()\n   \n    #Model\n    train = temp[col][temp['Days_since_1st_case'] <= total_days*training_size] #training default cut to 80% of dataset\n    test = temp[col][temp['Days_since_1st_case'] > total_days*training_size]\n    \n    \n    es = SimpleExpSmoothing(train).fit(smoothing_level=0.5)\n    fore_es = es.forecast(temp_pred.shape[0])\n     \n    #holt = Holt(df.qtde[:'2018']).fit()\n    #fore = holt.forecast(df.qtde['2018':].shape[0])\n    holt = Holt(train).fit()\n    fore_holt = holt.forecast(temp_pred.shape[0])\n    pred_holt = holt.predict(temp_pred.shape[0])\n        \n    hw = ExponentialSmoothing(train, seasonal_periods=period, trend='add',seasonal='add').fit()\n    fore_hw = hw.forecast(temp_pred.shape[0])\n    #pred_hw = holt.predict(temp_pred.shape[0])\n    \n    plt.figure(figsize=(16,8))\n    plt.plot(temp[col], label='Train')\n    plt.plot(test, label='Test')\n    plt.plot(fore_hw, label='Holt_Winters')\n    plt.plot(fore_es, label='Exponential Smoothing')\n    plt.plot(fore_holt, label='Holt Linear')\n    \n    #plt.xticks(rotation=45)\n    plt.legend(loc='best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast(df2,test,'ConfirmedCases','Italy', 25, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}