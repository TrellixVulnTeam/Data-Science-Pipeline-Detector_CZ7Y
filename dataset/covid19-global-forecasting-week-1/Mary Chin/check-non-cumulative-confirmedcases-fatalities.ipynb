{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is to check and iron out some inconsistencies report in:\nhttps://www.kaggle.com/c/covid19-global-forecasting-week-1/discussion/137500\n\n`ConfirmedCases` and `Fatalities` were supposed to be cumulative. But it's been observed not to be always the cases. At such occurrences the value from the previous day is pro-- and iterate over the next (if any) until there is no more day-to-day drop in `ConfirmedCases` and `Fatalities`. The doctored version of train.csv is then written as `trainDoctored.csv`."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nif 'kid' in os.getcwd():\n    HOME = '/home/kid/covid/data'\nelse:\n    HOME = '/kaggle'\nGFWPATH = f'{HOME}/input/covid19-global-forecasting-week-1'\nimport datetime\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def readGFWdata(file):\n    df = pd.read_csv(f'{GFWPATH}/{file}.csv', parse_dates=['Date'])\n    df['Date'] = pd.to_datetime(df['Date']).dt.date\n    if 'Country_Region' in df.columns:\n        countryregion, provincestate = 'Country_Region', 'Province_State'\n    else: # for backward compatibility wtih Week 1's data\n        countryregion, provincestate = 'Country/Region', 'Province/State'\n    df.sort_values(by=[countryregion, provincestate, 'Date'], inplace=True)\n    df[provincestate].fillna('', inplace=True)\n    return df, countryregion, provincestate\ndf, countryregion, provincestate = readGFWdata('train')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def catchNonCum(df):\n    dfDoctored = df.copy()\n    okay = True\n    for groupID, groupData in df.groupby([countryregion, provincestate]):\n        batchA = groupData[['Date', 'ConfirmedCases', 'Fatalities']]\n        batchB = batchA[1:].reset_index()\n        batchA = batchA[:-1].reset_index()\n        assert (batchA['Date'] == batchB['Date'] - datetime.timedelta(1)).all()\n        for colname in ['ConfirmedCases', 'Fatalities']:\n            checkAB = batchA[colname] > batchB[colname]\n            if checkAB.any():\n                okay = False\n                for idx in checkAB[checkAB].index:\n                    print(groupID[1], groupID[0], batchA.loc[idx, 'Date'].strftime(\"%Y-%m-%d\"), \n                                                  batchA.loc[idx, colname], colname)\n                    print(groupID[1], groupID[0], batchB.loc[idx, 'Date'].strftime(\"%Y-%m-%d\"), \n                                                  batchB.loc[idx, colname], colname)\n                    dfDoctored.loc[batchA['index'].loc[idx]+1, colname] = \\\n                    dfDoctored.loc[batchA['index'].loc[idx], colname]\n    return dfDoctored, okay\n\ndfDoctored, okay = catchNonCum(df)\nif okay:\n    print('All clear: no non-cumulative aberration found.')\nelse:\n    nround = 1\n    while not okay:\n        print('\\n*** round #', nround)\n        dfDoctored, okay = catchNonCum(dfDoctored)\n        nround += 1\n\nif 'Lat' in df.columns: # for backward compatibility wtih Week 1's data\n    for colname in ['Lat', 'Long']:\n        dfDoctored[colname] = dfDoctored[colname].map(lambda x: '{:.4f}'.format(x))\ndfDoctored.to_csv(f'{HOME}/working/trainDoctored.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}