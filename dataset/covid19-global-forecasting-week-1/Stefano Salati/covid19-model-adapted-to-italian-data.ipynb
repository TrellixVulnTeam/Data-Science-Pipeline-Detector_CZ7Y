{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 sandbox with regression and epidemiological models (WIP)\n\n## Data source\n* **Rest-of-the-world data are taken from here: [github](https://github.com/CSSEGISandData/COVID-19)**\n* **Italian data are taken from here: [github](https://github.com/pcm-dpc/COVID-19)**\n\n## Disclaimer\n* **The regression model is the result of my own work, while the epidemiological model is originally from [this work](https://www.kaggle.com/volpatto/covid-19-study-with-epidemiology-models). I only adapted it to work with adifferent dataset.**\n* **READ HERE FIRST: This is not an official study! This is very unlike to represent real scenarios! I'm not specialist in Epidemiology! This is a very simple demonstration about how to handle the models!**\n* **READ EVEN MORE: Real studies and predictions should be performed by teams with multiple specialities. COVID-19 is a real thing, don't propagate results and data as conclusive if YOU ARE NOT A SPECIALIST IN THE FIELD.**\n\n## Table of Contents\n\n1. [Importing libs](#importing)\n\n2. [Loading data](#loading)\n\n3. [Regression models](#regression)\n\n4. [Look at the data](#look)\n\n5. [Run regression models](#run_regression)\n\n\n\n\n5. [Epidemiology models](#models)\n\n6. [Programming SIR/SEIR-based models in Python](#implementations)\n\n7. [Least-squares fitting](#least-squares)\n\n8. [Extrapolation/Predictions](#deterministic-predictions)\n\n9. [Bayesian Calibration](#bayes-calibration)\n\n    * [SIR model](#bayes-sir)\n    * [Modified SEIR model](#bayes-seir2)\n\nThis notebook presents a simple \"study\", more like as an exercise, of how a data conciliation can be performed on Epidemiology models. This kind of approach can be adapted for other cases that have Dynamical Systems as mathematical model.\n\nClassical models are analyzed:\n\n* SIR (Susceptible-Infected-Recovered) model;\n* SEIR (Susceptible-Exposed-Infected-Recovered) model;\n\nNew modifications are proposed in order to represent better features that are present in COVID-19 spreading. The modified models are:\n\n* SIRD (Susceptible-Infected-Recovered-Dead) model, which considers the disease mortality rate explicity;\n* SEIR-2 model, which is a modification of SEIR that take into account the fact that exposed individuals without symptoms can transmit the disease to susceptible individuals during incubation time;\n* SEIRD model. This model is just SEIR-2 model, but considering the sub-population of Dead individuals;\n* SEIRD-Q model. This is the most ambitious model here. This model try to model, in some sense, the effect in the population dynamics related to removal due to quarantine.\n\n*New models will be devised in the next few days. Note that these models are \"local\" models, so it must be applied to territorial area for cities. It will be adjusted latter to take it into account.*\n\nBefore analyze the models, we begin having a look at the available data.\n\n**P.S.: This is just a study related to computational aspects. I'm not an epidemiologist. COVID-19 is a REAL issue! This notebook can not be regarded as professional advices in any sense except for, maybe, as a computational analysis. Maybe these models, or some idea, can help someone else that can really face this issue.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"importing\"></a>\n## Importing libs"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime,timedelta\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.optimize import curve_fit\nfrom scipy.optimize import fsolve\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nfrom itertools import compress\nimport traceback\nfrom scipy.signal import lfilter, filtfilt\nimport pymc3 as pm # for uncertainty quantification and model calibration\nfrom scipy.integrate import solve_ivp # to solve ODE system\nfrom scipy import optimize # to solve minimization problem from least-squares fitting\nfrom numba import jit # to accelerate ODE system RHS evaluations\nimport theano # to control better pymc3 backend and write a wrapper\nimport theano.tensor as t # for the wrapper to a custom model to pymc3\n\n# Plotting libs\nimport matplotlib.pyplot as plt\nimport altair as alt\n\nseed = 12345 # for the sake of reproducibility :)\nnp.random.seed(seed)\n\nplt.style.use('seaborn-talk') # beautify the plots!\n\nTHEANO_FLAGS='optimizer=fast_compile' # A theano trick","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"loading\"></a>\n## Loading data\nCommon to both logistic regressions and epidemiological models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load(keys):\n    def extract_ita(tipo, code):\n        if tipo == \"nat\":\n            url = \"../input/dpccovid19ita-20200418/dpc-covid19-ita-andamento-nazionale.csv\"\n            df = pd.read_csv(url)\n        elif tipo == \"reg\":\n            url = \"../input/dpccovid19ita-20200418/dpc-covid19-ita-regioni.csv\"\n            df_raw = pd.read_csv(url)\n            is_code =  df_raw['codice_regione']==code\n            df = df_raw[is_code]\n        elif tipo == \"prov\":\n            url = \"../input/dpccovid19ita-20200418/dpc-covid19-ita-province.csv\"\n            df_raw = pd.read_csv(url)\n            is_code =  df_raw['codice_provincia']==code\n            df = df_raw[is_code]\n    \n        # Interpretazione\n        #print(df)\n        try:\n            df = df[['data', 'totale_casi', 'deceduti','dimessi_guariti']].copy()\n        except:\n            df = df[['data', 'totale_casi']].copy()\n            df['deceduti'] = 0\n            df['dimessi_guariti'] = 0\n            \n        #df = df.loc[:,['data','totale_casi','deceduti','dimessi_guariti']]\n        date = df['data']\n        FMT = '%Y-%m-%dT%H:%M:%S'\n        df['date_n'] = pd.Series(date.map(lambda x : (dt.datetime.strptime(x, FMT) - dt.datetime.strptime(\"2019-12-31T00:00:00\", FMT)).days  ), index=df.index)\n        df.index = df['date_n']\n    \n        return df\n    \n    def extract_jhu(url):\n        df = pd.read_csv(url, delimiter=',')\n        df = df.transpose()\n        \n        # Create date_n\n        date_n = list(df.index[4:].values)\n        try:\n            FMT = '%m/%d/%y'\n            date_n = map(lambda x : (dt.datetime.strptime(x, FMT) - dt.datetime.strptime(\"12/31/19\", FMT)).days, date_n)\n        except:\n            FMT = '%m/%d/%Y'\n            date_n = map(lambda x : (dt.datetime.strptime(x, FMT) - dt.datetime.strptime(\"12/31/2019\", FMT)).days, date_n)\n        new_header = df.iloc[1]\n        df.columns = new_header\n        df = df[4:]\n        df['date_n'] = pd.Series(date_n, index=df.index)\n        \n        # Format date with a standard format\n        df['date'] = pd.Series(df.index, index=df.index)\n        FMTout = \"%Y-%m-%d\"\n        try:\n            FMTin = \"%m/%d/%y\"\n            #df['date'] = map(lambda x : (datetime.strftime(datetime.strptime(x, FMTin), FMTout)), pd.Series(df.index, index=df.index))\n            df['date'] = list(dt.datetime.strftime(dt.datetime.strptime(x, FMTin), FMTout) for x in pd.Series(df.index, index=df.index))\n        except:\n            FMTin = \"%m/%d/%Y\"\n            #df['date'] = map(lambda x : (datetime.strftime(datetime.strptime(x, FMTin), FMTout)), pd.Series(df.index, index=df.index))\n            df['date'] = list(dt.datetime.strftime(dt.datetime.strptime(x, FMTin), FMTout) for x in pd.Series(df.index, index=df.index))\n        \n        # Index based on date_n        \n        #df.index = range(len(df))\n        df.index = df['date_n']\n        \n        # Sum country regions\n        df = df.groupby(level=0, axis=1).sum()\n        \n        # Reorder columns to make in more readable\n        cols = df.columns.tolist()\n        cols = cols[-2:] + cols[:-2]\n        df = df[cols]\n        \n        # Filter only countris I am interested in\n        #df = df[['date_n','Italy', 'Germany', 'Spain', 'United Kingdom', 'France', 'Austria', 'US', 'China']]\n        \n        return df\n    \n    def concatandrename(df, df2, column, name):\n        df = pd.concat([df, df2[column]], axis=1)\n        df = df.rename(columns={column: name})\n        return df\n        \n    # Extract from JHU database\n    url_jhu_cases = \"../input/covid19jhu20200418/time_series_covid19_confirmed_global.csv\"\n    url_jhu_deaths = \"../input/covid19jhu20200418/time_series_covid19_deaths_global.csv\"\n    url_jhu_recovered = \"../input/covid19jhu20200418/time_series_covid19_recovered_global.csv\"\n    df_cases = extract_jhu(url_jhu_cases)\n    df_deaths = extract_jhu(url_jhu_deaths)\n    df_recovered = extract_jhu(url_jhu_recovered)\n    \n    # Extract from Ita database\n    df_ita = extract_ita(\"nat\", -1)\n    df_emiliaromagna = extract_ita(\"reg\", 8)\n    df_lombardia = extract_ita(\"reg\", 3)\n    df_veneto = extract_ita(\"reg\", 5)\n    df_parma = extract_ita(\"prov\", 34)\n    df_reggioemilia = extract_ita(\"prov\", 35)\n    df_modena = extract_ita(\"prov\", 36)\n    \n    # Merge Ita data with JHU data\n    df_cases = concatandrename(df_cases, df_ita, \"totale_casi\", \"Italia\")\n    df_cases = concatandrename(df_cases, df_emiliaromagna, \"totale_casi\", \"EmiliaRomagna\")\n    df_cases = concatandrename(df_cases, df_lombardia, \"totale_casi\", \"Lombardia\")\n    df_cases = concatandrename(df_cases, df_veneto, \"totale_casi\", \"Veneto\")\n    df_cases = concatandrename(df_cases, df_parma, \"totale_casi\", \"Parma\")\n    df_cases = concatandrename(df_cases, df_reggioemilia, \"totale_casi\", \"Reggio\")\n    df_cases = concatandrename(df_cases, df_modena, \"totale_casi\", \"Modena\")\n    \n    df_deaths = concatandrename(df_deaths, df_ita, \"deceduti\", \"Italia\")\n    df_deaths = concatandrename(df_deaths, df_emiliaromagna, \"deceduti\", \"EmiliaRomagna\")\n    df_deaths = concatandrename(df_deaths, df_lombardia, \"deceduti\", \"Lombardia\")\n    df_deaths = concatandrename(df_deaths, df_veneto, \"deceduti\", \"Veneto\")\n    df_deaths = concatandrename(df_deaths, df_parma, \"deceduti\", \"Parma\")\n    df_deaths = concatandrename(df_deaths, df_reggioemilia, \"deceduti\", \"Reggio\")\n    df_deaths = concatandrename(df_deaths, df_modena, \"deceduti\", \"Modena\")\n    \n    df_recovered = concatandrename(df_recovered, df_ita, \"dimessi_guariti\", \"Italia\")\n    df_recovered = concatandrename(df_recovered, df_emiliaromagna, \"dimessi_guariti\", \"EmiliaRomagna\")\n    df_recovered = concatandrename(df_recovered, df_lombardia, \"dimessi_guariti\", \"Lombardia\")\n    df_recovered = concatandrename(df_recovered, df_veneto, \"dimessi_guariti\", \"Veneto\")\n    df_recovered = concatandrename(df_recovered, df_parma, \"dimessi_guariti\", \"Parma\")\n    df_recovered = concatandrename(df_recovered, df_reggioemilia, \"dimessi_guariti\", \"Reggio\")\n    df_recovered = concatandrename(df_recovered, df_modena, \"dimessi_guariti\", \"Modena\")\n    \n    print(\"Elements in df_cases: {}\".format(len(df_cases)))\n    print(\"Elements in df_deaths: {}\".format(len(df_deaths)))\n    print(\"Elements in df_recovered: {}\".format(len(df_recovered)))\n    \n    # Prepara dati per processamento\n    if len(keys)>0:\n        x = np.asarray(list(df_cases['date_n']))\n        X = len(keys)*[x]\n        Y_cases = [np.asarray(list(df_cases[key])) for key in keys]\n        Y_deaths = [np.asarray(list(df_deaths[key])) for key in keys]\n        Y_recovered = [np.asarray(list(df_recovered[key])) for key in keys]\n        Label_cases = keys\n        Label_deaths = [Label_cases[i]+\"+\" for i in range(len(Label_cases))]\n        Label_recovered = [Label_cases[i]+\"|\" for i in range(len(Label_cases))]\n    else:\n        X = []\n        Y_cases = []\n        Y_deaths = []\n        Y_recovered = []\n        Label_cases = []\n        Label_deaths = []\n        Label_recovered = []\n    \n    return df_cases, df_deaths, df_recovered, X, Y_cases, Y_deaths, Y_recovered, Label_cases, Label_deaths, Label_recovered\n\n\n\"\"\"\nExtract data for one specific country/region\n\"\"\"\ndef country(df_cases, df_deaths, df_recovered, name):\n    df = pd.DataFrame(index=df_cases.index)\n    df = pd.concat([df, df_cases['date'], df_cases[name]], axis=1)\n    df = pd.concat([df, df_deaths[name]], axis=1)\n    df = pd.concat([df, df_recovered[name]], axis=1)\n    df.columns = ['date', 'confirmed', 'deaths', 'recovered']\n    df['confirmed_marker'] = 'Confirmed'\n    df['deaths_marker'] = 'Death'\n    df['recovered_marker'] = 'Recovered'\n    df = df.reset_index(drop=False)\n    return df\n\n\"\"\"\nTrims the initial days with 0 cases from a country df\n\"\"\"\ndef trim_country(df):\n    df0 = df[df.confirmed > 0]\n    df0 = df0.reset_index(drop=True)\n    df0['day'] = df0.date_n.apply(lambda x: (x - df0.date_n.min()))\n    \n    #df0 = df0.rename(columns={\"date_n\": \"day\"})\n    return df0\n\ndef load_population():\n    return pd.read_csv(\"../input/countries-of-the-world/countries of the world.csv\")\n\ndef get_target_population(df, country):\n    country = country + ' '\n    return float(df[df.Country == country].Population)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"regression\"></a>\n# Regression models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def daynumber2date(d):\n    return str(dt.datetime(2019, 12, 31) + dt.timedelta(days=int(d)))[:10]\n\nformatter_date = FuncFormatter(lambda x_val, tick_pos: \"{}\".format(daynumber2date(x_val)))\nformatter_log10 = FuncFormatter(lambda x_val, tick_pos: \"{}\".format(np.power(10,x_val)))\n\ndef removenan(x, y):\n    keep = np.logical_not(np.logical_or(np.logical_or(np.isnan(x), np.isinf(x)), np.logical_or(np.isnan(y), np.isinf(y))))\n    x = list(compress(x, keep))\n    y = list(compress(y, keep))\n    if (sum(np.isnan(x)) + sum(np.isinf(x)) + sum(np.isnan(y) + sum(np.isinf(y)))) > 0:\n        print(\"Stammerda non funziona\")\n    return x, y\n\ndef logistic1_model(x, a, dtau, tau):\n    return a/(1+np.exp(-(x-dtau)/tau))\n\ndef logistic2_model(x, a, b, dtau, tau):\n    return a/(1+b*np.exp(-np.power((x-dtau)/tau, 1.0)))\n\ndef logistic21_model(x, a, b, dtau, tau, ni):\n    return a/np.power(1+b*np.exp(-np.power((x-dtau)/tau, 1.0)), 1.0/ni)\n\ndef logistic3_model(x, a, b, tau, alpha):\n    # usato da Matteo P.\n    return a/(1+b*np.exp(-np.power(x/tau, alpha)))\n\ndef logistic31_model(x, a, b, tau, alpha, ni):\n    return a/np.power(1+b*np.exp(-np.power(x/tau, alpha)), 1.0/ni)\n\ndef logistic32_model(x, a, b, tau, alpha, ni, k):\n    return k + (a-k)/np.power(1+b*np.exp(-np.power(x/tau, alpha)), 1.0/ni)\n\ndef linear_model(x, a, b):\n    return a*x+b\n\ndef quadratic_model(x, a, b, c):\n    return a*(x**2)+b*x+c\n\ndef model(model, x, y, horizon=0, threshold=10, relative_rmse = False, verbose=False):\n    #x = np.asarray(x)\n    #y = np.asarray(y)\n    \n    if len(x) > 0:\n    \n        if horizon == 0:\n            x_pred = x\n        else:\n            x_pred = np.arange(min(x), max(x)+horizon, 1)\n        \n        if model == \"logistic1\":\n            try:\n                p0 = [20000, 100, 2]\n                fit = curve_fit(logistic1_model, x, y, p0=p0)\n                \n                y_pred = logistic1_model(x_pred, fit[0][0], fit[0][1], fit[0][2])\n    \n                # End date\n                sol = int(fsolve(lambda x : logistic1_model(x,fit[0][0],fit[0][1],fit[0][2]) - int(fit[0][2]),fit[0][1]))\n                end_date = dt.datetime(2019, 12, 31) + dt.timedelta(days=sol)\n                #print \"End date: \" + str(end_date)\n                \n            except:\n                traceback.print_exc()\n                print(model)\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[1, 0, 0], [0]]\n                end_date = 0\n        \n        if model == \"logistic2\":\n            try:\n                p0 = [1.52646450e+05, 1.56215676e-01, 9.59401246e+01, 6.23161909e+00]\n                fit = curve_fit(logistic2_model, x, y, maxfev=100000, p0=p0)\n                \n                y_pred = logistic2_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3])\n                \n            except Exception:\n                traceback.print_exc()\n                print(model)\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0, 1], [0]]\n            \n            end_date = 0\n            \n        if model == \"logistic21\":\n            try:                \n                #p0 = [1.52646450e+05, 1.56215676e-01, 9.59401246e+01, 6.23161909e+00, 1.0]\n                # Uso il valore massimo dei casi come a0, questo fa si' che il modello converga per tutti i set, se no non convergerebbe\n                p0 = [max(y), 1.56215676e-01, 9.59401246e+01, 6.23161909e+00, 1.0]\n                bounds = ([-np.inf, -np.inf, -np.inf, -np.inf, 0.000000],\n                          [ np.inf,  np.inf,  np.inf,  np.inf, 8.000000])\n                fit = curve_fit(logistic21_model, x, y, maxfev=100000, p0=p0)\n                \n                y_pred = logistic21_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3], fit[0][4])\n                \n            except Exception:\n                traceback.print_exc()\n                print(model)\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0, 1], [0]]\n            \n            end_date = 0\n            \n        if model == \"logistic3\":\n            try:\n                p0 = [1.52646560e+05, 1.56040732e-01, 9.59471514e+01, 1.5]\n                bounds = ([-np.inf, -np.inf, -np.inf, 0.0000009],\n                          [ np.inf,  np.inf,  np.inf, 8.0000000])\n                fit = curve_fit(logistic3_model, x, y, maxfev=100000, bounds=bounds, p0=p0)\n                \n                y_pred = logistic3_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3])\n                \n            except Exception:\n                traceback.print_exc()\n                print(model)\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0, 1], [0]]\n            \n            end_date = 0\n            \n        if model == \"logistic31\":\n            try:\n                p0 = [1.52646560e+05, 1.56040732e-01, 9.59471514e+01, 1.5, 1.0]\n                bounds = ([-np.inf, -np.inf, -np.inf, 0.0000009, 0.000000],\n                          [ np.inf,  np.inf,  np.inf, 8.0000000, 8.000000])\n                fit = curve_fit(logistic31_model, x, y, maxfev=100000, bounds=bounds, p0=p0)\n                \n                y_pred = logistic31_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3], fit[0][4])\n                \n            except Exception:\n                traceback.print_exc()\n                print(model)\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0, 1], [0]]\n            \n            end_date = 0\n            \n        if model == \"logistic32\":\n            try:\n                p0 = [1.52646560e+05, 1.56040732e-01, 9.59471514e+01, 1.5, 1.0, 0.0]\n                bounds = ([-np.inf, -np.inf, -np.inf, 0.000009, 0.000000, -np.inf],\n                          [ np.inf,  np.inf,  np.inf, 8.000000, 8.000000,  np.inf])\n                fit = curve_fit(logistic32_model, x, y, maxfev=100000, bounds=bounds, p0=p0)\n                \n                y_pred = logistic32_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3], fit[0][4], fit[0][5])\n                \n            except Exception:\n                traceback.print_exc()\n                print(model)\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0, 1], [0]]\n            \n            end_date = 0\n        \n        elif model == \"linear\":\n            try:\n                x_pred = np.arange(min(x), max(x)+horizon, 1)\n                fit = curve_fit(linear_model, x, y)\n                y_pred = linear_model(x_pred, fit[0][0], fit[0][1])\n            except:\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0], [0]]\n                \n            end_date = 0\n                \n        elif model == \"quadratic\":\n            try:\n                x_pred = np.arange(min(x), max(x)+horizon, 1)\n                fit = curve_fit(quadratic_model, x, y)\n                y_pred = quadratic_model(x_pred, fit[0][0], fit[0][1], fit[0][2])\n            except:\n                x_pred = [0]\n                y_pred = [0]\n                fit = [[0, 0, 0], [0]]\n                \n            end_date = 0\n        \n        # Calcolo RMSE\n        rmse = np.sqrt(mean_squared_error(y, y_pred[:len(y)]))\n        if relative_rmse:\n            rmse = rmse / max(y)\n        \n        # Cerco quando la derivata e' al di sotto di una certa soglia, quindi nuovi casi inferiori a ...\n        d = np.diff(y_pred)\n        zero_crossings = np.where(np.diff(np.sign(d-threshold)))[0]\n        if len(zero_crossings)>0:\n            last_zero_crossing_day = x_pred[zero_crossings[-1]]\n            end_date = last_zero_crossing_day\n        else:\n            end_date = -1\n            \n        if verbose:\n            #print len(x)\n            #print len(y)\n            #print len(x_pred)\n            #print len(y_pred)\n            print(fit[0])\n        \n        return x_pred, y_pred, fit, rmse, end_date\n    \n    else:\n        return [], [], [], 0, 0\n\n\ndef run_time_model(X, Y, past=0, horizon=0, threshold=10, relative_rmse=False, verbose=False):\n    Fit = list()\n    X_pred = list()\n    Y_pred = list()\n    Rmse = list()\n    End_date = list()\n    \n    if past>0:\n        print(\"Non hai capito un cazzo, past deve essere < 0\")\n    \n    for i, (x, y) in enumerate(zip(X,Y)):\n        x, y = removenan(x, y)\n        x = x[:len(x)+past]\n        y = y[:len(y)+past]\n        \n        #x_pred, y_pred, fit, end_date = model(\"logistic1\", x, y, horizon)\n        x_pred, y_pred, fit, rmse, end_date = model(\"logistic21\", x, y, horizon=horizon, threshold=threshold, relative_rmse=relative_rmse, verbose=verbose)\n        #x_pred, y_pred, fit, end_date = model(\"logistic3\", x, y, horizon)\n        #x_pred, y_pred, fit, end_date = model(\"logistic31\", x, y, horizon, verbose=True)\n        #x_pred, y_pred, fit, end_date = model(\"logistic32\", x, y, horizon, verbose=True)\n        \n        Fit.append(fit)\n        X_pred.append(x_pred)\n        Y_pred.append(y_pred)\n        Rmse.append(rmse)\n        End_date.append(end_date)\n        \n    return X_pred, Y_pred, Fit, Rmse, End_date\n\n\ndef run_time_model_timemachine(X, Y, Label, threshold):\n    timemachine = range(-20,0+1,1)\n    Timemachine_rmse = list()\n    Timemachine_enddate = list()\n        \n    for past in timemachine:\n        X_pred_cases, Y_pred_cases, Fit_cases, Rmse_cases, End_date_cases = run_time_model(X, Y, past=past, horizon=90, threshold=threshold, relative_rmse=True, verbose=False)\n        Timemachine_rmse.append(Rmse_cases)\n        Timemachine_enddate.append(End_date_cases)\n            \n    # Riordina risultati nel formato solito (per paese)\n    paese = 0\n    lista_enddate = list()\n    lista_rmse = list()\n    for paese in range(0, len(X)):\n        lista_enddate_paese = list()\n        lista_rmse_paese = list()\n        for giorno in range(0, len(Timemachine_enddate)):\n            lista_enddate_paese.append(Timemachine_enddate[giorno][paese])\n            lista_rmse_paese.append(Timemachine_rmse[giorno][paese])\n        lista_enddate.append(lista_enddate_paese)\n        lista_rmse.append(lista_rmse_paese)\n    \n    # Grafico\n    fig = plt.figure()\n    ax1 = fig.add_subplot(211)\n    ax1.yaxis.set_major_formatter(formatter_date)\n    \n    for i in range(len(lista_enddate)):\n        ax1.plot(timemachine, lista_enddate[i], label=Label[i])\n    ax1.legend()\n    ax1.set_title(\"Fine prevista\")\n    ax1.xaxis.set_label_text(\"Giorno nel passato\")\n    ax1.yaxis.set_label_text(\"Giorno\")\n    ax1.yaxis.grid(True, which='major')\n    ax1.yaxis.grid(True, which='minor')\n    \n    ax2 = fig.add_subplot(212)\n    for i in range(len(lista_enddate)):\n        ax2.plot(timemachine, lista_rmse[i], label=Label[i])\n    ax2.set_title(\"RMSE\")\n    ax2.xaxis.set_label_text(\"Giorno nel passato\")\n    ax2.yaxis.set_label_text(\"RMSE\")\n    ax2.yaxis.grid(True, which='major')\n    ax2.yaxis.grid(True, which='minor')\n    \n    return\n\n\ndef run_cross_model(Y1,Y2):\n    Fit = list()\n    Y1_pred = list()\n    Y2_pred = list()\n    \n    for i, (y1, y2) in enumerate(zip(Y1, Y2)):\n        y1, y2 = removenan(y1, y2)\n        y1_pred, y2_pred, fit = model(\"linear\", y1, y2)\n        Fit.append(fit)\n        Y1_pred.append(y1_pred)\n        Y2_pred.append(y2_pred)\n        \n    return Y1_pred, Y2_pred, Fit\n\n\ndef plot_timeseries(title, logplot, threshold, \\\n                    X, Y, X_pred, Y_pred, Label):\n    \n    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e']\n    plt.rcParams['figure.figsize'] = [20, 10]\n    plt.rc('font', size=14)\n    fig = plt.figure()\n    \n    ax1 = fig.add_subplot(221)\n    for idx, (x, y, x_pred, y_pred, label) in enumerate(zip(X, Y, X_pred, Y_pred, Label)):\n        if logplot:\n            ax1.scatter(x, np.log10(y), marker='.', color=colors[idx], label=label)\n            ax1.plot(x_pred, np.log10(y_pred), color=colors[idx], label=label)\n        else:\n            ax1.scatter(x, y, marker='.', color=colors[idx], label=label)\n            ax1.plot(x_pred, y_pred, color=colors[idx], label=label)\n    \n    ax1.set_title(title)\n    ax1.xaxis.set_label_text(\"Giorno\")\n    ax1.yaxis.set_label_text(\"Casi\")\n    ax1.legend()\n    ax1.xaxis.set_major_formatter(formatter_date)\n    if logplot:\n        ax1.set_ylim(0, 6)\n        ax1.yaxis.set_major_formatter(formatter_log10)\n    else:\n        ax1.set_ylim(0, 1000000)\n    ax1.yaxis.grid(True, which='major')\n    ax1.yaxis.grid(True, which='minor')\n    \n    # Nuovi casi previsti (derivata della previsione comulativa)\n    ax2 = fig.add_subplot(222)\n    ax2.set_title(title + \" (derivata)\")\n    for idx, (x, y, x_pred, y_pred, label) in enumerate(zip(X, Y, X_pred, Y_pred, Label)):\n        d = np.diff(y_pred)\n        ax2.plot(x_pred[1:], np.log10(d), color=colors[idx], label=label)\n        \n    ax2.xaxis.set_label_text(\"Giorno\")\n    ax2.yaxis.set_label_text(\"Nuovi casi\")\n    ax2.set_ylim(0, 5)\n    ax2.xaxis.set_major_formatter(formatter_date)\n    ax2.yaxis.set_major_formatter(formatter_log10)\n    ax2.set_yticks([np.log10(threshold)], minor=True)\n    ax2.xaxis.grid(True, which='major')\n    ax2.xaxis.grid(True, which='minor')\n    ax2.yaxis.grid(True, which='major')\n    ax2.yaxis.grid(True, which='minor')\n    \n    # Errori\n    ax3 = fig.add_subplot(223)\n    ax3.set_title(title + \" (errori)\")\n    for idx, (x, y, x_pred, y_pred, label) in enumerate(zip(X, Y, X_pred, Y_pred, Label)):\n        x, y = removenan(x, y)\n        ax3.plot(x, y_pred[:len(y)]-y, color=colors[idx], label=label)\n        \n    ax3.set_ylim(-3000, 3000)\n    ax3.yaxis.grid(True, which='major')\n    ax3.yaxis.grid(True, which='minor')\n    \n    plt.show()\n    return\n\n\ndef plot_timeseries2(title, logplot, threshold, \\\n                     X1, Y1, X1_pred, Y1_pred, Label1, \\\n                     X2, Y2, X2_pred, Y2_pred, Label2, scale2=1.0):\n    \n    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e']\n    plt.rcParams['figure.figsize'] = [20, 10]\n    plt.rc('font', size=14)\n    fig = plt.figure()\n    \n    ax1 = fig.add_subplot(111)\n    for idx, (x1, y1, x1_pred, y1_pred, label1, x2, y2, x2_pred, y2_pred, label2) in enumerate(zip(X1, Y1, X1_pred, Y1_pred, Label1, X2, Y2, X2_pred, Y2_pred, Label2)):\n        if logplot:\n            ax1.scatter(x1, np.log10(y1), marker='.', color=colors[idx], label=label1)\n            ax1.plot(x1_pred, np.log10(y1_pred), color=colors[idx], label=label1)\n            ax1.scatter(x2, np.log10(y2*scale2), marker='+', color=colors[idx], label=label2)\n            ax1.plot(x2_pred, np.log10(y2_pred*scale2), color=colors[idx], label=label2)\n        else:\n            ax1.scatter(x1, y1, marker='.', color=colors[idx], label=label1)\n            ax1.plot(x1_pred, y1_pred, color=colors[idx], label=label1)\n            ax1.scatter(x2, y2*scale2, marker='+', color=colors[idx], label=label2)\n            ax1.plot(x2_pred, y2_pred*scale2, color=colors[idx], label=label2)\n    \n    ax1.set_title(title)\n    ax1.xaxis.set_label_text(\"Giorno\")\n    ax1.yaxis.set_label_text(\"Casi\")\n    ax1.legend()\n    #ax1.xaxis.set_major_formatter(formatter_date)\n    if logplot:\n        ax1.set_ylim(0, 6)\n        ax1.yaxis.set_major_formatter(formatter_log10)\n    else:\n        ax1.set_ylim(0, 200000)\n    ax1.yaxis.grid(True, which='major')\n    ax1.yaxis.grid(True, which='minor')\n    \n    plt.show()\n    return\n\n\ndef plot_crossseries(title, xlabel, ylabel,\n                     Y1, Y2, Label, Y1_pred=[], Y2_pred=[], Fit=[]):\n    \n    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e']\n    fig = plt.figure()\n    \n    ax = fig.add_subplot(111)\n    plt.rcParams['figure.figsize'] = [20, 10]\n    plt.rc('font', size=14)\n    \n    if len(Y1_pred) > 0:\n        fit_active = True\n    else:\n        fit_active = False\n    \n    for idx, (y1, y2, label) in enumerate(zip(Y1, Y2, Label)):\n        #ax.scatter(y1, y2, marker='.', color=colors[idx], label=label)\n        ax.plot(y1, y2, marker='.', color=colors[idx], label=label)\n        \n        if fit_active:\n            y1_pred = Y1_pred[idx]\n            y2_pred = Y2_pred[idx]\n            fit = Fit[idx]\n            ax.plot(y1_pred, y2_pred, color=colors[idx], label=label)\n            #print(\"%s : % 5.2f %% deaths/total cases\" %(label, fit[0][0]*100))  \n              \n    ax.legend()\n    ax.set_title(title)\n    ax.xaxis.set_label_text(xlabel)\n    ax.yaxis.set_label_text(ylabel)\n    ax.xaxis.grid(True, which='major')\n    ax.xaxis.grid(True, which='minor')\n    ax.yaxis.grid(True, which='major')\n    ax.yaxis.grid(True, which='minor')\n    plt.show()\n    \n    return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"look\"></a>\n## Look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Caricamento dati\nif 1:\n    keys = ['Italia',\\\n            'Spain', \\\n            'Germany', \\\n            'France', \\\n            'US', \\\n            'China', \\\n            'Japan' \\\n            ]\nif 0:\n    keys = ['Italia',\\\n            'EmiliaRomagna', \\\n            'Lombardia', \\\n            'Veneto', \\\n            #'Parma', \\\n            #'Modena', \\\n            ]\nif 0:\n     keys = ['Italia']\n\n# Caricamento dati\ndf_cases, df_deaths, df_recovered, X, Y_cases, Y_deaths, Y_recovered, Label_cases, Label_deaths, Label_recovered =  load(keys)\n\n# Running average\nN = 5\nb = N*[1.0/N]\n\n# Plots\nif 1:\n    plot_crossseries(\"Crescita contagi vs contagi totali\", \"Cases\", \"New cases\", \\\n                     np.log10([Y_cases[i][1:] for i in range(len(Y_cases))]), \\\n                     np.log10(lfilter(b, [1.], np.diff(Y_cases))), \\\n                     Label_cases)\n\nif 0:\n    plot_crossseries(\"Crescita morti vs morti totali\", \"Cases\", \"New cases\", \\\n                     np.log10([Y_deaths[i][1:] for i in range(len(Y_deaths))]), \\\n                     np.log10(lfilter(b, [1.], np.diff(Y_deaths))), \\\n                     Label_deaths)\n\nif 0:\n    plot_crossseries(\"Morti vs casi totali\", \"Cases\", \"New cases\", \\\n                     np.log10(Y_cases), \\\n                     np.log10(lfilter(b, [1.], Y_deaths)), \\\n                     Label_deaths)\n\nif 1:\n    plot_crossseries(\"Crescita morti vs casi totali\", \"Cases\", \"New cases\", \\\n                     np.log10([Y_cases[i][1:] for i in range(len(Y_cases))]), \\\n                     np.log10(lfilter(b, [1.], np.diff(Y_deaths))), \\\n                     Label_deaths)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"run_regression\"></a>\n## Run regression models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Caricamento dati\nif 1:\n    keys = ['Italia',\\\n            'Spain', \\\n            'Germany', \\\n            'France', \\\n            'US', \\\n            'China'\n            ]\nif 0:\n    keys = ['Italia',\\\n            'EmiliaRomagna', \\\n            'Lombardia', \\\n            'Veneto', \\\n            #'Parma', \\\n            #'Modena', \\\n            ]\nif 0:\n     keys = ['Italia']\n\n# Caricamento dati\ndf_cases, df_deaths, df_recovered, X, Y_cases, Y_deaths, Y_recovered, Label_cases, Label_deaths, Label_recovered =  load(keys)\n\n# Previsione casi\ndays_ago = 0\nthreshold = 50\nX_pred_cases, Y_pred_cases, Fit_cases, Rmse_cases, End_date_cases = run_time_model(X, Y_cases, past=days_ago, horizon=90, threshold=threshold)\nX_pred_deaths, Y_pred_deaths, Fit_deaths, Rmse_deaths, End_date_deaths = run_time_model(X, Y_deaths, past=days_ago, horizon=90, threshold=threshold)\n\nif 1:\n    plot_timeseries(\"Casi\", True, threshold,\\\n                    X, Y_cases, X_pred_cases, Y_pred_cases, Label_cases)\n\n    print(\"Predicted end dates:\")\n    for i, date in enumerate(End_date_cases):\n        print(\"{}\\t\\t(as of {},\\t rmse={}):\\t{}\".format(Label_cases[i], daynumber2date(max(X[i])-days_ago), Rmse_cases[i], daynumber2date(date)))\n\n\n# Previsione morti\nif 0:\n    plot_timeseries(\"Morti\", True, threshold,\\\n                    X, Y_deaths, X_pred_deaths, Y_pred_deaths, Label_deaths)\n\n    print(\"Predicted end dates (deaths):\")\n    for i, date in enumerate(End_date_deaths):\n        print(\"{}\\t\\t(as of {},\\t rmse={}):\\t{}\".format(Label_deaths[i], daynumber2date(max(X[i])-days_ago), Rmse_deaths[i], daynumber2date(date)))\n\n\nif 0:\n    plot_timeseries2(\"Casi\", True, threshold,\\\n                     X, Y_cases, X_pred_cases, Y_pred_cases, Label_cases,\\\n                     X, Y_deaths, X_pred_deaths, Y_pred_deaths, Label_deaths, scale2=7.7)\n\n\n# Come varia la previsione nel tempo\nif 1:\n    run_time_model_timemachine(X, Y_cases, Label_cases, threshold=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"epi\"></a>\n# Epidemiological models"},{"metadata":{},"cell_type":"markdown","source":"## Load"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cases, df_deaths, df_recovered, X, Y_cases, Y_deaths, Y_recovered, Label_cases, Label_deaths, Label_recovered =  load([])\ndf_pop = load_population()\n\n\n\"\"\"\nInitial conditions\n\"\"\"\ndf_target_country = country(df_cases, df_deaths, df_recovered, \"Italy\")\ndf_target_country = trim_country(df_target_country)\ntarget_population = get_target_population(df_pop, 'Italy')\nprint(df_target_country)\nprint(target_population)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's take a look at the target country:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def altair_plot_for_confirmed_and_deaths(df_grouped: pd.DataFrame, data_at_x_axis: str='date') -> alt.Chart:\n    confirmed_plot = alt.Chart(df_grouped).mark_circle(size=60).encode(\n        x=alt.X(data_at_x_axis, axis=alt.Axis(title='Date')),\n        y=alt.Y('confirmed', axis=alt.Axis(title='Cases'), title='Confirmed'),\n        color=alt.Color(\"confirmed_marker\", title=\"Cases\"),\n    )\n\n    deaths_plot = alt.Chart(df_grouped).mark_circle(size=60).encode(\n        x=data_at_x_axis,\n        y='deaths',\n        color=alt.Color(\"deaths_marker\"),\n    )\n    \n    recovered_plot = alt.Chart(df_grouped).mark_circle(size=60).encode(\n        x=data_at_x_axis,\n        y='recovered',\n        color=alt.Color(\"recovered_marker\"),\n    )\n\n    return confirmed_plot + deaths_plot + recovered_plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"altair_plot_for_confirmed_and_deaths(df_target_country).interactive()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"models\"></a>\n## Epidemiology models\n\nNow, let me explore the data in order to calibrate an epidemiologic model in order to try to simulate and predict cases.\n\n### Classical models\n\nHere I present a brief review of classical temporal models (space dependency is not considered). Then I proposed modifications for such models.\n\n#### SIR model\n\nThe model represents an epidemic scenario, aiming to predict and control infectious diseases. It consists in a non-linear dynamical system, which considers populational sub-groups according to the state of the individuals. A simple model would be composed by 3 subgroups:\n\n* Susceptible individuals (S);\n* Infected (I);\n* Recovered (R).\n\nWith such components, a classical dynamical system known as SIR model. The equations of such a system is written as:\n\n\\begin{align*}\n  \\dot{S} &= - \\beta S I \\\\ \n  \\dot{I} &= \\beta S I - \\zeta I \\\\ \n  \\dot{R} &= \\zeta I\n\\end{align*}\n\nwhere $\\dot{(\\bullet)}$ stands for time-derivative.\n\nSome biological explanation for parameters:\n\n* $\\beta$ is the conversion parameter due to interaction between a susceptible individual with an infected one;\n* $\\zeta$ is the conversion parameter related to the recovery rate. In other words, the individuals that become immune;\n\n#### SEIR model\n\nAnother classical model known as SEIR (Susceptible-Exposed-Infected-Recovered) is common applied in Computational Epidemiology literature (you can check it elsewhere). In this model, a new sub-group of individuals is considered: Exposed. Such individuals are those that are infected, but don't show any sympton. In the classical SEIR model, exposed individuals **do not transmit the disease**. The ODE system now becomes:\n\n\\begin{align*}\n    \\dot{S} &= - \\beta S  I \\\\\n    \\dot{E} &= \\beta S I - \\alpha E \\\\\n    \\dot{I} &= \\alpha E - \\zeta I \\\\\n    \\dot{R} &= \\zeta I \\\\\n\\end{align*}\n\nBrief biological interpretation for additional parameter:\n\n* $\\alpha$ is the conversion parameter for exposed individuals that transformed into infected ones.\n\n### Modified models\n\nHere, I propose some simple modifications in order to improve model representability for COVID-19.\n\n#### Modified SIR model (SIRD)\n\nIn this model, deaths due to the disease is considered explicitly. A new individuals sub-group is introduced: dead individuals. To consider such phenomenon, an additional equation is required, as well as a modification in the Infected equation balance. The ODE system is given below:\n\n\\begin{align*}\n  \\dot{S} &= - \\beta S I \\\\ \n  \\dot{I} &= \\beta S I - \\zeta I - \\delta I \\\\ \n  \\dot{R} &= \\zeta I \\\\\n  \\dot{D} &= \\delta I\n\\end{align*}\n\nBrief biological interpretation for additional parameter:\n\n* $\\delta$ is the mortality rate for the disease.\n\n#### Modified SEIR model (SEIR-2)\n\nThis model aims to solve the lack of the original SEIR model, which does not consider disease transmission between exposed and susceptible individuals. In order to take it into account,\nwe modified balance equations for S and E as follows:\n\n\\begin{align*}\n    \\dot{S} &= - \\beta S  I  - \\gamma S E \\\\\n    \\dot{E} &= \\beta S I - \\alpha E + \\gamma S E \\\\\n    \\dot{I} &= \\alpha E - \\zeta I \\\\\n    \\dot{R} &= \\zeta I \\\\\n\\end{align*}\n\nBrief biological interpretation for additional parameter:\n\n* $\\gamma$ is the conversion rate parameter for susceptible individuals that interact with exposed individuals and then become exposed.\n\n#### Modified SEIR model with deaths (SEIRD)\n\nVery similiar to the last one, but it considers a sub-population of dead individuals due to the disease. Thus, the model is written as:\n\n\\begin{align*}\n    \\dot{S} &= - \\beta S  I  - \\gamma S E \\\\\n    \\dot{E} &= \\beta S I - \\alpha E + \\gamma S E \\\\\n    \\dot{I} &= \\alpha E - \\zeta I - \\delta I \\\\\n    \\dot{R} &= \\zeta I \\\\\n    \\dot{D} &= \\delta I\n\\end{align*}\n\n#### Modified SEIRD model considering quarantine lockdown (SEIRD-Q)\n\nThis is a modified model that take into account a removal rate from Susceptible, Exposed and Infected individuals to quarantine. The main hypothesis is that this conversion\nis under a constant removal parameter (by time, i.e., 1 / time), and after the conversion, the individual becomes \"Recovered\" and can not transmit the disease anymore. The new system is written as\n\n\\begin{align*}\n    \\dot{S} &= - \\beta S  I  - \\gamma S E - \\omega S\\\\\n    \\dot{E} &= \\beta S I - \\alpha E + \\gamma S E - \\omega E \\\\\n    \\dot{I} &= \\alpha E - \\zeta I - \\delta I - \\omega I \\\\\n    \\dot{R} &= \\zeta I + \\omega (S + E + I) \\\\\n    \\dot{D} &= \\delta I\n\\end{align*}\n\nBrief biological interpretation for additional parameter:\n\n* $\\omega$ is the conversion rate parameter for Susceptible, Exposed and Infected individuals that becomes Recovered due to a removal to a quarantine.\n\n### Remarks for the models units\n\nAll sub-population variables (S, I, R, etc) are dimensionless. To obtain the variables, we have to consider that\n\n\\begin{align*}\n    &S := \\frac{\\mathcal{S}}{N} \\\\\n    &E := \\frac{\\mathcal{E}}{N} \\\\\n    &I := \\frac{\\mathcal{I}}{N} \\\\\n    &R := \\frac{\\mathcal{R}}{N} \\\\\n    &D := \\frac{\\mathcal{D}}{N} \\\\\n\\end{align*}\n\nwith $N$ denoting the total population and $\\mathcal{S}$, $\\mathcal{E}$, $\\mathcal{I}$, $\\mathcal{R}$ and $\\mathcal{D}$ as the absolute sub-population amounts. Therefore, S, E, I, R and D are given as fractions of the total population."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"implementations\"></a>\n## Programming SIR/SEIR-based models in Python"},{"metadata":{"trusted":true},"cell_type":"code","source":"@jit(nopython=True)\ndef sir_model(t, X, beta=1, zeta=1/15):\n    S, I, R = X\n    S_prime = - beta * S * I\n    I_prime = beta * S * I - zeta * I\n    R_prime = zeta * I\n    return S_prime, I_prime, R_prime\n\n\n@jit(nopython=True)\ndef sird_model(t, X, beta=1, delta=0.02, zeta=1/15):\n    \"\"\"\n    SIR model that takes into account the number of deaths.\n    \"\"\"\n    S, I, R, D = X\n    S_prime = - beta * S * I\n    I_prime = beta * S * I - zeta * I - delta * I\n    R_prime = zeta * I\n    D_prime = delta * I\n    return S_prime, I_prime, R_prime, D_prime\n\n\n@jit(nopython=True)\ndef seir2_model(t, X, alpha=1/5, beta=1, gamma=0, zeta=1/15, delta=0.02):\n    \"\"\"\n    This is a modified SEIR model in order to take into account incubation time in exposed individual.\n    The exposed individuals can transmit the infection to susceptible individuals.\n    \"\"\"\n    S, E, I, R = X\n    S_prime = - beta * S * I - gamma * E * S\n    E_prime = beta * S * I - alpha * E + gamma * E * S\n    I_prime = alpha * E - zeta * I - delta * I\n    R_prime = zeta * I\n    return S_prime, E_prime, I_prime, R_prime\n\n\n@jit(nopython=True)\ndef seird_model(t, X, alpha=1/5, beta=1, gamma=0, zeta=1/15, delta=0.02):\n    \"\"\"\n    A modified SEIR model in order to take into account deaths.\n    \"\"\"\n    S, E, I, R, D = X\n    S_prime = - beta * S * I - gamma * E * S\n    E_prime = beta * S * I - alpha * E + gamma * E * S\n    I_prime = alpha * E - zeta * I - delta * I\n    R_prime = zeta * I\n    D_prime = delta * I\n    return S_prime, E_prime, I_prime, R_prime, D_prime\n\n\n@jit(nopython=True)\ndef seirdq_model(t, X, alpha=1/5, beta=1, gamma=0, omega=0, zeta=1/15, delta=0.02):\n    \"\"\"\n    A modified SEIRD model in order to take into account quarantine.\n    \"\"\"\n    S, E, I, R, D = X\n    S_prime = - beta * S * I - gamma * E * S - omega * S\n    E_prime = beta * S * I - alpha * E + gamma * E * S - omega * E\n    I_prime = alpha * E - zeta * I - delta * I - omega * I\n    R_prime = zeta * I + omega * (S + E + I)\n    D_prime = delta * I\n    return S_prime, E_prime, I_prime, R_prime, D_prime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ODE solvers wrappers using `scipy.integrate.solve_ivp`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sir_ode_solver(y0, t_span, t_eval, beta=1, zeta=1/14):\n    solution_ODE = solve_ivp(\n        fun=lambda t, y: sir_model(t, y, beta=beta, zeta=zeta), \n        t_span=t_span, \n        y0=y0,\n        t_eval=t_eval,\n        method='LSODA'\n    )\n    \n    return solution_ODE\n\n\ndef sird_ode_solver(y0, t_span, t_eval, beta=1, delta=0.02, zeta=1/14):\n    solution_ODE = solve_ivp(\n        fun=lambda t, y: sird_model(t, y, beta=beta, zeta=zeta, delta=delta), \n        t_span=t_span, \n        y0=y0,\n        t_eval=t_eval,\n        method='LSODA'\n    )\n    \n    return solution_ODE\n\n\ndef seir_ode_solver(y0, t_span, t_eval, beta=1, gamma=0, alpha=1/4, zeta=1/14, delta=0.0):\n    solution_ODE = solve_ivp(\n        fun=lambda t, y: seir2_model(t, y, alpha=alpha, beta=beta, gamma=gamma, zeta=zeta, delta=delta), \n        t_span=t_span, \n        y0=y0,\n        t_eval=t_eval,\n        method='LSODA'\n    )\n    \n    return solution_ODE\n\n\ndef seird_ode_solver(y0, t_span, t_eval, beta=1, gamma=0, delta=0.02, alpha=1/4, zeta=1/14):\n    solution_ODE = solve_ivp(\n        fun=lambda t, y: seird_model(t, y, alpha=alpha, beta=beta, gamma=gamma, zeta=zeta, delta=delta), \n        t_span=t_span, \n        y0=y0,\n        t_eval=t_eval,\n        method='LSODA'\n    )\n    \n    return solution_ODE\n\n\ndef seirdq_ode_solver(y0, t_span, t_eval, beta=1, gamma=0, delta=0.02, omega=0, alpha=1/4, zeta=1/14):\n    solution_ODE = solve_ivp(\n        fun=lambda t, y: seirdq_model(t, y, alpha=alpha, beta=beta, gamma=gamma, omega=omega, zeta=zeta, delta=delta), \n        t_span=t_span, \n        y0=y0,\n        t_eval=t_eval,\n        method='LSODA'\n    )\n    \n    return solution_ODE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll assume that the whole country's population is suscetible. So I can define the following initial conditions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"S0, E0, I0, R0, D0 = target_population, 5 * float(df_target_country.confirmed[0]), float(df_target_country.confirmed[0]), 0., 0.\n\ny0_sir = S0 / target_population, I0 / target_population, R0  # SIR IC array\ny0_sird = S0 / target_population, I0 / target_population, R0, D0  # SIRD IC array\ny0_seir = S0 / target_population, E0 / target_population, I0 / target_population, R0  # SEIR IC array\ny0_seird = S0 / target_population, E0 / target_population, I0 / target_population, R0, D0  # SEIRD IC array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select the models to run setting bool variables below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"has_to_run_sir = False\nhas_to_run_sird = False\nhas_to_run_seir = False\nhas_to_run_seird = True\nhas_to_run_seirdq = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"least-squares\"></a>\n## Least-Squares fitting\n\nNow, we can know how to solve the forward problem, so we can try to fit it with a non-linear Least-Squares method for parameter estimation. Let's begin with a generic Least-Square formulation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sir_least_squares_error_ode(par, time_exp, f_exp, fitting_model, initial_conditions):\n    args = par\n    time_span = (time_exp.min(), time_exp.max())\n    \n    y_model = fitting_model(initial_conditions, time_span, time_exp, *args)\n    simulated_time = y_model.t\n    simulated_ode_solution = y_model.y\n    _, simulated_qoi, _ = simulated_ode_solution\n    \n    residual = f_exp - simulated_qoi\n\n    return np.sum(residual ** 2.0)\n\n\ndef sird_least_squares_error_ode(par, time_exp, f_exp, fitting_model, initial_conditions):\n    args = par\n    f_exp1, f_exp2 = f_exp\n    time_span = (time_exp.min(), time_exp.max())\n    \n    y_model = fitting_model(initial_conditions, time_span, time_exp, *args)\n    simulated_time = y_model.t\n    simulated_ode_solution = y_model.y\n    _, simulated_qoi1, _, simulated_qoi2 = simulated_ode_solution\n    \n    residual1 = f_exp1 - simulated_qoi1\n    residual2 = f_exp2 - simulated_qoi2\n\n    weighting_for_exp1_constraints = 1e0\n    weighting_for_exp2_constraints = 1e0\n    return weighting_for_exp1_constraints * np.sum(residual1 ** 2.0) + weighting_for_exp2_constraints * np.sum(residual2 ** 2.0)\n\n\ndef seir_least_squares_error_ode(par, time_exp, f_exp, fitting_model, initial_conditions):\n    args = par\n    time_span = (time_exp.min(), time_exp.max())\n    \n    y_model = fitting_model(initial_conditions, time_span, time_exp, *args)\n    simulated_time = y_model.t\n    simulated_ode_solution = y_model.y\n    _, _, simulated_qoi, _ = simulated_ode_solution\n    \n    residual = f_exp - simulated_qoi\n\n    return np.sum(residual ** 2.0)\n\n\ndef seird_least_squares_error_ode(par, time_exp, f_exp, fitting_model, initial_conditions):\n    args = par\n    f_exp1, f_exp2 = f_exp\n    time_span = (time_exp.min(), time_exp.max())\n    \n    y_model = fitting_model(initial_conditions, time_span, time_exp, *args)\n    simulated_time = y_model.t\n    simulated_ode_solution = y_model.y\n    _, _, simulated_qoi1, _, simulated_qoi2 = simulated_ode_solution\n    \n    residual1 = f_exp1 - simulated_qoi1\n    residual2 = f_exp2 - simulated_qoi2\n\n    weighting_for_exp1_constraints = 1e0\n    weighting_for_exp2_constraints = 1e0\n    return weighting_for_exp1_constraints * np.sum(residual1 ** 2.0) + weighting_for_exp2_constraints * np.sum(residual2 ** 2.0)\n\n\ndef callback_de(xk, convergence):\n    print(f'parameters = {xk}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting fitting domain (given time for each observation) and the observations (observed population at given time):"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_time = df_target_country.day.values.astype(np.float64)\ninfected_individuals = df_target_country.confirmed.values / target_population\ndead_individuals = df_target_country.deaths.values / target_population\nrecovered_individuals = df_target_country.recovered.values / target_population","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To calibrate the model, we define an objective function, which is a Least-Squares function in the present case, and minimize it. To (*try to*) avoid local minima, we use Differential Evolution (DE) method (see this [nice presentation](https://www.maths.uq.edu.au/MASCOS/Multi-Agent04/Fleetwood.pdf) to get yourself introduced to this great subject). In summary, DE is a family of Evolutionary Algorithms that aims to solve Global Optimization problems. Moreover, DE is derivative-free and population-based method.\n\nBelow, calibration is performed for selected models:"},{"metadata":{"trusted":true},"cell_type":"code","source":"if has_to_run_sir:\n    num_of_parameters_to_fit_sir = 1\n    bounds_sir = num_of_parameters_to_fit_sir * [(0, 1)]\n\n    result_sir = optimize.differential_evolution(\n        sir_least_squares_error_ode, \n        bounds=bounds_sir, \n        args=(data_time, infected_individuals, sir_ode_solver, y0_sir), \n        popsize=300,\n        strategy='best1bin',\n        tol=1e-2,\n        recombination=0.5,\n#         mutation=0.7,\n        maxiter=100,\n        disp=True,\n        seed=seed,\n        callback=callback_de,\n        workers=-1\n    )\n\n    print(result_sir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if has_to_run_sird:\n    # num_of_parameters_to_fit_sir = 1\n    # bounds_sir = num_of_parameters_to_fit_sir * [(0, 1)]\n    bounds_sird = [(0, 1), (0, 0.2)]\n\n    result_sird = optimize.differential_evolution(\n        sird_least_squares_error_ode, \n        bounds=bounds_sird, \n        args=(data_time, [infected_individuals, dead_individuals], sird_ode_solver, y0_sird), \n        popsize=300,\n        strategy='best1bin',\n        tol=1e-2,\n        recombination=0.5,\n    #     mutation=0.7,\n        maxiter=100,\n        disp=True,\n        seed=seed,\n        callback=callback_de,\n        workers=-1\n    )\n\n    print(result_sird)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if has_to_run_seird:\n    num_of_parameters_to_fit_sir = 1\n    # bounds_sir = num_of_parameters_to_fit_sir * [(0, 1)]\n    bounds_seird = [(0, 1), (0, 1), (0, 0.2)]\n\n    result_seird = optimize.differential_evolution(\n        seird_least_squares_error_ode, \n        bounds=bounds_seird, \n        args=(data_time, [infected_individuals, dead_individuals], seird_ode_solver, y0_seird), \n        popsize=300,\n        strategy='best1bin',\n        tol=1e-2,\n        recombination=0.7,\n    #     mutation=0.7,\n        maxiter=100,\n        disp=True,\n        seed=seed,\n        callback=callback_de,\n        workers=-1\n    )\n\n    print(result_seird)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if has_to_run_seirdq:\n#     num_of_parameters_to_fit_sir = 1\n    # bounds_sir = num_of_parameters_to_fit_sir * [(0, 1)]\n    bounds_seird = [(0, 1), (0, 1), (0, 0.2), (0, 1)]\n\n    result_seirdq = optimize.differential_evolution(\n        seird_least_squares_error_ode, \n        bounds=bounds_seird, \n        args=(data_time, [infected_individuals, dead_individuals], seirdq_ode_solver, y0_seird), \n        popsize=200,\n        strategy='best1bin',\n        tol=1e-2,\n        recombination=0.7,\n    #     mutation=0.7,\n        maxiter=200,\n        disp=True,\n        seed=seed,\n        callback=callback_de,\n        workers=-1\n    )\n\n    print(result_seirdq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if has_to_run_seir:\n    num_of_parameters_to_fit_seir = 2\n    bounds_seir = num_of_parameters_to_fit_seir * [(0, 1)]\n\n    result_seir = optimize.differential_evolution(\n        seir_least_squares_error_ode, \n        bounds=bounds_seir, \n        args=(data_time, infected_individuals, seir_ode_solver, y0_seir), \n        popsize=300,\n        strategy='best1bin',\n        tol=1e-2,\n        recombination=0.7,\n#         mutation=0.7,\n        maxiter=100,\n        disp=True,\n        seed=seed,\n        callback=callback_de,\n        workers=-1\n    )\n\n    print(result_seir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zeta_fitted = 1/14  # recover rate... the inverse is equal to the amount of days needed to recover from the disease\nif has_to_run_sir:\n    beta_fitted_sir = result_sir.x  # SIR parameters\n    \nif has_to_run_sird:\n    beta_fitted_sird, delta_fitted_sird = result_sird.x  # SIRD parameters\n    \nalpha_fitted = 1/4\nif has_to_run_seird:\n    beta_fitted_seird, gamma_fitted_seird, delta_fitted_seird = result_seird.x  # SEIRD parameters\n    \nif has_to_run_seirdq:\n    beta_fitted_seirdq, gamma_fitted_seirdq, delta_fitted_seirdq, omega_fitted_seirdq = result_seirdq.x  # SEIRD parameters\n\nif has_to_run_seir:\n#     beta_fitted_seir, gamma_fitted_seir = result_seir.x  # SEIR parameters\n#     gamma_fitted_seir = 0.0\n    beta_fitted_seir, gamma_fitted_seir = result_seir.x  # SEIR parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = data_time.min()\ntf = data_time.max()\n\nif has_to_run_sir:\n    solution_ODE_sir = sir_ode_solver(y0_sir, (t0, tf), data_time, beta_fitted_sir, zeta_fitted)  # SIR\n    t_computed_sir, y_computed_sir = solution_ODE_sir.t, solution_ODE_sir.y\n    S_sir, I_sir, R_sir = y_computed_sir\n\nif has_to_run_sird:\n    solution_ODE_sird = sird_ode_solver(y0_sird, (t0, tf), data_time, beta_fitted_sird, delta_fitted_sird, zeta_fitted)  # SIRD\n    t_computed_sird, y_computed_sird = solution_ODE_sird.t, solution_ODE_sird.y\n    S_sird, I_sird, R_sird, D_sird = y_computed_sird\n\nif has_to_run_seird:\n    solution_ODE_seird = seird_ode_solver(y0_seird, (t0, tf), data_time, beta_fitted_seird, gamma_fitted_seird, delta_fitted_seird, alpha_fitted, zeta_fitted)  # SEIRD\n    t_computed_seird, y_computed_seird = solution_ODE_seird.t, solution_ODE_seird.y\n    S_seird, E_seird, I_seird, R_seird, D_seird = y_computed_seird\n\nif has_to_run_seirdq:\n    solution_ODE_seirdq = seirdq_ode_solver(\n        y0_seird, \n        (t0, tf), \n        data_time, \n        beta_fitted_seirdq, \n        gamma_fitted_seirdq, \n        delta_fitted_seirdq, \n        omega_fitted_seirdq, \n        alpha_fitted, \n        zeta_fitted\n    )\n    t_computed_seirdq, y_computed_seirdq = solution_ODE_seirdq.t, solution_ODE_seirdq.y\n    S_seirdq, E_seirdq, I_seirdq, R_seirdq, D_seirdq = y_computed_seirdq\n    \nif has_to_run_seir:\n    solution_ODE_seir = seir_ode_solver(y0_seir, (t0, tf), data_time, beta_fitted_seir, gamma_fitted_seir, alpha_fitted,  zeta_fitted)  # SEIR\n    t_computed_seir, y_computed_seir = solution_ODE_seir.t, solution_ODE_seir.y\n    S_seir, E_seir, I_seir, R_seir = y_computed_seir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list = list()\nalpha_list = list()\nbeta_list = list()\ndelta_list = list()\ngamma_list = list()\nomega_list = list()\nzeta_list = list()\n\nif has_to_run_sir:\n    model_list.append(\"SIR\")\n    alpha_list.append(\"-\")\n    beta_list.append(np.float(beta_fitted_sir))\n    delta_list.append(\"-\")\n    gamma_list.append(\"-\")\n    omega_list.append(\"-\")\n    zeta_list.append(zeta_fitted)\n\nif has_to_run_sird:\n    model_list.append(\"SIRD\")\n    alpha_list.append(\"-\")\n    beta_list.append(beta_fitted_sird)\n    delta_list.append(delta_fitted_sird)\n    gamma_list.append(\"-\")\n    omega_list.append(\"-\")\n    zeta_list.append(zeta_fitted)\n    \nif has_to_run_seir:\n    model_list.append(\"SEIR\")\n    alpha_list.append(alpha_fitted)\n    beta_list.append(beta_fitted_seir)\n    delta_list.append(\"-\")\n    gamma_list.append(gamma_fitted_seir)\n    omega_list.append(\"-\")\n    zeta_list.append(zeta_fitted)\n\nif has_to_run_seird:\n    model_list.append(\"SEIRD\")\n    alpha_list.append(alpha_fitted)\n    beta_list.append(beta_fitted_seird)\n    delta_list.append(delta_fitted_seird)\n    gamma_list.append(gamma_fitted_seird)\n    omega_list.append(\"-\")\n    zeta_list.append(zeta_fitted)\n\nif has_to_run_seirdq:\n    model_list.append(\"SEIRD-Q\")\n    alpha_list.append(alpha_fitted)\n    beta_list.append(beta_fitted_seirdq)\n    delta_list.append(delta_fitted_seirdq)\n    gamma_list.append(gamma_fitted_seirdq)\n    omega_list.append(omega_fitted_seirdq)\n    zeta_list.append(zeta_fitted)\n    \nparameters_dict = {\n    \"Model\": model_list,\n    r\"$\\alpha$\": alpha_list,\n    r\"$\\beta$\": beta_list,\n    r\"$\\delta$\": delta_list,\n    r\"$\\gamma$\": gamma_list,\n    r\"$\\omega$\": omega_list,\n    r\"$\\zeta$\": zeta_list,\n}\n\ndf_parameters_calibrated = pd.DataFrame(parameters_dict)\n\ndf_parameters_calibrated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_parameters_calibrated.to_latex(index=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show calibration result based on available data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,7))\n\nif has_to_run_sir:\n    plt.plot(t_computed_sir, I_sir * target_population, label='Infected (SIR)', marker='v', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_sir, R_sir * target_population, label='Recovered (SIR)', marker='o', linestyle=\"-\", markersize=10)\n    \nif has_to_run_sird:\n    plt.plot(t_computed_sird, I_sird * target_population, label='Infected (SIRD)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_sird, R_sird * target_population, label='Recovered (SIRD)', marker='o', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_sird, D_sird * target_population, label='Deaths (SIRD)', marker='s', linestyle=\"-\", markersize=10)\n    \nif has_to_run_seird:\n    plt.plot(t_computed_seird, I_seird * target_population, label='Infected (SEIRD)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_seird, R_seird * target_population, label='Recovered (SEIRD)', marker='o', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_seird, D_seird * target_population, label='Deaths (SEIRD)', marker='s', linestyle=\"-\", markersize=10)\n    \nif has_to_run_seirdq:\n    plt.plot(t_computed_seirdq, I_seirdq * target_population, label='Infected (SEIRD-Q)', marker='X', linestyle=\"-\", markersize=10)\n#     plt.plot(t_computed_seirdq, R_seirdq * target_population, label='Recovered (SEIRD-Q)', marker='o', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_seirdq, D_seirdq * target_population, label='Deaths (SEIRD-Q)', marker='s', linestyle=\"-\", markersize=10)\n\nif has_to_run_seir:\n    plt.plot(t_computed_seir, I_seir * target_population, label='Infected (SEIR)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_seir, R_seir * target_population, label='Recovered (SEIR)', marker='o', linestyle=\"-\", markersize=10)\n    \nplt.plot(data_time, infected_individuals * target_population, label='Observed infected', marker='s', linestyle=\"\", markersize=10)\nplt.plot(data_time, dead_individuals * target_population, label='Recorded deaths', marker='v', linestyle=\"\", markersize=10)\nplt.plot(data_time, recovered_individuals * target_population, label='Recorded recovered', marker='v', linestyle=\"\", markersize=10)\nplt.legend()\nplt.grid()\nplt.xlabel('Time (days)')\nplt.ylabel('Population')\n\nplt.tight_layout()\nplt.savefig(\"all_deterministic_calibration.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"methods_list = list()\ndeaths_list = list()\nif has_to_run_sird:\n    methods_list.append(\"SIRD\")\n    deaths_list.append(int(D_sird.max() * target_population))\n    print(f\"Death estimate for today (SIRD):\\t{int(D_sird.max() * target_population)}\")\n    \nif has_to_run_seird:\n    methods_list.append(\"SEIRD\")\n    deaths_list.append(int(D_seird.max() * target_population))\n    print(f\"Death estimate for today (SEIRD):\\t{int(D_seird.max() * target_population)}\")\n    \nif has_to_run_seirdq:\n    methods_list.append(\"SEIRD-Q\")\n    deaths_list.append(int(D_seirdq.max() * target_population))\n    print(f\"Death estimate for today (SEIRD-Q):\\t{int(D_seirdq.max() * target_population)}\")\n\nmethods_list.append(\"Recorded\")\ndeaths_list.append(int(dead_individuals[-1] * target_population))\n\ndeath_estimates_dict = {\"Method\": methods_list, \"Deaths estimate\": deaths_list}\ndf_deaths_estimates = pd.DataFrame(death_estimates_dict)\nprint(f\"Recorded deaths until today:\\t{int(dead_individuals[-1] * target_population)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_deaths_estimates.set_index(\"Model\", inplace=True)\nprint(df_deaths_estimates.to_latex(index=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"deterministic-predictions\"></a>\n## Extrapolation/Predictions\n\nNow, let's extrapolate to next days."},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = float(data_time.min())\nnumber_of_days_after_last_record = 90\ntf = data_time.max() + number_of_days_after_last_record\ntime_range = np.linspace(0., tf, int(tf))\n\nif has_to_run_sir:\n    solution_ODE_predict_sir = sir_ode_solver(y0_sir, (t0, tf), time_range, beta_fitted_sir, zeta_fitted)  # SIR\n    t_computed_predict_sir, y_computed_predict_sir = solution_ODE_predict_sir.t, solution_ODE_predict_sir.y\n    S_predict_sir, I_predict_sir, R_predict_sir = y_computed_predict_sir\n\nif has_to_run_sird:\n    solution_ODE_predict_sird = sird_ode_solver(y0_sird, (t0, tf), time_range, beta_fitted_sird, delta_fitted_sird, zeta_fitted)  # SIR\n    t_computed_predict_sird, y_computed_predict_sird = solution_ODE_predict_sird.t, solution_ODE_predict_sird.y\n    S_predict_sird, I_predict_sird, R_predict_sird, D_predict_sird = y_computed_predict_sird\n\nif has_to_run_seird:\n    solution_ODE_predict_seird = seird_ode_solver(y0_seird, (t0, tf), time_range, beta_fitted_seird, gamma_fitted_seird, delta_fitted_seird, alpha_fitted, zeta_fitted)  # SEIRD\n    t_computed_predict_seird, y_computed_predict_seird = solution_ODE_predict_seird.t, solution_ODE_predict_seird.y\n    S_predict_seird, E_predict_seird, I_predict_seird, R_predict_seird, D_predict_seird = y_computed_predict_seird\n    \nif has_to_run_seirdq:\n    solution_ODE_predict_seirdq = seirdq_ode_solver(y0_seird, (t0, tf), time_range, beta_fitted_seirdq, gamma_fitted_seirdq, delta_fitted_seirdq, omega_fitted_seirdq, alpha_fitted, zeta_fitted)  # SEIRD\n    t_computed_predict_seirdq, y_computed_predict_seirdq = solution_ODE_predict_seirdq.t, solution_ODE_predict_seirdq.y\n    S_predict_seirdq, E_predict_seirdq, I_predict_seirdq, R_predict_seirdq, D_predict_seirdq = y_computed_predict_seirdq\n\nif has_to_run_seir:\n    solution_ODE_predict_seir = seir_ode_solver(y0_seir, (t0, tf), time_range, beta_fitted_seir, gamma_fitted_seir, alpha_fitted, zeta_fitted)  # SEIR\n    t_computed_predict_seir, y_computed_predict_seir = solution_ODE_predict_seir.t, solution_ODE_predict_seir.y\n    S_predict_seir, E_predict_seir, I_predict_seir, R_predict_seir = y_computed_predict_seir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating the day when the number of infected individuals is max:"},{"metadata":{"trusted":true},"cell_type":"code","source":"has_to_plot_infection_peak = True\n\nif has_to_run_sir:\n    crisis_day_sir = np.argmax(I_predict_sir)\n    \nif has_to_run_sird:\n    crisis_day_sird = np.argmax(I_predict_sird)\n\nif has_to_run_seir:\n    crisis_day_seir = np.argmax(I_predict_seir)\n    \nif has_to_run_seird:\n    crisis_day_seird = np.argmax(I_predict_seird)\n    \nif has_to_run_seirdq:\n    crisis_day_seirdq = np.argmax(I_predict_seirdq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,7))\n\nif has_to_run_sir:\n    plt.plot(t_computed_predict_sir, 100 * S_predict_sir, label='Susceptible (SIR)', marker='s', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_sir, 100 * I_predict_sir, label='Infected (SIR)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_sir, 100 * R_predict_sir, label='Recovered (SIR)', marker='o', linestyle=\"-\", markersize=10)\n    if has_to_plot_infection_peak:\n        plt.axvline(x=crisis_day_sir + 1, color=\"red\", linestyle=\"--\", label=\"Infected peak (SIR)\")\n    \nif has_to_run_sird:\n    plt.plot(t_computed_predict_sird, 100 * S_predict_sird, label='Susceptible (SIRD)', marker='s', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_sird, 100 * I_predict_sird, label='Infected (SIRD)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_sird, 100 * R_predict_sird, label='Recovered (SIRD)', marker='o', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_sird, 100 * D_predict_sird, label='Deaths (SIRD)', marker='v', linestyle=\"-\", markersize=10)\n    if has_to_plot_infection_peak:\n        plt.axvline(x=crisis_day_sird + 1, color=\"red\", linestyle=\"--\", label=\"Infected peak (SIRD)\")\n\nif has_to_run_seird:\n    plt.plot(t_computed_predict_seird, 100 * S_predict_seird, label='Susceptible (SEIRD)', marker='s', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seird, 100 * E_predict_seird, label='Exposed (SEIRD)', marker='*', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seird, 100 * I_predict_seird, label='Infected (SEIRD)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seird, 100 * R_predict_seird, label='Recovered (SEIRD)', marker='o', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seird, 100 * D_predict_seird, label='Deaths (SEIRD)', marker='v', linestyle=\"-\", markersize=10)\n    if has_to_plot_infection_peak:\n        plt.axvline(x=crisis_day_seird + 1, color=\"red\", label=\"Infected peak (SEIRD)\")\n    \nif has_to_run_seirdq:\n    plt.plot(t_computed_predict_seirdq, 100 * S_predict_seirdq, label='Susceptible (SEIRD-Q)', marker='s', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seirdq, 100 * E_predict_seirdq, label='Exposed (SEIRD-Q)', marker='*', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seirdq, 100 * I_predict_seirdq, label='Infected (SEIRD-Q)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seirdq, 100 * R_predict_seirdq, label='Recovered (SEIRD-Q)', marker='o', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seirdq, 100 * D_predict_seirdq, label='Deaths (SEIRD-Q)', marker='v', linestyle=\"-\", markersize=10)\n    if has_to_plot_infection_peak:\n        plt.axvline(x=crisis_day_seirdq + 1, color=\"red\", label=\"Infected peak (SEIRD-Q)\")\n\nif has_to_run_seir:\n    plt.plot(t_computed_predict_seir, 100 * S_predict_seir, label='Susceptible (SEIR)', marker='s', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seir, 100 * E_predict_seir, label='Exposed (SEIR)', marker='*', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seir, 100 * I_predict_seir, label='Infected (SEIR)', marker='X', linestyle=\"-\", markersize=10)\n    plt.plot(t_computed_predict_seir, 100 * R_predict_seir, label='Recovered (SEIR)', marker='o', linestyle=\"-\", markersize=10)\n    if has_to_plot_infection_peak:\n        plt.axvline(x=crisis_day_seir + 1, color=\"red\", linestyle=\"--\", label=\"Infected peak (SEIR)\")\n\nplt.xlabel('Time (days)')\nplt.ylabel('Population %')\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.savefig(\"seir_deterministic_predictions.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if has_to_run_sir:\n    print(f\"Max number of infected individuals (SIR model):\\t {int(np.max(I_predict_sir) * target_population)}\")\n    print(f\"Population percentage of max number of infected individuals (SIR model):\\t {np.max(I_predict_sir) * 100:.2f}%\")\n    print(f\"Day estimate for max number of infected individuals (SIR model):\\t {crisis_day_sir + 1}\")\n    print(\"\")\n\nif has_to_run_sird:\n    print(f\"Max number of infected individuals (SIRD model):\\t {int(np.max(I_predict_sird) * target_population)}\")\n    print(f\"Population percentage of max number of infected individuals (SIRD model):\\t {np.max(I_predict_sird) * 100:.2f}%\")\n    print(f\"Day estimate for max number of infected individuals (SIRD model):\\t {crisis_day_sird + 1}\")\n    print(f\"Percentage of number of death estimate (SIRD model):\\t {100 * D_predict_sird[-1]:.3f}%\")\n    print(f\"Number of death estimate (SIRD model):\\t {target_population * D_predict_sird[-1]:.3f}\")\n    print(\"\")\n\nif has_to_run_seir:\n    print(f\"Max number of infected individuals (SEIR model):\\t {int(np.max(I_predict_seir) * target_population)}\")\n    print(f\"Population percentage of max number of infected individuals (SEIR model):\\t {np.max(I_predict_seir) * 100:.2f}%\")\n    print(f\"Day estimate for max number of infected individuals (SEIR model):\\t {crisis_day_seir + 1}\")\n    print(\"\")\n    \nif has_to_run_seird:\n    print(f\"Max number of infected individuals (SEIRD model):\\t {int(np.max(I_predict_seird) * target_population)}\")\n    print(f\"Population percentage of max number of infected individuals (SEIRD model):\\t {np.max(I_predict_seird) * 100:.2f}%\")\n    print(f\"Day estimate for max number of infected individuals (SEIRD model):\\t {crisis_day_seird + 1}\")\n    print(f\"Percentage of number of death estimate (SEIRD model):\\t {100 * D_predict_seird[-1]:.3f}%\")\n    print(f\"Number of death estimate (SEIRD model):\\t {target_population * D_predict_seird[-1]:.3f}\")\n    print(\"\")\n    \nif has_to_run_seirdq:\n    print(f\"Max number of infected individuals (SEIRD-Q model):\\t {int(np.max(I_predict_seirdq) * target_population)}\")\n    print(f\"Population percentage of max number of infected individuals (SEIRD-Q model):\\t {np.max(I_predict_seirdq) * 100:.2f}%\")\n    print(f\"Day estimate for max number of infected individuals (SEIRD-Q model):\\t {crisis_day_seirdq + 1}\")\n    print(f\"Percentage of number of death estimate (SEIRD-Q model):\\t {100 * D_predict_seirdq[-1]:.3f}%\")\n    print(f\"Number of death estimate (SEIRD-Q model):\\t {target_population * D_predict_seirdq[-1]:.3f}\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bayes-calibration\"></a>\n## Bayesian Calibration\n\nNow that we have an idea of the values that we must expect (i.e., some prior knowledge), we can properly apply a Bayesian model calibration. This way, we can estimate uncertainties on our models parameters and outcomes/predictions. For such purpose, we'll use the great [PyMC3](https://docs.pymc.io/) package."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bayes-sir\"></a>\n### SIR Model\n\nLet's begin with easy :) Just one parameter!"},{"metadata":{"trusted":true},"cell_type":"code","source":"@theano.compile.ops.as_op(itypes=[t.dvector, t.dvector, t.dvector, t.dscalar], otypes=[t.dvector])\ndef sir_ode_solver_wrapper(time_exp, f_observations, initial_conditions, beta):\n    time_span = (time_exp.min(), time_exp.max())\n    \n    zeta = 1/14\n    y_model = sir_ode_solver(initial_conditions, time_span, time_exp, beta, zeta)\n    simulated_time = y_model.t\n    simulated_ode_solution = y_model.y\n    _, simulated_qoi, _ = simulated_ode_solution\n\n    return simulated_qoi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with pm.Model() as model_mcmc:\n    # Prior distributions for the model's parameters\n    beta = pm.Uniform('beta', lower=0.2, upper=0.4)\n\n    # Defining the deterministic formulation of the problem\n    fitting_model = pm.Deterministic('sir_model', sir_ode_solver_wrapper(\n        theano.shared(data_time), \n        theano.shared(infected_individuals), \n        theano.shared(np.array(y0_sir)),\n        beta,\n        )\n    )\n\n    # Variance related to population fraction amount! Let's assume a variance of 100 individuals, since there are cases that have been not tracked\n    variance = (100 / target_population) * (100 / target_population)\n    standard_deviation = np.sqrt(variance)\n    likelihood_model = pm.Normal('likelihood_model', mu=fitting_model, sigma=standard_deviation, observed=infected_individuals)\n\n    # The Monte Carlo procedure driver\n    step = pm.step_methods.Metropolis()\n    sir_trace = pm.sample(4500, chains=4, cores=4, step=step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pm.traceplot(sir_trace, var_names=('beta'))\nplt.savefig('sir_beta_traceplot.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pm.plot_posterior(sir_trace, var_names=('beta'), kind='hist', round_to=3)\nplt.savefig('sir_beta_posterior.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"percentile_cut = 2.5\n\ny_min_sir = np.percentile(sir_trace['sir_model'], percentile_cut, axis=0)\ny_max_sir = np.percentile(sir_trace['sir_model'], 100 - percentile_cut, axis=0)\ny_fit_sir = np.percentile(sir_trace['sir_model'], 50, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9, 7))\n\nplt.plot(data_time, y_fit_sir, 'b', label='Infected')\nplt.fill_between(data_time, y_min_sir, y_max_sir, color='b', alpha=0.2)\n\nplt.legend()\nplt.xlabel('Time (day)')\nplt.ylabel('Population %')\n# plt.xlim(0, 10)\n\nplt.savefig('sir_uncertainty.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Improvements in this SIR model calibration are under investigations!"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bayes-seir2\"></a>\n### SEIR-2 Model\n\nA more interesting model, with two parameters to calibrate."},{"metadata":{"trusted":true},"cell_type":"code","source":"@theano.compile.ops.as_op(itypes=[t.dvector, t.dvector, t.dvector, t.dscalar, t.dscalar], otypes=[t.dvector])\ndef seir_ode_solver_wrapper(time_exp, f_observations, initial_conditions, beta, gamma):\n    time_span = (time_exp.min(), time_exp.max())\n    \n    y_model = seir_ode_solver(initial_conditions, time_span, time_exp, beta, gamma)\n    simulated_time = y_model.t\n    simulated_ode_solution = y_model.y\n    _, _, simulated_qoi, _ = simulated_ode_solution\n\n    return simulated_qoi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with pm.Model() as model_mcmc:\n    # Prior distributions for the model's parameters\n    beta = pm.Uniform('beta', lower=0, upper=0.001)\n    gamma = pm.Uniform('gamma', lower=0, upper=0.5)\n\n    # Defining the deterministic formulation of the problem\n    fitting_model = pm.Deterministic('seir2_model', seir_ode_solver_wrapper(\n        theano.shared(data_time), \n        theano.shared(infected_individuals), \n        theano.shared(np.array(y0_seir)),\n        beta,\n        gamma\n        )\n    )\n\n    # Variance related to population fraction amount! Let's assume a variance of 100 individuals, since there are cases that have been not tracked\n    variance = (100 / target_population) * (100 / target_population)\n    standard_deviation = np.sqrt(variance)\n    likelihood_model = pm.Normal('likelihood_model', mu=fitting_model, sigma=standard_deviation, observed=infected_individuals)\n\n    # The Monte Carlo procedure driver\n    step = pm.step_methods.Metropolis()\n    seir_trace = pm.sample(8500, chains=4, cores=4, step=step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pm.traceplot(seir_trace, var_names=('beta'))\nplt.savefig('seir2_beta_traceplot.png')\nplt.show()\n\npm.traceplot(seir_trace, var_names=('gamma'))\nplt.savefig('seir2_gamma_traceplot.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pm.plot_posterior(seir_trace, var_names=('beta'), kind='hist', round_to=3)\nplt.savefig('seir2_beta_posterior.png')\nplt.show()\n\npm.plot_posterior(seir_trace, var_names=('gamma'), kind='hist', round_to=3)\nplt.savefig('seir2_gamma_posterior.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"percentile_cut = 2.5\n\ny_min_seir = np.percentile(seir_trace['seir2_model'], percentile_cut, axis=0)\ny_max_seir = np.percentile(seir_trace['seir2_model'], 100 - percentile_cut, axis=0)\ny_fit_seir = np.percentile(seir_trace['seir2_model'], 50, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9, 7))\n\nplt.plot(data_time, y_fit_seir, 'b', label='Infected')\nplt.fill_between(data_time, y_min_seir, y_max_seir, color='b', alpha=0.2)\n\nplt.legend()\nplt.xlabel('Time (day)')\nplt.ylabel('Population %')\n# plt.xlim(0, 10)\n\nplt.savefig('seir2_uncertainty.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Bayesian calibration is currently under investigations/improvements."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}