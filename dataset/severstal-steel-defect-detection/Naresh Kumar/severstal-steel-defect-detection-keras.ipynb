{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os, gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npath = '../input/severstal-steel-defect-detection/'\ntrain = pd.read_csv(path + 'train.csv')\n\n# RESTRUCTURE TRAIN DATAFRAME\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).values\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/ateplyuk/pytorch-starter-u-net-resnet\n# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, \n                 preprocess=None, info={}):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index): \n        X = np.empty((self.batch_size,128,800,3),dtype=np.float32)\n        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f).resize((800,128))\n            if self.subset == 'train': \n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess!=None: X = self.preprocess(X)\n        if self.subset == 'train': return X, y\n        else: return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/titericz/building-and-visualizing-masks\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13.5,2.5))\nbar = plt.bar( [1,2,3,4],100*np.mean( train2.iloc[:,1:5]!='',axis=0) )\nplt.title('Percent Training Images with Defect', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Defect Type')\nplt.xticks([1,2,3,4])\nfor rect in bar:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=16)\nplt.ylim((0,50)); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n# https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\n\n# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.backbones import get_preprocessing\n\n# LOAD UNET WITH PRETRAINING FROM IMAGENET\npreprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\nmodel = Unet('resnet34', input_shape=(128, 800, 3), classes=4, activation='sigmoid')\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n\n# TRAIN AND VALIDATE MODEL\nidx = int(0.8*len(train2)); print()\ntrain_batches = DataGenerator(train2.iloc[:idx],shuffle=True,preprocess=preprocess)\nvalid_batches = DataGenerator(train2.iloc[idx:],preprocess=preprocess)\nhistory = model.fit_generator(train_batches, validation_data = valid_batches, epochs = 30, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'unet.model.18.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = load_model(r'../input/modelh5/unet.model.18.hdf5',custom_objects={'dice_coef':dice_coef})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_testdata(a):\n\n    data = []\n    c = 1\n\n    for i in range(a.shape[0]-1):\n        if a[i]+1 == a[i+1]:\n            c += 1\n            if i == a.shape[0]-2:\n                data.append(str(a[i-c+2]))\n                data.append(str(c))\n\n        if a[i]+1 != a[i+1]:\n            data.append(str(a[i-c+1]))\n            data.append(str(c))\n            c = 1\n\n    data = \" \".join(data)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"../input/severstal-steel-defect-detection/test_images/\"\n\ntest_list = os.listdir(test_path)\n\ndata = []\n\nfor fn in test_list:\n    abs_name = test_path + fn\n    a = Image.open(abs_name).resize((800,128))\n    x=np.expand_dims(a, axis=0)\n    pred = model1.predict(x)\n    for i in range(4):\n        pred_fi = pred[:,:,i+1].T.flatten()\n        pred_fi = np.where(pred_fi > 0.3, 1, 0)\n        pred_fi_id = np.where(pred_fi == 1)\n        pred_fi_id = make_testdata(pred_fi_id[0])\n        x = [fn + \"_\" + str(i+1), pred_fi_id]\n        data.append(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['ImageId_ClassId', 'EncodedPixels']\nd = pd.DataFrame(data=data, columns=columns, dtype='str')\n\ndef expand(x):\n    new_val = ''\n    val = x.split(' ')\n    for char in val:\n        doub = str(int(char)*2)\n        new_val = new_val+doub+' '\n        new_val[:-1]\n    return new_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['ImageId_ClassId', 'EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = pd.DataFrame(data=data, columns=columns, dtype='str')\nd['EncodedPixels'] = d['EncodedPixels'].apply(lambda x: expand(x) if x!='' else '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}