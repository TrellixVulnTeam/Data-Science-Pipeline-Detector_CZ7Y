{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"This is a series of notebooks were I explore the [**fastai**](https://www.fast.ai/) [**library**](https://docs.fast.ai/) (with a focus on computer vision given the nature of the competition). More parts will be available in the upcoming weeks, so stay tuned!\n\nIn this first part, I will show you:\n\n1. How to read an image\n2. How to read a mask from a [**run-length encoding**](https://en.wikipedia.org/wiki/Run-length_encoding)\n3. How to combine both steps to get a bunch of images and masks\n\nLet's start!"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Loading an image"},{"metadata":{},"cell_type":"markdown","source":"Alright, to get started, let's get an image from the training dataset.\nFor that, we will need only two things:\n\n1. path to the image\n2. [`open_image`](https://docs.fast.ai/vision.image.html#open_image) utility function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import open_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_id = \"0002cc93b\"\nimg_path = f\"../input/severstal-steel-defect-detection/train_images/{img_id}.jpg\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"open_image(img_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One channel from RGB but not necessary here (since all three channels are the same).\nopen_image(img_path, convert_mode = \"L\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = open_image(img_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the first 5 * 5 patch\nimg.px[:, :5, :5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The image shape: (channels, width, height)\nimg.px.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Notice that all channels contain the same information here.\nprint((img.px[0, : , :] == img.px[1, :, :]).all())\nprint((img.px[1, : , :] == img.px[2, :, :]).all())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That was easy!"},{"metadata":{},"cell_type":"markdown","source":"# Loading a mask"},{"metadata":{},"cell_type":"markdown","source":"Next, let's load a mask for the given image. As you will see, the masks are stored as textual representation (run-length encoding shortned as rle) rather than images to save space. This is a slightly more complicated task but \nnothing insurmontable. For that, we will need three things:\n    \n1. mapping between the image and the mask (or masks if many)\n2. the mask's rle\n3. [`open_mask_rle utiliy`](https://docs.fast.ai/vision.image.html#open_mask_rle) function"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"To get the mapping and the rle, we need to open the train CSV. Will be using pandas for that."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"../input/severstal-steel-defect-detection/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Will extract img_id and class_id\ntrain_df[\"img_id\"] = train_df[\"ImageId_ClassId\"].str.split(\".\").str[0]\ntrain_df[\"class_id\"] =  train_df[\"ImageId_ClassId\"].str.split(\".\").str[1].str.split('_').str[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find the rle corresponding to the `img_id` (id of the displayed image). "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[lambda df: df[\"img_id\"] == img_id, [\"EncodedPixels\", \"class_id\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The mask is the first elemen\nmask_rle = train_df.loc[lambda df: df[\"img_id\"] == img_id, \"EncodedPixels\"].values[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! So we have one mask (represented using rle) with `class_id` 1 for the given image. Let's\nplot the mask!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import open_mask_rle\nmask_shape = (img.px.shape[1], img.px.shape[2])\nmask = open_mask_rle(mask_rle, shape=mask_shape)\nmask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hum, that looks like a mask but wrongly shaped. What went wrong?\nWell, this is a quirk of the rle format. I won't delve into too much details but\njust remember that you need to rotate the mask 90 degrees (counter-clockwise).\nTo do so, one can use the transpose operation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import ImageSegment\n# Need to create a mask using the ImageSegment class\nmask = ImageSegment(mask.data.transpose(2, 1))\nmask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks better!"},{"metadata":{},"cell_type":"markdown","source":"# Combining both steps in a pipeline"},{"metadata":{},"cell_type":"markdown","source":"Before doing that, let's plot both the image and the mask in a single plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"img.show(y=mask, figsize=(20, 10), title=f\"{img_id} with mask, label 1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I was planning to run a data pipeline without doing any intermediate steps. However, I was unable to do so so far. If you know how to do it, please let me know in the comments section.\nFor now, I have a step where I extract and save masks (one mask per image). \n\nLet's go through this."},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir ../masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport torch\nfrom fastai.vision import open_mask_rle, ImageSegment\n\ndef get_and_save_mask(img_id, df, shape=(1600, 256)):\n    \"\"\" Extract the mask(s) for each image. The mask could be None.\"\"\"\n    # Shape: (width, height)\n    # One mask (or none) per image.\n    masks = []\n    rle_df = df.loc[df[\"img_id\"] == img_id, ['class_id', 'EncodedPixels']]\n    # Not all images have masks\n    for row in rle_df.itertuples():\n        rle = row.EncodedPixels\n        class_id = row.class_id\n        if isinstance(rle, float) and math.isnan(rle):\n            continue\n        one_mask = open_mask_rle(rle, shape=shape)\n        one_mask = int(class_id) * one_mask.data\n        masks.append(one_mask)\n    if len(masks) == 0:\n        return\n    stacked_mask = torch.stack(masks, dim=0).sum(dim=0)\n    mask_img = ImageSegment(stacked_mask.reshape((1, shape[0], shape[1])).transpose(2, 1))\n    mask_img.save(f\"../masks/{img_id}.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run over all the train images\nfor img_id in train_df[\"img_id\"].unique():\n    get_and_save_mask(img_id, train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load one of these saved masks. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import open_mask\nopen_mask(\"../masks/0025bde0c.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Awesome, it worked! Alright, now that we have both images and masks saved \nas files, let's load a bunch of them.\n\nBefore we dive deep, here is the plan to get the data pipeline: \n\n* contruct a DataFrame that contains only images having at least one mask (this will be called\n`with_masks_df`)\n* Load images using the `from_df` method\n* Extract labels using the `label_from_func` method: this takes a function that reads\none image input path and outputs a mask path. Since we have multiple classes (0 for background\nand 1 through 4 for the different defect types), these should be passed as well.\n* Transform the images and masks. Notice that this step is optional but I am \nadding it to get resized images (since I pass the `size` variable)\n* Finally, use the `databunch` method to create a [**DataBunch**](https://docs.fast.ai/basic_data.html#DataBunch). Again, this isn't necessary but will comes handy in the next notebook so I want you to get used to the concept.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering images with at least one mask\nwith_masks_df = (train_df.groupby('img_id')['EncodedPixels'].count() \n                      .reset_index()\n                      .rename(columns={\"EncodedPixels\": \"n_masks\"}))\nwith_masks_df = with_masks_df.loc[lambda df: df[\"n_masks\"] > 0, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data pipeline\nfrom fastai.vision import SegmentationItemList, get_transforms\n\ntrain_folder = \"../input/severstal-steel-defect-detection/train_images/\"\nsl = SegmentationItemList.from_df(with_masks_df, train_folder, suffix=\".jpg\")\nsize = 256\nbatch_size = 16\ndata = (sl.split_none()\n          .label_from_func(lambda x : str(x).replace(train_folder, '../masks/'),\n                           classes=[0, 1, 2, 3, 4])\n          .transform(get_transforms(), size=size, tfm_y=True)\n          .databunch(bs=batch_size))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the pipeline is defined, we can visualize some images with the associated masks."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's it for this first notebook. In the next one, we will be building upon these foundations\nand train a [**U-net**](https://arxiv.org/abs/1505.04597) model. \nStay tuned. ;)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}