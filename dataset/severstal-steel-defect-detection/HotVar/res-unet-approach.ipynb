{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi, this kernel shows Res-unet approach to figure out defects of steels from their images.  \nI noted training and inference codes, but i commented training codes because there's time limit(an hour) to submit."},{"metadata":{},"cell_type":"markdown","source":"Load libraries and given data."},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"import os, shutil\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nfrom glob import glob\nfrom tqdm import tqdm_notebook\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras import losses \nfrom keras.utils import Sequence\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TRAIN = os.path.join('../input/severstal-steel-defect-detection/train_images/')\nPATH_TEST = os.path.join('../input/severstal-steel-defect-detection/test_images/')\nfile_train = glob(os.path.join(PATH_TRAIN, '*.jpg'))\nfile_test = sorted(glob(os.path.join(PATH_TEST, '*.jpg')))\nLEN_TRAIN = len(file_train)\nLEN_TEST = len(file_test)\ndf_rle = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\nprint(f'length - train data : {LEN_TRAIN}')\nprint(f'length - test data: {LEN_TEST}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check image size identity\ntmp = Image.open(file_train[0])\nsize = tmp.size\nis_identical = True\nprint('check size identity...')\nfor fname in tqdm_notebook(file_train+file_test):\n    img = Image.open(fname)\n    if size != img.size:\n        print('found abnormal size!!')\n        is_identical = False\n        break\nif is_identical:\n    print(f'all images are {size}')\n    W = size[0]\n    H = size[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are imbalanced distributions of defects in the training dataset. Then I decided to build seperated 4 models."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"counts = (df_rle['EncodedPixels'].isnull()).value_counts(ascending=True)\nplt.title('The number of class in defects')\nplt.bar(['defect', 'not defect'], counts, color='k')\nplt.text(0, counts[0]+500, counts[0])\nplt.text(1, counts[1]+500, counts[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = np.empty(4)\nfor i in range(4):\n    counts[i] = np.sum(df_rle.iloc[np.arange(len(df_rle))%4==i, 1].notnull())\n    plt.text(i, counts[i]+10, int(counts[i]))\nplt.title('Defects on each class')\nplt.bar(['class1', 'class2', 'class3', 'class4'], counts, color='k')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare utility functions to handle mask images. In this competition, We need to be cautious on both facts that all pixels are start from (1, 1) indecies and numberd form top to bottom, then left to right."},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 1;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[y][x]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel\n                    runLength = 1\n                else:\n                    rle.append(str(runStart))\n                    rle.append(str(runLength))\n                    runStart = -1\n                    runLength = 0                    \n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor\n            currentPixel += 1\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for start, length in zip(starts, lengths):\n        mask[start-1:start-1+length] = 255\n\n    return mask.reshape(width, height).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# return class-wise masks indicates where the defects are.\ndef get_mask(fname, width, height):\n    masks = np.zeros((4, height, width))\n    id_img = fname.split('/')[-1]\n    for i in range(1, 5):\n        classId_img = id_img + '_' + str(i)\n        rle = df_rle[classId_img == df_rle['ImageId_ClassId']].iloc[0, 1]\n        if type(rle)==str:\n            masks[i-1] = rle2mask(rle, width, height)\n    return masks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting masks."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(8, 3, figsize=(15, 10))\naxes[0, 0].set_ylabel('class1')\naxes[1, 0].set_ylabel('class2')\naxes[2, 0].set_ylabel('class3')\naxes[3, 0].set_ylabel('class4')\nfor i in range(2):\n    for j in range(3):\n        fname = file_train[np.random.randint(LEN_TRAIN)]\n        img = np.asarray(Image.open(fname).convert('L'))\n        masks = get_mask(fname, W, H)\n        for k, mask in enumerate(masks):\n            axes[i*4+k, j].imshow(img)\n            y, x = np.argwhere(mask>0).T\n            axes[i*4+k, j].scatter(x, y, alpha=0.1, c='r', s=0.01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is an image generator class. A generator takes only single channel from image, then performs resize, normalization and returns batch of images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize_img(img, resize_w, resize_h):\n    img = Image.fromarray(img)\n    w, h = img.size\n    re_img = img.resize((resize_w, resize_h))\n    return np.asarray(re_img)\n\ndef im2NHWC(img):\n    ret = resize_img(img, resize_w, resize_h)\n    ret = np.expand_dims(ret, axis=0)\n    ret = np.expand_dims(ret, axis=3)\n    return ret\n\ndef NHWC2im(nhwc):\n    ret = np.squeeze(nhwc)\n    ret = resize_img(ret, W, H)\n    return ret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class training_generator(Sequence):\n    def __init__(self, fnames, size_batch, w, h, idx_class, resize_w=W, resize_h=H):\n        self.fnames = fnames\n        self.size_batch = size_batch\n        self.w = w\n        self.h = h\n        self.idx_class = idx_class\n        self.resize_w = resize_w\n        self.resize_h = resize_h\n        self.on_epoch_end()\n        \n    def __load__(self, fname):\n        img = np.asarray(Image.open(fname).convert('L'))\n        mask = get_mask(fname, self.w, self.h)[self.idx_class]\n        return img, mask    \n     \n    def __getitem__(self, idx_batch):\n        if (idx_batch+1)*self.size_batch > len(self.fnames):\n            self.size_batch = len(self.fnames) - idx_batch*self.size_batch\n            \n        fnames_batch = self.fnames[idx_batch*self.size_batch:(idx_batch+1)*self.size_batch]\n        images = list()\n        masks = list()\n        \n        for fname in fnames_batch:\n            img, mask = self.__load__(fname)\n            #img, mask = self.transform_item(img, mask)\n            img = resize_img(img, self.resize_w, self.resize_h)\n            mask = resize_img(mask, self.resize_w, self.resize_h)\n            images.append(img)\n            masks.append(mask)\n        images = np.expand_dims(np.array(images), axis=3)\n        masks = np.expand_dims(np.array(masks), axis=3)\n        \n        return images/255., masks/255.\n    \n    def on_epoch_end(self):\n        pass\n    \n    def __len__(self):\n        return int(np.ceil(len(self.fnames)/float(self.size_batch)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define loss and score functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\ndef get_iou_vector(A, B):\n    # Numpy version\n    \n    batch_size = A.shape[0]\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n        \n        # deal with empty mask first\n        if true == 0:\n            metric += (pred == 0)\n            continue\n        \n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection / union\n        \n        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n        \n        metric += iou\n        \n    metric /= batch_size\n    return metric\n\ndef iou_metric(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_loss(pred, y):\n    pred_f = K.flatten(pred)\n    y_f = K.flatten(y)\n    intersection = K.sum(y_f * pred_f)\n    union = K.sum(y_f + pred_f)\n    score = 2. * (intersection+1e-5) / (union+1e-05)\n    return 1. - score\n\ndef dice_coef(pred, y):\n    pred_f = pred.flatten()\n    y_f = y.flatten()\n    intersection = np.sum(y_f * pred_f)\n    union = np.sum(y_f + pred_f)\n    return 2. * (intersection+1e-5) / (union+1e-05)\n\ndef bce_dice_loss(y_true, y_pred):\n    return losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To perform deeper inference than normal u-net does, we need deeper layers with residual-block.  \nHere is Refference : https://github.com/nikhilroxtomar/Deep-Residual-Unet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bn_act_block(x, with_act=True):\n    layer = BatchNormalization()(x)\n    if with_act:\n        layer = Activation('relu')(layer)\n    return layer\n\ndef conv_block(x, n_filters, kernel_size=3, padding='same', strides=1):\n    layer = bn_act_block(x)\n    layer = Conv2D(n_filters, kernel_size, padding=padding, strides=strides)(layer)\n    return layer\n\ndef initial_block(x, n_filters, kernel_size=3, padding='same', strides=1):\n    layer = Conv2D(n_filters, kernel_size, padding=padding, strides=strides)(x)\n    layer = conv_block(layer, n_filters, kernel_size, padding, strides)\n    shortcut = Conv2D(n_filters, kernel_size=1, padding=padding, strides=strides)(x)\n    shortcut = bn_act_block(shortcut, False)\n    ret = Add()([layer, shortcut])\n    return ret\n\ndef residual_block(x, n_filters, kernel_size=3, padding='same', strides=1):\n    residue = conv_block(x, n_filters, kernel_size, padding, strides)\n    residue = conv_block(residue, n_filters, kernel_size, padding, strides=1)\n    shortcut = Conv2D(n_filters, kernel_size=1, padding=padding, strides=strides)(x)\n    shortcut = bn_act_block(shortcut, False)\n    ret = Add()([residue, shortcut])\n    return ret\n\ndef upsample_concat_block(x, to_concat):\n    upsampled = UpSampling2D(size=(2, 2))(x)\n    ret = Concatenate()([upsampled, to_concat])\n    return ret","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Handle the number of model-params to modify size_batch, img_width, img_height and num_channels."},{"metadata":{"trusted":true},"cell_type":"code","source":"SIZE_BATCH = 16\nresize_w = W//4\nresize_h = H//4\nn_filters = [8, 16, 32, 64, 128]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Res_Unet method defines 4 models(against each class).  "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def Res_Unet(h, w, pre_weights=None):   \n    # Encoder\n    inputs = Input((h, w, 1)) \n    e1 = initial_block(inputs, n_filters[0], strides=1)\n    e2 = residual_block(e1, n_filters[1], strides=2)\n    e3 = residual_block(e2, n_filters[2], strides=2)\n    e4 = residual_block(e3, n_filters[3], strides=2)\n    e5 = residual_block(e4, n_filters[4], strides=2)\n    \n    # Bridge\n    b1 = conv_block(e5, n_filters[3], strides=1)\n    b2 = conv_block(b1, n_filters[3], strides=1)\n    \n    # Decoder\n    u1 = upsample_concat_block(b2, e4)\n    d1 = residual_block(u1, n_filters[4])\n    u2 = upsample_concat_block(d1, e3)\n    d2 = residual_block(u2, n_filters[3])\n    u3 = upsample_concat_block(d2, e2)\n    d3 = residual_block(u3, n_filters[2])\n    u4 = upsample_concat_block(d3, e1)\n    d4 = residual_block(u4, n_filters[1])\n    \n    outputs = Conv2D(1, 1, padding='same', activation='sigmoid')(d4)\n    \n    model = Model(input=inputs, output=outputs)\n    model.compile(optimizer=Adam(lr=1e-02), loss=bce_dice_loss, metrics=[iou_metric])\n    \n    if(pre_weights):\n        model.load_weights(pre_weights)\n        \n    return model\n\nmodels = list()\nfor i in range(4):\n    # load pre-trained model for inference processing.\n    models.append(Res_Unet(resize_h, resize_w, pre_weights=f'../input/mymodel/model_class{i+1}.h5'))\n    # build initial model for training.\n    #models.append(Res_Unet(resize_h, resize_w'))\nmodels[0].summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This kernel only does inference, so i hide training script."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# for training\n\"\"\"\n# training with validation\nhistory = [None, None, None, None]\nn_epochs = [4, 4, 30, 10]\nfor i in range(4):\n    early_stopping = EarlyStopping(monitor='val_loss')\n    splited_train, splited_valid = train_test_split(file_train, train_size=0.9)\n    train_generator = training_generator(splited_train,\n                                         size_batch=SIZE_BATCH,\n                                         w=W,\n                                         h=H,\n                                         idx_class=i,\n                                         resize_w=resize_w,\n                                         resize_h=resize_h)\n    valid_generator = training_generator(splited_valid,\n                                         size_batch=SIZE_BATCH,\n                                         w=W,\n                                         h=H,\n                                         idx_class=i,\n                                         resize_w=resize_w,\n                                         resize_h=resize_h)\n    history[i] = models[i].fit_generator(train_generator,\n                                         steps_per_epoch=len(splited_train)//SIZE_BATCH,\n                                         epochs=n_epochs[i],\n                                         shuffle=True,\n                                         verbose=1,\n                                         validation_data=valid_generator,\n                                         validation_steps=len(splited_valid)//SIZE_BATCH)\n\n    eval(f\"models[{i}].save_weights('model_class{i+1}')\")\n    print(f'class{i+1} training done.')\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# plot training histories.\n\"\"\"\nfig, axes = plt.subplots(2, 2, figsize=(18, 10))\nfor i , ax in enumerate(axes.flatten()):\n    ax_t = ax.twinx()\n    ax.plot(history[i].history['iou_metric'], 'b', label='trainig_acc')\n    ax.plot(history[i].history['val_iou_metric'], 'y', label='validation_acc')\n    ax_t.plot(history[i].history['loss'], 'r', label='dice_loss')\n    ax_t.plot(history[i].history['val_loss'], 'g', label='validation_loss')\n    ax.set_xlabel('epochs')\n    ax.set_ylabel('my_iou_metric')\n    ax_t.set_ylabel('loss')\n    ax.legend(loc='right')\n    ax_t.legend(loc='center left')\nplt.show()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compare original images, masked images and predicted masks"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sample_idx = np.random.randint(0, len(file_train), 3)\nfig, axes = plt.subplots(12, 3, figsize=(15, 15))\naxes[0, 0].set_title('original image')\naxes[0, 1].set_title('masked image')\naxes[0, 2].set_title('predicted image')\naxes[0, 0].set_ylabel('class1')\naxes[1, 0].set_ylabel('class2')\naxes[2, 0].set_ylabel('class3')\naxes[3, 0].set_ylabel('class4')\nfor i in range(3):\n    fname = file_train[sample_idx[i]]\n    img = np.asarray(Image.open(fname).convert('L'))\n    masks = get_mask(fname, W, H)\n    \n    for j, mask in enumerate(masks):\n        # draw background images\n        axes[i*4+j, 0].imshow(img)\n        axes[i*4+j, 1].imshow(img)\n        axes[i*4+j, 2].imshow(img)\n        \n        # draw target masks\n        if mask is not None:\n            y, x = np.argwhere(mask>0).T\n            axes[i*4+j, 1].scatter(x, y, alpha=0.1, c='r', s=0.01)\n            \n        # draw predicted segments\n        nhwc = im2NHWC(img)/255.\n        predicted = models[j].predict_on_batch(nhwc)\n        predicted = NHWC2im(predicted)\n        y, x = np.argwhere(predicted > 0.9).T\n        axes[i*4+j, 2].scatter(x, y, alpha=0.1, c='r', s=0.01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now make submission file that indicates predicted masks with run-length-encode format.  \n  \nThe prediction works on seperated models because we need to predict all class masks.  \nAnd I took pixels which is only bigger than 0.9(arbitrary chosen) as mask segment. We can tune this value later."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\ni = 0\nfor fname in tqdm_notebook(file_test):\n    img = np.asarray(Image.open(fname).convert('L'))/255.\n    nhwc = im2NHWC(img)\n    for j in range(4):\n        classId_test = fname.split('/')[-1] + '_' + str(j+1)\n\n        # predict the defects from each model\n        predicted = models[j].predict_on_batch(nhwc)\n        predicted = NHWC2im(predicted)\n\n        # take pixels bigger than threshold-value as masks.\n        th_predicted = (predicted>0.9).astype(int)*255\n        rle_predicted = mask2rle(th_predicted, 1600, 256)\n        submission.loc[i] = [classId_test, rle_predicted]\n        i+=1\n        \nsubmission.to_csv('./submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Unfortunately, my submission file was not able to score. Except when i submit blank file, it always returned status, kernel timeout.  \nAnyone who solved such problem, please give me a hand."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}