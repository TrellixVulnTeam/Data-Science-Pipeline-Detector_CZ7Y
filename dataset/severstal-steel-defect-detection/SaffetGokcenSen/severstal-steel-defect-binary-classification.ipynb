{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df_whole = pd.read_csv(\"/kaggle/input/severstal-steel-defect-detection/train.csv\")\ntrain_df_whole[\"image_id\"] = train_df_whole[\"ImageId_ClassId\"].str[:-2]\ntrain_df_whole[\"class_id\"] = train_df_whole[\"ImageId_ClassId\"].str[-1].astype(\"float\")\ntrain_df_whole[\"defected\"] = ~train_df_whole[\"EncodedPixels\"].isna()\ntrain_df_whole[\"class_id\"] = train_df_whole[\"class_id\"]*train_df_whole[\"defected\"].astype(\"float\")\ntrain_df_whole.drop(\"ImageId_ClassId\", axis=1, inplace=True)\ntrain_df_whole.drop_duplicates(inplace=True)\nfreq_df = pd.DataFrame(train_df_whole[\"image_id\"].value_counts().reset_index())\nfreq_df.columns = [\"image_id\", \"frequency\"]\ntrain_df_whole = train_df_whole.merge(freq_df, how=\"left\", on=\"image_id\")\nthe_filter = ~((train_df_whole[\"frequency\"] >= 2) & (train_df_whole[\"EncodedPixels\"].isna()))\ntrain_df_whole = train_df_whole[the_filter]\ntrain_df_whole = train_df_whole.drop([\"EncodedPixels\", \"class_id\", \"frequency\"], axis=1).drop_duplicates()\ntrain_df_whole.reset_index(drop=True, inplace=True)\n\ntrain_df, validate_df = train_test_split(train_df_whole, test_size=0.1, stratify=train_df_whole[[\"defected\"]].copy())\ntrain_df.reset_index(drop=True, inplace=True)\nvalidate_df.reset_index(drop=True, inplace=True)\n\nprint(train_df[\"defected\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\n\ndata_parent_dir = \"/kaggle/classification\"\nif not os.path.exists(data_parent_dir):\n    os.mkdir(data_parent_dir)\n\ndata_dir = \"/kaggle/classification/data\"\nif not os.path.exists(data_dir):\n    os.mkdir(data_dir)\n\ndefected_images_dir = \"/kaggle/classification/data/defected\"\nif not os.path.exists(defected_images_dir):\n    os.mkdir(defected_images_dir)\n    \nfor the_file in os.listdir(defected_images_dir):\n    file_path = os.path.join(defected_images_dir, the_file)\n    try:\n        if os.path.isfile(file_path):\n            os.unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n    \nnot_defected_images_dir = \"/kaggle/classification/data/not_defected\"\nif not os.path.exists(not_defected_images_dir):\n    os.mkdir(not_defected_images_dir)\n    \nfor the_file in os.listdir(not_defected_images_dir):\n    file_path = os.path.join(not_defected_images_dir, the_file)\n    try:\n        if os.path.isfile(file_path):\n            os.unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n    \nvalidation_data_dir = \"/kaggle/classification/validation_data\"\nif not os.path.exists(validation_data_dir):\n    os.mkdir(validation_data_dir)\n    \ndefected_validation_images_dir = \"/kaggle/classification/validation_data/defected\"\nif not os.path.exists(defected_validation_images_dir):\n    os.mkdir(defected_validation_images_dir)\n    \nfor the_file in os.listdir(defected_validation_images_dir):\n    file_path = os.path.join(defected_validation_images_dir, the_file)\n    try:\n        if os.path.isfile(file_path):\n            os.unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n    \nnot_defected_validation_images_dir = \"/kaggle/classification/validation_data/not_defected\"\nif not os.path.exists(not_defected_validation_images_dir):\n    os.mkdir(not_defected_validation_images_dir)\n    \nfor the_file in os.listdir(not_defected_validation_images_dir):\n    file_path = os.path.join(not_defected_validation_images_dir, the_file)\n    try:\n        if os.path.isfile(file_path):\n            os.unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n\norig_train_dir = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\nfor file_name, the_label in zip(train_df[\"image_id\"], train_df[\"defected\"]):\n    src = os.path.join(orig_train_dir, file_name)\n    if the_label:\n        dst = os.path.join(defected_images_dir, file_name)\n    else:\n        dst = os.path.join(not_defected_images_dir, file_name)\n    copyfile(src, dst)\n\nfor file_name, the_label in zip(validate_df[\"image_id\"], validate_df[\"defected\"]):\n    src = os.path.join(orig_train_dir, file_name)\n    if the_label:\n        dst = os.path.join(defected_validation_images_dir, file_name)\n    else:\n        dst = os.path.join(not_defected_validation_images_dir, file_name)\n    copyfile(src, dst)\n        \ntrain_batch_size = 8\nvalidate_batch_size = 8\n\ndata_gen_args_image = dict(\n    rotation_range=40.0,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=1.0/255.0\n)\n\n# we create two instances with the same arguments\nimage_datagen = ImageDataGenerator(**data_gen_args_image)\n\n# Provide the same seed and keyword arguments to the fit and flow methods\nimage_generator = image_datagen.flow_from_directory(\n    '/kaggle/classification/data',\n    target_size=(256, 1600),\n    batch_size=train_batch_size,\n    color_mode=\"rgb\",\n    class_mode=\"binary\",\n    classes=[\"not_defected\", \"defected\"]\n)\ntrain_generator = image_generator\n\nvalidation_image_datagen = ImageDataGenerator(rescale=1.0/255.0)\nvalidation_image_generator = validation_image_datagen.flow_from_directory(\n    '/kaggle/classification/validation_data',\n    target_size=(256, 1600),\n    batch_size=validate_batch_size,\n    color_mode=\"rgb\",\n    class_mode=\"binary\",\n    classes=[\"not_defected\", \"defected\"]\n)\n\nvalidation_generator = validation_image_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.losses import binary_crossentropy\nfrom keras.applications import VGG16\nfrom keras.layers import Flatten, Dense, UpSampling2D, Conv2D, Activation, MaxPooling2D  # , Conv2DTranspose\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n\nconv_base = VGG16(weights=\"/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\", include_top=False, input_shape=(256, 1600, 3))\n\nx = conv_base.output\n# x = UpSampling2D(32, interpolation='bilinear')(x)\nx = Conv2D(1, (2, 2))(x)\nx = Flatten()(x)\noutputs = Dense(units=1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=conv_base.input, outputs=outputs)\nfor layer in conv_base.layers:\n    layer.trainable = False\nmodel.summary()\n\ncallbacks_list = [\n    # EarlyStopping(monitor=\"acc\", patience=2),\n    ModelCheckpoint(filepath=\"best_model_binary.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=1, cooldown=2, verbose=1),\n    #TensorBoard(log_dir=\"./log_dir\", histogram_freq=1)\n]\n\nmodel.compile(loss=binary_crossentropy, optimizer=optimizers.Adam(), metrics=[\"acc\"])\n\ntrain_set_size = train_df.shape[0]\nif train_batch_size == train_set_size:\n    steps_per_epoch = 1\nelse:\n    steps_per_epoch = (train_set_size // train_batch_size) + 1\n\nvalidate_set_size = validate_df.shape[0]\nif validate_batch_size == validate_set_size:\n    validate_steps_per_epoch = 1\nelse:\n    validate_steps_per_epoch = (validate_set_size // validate_batch_size) + 1\n\nhistory = model.fit_generator(\n    generator=train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=22,\n    validation_data=validation_generator,\n    validation_steps = validate_steps_per_epoch,\n    callbacks=callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.figure(1)\n_ = plt.plot(epochs, acc, 'bo', label='Training acc')\n_ = plt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\n_ = plt.legend()\nplt.figure(2)\n_ = plt.plot(epochs, loss, 'bo', label='Training loss')\n_ = plt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\n_ = plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\nfrom numpy import squeeze\n\nthe_image = load_img(\"/kaggle/input/severstal-steel-defect-detection/test_images/1804f41eb.jpg\")\nimage_array = img_to_array(the_image)\nimage_array = np.expand_dims(image_array, 0)\npredicted_type = model.predict(image_array, batch_size=1)\nprint(\"predicted type:\")\nprint(predicted_type)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}