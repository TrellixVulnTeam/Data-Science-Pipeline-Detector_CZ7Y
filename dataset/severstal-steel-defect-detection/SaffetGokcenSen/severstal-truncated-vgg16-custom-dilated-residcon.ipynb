{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df_whole = pd.read_csv(\"/kaggle/input/severstal-steel-defect-detection/train.csv\")\nthe_filter = train_df_whole[\"EncodedPixels\"].isna()\ntrain_df_whole = train_df_whole[~the_filter]\ntrain_df_whole[\"image_id\"] = train_df_whole[\"ImageId_ClassId\"].str[:-2]\ntrain_df_whole[\"class_id\"] = train_df_whole[\"ImageId_ClassId\"].str[-1].astype(\"float\")\ntrain_df_whole.drop(\"ImageId_ClassId\", axis=1, inplace=True)\ntrain_df_whole.reset_index(drop=True, inplace=True)\n\ntrain_df, validate_df = train_test_split(train_df_whole, test_size=0.1, stratify=train_df_whole[[\"class_id\"]].copy())\ntrain_df.reset_index(drop=True, inplace=True)\nvalidate_df.reset_index(drop=True, inplace=True)\n\ntrain_df[\"image_id\"].value_counts()\nvalidate_df[\"image_id\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import zeros, flipud, rot90, uint8, asarray, float32\ndef rle2mask(rle, imgshape):\n    # width = imgshape[0]\n    width = imgshape[1]\n    # height= imgshape[1]\n    height = imgshape[0]\n    \n    #mask= np.zeros( width*height ).astype(np.uint8)\n    # mask= zeros( width*height ).astype(uint8)\n    mask= zeros( width*height )\n    \n    #array = np.asarray([int(x) for x in rle.split()])\n    array = asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n        \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = float32(1.0)\n        \n    # return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )\n    return flipud( rot90( mask.reshape(width, height), k=1 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import os\nfrom keras.preprocessing.image import ImageDataGenerator, save_img, array_to_img  #, load_img\n#import shutil\n#from PIL import Image\nfrom os.path import exists, join, isfile\nfrom os import mkdir, listdir, unlink\nfrom numpy import expand_dims, round\nfrom shutil import copyfile\n\ndata_dir = \"/kaggle/data\"\nif not exists(data_dir):\n    mkdir(data_dir)\n\nmasks_dir = \"/kaggle/data/masks\"\nif not exists(masks_dir):\n    mkdir(masks_dir)\nmasks_subdir = \"/kaggle/data/masks/masks\"\nif not exists(masks_subdir):\n    mkdir(masks_subdir)\n    \nfor the_file in listdir(masks_subdir):\n    file_path = join(masks_subdir, the_file)\n    try:\n        if isfile(file_path):\n            unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n\nimages_dir = \"/kaggle/data/images\"\nif not exists(images_dir):\n    mkdir(images_dir)\nimages_subdir = \"/kaggle/data/images/images\"\nif not exists(images_subdir):\n    mkdir(images_subdir)\n\nfor the_file in listdir(images_subdir):\n    file_path = join(images_subdir, the_file)\n    try:\n        if isfile(file_path):\n            unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n    \nvalidation_data_dir = \"/kaggle/validation_data\"\nif not exists(validation_data_dir):\n    mkdir(validation_data_dir)\n    \nvalidation_masks_dir = \"/kaggle/validation_data/masks\"\nif not exists(validation_masks_dir):\n    mkdir(validation_masks_dir)\nvalidation_masks_subdir = \"/kaggle/validation_data/masks/masks\"\nif not exists(validation_masks_subdir):\n    mkdir(validation_masks_subdir)\n    \nfor the_file in listdir(validation_masks_subdir):\n    file_path = join(validation_masks_subdir, the_file)\n    try:\n        if isfile(file_path):\n            unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n    \nvalidation_images_dir = \"/kaggle/validation_data/images\"\nif not exists(validation_images_dir):\n    mkdir(validation_images_dir)\nvalidation_images_subdir = \"/kaggle/validation_data/images/images\"\nif not exists(validation_images_subdir):\n    mkdir(validation_images_subdir)\n\nfor the_file in listdir(validation_images_subdir):\n    file_path = join(validation_images_subdir, the_file)\n    try:\n        if isfile(file_path):\n            unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n\nthe_height = 256\nthe_width = 1600\n\nimgshape = (the_height, the_width)\norig_train_dir = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\n#the_index = 0\nfor file_name, rle, class_id in zip(train_df[\"image_id\"], train_df[\"EncodedPixels\"], train_df[\"class_id\"]):\n    the_mask = rle2mask(rle, imgshape)\n    the_mask = expand_dims(the_mask, 2)\n    mask_file_name = file_name[:-4] + \"_\" + str(int(class_id)) + \"_mask.png\"\n    image_file_name = file_name[:-4] + \"_\" + str(int(class_id)) + \"_image.jpg\"\n    save_img(masks_subdir + \"/\" + mask_file_name, the_mask, data_format=\"channels_last\", scale=False)\n    src = join(orig_train_dir, file_name)\n    dst = join(images_subdir, image_file_name)\n    copyfile(src, dst)\n    #the_index = the_index + 1\n    #if the_index == 100:\n    #    break\n\nimgshape = (the_height, the_width)\norig_train_dir = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\n#the_index = 0\nfor file_name, rle, class_id in zip(validate_df[\"image_id\"], validate_df[\"EncodedPixels\"], validate_df[\"class_id\"]):\n    the_mask = rle2mask(rle, imgshape)\n    the_mask = expand_dims(the_mask, 2)\n    mask_file_name = file_name[:-4] + \"_\" + str(int(class_id)) + \"_mask.png\"\n    image_file_name = file_name[:-4] + \"_\" + str(int(class_id)) + \"_image.jpg\"\n    save_img(validation_masks_subdir + \"/\" + mask_file_name, the_mask, data_format=\"channels_last\", scale=False)\n    src = join(orig_train_dir, file_name)\n    dst = join(validation_images_subdir, image_file_name)\n    copyfile(src, dst)\n    #the_index = the_index + 1\n    #if the_index == 100:\n    #    break\n        \ntrain_batch_size = 4\nvalidate_batch_size = 4\n\ndata_gen_args_image = dict(\n    rotation_range=135.0,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=1.0/255.0\n)\n\ndef round_pixels(image):\n    return round(image)\n\ndata_gen_args_mask = dict(\n    rotation_range=135.0,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    preprocessing_function=round_pixels\n)\n\n# we create two instances with the same arguments\nimage_datagen = ImageDataGenerator(**data_gen_args_image)\nmask_datagen = ImageDataGenerator(**data_gen_args_mask)\n\n# Provide the same seed and keyword arguments to the fit and flow methods\nseed = 1\nimage_generator = image_datagen.flow_from_directory(\n    '/kaggle/data/images',\n    target_size=(the_height, the_width),\n    batch_size=train_batch_size,\n    color_mode=\"rgb\",\n    class_mode=None,\n    seed=seed\n)\n\nmask_generator = mask_datagen.flow_from_directory(\n    '/kaggle/data/masks',\n    target_size=(the_height, the_width),\n    batch_size=train_batch_size,\n    color_mode=\"grayscale\",\n    class_mode=None,\n    seed=seed\n)\n\n# combine generators into one which yields image and masks\ntrain_generator = zip(image_generator, mask_generator)\n\n# the_index = 0\n# fig_index = 1\n# for the_image, the_mask in train_generator:\n#     plt.figure(fig_index)\n#     the_image = np.squeeze(the_image, 0)\n#     the_image = array_to_img(the_image)\n#     plt.imshow(the_image)\n#     \n#     fig_index = fig_index + 1\n#     plt.figure(fig_index)\n#     the_mask = np.squeeze(the_mask, 0)\n#     the_mask = array_to_img(the_mask)\n#     plt.imshow(the_mask)\n#     \n#     fig_index = fig_index + 1\n#     \n#     the_index = the_index + 1\n#     if the_index == 5:\n#         break\n\nvalidation_image_datagen = ImageDataGenerator(rescale=1.0/255.0)\nvalidation_mask_datagen = ImageDataGenerator(preprocessing_function=round_pixels)\n        \nseed = 10\nvalidation_image_generator = validation_image_datagen.flow_from_directory(\n    '/kaggle/validation_data/images',\n    target_size=(the_height, the_width),\n    batch_size=validate_batch_size,\n    color_mode=\"rgb\",\n    class_mode=None,\n    seed=seed\n)\n\nvalidation_mask_generator = validation_mask_datagen.flow_from_directory(\n    '/kaggle/validation_data/masks',\n    target_size=(the_height, the_width),\n    batch_size=validate_batch_size,\n    color_mode=\"grayscale\",\n    class_mode=None,\n    seed=seed\n)\n\n# combine generators into one which yields image and masks\nvalidation_generator = zip(validation_image_generator, validation_mask_generator)\n\n# the_index = 0\n# fig_index = 11\n# for the_image, the_mask in train_generator:\n#     plt.figure(fig_index)\n#     the_image = np.squeeze(the_image, 0)\n#     the_image = array_to_img(the_image)\n#     plt.imshow(the_image)\n#     \n#     fig_index = fig_index + 1\n#     plt.figure(fig_index)\n#     the_mask = np.squeeze(the_mask, 0)\n#     the_mask = array_to_img(the_mask)\n#     plt.imshow(the_mask)\n#     \n#     fig_index = fig_index + 1\n#     \n#     the_index = the_index + 1\n#     if the_index == 5:\n#         break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.losses import binary_crossentropy\n\ndef dice_coeff(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = (2.0 * K.sum(intersection) + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n    return score\n\ndef dice_metric(y_true, y_pred):\n    smooth = 1.0\n    y_true_f = K.cast(K.round(K.flatten(y_true)), \"float32\")\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2.0 * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_metric(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nfrom keras.layers import Input, SeparableConv2D, Dropout, Conv2D, Activation, BatchNormalization, add, UpSampling2D  #, GlobalAveragePooling2D, Lambda\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.regularizers import l2\n# from keras.layers.merge import concatenate\n\nthe_rate = 0.5\n\n#the_input = Input(shape=(the_height, the_width, 3))\n#\n#u1 = SeparableConv2D(filters=64,\n#                     kernel_size=(3, 3),\n#                     data_format=\"channels_last\",\n#                     dilation_rate=1,\n#                     depthwise_regularizer=l2(0.0001),\n#                     pointwise_regularizer=l2(0.0001),\n#                     padding=\"same\")(the_input)\n#u1 = BatchNormalization()(u1)\n#u1 = Activation(\"relu\")(u1)\n#u1 = Dropout(rate=the_rate)(u1)\n\nconv_base = VGG16(weights=\"/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\", include_top=False, input_shape=(the_height, the_width, 3))\n\nprint(conv_base.summary())\n\nfor layer in conv_base.layers:\n    layer.trainable = False\n\n# u1 = conv_base.layers[9].output\n\nu1 = conv_base.get_layer('block2_conv2').output\n\nu2 = SeparableConv2D(filters=128,\n                     kernel_size=(3, 3),\n                     data_format=\"channels_last\",\n                     dilation_rate=2,\n                     depthwise_regularizer=l2(0.0001),\n                     pointwise_regularizer=l2(0.0001),\n                     padding=\"same\")(u1)\nu2 = BatchNormalization()(u2)\nu2 = Activation(\"relu\")(u2)\nu2 = Dropout(rate=the_rate)(u2)\n\nu3 = SeparableConv2D(filters=128,\n                     kernel_size=(3, 3),\n                     data_format=\"channels_last\",\n                     dilation_rate=4,\n                     depthwise_regularizer=l2(0.0001),\n                     pointwise_regularizer=l2(0.0001),\n                     padding=\"same\")(u2)\nu3 = BatchNormalization()(u3)\nu3 = Activation(\"relu\")(u3)\nu3 = add([u3, u1])\nu3 = Activation(\"relu\")(u3)\nu3 = Dropout(rate=the_rate)(u3)\n\nu4 = SeparableConv2D(filters=128,\n                     kernel_size=(3, 3),\n                     data_format=\"channels_last\",\n                     dilation_rate=8,\n                     depthwise_regularizer=l2(0.0001),\n                     pointwise_regularizer=l2(0.0001),\n                     padding=\"same\")(u3)\nu4 = BatchNormalization()(u4)\nu4 = Activation(\"relu\")(u4)\nu4 = Dropout(rate=the_rate)(u4)\n\nu5 = SeparableConv2D(filters=128,\n                     kernel_size=(3, 3),\n                     data_format=\"channels_last\",\n                     dilation_rate=16,\n                     depthwise_regularizer=l2(0.0001),\n                     pointwise_regularizer=l2(0.0001),\n                     padding=\"same\")(u4)\nu5 = BatchNormalization()(u5)\nu5 = Activation(\"relu\")(u5)\nu5 = add([u5, u3])\nu5 = Activation(\"relu\")(u5)\nu5 = Dropout(rate=the_rate)(u5)\n\nu6 = UpSampling2D((2, 2), interpolation='bilinear')(u5)\nthe_output = Conv2D(1, (1, 1), activation='sigmoid', kernel_regularizer=l2(0.0001))(u6)\n\nmodel = Model(inputs=conv_base.input, outputs=the_output)\nprint(model.summary())\n\ncallbacks_list = [\n    # EarlyStopping(monitor=\"acc\", patience=2),\n    ModelCheckpoint(filepath=\"best_model.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=1, cooldown=2, min_lr=1.0e-6, verbose=1),\n    #TensorBoard(log_dir=\"./log_dir\", histogram_freq=1)\n]\n\nmodel.compile(loss=dice_loss, optimizer=optimizers.Adam(lr=1.0e-3), metrics=[dice_coeff])\n# model.compile(loss=dice_loss, optimizer=optimizers.SGD(momentum=0.99), metrics=[dice_coeff])\n\ntrain_set_size = train_df.shape[0]\nif train_batch_size == train_set_size:\n    steps_per_epoch = 1\nelse:\n    steps_per_epoch = (train_set_size // train_batch_size) + 1\n\nvalidate_set_size = validate_df.shape[0]\nif validate_batch_size == validate_set_size:\n    validate_steps_per_epoch = 1\nelse:\n    validate_steps_per_epoch = (validate_set_size // validate_batch_size) + 1\n\nhistory = model.fit_generator(\n    generator=train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=20,\n    validation_data=validation_generator,\n    validation_steps = validate_steps_per_epoch,\n    callbacks=callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndice = history.history['dice_coeff']\nval_dice = history.history['val_dice_coeff']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(dice) + 1)\nplt.figure(1)\n_ = plt.plot(epochs, dice, 'bo', label='Training dice')\n_ = plt.plot(epochs, val_dice, 'b', label='Validation dice')\nplt.title('Training and validation dice scores')\n_ = plt.legend()\nplt.figure(2)\n_ = plt.plot(epochs, loss, 'bo', label='Training loss')\n_ = plt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\n_ = plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(mask):\n    height = mask.shape[0]\n    width = mask.shape[1]\n    reshaped_mask = mask.reshape(height*width, order=\"F\")\n    rle = \"\"\n    previous_equals_zero = True\n    reshaped_mask_length = len(reshaped_mask)\n    for i in range(reshaped_mask_length):\n        if (reshaped_mask[i] == 1.0) and previous_equals_zero:\n            previous_equals_zero = False\n            start_index = i\n            if i == reshaped_mask_length - 1:\n                one_sequence_length = 1\n                rle = rle + \" \" + str(start_index) + \" \" + str(one_sequence_length)\n        elif (reshaped_mask[i] == 0.0) and (not previous_equals_zero):\n            previous_equals_zero = True\n            one_sequence_length = i - start_index\n            rle = rle + \" \" + str(start_index) + \" \" + str(one_sequence_length)\n        elif (reshaped_mask[i] == 1.0) and (not previous_equals_zero) and (i == reshaped_mask_length-1):\n            one_sequence_length = i - start_index + 1\n            rle = rle + \" \" + str(start_index) + \" \" + str(one_sequence_length)\n    rle = rle[1:]\n    return rle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\nfrom numpy import squeeze\n\nthe_image = load_img(\"/kaggle/input/severstal-steel-defect-detection/test_images/1804f41eb.jpg\", target_size=(the_height, the_width))\nimage_array = img_to_array(the_image)\nimage_array = expand_dims(image_array, 0)\npredicted_mask = model.predict(image_array, batch_size=1)\npredicted_mask = squeeze(predicted_mask, 0)\npredicted_rle = mask2rle(predicted_mask)\nprint(\"predicted rle:\")\nprint(predicted_rle)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}