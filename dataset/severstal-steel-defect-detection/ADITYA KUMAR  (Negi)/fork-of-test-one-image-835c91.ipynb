{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n#!pip install segmentation_models\n\nimport os\nimport cv2\nimport tensorflow as tf\nimport keras \nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nfrom collections import defaultdict\nimport gc\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import  Adam\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint,Callback\n#import segmentation_models as sm\n#model = sm.Unet('resnet34', encoder_weights='imagenet')\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\n\nfrom keras.models import Model, load_model\nfrom keras.layers import AveragePooling2D,MaxPooling2D,Dense,Dropout,Flatten\n\nfrom keras.models import load_model\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    PadIfNeeded,\n    HorizontalFlip,\n    VerticalFlip,    \n    CenterCrop,    \n    Crop,\n    Compose,\n    Transpose,\n    RandomRotate90,\n    ElasticTransform,\n    GridDistortion, \n    OpticalDistortion,\n    RandomSizedCrop,\n    OneOf,\n    CLAHE,\n    RandomBrightnessContrast,    \n    RandomGamma,\n    RandomContrast,\n    InvertImg,\n    RandomContrast\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"import segmentation_models as sm\n\nBACKBONE = 'resnet34'\npreprocess_input = sm.backbones.get_preprocessing(BACKBONE)\nmodel = sm.Unet(BACKBONE,input_shape=(256, 1600,3),classes=4, activation='sigmoid',encoder_weights='imagenet')\n\nmodel.save(\"seg_model.h5\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection')\ntrain_df = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/train.csv')\ntrain_df['Image_id']= train_df[train_df.columns[0]].apply(lambda x : x.split('_')[0])\ntrain_df['class_id']= train_df[train_df.columns[0]].apply(lambda x : x.split('_')[1])\ntrain_df['mask']= ~train_df[train_df.columns[1]].isna()\nprint(train_df.shape)\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count=train_df.groupby(by='Image_id').agg(np.sum).reset_index()\nprint(mask_count.shape)\nmask_count.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count.sort_values(by='mask',ascending=False,inplace=True)\nmask_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/sample_submission.csv')\nsub_df['Image_id']=sub_df[sub_df.columns[0]].apply(lambda x : x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['Image_id'].unique(),columns=['Image_id'])\nprint(test_imgs.shape)\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '/kaggle/input/severstal-steel-defect-detection/train_images/'\ntrain_dir=os.listdir(train_path)\ntrain_dir[:3]\ntest_path = '/kaggle/input/severstal-steel-defect-detection/test_images/' \ntest_dir = os.listdir(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_class = load_model('/kaggle/input/classification-model/class_model.h5')\n#model_class.load_weights('/kaggle/input/classifier-model-weight/classifier.h5')\nimport sys\nimport os\nimport zipfile\npa='/kaggle/input/efficientnet'\n    \n    \nsys.path.append(os.path.abspath('/kaggle/input/efficientnet-models/efficientnet-master/'))\nfrom efficientnet.keras import EfficientNetB2,EfficientNetB3\nN_CLASSES=4\ndef ClsModel(n_classes=1, input_shape=(254,600,3)):\n    base_model = EfficientNetB2(weights=None, include_top=False, input_shape=input_shape)\n    x = AveragePooling2D(pool_size=(5,5), name='avg_pool')(base_model.output)\n    x = Flatten()(x)\n    x = Dense(1600, activation='relu', name='dense_post_pool')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_classes, activation='sigmoid', name='predictions')(x)\n    model = Model(inputs=base_model.input, output=output)\n    return model\nmodel = ClsModel(n_classes=N_CLASSES)\nN_CLASSES=4\ndef ClsModel(n_classes=1, input_shape=(254,254,3)):\n    base_model = EfficientNetB3(weights=None, include_top=False, input_shape=input_shape)\n    x = AveragePooling2D(pool_size=(3,3), name='avg_pool')(base_model.output)\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu', name='dense_post_pool')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_classes, activation='sigmoid', name='predictions')(x)\n    model = Model(inputs=base_model.input, output=output)\n    return model\nmodel_class = ClsModel(n_classes=N_CLASSES)\n#model_class.load_weights('/kaggle/input/efficient977/EfficientNetB3_efficenent_exp_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch size is fixed and 1 can include  patch size\nclass DataGenerator1(keras.utils.Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=train_path,val ='no',augmentaion =[1],\n                 batch_size=1, dim=(254, 600), n_channels=3,\n                 n_classes=4, random_state=1994, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.val=val\n        self.augmentaion=augmentaion\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        \n        indexes = self.indexes[self.batch_size*index:self.batch_size*(index+1)]\n\n        # Find list of IDs\n\n        ID = [self.list_IDs[k] for k in indexes]\n        X = self.__generate_X(ID)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(ID)   \n            return X,y # preprocess as resnet34  \n        elif self.mode == 'predict':\n            return X\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, ID):\n        'Generates data containing batch_size samples'\n        # Initialization \n        img_i = np.empty((self.batch_size,*self.dim,self.n_channels),dtype=np.uint8)\n        \n\n        # Generate data\n        for i,loc in enumerate(ID):\n            im_name = self.df['Image_id'].loc[loc]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img=cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img=cv2.resize(img ,(600,254))\n            #img_i[i,] = img \n            \n            if self.augmentaion[0]==1 : # don't change\n                img_i[i,] = img\n                continue;\n            aug_no =0\n            aug = self.augmentaion[aug_no](p=1)\n            img = aug(image=img)['image']\n            img_i[i,] = img\n        #rgb\n        return img_i\n\n    \n    def __generate_y(self, ID):\n        # image name\n        y = np.empty((self.batch_size,self.n_classes))\n        for i,loc in enumerate(ID):\n            y[i,] = self.df['mask'].loc[loc]\n        return y\n    \n    \n    def __load_rgb(self, img_path):\n        return cv2.imread(img_path)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch size is fixed and 1 can include  patch size\nclass DataGenerator2(keras.utils.Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=train_path,val ='no',augmentaion =[1],\n                 batch_size=1, dim=(254, 254), n_channels=3,\n                 n_classes=4, random_state=1994, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.val=val\n        self.augmentaion=augmentaion\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        \n        indexes = self.indexes[self.batch_size*index:self.batch_size*(index+1)]\n\n        # Find list of IDs\n\n        ID = [self.list_IDs[k] for k in indexes]\n        X = self.__generate_X(ID)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(ID)   \n            return X,y # preprocess as resnet34  \n        elif self.mode == 'predict':\n            return X\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, ID):\n        'Generates data containing batch_size samples'\n        # Initialization \n        img_i = np.empty((self.batch_size,*self.dim,self.n_channels),dtype=np.uint8)\n        \n\n        # Generate data\n        for i,loc in enumerate(ID):\n            im_name = self.df['Image_id'].loc[loc]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img=cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img=cv2.resize(img ,(254,254))\n            #img_i[i,] = img \n            \n            if self.augmentaion[0]==1 : # don't change\n                img_i[i,] = img\n                continue;\n            aug_no =0\n            aug = self.augmentaion[aug_no](p=1)\n            img = aug(image=img)['image']\n            img_i[i,] = img\n        #rgb\n        return img_i\n\n    \n    def __generate_y(self, ID):\n        # image name\n        y = np.empty((self.batch_size,self.n_classes))\n        for i,loc in enumerate(ID):\n            y[i,] = self.df['mask'].loc[loc]\n        return y\n    \n    \n    def __load_rgb(self, img_path):\n        return cv2.imread(img_path)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_class_2 = load_model('/kaggle/input/efficent-model-and-weights-975/efficent_class_model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_classifer_path=['/kaggle/input/efficent-b2-600/EfficientNetB3_efficenent_254_600_exp_4.h5',\n    '/kaggle/input/efficient977/EfficientNetB3_efficenent_exp_2.h5']\n\n#model_class_2 = load_model('/kaggle/input/efficent-model-and-weights-975/efficent_class_model.h5')\n\nclass_models =[model,model_class]\n\npred_class_i=[]\npred=[]\n\n\nDataGenerator=[DataGenerator1,DataGenerator2]\nfor i in range(2):\n    augmentaion=[1,HorizontalFlip,VerticalFlip]\n    for aug in augmentaion:  \n        class_models[i].load_weights(all_classifer_path[i])\n\n        test_generator = DataGenerator[i](\n                test_imgs.index,\n                df=test_imgs,\n                shuffle=False,\n                mode='predict',\n                base_path='../input/severstal-steel-defect-detection/test_images',\n                target_df=test_imgs,\n                augmentaion=[aug],\n                batch_size=1,\n                n_classes=4\n            )\n\n        batch_pred_class = class_models[i].predict_generator(\n                test_generator, \n                workers=1,\n                verbose=1,\n                use_multiprocessing=False\n            )\n        pred.append(batch_pred_class.round().astype(int))\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"np.sum(((pred_class_i[0]+pred_class_i[1]+pred_class_i[2])/3).round().astype(int),axis=0)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"pred=pred_class_i[0].round()*1.3+pred_class_i[1].round()+pred_class_i[2].round()\n\npred[pred==1]=0\npred[pred>=2]=1\npred=pred.round().astype('int')\nnp.sum(pred,axis=0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pred.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(test).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_1=np.array(test)\ntest_1=test_1[0]+test_1[1]+test_1[2]+test_1[3]+test_1[4]+test_1[5]\ntest_1[np.where(test_1<=2)]=0\ntest_1[np.where(test_1>2)]=1\nnp.sum(test_1,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"test=pred_class_i[0].round().astype(int).copy()\nnp.sum(test.round().astype(int),axis=0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(test_1.round().astype(int),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aaa=[128/43/741/120]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(batch_pred_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_class =test_1.round().astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(pred_class,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n\ndef mask_image(img,mask):\n    img_i = img\n\n    mask_i=mask\n    for ch in range(4):\n        contours, _ = cv2.findContours(mask_i[:, :, ch], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)        \n        for i in range(0, len(contours)):\n            cv2.polylines(img_i, contours[i], True, palet[ch], 2)\n        \n    return img_i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# batch size is fixed and 1 can include  patch size\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=train_path,\n                 batch_size=1, dim=(256, 1600), n_channels=3,\n                 n_classes=4, random_state=1994, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n    \n    \n    def __getitem__(self, index):\n            'Generate one batch of data'\n            # Generate indexes of the batch\n            indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n            # Find list of IDs\n            list_IDs_batch = [self.list_IDs[k] for k in indexes]\n\n            X = self.__generate_X(list_IDs_batch)\n\n            if self.mode == 'fit':\n                y = self.__generate_y(list_IDs_batch)\n                return X, y\n\n            elif self.mode == 'predict':\n                return X\n\n            else:\n                raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n            \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        \n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, ID):\n        'Generates data containing batch_size samples'\n        # Initialization        \n        # Generate data\n        img_i = np.empty((self.batch_size,*self.dim,self.n_channels),dtype=np.uint8)\n        for i,index in enumerate(ID):\n            im_name = self.df['Image_id'].loc[index]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img =cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n            img_i[i,]=img\n        return img_i\n    \n    def __generate_y(self, ID):\n        # image name\n        img_i = np.empty((self.batch_size,*self.dim,self.n_classes),dtype=np.uint8)\n        \n        for i,index in enumerate(ID):\n            im_name = self.df['Image_id'].loc[index]\n            # tran_df\n            image_df = self.target_df[self.target_df['Image_id'] == im_name]\n            rles = image_df['EncodedPixels'].values\n            img =build_masks(rles, input_shape=self.dim)\n            img_i[i,]=img\n        \n        return img_i\n    \n\n    \n    def __check_input__(self,index):\n        X,y=self.__getitem__(index)\n        \n        # Find list of IDs\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        ID=list_IDs_batch[0]\n        X=X[0]\n        y=y[0]\n        im_name=self.df['Image_id'].loc[ID]\n        img= cv2.imread(train_path+im_name)\n        image_df = self.target_df[self.target_df['Image_id'] == im_name]\n        rles = image_df['EncodedPixels'].values\n        masks = build_masks(rles, input_shape=self.dim)\n        \n        # Plot\n        fig,axis = plt.subplots(nrows=1,ncols=1, figsize=(20, 20))\n        for i in range(1):\n            try:\n                img_i=mask_image(X[i].astype(np.uint8),y[i].astype(np.uint8))\n                axis[i].imshow(img_i)\n            except IndexError: # less the 10 crop \n                print(\"IndexError : so skip\")\n                img_i=mask_image(X,y)\n                axis.imshow(img_i,cmap='gray')\n                \n                break\n            except TypeError: # only one crop\n                img_i=mask_image(X,y)\n                print(\"i\")\n\n                axis.imshow(img_i,cmap='gray')\n                print(\"TypeError (axis[i] is fails): so skip\")\n                break\n\n        img_i=mask_image(img.astype(np.uint8),masks.astype(np.uint8))\n        plt.figure(figsize=(10,10))\n        plt.imshow(img_i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_missing_train_idx = mask_count[mask_count['mask'] > 0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nBATCH_SIZE = 10\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=25, \n    test_size=0.2\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=non_missing_train_idx,\n    target_df=train_df,\n    batch_size=BATCH_SIZE,\n    n_classes=4,\n    mode='fit'\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=non_missing_train_idx,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n# genrator input to model\ntrain_generator.__check_input__(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics\ndef dice_coef(y_true, y_pred, smooth= 1e-6):\n    #y_true_f = K.flatten(y_true)\n    #y_pred_f = K.flatten(y_pred)\n    y_pred = K.round(y_pred)\n    intersection = K.sum(y_true * y_pred, axis=(1,2))\n    return K.mean((2. * intersection + smooth) / (K.sum(y_true, axis=(1,2)) + K.sum(y_pred, axis=(1,2)) + smooth))\n\n# loss function\ndef dice_loss(y_true, y_pred,smooth = 1e-9):\n    intersection = K.sum(y_true * y_pred, axis=(1,2))\n    score = (2. * intersection + smooth) / (K.sum(y_true, axis=(1,2)) + K.sum(y_pred, axis=(1,2)) + smooth)\n    return K.mean(1-score)\n\ndef bce_dice_loss(y_true, y_pred):\n    return dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth= 1e-6):\n    #y_true_f = K.flatten(y_true)\n    #y_pred_f = K.flatten(y_pred)\n    y_pred = K.round(y_pred)\n    intersection = K.sum(y_true * y_pred,axis=(1,2))\n    return K.mean((2. * intersection + smooth) / (K.sum(y_true, axis=(1,2)) + K.sum(y_pred, axis=(1,2)) + smooth))\n\nopt=keras.optimizers.Adam(lr=1e-4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = sm.Unet(BACKBONE,input_shape=(256, 1600,3),classes=4, activation='sigmoid')\n#model.compile(optimizer=opt,loss = 'binary_crossentropy',metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es=EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    verbose=1,\n    mode='min'\n)\nRR = ReduceLROnPlateau(\n        monitor = 'val_loss', \n        factor = 0.5, \n        patience = 2, \n        min_lr=1e-6, \n        verbose=1, \n        mode='min')\n\ncheckpoint = ModelCheckpoint(\n    '1600_FULL.h5', \n    monitor='val_loss', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='min',   \n)\n'''\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint,es,RR],\n    use_multiprocessing=False,\n    verbose=1,\n    workers=1,\n    epochs=20)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_seg = load_model('/kaggle/input/seg-model/seg_model .h5')\n#model_seg.load_weights('/kaggle/input/16000-model/1600.h5')\nmodel_seg.load_weights('/kaggle/input/16000-model/1600.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(pred_class,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsub_df['Image_id'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['Image_id'].unique(), columns=['Image_id'])\ntest_imgs=test_imgs\n\nfiltered_mask = sub_df['Image_id'].isin(test_imgs[\"Image_id\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(\n    lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\ntest_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nfiltered_sub_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_class=pred_class.flatten()\nall_class\nfiltered_sub_df['EncodedPixels']=all_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sliding_window(img, sz=256):\n    total=7\n    x=0\n    img=img[0]\n    new_img = np.empty((total,256,256,3),dtype=np.uint8)\n    for count in range(total-1):\n        new_img[count,]=img[:, x:x+sz, :]\n        x=x+sz\n    new_img[-1,]=img[:, -256:, :]\n    \n    return new_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch size is fixed and 1 can include  patch size\nclass DataGenerator2(keras.utils.Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=train_path,\n                 batch_size=1, dim=(256, 1600), n_channels=3,\n                 n_classes=4, random_state=1994, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) // self.batch_size))\n    \n    \n    def __getitem__(self, index):\n            'Generate one batch of data'\n            # Generate indexes of the batch\n            indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n            # Find list of IDs\n            list_IDs_batch = [self.list_IDs[k] for k in indexes]\n\n\n            X = self.__generate_X(list_IDs_batch)\n\n            if self.mode == 'fit':\n                y = self.__generate_y(list_IDs_batch)\n                return crop_rand_pattern(X, y)\n\n            elif self.mode == 'predict':\n                return sliding_window(X)\n            \n            elif self.mode=='val':\n                y = self.__generate_y(list_IDs_batch)\n                \n                return sliding_window_predict(X, y)\n            else:\n                raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n            \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        \n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, ID):\n        'Generates data containing batch_size samples'\n        # Initialization        \n        # Generate data\n        img_i = np.empty((self.batch_size,*self.dim,self.n_channels),dtype=np.uint8)\n        for i,index in enumerate(ID):\n            im_name = self.df['Image_id'].loc[index]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img =cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n            img_i[i,]=img\n        return img_i\n    \n    def __generate_y(self, ID):\n        # image name\n        img_i = np.empty((self.batch_size,*self.dim,self.n_classes),dtype=np.uint8)\n        \n        for i,index in enumerate(ID):\n            im_name = self.df['Image_id'].loc[index]\n            # tran_df\n            image_df = self.target_df[self.target_df['Image_id'] == im_name]\n            rles = image_df['EncodedPixels'].values\n            img =build_masks(rles, input_shape=self.dim)\n            img_i[i,]=img\n        \n        return img_i\n    \n\n    \n    def __check_input__(self,index):\n        X,y=self.__getitem__(index)\n        \n        # Find list of IDs\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        ID=list_IDs_batch\n        X=X\n        y=y\n        for i,ID in enumerate(list_IDs_batch):\n            im_name=self.df['Image_id'].loc[ID]\n            img= cv2.imread(train_path+im_name)\n            image_df = self.target_df[self.target_df['Image_id'] == im_name]\n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            img_i=mask_image(img.astype(np.uint8),masks.astype(np.uint8))\n            \n            plt.figure(figsize=(10,10))\n            plt.imshow(img_i)\n            plt.show()\n            \n        \n        # Plot\n        col=y.shape[0]\n        fig,axis = plt.subplots(nrows=1,ncols=col, figsize=(20, 20))\n        for i in range(col):\n            try:\n                img_i=mask_image(X[i].astype(np.uint8),y[i].astype(np.uint8))\n                axis[i].imshow(img_i)\n            except IndexError: # less the 10 crop \n                print(\"IndexError : so skip\")\n                img_i=mask_image(X[i].astype(np.uint8),y[i].astype(np.uint8))\n                axis.imshow(img_i,cmap='gray')\n                \n                break\n            except TypeError: # only one crop\n                img_i=mask_image(X[i].astype(np.uint8),y[i].astype(np.uint8))\n                print(\"i\")\n\n                axis.imshow(img_i,cmap='gray')\n                print(\"TypeError (axis[i] is fails): so skip\")\n                break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_seg_2 = load_model('/kaggle/input/seg-model-256-256/seg_model.h5')\nmodel_seg_2.load_weights('/kaggle/input/seg-weights-898/bce_dice_loss_bce_from_8963_exp_4.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n\ntest_df = []\n\nfor i in range(0, test_imgs.shape[0], 300):\n    batch_idx = list(\n        range(i, min(test_imgs.shape[0], i + 300))\n    )\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        target_df=test_imgs,\n        batch_size=1,\n        n_classes=4\n    )\n\n    batch_pred_masks = model_seg.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = test_imgs['Image_id'].iloc[b]\n        image_df = filtered_sub_df[filtered_sub_df['Image_id'] == filename].copy()\n        \n        pred_masks=batch_pred_masks[j,].round().astype(int)\n        value = np.sum(pred_masks,axis=(1,0))\n        # defect class by seg vs classifier True or flase\n        c1=np.array(value*image_df['EncodedPixels'])\n        \n        pred_masks=batch_pred_masks[j,]\n        pred_masks[np.where(pred_masks>0.6)]=1\n        pred_masks[np.where(pred_masks<=0.6)]=0\n        pred_rles = build_rles(pred_masks)\n        \n        pred_rles=np.array(pred_rles)\n        # if False\n        pred_rles[c1==0]=''\n\n        image_df['EncodedPixels'] = pred_rles\n        \n        test_df.append(image_df)\n        \n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.concat(test_df)\nprint(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1=np.sum(~(test_df.loc[np.arange(1801)*4]['EncodedPixels']=='').values)\nc2=np.sum(~(test_df.loc[np.arange(1801)*4+1]['EncodedPixels']=='').values)\nc3=np.sum(~(test_df.loc[np.arange(1801)*4+2]['EncodedPixels']=='').values)\nc4=np.sum(~(test_df.loc[np.arange(1801)*4+3]['EncodedPixels']=='').values)\nprint(\" class1 ={} \\n class2 ={} \\n class3 ={} \\n class4 ={}\".format(c1,c2,c3,c4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['dice_coef', 'val_dice_coef']].plot()\nhistory_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=np.array([0,2])\na[np.where(a>0.7)]=10\na","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}