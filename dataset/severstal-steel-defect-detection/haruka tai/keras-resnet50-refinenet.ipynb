{"cells":[{"metadata":{},"cell_type":"markdown","source":"ver2\n1. refineユニット後のupsampling後のconvをRCUに変更する→明らかにダメそうなので提出はしない\n\nver3\n1. refineユニット後を単純にupsampling4*4だけにしてみる→ダメそう\n\nver4\n1. refinenetの出力を元画像の1/4のままにする→推論時には出力画像を4倍する→ダメそう\n\nver5\n1. refinenetにBN層を追加する→精度ダメ72\n\nver6\n1. 損失関数をDiceにしてみる\n2. BN層を減らす\n→精度改善\n\nver7,8,9,10,11,12,13\n1. 画像サイズを半分にする→テストのときにはpredをresizeする\n2. 評価関数をsoftmax+crossentropyにする\n→精度0.85\n\nver14\n1. 画像サイズを半分\n2. モデルをxceptionにしてみる"},{"metadata":{},"cell_type":"markdown","source":"# import lib"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport tensorflow as tf\nimport time\n\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.xception import Xception\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D\nfrom keras import optimizers\nfrom keras.layers.normalization import BatchNormalization as BN\n\nfrom keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D, ZeroPadding2D\nfrom keras.models import Model\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.utils import plot_model\nfrom keras import backend as K\n\nfrom keras.regularizers import l2\n\nfrom keras.callbacks import ModelCheckpoint\n\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image, ImageDraw, ImageFilter\nprint(os.listdir(\"../input/keras-pretrained-models\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# data load"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ImageId'] = train['ImageId_ClassId'].str[:-2]\ntrain['ClassId'] = train['ImageId_ClassId'].str[-1:]\ntrain = train[['ImageId','ClassId','EncodedPixels']]\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# for train index"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\n\nfilelist = os.listdir(\"../input/severstal-steel-defect-detection/train_images/\")\n\ntrain_img = []\n\nfor i in filelist:\n    x = train[train[\"ImageId\"] == i]\n    if len(x[x[\"EncodedPixels\"] == 0]) == 4:\n        pass\n        \n    else:\n        train_img.append(i)\n        \ntrain_img = np.array(train_img)\n\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# indicate image"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = train[\"ImageId\"][43212]\nimg_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abs_path = \"../input/severstal-steel-defect-detection/train_images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_image = cv2.imread(abs_path+img_name)\nplt.figure(figsize=(15,15))\nplt.imshow(seed_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# indicate segment"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_exact = train[train[\"ImageId\"] == img_name]\ndf_exact","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_exact2 = df_exact[df_exact[\"ClassId\"] == \"1\"]\ndf_exact2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"segment_4 = []\nfor i in range(4):\n    x = train[train[\"ImageId\"] == img_name]\n    x2 = x[x[\"ClassId\"] == str(i+1)]\n    x3 = x2[\"EncodedPixels\"].values[0]\n    \n    if x3 ==0:\n        x4 = \"ok\"\n        \n    else:\n        x4 = x3.split()\n        \n    segment_4.append(x4)\n\nsegment_4 = np.array(segment_4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"segment_4[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#セグメンテーションの生成\nseg_img = np.zeros([seed_image.shape[0], seed_image.shape[1],4], dtype=np.uint8)\n\nfor j in range(4):\n    \n    seg_np = np.zeros([seed_image.shape[0]*seed_image.shape[1]], dtype=np.uint8)\n    \n    if segment_4[j]==\"ok\":\n        pass\n    \n    else:\n        for i in range(len(segment_4[j])//2):\n            start = int(segment_4[j][2*i])\n            length = int(segment_4[j][2*i+1])\n            seg_np[start:start+length]=1\n\n    seg_img[:,:,j] = seg_np.reshape([seed_image.shape[1],seed_image.shape[0]]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_image = cv2.resize(seed_image, dsize=(800, 128))\nseg_img = cv2.resize(seg_img, dsize=(800, 128))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nplt.imshow(seed_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nplt.imshow(seg_img[:,:,0],\"gray\",vmin=0,vmax=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def vertical_flip(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = image[::-1, :, :]\n        fmap = fmap[::-1, :, :]\n    return image, fmap\n\n\ndef horizontal_flip(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = image[:, ::-1, :]\n        fmap = fmap[:, ::-1, :]\n    return image, fmap\n\ndef image_translation(img,fmap):\n    params = np.random.randint(-50, 51)\n    if not isinstance(params, list):\n        params = [params, params]\n    rows, cols, ch = img.shape\n\n    M = np.float32([[1, 0, params[0]], [0, 1, params[1]]])\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return dst, fmap\n\ndef image_shear(img,fmap):\n    params = np.random.randint(-20, 21)*0.01\n    rows, cols, ch = img.shape\n    factor = params*(-1.0)\n    M = np.float32([[1, factor, 0], [0, 1, 0]])\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return dst, fmap\n\ndef image_rotation(img,fmap):\n    params = np.random.randint(-5, 6)\n    rows, cols, ch = img.shape\n    M = cv2.getRotationMatrix2D((cols/2, rows/2), params, 1)\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return dst,fmap\n\ndef image_contrast(img,fmap):\n    params = np.random.randint(7, 10)*0.1\n    alpha = params\n    dst = cv2.multiply(img, np.array([alpha]))                    # mul_img = img*alpha\n    #new_img = cv2.add(mul_img, beta)                                  # new_img = img*alpha + beta\n  \n    return dst, fmap\n\ndef image_blur(img,fmap):\n    params = params = np.random.randint(1, 21)\n    blur = []\n    if params == 1:\n        blur = cv2.blur(img, (3, 3))\n    if params == 2:\n        blur = cv2.blur(img, (4, 4))\n    if params == 3:\n        blur = cv2.blur(img, (5, 5))\n    if params == 4:\n        blur = cv2.GaussianBlur(img, (3, 3), 0)\n    if params == 5:\n        blur = cv2.GaussianBlur(img, (5, 5), 0)\n    if params == 6:\n        blur = cv2.GaussianBlur(img, (7, 7), 0)\n    if params == 7:\n        blur = cv2.medianBlur(img, 3)\n    if params == 8:\n        blur = cv2.medianBlur(img, 5)\n    if params == 9:\n        blur = cv2.blur(img, (6, 6))\n    if params == 10:\n        blur = cv2.bilateralFilter(img, 9, 75, 75)\n    if params > 10:\n        blur = img\n        \n    return blur.reshape([blur.shape[0],blur.shape[1],1]), fmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dst, fmap = vertical_flip(seed_image, seg_img)\n\nplt.subplot(2, 1, 1)\nplt.imshow(dst, \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\",vmin=0,vmax=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dst, fmap = horizontal_flip(seed_image, seg_img)\n\nplt.subplot(2, 1, 1)\nplt.imshow(dst)\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dst, fmap = image_translation(seed_image, seg_img)\n\nplt.subplot(2, 1, 1)\nplt.imshow(dst)\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dst, fmap = image_shear(seed_image, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst)\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dst, fmap = image_rotation(seed_image, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst)\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dst, fmap = image_contrast(seed_image, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst)\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train split"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(2019)\nnp.random.shuffle(train_img)\ntrain_num = int(len(train_img)*0.80)\ntrain_idx = train_img[:train_num]\nval_idx = train_img[train_num:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# make model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 800, 128\nnum_train = len(train_idx)\nnum_val = len(val_idx)\n\npretrain_model = \"xception\"\n\nbatch_size = 8\nprint(num_train, num_val)\nabs_path = \"../input/severstal-steel-defect-detection/train_images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_segment_data(train, img_name, img_height, img_width):\n    segment_4 = []\n    for i in range(4):\n        x = train[train[\"ImageId\"] == img_name]\n        x2 = x[x[\"ClassId\"] == str(i+1)]\n        x3 = x2[\"EncodedPixels\"].values[0]\n\n        if x3 ==0:\n            x4 = \"ok\"\n\n        else:\n            x4 = x3.split()\n            \n        segment_4.append(x4)\n\n    segment_4 = np.array(segment_4)\n    \n    #セグメンテーションの生成\n    seg_img = np.zeros([img_height, img_width,5], dtype=np.uint8)\n\n    for j in range(4):\n\n        seg_np = np.zeros([img_height*img_width], dtype=np.uint8)\n\n        if segment_4[j]==\"ok\":\n            pass\n\n        else:\n            length=len(segment_4[j])//2\n            for i in range(length):\n                start = int(segment_4[j][2*i])\n                length = int(segment_4[j][2*i+1])\n                seg_np[start:start+length]=1\n\n        seg_img[:,:,j+1] = seg_np.reshape([img_width,img_height]).T\n        \n    #seg_img[:,:,0] = np.ones([seed_image.shape[0], seed_image.shape[1]], dtype=np.uint8) - seg_img[:,:,1] - seg_img[:,:,2] - seg_img[:,:,3] - seg_img[:,:,4]\n                \n    return seg_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_random_data(train_pd, img_index_1, abs_path, img_width, img_height, data_aug):\n    image_file = abs_path + img_index_1\n    \n    seed_image = cv2.imread(image_file)\n    fmap = get_segment_data(train_pd, img_index_1, img_height, img_width)\n    \n    seed_image = cv2.resize(seed_image, dsize=(img_width, img_height))\n    fmap = cv2.resize(fmap, dsize=(img_width, img_height))\n    \n    if data_aug:\n        \n        r = np.random.rand()\n        \n        if r >= 0.5:\n    \n            seed_image, fmap = vertical_flip(seed_image, fmap)\n            seed_image, fmap = horizontal_flip(seed_image, fmap)\n            seed_image, fmap = image_shear(seed_image, fmap)\n            seed_image, fmap = image_rotation(seed_image, fmap)\n            seed_image, fmap = image_contrast(seed_image, fmap)\n    \n    seed_image = seed_image / 255\n    \n    fmap[:,:,0] = np.ones([img_height, img_width], dtype=np.float32) - fmap[:,:,1] - fmap[:,:,2] - fmap[:,:,3] - fmap[:,:,4]\n    \n    return seed_image, fmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_generator(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug):\n    '''data generator for fit_generator'''\n    n = len(img_index)\n    i = 0\n    while True:\n        image_data = []\n        fmap_data = []\n        for b in range(batch_size):\n            if i==0:\n                np.random.shuffle(img_index)\n            image, fmap = get_random_data(train_pd, img_index[i], abs_path, img_width, img_height, data_aug)\n            image_data.append(image)\n            fmap_data.append(fmap)\n            i = (i+1) % n\n        image_data = np.array(image_data)\n        fmap_data = np.array(fmap_data)\n        yield image_data, fmap_data\n\ndef data_generator_wrapper(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug):\n    n = len(img_index)\n    if n==0 or batch_size<=0: return None\n    return data_generator(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape=(img_height, img_width, 3))\n\nif pretrain_model == \"xception\":\n\n    basemodel = Xception(include_top=False, weights=None, input_tensor=input_tensor)\n\n    basemodel.load_weights(\"../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n    \nelse:\n\n    basemodel = ResNet50(include_top=False, weights=None, input_tensor=input_tensor)\n\n    basemodel.load_weights(\"../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n\nbasemodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shortcut_en(x, residual):\n    '''shortcut connection を作成する。\n    '''\n    x_shape = K.int_shape(x)\n    residual_shape = K.int_shape(residual)\n\n    if x_shape == residual_shape:\n        # x と residual の形状が同じ場合、なにもしない。\n        shortcut = x\n    else:\n        # x と residual の形状が異なる場合、線形変換を行い、形状を一致させる。\n        stride_w = int(round(x_shape[1] / residual_shape[1]))\n        stride_h = int(round(x_shape[2] / residual_shape[2]))\n\n        shortcut = Conv2D(filters=residual_shape[3],\n                          kernel_size=(1, 1),\n                          strides=(stride_w, stride_h),\n                          kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n    return Add()([shortcut, residual])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RCU(data, filters, conv_sepa = True):\n    \n    if conv_sepa:\n    \n        x = BN()(data)\n        x = Activation(\"relu\")(x)\n        x = SeparableConv2D(filters=filters,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        x = Activation(\"relu\")(x)\n        x = SeparableConv2D(filters=filters,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n\n        x = shortcut_en(data, x)\n        \n    else:\n    \n        x = BN()(data)\n        x = Activation(\"relu\")(data)\n        x = Conv2D(filters=filters,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(filters=filters,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n\n        x = shortcut_en(data, x)\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#re4 -> (8,50,2048)\n#re3 -> (16,100,1024)\n#re2 -> (32,200,512)\n#re1 -> (64,400,256)\n\ndef Multi_Resolution_Fusion(re4, re3, re2, re1, conv_sepa = True):\n    \n    if conv_sepa:\n    \n        re3_shape = K.int_shape(re3)\n        re4 = SeparableConv2D(filters=re3_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(re4)\n        re4 = BN()(re4)\n        re4 = UpSampling2D((2,2))(re4)\n        re3_4 = Add()([re3, re4])\n\n        re2_shape = K.int_shape(re2)\n        re3_4 = SeparableConv2D(filters=re2_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(re3_4)\n        re3_4 = BN()(re3_4)\n        re3_4 = UpSampling2D((2,2))(re3_4)\n        re2_3_4 = Add()([re2, re3_4])\n\n        re1_shape = K.int_shape(re1)\n        re2_3_4 = SeparableConv2D(filters=re1_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(re2_3_4)\n        re2_3_4 = BN()(re2_3_4)\n        re2_3_4 = UpSampling2D((2,2))(re2_3_4)\n        re1_2_3_4 = Add()([re1, re2_3_4])\n        \n    else:\n    \n        re3_shape = K.int_shape(re3)\n        re4 = Conv2D(filters=re3_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(re4)\n        re4 = BN()(re4)\n        re4 = UpSampling2D((2,2))(re4)\n        re3_4 = Add()([re3, re4])\n\n        re2_shape = K.int_shape(re2)\n        re3_4 = Conv2D(filters=re2_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(re3_4)\n        re3_4 = BN()(re3_4)\n        re3_4 = UpSampling2D((2,2))(re3_4)\n        re2_3_4 = Add()([re2, re3_4])\n\n        re1_shape = K.int_shape(re1)\n        re2_3_4 = Conv2D(filters=re1_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(re2_3_4)\n        re2_3_4 = BN()(re2_3_4)\n        re2_3_4 = UpSampling2D((2,2))(re2_3_4)\n        re1_2_3_4 = Add()([re1, re2_3_4])\n    \n    return re1_2_3_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Chained_Residual_Pooling(data, conv_sepa = True):\n    \n    if conv_sepa:\n    \n        data_shape = K.int_shape(data)\n\n        data = Activation(\"relu\")(data)\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(data)\n        x = SeparableConv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        data = Add()([data, x])\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(x)\n        x = SeparableConv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        data = Add()([data, x])\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(x)\n        x = SeparableConv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        data = Add()([data, x])\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(x)\n        x = SeparableConv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        data = Add()([data, x])\n        \n    else:\n    \n        data_shape = K.int_shape(data)\n\n        data = Activation(\"relu\")(data)\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(data)\n        x = Conv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        data = Add()([data, x])\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(x)\n        x = Conv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        data = Add()([data, x])\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(x)\n        x = Conv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        data = Add()([data, x])\n\n        x = MaxPooling2D(pool_size=5, strides=1, padding='same')(x)\n        x = Conv2D(filters=data_shape[3],kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        data = Add()([data, x])\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if pretrain_model == \"xception\":\n    \n    re1 = basemodel.get_layer(\"block3_sepconv2_bn\").output\n    re1 = ZeroPadding2D(padding=((1, 0), (1, 0)))(re1)\n\n    re2 = basemodel.get_layer(\"block4_sepconv2_bn\").output\n\n    re3 = basemodel.get_layer(\"block13_sepconv2_bn\").output\n\n    re4 = basemodel.output\n    \n    re1 = RCU(re1, 256)\n    re1 = RCU(re1, 256)\n\n    re2 = RCU(re2, 256)\n    re2 = RCU(re2, 256)\n\n    re3 = RCU(re3, 256)\n    re3 = RCU(re3, 256)\n\n    re4 = RCU(re4, 512)\n    re4 = RCU(re4, 512)\n\n    re = Multi_Resolution_Fusion(re4, re3, re2, re1)\n    re = Chained_Residual_Pooling(re)\n\n    re = RCU(re, 256)\n\n    x1 = Conv2DTranspose(filters=128,kernel_size=(1,1),strides=(2,2),padding=\"same\",kernel_initializer='he_normal',\n                              kernel_regularizer=l2(1.e-4))(re)\n\n    x = UpSampling2D((2,2))(re)\n    x=Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n    x = BN()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Add()([x,x1])\n\n    x2 = Conv2DTranspose(filters=64,kernel_size=(1,1),strides=(2,2),padding=\"same\",kernel_initializer='he_normal',\n                              kernel_regularizer=l2(1.e-4))(x)\n\n    x = UpSampling2D((2,2))(x)\n    x=Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n    x = BN()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Add()([x,x2])\n\n    x=Conv2D(filters=5,kernel_size=(1,1),strides=(1,1),padding=\"same\")(x)\n    outputs = Activation('softmax')(x)\n    \nelse:\n    \n    re1 = basemodel.get_layer(\"activation_10\").output\n\n    re2 = basemodel.get_layer(\"activation_22\").output\n\n    re3 = basemodel.get_layer(\"activation_40\").output\n\n    re4 = basemodel.output\n\n    re1 = RCU(re1, 256, conv_sepa = False)\n    re1 = RCU(re1, 256, conv_sepa = False)\n\n    re2 = RCU(re2, 256, conv_sepa = False)\n    re2 = RCU(re2, 256, conv_sepa = False)\n\n    re3 = RCU(re3, 256, conv_sepa = False)\n    re3 = RCU(re3, 256, conv_sepa = False)\n\n    re4 = RCU(re4, 512, conv_sepa = False)\n    re4 = RCU(re4, 512, conv_sepa = False)\n\n    re = Multi_Resolution_Fusion(re4, re3, re2, re1, conv_sepa = False)\n    re = Chained_Residual_Pooling(re, conv_sepa = False)\n    \n    re = RCU(re, 256)\n\n    x = UpSampling2D((2,2))(re)\n    x = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n    x = BN()(x)\n    x = Activation(\"relu\")(x)\n\n    x = UpSampling2D((2,2))(x)\n    x = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n    x = BN()(x)\n    x = Activation(\"relu\")(x)\n    \n    x = Conv2D(filters=5,kernel_size=(1,1),strides=(1,1),padding=\"same\")(x)\n    outputs = Activation('softmax')(x)\n\n# instantiate decoder model\nmodel = Model(basemodel.input, outputs)\nmodel.summary()\n\n#model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\nmodel.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelCheckpoint = ModelCheckpoint(filepath = 'best_weight.h5',\n                                  monitor='val_acc',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=True,\n                                  mode='max',\n                                  period=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\n\nmodel.fit_generator(data_generator_wrapper(train,train_idx, batch_size, abs_path, img_width, img_height, True),\n        steps_per_epoch=max(1, num_train//batch_size),\n        validation_data=data_generator_wrapper(train,val_idx, batch_size, abs_path, img_width, img_height, False),\n        validation_steps=max(1, num_val//batch_size),\n        epochs=6,\n        initial_epoch=0,\n        callbacks=[modelCheckpoint])\n\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"best_weight.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pred test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"../input/severstal-steel-defect-detection/test_images/\"\n\ntest_list = os.listdir(test_path)\n\nabs_name = test_path + test_list[0]\nseed_image = cv2.imread(abs_name)\nseed_image = cv2.resize(seed_image, dsize=(img_width, img_height))\nseed_image = np.expand_dims(seed_image, axis=0)\nseed_image = seed_image/255\npred = model.predict(seed_image)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nplt.imshow(seed_image[0,:,:,0], \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = cv2.resize(pred, dsize=(1600, 256))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(15,15), sharey=True)\nsns.heatmap(pred[:,:,0],vmin=0, vmax=1, ax=ax1)\nsns.heatmap(pred[:,:,1],vmin=0, vmax=1, ax=ax2)\nsns.heatmap(pred[:,:,2],vmin=0, vmax=1, ax=ax3)\nsns.heatmap(pred[:,:,3],vmin=0, vmax=1, ax=ax4)\nsns.heatmap(pred[:,:,4],vmin=0, vmax=1, ax=ax5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_testdata(a):\n\n    data = []\n    c = 1\n\n    for i in range(a.shape[0]-1):\n        if a[i]+1 == a[i+1]:\n            c += 1\n            if i == a.shape[0]-2:\n                data.append(str(a[i-c+2]))\n                data.append(str(c))\n\n        if a[i]+1 != a[i+1]:\n            data.append(str(a[i-c+1]))\n            data.append(str(c))\n            c = 1\n\n    data = \" \".join(data)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\n\ntest_path = \"../input/severstal-steel-defect-detection/test_images/\"\n\ntest_list = os.listdir(test_path)\n\ndata = []\n\nfor fn in test_list:\n    abs_name = test_path + fn\n    seed_image = cv2.imread(abs_name)\n    seed_image = cv2.resize(seed_image, dsize=(img_width, img_height))\n    seed_image = np.expand_dims(seed_image, axis=0)\n    seed_image = seed_image/255\n    pred = model.predict(seed_image)[0]\n    pred = cv2.resize(pred, dsize=(1600, 256))\n    for i in range(4):\n        \n        pred_fi = pred[:,:,i+1].T.flatten()\n        pred_fi = np.where(pred_fi > 0.25, 1, 0)\n        pred_fi_id = np.where(pred_fi == 1)\n        pred_fi_id = make_testdata(pred_fi_id[0])\n        x = [fn + \"_\" + str(i+1), pred_fi_id]\n        data.append(x)\n\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['ImageId_ClassId', 'EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = pd.DataFrame(data=data, columns=columns, dtype='str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"submission.csv\")\nprint(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}