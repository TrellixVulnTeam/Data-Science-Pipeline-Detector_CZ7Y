{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport json\n\nimport cv2\n\nimport keras\nfrom keras import backend as K\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.layers import Input, BatchNormalization, Activation, Dropout\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.losses import binary_crossentropy\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nimport multiprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\ntrain['ImageId'] = train['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain['ClassId'] = train['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain['hasMask'] = ~ train['EncodedPixels'].isna()\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count = train.groupby('ImageId').agg(np.sum).reset_index()\n\nmask_count.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count.shape)\n\nmask_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\n\nsub['ImageId'] = sub['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n\ntest_imgs = pd.DataFrame(sub['ImageId'].unique(), columns=['ImageId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(mask_rle, shape=(256,1600)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_masks(rles, input_shape):\n    depth = len(rles)\n    height, width = input_shape\n    masks = np.zeros((height, width, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, (width, height))\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs_folder = '../input/severstal-steel-defect-detection/test_images/'\ntrain_imgs_folder = '../input/severstal-steel-defect-detection/train_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=16, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_grayscale(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n#         img = cv2.resize(img, self.dim)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img\n    \n#     def __init__(self, images_list=None, folder_imgs=train_imgs_folder, \n#                  batch_size=32, shuffle=True, augmentation=None,\n#                  resized_height=224, resized_width=224, num_channels=3):\n#         self.batch_size = batch_size\n#         self.shuffle = shuffle\n#         self.augmentation = augmentation\n#         if images_list is None:\n#             self.images_list = os.listdir(folder_imgs)\n#         else:\n#             self.images_list = deepcopy(images_list)\n#         self.folder_imgs = folder_imgs\n#         self.len = len(self.images_list) // self.batch_size\n#         self.resized_height = resized_height\n#         self.resized_width = resized_width\n#         self.num_channels = num_channels\n#         self.num_classes = 4\n#         self.is_test = not 'train' in folder_imgs\n#         if not shuffle and not self.is_test:\n#             self.labels = [img_2_ohe_vector[img] for img in self.images_list[:self.len*self.batch_size]]\n\n#     def __len__(self):\n#         return self.len\n    \n#     def on_epoch_start(self):\n#         if self.shuffle:\n#             random.shuffle(self.images_list)\n\n#     def __getitem__(self, idx):\n#         current_batch = self.images_list[idx * self.batch_size: (idx + 1) * self.batch_size]\n#         X = np.empty((self.batch_size, self.resized_height, self.resized_width, self.num_channels))\n#         y = np.empty((self.batch_size, self.num_classes))\n\n#         for i, image_name in enumerate(current_batch):\n#             path = os.path.join(self.folder_imgs, image_name)\n#             img = cv2.resize(cv2.imread(path), (self.resized_height, self.resized_width)).astype(np.float32)\n#             if not self.augmentation is None:\n#                 augmented = self.augmentation(image=img)\n#                 img = augmented['image']\n#             X[i, :, :, :] = img/255.0\n#             if not self.is_test:\n#                 y[i, :] = img_2_ohe_vector[image_name]\n#         return X, y\n\n#     def get_labels(self):\n#         if self.shuffle:\n#             images_current = self.images_list[:self.len*self.batch_size]\n#             labels = [img_2_ohe_vector[img] for img in images_current]\n#         else:\n#             labels = self.labels\n#         return np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    mask_count.index, random_state=2019, test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count,\n    target_df=train,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_count,\n    target_df=train,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\n\ndef build_model(input_shape):\n    inputs = Input(input_shape)\n\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    u6 = concatenate([u6, c5])\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4])\n    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n        # Load ImageNet weights\n#     if encoder == 'vgg19':\n#         pretrained_model = VGG19(include_top=False)\n#     else:\n# #         pretrained_model = VGG16(include_top=False)\n    \n#     pretrained_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n#     for layer, pretrained_layer in zip(\n#             model.layers[2:], pretrained_model.layers[2:]):\n#         layer.set_weights(pretrained_layer.get_weights())\n#     imagenet_weights = pretrained_model.layers[1].get_weights()\n#     init_bias = imagenet_weights[1]\n#     init_kernel = np.average(imagenet_weights[0], axis=2)\n#     init_kernel = np.reshape(\n#         init_kernel,\n#         (init_kernel.shape[0],\n#             init_kernel.shape[1],\n#             1,\n#             init_kernel.shape[2]))\n#     init_kernel = np.dstack([init_kernel] * img_input.shape.as_list()[-1])  # input image is grayscale\n#     model.layers[1].set_weights([init_kernel, init_bias])\n    \n    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnet50(input_shape):\n    inputs = Input(input_shape)\n    \n    model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n    \n    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\ndef conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # first layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # second layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x\n  \ndef get_unet(input_shape, n_filters = 16, dropout = 0.1, batchnorm = True):\n    # Contracting Path\n    inputs = Input(input_shape)\n    \n    c1 = conv2d_block(inputs, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    \n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model((256, 1600, 1))\n# model = resnet50((224, 224, 3))\n# model = get_unet((256, 1600, 1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_dice_coef', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint],\n#     use_multiprocessing=True,\n#     workers=multiprocessing.cpu_count(),\n#     worker=1,\n    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')\ntest_df = []\n\nfor i in range(0, test_imgs.shape[0], 500):\n    batch_idx = list(\n        range(i, min(test_imgs.shape[0], i + 500))\n    )\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        target_df=sub,\n        batch_size=1,\n        n_classes=4\n    )\n    \n    batch_pred_masks = model.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = test_imgs['ImageId'].iloc[b]\n        image_df = sub[sub['ImageId'] == filename].copy()\n        \n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n        \n        image_df['EncodedPixels'] = pred_rles\n        test_df.append(image_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.concat(test_df)\ntest_df.drop(columns='ImageId', inplace=True)\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}