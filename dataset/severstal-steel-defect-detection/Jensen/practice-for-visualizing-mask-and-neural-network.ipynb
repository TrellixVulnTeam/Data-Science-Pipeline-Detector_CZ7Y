{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\nimport sys\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\ntrain_dir = '../input/severstal-steel-defect-detection/' \ntrain_image_dir = os.path.join(train_dir, 'train_images') \ntrain = pd.read_csv(os.path.join(train_dir, 'train.csv'))\ntrain['ClassId_EncodedPixels'] = train.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\ngrouped_EncodedPixels = train.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)\nimg_h=256\nimg_w=256\nk_size=3\nbatch_size=10\nepochs=1\ntrain=train.dropna(subset=['EncodedPixels'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def rle2mask(rle,img):\n\twidth=img.shape[0]\n\tlength=img.shape[1]\n\tmask= np.zeros(width*length).astype(np.uint8)\n\trle=rle.split()\n\tstarts = rle[0::2]\n\tlengths = rle[1::2]\n\tfor i in range(len(starts)):\n\t\tmask[int(starts[i]):(int(starts[i])+int(lengths[i]))]=1\n\treturn np.flipud(np.rot90(mask.reshape(length, width), k=1 ) )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train.ImageId))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.barplot(x=train.ClassId.value_counts().index,y=train.ClassId.value_counts())\nplt.ylabel('')\nplt.xlabel('ClassId')\nplt.title(\"Number of images for each class\",size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(20,10))\ncol=2\nrow=5\nfor i in range(1,11):\n\tfig.add_subplot(row,col,i)\n\tGraph=train['ImageId'][i]\n\timg_new=cv2.imread(\"../input/severstal-steel-defect-detection/train_images/\"+Graph)\n\timg_new= cv2.cvtColor(img_new,cv2.COLOR_BGR2RGB)\n\tmask = rle2mask(train['EncodedPixels'].iloc[i], img_new)\n\timg_new[mask==1,0] = 255\n\tplt.imshow(img_new)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n\timg_flt= img.T.flatten()\n\timg_flt= np.concatenate([[0],img_flt,[0]]) \n\truns = np.where(img_flt[1:] != img_flt[:-1])[0]  \n\truns[1::2] -= runs[::2]\n\treturn ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, list_ids, labels, image_dir, batch_size=32,\n                 img_h=256, img_w=256, shuffle=True):\n        \n        self.list_ids = list_ids\n        self.labels = labels\n        self.image_dir = image_dir\n        self.batch_size = batch_size\n        self.img_h = img_h\n        self.img_w = img_w\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_ids)) / self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        list_ids_temp = [self.list_ids[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(list_ids_temp)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.list_ids))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, list_ids_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n        y = np.empty((self.batch_size, self.img_h, self.img_w, 4))\n        \n        for idx, id in enumerate(list_ids_temp):\n            file_path =  os.path.join(self.image_dir, id)\n            image = cv2.imread(file_path, 0)\n            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            # standardization of the image\n            image_resized -= image_resized.mean()\n            image_resized /= image_resized.std()\n            \n            mask = np.empty((img_h, img_w, 4))\n            \n            for idm, image_class in enumerate(['1','2','3','4']):\n                rle = self.labels.get(id + '_' + image_class)\n                # if there is no mask create empty mask\n                if rle is None:\n                    class_mask = np.zeros((1600, 256))\n                else:\n                    class_mask = rle_to_mask(rle, width=1600, height=256)\n             \n                class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n                mask[...,idm] = class_mask_resized\n            \n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            y[idx,] = mask\n        \n        # normalize Y\n        y = (y > 0).astype(int)\n            \n        return X, y\n\nmasks={}\nfor index,row in train[train['EncodedPixels']!=-1].iterrows():\n\tmasks[row['ImageId']]=row['EncodedPixels']\n\n\ntrain_image_ids=os.listdir('../input/severstal-steel-defect-detection/train_images/')\ntrain_image_ids.sort(key=lambda x:str(x[:-4]))\nX_train, X_val = train_test_split(train_image_ids, test_size=0.2, random_state=42)\ntrain_generator=DataGenerator(X_train,masks,train_image_dir,batch_size=32,img_h=256,img_w=256,shuffle=True)\nvalidation_generator =DataGenerator(X_val, masks,train_image_dir,batch_size=32,img_h=256,img_w=256,shuffle=True)\n\ndef viz_steel(img,masks):\n\timg=cv2.cvtColor(img.astype('float64'),cv2.COLOR_RGB2BGR)\n\tfig,ax=plt.subplots(nrows=1,ncols=4,sharey=True,figsize=(20,10))\n\tcmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n\tfor idx, mask in enumerate(masks):\n\t\tax[idx].imshow(img)\n\t\tax[idx].imshow(mask, alpha=0.3, cmap=cmaps[idx])\nx, y = train_generator.__getitem__(0)\n#for ix in range(0,batch_size):\n#\tif y[ix].sum() > 0:\n#\t\timg = x[ix]\n#\t\tmasks_temp = [y[ix][...,i] for i in range(0,4)]\n#\t\tviz_steel(img, masks_temp)\n\n\nfrom tensorflow import reduce_sum\nfrom tensorflow.keras.backend import pow\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPool2D,UpSampling2D,Concatenate,Add,Flatten\nfrom tensorflow.keras.losses import binary_crossentropy\n\ndef bn_act(x,act=True):\n\tx=tf.keras.layers.BatchNormalization()(x)\n\tif act==True:\n\t\tx=tf.keras.layers.Activation('relu')(x)\n\treturn x\n\ndef conv_block(x,filters,kernel_size=3,padding='same',strides=1):\n\tconv=bn_act(x)\n\tconv=Conv2D(filters,kernel_size,padding=padding,strides=strides)(conv)\n\treturn conv\n\ndef stem(x,filters,kernel_size=3,padding='same',strides=1):\n\tconv=Conv2D(filters,kernel_size,padding=padding,strides=strides)(x)\n\tconv=conv_block(conv,filters,kernel_size,padding,strides)\n\tshortcut=Conv2D(filters,kernel_size=1,padding=padding,strides=strides)(x)\n\tshortcut=bn_act(shortcut,act=False)\n\toutput=Add()([conv,shortcut])\n\treturn output\n\ndef residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n    res = conv_block(x, filters, k_size, padding, strides)\n    res = conv_block(res, filters, k_size, padding, 1)\n    shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    output = Add()([shortcut, res])\n    return output\n\ndef upsample_concat_block(x,xskip):\n\tu=UpSampling2D((2,2))(x)\n\tc=Concatenate()([u,xskip])\n\treturn c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResUNet(img_h,img_w):\n\tf=[16,32,64,128,256]\n\tinputs=Input((img_h,img_w,1))\n\n\te0=inputs\n\te1=stem(e0,f[0])\n\te2=residual_block(e1,f[1],strides=2)\n\te3=residual_block(e2,f[2],strides=2)\n\te4=residual_block(e3,f[3],strides=2)\n\te5=residual_block(e4,f[4],strides=2)\n\n\tb0=conv_block(e5,f[4],strides=1)\n\tb1=conv_block(b0,f[4],strides=1)\n\n\tu1=upsample_concat_block(b1,e4)\n\td1=residual_block(u1,f[4])\n\n\tu2=upsample_concat_block(d1,e3)\n\td2=residual_block(u2,f[3])\n\n\tu3=upsample_concat_block(d2,e2)\n\td3=residual_block(u3,f[2])\n\n\tu4=upsample_concat_block(d3,e1)\n\td4=residual_block(u4,f[1])\n\n\toutputs=tf.keras.layers.Conv2D(4,(1,1),padding='same',activation='sigmoid')(d4)\n\tmodel=tf.keras.models.Model(inputs,outputs)\n\treturn model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dsc(y_true, y_pred):\n    smooth = 1.\n    y_true_f = tf.keras.layers.Flatten()(y_true)\n    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n    intersection = reduce_sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss\ndef tversky(y_true, y_pred, smooth=1e-6):\n    y_true_pos = tf.keras.layers.Flatten()(y_true)\n    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n    false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\n\ndef focal_tversky_loss(y_true,y_pred):\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return tf.keras.backend.pow((1-pt_1), gamma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResUNet(img_h=img_h, img_w=img_w)\nadam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\nmodel.compile(optimizer=adam, loss=focal_tversky_loss, metrics=[tversky])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#history = model.fit_generator(generator=train_generator, validation_data=validation_generator, epochs=epochs, verbose=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}