{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport gc\n!pip install segmentation-models\n!pip install git+https://github.com/qubvel/segmentation_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\ntestImgPath = \"/kaggle/input/severstal-steel-defect-detection/test_images/\"\ntrainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\ndata=pd.read_csv(trainCsv)\ndata.ClassId=data.ClassId.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WIDTH=800\nHEIGHT=128 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data(trainImgPath):\n    train_Img_Id = []\n    train_class_Id = []\n    for i in os.listdir(trainImgPath):\n        for j in range(1,5):\n            train_Img_Id.append(i)\n            train_class_Id.append(j)\n    train_Imgs = pd.DataFrame(train_Img_Id,columns=['ImageId'])\n    train_Imgs['ClassId'] = train_class_Id\n    train_data = pd.merge(train_Imgs,data ,how='outer', on=['ImageId','ClassId']) \n    train_data = train_data.fillna('') \n    return train_data \ntrain_data = read_data(trainImgPath)\ntrain_data.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(train_data):\n    train_data = pd.pivot_table(train_data, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\n    train_data = train_data.reset_index() # add Index column to one level with classID   \n    train_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4']\n    has_defect = []\n    stratify = []\n    for index,row in train_data.iterrows():\n        if row.Defect_1 or row.Defect_2 or row.Defect_3 or row.Defect_4: \n            has_defect.append(1)\n        else:\n            has_defect.append(0)\n\n    train_data[\"has_defect\"] = has_defect \n\n\n    for index , row in train_data.iterrows():\n        if row.Defect_1 != '':\n            stratify.append(1)\n        elif row.Defect_2 != '':\n            stratify.append(2)\n        elif row.Defect_3 != '':\n            stratify.append(3)\n        elif row.Defect_4 != '':\n            stratify.append(4)\n        else:\n            stratify.append(0)\n\n    train_data[\"stratify\"] = stratify \n    return train_data\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xset = train_data[\"ImageId\"]\nyset = train_data.iloc[:,1:5]\nxset[0] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test = train_test_split(train_data, test_size = 0.1, stratify=train_data['stratify'], random_state=42)\nx_train, x_val = train_test_split(x_train, test_size = 0.2, stratify = x_train['stratify'], random_state=42)\nprint(x_train.shape, x_val.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nums_def_1 = sum(x_train.Defect_1 != '')\nnums_def_2 = sum(x_train.Defect_2 != '')\nnums_def_3 = sum(x_train.Defect_3 != '')\nnums_def_4 = sum(x_train.Defect_4 != '')\n\nprint ( \"Number of Images In Train Dataset is : \", len(x_train), '\\n' ) \nprint ( \"Number of Images In Defect (1) : \", nums_def_1, '\\n' ) \nprint ( \"Number of Images In Defect (2) : \", nums_def_2, '\\n' ) \nprint ( \"Number of Images In Defect (3) : \", nums_def_3, '\\n' ) \nprint ( \"Number of Images In Defect (4) : \", nums_def_4, '\\n' ) \n\nsum_of_defects = [nums_def_1 ,nums_def_2,nums_def_3,nums_def_4]\nx_axis = ['1' , '2' , '3' , '4']\nfig, ax = plt.subplots()\nsns.barplot(x=x_axis,y=sum_of_defects) \nax.set_title(\"Number of images for each Defect\")\nax.set_xlabel(\"Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_defects = 0\none_defect = 0\nmulti_defect = 0\n\nfor index,row in x_train.iterrows():\n    cnt = 0\n    if row.Defect_1:\n        cnt+=1\n    if row.Defect_2:\n        cnt+=1\n    if row.Defect_3:\n        cnt+=1\n    if row.Defect_4:\n        cnt+=1\n        \n    if cnt > 1:\n        multi_defect += 1\n    elif cnt == 0:\n        zero_defects += 1\n    else:\n        one_defect += 1 \nnum_of_defects = [zero_defects ,one_defect,multi_defect]\nx_axis = [ 'No Defects' , '1 label' ,'multi label']\nfig, ax = plt.subplots()\nsns.barplot(x=x_axis,y=num_of_defects) \nax.set_title(\"Number of defects in images..\")\nax.set_xlabel(\"Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Samples of Images that have Defect 1: \")\nDefect1 = x_train[x_train.Defect_1 != ''] \ncnt = 0\nfor index ,row in Defect1[::-1].iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_1)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 2: \")\nDefect2 = x_train[x_train.Defect_2 != '']\n#Defect2 = Defect2[::-1]\ncnt = 0 \nfor index ,row in Defect2.iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_2)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 3: \")\nDefect3 = x_train[x_train.Defect_3 != ''] \ncnt = 0\nfor index ,row in Defect3[::-1].iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_3)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 4: \")\nDefect4 = x_train[x_train.Defect_4 != ''] \ncnt = 0\nfor index ,row in Defect4[::-1].iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_4)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_all = x_train[['ImageId','has_defect']]\nx_val_all = x_val[['ImageId','has_defect']]\nx_test_all = x_test[['ImageId','has_defect']] \nprint(x_train_all.shape , x_val_all.shape,x_test_all.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator \n\ndef data_generator():\n    train_datagen = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                               width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\n    train_data_generator = train_datagen.flow_from_dataframe(\n            dataframe=x_train_all.astype(str),\n            directory=trainImgPath,\n            x_col=\"ImageId\",\n            y_col=\"has_defect\",\n            target_size=(HEIGHT,WIDTH),\n            batch_size=16,\n            class_mode='binary') \n\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    \n    valid_data_generator = test_datagen.flow_from_dataframe(\n            dataframe=x_val_all.astype(str),\n            directory=trainImgPath,\n            x_col=\"ImageId\",\n            y_col=\"has_defect\",\n            target_size=(HEIGHT,WIDTH),\n            batch_size=16,\n            class_mode='binary')\n\n    test_data_generator = test_datagen.flow_from_dataframe(\n            dataframe=x_test_all.astype(str),\n            directory=trainImgPath,\n            x_col=\"ImageId\",\n            y_col=\"has_defect\",\n            target_size=(HEIGHT,WIDTH),\n            batch_size=16,\n            class_mode='binary',\n            shuffle=False)\n    \n    return train_data_generator, valid_data_generator, test_data_generator\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_generator, valid_data_generator, test_data_generator = data_generator()\ntrain_data_generator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Classification Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50 \nfrom tensorflow.keras.utils import plot_model\nimport keras \nfrom keras import backend as K\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\nfrom keras.models import Model, load_model\n\nClassification_Model = keras.applications.xception.Xception(include_top = False, input_shape = (HEIGHT,WIDTH,3))\n\nlayer = Classification_Model.output\nlayer = GlobalAveragePooling2D()(layer)\n\nlayer = Dense(1024, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(512, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(64, activation='relu')(layer)\npredictions = Dense(1, activation='sigmoid')(layer)\nmodel = Model(inputs=Classification_Model.input, outputs=predictions)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nmodel_history = model.fit_generator(train_data_generator, validation_data = valid_data_generator, epochs = 30, verbose=1)\nmodel.save('classification_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_evaluate = model.evaluate(test_data_generator,verbose=1)\ntest_evaluate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Segmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_mask(encoded_pixels):\n    counts=[]\n    mask=np.zeros((256*1600), dtype=np.uint8) #don't change this\n    pre_mask=np.asarray([int(point) for point in encoded_pixels.split()])\n    for index,count in enumerate(pre_mask):\n        if(index%2!=0):\n            counts.append(count)\n    i=0\n    for index,pixel in enumerate(pre_mask):\n        if(index%2==0):\n            if(i==len(counts)):\n                break\n            mask[pixel:pixel+counts[i]]=1\n            i+=1\n    mask=np.reshape(mask,(1600,256)) #don't change this\n    mask=cv2.resize(mask,(HEIGHT,WIDTH)).T\n    return mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras \nclass Data_Generator(keras.utils.Sequence):\n    \n    def __init__(self, x_set, y_set, batch_size=16,preprocess=None,shuffle=False,op=\"train\",info={},width=WIDTH,height=HEIGHT):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.shuffle = shuffle\n        self.info=info\n        self.h = height\n        self.w = WIDTH\n        self.op = op\n        if self.op == \"train\":\n            self.path = trainImgPath\n        elif self.op == \"test\":\n            self.path = testImgPath \n        self.on_epoch_end()    \n        \n        \n\n    def __len__(self):\n        return int(np.floor(len(self.x) / self.batch_size))\n    \n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.x))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n        \n        \n    def __getitem__(self, idx):\n        imgs = np.empty((self.batch_size,self.h,self.w,3),dtype=np.float32)\n        masks = np.empty((self.batch_size,self.h,self.w,4),dtype=np.int8)\n        indexes = self.indexes[idx*self.batch_size: (idx+1)*self.batch_size]\n        \n        for index , val in enumerate(self.x.iloc[indexes]):\n            self.info[index*self.batch_size+index] = val\n            img=cv2.imread(self.path + val) \n            imgs[index,] = cv2.resize(img,(self.w,self.h))\n            if self.op == \"train\":\n                for idx in range(4):\n                    masks[index,:,:,idx] = convert_to_mask(self.y['Defect_'+str(idx+1)].iloc[indexes[index]])\n        if self.preprocess :\n            imgs = self.preprocess(imgs)\n        if self.op == \"train\":\n            return imgs,masks \n        else: \n            return imgs\n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\nfrom segmentation_models.losses import jaccard_loss\nfrom segmentation_models.metrics import iou_score\n \nnetwork = 'resnet34'\nprocess_input = get_preprocessing(network)\n \nmodel = Unet(network,input_shape = (HEIGHT, WIDTH, 3),classes=4,activation='sigmoid')\nmodel.compile('adam', loss='binary_crossentropy',metrics=[dice_coef])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = int(0.8*len(xset)) #dropout 0.2 of dataset \ntrain_data_generator = Data_Generator(xset.iloc[:idx],yset.iloc[:idx],shuffle=True,preprocess=process_input )\n \nval_data_generator = Data_Generator(xset.iloc[:idx],yset.iloc[:idx],preprocess=process_input)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(\n   train_data_generator, \n   validation_data = val_data_generator, \n   epochs = 30,\n   verbose=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=model.evaluate(xtest,ytest)\nresullts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('segmentation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}