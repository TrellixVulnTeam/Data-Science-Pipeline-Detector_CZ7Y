{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.vis_utils import plot_model\nimport random\n#from segmentation_models import Unet\n#from segmentation_models.backbones import get_preprocessing\nrandom.seed(1)\nfrom keras.models import load_model\nfrom keras.preprocessing.image import img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train df","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"count ids","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nprint(mask_count_df.shape)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test df","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"cho\" is Image ids having multi label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cho=np.load(\"../input/chonpy/cho.npy\")\ncho=list(cho)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create random crop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#ランダム幾何変換関数\ndef crop(A,B):\n  B0=B[0]\n  B1=B[1]\n  B2=B[2]\n  B3=B[3]\n  if random.choice([0, 1]) == 0:\n    A=cv2.flip(A,0)\n    B0=cv2.flip(B0,0)\n    B1=cv2.flip(B1,0)\n    B2=cv2.flip(B2,0)\n    B3=cv2.flip(B3,0)\n  else:\n    pass\n  if random.choice([0,1])==0:\n    A=cv2.flip(A,1)\n    B0=cv2.flip(B0,1)\n    B1=cv2.flip(B1,1)\n    B2=cv2.flip(B2,1)\n    B3=cv2.flip(B3,1)\n  else:\n    pass\n  \"\"\"\n  rows,cols,aa = A.shape\n  m1=random.choice(list(range(-5,5)))\n  m2=random.choice(list(range(-5,5)))\n  A = cv2.warpAffine(A,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n  B0 = cv2.warpAffine(B0,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n  B1 = cv2.warpAffine(B1,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n  B2 = cv2.warpAffine(B2,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n  B3 = cv2.warpAffine(B3,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n  m3 = random.choice(list(range(-2,2)))\n  A = cv2.warpAffine(A,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n  B0 = cv2.warpAffine(B0,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n  B1 = cv2.warpAffine(B1,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n  B2 = cv2.warpAffine(B2,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n  B3 = cv2.warpAffine(B3,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n  ra=random.uniform(-0.1, 0.1)\n  img= np.zeros([rows,cols])\n  if random.choice([0, 1]) == 0:\n    A=np.reshape(A,(256,1600,1))\n    img=np.reshape(img,(256,1600,1))\n    for i in range(cols):\n      weight = 1+((i*ra)/cols)\n      img[:,i] = cv2.addWeighted(A[:,i],0.5*weight,A[:,i],0.5*weight,0)\n    A=img\n  else:\n    img=img.T\n    A=A.T\n    A=np.reshape(A,(1600,256,1))\n    img=np.reshape(img,(1600,256,1))\n    for i in range(rows):\n      weight = 1+((i*ra)/rows)\n      img[:,i] = cv2.addWeighted(A[:,i],0.5*weight,A[:,i],0.5*weight,0)\n    img=np.reshape(img,(256,1600))\n    A=img.T\n  \"\"\"\n  A=A*random.uniform(0.95, 1.05)\n  B=[B0,B1,B2,B3]\n  return(A,B)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create mask","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(mask_rle, shape=(256,1600)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask(gyo):\n\ttrain=train_df.iat[gyo,2].split(\" \")\n\ttrain = [int(num) for num in train]\n\tmask = np.zeros(256*1600)\n\tmask=np.ravel(mask)\n\n\tfor i in range(int(len(train)/2)):\n\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n\tmask=mask.reshape(1600,256)\n\tmask=mask.T\n\tmask.reshape(256,1600)\n\tmask=np.array(mask)\n\treturn(train_df.iat[gyo,1],mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_masks(rles, input_shape):\n    depth = len(rles)\n    height, width = input_shape\n    masks = np.zeros((height, width, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, (width, height))\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data generator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#data generator にて入出力を作る場合のコード\ndef batch_iter(data_size, batch_size):\n    data_size=int((4/5)*data_size)\n    num_batches_per_epoch = int(data_size / batch_size)\n\n    def data_generator():\n        while True:\n            for batch_num in range(num_batches_per_epoch):\n                start_index = batch_num * batch_size\n                k=random.sample(list(range(data_size)), len(list(range(data_size))) )\n                XX=[]\n                YY=[]\n                zeros=np.zeros([256,1600])\n                for i in range(batch_size):\n                \timageid=train_df.iat[k[i+start_index],0]\n\n                \ty=mask(k[i+start_index])\n                \tif k[i+start_index] in cho:\n                \t  x = cv2.imread(\"../input/train-images2/train_images2/\"+str(k[i+start_index])+\"_gyo.jpg\", cv2.IMREAD_GRAYSCALE)                  \n                \telse:\n                \t  x = cv2.imread(\"../input/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n                \tx=np.array(x)\n                \tx=x/255\n                \tY=[]\n                \tfor j in range(4):\n                \t\tif y[0]==j+1:\n                \t\t\tY.append(y[1])\n                \t\telse:\n                \t\t\tY.append(zeros)\n                \tx,Y=crop(x,Y)\n                \tx=np.reshape(x, (256,1600,1))\n                \tY=np.stack(Y,2)\n                \tXX.append(x)\n                \tYY.append(Y)\n                X_train=np.array(XX)\n                Y_train=np.array(YY)\n                yield X_train, Y_train\n    return num_batches_per_epoch, data_generator()\n#4:1で学習\ndef batch_iter2(data_size, batch_size):\n    num_batches_per_epoch = int(data_size / (5*batch_size))\n    def data_generator2():\n        while True:\n            for batch_num in range(num_batches_per_epoch):\n                start_index = int((4*data_size)/5+batch_num * batch_size)\n                l0=[0]*(int((4*data_size)/5))\n                l=random.sample(list(range(int((4*data_size)/5),data_size)), len(list(range(int((4*data_size)/5),data_size))) )\n                l=l0+l\n                XX=[]\n                YY=[]\n                zeros=np.zeros([256,1600])\n                for i in range(batch_size):\n                \timageid=train_df.iat[l[i+start_index],0]\n                \ty=mask(l[i+start_index])\n                \tif l[i+start_index] in cho:\n                \t  x = cv2.imread(\"../input/train-images2/train_images2/\"+str(l[i+start_index])+\"_gyo.jpg\", cv2.IMREAD_GRAYSCALE)                  \n                \telse:\n                \t  x = cv2.imread(\"../input/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n                \tx=np.array(x)\n                \tx=x/255\n                \tY=[]\n                \tfor j in range(4):\n                \t\tif y[0]==j+1:\n                \t\t\tY.append(y[1])\n                \t\telse:\n                \t\t\tY.append(zeros)\n                  \n                \tx,Y=crop(x,Y)\n                \tx=np.reshape(x, (256,1600,1))\n                \tY=np.stack(Y,2)\n                \tXX.append(x)\n                \tYY.append(Y)\n                X_train=np.array(XX)\n                Y_train=np.array(YY)\n                yield X_train, Y_train\n    return num_batches_per_epoch, data_generator2()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot history","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#履歴\ndef plot_history(history, outdir):\n    # 精度の履歴をプロット\n    plt.figure()\n    plt.plot(history.history['dice_coef'], marker='.')\n    plt.plot(history.history['val_dice_coef'], marker='.')\n    plt.title('model dice_coef')\n    plt.xlabel('epoch')\n    plt.ylabel('dice_coef')\n    plt.grid()\n    plt.legend(['train', 'test'], loc='upper left')\n###\n#    plt.savefig(os.path.join(outdir, 'dice_coef5.png'))\n    # 損失の履歴をプロット\n    plt.figure()\n    plt.plot(history.history['loss'], marker='.')\n    plt.plot(history.history['val_loss'], marker='.')\n    plt.title('model loss')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.grid()\n    plt.legend(['train', 'test'], loc='upper left')\n###保存\n#    plt.savefig(os.path.join(outdir, 'loss5.png'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"define model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#model\ndef build_model(input_shape):\n    inputs = Input(input_shape)\n\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    u6 = concatenate([u6, c5])\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4])\n    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n    \n    return model\n\nmodel = build_model((256, 1600, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_dice_coef', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"start!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#学習開始\n#history=model.fit_generator(batch_iter(len(train_df)-len(train_df)%128, 16)[1], batch_iter(len(train_df)-len(train_df)%128, 16)[0],validation_data=batch_iter2(len(train_df)-len(train_df)%128,4)[1],validation_steps=batch_iter2(len(train_df)-len(train_df)%128,4)[0],callbacks=[checkpoint], epochs=30,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nwith open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['dice_coef', 'val_dice_coef']].plot()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#output","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nimageid=[]\nfor i in range(len(test_df)):\n  for j in range(4):\n    imageid.append(test_df.iat[i,0])\nencode=['']*len(imageid)\nclassid=[]\nfor i in range(len(test_df)):\n  for j in range(4):\n    classid.append(j+1)\nsample_submission=pd.DataFrame({'ImageId':imageid,'EncodedPixels':encode,'ClassId':classid})\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimageid=[]\nfor i in range(len(test_df)):\n  for j in range(4):\n    imageid.append(test_df.iat[i,0]+\"_\"+str(j+1))\nencode=['1 1']*len(imageid)\nsample_submission=pd.DataFrame({'ImageId_ClassId':imageid,'EncodedPixels':encode})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.load_weights('../input/weights3/weights.3')\nfor i in range(len(test_df)):\n#for i in range(200):\n  img = cv2.imread(\"../input/severstal-steel-defect-detection/test_images/\"+test_df.iat[i,0], cv2.IMREAD_GRAYSCALE)\n  X=[]\n  img=img.reshape(256,1600,1)\n  img = np.array(img)/255\n  X.append(img)\n  X=np.array(X)\n  pred = model.predict(X, batch_size=1, verbose=0)\n  C=pred[0]\n  C=np.where(C >0.5, 1, 0)\n  C=build_rles(C)\n  for j in range(4):\n    sample_submission.iat[4*i+j,1]=C[j]\n\n\n\"\"\"\nindexNames = sample_submission[ sample_submission['EncodedPixels'] == '' ].index\n# Delete these row indexes from dataFrame\nsample_submission.drop(indexNames , inplace=True)\n\"\"\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nsample_submission = pd.concat([test_df, sample_submission])\nindexNames = sample_submission[ sample_submission['EncodedPixels'] == '' ].index\nsample_submission.drop(indexNames , inplace=True)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nprint(sample_submission)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nsample_submission=pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nprint(sample_submission.iat[0,0])\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}