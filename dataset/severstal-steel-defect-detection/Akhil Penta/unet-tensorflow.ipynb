{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Conv2DTranspose, Concatenate\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/titericz/building-and-visualizing-masks\n#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n\n#defining function for converting EncodedPixels(rle: run length encoding) to mask\ndef rle2mask(rle_string, img_shape=(256,1600)):\n    '''\n    input: EncodedPixels (run-length-encoded) string & image shape:-(width,height)\n    output: mask in numpy.ndarray format with shape (256,1600)\n    '''\n    rle_array = np.array([int(s)for s in rle_string.split()])\n    starts_array = rle_array[::2]-1\n    lengths_array = rle_array[1::2]\n    mask_array = np.zeros(img_shape[0]*img_shape[1],dtype=np.uint8)\n    #print(starts_array,lengths_array)\n    for i in range(len(starts_array)):\n        mask_array[starts_array[i]:starts_array[i]+lengths_array[i]] = 1\n    #order='F' because encoded pixels are numbered from top to bottom, then left to right\n    return mask_array.reshape(img_shape, order = 'F')\n\n#defining function for converting given mask to EncodedPixels(rle: run length encoding)\ndef mask2rle(mask_array):\n    '''\n    input: mask in numpy.ndarray format\n    output: EncodedPixels (run-length-encoded) string\n    '''\n    mask_array = mask_array.T.flatten()\n    mask_array = np.concatenate([[0], mask_array, [0]])\n    rle_array = np.where(mask_array[1:]!=mask_array[:-1])[0]+1\n    rle_array[1::2] -= rle_array[::2]\n    rle_string = ' '.join(map(str,rle_array))\n    return rle_string\n\n#defining function for calculation of metric dice coefficient\ndef dice_coefficient(y_true, y_pred):\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    intersection = tf.math.reduce_sum(y_true_f * y_pred_f)\n    smoothing_const = 1e-9\n    return (2. * intersection + smoothing_const) / (tf.math.reduce_sum(y_true_f) + tf.math.reduce_sum(y_pred_f) + smoothing_const)\n\n#defining function for calculation of dice coefficient\ndef dice_loss(y_true, y_pred):\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    return (1-dice_coefficient(y_true, y_pred))\n\n#defining function for calculation of loss function: binary cross entropy + dice loss\ndef bce_dice_loss(y_true, y_pred):\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    return binary_crossentropy(y_true, y_pred) + (1-dice_coefficient(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining Unet architecture\n# https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n# https://github.com/hlamba28/UNET-TGS\n\ndef conv2D_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True ):\n    \"\"\"function to pass Input_tensor through 2- Conv2D layers configured as per the input parameters\"\"\"\n    # first Conv2D layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n            kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n\n    # second Conv2D layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n            kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n\n    return x\n\n\ndef Unet_Model(input_image, n_filters = 16, dropout = 0.1, batchnorm = True):\n    # Encoder (Contraction Path)\n    E1 = conv2D_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(E1)\n    p1 = Dropout(dropout)(p1)\n\n    E2 = conv2D_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(E2)\n    p2 = Dropout(dropout)(p2)\n\n    E3 = conv2D_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(E3)\n    p3 = Dropout(dropout)(p3)\n\n    E4 = conv2D_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(E4)\n    p4 = Dropout(dropout)(p4)\n\n    E5 = conv2D_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n\n    # Decoder (Expansive Path)\n    D6 = Conv2DTranspose(n_filters * 8, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(E5)\n    D6 = Concatenate()([D6, E4])\n    D6 = Dropout(dropout)(D6)\n    E6 = conv2D_block(D6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n\n    D7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(E6)\n    D7 = Concatenate()([D7, E3])\n    D7 = Dropout(dropout)(D7)\n    E7 = conv2D_block(D7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n\n    D8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(E7)\n    D8 = Concatenate()([D8, E2])\n    D8 = Dropout(dropout)(D8)\n    E8 = conv2D_block(D8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n\n    D9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(E8)\n    D9 = Concatenate()([D9, E1])\n    D9 = Dropout(dropout)(D9)\n    E9 = conv2D_block(D9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid')(E9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input((256, 1600, 3), name='img')\nmodel = Unet_Model(input_img, n_filters=8, dropout=0.2, batchnorm=True)\nmodel.compile(optimizer=Adam(), loss=bce_dice_loss, metrics=[dice_coefficient])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading trained model weights\nmodel.load_weights('../input/unet1/unet(trained-60epochs).h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PredictDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self,dataframe, list_idcs, batch_size=32, ):\n        self.batch_size = batch_size\n        self.df = dataframe\n        self.list_idcs = list_idcs\n        self.indices = self.df.index.tolist()\n        self.rem = len(self.list_idcs) % (self.batch_size)\n        self.on_epoch_end()\n\n    def __len__(self):\n         return len(self.list_idcs) // (self.batch_size)\n#         if (self.rem) == 0:\n#             return len(self.list_idcs) // (self.batch_size)\n#         else:\n#             return (len(self.list_idcs) // (self.batch_size) )+1\n\n    def __getitem__(self, index):\n        index = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n#         if ((index + 1) * self.batch_size) < len(self.list_idcs):\n#             index = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n#         else:\n#             index = self.indices[index * self.batch_size: (index * self.batch_size)+ self.rem]\n        batch = [self.list_idcs[k] for k in index]\n        \n        X = self.__get_data(batch)\n         \n        return X\n    def on_epoch_end(self):\n        self.index = np.arange(len(self.indices))\n\n    def __get_data(self, batch):\n        X = np.empty((self.batch_size,256,1600,3),dtype=np.float32) # image place-holders\n              \n        for i, id in enumerate(batch):\n          img = Image.open('../input/severstal-steel-defect-detection/test_images/' + str(self.df['ImageId'].loc[id]))\n          X[i,] = img#input image\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_IDs = list(os.listdir('../input/severstal-steel-defect-detection/test_images'))\ntest_imgsIds_df = pd.DataFrame({'ImageId': test_img_IDs})\nprint(len(test_imgsIds_df))\ntest_imgsIds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SubmissionDf = pd.DataFrame(columns = ['ImageId','EncodedPixels','ClassId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(test_imgsIds_df),320):\n    batch_idcs =  list(range(i, min(test_imgsIds_df.shape[0], i + 320)))#.iloc[batch_idcs]\n    if len(batch_idcs)== 320:        \n        test_subbatch = PredictDataGenerator(dataframe = test_imgsIds_df,\n                                             list_idcs = batch_idcs)\n    else:\n        test_subbatch = PredictDataGenerator(dataframe = test_imgsIds_df,\n                                             list_idcs = batch_idcs,\n                                             batch_size= len(batch_idcs))\n    subbatch_pred_masks = model.predict(test_subbatch)\n    for j, idx in tqdm(enumerate(batch_idcs)):\n        filename = test_imgsIds_df['ImageId'].iloc[idx]\n        rle1 = mask2rle(subbatch_pred_masks[j,:,:,0].round().astype(int))\n        rle2 = mask2rle(subbatch_pred_masks[j,:,:,1].round().astype(int))\n        rle3 = mask2rle(subbatch_pred_masks[j,:,:,2].round().astype(int))\n        rle4 = mask2rle(subbatch_pred_masks[j,:,:,3].round().astype(int))\n        df = pd.DataFrame({'ImageId':[filename]*4,\n                      'EncodedPixels': [rle1,rle2,rle3,rle4],\n                      'ClassId':['1', '2', '3', '4']})\n        SubmissionDf = SubmissionDf.append(df,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SubmissionDf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SubmissionDf.sort_values(by=['ImageId', 'ClassId'], inplace=True)\nSubmissionDf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SubmissionDf['ImageId_ClassId'] = SubmissionDf['ImageId'] + '_' + SubmissionDf['ClassId']\nSubmissionDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SubmissionDf[['ImageId_ClassId','EncodedPixels' ]].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}