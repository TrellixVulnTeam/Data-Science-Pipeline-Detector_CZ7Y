{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### End-To-End Severstal Steel Defect Detection (EDA, Validation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# it ensures any edits to libraries you make are reloaded here automatically\n%reload_ext autoreload\n%autoreload 2 \n\n# any charts or images displayed are shown in this notebook.\n%matplotlib inline \n\n# avoid priniting warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n#display is equivalent to print but in case of data frame it makes prity print\nfrom IPython.display import display as disp ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing all required packages and libraries "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd # pwd (present working directory) our default current working directroy is /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utility Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def list_files(dir_name='/kaggle/input'):\n    for dirname, _, filenames in os.walk(dir_name):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list_files(\"/kaggle/input/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv_path = \"../input/severstal-steel-defect-detection/train.csv\"\nsample_submission_csv_path = \"../input/severstal-steel-defect-detection/sample_submission.csv\"\ntrain_image_path = \"../input/severstal-steel-defect-detection/train_images/\"\ntest_image_path = \"../input/severstal-steel-defect-detection/test_images/\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"def explore_csv(path):\n    df = pd.read_csv(path)    \n    disp(df)\n    print(\"Path:\", path)\n    print(\"File Name:\", path.split(\"/\")[-1])\n    print()\n    print(\"Shape:\", df.shape)\n    print()\n    print(df.info())\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_csv(train_csv_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Training Data (CSV File)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Exploring train.csv file\n\ntrain_df = pd.read_csv(train_csv_path)\ndisp(train_df.head())\nprint(\"\\nTotal numberof Rows, Columns:\",train_df.shape)\n# Total numberof Rows in Training CSV\nprint(\"\\nTotal numberof Rows in Training CSV:\",train_df.shape[0])\nprint()\n\n# Number of images with defects\ndefect_count = train_df.EncodedPixels.count()\nprint(\"Number of images with defects (as per CSV):\",defect_count)\n# Number of images with NO defects\nno_defect_count = train_df.EncodedPixels.isna().sum()\nprint(\"Number of images with no defects(as per CSV):\",no_defect_count)\nprint(\"Note: For each image there ar 4 rows in CSV\\n\")\n\n# Number of jpegs in  training and test sets\ntrain_fns = os.listdir('/kaggle/input/severstal-steel-defect-detection/train_images')\nprint(\"The number of Training Images:\", len(train_fns))\ntest_fns = os.listdir('/kaggle/input/severstal-steel-defect-detection/test_images')\nprint(\"The number of Test Images:\", len(test_fns))\n\n# Number of images has at least one defect (max of 4 defects)\ndf = train_df.dropna()\ndf['ImageId'] = [x.split('_')[0] for x in df['ImageId_ClassId']]\nprint(\"\\nNumber of images has AT LEAST ONE DEFECT:\",len(df.ImageId.unique()))\nprint(\"Number of NO Defect images in training set:\", len(train_fns) - len(df.ImageId.unique()))\nprint()\nnote = \"\"\"Note: There is possible to have maximum of 4 defects \n    but in this case there are only 2 images has 3 Defects\n    \"\"\"\nprint(note)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting a pie chart to show the percentage of \"Defect vs No Defect\"\nlabels = 'Defect', 'No Defect'\nsizes = [defect_count, no_defect_count]\nexplode=(0.1,0)\nplt.pie(sizes, labels=labels, autopct='%1.2f%%', explode=explode, colors=['r','g'], shadow=True, startangle=0)\nplt.title('Defect vs No Defect')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of images has at least one defect (max of 4 defects)\ndf = train_df.dropna()\ndf['ClassId'] = [x.split('_')[1] for x in df['ImageId_ClassId']]\ndf['ImageId'] = [x.split('_')[0] for x in df['ImageId_ClassId']]\n\nimages_per_class = df.groupby('ClassId')['ImageId'].count()\ndisp(images_per_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot number of images per defect class (4 classes)\nfig, ax = plt.subplots() \nplt.barh(\n    y=[1,2,3,4],\n    width=images_per_class, \n    color=['magenta', 'red', 'green', 'cyan'], \n    tick_label=[\"Defect Class1\",\"Defect Class2\",\"Defect Class3\",\"Defect Class4\"]    \n)\nfor y, v in enumerate(images_per_class, 1):\n    ax.text(1,y,v)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting a pie chart to show the percentage of \"Defect vs No Defect\"\nlabels = [\"Defect Class1\",\"Defect Class2\",\"Defect Class3\",\"Defect Class4\"]\nsizes = images_per_class\nplt.pie(sizes, labels=labels, autopct='%1.2f%%',  colors=['r','g','m','y'], shadow=True, startangle=0)\nplt.title('Defect Classes % wise')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"defect_classes_per_image = pd.DataFrame({ 'NoOfDefects': df.groupby('ImageId')['ClassId'].count()})\none_defect_imgs = defect_classes_per_image.groupby(\"NoOfDefects\").get_group(1).index.values.tolist()\ntwo_defects_imgs = defect_classes_per_image.groupby(\"NoOfDefects\").get_group(2).index.values.tolist()\nthree_defects_imgs = defect_classes_per_image.groupby(\"NoOfDefects\").get_group(3).index.values.tolist()\nno_of_defects = defect_classes_per_image.groupby(\"NoOfDefects\").size()\nprint(f\"Image with One defect: {no_of_defects[1]} \\nImage with Two defects: {no_of_defects[2]}\\nImage with Three defects: {no_of_defects[3]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot number of defects in each images\nfig, ax = plt.subplots() \nplt.barh(\n    y=[1,2,3],\n    width=no_of_defects, \n    color=['magenta', 'red', 'green'],\n    tick_label=[\"1 Defect\",\"2 Defects\",\"3 Defects\"]    \n)\nfor y, v in enumerate(no_of_defects, 1):\n    ax.text(1,y,v)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: it can display only 10 images in 2 cols\ndef display_images_in_two_cols(image_file_names):\n    nrows=(len(image_file_names)//2)\n    fig, ax = plt.subplots( nrows=nrows, ncols=2, figsize=(22, 2*nrows))\n    ax = ax.flatten()\n    for i in range(len(image_file_names)):\n        img = plt.imread('/kaggle/input/severstal-steel-defect-detection/train_images/'+image_file_names[i])\n        plt.tight_layout()\n        ax[i].axis(\"off\")\n        ax[i].imshow(img)\n\n# Note: it can display given images in 1 column        \ndef display_images(filenames):\n    for i in range(len(filenames)):\n        img = plt.imread('/kaggle/input/severstal-steel-defect-detection/train_images/'+filenames[i])\n        plt.figure(figsize=[19,65])\n        plt.axis(\"off\")\n        plt.tight_layout()\n        plt.imshow(img)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfilenames = os.listdir('/kaggle/input/severstal-steel-defect-detection/train_images')\ndisplay_images_in_two_cols(filenames[0:12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir('/kaggle/input/severstal-steel-defect-detection/train_images')\ndisplay_images(filenames[0:12])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reshaping-1 Training Data Set\nImageId_ClassId, EncodedPixels --> ImageId,D1,D2,D3,D4,Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/'\ntrain = pd.read_csv(path + 'train.csv')\n\nimport numpy as np\n\n# Unstack the EncodedPixels and store into new Dataframe\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['D1'] = train['EncodedPixels'][0::4].values\ntrain2['D2'] = train['EncodedPixels'][1::4].values\ntrain2['D3'] = train['EncodedPixels'][2::4].values\ntrain2['D4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1)\ndisp(train2.head())\nprint()\nprint(\"Shape:\",train2.shape)\nprint(\"\\nNumber of Defects for each Defect Class:\")\nprint(np.sum(train2.iloc[:,1:]!='',axis=0))\nZeroDefectsImages = train2[train2['count']==0].ImageId.values\ndisp(\"Zero Defect Images:\")\ndisp(ZeroDefectsImages.shape)\ndisp(ZeroDefectsImages)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reshaping-2 Training Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \n# reading in the training set\ndata = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\n\n# isolating the file name and class\ndata['ImageId'], data['ClassId'] = data.ImageId_ClassId.str.split('_').str\ndata['ClassId'] = data['ClassId'].astype(np.uint8)\n\n# keep only the images with EncodedPixels\nsquashed = data.dropna(subset=['EncodedPixels'], axis='rows')\ndisp( squashed)\nprint(squashed.shape)\n\n# squash multiple rows per image into a list\nsquashed = squashed[['ImageId', 'EncodedPixels', 'ClassId']].groupby('ImageId', as_index=False).agg(list) \n\n# count the amount of class labels per image\nsquashed['Distinct Defect Types'] = squashed.ClassId.apply(lambda x: len(x))\n\n# select images has more than 2 defects\ndisp(squashed[squashed['Distinct Defect Types']> 2])\n\n# display squashed sample\ndisp(squashed.sample(10))\nprint(f\"Number of images with at least One defect: {squashed.shape[0]}\")\nprint(squashed.shape)\n\n# Discovering Zero Defect image file names\ntempdf = data[['ImageId', 'EncodedPixels', 'ClassId']].fillna(\"RAM\")\ntempdf = tempdf[['ImageId', 'EncodedPixels', 'ClassId']].groupby('ImageId', as_index=False).agg(list)\ntempdf['all_nan'] = tempdf.EncodedPixels.apply(lambda x: x.count(\"RAM\") )\nZeroDefectsImages=tempdf[tempdf[\"all_nan\"]==4].ImageId.values\nprint(f\"Number of images with Zero defect: {ZeroDefectsImages.shape[0]}\")\ndisp(ZeroDefectsImages.shape)\ndisp(ZeroDefectsImages)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# import torch.backends.cudnn as cudnn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook as tqdm\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensor\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/train_images/'\n#path = '../input/severstal-steel-defect-detection/test_images/'\nsample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\ntest_data_folder = \"../input/severstal-steel-defect-detection/test_images/\"\npalet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataframe (ImageId, ClassId)\n#### creating Dataframe based on defects types (minimum one defect type)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(123)\nudf = pd.DataFrame()\nudf['ImageId'] = squashed[squashed['Distinct Defect Types'] == 1].ImageId\nudf['ClassId'] = squashed[squashed['Distinct Defect Types'] == 1].ClassId\nudf.ClassId = udf.ClassId.apply(lambda x: x[0])\n\n# Converting ClassId (1,2,3,4) into Labels (0,1,2,3)\nudf1 = udf[udf.ClassId == 1]\nudf1[\"ClassId\"] = 0\nudf2 = udf[udf.ClassId == 2]\nudf2[\"ClassId\"] = 1\nudf3 = udf[udf.ClassId == 3]\nudf3[\"ClassId\"] = 2\nudf4 = udf[udf.ClassId == 4]\nudf4[\"ClassId\"] = 3\nprint(\"Single Defect Count:\")\nprint(\"Class1:{}, Class2:{}, Class3:{}, Class4:{}\"\n      .format( len(udf1), len(udf2), len(udf3), len(udf4)))\n\n\n# (Solving Class Imbalance problem)\n# Since Defect 2 type images are lesser than other defects, we are reusing the same images \n# udf2 = pd.concat([udf2,udf2,udf2])  \n\nsample_size = len(udf2)\nudf1 = udf1[0:sample_size]\nudf2 = udf2[0:sample_size]\nudf3 = udf3[0:sample_size]\nudf4 = udf4[0:sample_size]\n\nudf = pd.concat([udf1, udf2, udf3,  udf4 ])\nudf.reset_index(drop=True,inplace=True)\n\nprint()\nprint(\"Label Distribution\")\nprint(\"Total Rec:{}, Class1:{}, Class2:{}, Class3:{}, Class4:{}\" \n      .format( len(udf),\n               len(udf[udf[\"ClassId\"] == 0]),\n               len(udf[udf[\"ClassId\"] == 1]),\n               len(udf[udf[\"ClassId\"] == 2]), \n               len(udf[udf[\"ClassId\"] == 3])))\n\n\ntrain_df, val_df = train_test_split(udf, test_size=0.2, stratify=udf[\"ClassId\"], random_state=39)\nprint()\nprint(\"Train DF Shape:\",train_df.shape)\nprint(\"Val DF Shape:  \",val_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utility Functions \n#### (mask2rle, rle2mask, draw_mask, draw_contour, draw_plot, draw_OMG)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef rle2mask(rle, imgshape=(256,1600)):\n    width = imgshape[0]\n    height= imgshape[1]\n    mask= np.zeros( width*height ).astype(np.uint8)    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1 \n    mask = mask.reshape(height,width)\n    return mask.T\n\n\ndef draw_mask(imageid, rle, classid):\n    masks = np.zeros((256,1600,4), dtype=np.uint8)\n    for r, c in zip(rle,classid):\n        index = c - 1\n        masks[:,:,index] = rle2mask(r) \n    return masks\n\n\ndef draw_contour(image, masks):\n    for i in range(4):\n        contours, hierarchy = cv2.findContours(masks[:,:,i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        image = cv2.drawContours(image, contours, -1, palet[i], 2)        \n    return image\n\ndef draw_plot(img, imageid, classid):\n    plt.figure(figsize=(20,5))\n    plt.axis(\"off\")\n    plt.title(imageid+ \" \"+str(classid))\n    plt.imshow(img)\n\n\ndef draw_OMG(imageids):\n    \"\"\" Drawing Original Image, Masked Image , Guided Image (Contour Image)\n    \"\"\"\n    for imageid in imageids:\n        try:\n            rle = squashed[squashed.ImageId == imageid].EncodedPixels.tolist()[0]\n            classid = squashed[squashed.ImageId == imageid].ClassId.tolist()[0]\n\n            img = cv2.imread(path+imageid)\n            draw_plot(img, imageid, classid)\n\n            masks=draw_mask(imageid,rle,classid)\n            img = draw_contour(img,masks)\n            draw_plot(img, imageid, classid)\n\n            \n            for i in range(4):\n                for j in range(3):\n                    img[masks[:,:,i]==1,j] = palet[i][j]                    \n            draw_plot(img, imageid, classid)\n            \n        except IndexError:\n            try:\n                img = plt.imread(path+imageid)\n                plt.imshow(img)\n            except FileNotFoundError:\n                print(\"File Not Found:\"+imageid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization Original, Mask, Guided(Contour) \n\nconditions = [\n    squashed['ClassId'].astype(str)=='[1]',\n    squashed['ClassId'].astype(str)=='[2]',\n    squashed['ClassId'].astype(str)=='[3]',\n    squashed['ClassId'].astype(str)=='[4]',\n    squashed['Distinct Defect Types']==2,\n    squashed['Distinct Defect Types']==3\n]\nsample_size = 2\nfor condition in conditions:\n    sample = squashed[condition].sample(sample_size) \n    draw_OMG(sample.ImageId.values)\n\ndraw_OMG([\"000f6bf48.jpg\", \"db4867ee8.jpg\", \"0025bde0c.jpg\"]) # 4, 1 2 3,  3 4\ndraw_OMG([\"a0906d0b3.jpg\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset & Data Loader "},{"metadata":{"trusted":true},"cell_type":"code","source":"mean=(0.485, 0.456, 0.406)\nstd=(0.229, 0.224, 0.225)\nphase=\"train\"\n_tasks = Compose([\n    ToTensor(),\n    #Normalize(mean=mean, std=std),\n    ])\nclass TrainDataset(Dataset):\n    \n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        self.fnames = self.df[\"ImageId\"]\n        \n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx].ImageId \n        label = self.df.iloc[idx].ClassId\n        img = plt.imread(path+image_id)\n        img = self.transforms(image=img)               \n        return img,label,image_id\n    \n    def __len__(self):\n        return len(self.fnames)\n\n    \ntrain_dataset = TrainDataset(train_df, _tasks)\nval_dataset = TrainDataset(val_df, _tasks)\n\n\ntr_sampler = SubsetRandomSampler(range(len(train_df)))\nval_sampler = SubsetRandomSampler(range(len(val_df)))\n\n\nbatch_size = 16 \nnum_workers = 4\n\ntrain_loader = DataLoader(train_dataset,batch_size=batch_size,\n                          num_workers=num_workers,pin_memory=True,\n                          shuffle=False,sampler=tr_sampler)\nval_loader = DataLoader(val_dataset,batch_size=batch_size,\n                        num_workers=num_workers,pin_memory=True,\n                        shuffle=False,sampler=val_sampler) \n\nprint(\"Done\", np.random.randint(1000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization - From data loader (batch by batch)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_loader_raw(k):\n    batch_size = len(k[1])\n    filenames = k[2]\n    print(filenames)\n    print(\"Image Shape:\",k[0][\"image\"].shape)\n    print(\"Label Shape:\",k[1].shape)\n    print(\"Batch Size:\",batch_size)\n    counter = np.zeros(4)\n    for i in range(batch_size):        \n        plt.figure(figsize=(20,5))\n        plt.title(\"Class Id: \"+str(k[1][i].item()+1)+ \"  \"+k[2][i])\n        plt.imshow(k[0][\"image\"][i].permute(1,2,0))        \n        counter[k[1][i].item()] += 1\n        draw_OMG([k[2][i]])\n    print(\"Defect Class distribution of {} images of type [1, 2, 3, 4] respectively:\".format(batch_size), counter)    \n\n\n\nk = next(iter(train_loader))    \ndraw_loader_raw(k)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Custom Model (extended from nn.Module)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        ## define the layers\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)       \n        self.pool = nn.MaxPool2d(2, 2)\n        self.linear1 = nn.Linear(256*1600, 512)\n        self.linear2 = nn.Linear(512, 24)\n        self.linear3 = nn.Linear(24, 4)\n        \n    \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x\n\nmodel = Model()\nprint(model)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nloss_function = nn.CrossEntropyLoss()\n#optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay= 1e-6, momentum = 0.9, nesterov = True)\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay= 1e-6, betas=(0.9,0.999), eps=1e-08,amsgrad=False)\n## run for 30 Epochs \nfor epoch in range(50):\n    train_loss, val_loss = [], []\n    \n    ## training part \n    model.train()\n    for data, target, imageid in tqdm(train_loader,desc=\"Epoch {}: \".format(epoch+1)):\n        data, target = data[\"image\"].to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_function(output, target)  \n        loss.backward()\n        optimizer.step()        \n        train_loss.append(loss.item()) \n        \n    # evaluation part \n    model.eval()\n    for data, target, imageid in tqdm(val_loader, desc=\"Epoch {}: \".format(epoch+1)):\n        data, target =  data[\"image\"].to(device), target.to(device)\n        output = model(data)\n        loss = loss_function(output, target)\n        val_loss.append(loss.item())\n    \n    print(\"Train Loss:(max, min):\",max(train_loss), min(train_loss))\n    print(\"Val   Loss:(max, min):\",max(val_loss), min(val_loss))\n    \nprint(\"DONE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction on Validation Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"## dataloader for validation dataset \nac = [0,0,0,0] # Actual Count\npc = [0,0,0,0] # Predicted Count\ncount = 0\nlc = 0\nfor data, labels, imageid in val_loader:\n    lc += 1\n    data, labels = data[\"image\"].to(device), labels.to(device)\n    output = model(data)    \n    _, preds_tensor = torch.max(output, 1)\n    actual = np.squeeze(labels.cpu().numpy()) + 1\n    preds = np.squeeze(preds_tensor.cpu().numpy()) + 1\n    for i, l in enumerate(actual):\n        ac[l-1] += 1\n        if l == preds[i]:\n            count = count+1\n            pc[l-1] += 1\n\nprint(\"Actual Count\")\nprint(\"     vs\")\nprint(\"Predicted Count\")\nprint(ac)\nprint(pc)\nprint()\nprint(\"****** PERCENTAGE ********\")\nprint((np.array(pc)/np.array(ac))*100 //1)\nprint()\n\nprint(\"******* OVER ALL *********\")\nprint(count/len(val_df))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}