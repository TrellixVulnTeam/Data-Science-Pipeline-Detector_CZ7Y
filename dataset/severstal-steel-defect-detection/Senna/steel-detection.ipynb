{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# %reload_ext autoreload\n# %autoreload 2\n# %matplotlib inline\n\n# import fastai\n# from fastai.vision import *\n# from PIL import Image\n# import zipfile\n# import io\n# import cv2\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# fastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nfolds = 1#4\n# bs = 4\n# n_cls = 4\n# noise_th = 2000 #predicted masks must be larger than noise_th\n# TEST = '../input/severstal-steel-defect-detection/test_images/'\n# BASE = '../input/severstal-fast-ai-256x256-crops/'\n\n# torch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #the code below modifies fast.ai functions to incorporate Hcolumns into fast.ai Dynamic Unet\n\n# from fastai.vision.learner import create_head, cnn_config, num_features_model, create_head\n# from fastai.callbacks.hooks import model_sizes, hook_outputs, dummy_eval, Hook, _hook_inner\n# from fastai.vision.models.unet import _get_sfs_idxs, UnetBlock\n\n# class Hcolumns(nn.Module):\n#     def __init__(self, hooks:Collection[Hook], nc:Collection[int]=None):\n#         super(Hcolumns,self).__init__()\n#         self.hooks = hooks\n#         self.n = len(self.hooks)\n#         self.factorization = None \n#         if nc is not None:\n#             self.factorization = nn.ModuleList()\n#             for i in range(self.n):\n#                 self.factorization.append(nn.Sequential(\n#                     conv2d(nc[i],nc[-1],3,padding=1,bias=True),\n#                     conv2d(nc[-1],nc[-1],3,padding=1,bias=True)))\n#                 #self.factorization.append(conv2d(nc[i],nc[-1],3,padding=1,bias=True))\n        \n#     def forward(self, x:Tensor):\n#         n = len(self.hooks)\n#         out = [F.interpolate(self.hooks[i].stored if self.factorization is None\n#             else self.factorization[i](self.hooks[i].stored), scale_factor=2**(self.n-i),\n#             mode='bilinear',align_corners=False) for i in range(self.n)] + [x]\n#         return torch.cat(out, dim=1)\n\n# class DynamicUnet_Hcolumns(SequentialEx):\n#     \"Create a U-Net from a given architecture.\"\n#     def __init__(self, encoder:nn.Module, n_classes:int, blur:bool=False, blur_final=True, \n#                  self_attention:bool=False,\n#                  y_range:Optional[Tuple[float,float]]=None,\n#                  last_cross:bool=True, bottle:bool=False, **kwargs):\n#         imsize = (224,224)\n#         sfs_szs = model_sizes(encoder, size=imsize)\n#         sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n#         self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n#         x = dummy_eval(encoder, imsize).detach()\n\n#         ni = sfs_szs[-1][1]\n#         middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),\n#                                     conv_layer(ni*2, ni, **kwargs)).eval()\n#         x = middle_conv(x)\n#         layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\n\n#         self.hc_hooks = [Hook(layers[-1], _hook_inner, detach=False)]\n#         hc_c = [x.shape[1]]\n        \n#         for i,idx in enumerate(sfs_idxs):\n#             not_final = i!=len(sfs_idxs)-1\n#             up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\n#             do_blur = blur and (not_final or blur_final)\n#             sa = self_attention and (i==len(sfs_idxs)-3)\n#             unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, \n#                 blur=blur, self_attention=sa, **kwargs).eval()\n#             layers.append(unet_block)\n#             x = unet_block(x)\n#             self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n#             hc_c.append(x.shape[1])\n\n#         ni = x.shape[1]\n#         if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\n#         if last_cross:\n#             layers.append(MergeLayer(dense=True))\n#             ni += in_channels(encoder)\n#             layers.append(res_block(ni, bottle=bottle, **kwargs))\n#         hc_c.append(ni)\n#         layers.append(Hcolumns(self.hc_hooks, hc_c))\n#         layers += [conv_layer(ni*len(hc_c), n_classes, ks=1, use_activ=False, **kwargs)]\n#         if y_range is not None: layers.append(SigmoidRange(*y_range))\n#         super().__init__(*layers)\n\n#     def __del__(self):\n#         if hasattr(self, \"sfs\"): self.sfs.remove()\n            \n# def unet_learner(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n#         norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, \n#         blur:bool=False, self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, \n#         last_cross:bool=True, bottle:bool=False, cut:Union[int,Callable]=None, \n#         hypercolumns=True, **learn_kwargs:Any)->Learner:\n#     \"Build Unet learner from `data` and `arch`.\"\n#     meta = cnn_config(arch)\n#     body = create_body(arch, pretrained, cut)\n#     M = DynamicUnet_Hcolumns if hypercolumns else DynamicUnet\n#     model = to_device(M(body, n_classes=data.c, blur=blur, blur_final=blur_final,\n#         self_attention=self_attention, y_range=y_range, norm_type=norm_type, \n#         last_cross=last_cross, bottle=bottle), data.device)\n#     learn = Learner(data, model, **learn_kwargs)\n#     learn.split(ifnone(split_on, meta['split']))\n#     if pretrained: learn.freeze()\n#     apply_init(model[2], nn.init.kaiming_normal_)\n#     return learn\n# class SegmentationLabelList(SegmentationLabelList):\n#     def open(self, fn): return open_mask(fn, div=True)\n    \n# class SegmentationItemList(SegmentationItemList):\n#     _label_cls = SegmentationLabelList\n\n# # Setting transformations on masks to False on test set\n# def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n#     if not tfms: tfms=(None,None)\n#     assert is_listy(tfms) and len(tfms) == 2\n#     self.train.transform(tfms[0], **kwargs)\n#     self.valid.transform(tfms[1], **kwargs)\n#     kwargs['tfm_y'] = False # Test data has no labels\n#     if self.test: self.test.transform(tfms[1], **kwargs)\n#     return self\n# fastai.data_block.ItemLists.transform = transform\n\n# def open_mask(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=ImageSegment,\n#         after_open:Callable=None)->ImageSegment:\n#     with warnings.catch_warnings():\n#         warnings.simplefilter(\"ignore\", UserWarning)\n#         x = PIL.Image.open(fn).convert(convert_mode)\n#     if after_open: x = after_open(x)\n#     x = pil2tensor(x,np.float32)\n#     return cls(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Prediction with flip TTA\n# def model_pred(learns, F_save,\n#         ds_type:fastai.basic_data.DatasetType=DatasetType.Valid, \n#         tta:bool=True): #if use train dl, disable shuffling\n#     for learn in learns: learn.model.eval();\n#     dl = learn.data.dl(ds_type)\n#     #sampler = dl.batch_sampler.sampler\n#     #dl.batch_sampler.sampler = torch.utils.data.sampler.SequentialSampler(sampler.data_source)\n#     name_list = [Path(n).stem for n in dl.dataset.items]\n#     num_batchs = len(dl)\n#     t = progress_bar(iter(dl), leave=False, total=num_batchs)\n#     count = 0\n#     with torch.no_grad():\n#         for x,y in t:\n#             x = x.cuda()\n#             preds = []\n#             for learn in learns:\n#                 #i, hights, widths, classes\n#                 py = torch.softmax(learn.model(x),dim=1).permute(0,2,3,1).detach()\n#                 if tta:\n#                     #you can comment some transfromations to save time\n#                     flips = [[-1],[-2],[-2,-1]]\n#                     for f in flips:\n#                         py += torch.softmax(torch.flip(learn.model(torch.flip(x,f)),f),dim=1).permute(0,2,3,1).detach()\n#                     py /= len(flips) + 1\n#                 preds.append(py)\n#             py = torch.stack(preds).mean(0).cpu().numpy() # taking average of all preds\n#             batch_size = len(py)\n#             for i in range(batch_size):\n#                 taget = y[i].detach().cpu().numpy() if y is not None else None\n#                 F_save(py[i],taget,name_list[count])\n#                 count += 1\n#     #dl.batch_sampler.sampler = sampler\n    \n# def save_img(data,name,out):\n#     img = cv2.imencode('.png',(data*255).astype(np.uint8))[1]\n#     out.writestr(name, img)\n    \n# #dice for threshold selection\n# def dice_np(pred, targs, e=1e-7):\n#     targs = targs[0,:,:]\n#     pred = np.dstack([1.0 - pred.sum(-1), pred])\n#     c = pred.shape[-1]\n#     pred = np.argmax(pred, axis=-1)\n#     dices = []\n#     eps = 1e-7\n#     for i in range(1,c):\n#         intersect = ((pred==i) & (targs==i)).sum().astype(np.float)\n#         union = ((pred==i).sum() + (targs==i).sum()).astype(np.float)\n#         dices.append((2.0*intersect + eps) / (union + eps))\n#     return np.array(dices).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def enc2mask(encs, shape=(1600,512)):\n#     img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n#     for m,enc in enumerate(encs):\n#         if isinstance(enc,np.float) and np.isnan(enc): continue\n#         s = enc.split()\n#         for i in range(len(s)//2):\n#             start = int(s[2*i]) - 1\n#             length = int(s[2*i+1])\n#             img[start:start+length] = 1 + m\n#     return img.reshape(shape).T\n\n# def mask2enc(mask, n=n_cls):\n#     pixels = mask.T.flatten()\n#     encs = []\n#     for i in range(1,n+1):\n#         p = (pixels == i).astype(np.int8)\n#         if p.sum() == 0: encs.append('')\n#         else:\n#             p = np.concatenate([[0], p, [0]])\n#             runs = np.where(p[1:] != p[:-1])[0] + 1\n#             runs[1::2] -= runs[::2]\n#             encs.append(' '.join(str(x) for x in runs))\n#     return encs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stats = ([0.400,0.402,0.404], [0.178,0.181,0.175])\n# #check https://www.kaggle.com/iafoss/256x256-images-with-defects for stats\n\n# data = (SegmentationItemList.from_folder(TEST)\n#         .split_by_idx([0])\n#         .label_from_func(lambda x : str(x), classes=[0,1,2,3,4])\n#         .add_test(Path(TEST).ls(), label=None)\n#         .databunch(path=Path('.'), bs=bs)\n#         .normalize(stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rles,ids_test = [],[]\n# learns = []\n# for fold in range(nfolds):\n#     learn = unet_learner(data, models.resnet34, pretrained=False)\n#     learn.model.load_state_dict(torch.load(Path(BASE)/f'models/fold{fold}.pth')['model'])\n#     learns.append(learn)\n\n# with zipfile.ZipFile('pred.zip', 'w') as archive_out:\n#     def to_mask(yp, y, id):\n#         name = id + '.png'\n#         save_img(yp[:,:,1:],name,archive_out)\n#         yp = np.argmax(yp, axis=-1)\n#         for i in range(n_cls):\n#             idxs = yp == i+1\n#             if idxs.sum() < noise_th: yp[idxs] = 0\n#         encs = mask2enc(yp)\n#         for i, enc in enumerate(encs):\n#             ids_test.append(id + '.jpg_' + str(i+1))\n#             rles.append(enc)\n    \n#     model_pred(learns,to_mask,DatasetType.Test)\n    \n# sub_df = pd.DataFrame({'ImageId_ClassId': ids_test, 'EncodedPixels': rles})\n# sub_df.sort_values(by='ImageId_ClassId').to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nimport glob\nimport gc\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Resize, Compose)\n#from albumentations.torch import ToTensor\nfrom albumentations.pytorch.transforms import ToTensor\nimport torch.utils.data as data\nimport torchvision.models as models\nimport torch.nn as nn\nfrom torch.nn import functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SteelDataset(Dataset):\n    def __init__(self, df, augment=None):\n\n        \n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        \n\n    def __len__(self):\n        return len(self.fnames)\n\n\n    def __getitem__(self, index):\n        image_id = self.fnames[index]\n        image = cv2.imread(test_data_folder + '/%s'%(image_id), cv2.IMREAD_COLOR)\n        return image_id, image\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\ntest_data_folder = \"../input/severstal-steel-defect-detection/test_images\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def null_collate(batch):\n    batch_size = len(batch)\n\n    input = []\n    infor = []\n    for b in range(batch_size):\n        input.append(batch[b][1])\n        infor.append(batch[b][0])\n\n    input = np.stack(input).astype(np.float32)/255\n    input = input.transpose(0,3,1,2)\n    \n    input = torch.from_numpy(input).float()\n    \n    return infor, input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(sample_submission_path)\ntest_dataset = SteelDataset(df)\n\ntest_loader = DataLoader(\n            test_dataset,\n            batch_size  = 2,\n            drop_last   = False,\n            num_workers = 0,\n            pin_memory  = True,\n            collate_fn  = null_collate\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test time augmentation  -----------------------\ndef null_augment   (input): return input\ndef flip_lr_augment(input): return torch.flip(input, dims=[2])\ndef flip_ud_augment(input): return torch.flip(input, dims=[3])\n\ndef null_inverse_augment   (logit): return logit\ndef flip_lr_inverse_augment(logit): return torch.flip(logit, dims=[2])\ndef flip_ud_inverse_augment(logit): return torch.flip(logit, dims=[3])\n\naugment = (\n        (null_augment,   null_inverse_augment   ),\n        (flip_lr_augment,flip_lr_inverse_augment),\n        (flip_ud_augment,flip_ud_inverse_augment),\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEMPERATE=0.5\n######################################################################################\ndef probability_mask_to_probability_label(probability):\n    batch_size,num_class,H,W = probability.shape\n    probability = probability.permute(0, 2, 3, 1).contiguous().view(batch_size,-1, 5)\n    value, index = probability.max(1)\n    probability = value[:,1:]\n    return probability\n\n\ndef remove_small_one(predict, min_size):\n    H,W = predict.shape\n    num_component, component = cv2.connectedComponents(predict.astype(np.uint8))\n    predict = np.zeros((H,W), np.bool)\n    for c in range(1,num_component):\n        p = (component==c)\n        if p.sum()>min_size:\n            predict[p] = True\n    return predict\n\ndef remove_small(predict, min_size):\n    for b in range(len(predict)):\n        for c in range(4):\n            predict[b,c] = remove_small_one(predict[b,c], min_size[c])\n    return predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_evaluate_segmentation(net, test_loader, augment=[]):\n\n    #----\n\n    #def sharpen(p,t=0):\n    def sharpen(p,t=TEMPERATE):\n        if t!=0:\n            return p**t\n        else:\n            return p\n\n\n    test_num  = 0\n    test_id   = []\n    #test_image = []\n    test_probability_label = [] # 8bit\n    test_probability_mask  = [] # 8bit\n    test_truth_label = []\n    test_truth_mask  = []\n\n    #start = timer()\n    for t, (fnames, input) in enumerate(tqdm(test_loader)):\n\n        batch_size,C,H,W = input.shape\n        input = input.cuda()\n\n        with torch.no_grad():\n            net.eval()\n\n            num_augment = 0\n            if 1: #  null\n                logit =  net(input)\n                probability = torch.softmax(logit,1)\n\n                probability_mask = sharpen(probability,0)\n                num_augment+=1\n\n            if 'flip_lr' in augment:\n                logit = net(torch.flip(input,dims=[3]))\n                probability  = torch.softmax(torch.flip(logit,dims=[3]),1)\n\n                probability_mask += sharpen(probability)\n                num_augment+=1\n\n            if 'flip_ud' in augment:\n                logit = net(torch.flip(input,dims=[2]))\n                probability = torch.softmax(torch.flip(logit,dims=[2]),1)\n\n                probability_mask += sharpen(probability)\n                num_augment+=1\n\n            #---\n            probability_mask = probability_mask/num_augment\n            probability_label = probability_mask_to_probability_label(probability_mask)\n\n        probability_mask = (probability_mask.data.cpu().numpy()*255).astype(np.uint8)\n        probability_label = (probability_label.data.cpu().numpy()*255).astype(np.uint8)\n\n        test_id.extend([i for i in fnames])\n\n        test_probability_mask.append(probability_mask)\n        test_probability_label.append(probability_label)\n        \n    test_probability_mask = np.concatenate(test_probability_mask)\n    test_probability_label = np.concatenate(test_probability_label)\n    \n    \n    return test_probability_label, test_probability_mask, test_id\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/henge5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ckpt_file = '../input/henge5/trace_model_swa.pth'\nnet = torch.jit.load(ckpt_file).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probability_label, probability_mask, image_id = do_evaluate_segmentation(net, test_loader, augment=['null'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del net\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#value = probability_mask*(value==probability_mask)\nprobability_mask = probability_mask[:,1:] #remove background class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_label      = [ 0.70, 0.8, 0.50, 0.70,]\nthreshold_mask_pixel = [ 0.6, 0.8, 0.5, 0.6,]\nthreshold_mask_size  = [ 1,  1,  1,  1,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_label = probability_label>(np.array(threshold_label)*255).astype(np.uint8).reshape(1,4)\npredict_mask  = probability_mask>(np.array(threshold_mask_pixel)*255).astype(np.uint8).reshape(1,4,1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id_class_id = []\nencoded_pixel = []\nfor b in range(len(image_id)):\n    for c in range(4):\n        image_id_class_id.append(image_id[b]+'_%d'%(c+1))\n\n        if predict_label[b,c]==0:\n            rle=''\n        else:\n            rle = mask2rle(predict_mask[b,c])\n        encoded_pixel.append(rle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(zip(image_id_class_id, encoded_pixel), columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarise_submission_csv(df):\n\n\n    text = ''\n    df['Class'] = df['ImageId_ClassId'].str[-1].astype(np.int32)\n    df['Label'] = (df['EncodedPixels']!='').astype(np.int32)\n    num_image = len(df)//4\n    num = len(df)\n\n    pos = (df['Label']==1).sum()\n    neg = num-pos\n\n\n    pos1 = ((df['Class']==1) & (df['Label']==1)).sum()\n    pos2 = ((df['Class']==2) & (df['Label']==1)).sum()\n    pos3 = ((df['Class']==3) & (df['Label']==1)).sum()\n    pos4 = ((df['Class']==4) & (df['Label']==1)).sum()\n\n    neg1 = num_image-pos1\n    neg2 = num_image-pos2\n    neg3 = num_image-pos3\n    neg4 = num_image-pos4\n\n\n    text += 'compare with LB probing ... \\n'\n    text += '\\t\\tnum_image = %5d(1801) \\n'%num_image\n    text += '\\t\\tnum  = %5d(7204) \\n'%num\n    text += '\\n'\n\n    text += '\\t\\tpos1 = %5d( 128)  %0.3f\\n'%(pos1,pos1/128)\n    text += '\\t\\tpos2 = %5d(  43)  %0.3f\\n'%(pos2,pos2/43)\n    text += '\\t\\tpos3 = %5d( 741)  %0.3f\\n'%(pos3,pos3/741)\n    text += '\\t\\tpos4 = %5d( 120)  %0.3f\\n'%(pos4,pos4/120)\n    text += '\\n'\n\n    text += '\\t\\tneg1 = %5d(1673)  %0.3f  %3d\\n'%(neg1,neg1/1673, neg1-1673)\n    text += '\\t\\tneg2 = %5d(1758)  %0.3f  %3d\\n'%(neg2,neg2/1758, neg2-1758)\n    text += '\\t\\tneg3 = %5d(1060)  %0.3f  %3d\\n'%(neg3,neg3/1060, neg3-1060)\n    text += '\\t\\tneg4 = %5d(1681)  %0.3f  %3d\\n'%(neg4,neg4/1681, neg4-1681)\n    text += '--------------------------------------------------\\n'\n    text += '\\t\\tneg  = %5d(6172)  %0.3f  %3d \\n'%(neg,neg/6172, neg-6172)\n    text += '\\n'\n\n    if 1:\n        #compare with reference\n        pass\n\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = summarise_submission_csv(df)\nprint(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\ndf = pd.read_csv('submission.csv')[:60]\ndf['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\n\nfor row in df.itertuples():\n    img_path = os.path.join(test_data_folder, row.Image)\n    img = cv2.imread(img_path)\n    mask = rle2mask(row.EncodedPixels, (1600, 256)) \\\n        if isinstance(row.EncodedPixels, str) else np.zeros((256, 1600))\n    if mask.sum() == 0:\n        continue\n    \n    fig, axes = plt.subplots(1, 2, figsize=(20, 60))\n    axes[0].imshow(img/255)\n    axes[1].imshow(mask*60)\n    axes[0].set_title(row.Image)\n    axes[1].set_title(row.Class)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}