{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#this is the acompanying evaluation notebook\n#it evaluates the test set and shows how the diffrent models perform\nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nThis is the inference kernel for [U-Net++ with EfficientNetB4](https://www.kaggle.com/xhlulu/severstal-u-net-with-efficientnetb4) kernel, which needed to be trained separately due to the running time exceeding 60 mins. This follows the same workflow as my [Severstal: Simple 2-step pipeline](https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline), except it loads a trained model instead of training it from scratch. Below are the relevant sections:\n\n* **Load Models**: Load the U-Net++ with some custom objects (ie. functions/classes not built-in Keras). Also load the [DenseNet for predicting missing masks](https://www.kaggle.com/xhlulu/severstal-predict-missing-masks) (i.e. samples without any defect). Those models were trained separately.\n* **Step 1: Remove test images without defects**: Basically the same task as step 1 in the *Simple 2-step pipeline*.\n* **Step 2: Predict masks using U-Net++**: Closely follows the step 2 of the same kernel, except this time we are resizing the decoded mask from 256x1600 to 256x512 before feeding it to the model, and resize the output of the model from 256x512 to 256x1600 before encoding it.\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import cv2\nimport keras\nimport keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.engine import Layer, InputSpec\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras import initializers, constraints, regularizers, layers\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm import tqdm\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport cv2\nimport collections\nimport time \nimport tqdm\nfrom PIL import Image\nfrom functools import partial\ntrain_on_gpu = True\nfrom skimage.data import imread\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport skimage\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom skimage.util import img_as_float\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load models\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Custom objects needed to load U-Net:\n\nclass GroupNormalization(keras.layers.Layer):\n    \"\"\"Group normalization layer\n    Group Normalization divides the channels into groups and computes within each group\n    the mean and variance for normalization. GN's computation is independent of batch sizes,\n    and its accuracy is stable in a wide range of batch sizes\n    # Arguments\n        groups: Integer, the number of groups for Group Normalization.\n        axis: Integer, the axis that should be normalized\n            (typically the features axis).\n            For instance, after a `Conv2D` layer with\n            `data_format=\"channels_first\"`,\n            set `axis=1` in `BatchNormalization`.\n        epsilon: Small float added to variance to avoid dividing by zero.\n        center: If True, add offset of `beta` to normalized tensor.\n            If False, `beta` is ignored.\n        scale: If True, multiply by `gamma`.\n            If False, `gamma` is not used.\n            When the next layer is linear (also e.g. `nn.relu`),\n            this can be disabled since the scaling\n            will be done by the next layer.\n        beta_initializer: Initializer for the beta weight.\n        gamma_initializer: Initializer for the gamma weight.\n        beta_regularizer: Optional regularizer for the beta weight.\n        gamma_regularizer: Optional regularizer for the gamma weight.\n        beta_constraint: Optional constraint for the beta weight.\n        gamma_constraint: Optional constraint for the gamma weight.\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n    # Output shape\n        Same shape as input.\n    # References\n        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n    \"\"\"\n\n    def __init__(self,\n                 groups=32,\n                 axis=-1,\n                 epsilon=1e-5,\n                 center=True,\n                 scale=True,\n                 beta_initializer='zeros',\n                 gamma_initializer='ones',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(GroupNormalization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.groups = groups\n        self.axis = axis\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n\n        if dim is None:\n            raise ValueError('Axis ' + str(self.axis) + ' of '\n                             'input tensor should have a defined dimension '\n                             'but the layer received an input with shape ' +\n                             str(input_shape) + '.')\n\n        if dim < self.groups:\n            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n                             'more than the number of channels (' +\n                             str(dim) + ').')\n\n        if dim % self.groups != 0:\n            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n                             'multiple of the number of channels (' +\n                             str(dim) + ').')\n\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name='gamma',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name='beta',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.built = True\n\n    def call(self, inputs, **kwargs):\n        input_shape = K.int_shape(inputs)\n        tensor_input_shape = K.shape(inputs)\n\n        # Prepare broadcasting shape.\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n        broadcast_shape.insert(1, self.groups)\n\n        reshape_group_shape = K.shape(inputs)\n        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n        group_axes[self.axis] = input_shape[self.axis] // self.groups\n        group_axes.insert(1, self.groups)\n\n        # reshape inputs to new group shape\n        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n        group_shape = K.stack(group_shape)\n        inputs = K.reshape(inputs, group_shape)\n\n        group_reduction_axes = list(range(len(group_axes)))\n        group_reduction_axes = group_reduction_axes[2:]\n\n        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n\n        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n\n        # prepare broadcast shape\n        inputs = K.reshape(inputs, group_shape)\n        outputs = inputs\n\n        # In this case we must explicitly broadcast all parameters.\n        if self.scale:\n            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n            outputs = outputs * broadcast_gamma\n\n        if self.center:\n            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n            outputs = outputs + broadcast_beta\n\n        outputs = K.reshape(outputs, tensor_input_shape)\n\n        return outputs\n\n    def get_config(self):\n        config = {\n            'groups': self.groups,\n            'axis': self.axis,\n            'epsilon': self.epsilon,\n            'center': self.center,\n            'scale': self.scale,\n            'beta_initializer': initializers.serialize(self.beta_initializer),\n            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n            'beta_constraint': constraints.serialize(self.beta_constraint),\n            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n        }\n        base_config = super(GroupNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class AccumOptimizer(keras.optimizers.Optimizer):\n    \"\"\"继承Optimizer类，包装原有优化器，实现梯度累积。\n    # 参数\n        optimizer：优化器实例，支持目前所有的keras优化器；\n        steps_per_update：累积的步数。\n    # 返回\n        一个新的keras优化器\n    Inheriting Optimizer class, wrapping the original optimizer\n    to achieve a new corresponding optimizer of gradient accumulation.\n    # Arguments\n        optimizer: an instance of keras optimizer (supporting\n                    all keras optimizers currently available);\n        steps_per_update: the steps of gradient accumulation\n    # Returns\n        a new keras optimizer.\n    \"\"\"\n    def __init__(self, optimizer=Adam(2e-3), steps_per_update=4, **kwargs):\n        super(AccumOptimizer, self).__init__(**kwargs)\n        self.optimizer = optimizer\n        with K.name_scope(self.__class__.__name__):\n            self.steps_per_update = steps_per_update\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.cond = K.equal(self.iterations % self.steps_per_update, 0)\n            self.lr = self.optimizer.lr\n            self.optimizer.lr = K.switch(self.cond, self.optimizer.lr, 0.)\n            for attr in ['momentum', 'rho', 'beta_1', 'beta_2']:\n                if hasattr(self.optimizer, attr):\n                    value = getattr(self.optimizer, attr)\n                    setattr(self, attr, value)\n                    setattr(self.optimizer, attr, K.switch(self.cond, value, 1 - 1e-7))\n            for attr in self.optimizer.get_config():\n                if not hasattr(self, attr):\n                    value = getattr(self.optimizer, attr)\n                    setattr(self, attr, value)\n            # 覆盖原有的获取梯度方法，指向累积梯度\n            # Cover the original get_gradients method with accumulative gradients.\n            def get_gradients(loss, params):\n                return [ag / self.steps_per_update for ag in self.accum_grads]\n            self.optimizer.get_gradients = get_gradients\n    def get_updates(self, loss, params):\n        self.updates = [\n            K.update_add(self.iterations, 1),\n            K.update_add(self.optimizer.iterations, K.cast(self.cond, 'int64')),\n        ]\n        # 累积梯度 (gradient accumulation)\n        self.accum_grads = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        grads = self.get_gradients(loss, params)\n        for g, ag in zip(grads, self.accum_grads):\n            self.updates.append(K.update(ag, K.switch(self.cond, ag * 0, ag + g)))\n        # 继承optimizer的更新 (inheriting updates of original optimizer)\n        self.updates.extend(self.optimizer.get_updates(loss, params)[1:])\n        self.weights.extend(self.optimizer.weights)\n        return self.updates\n    def get_config(self):\n        iterations = K.eval(self.iterations)\n        K.set_value(self.iterations, 0)\n        config = self.optimizer.get_config()\n        K.set_value(self.iterations, iterations)\n        return config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\nclass FixedDropout(keras.layers.Dropout):\n    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)\ndef dice_coef_rounded(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return score\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Remove test images without defects"},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsub_df = pd.read_csv('../input/understanding_cloud_organization/sample_submission.csv')\nsub_df['ImageId'] = sub_df['Image_Label'].apply(lambda x: x.split('_')[0])\n\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ntest_imgs.head()\n\n\n\n#train_df = pd.read_csv('../input/cloud-experiment-dataset/trainC1-16.csv')\n#train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n#train_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n#train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Perform Removal"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#`filtered_sub_df` contains all of the images with at least one mask. `null_sub_df` contains all the images with exactly 4 missing masks.\n\nfiltered_mask = sub_df['ImageId'].isin(test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\ntest_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nfiltered_sub_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Predict masks using U-Net++"},{"metadata":{},"cell_type":"markdown","source":"## Utility Functions"},{"metadata":{},"cell_type":"markdown","source":"Unhide below for the definition of `np_resize`, `build_masks`, `build_rles`."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def np_resize(img, input_shape):\n    \"\"\"\n    Reshape a numpy array, which is input_shape=(height, width), \n    as opposed to input_shape=(width, height) for cv2\n    \"\"\"\n    height, width = input_shape\n    return cv2.resize(img, (width, height))\n    \ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape, reshape=None):\n    depth = len(rles)\n    if reshape is None:\n        masks = np.zeros((*input_shape, depth))\n    else:\n        masks = np.zeros((*reshape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            if reshape is None:\n                masks[:, :, i] = rle2mask(rle, input_shape)\n            else:\n                mask = rle2mask(rle, input_shape)\n                reshaped_mask = np_resize(mask, reshape)\n                masks[:, :, i] = reshaped_mask\n    \n    return masks\n\ndef build_rles(masks, reshape=None):\n    width, height, depth = masks.shape\n    \n    rles = []\n    \n    for i in range(depth):\n        mask = masks[:, :, i]\n        \n        if reshape:\n            mask = mask.astype(np.float32)\n            mask = np_resize(mask, reshape).astype(np.int64)\n        \n        rle = mask2rle(mask)\n        rles.append(rle)\n        \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 #base_path='../input/severstal-steel-defect-detection/train_images',\n                 #base_path='../input/severstal-steel-defect-detection/train_images',\n                 #batch_size=32, dim=(256, 1600), n_channels=3, reshape=None,\n                 #n_classes=4, random_state=2019, shuffle=True):\n                 base_path='../input/understanding_cloud_organization/train_images',\n                 batch_size=32, dim=(1400, 2100), n_channels=3, reshape=None,\n                 augment=False, n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.reshape = reshape\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        if self.reshape is None:\n            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        else:\n            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            \n            if self.reshape is not None:\n                img = np_resize(img, self.reshape)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        if self.reshape is None:\n            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        else:\n            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            \n            if self.reshape is not None:\n                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n            else:\n                masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate what models \n# activateelu_data_4 = True\n# batch4_data_4 = True\n# lesslayers_data_4 = True\n# groupnorm_data_4 = True\n# augmented_class_16 = True\n# augmented_pure_4 = True\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the baseline_data_4 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/baseline_data_4.h5'\nh_classes = 4\ncsv_file_name = 'baseline_data_4.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    \n    \n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the activateelu_data_4 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/activateelu_data_4.h5'\nh_classes = 4\ncsv_file_name = 'activateelu_data_4.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the batch4_data_4 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/batch4_data_4.h5'\nh_classes = 4\ncsv_file_name = 'batch4_data_4.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the lesslayers_data_4 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/lesslayers_data_4.h5'\nh_classes = 4\ncsv_file_name = 'lesslayers_data_4.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the groupnorm_data_4 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/groupnorm_data_4.h5'\nh_classes = 4\ncsv_file_name = 'groupnorm_data_4.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the augmented_pure_4 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/augmented_pure_4.h5'\nh_classes = 4\ncsv_file_name = 'augmented_pure_4.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the augmented_class_16 class model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nunet_model_path = '../input/trained-models-cloud-mini-project/augmented_class_16.h5'\nh_classes = 16\ncsv_file_name = 'augmented_class_16.csv'\n\nfrom keras.optimizers import Adam\n\ncustom_objects = custom_objects={\n    'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'GroupNormalization': GroupNormalization,\n    'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    'dice_coef_rounded': dice_coef_rounded\n\n}\n\nunet = load_model(unet_model_path, custom_objects=custom_objects)\n\nunet.summary()\n\ntest_df = []\n\n#for all images in test set iterate over thme in increments of 300\nfor i in range(0, test_imgs.shape[0], 300):\n    #print(\"loop : \", i)\n\n    # create a batch of 300 elements that needs to be processed\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 300)) )\n\n    # make the test generator for that batch \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/understanding_cloud_organization/test_images',        \n        target_df=filtered_sub_df,\n        reshape=(256, 384),\n        batch_size=1,\n        n_classes=h_classes\n    )\n\n    # predict masks for each of those sampels\n    batch_pred_masks = unet.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm.tqdm(enumerate(batch_idx)):\n\n        filename = test_imgs['ImageId'].iloc[b]\n\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks,reshape=(350, 525))\n\n        image_df = pd.DataFrame(  np.array( [ \n            [image_df.iloc[0, 0], pred_rles[0], image_df.iloc[0, 2]], \n            [image_df.iloc[1, 0], pred_rles[1], image_df.iloc[1, 2]], \n            [image_df.iloc[2, 0], pred_rles[2], image_df.iloc[2, 2]], \n            [image_df.iloc[3, 0], pred_rles[3], image_df.iloc[3, 2]] ] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n        test_df.append(image_df)\n\n\n\n\n\nl1 = pred_rles[0]\nl2 = pred_rles[1]\nl3 = pred_rles[2]\nl4 = pred_rles[3]\n\n\ndf = pd.DataFrame(  np.array( [ \n    [image_df.iloc[0, 0], l1, image_df.iloc[0, 2]], \n    [image_df.iloc[1, 0], l2, image_df.iloc[1, 2]], \n    [image_df.iloc[2, 0], l3, image_df.iloc[2, 2]], \n    [image_df.iloc[3, 0], l4, image_df.iloc[3, 2]] \n] ), columns=[ 'Image_Label', 'EncodedPixels', 'ImageId' ] )\n\n\nprint(df)\n\ntest_df = pd.concat(test_df)\nfinal_submission_df = pd.concat([test_df, null_sub_df])\n\nprint(test_df.shape)\nprint(final_submission_df.shape)\n\nfinal_submission_df.head()\n\nfinal_submission_df[['Image_Label', 'EncodedPixels']].to_csv(csv_file_name, index=False)#\n\nprint(final_submission_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotter_funk(my_plot, index, mask, label,image_name):\n    my_plot_arr = my_plot.flat[index]\n    my_plot_arr.axis('off') \n    imgcv2 = plt.imread('../input/understanding_cloud_organization/test_images/' + image_name)\n    my_plot_arr.imshow(imgcv2)\n    my_plot_arr.imshow(mask, alpha=0.5)\n    my_plot_arr.set_title(label, fontsize=24)\n\n\ndef rle_decode(mask_rle, shape=(350, 525)):\n   \n\n\n    try: # label might not be there!\n        s = mask_rle[0].split()\n\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n        starts -= 1\n        ends = starts + lengths\n        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n        return img.reshape(shape, order='F')  # Needed to align to RLE direction\n    except:\n        #print(\"fail\")\n        return np.zeros((350, 525))\n    \n\n    \n    \n\n\ndef plot_results( result_csv,image_name1,image_name2,image_name3,image_name4 ):\n\n    train_df = pd.read_csv(result_csv)\n    train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n    train_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n    #train_df['EncodedPixels'] = train_df['EncodedPixels'].apply(lambda x: x.split(' ')[0])\n    train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\n    print(result_csv)\n\n\n\n\n    labels = [] # sorted(list(set(train_df['Image_Label'].apply(lambda x: x.split('_')[1]))))\n\n    labels.append(\"Fish\")\n    labels.append(\"Flower\")\n    labels.append(\"Gravel\")\n    labels.append(\"Sugar\")\n    labels.append(\"Fish\")\n    labels.append(\"Flower\")\n    labels.append(\"Gravel\")\n    labels.append(\"Sugar\")\n    labels.append(\"Fish\")\n    labels.append(\"Flower\")\n    labels.append(\"Gravel\")\n    labels.append(\"Sugar\")\n    labels.append(\"Fish\")\n    labels.append(\"Flower\")\n    labels.append(\"Gravel\")\n    labels.append(\"Sugar\")\n\n\n    label = 'Fish'\n    image_label = image_name1 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label , 'EncodedPixels'].values\n    Fish1 = rle_decode(mask_rle)\n    label = 'Flower'\n    image_label = image_name1 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Flower1 = rle_decode(mask_rle)\n    label = 'Gravel'\n    image_label = image_name1 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Gravel1 = rle_decode(mask_rle)\n    label = 'Sugar'\n    image_label = image_name1 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Sugar1 = rle_decode(mask_rle)\n\n\n    label = 'Fish'\n    image_label = image_name2 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label , 'EncodedPixels'].values\n    Fish2 = rle_decode(mask_rle)\n    label = 'Flower'\n    image_label = image_name2 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Flower2 = rle_decode(mask_rle)\n    label = 'Gravel'\n    image_label = image_name2 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Gravel2 = rle_decode(mask_rle)\n    label = 'Sugar'\n    image_label = image_name2 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Sugar2 = rle_decode(mask_rle)\n\n    label = 'Fish'\n    image_label = image_name3 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label , 'EncodedPixels'].values\n    Fish3 = rle_decode(mask_rle)\n    label = 'Flower'\n    image_label = image_name3 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Flower3 = rle_decode(mask_rle)\n    label = 'Gravel'\n    image_label = image_name3 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Gravel3 = rle_decode(mask_rle)\n    label = 'Sugar'\n    image_label = image_name3 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Sugar3 = rle_decode(mask_rle)\n\n    label = 'Fish'\n    image_label = image_name4 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label , 'EncodedPixels'].values\n    Fish4 = rle_decode(mask_rle)\n    label = 'Flower'\n    image_label = image_name4 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Flower4 = rle_decode(mask_rle)\n    label = 'Gravel'\n    image_label = image_name4 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Gravel4 = rle_decode(mask_rle)\n    label = 'Sugar'\n    image_label = image_name4 + '_' + label\n    mask_rle = train_df.loc[train_df['Image_Label'] == image_label, 'EncodedPixels'].values\n    Sugar4 = rle_decode(mask_rle)\n\n\n\n\n\n    fig, my_plot = plt.subplots(4, 4, figsize=(20, 20)) \n\n\n    plotter_funk(my_plot, 0, Fish1, labels[0],image_name1)\n    plotter_funk(my_plot, 1, Flower1, labels[1],image_name1)\n    plotter_funk(my_plot, 2, Gravel1, labels[2],image_name1)\n    plotter_funk(my_plot, 3, Sugar1, labels[3],image_name1)\n    plotter_funk(my_plot, 4, Fish2, labels[0],image_name2)\n    plotter_funk(my_plot, 5, Flower2, labels[1],image_name2)\n    plotter_funk(my_plot, 6, Gravel2, labels[2],image_name2)\n    plotter_funk(my_plot, 7, Sugar2, labels[3],image_name2)\n    plotter_funk(my_plot, 8, Fish3, labels[0],image_name3)\n    plotter_funk(my_plot, 9, Flower3, labels[1],image_name3)\n    plotter_funk(my_plot, 10, Gravel3, labels[2],image_name3)\n    plotter_funk(my_plot, 11, Sugar3, labels[3],image_name3)\n    plotter_funk(my_plot, 12, Fish4, labels[0],image_name4)\n    plotter_funk(my_plot, 13, Flower4, labels[1],image_name4)\n    plotter_funk(my_plot, 14, Gravel4, labels[2],image_name4)\n    plotter_funk(my_plot, 15, Sugar4, labels[3],image_name4)\n\n    plt.tight_layout(h_pad=0.1, w_pad=0.1)\n    plt.show()\n    \n    \n    \n    \nplot_results('../input/trained-models-cloud-mini-project/baseline_data_4.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\nplot_results('../input/trained-models-cloud-mini-project/activateelu_data_4.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\nplot_results('../input/trained-models-cloud-mini-project/batch4_data_4.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\nplot_results('../input/trained-models-cloud-mini-project/lesslayers_data_4.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\nplot_results('../input/trained-models-cloud-mini-project/groupnorm_data_4.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\nplot_results('../input/trained-models-cloud-mini-project/augmented_class_16.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\nplot_results('../input/trained-models-cloud-mini-project/augmented_pure_4.csv' , '0a3d2d8.jpg', '006440a.jpg','00a47f4.jpg' ,'0111e06.jpg')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}