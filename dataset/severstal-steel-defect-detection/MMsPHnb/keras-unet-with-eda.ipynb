{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Keras Segmentation Models\nIn this kernel, we learn how to install and use pretrained Keras segmentation models from GitHub [here][1] with docs [here][2]. We also plot EDA showing training examples, UNET prediction examples, and UNET error.\n\n# Data Generator\nFirst let's restructure the train.csv dataframe and build a data generator. We will need to feed our neural network `X_train` of images and `y_train` of masks. We will resize all images by a factor of 0.5 for efficiency. (Convert 256x1600 RGB to 128x800 RGB).\n\n[1]: https://github.com/qubvel/segmentation_models\n[2]: https://segmentation-models.readthedocs.io/en/latest/tutorial.html","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd, os, gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image \nimport warnings\n#import tensorflow as tf\n#from tensorflow.keras.losses import binary_crossentropy\nwarnings.filterwarnings(\"ignore\")\npath = '../input/'\ntrain = pd.read_csv('../input/submission1/submission (1).csv')\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\n\n\n\n#train2 = pd.DataFrame({'ImageId':train['ImageId']}) \n#train2['e1'] = train.loc[train['ClassId'] == 1, ['EncodedPixels']]\n#train2['e2'] = train.loc[train['ClassId'] == 2, ['EncodedPixels']]\n#train2['e3'] = train.loc[train['ClassId'] == 3, ['EncodedPixels']]\n#train2['e4'] = train.loc[train['ClassId'] == 4, ['EncodedPixels']]\n\n\ntrain2.reset_index(inplace=True,drop=True) #不创建新的对象，直接对原始对象进行修改；去掉原来的索引index列；\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).values #axis=按列填充;iloc按行查看\ntrain2.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-11-13T10:07:41.529811Z","iopub.execute_input":"2021-11-13T10:07:41.530121Z","iopub.status.idle":"2021-11-13T10:07:41.567223Z","shell.execute_reply.started":"2021-11-13T10:07:41.530071Z","shell.execute_reply":"2021-11-13T10:07:41.566586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# https://www.kaggle.com/ateplyuk/pytorch-starter-u-net-resnet\n# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\nimport keras\nimport math\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, \n                 preprocess=None, info={}):\n        #batch_size = 16每个序列时间训练样本数为16，shuffle：是否打乱输出样本，还是按照时间顺序绘制它们。\n        super().__init__()\n        self.df = df #image_id\n        self.shuffle = shuffle\n        self.subset = subset#子集\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'severstal-steel-defect-detection/train_images/'\n        if self.subset == \"test\":\n            self.data_path = path + 'severstal-steel-defect-detection/test_images/'\n        self.on_epoch_end()\n\n        \n    def __fillna__(self):\n        self.df.fillna('0',inplace=True)\n    #def __len__(self):\n     #   return int(np.floor(len(self.df) / self.batch_size))\n    def __len__(self):\n        return int(math.ceil(len(self.df) / self.batch_size))\n    #np.floor向下取整函数#计算每一个epoch的迭代次数使用次数（表示每个历元的批数）\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    #在每一次epoch结束是否需要进行一次随机，重新随机一下index\n    \n    def __getitem__(self, index): \n    #   该函数返回每次我们需要的经过处理的数据。   \n        X = np.empty((self.batch_size,128,800,3),dtype=np.float32)\n        \n        #numpy.empty(shape, dtype=float, order=‘C’)\n        \n        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)#*self.img_size训练的图片尺寸\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        #生成每个batch的索引indexs\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f).resize((800,128))\n            if self.subset == 'train': \n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess!=None: X = self.preprocess(X)\n        if self.subset == 'train': return X, y\n        else: return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T10:07:42.380788Z","iopub.execute_input":"2021-11-13T10:07:42.381078Z","iopub.status.idle":"2021-11-13T10:07:42.397785Z","shell.execute_reply.started":"2021-11-13T10:07:42.381029Z","shell.execute_reply":"2021-11-13T10:07:42.396958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions\nNext we'll need some utility functions. The first converts rle to mask. The second converts a mask to its contour. The third enlarges a mask. The second and third together put blank space between defect and mask contour for better visualization.","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/titericz/building-and-visualizing-masks\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    #判断是否为空值，如果是用0填充（确保格式相同)\n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1#起始值为1，确保为0\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)#聚合array\n    mask2 = np.logical_xor(mask,mask2)#相同时输出0，不同时输出1；建立掩模\n    \n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):#\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT/\n    w = mask.shape[1]\n    h = mask.shape[0]\n\n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n       \n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-13T10:07:44.539193Z","iopub.execute_input":"2021-11-13T10:07:44.539508Z","iopub.status.idle":"2021-11-13T10:07:44.558033Z","shell.execute_reply.started":"2021-11-13T10:07:44.539458Z","shell.execute_reply":"2021-11-13T10:07:44.55709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train EDA\nLet's confirm our Data Generator works and view some training images. We will only show examples with defects. Note that all mask contours are plotted with a little blank space around the defect to aid visualization. Below we show examples of each type but note that in the training set only 7.1%, 2.0%, 41.0%, 6.4% of images have defects 1, 2, 3, 4 respectively.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(13.5,2.5))#指定figure的宽和高，单位为英寸\nbar = plt.bar( [1,2,3,4],100*np.mean( train2.iloc[:,1:5]!='',axis=0) )\nplt.title('Percent Training Images with Defect', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Defect Type')\nplt.xticks([1,2,3,4])\nfor rect in bar:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=16)\nplt.ylim((0,100)); plt.show()#此处将50修改为100","metadata":{"execution":{"iopub.status.busy":"2021-11-13T10:07:51.765197Z","iopub.execute_input":"2021-11-13T10:07:51.765523Z","iopub.status.idle":"2021-11-13T10:07:51.911624Z","shell.execute_reply.started":"2021-11-13T10:07:51.765471Z","shell.execute_reply":"2021-11-13T10:07:51.909784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DEFECTIVE IMAGE SAMPLES\nfilenames = {}\ndefects = list(train2[train2['e1']!=''].sample(1).index)\ndefects += list(train2[train2['e2']!=''].sample(1).index)\ndefects += list(train2[train2['e3']!=''].sample(2).index)\ndefects += list(train2[train2['e4']!=''].sample(2).index)\n\n# DATA GENERATOR\n#train_batches= pd.read_csv('../input/submission1/submission (1).csv')\ntrain_batches = DataGenerator(train2[train2.index.isin(defects)],shuffle=True,info=filenames)\nprint('Images and masks from our Data Generator')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\n# DISPLAY IMAGES WITH DEFECTS\nfor i,batch in enumerate(train_batches):\n    plt.figure(figsize=(14,50)) #20,18\n    for k in range(16):#sample为6张\n        plt.subplot(16,1,k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        extra = '  has defect'\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            msk = mask2pad(msk,pad=3)\n            msk = mask2contour(msk,width=2)\n            if np.sum(msk)!=0: extra += ' '+str(j+1)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        plt.title(filenames[16*i+k]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T10:07:53.033237Z","iopub.execute_input":"2021-11-13T10:07:53.033537Z","iopub.status.idle":"2021-11-13T10:07:54.311854Z","shell.execute_reply.started":"2021-11-13T10:07:53.033487Z","shell.execute_reply":"2021-11-13T10:07:54.310655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}