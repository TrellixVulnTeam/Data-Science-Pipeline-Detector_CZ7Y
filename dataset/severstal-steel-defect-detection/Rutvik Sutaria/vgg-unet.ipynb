{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import UpSampling2D, Conv2D, Activation,Dropout\nfrom keras.layers.convolutional import Conv2DTranspose\nfrom keras import Model\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/severstal-steel-defect-detection/'\ntrain_image_dir = os.path.join(train_dir, 'train_images')\ntest_image_dir = os.path.join(train_dir, 'test_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# original image is 1600x256, so we will resize it\nimg_w = 800 # resized width\nimg_h = 128 # resized height\nbatch_size = 12\nepochs = 10\n# batch size for training unet\nk_size = 3 # kernel size 3x3\nval_size = .20 # split of training set between train and validation set\n# we will repeat the images with lower samples to make the training process more fair\nrepeat = False\n# only valid if repeat is True\nclass_1_repeat = 1 # repeat class 1 examples x times\nclass_2_repeat = 1\nclass_3_repeat = 1\nclass_4_repeat = 1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(train_dir, 'train.csv')).fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n# lets create a dict with class id and encoded pixels and group all the defaults per image\ntrain_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\ngrouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_to_mask(rle_string,height,width):\n    '''\n    convert RLE(run length encoding) string to numpy array\n\n    Parameters: \n    rleString (str): Description of arg1 \n    height (int): height of the mask\n    width (int): width of the mask \n    \n\n    Returns: \n    numpy.array: numpy array of the mask\n    '''\n    rows, cols = height, width\n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rleNumbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rlePairs = np.array(rleNumbers).reshape(-1,2)\n        img = np.zeros(rows*cols,dtype=np.uint8)\n        for index,length in rlePairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, list_ids, labels, image_dir, batch_size=32,\n                 img_h=256, img_w=512, shuffle=True):\n        \n        self.list_ids = list_ids\n        self.labels = labels\n        self.image_dir = image_dir\n        self.batch_size = batch_size\n        self.img_h = img_h\n        self.img_w = img_w\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_ids)) / self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        list_ids_temp = [self.list_ids[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(list_ids_temp)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.list_ids))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, list_ids_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n        y = np.empty((self.batch_size, self.img_h, self.img_w, 4))\n        \n        for idx, id in enumerate(list_ids_temp):\n#             print(id)\n            file_path =  os.path.join(self.image_dir, id)\n            image = cv2.imread(file_path, 0)\n            # print\n            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            \n            mask = np.empty((img_h, img_w, 4))\n            \n            for idm, image_class in enumerate(['1','2','3','4']):\n                rle = self.labels.get(id + '_' + image_class)\n                # if there is no mask create empty mask\n                if rle is None:\n                    class_mask = np.zeros((1600, 256))\n                else:\n                    class_mask = rle_to_mask(rle, width=1600, height=256)\n             \n                class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n                mask[...,idm] = class_mask_resized\n            \n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            y[idx,] = mask\n        \n        # normalize Y\n        y = (y > 0).astype(int)\n            \n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dict of all the masks\nmasks = {}\nfor index, row in train_df[train_df['EncodedPixels']!=-1].iterrows():\n    masks[row['ImageId_ClassId']] = row['EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_ids = train_df['ImageId'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val = train_test_split(train_image_ids, test_size=val_size, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'img_h': img_h,\n          'img_w': img_w,\n          'image_dir': train_image_dir,\n          'batch_size': batch_size,\n          'shuffle': True}\n\n# Get Generators\ntraining_generator = DataGenerator(X_train, masks, **params)\nvalidation_generator = DataGenerator(X_val, masks, **params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out the shapes\nx, y = training_generator.__getitem__(0)\nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize steel image with four classes of faults in seperate columns\ndef viz_steel_img_mask(img, masks):\n#     img = cv2.cvtColor(img.astype('float32'), cv2.COLOR_BGR2RGB)\n    fig, ax = plt.subplots(nrows=1, ncols=4, sharey=True, figsize=(20,10))\n    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n    for idx, mask in enumerate(masks):\n        ax[idx].imshow(img)\n        ax[idx].imshow(mask, alpha=0.3, cmap=cmaps[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ix in range(0,batch_size):\n    if y[ix].sum() > 0:\n        img = x[ix][...,0]\n        masks_temp = [y[ix][...,i] for i in range(0,4)]\n        viz_steel_img_mask(img, masks_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    # print((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n    # print(K.sum(y_true_f).shape)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nbase_model = VGG16(weights=None, input_shape=(img_h,img_w,1), include_top=False)\nbase_model.trainable = False\ndef VGG_Unet():\n  base_model = VGG16(weights=None, input_shape=(img_h,img_w,1), include_top=False)\n  base_out = base_model.output\n  u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (base_out)\n  # u6 = concatenate([u6, c4])\n  c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n  c6 = Dropout(0.2) (c6)\n  c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n  u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n  # u7 = concatenate([u7, c3])\n  c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n  c7 = Dropout(0.2) (c7)\n  c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n  u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n  # u8 = concatenate([u8, c2])\n  c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n  c8 = Dropout(0.1) (c8)\n  c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n  u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n  # u9 = concatenate([u9, c1], axis=3)\n  c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n  c9 = Dropout(0.1) (c9)\n  c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n  u10 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c9)\n  # u9 = concatenate([u9, c1], axis=3)\n  c10 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u10)\n  c10 = Dropout(0.1) (c10)\n  c10 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c10)\n\n  outputs = Conv2D(4, (1, 1), activation='sigmoid') (c10)\n  model = Model(input=base_model.input, output=outputs)\n\n  model.compile(optimizer = keras.optimizers.Adam(lr=0.0001),loss = 'binary_crossentropy',metrics = [dice_coef])\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG_Unet()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('../input/weights/vgg_unet_weights_25.h5')\n# history = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save_path = './vgg_unet_weights1.h5' \nmodel.save(model_save_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # summarize history for accuracy\n# plt.figure(figsize=(20,5))\n# plt.subplot(1,2,1)\n# plt.plot(history.history['dice_coef'])\n# plt.plot(history.history['val_dice_coef'])\n# plt.title('model accuracy')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'validation'], loc='upper left')\n\n# # summarize history for loss\n# plt.subplot(1,2,2)\n# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('model loss')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'validation'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_iou(target, prediction):\n    intersection = np.logical_and(target, prediction)\n    union = np.logical_or(target, prediction)\n    if np.sum(union) == 0:\n        iou_score = 0\n    else:\n        iou_score = np.sum(intersection) / np.sum(union)\n    return iou_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def viz_single_fault(img, mask, pred, image_class):\n    \n    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(15,5))\n    \n    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n    \n    ax[0].imshow(img)\n    ax[0].imshow(mask, alpha=0.3, cmap=cmaps[image_class-1])\n    ax[0].set_title('Mask - Defect Class %s' % image_class)\n    \n    ax[1].imshow(img)\n    ax[1].imshow(pred, alpha=0.3, cmap=cmaps[image_class-1])\n    ax[1].set_title('Predicted Mask - Defect Class %s' % image_class)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count = 0\n# # a list to keep count of the number of plots made per image class\n# class_viz_count = [0,0,0,0]\n# # to keep the total iou score per image class\n# class_iou_score = [0, 0, 0, 0]\n# # to keep sum of mask pixels per image class\n# class_mask_sum = [0, 0, 0, 0]\n# # to keep sum of predicted mask pixels per image class\n# class_pred_sum = [0, 0, 0, 0]\n\n# # loop over to all the batches in one epoch \n# for i in range(0, validation_generator.__len__()):\n#     # get a batch of image, true mask, and predicted mask\n#     x, y = validation_generator.__getitem__(i)\n#     predictions = model.predict(x)\n\n#     # loop through x to get all the images in the batch\n#     for idx, val in enumerate(x):\n#         # we are only interested if there is a fault. if we are dropping images with no faults before this will become redundant\n#         if y[idx].sum() > 0: \n#             # get an image and convert to make it matplotlib.pyplot friendly\n#             img = x[idx][...,0]\n# #             img = cv2.cvtColor(img.astype('float32'), cv2.COLOR_BGR2RGB)\n#             # loop over the four ourput layers to create a list of all the masks for this image\n#             masks_temp = [y[idx][...,i] for i in range(0,4)]\n#             # loop over the four output layers to create a list of all the predictions for this image\n#             preds_temp = [predictions[idx][...,i] for i in range(0,4)]\n#             # turn to binary (prediction) mask \n#             preds_temp = [p > .5 for p in preds_temp]\n\n#             for i, (mask, pred) in enumerate(zip(masks_temp, preds_temp)):\n#                 image_class = i + 1\n#                 class_iou_score[i] += calculate_iou(mask, pred)\n#                 class_mask_sum[i] += mask.sum()\n#                 class_pred_sum[i] += pred.sum()\n#                 if mask.sum() > 0 and class_viz_count[i] < 5:\n#                     viz_single_fault(img, mask, pred, image_class)\n#                     class_viz_count[i] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class_ids = [1,2,3,4]\n# plt.figure(figsize=(20,5))\n# plt.subplot(1,3,1)\n# y_pos = np.arange(len(class_ids))\n# plt.bar(y_pos, class_iou_score)\n# plt.xticks(y_pos, class_ids)\n# plt.title('IoU score per class')\n# plt.ylabel('IoU Sum')\n# plt.xlabel('class id')\n# plt.subplot(1,3,2)\n# plt.bar(y_pos, class_mask_sum)\n# plt.xticks(y_pos, class_ids)\n# plt.title('labeled mask pixel sum per class')\n# plt.ylabel('pixel sum')\n# plt.xlabel('class id')\n# plt.ticklabel_format(axis='y',style='sci',scilimits=(1,4))\n# plt.subplot(1,3,3)\n# plt.bar(y_pos, class_pred_sum)\n# plt.xticks(y_pos, class_ids)\n# plt.title('predicted mask pixel sum per class')\n# plt.ylabel(' pixel sum')\n# plt.xlabel('class id')\n# plt.ticklabel_format(axis='y',style='sci',scilimits=(1,4))\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_tensor(img_dir, img_h, img_w, channels=1):\n\n    X = np.empty((1, img_h, img_w, channels))\n    # Store sample\n    image = cv2.imread(img_dir, 0)\n    image_resized = cv2.resize(image, (img_w, img_h))\n    image_resized = np.array(image_resized, dtype=np.float64)\n    # normalize image\n    image_resized -= image_resized.mean()\n    image_resized /= image_resized.std()\n    \n    X[0,] = np.expand_dims(image_resized, axis=2)\n\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import morphology\n\ndef remove_small_regions(img, size):\n    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n    img = morphology.remove_small_objects(img, size)\n    img = morphology.remove_small_holes(img, size)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\n# get all files using glob\ntest_files = [f for f in glob.glob('../input/severstal-steel-defect-detection/train_images/' + \"*.jpg\", recursive=True)]\ntest_files = test_files[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(train_dir, 'sample_submission.csv'))\ntest_df['ImageId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_df['ClassId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_ids = test_df['ImageId'].unique()\nprint(test_image_ids[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = []\ndef process_pred_mask(pred_mask):\n    pred_mask = cv2.resize(pred_mask.astype('float32'),(1600, 256))\n    #pred_mask = (pred_mask > .5).astype(int)\n    #pred_mask = remove_small_regions(pred_mask, 0.02 * np.prod(512)) * 255\n    pred_mask = mask2rle(pred_mask)\n    print(len(pred_mask))\n    return pred_mask\n\n# loop over all the test images\nfor f in test_files:\n    # get test tensor, output is in shape: (1, 256, 512, 3)\n    test = get_test_tensor(f, img_h, img_w) \n    # get prediction, output is in shape: (1, 256, 512, 4)\n    pred_masks = model.predict(test) \n   \n    # get a list of masks with shape: 256, 512\n    pred_masks = [pred_masks[0][...,i] for i in range(0,4)]\n    \n    # apply all the processing steps to each of the mask\n    \n    pred_masks = [process_pred_mask(pred_mask) for pred_mask in pred_masks]\n    #break\n    # get our image id\n    id = f.split('/')[-1]\n    # create ImageId_ClassId and get the EncodedPixels for the class ID, and append to our submissions list\n    [submission.append((id+'_%s' % (k+1), pred_mask)) for k, pred_mask in enumerate(pred_masks)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to a csv\nsubmission_df = pd.DataFrame(submission, columns=['ImageId_ClassId', 'EncodedPixels'])\n# check out some predictions and see if RLE looks ok\nsubmission_df[ submission_df['EncodedPixels'] != ''].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# take a look at our submission \nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write it out\nsubmission_df.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}