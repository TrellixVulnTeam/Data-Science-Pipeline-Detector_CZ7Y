{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport gc\n!pip install segmentation-models\n!pip install git+https://github.com/qubvel/segmentation_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\ntrainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\ndata=pd.read_csv(trainCsv)\ndata.ClassId=data.ClassId.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Img_Id = []\ntrain_class_Id = []\nfor i in os.listdir(trainImgPath):\n    for j in range(1,5):\n        train_Img_Id.append(i)\n        train_class_Id.append(j)\ntrain_Imgs = pd.DataFrame({'ImageId':train_Img_Id,'ClassId':train_class_Id})\ntrain_Imgs.head(10)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.merge(train_Imgs,data ,how='outer', on=['ImageId','ClassId']) \ntrain_data = train_data.fillna('') \ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.pivot_table(train_data, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\ntrain_data = train_data.reset_index() # add Index column to one level with classID   \ntrain_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4'] \nhas_defect = []\nstratify = []\nfor index,row in train_data.iterrows():\n    if row.Defect_1 or row.Defect_2 or row.Defect_3 or row.Defect_4: \n        has_defect.append(1)\n    else:\n        has_defect.append(0) \n    if row.Defect_1 != '':\n        stratify.append(1)\n    elif row.Defect_2 != '':\n        stratify.append(2)\n    elif row.Defect_3:\n        stratify.append(3)\n    elif row.Defect_4:\n        stratify.append(4)\n    else:\n        stratify.append(0)\n        \ntrain_data[\"has_defect\"] = has_defect \ntrain_data[\"stratify\"] = stratify \n\ntrain_data.head(5) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WIDTH=288\nHEIGHT=288\nTRAINING_SIZE=7095 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test = train_test_split(train_data, test_size = 0.1, stratify=train_data['stratify'], random_state=42)\nx_train, x_val = train_test_split(x_train, test_size = 0.2, stratify = x_train['stratify'], random_state=42)\nprint(x_train.shape, x_val.shape, x_test.shape) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_classification = x_train[['ImageId','has_defect']]\nx_val_classification = x_val[['ImageId','has_defect']]\nx_test_classification = x_test[['ImageId','has_defect']] \nprint(x_train_classification.shape , x_val_classification.shape,x_test_classification.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator \ntrain_datagen = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_data_generator = train_datagen.flow_from_dataframe(\n        dataframe=x_train_classification.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=\"has_defect\",\n        target_size=(WIDTH,HEIGHT),\n        batch_size=16,\n        class_mode='binary') \n\nvalid_data_generator = test_datagen.flow_from_dataframe(\n        dataframe=x_val_classification.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=\"has_defect\",\n        target_size=(WIDTH,HEIGHT),\n        batch_size=16,\n        class_mode='binary') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\nfrom keras.models import Model, load_model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Model = keras.applications.xception.Xception(include_top = False, input_shape = (HEIGHT,WIDTH,3))\n\nlayer = Classification_Model.output\nlayer = GlobalAveragePooling2D()(layer)\n\nlayer = Dense(1024, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(512, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(64, activation='relu')(layer)\npredictions = Dense(1, activation='sigmoid')(layer)\nmodel = Model(inputs=Classification_Model.input, outputs=predictions)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nTraining = model.fit_generator(train_data_generator, validation_data = valid_data_generator, epochs = 30, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_mask(encoded_pixels):\n    counts=[]\n    mask=np.zeros((256*1600), dtype=np.uint8) #don't change this\n    pre_mask=np.asarray([int(point) for point in encoded_pixels.split()])\n    for index,count in enumerate(pre_mask):\n        if(index%2!=0):\n            counts.append(count)\n    i=0\n    for index,pixel in enumerate(pre_mask):\n        if(index%2==0):\n            if(i==len(counts)):\n                break\n            mask[pixel:pixel+counts[i]]=1\n            i+=1\n    mask=np.reshape(mask,(1600,256)) #don't change this\n    mask=cv2.resize(mask,(HEIGHT,WIDTH)).T\n    return mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_imgs(train_data):\n    list_of_imgs=np.empty(( len(train_data) ,HEIGHT,WIDTH,3), dtype=np.uint8)\n    list_of_masks=np.empty((len(train_data) ,HEIGHT,WIDTH), dtype=np.uint8)\n    i=0\n    j=0\n    for index,row in train_data.iterrows():\n        imgpath = trainImgPath + '/' + row.ImageId\n        rle=row[1]\n        rle=''.join(rle)\n        mask=convert_to_mask(rle)\n        y=np.zeros((WIDTH,HEIGHT))\n        y=mask\n        list_of_masks[i]=y\n        img=cv2.imread(imgpath)\n        img=cv2.resize(img,(HEIGHT,WIDTH))\n        list_of_imgs[i]=img\n        i+=1\n        del y\n        del mask\n        del img\n        gc.collect()\n    return list_of_imgs,list_of_masks\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_defect_1 = x_train[x_train['Defect_1']!=''][['ImageId','Defect_1']]\nval_img_defect_1 =  x_val[x_val['Defect_1']!=''][['ImageId','Defect_1']] \ntest_img_defect_1 =  x_test[x_test['Defect_1']!=''][['ImageId','Defect_1']] \n    \ntrain_img_defect_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr_sgm , y_tr_sgm =  generate_imgs(train_img_defect_1)\nx_val_sgm , y_val_sgm =  generate_imgs(val_img_defect_1) \nprint(x_val_sgm)\nprint(y_val_sgm)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score \n\nnetwork = 'resnet34'\npreprocess = get_preprocessing(network) \n\nmodel = Unet(network, classes=1, activation='sigmoid', encoder_weights='imagenet') \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen_segm = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\ntest_datagen_segm = ImageDataGenerator(rescale=1./255)\n\ntrain_data_generator = train_datagen_segm.flow_from_dataframe(\n        dataframe=train_img_defect_1.astype(str),\n        directory=trainImgPath,\n        x_col=x,\n        y_col=y,\n        target_size=(WIDTH,HEIGHT),\n        batch_size=16,\n        class_mode='binary') \n\nvalid_data_generator = test_datagen_segm.flow_from_dataframe(\n        dataframe=val_img_defect_1.astype(str),\n        directory=trainImgPath,\n        x_col=x_val_sgm,\n        y_col=y_val_sgm,\n        target_size=(WIDTH,HEIGHT),\n        batch_size=16,\n        class_mode='binary') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import segmentation_models as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss=sm.losses.dice_loss,metrics=[dice_coef])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_defect_1 = model.fit_generator(train_data_generator, validation_data = valid_data_generator, epochs = 30, verbose=1 )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape,y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest=train_test_split(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\n \nnetwork = 'resnet34'\nprocess_input = get_preprocessing(network)\nxtrain = process_input(xtrain)\nmodel = Unet(network,input_shape = (WIDTH, HEIGHT, 3),classes=4,activation='softmax')\nmodel.compile('adam', loss='binary_crossentropy',metrics=[dice_coef])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    x=xtrain,\n    y=ytrain,\n    batch_size=16,\n    epochs=50, \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}