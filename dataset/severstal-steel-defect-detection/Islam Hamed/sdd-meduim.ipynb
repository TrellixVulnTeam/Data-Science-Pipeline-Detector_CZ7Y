{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport seaborn as sns\nimport gc\n!pip install segmentation-models\n!pip install git+https://github.com/qubvel/segmentation_models ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"trainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\ntrainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\ndata=pd.read_csv(trainCsv)\ndata.ClassId=data.ClassId.astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Read Image_Ids & ClassId 4 Times for one Image*\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Img_Id = []\ntrain_class_Id = []\nfor i in os.listdir(trainImgPath):\n    for j in range(1,5):\n        train_Img_Id.append(i)\n        train_class_Id.append(j)\ntrain_Imgs = pd.DataFrame(train_Img_Id,columns=['ImageId'])\ntrain_Imgs['ClassId'] = train_class_Id\ntrain_Imgs.head(10)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data Preprocessing Not Cleaned  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.merge(train_Imgs,data ,how='outer', on=['ImageId','ClassId']) \ntrain_data = train_data.fillna('') \ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* *Data Cleaning*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.pivot_table(train_data, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\ntrain_data = train_data.reset_index() # add Index column to one level with classID   \ntrain_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4']\ntrain_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(15) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Multi Defects ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"has_defect = []\nstratify = []\nfor index,row in train_data.iterrows():\n    if row.Defect_1 or row.Defect_2 or row.Defect_3 or row.Defect_4: \n        has_defect.append(1)\n    else:\n        has_defect.append(0)\n        \ntrain_data[\"has_defect\"] = has_defect \n \n \nfor index , row in train_data.iterrows():\n    if row.Defect_1 != '':\n        stratify.append(1)\n    elif row.Defect_2 != '':\n        stratify.append(2)\n    elif row.Defect_3 != '':\n        stratify.append(3)\n    elif row.Defect_4 != '':\n        stratify.append(4)\n    else:\n        stratify.append(0)\n        \n\n        \ntrain_data[\"stratify\"] = stratify   \ntrain_data.head(15)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Train / Test / Validation \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test = train_test_split(train_data, test_size = 0.1, stratify=train_data['stratify'], random_state=42)\nx_train, x_val = train_test_split(x_train, test_size = 0.2, stratify = x_train['stratify'], random_state=42)\nprint(x_train.shape, x_val.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data Analysis & Statisics on Data set \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some Data Analysis & Data Visualization for the Data Set \nnums_def_1 = sum(x_train.Defect_1 != '')\nnums_def_2 = sum(x_train.Defect_2 != '')\nnums_def_3 = sum(x_train.Defect_3 != '')\nnums_def_4 = sum(x_train.Defect_4 != '')\n\nprint ( \"Number of Images In Train Dataset is : \", len(x_train), '\\n' ) \nprint ( \"Number of Images In Defect (1) : \", nums_def_1, '\\n' ) \nprint ( \"Number of Images In Defect (2) : \", nums_def_2, '\\n' ) \nprint ( \"Number of Images In Defect (3) : \", nums_def_3, '\\n' ) \nprint ( \"Number of Images In Defect (4) : \", nums_def_4, '\\n' ) \n\nsum_of_defects = [nums_def_1 ,nums_def_2,nums_def_3,nums_def_4]\nx_axis = ['1' , '2' , '3' , '4']\nfig, ax = plt.subplots()\nsns.barplot(x=x_axis,y=sum_of_defects) \nax.set_title(\"Number of images for each Defect\")\nax.set_xlabel(\"Label\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_defects = 0\none_defect = 0\nmulti_defect = 0\n\nfor index,row in x_train.iterrows():\n    cnt = 0\n    if row.Defect_1:\n        cnt+=1\n    if row.Defect_2:\n        cnt+=1\n    if row.Defect_3:\n        cnt+=1\n    if row.Defect_4:\n        cnt+=1\n        \n    if cnt > 1:\n        multi_defect += 1\n    elif cnt == 0:\n        zero_defects += 1\n    else:\n        one_defect += 1 \n        \n\nprint( zero_defects )\nprint(one_defect )\nprint(multi_defect)     \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_of_defects = [zero_defects ,one_defect,multi_defect]\nx_axis = [ 'No Defects' , '1 label' ,'multi label']\nfig, ax = plt.subplots()\nsns.barplot(x=x_axis,y=num_of_defects) \nax.set_title(\"Number of defects in images..\")\nax.set_xlabel(\"Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_mask(encoded_pixels):\n    counts=[]\n    mask=np.zeros((256*1600), dtype=np.uint8) #don't change this\n    pre_mask=np.asarray([int(point) for point in encoded_pixels.split()])\n    for index,count in enumerate(pre_mask):\n        if(index%2!=0):\n            counts.append(count)\n    i=0\n    for index,pixel in enumerate(pre_mask):\n        if(index%2==0):\n            if(i==len(counts)):\n                break\n            mask[pixel:pixel+counts[i]]=1\n            i+=1\n    mask=np.reshape(mask,(1600,256)) #don't change this\n    mask=cv2.resize(mask,(256,1600)).T\n    return mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data Visualization \n* ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 1: \")\nDefect1 = x_train[x_train.Defect_1 != ''] \ncnt = 0\nfor index ,row in Defect1[::-1].iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_1)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1\n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 2: \")\nDefect2 = x_train[x_train.Defect_2 != '']\n#Defect2 = Defect2[::-1]\ncnt = 0 \nfor index ,row in Defect2.iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_2)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 3: \")\nDefect3 = x_train[x_train.Defect_3 != ''] \ncnt = 0\nfor index ,row in Defect3[::-1].iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_3)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples of Images that have Defect 4: \")\nDefect4 = x_train[x_train.Defect_4 != ''] \ncnt = 0\nfor index ,row in Defect4[::-1].iterrows():\n    if cnt == 5:\n        break\n    fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n    Img = cv2.imread( trainImgPath + row.ImageId )\n    mask = convert_to_mask(row.Defect_4)\n    ax1.imshow(Img)\n    ax1.set_title(i[0])\n    ax2.imshow(mask)\n    cnt+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert EncodedPixels To Mask**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Defect2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WIDTH=512\nHEIGHT=256\nTRAINING_SIZE=7095","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"sample of dataset that have defect_1 : \")\nImg = cv2.imread( trainImgPath + x_train['ImageId'][0] ) \nplt.imshow(Img)\nplt.show() \n\nmask = convert_to_mask(x_train['Defect_1'][0]) \nplt.imshow(mask)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preparation \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50 \nfrom tensorflow.keras.utils import plot_model\nimport keras \nfrom keras import backend as K\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\nfrom keras.models import Model, load_model\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_defected_non_defected = x_train[['ImageId','has_defect']]\nx_val_defected_non_defected = x_val[['ImageId','has_defect']]\nx_test_defected_non_defected = x_test[['ImageId','has_defect']] \nprint(x_train_defected_non_defected.shape , x_val_defected_non_defected.shape,x_test_defected_non_defected.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data Augmentation for Binary Classification Model Defected & Non Defected\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.preprocessing.image import ImageDataGenerator ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_data_generator = train_datagen.flow_from_dataframe(\n        dataframe=x_train_defected_non_defected.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=\"has_defect\",\n        target_size=(HEIGHT,WIDTH),\n        batch_size=16,\n        class_mode='binary') \n\nvalid_data_generator = test_datagen.flow_from_dataframe(\n        dataframe=x_val_defected_non_defected.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=\"has_defect\",\n        target_size=(HEIGHT,WIDTH),\n        batch_size=16,\n        class_mode='binary')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bulid Binary Classification Model \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Model = keras.applications.xception.Xception(include_top = False, input_shape = (HEIGHT,WIDTH,3))\n\nlayer = Classification_Model.output\nlayer = GlobalAveragePooling2D()(layer)\n\nlayer = Dense(1024, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(512, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(64, activation='relu')(layer)\npredictions = Dense(1, activation='sigmoid')(layer)\nmodel = Model(inputs=Classification_Model.input, outputs=predictions)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom datetime import datetime\nfrom tensorflow.python.keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nTraining_Model = model.fit_generator(train_data_generator, validation_data = valid_data_generator, epochs = 30, verbose=1, callbacks = [mc,tensorboard_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Training_Model.save('classification_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train_multi = x_train[['ImageId','has_defect_1','has_defect_2','has_defect_3','has_defect_4']][x_train['has_defect']==1]\nX_val_multi = x_val[['ImageId','has_defect_1','has_defect_2','has_defect_3','has_defect_4']][x_val['has_defect']==1]\nX_test_multi = x_test[['ImageId','has_defect_1','has_defect_2','has_defect_3','has_defect_4']][x_test['has_defect']==1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_DataGenerator_2 = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\n\ntrain_generator = train_DataGenerator_2.flow_from_dataframe(\n        dataframe=X_train_multi.astype(str),\n        directory= trainImgPath,\n        x_col=\"ImageId\",\n        y_col=[\"has_defect_1\",\"has_defect_2\",\"has_defect_3\",\"has_defect_4\"],\n        target_size=(256,512),\n        batch_size=16,\n        class_mode='other')\n\n\ntest_DataGenerator_2 = ImageDataGenerator(rescale=1./255)\nvalidation_generator = test_DataGenerator_2.flow_from_dataframe(\n        dataframe=X_val_multi.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=[\"has_defect_1\",\"has_defect_2\",\"has_defect_3\",\"has_defect_4\"],\n        target_size=(256,512),\n        batch_size=16,\n        class_mode='other')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_DataGenerator_multi_class = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\nmulti_class_train_gen = train_DataGenerator_multi_class.flow_from_dataframe(\n        dataframe= x_multi_class_train.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=['has_defect_1','has_defect_2','has_defect_3','has_defect_4'],\n        target_size=(HEIGHT,WIDTH),\n        batch_size=16,\n        class_mode='other')\n\ntest_DataGenerator_multi = ImageDataGenerator(rescale=1./255)\nmulti_class_val_gen = test_DataGenerator_multi.flow_from_dataframe(\n        dataframe=x_multi_class_val.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=['has_defect_1','has_defect_2','has_defect_3','has_defect_4'],\n        target_size=(HEIGHT,WIDTH),\n        batch_size=16,\n        class_mode='other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmulti_class_model = keras.applications.xception.Xception(include_top = False, input_shape = (256,512,3))\n\n# add a global spatial average pooling layer\nx = multi_class_model.output\nx = GlobalAveragePooling2D()(x)\n\n# let's add fully-connected layers\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\n\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\n\nx = Dense(64, activation='relu')(x)\n\n# and the prediction layer\npredictions = Dense(4, activation='sigmoid')(x)\n\n# this is the model we will train\nmodel = Model(inputs=multi_class_model.input, outputs=predictions)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nhistory = model.fit_generator(train_generator, validation_data = validation_generator, epochs = 15, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image Segmentation\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_1 = x_train[x_train['has_defect_1']==1][['ImageId','Defect_1']]\ntrain_data_2 = x_train[x_train['has_defect_2']==1][['ImageId','Defect_2']]\ntrain_data_3 = x_train[x_train['has_defect_3']==1][['ImageId','Defect_3']]\ntrain_data_4 = x_train[x_train['has_defect_4']==1][['ImageId','Defect_4']]\n\nval_data_1 = x_val[x_val['has_defect_1']==1][['ImageId','Defect_1']]\nval_data_2 = x_val[x_val['has_defect_2']==1][['ImageId','Defect_2']]\nval_data_3 = x_val[x_val['has_defect_3']==1][['ImageId','Defect_3']]\nval_data_4 = x_val[x_val['has_defect_4']==1][['ImageId','Defect_4']]\n\ntest_data_1 = x_test[x_test['has_defect_1']==1][['ImageId','Defect_1']]\ntest_data_2 = x_test[x_test['has_defect_2']==1][['ImageId','Defect_2']]\ntest_data_3 = x_test[x_test['has_defect_3']==1][['ImageId','Defect_3']]\ntest_data_4 = x_test[x_test['has_defect_4']==1][['ImageId','Defect_4']]\n\ntrain_data_1.columns = train_data_2.columns = train_data_3.columns = train_data_4.columns = ['ImageId','EncodedPixels']\nval_data_1.columns = val_data_2.columns = val_data_3.columns = val_data_4.columns = ['ImageId','EncodedPixels']\ntest_data_1.columns = test_data_2.columns = test_data_3.columns = test_data_4.columns = ['ImageId','EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\nfrom keras.models import Model, load_model\nimport tensorflow as tf\nfrom tensorflow.python.keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.metrics import recall_score\nfrom random import random\nfrom random import seed\n\n# https://github.com/qubvel/segmentation_models\nimport segmentation_models \n\nimport segmentation_models as sm\nfrom segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\n\nnetwork = 'resnet34'\nprocess_input = get_preprocessing(network)\nx_train = process_input(x_train)\nmodel = Unet(network,input_shape = (WIDTH, HEIGHT, 3),classes=4,activation='sigmoid')\nmodel.compile('adam', loss='binary_crossentropy',metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall tf-nightly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\nfrom keras.models import Model, load_model\nimport tensorflow as tf\nfrom tensorflow.python.keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint\n \n\n# https://github.com/qubvel/segmentation_models\nimport segmentation_models\nprint(segmentation_models.__version__)\n\nimport segmentation_models as sm\nfrom segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\n\nfrom tensorflow.keras.utils import plot_model\nnetwork = 'resnet34'\npreprocess = get_preprocessing(network) \ntrain_data_1 = preprocess(train_data_1)\n\nmodel = Unet(network ,input_shape = (WIDTH, HEIGHT, 3), classes=1, activation='sigmoid') \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install tensorflow==2.1.0\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tf-nightly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall tf-nightly \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\nfrom lasagne.layers import (InputLayer, ConcatLayer, Pool2DLayer, ReshapeLayer, DimshuffleLayer, NonlinearityLayer,\n                            DropoutLayer, Deconv2DLayer, batch_norm)\ntry:\n    from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\nexcept ImportError:\n    from lasagne.layers import Conv2DLayer as ConvLayer\nimport lasagne\nfrom lasagne.init import HeNormal ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_UNet(n_input_channels=1, BATCH_SIZE=None, num_output_classes=2, pad='same', nonlinearity=lasagne.nonlinearities.elu, input_dim=(None, None), base_n_filters=64, do_dropout=False):\n    net = OrderedDict()\n    net['input'] = InputLayer((BATCH_SIZE, n_input_channels, input_dim[0], input_dim[1]))\n\n    net['contr_1_1'] = batch_norm(ConvLayer(net['input'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['contr_1_2'] = batch_norm(ConvLayer(net['contr_1_1'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['pool1'] = Pool2DLayer(net['contr_1_2'], 2)\n\n    net['contr_2_1'] = batch_norm(ConvLayer(net['pool1'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['contr_2_2'] = batch_norm(ConvLayer(net['contr_2_1'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['pool2'] = Pool2DLayer(net['contr_2_2'], 2)\n\n    net['contr_3_1'] = batch_norm(ConvLayer(net['pool2'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['contr_3_2'] = batch_norm(ConvLayer(net['contr_3_1'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['pool3'] = Pool2DLayer(net['contr_3_2'], 2)\n\n    net['contr_4_1'] = batch_norm(ConvLayer(net['pool3'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['contr_4_2'] = batch_norm(ConvLayer(net['contr_4_1'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    l = net['pool4'] = Pool2DLayer(net['contr_4_2'], 2)\n    \n    # the paper does not really describe where and how dropout is added. Feel free to try more options\n    if do_dropout:\n        l = DropoutLayer(l, p=0.4)\n\n    net['encode_1'] = batch_norm(ConvLayer(l, base_n_filters*16, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['encode_2'] = batch_norm(ConvLayer(net['encode_1'], base_n_filters*16, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['upscale1'] = batch_norm(Deconv2DLayer(net['encode_2'], base_n_filters*16, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n    net['concat1'] = ConcatLayer([net['upscale1'], net['contr_4_2']], cropping=(None, None, \"center\", \"center\"))\n    net['expand_1_1'] = batch_norm(ConvLayer(net['concat1'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['expand_1_2'] = batch_norm(ConvLayer(net['expand_1_1'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n\n    net['upscale2'] = batch_norm(Deconv2DLayer(net['expand_1_2'], base_n_filters*8, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n    net['concat2'] = ConcatLayer([net['upscale2'], net['contr_3_2']], cropping=(None, None, \"center\", \"center\"))\n    net['expand_2_1'] = batch_norm(ConvLayer(net['concat2'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['expand_2_2'] = batch_norm(ConvLayer(net['expand_2_1'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n\n    net['upscale3'] = batch_norm(Deconv2DLayer(net['expand_2_2'], base_n_filters*4, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n    net['concat3'] = ConcatLayer([net['upscale3'], net['contr_2_2']], cropping=(None, None, \"center\", \"center\"))\n    net['expand_3_1'] = batch_norm(ConvLayer(net['concat3'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['expand_3_2'] = batch_norm(ConvLayer(net['expand_3_1'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n\n    net['upscale4'] = batch_norm(Deconv2DLayer(net['expand_3_2'], base_n_filters*2, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n    net['concat4'] = ConcatLayer([net['upscale4'], net['contr_1_2']], cropping=(None, None, \"center\", \"center\"))\n    net['expand_4_1'] = batch_norm(ConvLayer(net['concat4'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['expand_4_2'] = batch_norm(ConvLayer(net['expand_4_1'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n    net['output_segmentation'] = ConvLayer(net['expand_4_2'], num_output_classes, 1, nonlinearity=None)\n    net['dimshuffle'] = DimshuffleLayer(net['output_segmentation'], (1, 0, 2, 3))\n    net['reshapeSeg'] = ReshapeLayer(net['dimshuffle'], (num_output_classes, -1))\n    net['dimshuffle2'] = DimshuffleLayer(net['reshapeSeg'], (1, 0))\n    net['output_flattened'] = NonlinearityLayer(net['dimshuffle2'], nonlinearity=lasagne.nonlinearities.softmax)\n\n    return net","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_UNet(n_input_channels=3,input_dim=(WIDTH, HEIGHT)) \n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}