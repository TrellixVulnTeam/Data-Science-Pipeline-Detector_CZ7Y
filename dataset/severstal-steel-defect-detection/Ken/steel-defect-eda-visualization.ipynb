{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1) Overview \n\n- Identify defects to increase steel production efficiency \n\n- Semantic segmentation problem\n> Examining image at pixel level by assigning each pixel in each image an object class \n\n- Model must produce dense pixel wise predictions\n> Recognize object in image AND delineate boundaries of each object\n\n- 4 classes of defects in one image is possible \n> Identify each type of defect \n\n- An image may appear 4 times in the data if there are 4 defects present \n> 4 defects = 4 separate classes \n\n- Mask = defective portion of image \n> Mask size = defect size\n> binary \n\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\n\n# visualization\nimport matplotlib.pyplot as plt\n\n# plotly offline imports\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\nfrom plotly import subplots\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.graph_objs import *\nfrom plotly.graph_objs.layout import Margin, YAxis, XAxis\ninit_notebook_mode()\n\n# frequent pattern mining\nfrom mlxtend.frequent_patterns import fpgrowth\n\n# path where all the training images are\nimg_path = '../input/train_images/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Load \n\n- Process data \n- Count observations (images)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv('../input/train.csv').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NaN or no mask with -1\ntrain_df = pd.read_csv('../input/train.csv').fillna(-1)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Image id & Class id are 2 separate entities "},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate IDs into 2 columns \n\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0]) # index 0 after jpg_\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1]) # index 1 after jpg_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1) Group EncodedPixels with class_id\n\n- Group format in (x, y)\n>  $x$ = class_id / $y$ = EncodedPixels\n\n- Create dictionary to contain all defects for each individual image "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group class & pixel \ntrain_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], \n                                                                row['EncodedPixels']), axis = 1)\n\n# Dict for all defect labels \ngrouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_EncodedPixels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3) Describe image data & defects "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of unique images: %s' % len(train_df['ImageId'].unique()))\n\nprint('Unique images with at least one defect: %s' %len(train_df[train_df['EncodedPixels'] != -1]['ImageId'].unique()))\n\nprint('Total instances of defects or total defects for all images: %s' % len(train_df[train_df['EncodedPixels'] != -1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### % of defective units?"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_images = len(train_df['ImageId'].unique())\ndefective = len(train_df[train_df['EncodedPixels'] != -1]['ImageId'].unique())\nprint('defective proportion of images: %s' % (defective / total_images))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### >50% defective units "},{"metadata":{},"cell_type":"markdown","source":"# 3) Visualizing \n\n- decode encoded masks\n\n- mark defects on images "},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 images with 2 defect classes \nxsamples = []\n\nfor i in grouped_EncodedPixels.iteritems():\n    if(len([i[1] for x in i[1] if x[1] != -1]) == 2) and (len(xsamples) < 10):\n        xsamples.append(i[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decode mask\n    # rle-to-mask-converter \ndef rle_to_mask(rle_string, height, width):\n    '''\n    convert RLE(run length encoding) string to numpy array\n    \n    Parameters:\n    rle_string (str): string of rle encoded mask\n    height (int): mask height\n    width (int): mask width\n    \n    Return:\n    numpy.array: numpy array of the mask\n    '''\n    \n    rows, cols = height, width\n    \n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(rows*cols, dtype=np.uint8)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize steel image with 4 defect classes in separate cols\ndef viz_two_class_from_path(img_path, img_id, encoded_masks):\n    '''\n    visualize an image with two types of defects by plotting them on two columns\n    with the defect overlayed on top of the original image.\n\n    Parameters: \n    img_path (str): path of images\n    img_id (str): image id or filename of the path\n    encoded_masks (list): a list of strings of encoded masks \n    \n    Returns: \n    matplotlib image plot in columns for two classes iwth defect\n    '''\n    \n    img = cv2.imread(os.path.join(img_path, img_id))\n    fig, ax = plt.subplots(nrows = 1, ncols = 2, \n                           sharey = True, figsize = (20,10))\n    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n    axid = 0\n    for idx, encoded_mask in enumerate(encoded_masks):\n        class_id = idx + 1\n        if encoded_mask == -1:\n            pass\n        else:\n            mask_decoded = rle_to_mask(encoded_mask, 256, 1600)\n            ax[axid].get_xaxis().set_ticks([])\n            ax[axid].get_yaxis().set_ticks([])\n            ax[axid].text(0.25, 0.25, 'Image Id: %s - Class Id: %s' % (img_id, class_id), fontsize=12)\n            ax[axid].imshow(img)\n            ax[axid].imshow(mask_decoded, alpha = 0.15, cmap = cmaps[idx])\n            axid += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize images grabbed with mask\nfor xsample in xsamples:\n    img_id = xsamples\n    mask_1, mask_2, mask_3, mask_4 = grouped_EncodedPixels[xsample]\n    masks = [mask_1[1], mask_2[1], mask_3[1], mask_4[1]]\n    viz_two_class_from_path(img_path, xsample, masks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### At least 2 defects present in each image, 1 left, 1 right \n\n#### Different classes of Mask (defects) do not overlap \n\n"},{"metadata":{},"cell_type":"markdown","source":"## 3) Four defect classes \n\n- visualize 4 classes in separate cols\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize image with 4 defect classes in seperate columns\ndef viz_one_class_from_path(img_path, img_id, mask, class_id, text=None):\n    '''\n    visualize an image with two types of defects by plotting them on two columns\n    with the defect overlayed on top of the original image.\n\n    Parameters: \n    img_path (str): path of images\n    img_id (str): image id or filename of the path\n    encoded_mask (str): RLE mask\n    class_id (str): class id of the defect\n    \n    Returns: \n    matplotlib image plot in columns for two classes with defect\n    '''\n    img = cv2.imread(os.path.join(img_path, img_id))\n    mask_decoded = rle_to_mask(mask, 256, 1600)\n    fig, ax = plt.subplots(figsize = (20,10))\n    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"] # colors mapped in numerical order to classes in array  \n    ax.get_xaxis().set_ticks([])\n    ax.get_yaxis().set_ticks([])\n    if text: \n        ax.text(0.25, 0.25, text, fontsize=12)\n    ax.imshow(img)\n    ax.imshow(mask_decoded, alpha = 0.15, cmap = cmaps[int(class_id)-1])\n\ndef viz_per_class(train_df, class_id, sample_size = 5):\n    class_samples = train_df[(train_df['ClassId'] == class_id) & (train_df['EncodedPixels']!=-1)].sample(sample_size)\n    class_img_ids = class_samples['ImageId'].values\n    class_encoded_masks = class_samples['EncodedPixels'].values\n    \n    for img_id, mask in zip(class_img_ids, class_encoded_masks):\n        viz_one_class_from_path(img_path, img_id, mask, class_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class 1 \nviz_per_class(train_df, '1', 1) # class 1, 1 image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class 2\nviz_per_class(train_df, '2', 1) # class 2, 1 image ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"viz_per_class(train_df, '3', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"viz_per_class(train_df, '4', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Defect Frequency\n\n- images with labels (defective)\n- images without labels (non defective)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sum of pixels for the mask for each class id\n\ntrain_df['mask_pixel_sum'] = train_df.apply(lambda x: rle_to_mask(x['EncodedPixels'],\n                                                                  width = 1500,\n                                                                  height = 300).sum(),\n                                           axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Num of images with no label (defect masks)\n\n# -1 = defective \nannotation_count = grouped_EncodedPixels.apply(lambda x: 1 if len([1 for y in x if y[1] != -1]) > 0 else 0).value_counts()\n\nannotation_count_labels = ['No Label' if x == 0 else 'Label' for x in annotation_count.index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Num of defects per image \n\ndefect_count_df = grouped_EncodedPixels.apply(lambda x: len([1 for y in x if y[1] != -1]))\n\ndefect_count_per_image = defect_count_df.value_counts()\n\ndefect_count_labels = defect_count_per_image.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viz \n\ntrace0 = Bar(x = annotation_count_labels, \n             y = annotation_count, \n             name = 'Labelled v. Not Labelled')\n\ntrace1 = Bar(x = defect_count_labels, y = defect_count_per_image, \n             name = 'Defects per image')\n\nfig = subplots.make_subplots(rows = 1, cols = 2)\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\n\nfig['layout'].update(height = 500, width = 1000, \n                     title = 'Defect labels & defect frequency per image')\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1) Bar observations\n\n- More than 1 type of defect is identified in 1 image frequently \n- Majority only have 1\n- Many don't have defects \n- Many images with no labels or defect masks \n> Possible missing labels \n>- Over 50% of units have defects "},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_10_samples = defect_count_df[defect_count_df == 0].sample(10).index\n\nfor samp in rand_10_samples:\n    viz_one_class_from_path(img_path, samp, -1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5) Defect size per class \n\n- Count num of pixels in mask to approximate defect size \n- Check inter-class variation of defect size\n\n>- Count masks \n>- Sum pixels"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_ids = ['1', '2', '3', '4']\n\nmask_count_per_class = [train_df[(train_df['ClassId'] == class_id) &\n                                 (train_df['mask_pixel_sum']!= 0)]['mask_pixel_sum'].count() for class_id in class_ids]\n\npixel_sum_per_class = [train_df[(train_df['ClassId'] == class_id) &\n                                (train_df['mask_pixel_sum']!= 0)]['mask_pixel_sum'].sum() for class_id in class_ids]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = subplots.make_subplots(rows = 1, cols = 2,\n                             specs = [[{'type':'domain'}, \n                                      {'type':'domain'}]])\n\nfig.add_trace(Pie(labels = class_ids, \n                  values = mask_count_per_class, \n                  name = 'Freq'), 1, 1)\n\nfig.add_trace(Pie(labels = class_ids,\n                  values = pixel_sum_per_class,\n                  name = 'Area'), 1, 2)\n\nfig.update_traces(hole = .4, hoverinfo = 'label + percent + name')\n\nfig.update_layout(title_text = 'Steel Defect Mask & Pixel Count',\n                  annotations = [dict(text = 'Freq', \n                                      x = 0.18, y = 0.5, \n                                      font_size = 20, \n                                      showarrow = False), \n                                 dict(text = 'Area', \n                                      x = 0.8, y = 0.5,\n                                      font_size = 20,\n                                      showarrow = False)])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Mask = frequency of class \n\n#### Pixel = area of class "},{"metadata":{},"cell_type":"markdown","source":"### 5.1) Pie observations\n\n- Severe class imbalance in dataset\n- Highest mask count = 3 \n>- 80.3% of defects are class 3 \n\n- Mask 4 at 16.8 Freq\n>- total defect area of 16.8$\n\n- Class 1 & 2 may be difficult to predict given small sample size "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist & boxplot of mask pixels per class Id\n\nfig = px.histogram(train_df[train_df['mask_pixel_sum']!=0][['ClassId', 'mask_pixel_sum']],\n                   x = 'mask_pixel_sum', y = 'ClassId', \n                   color = 'ClassId', marginal = 'box')\n\nfig['layout'].update(title = 'Histogram & boxplot of mask pixels per class')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hist & box observations \n\n- Class 4 is larger in area size than 3 \n- Class 3 has many outliers\n-> Outlier values can be larger than class 4 values \n\n"},{"metadata":{},"cell_type":"markdown","source":"# 6) Segment analysis \n\n- Multiple regions on images are identical defects \n- Examine behaviour of segments for different classes "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build function to convert encoded mask to mask \n    # AND count number of segments per defect\n    \ndef count_segment(mask):\n    '''\n    Given a mask, count number of regions \n        \n    Parameters:\n    mask (numpy.array): numpy array of the mask\n    \n    Returns:\n    int: number of segments\n    '''\n    \n    if mask.sum() == 0:\n        return 0 \n    else:\n        # opencv & threshold mechanism to calc contours\n        _, threshold = cv2.threshold(mask, 240, 255, \n                                     cv2.THRESH_BINARY)\n        _, contours = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        \n        # segment count\n        for c in contours:\n            segments_count = len(c)\n            \n        return segments_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count_segment to convert encoded mask to mask & count segments per defect\ntrain_df['segments'] = train_df.apply(lambda r: count_segment(rle_to_mask(r['EncodedPixels'],\n                                                                           height = 256,\n                                                                           width = 1600)),\n                                      axis = 1)\n\ntrain_df['avg_mask_per_seg'] = (train_df['mask_pixel_sum'] / train_df['segments']).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if function works \n\nfor segments in range(0,6):\n    samp = train_df[train_df['segments'] == segments].sample(1)\n    encoded_pixels = samp['EncodedPixels'].values[0]\n    image_id = samp['ImageId'].values[0]\n    class_id = samp['ClassId'].values[0]\n    segments = samp['segments'].values[0]\n    viz_one_class_from_path(img_path, image_id, \n                            encoded_pixels, class_id, \n                            text='Number of Segments: %s' % segments)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot \n\nfig = px.scatter(train_df[train_df['mask_pixel_sum']!=0], \n                 x = 'mask_pixel_sum', y = 'segments', \n                 color = 'ClassId',\n                 size = 'avg_mask_per_seg', \n                 hover_data = ['avg_mask_per_seg'])\n\nfig = px.scatter(train_df[train_df['mask_pixel_sum']!=0], \n                 x = 'mask_pixel_sum',\n                 y = 'segments', \n                 color = 'ClassId',\n                 marginal_y = 'rug', marginal_x = 'histogram')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"segment_labels_per_class = []\nsegment_values_per_class = []\n\nfor class_id in ['1','2','3','4']:\n    segments_value_count = train_df[(train_df['mask_pixel_sum']!=0) & (train_df['ClassId'] == class_id)]['segments'].value_counts()\n    segments_value_count = segments_value_count.reset_index()\n    segments_value_count.columns = ['segments','segments_count']\n    segments_5_10_count = segments_value_count[(segments_value_count['segments'] >= 5) & \n                                               (segments_value_count['segments'] <= 10)]['segments_count'].sum()\n    segments_10_plus_count = segments_value_count[segments_value_count['segments'] >10]['segments_count'].sum()\n    segment_keys = list(segments_value_count[segments_value_count['segments'] < 5]['segments'].values)\n    segment_keys.append('5 - 10')\n    segment_keys.append('10 +')\n    segments_values = list(segments_value_count[segments_value_count['segments'] < 5]['segments_count'].values)\n    segments_values.append(segments_5_10_count)\n    segments_values.append(segments_10_plus_count)\n    segment_labels_per_class.append(segment_keys)\n    segment_values_per_class.append(segments_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows = 1, cols = 4, \n                             specs = [[{'type':'domain'}, {'type':'domain'},\n                                       {'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=segment_labels_per_class[0], \n                  values = segment_values_per_class[0], name=\"Class Id 1\"), 1, 1)\n\nfig.add_trace(Pie(labels=segment_labels_per_class[1], \n                  values = segment_values_per_class[1], name=\"Class Id 2\"), 1, 2)\n\nfig.add_trace(Pie(labels=segment_labels_per_class[2], \n                  values = segment_values_per_class[2], name=\"Class Id 3\"), 1, 3)\n\nfig.add_trace(Pie(labels=segment_labels_per_class[3], \n                  values = segment_values_per_class[3], name=\"Class Id 4\"), 1, 4)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Segments Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='1', x=0.1, y = 0.5, \n                      font_size = 20, showarrow = False),\n                 dict(text='2', x = 0.37, y = 0.5, \n                      font_size = 20, showarrow = False),\n                 dict(text='3', x = 0.63, y = 0.5,\n                      font_size=20, showarrow=False),\n                 dict(text='4', x = 0.91, y = 0.5, font_size=20, showarrow=False)])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows=1, cols=4, specs=[[{'type':'domain'}, {'type':'domain'},{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=segment_labels_per_class[0], values=segment_values_per_class[0], name=\"Class Id 1\"), 1, 1)\nfig.add_trace(Pie(labels=segment_labels_per_class[1], values=segment_values_per_class[1], name=\"Class Id 2\"), 1, 2)\nfig.add_trace(Pie(labels=segment_labels_per_class[2], values=segment_values_per_class[2], name=\"Class Id 3\"), 1, 3)\nfig.add_trace(Pie(labels=segment_labels_per_class[3], values=segment_values_per_class[3], name=\"Class Id 4\"), 1, 4)\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Segments Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='1', x=0.1, y=0.5, font_size=20, showarrow=False),\n                 dict(text='2', x=0.37, y=0.5, font_size=20, showarrow=False),\n                 dict(text='3', x=0.63, y=0.5, font_size=20, showarrow=False),\n                 dict(text='4', x=0.91, y=0.5, font_size=20, showarrow=False)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Segments of defects per class \n\n- legend indicates number of defects attributed to class "},{"metadata":{},"cell_type":"markdown","source":"# 7) Frequent Pattern algorithm\n\n- Frequency of different defects occuring simultaneously  \n\n- Investigate which classes occur in pairs "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Series with defect classes\n\nclass_per_image = grouped_EncodedPixels.apply(lambda encoded_list: [x[0] for x in encoded_list if x[1] !=-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of class count \n\nclass_per_image_list = []\nfor r in class_per_image.iteritems():\n    class_count = {'1':0, '2':0, '3':0, '4':0}\n    for image_class in r[1]:\n        class_count[image_class] = 1\n    class_per_image_list.append(class_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency Pattern calc. for all images\nclass_per_image_df = pd.DataFrame(class_per_image_list)\n\nclass_fp_df = fpgrowth(class_per_image_df, \n                       use_colnames = True, \n                       min_support = 0.001)\n\nclass_fp_df = class_fp_df.sort_values(by = ['support'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Images with at least 1 mask \n\nclass_per_defect_image_df = class_per_image_df[(class_per_image_df.T != 0).any()]\n\nclass_fp_defect_df = fpgrowth(class_per_defect_image_df, \n                              use_colnames = True,\n                             min_support = 0.001)\n\nclass_fp_defect_df = class_fp_defect_df.sort_values(by = ['support'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_h(x, y, title, x_label, y_label):\n    y_pos = np.arange(len(y))\n    plt.barh(y_pos, x)\n    plt.yticks(y_pos, y)\n    plt.title(title)\n    plt.ylabel(y_label)\n    plt.xlabel(x_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\n# plot for FP for all images\nplt.subplot(1,2,1)\ncombinations = [', '.join(x) for x in class_fp_df['itemsets'].values]\nsupport = class_fp_df['support'].values\nbar_h(support, combinations, 'Defect Classes Appearing Frequently - All Samples', 'Defect Classes', 'Support')\n\n# plot for FP for images with at least one fault\nplt.subplot(1,2,2)\ncombinations = [', '.join(x) for x in class_fp_defect_df['itemsets'].values]\nsupport = class_fp_defect_df['support'].values\nbar_h(support, combinations, 'Defect Classes Appearing Frequently - Defective Samples Only', 'Defect Classes', 'Support')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.1) Bar_h observation\n\n- Single defects of 3, 1, or 4 are most frequent\n\n- Combination of 3 and 4 is more frequent than 3 and 1 \n\n- 2 rarely appears \n>- Combined 3 and 4 more frequent than 2 alone "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}