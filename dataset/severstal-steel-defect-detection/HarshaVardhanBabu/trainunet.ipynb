{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport zipfile\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom fastai.vision import *\nimport cv2\nimport fastai\nimport torch\nfrom matplotlib import pyplot as plt\nfrom pathlib import Path\nimport matplotlib\nimport shutil\nfrom tqdm import tqdm_notebook as tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import fastai\n\ndef transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n    if not tfms: tfms=(None,None)\n    assert is_listy(tfms) and len(tfms) == 2\n    self.train.transform(tfms[0], **kwargs)\n    self.valid.transform(tfms[1], **kwargs)\n    kwargs['tfm_y'] = False # Test data has no labels\n    if self.test: self.test.transform(tfms[1], **kwargs)\n    return self\n\nfastai.data_block.ItemLists.transform = transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice(input:Tensor, targs:Tensor, eps:float=1e-8)->Rank0Tensor:\n    input = input.clone()\n    targs = targs.clone()\n    n = targs.shape[0]\n    input = torch.softmax(input, dim=1).argmax(dim=1)\n    input = input.view(n, -1)\n    targs = targs.view(n, -1)\n    input[input == 0] = -999\n    intersect = (input == targs).sum().float()\n    union = input[input > 0].sum().float() + targs[targs > 0].sum().float()\n    del input, targs\n    gc.collect()\n    return ((2.0 * intersect + eps) / (union + eps)).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_path = \"/tmp/.cache/torch/checkpoints/\"\nif(not os.path.exists(resnet_path)):\n    os.makedirs(resnet_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! cp ../input/resnet18/resnet18.pth /tmp/.cache/torch/checkpoints/resnet18-5c106cde.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/severstal-steel-defect-detection\"))\nprint(os.listdir(\"../input/masksv1\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_folder = Path(\"../input/severstal-steel-defect-detection\")\nmasks_folder = Path(\"../input/masksv1/masks\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \ndef rle2mask(mask_rle,shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\ndef multiplerle2mask(mask_rle_row,shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    if(mask_rle_row['has_rle'] > 0):\n        for i in mask_rle_row.index[:-1]:\n            class_id = int(i)\n            if(not pd.isnull(mask_rle_row[i])):\n                s = mask_rle_row[i].split()\n                starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n                starts -= 1\n                ends = starts + lengths\n                for lo, hi in zip(starts, ends):\n                    img[lo:hi] = class_id\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_masks(x):\n#     print(x,x[0])\n#     print(pd.isnull(x[0]))\n    count = 0\n    if not pd.isnull(x[0]) : count = count + 1\n    if not pd.isnull(x[1]) : count = count + 1\n    if not pd.isnull(x[2]) : count = count + 1\n    if not pd.isnull(x[3]) : count = count + 1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(input_folder/\"train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split(\"_\")[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ImageName'] = train_df['ImageId_ClassId'].apply(lambda x: x.split(\"_\")[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pivot = train_df.pivot(index='ImageName',columns='ClassId',values = 'EncodedPixels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pivot['has_rle'] = train_df_pivot.apply(lambda row: count_masks(row), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pivot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pivot.has_rle.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pivot[train_df_pivot['has_rle']==1].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_entry = train_df_pivot.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = open_image(str(input_folder/\"train_images\"/test_entry.name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_name(name):\n    name = Path(name)\n    return Path(name.stem+\"_mask.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masks_folder/mask_name(test_entry.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = open_mask(masks_folder/mask_name(test_entry.name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask.data.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask2rle(mask.data.numpy()) == test_entry['1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask_paths = Path(\"./train_masks\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask_paths/mask_name(train_df_pivot.iloc[0].name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# os.makedirs(mask_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# z = zipfile.ZipFile(\"masks.zip\",\"w\",zipfile.ZIP_DEFLATED)\n# for name,row in tqdm(train_df_pivot.iterrows()):\n#     temp_mask = multiplerle2mask(row)\n#     mask_file_name = mask_name(name)\n#     matplotlib.image.imsave(mask_file_name, temp_mask)\n#     z.write(mask_file_name)\n#     os.remove(mask_file_name)\n# z.printdir()\n# z.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shutil.make_archive(\"masks.zip\", 'zip', \"train_masks\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"masks.zip\"> Masks </a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_y_fn = lambda x: masks_folder/f'{x.stem}_mask.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Setting div=True in open_mask\n# class SegmentationLabelList(SegmentationLabelList):\n#     def open(self, fn): return open_mask(fn, div=True)\n    \n# class SegmentationItemList(SegmentationItemList):\n#     _label_cls = SegmentationLabelList\n\n# # Setting transformations on masks to False on test set\n# def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n#     if not tfms: tfms=(None,None)\n#     assert is_listy(tfms) and len(tfms) == 2\n#     self.train.transform(tfms[0], **kwargs)\n#     self.valid.transform(tfms[1], **kwargs)\n#     kwargs['tfm_y'] = False # Test data has no labels\n#     if self.test: self.test.transform(tfms[1], **kwargs)\n#     return self\n# fastai.data_block.ItemLists.transform = transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (SegmentationItemList.from_folder(input_folder/\"train_images\")\n        .split_by_rand_pct()\n        .label_from_func(get_y_fn, classes=['0','1','2','3','4'])\n        .transform(get_transforms(flip_vert=True), tfm_y=True, size=128)\n        .databunch(bs=32, path=\"/kaggle/working\"))\n#         .normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = (SegmentationItemList.from_folder(input_folder/\"train_images\")\n#         #Where to find the data? -> in path_img and its subfolders\n#         .split_by_rand_pct()\n#         #How to split in train/valid? -> randomly with the default 20% in valid\n#         .label_from_func(get_y_fn, classes=['0','1','2','3','4'])\n#         #How to label? -> use the label function on the file name of the data\n#         .transform(None, tfm_y=True, size=256)\n#         # Adding the test folder\n# #         .add_test_folder(input_folder/\"test_images\")\n#         #Data augmentation? -> use tfms with a size of 128, also transform the label images\n#         .databunch(bs=32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(7,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_im = data.train_ds[0][0]\nmask = data.train_ds[0][1]\nact_mask = open_mask(get_y_fn(data.train_ds.items[0]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# act_mask.data.unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask.data.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"open_image(data.train_ds.items[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"act_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# res_im.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = unet_learner(data, models.resnet18,path=\"/kaggle/working\",metrics=[dice])\nlearn.fit_one_cycle(10,1e-3)\nlearn.save('mini_train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,slice(3e-5))\nlearn.save('mini_train_unfreeeze')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def no_tfms(self, x,**kwargs): return None\n# EmptyLabel.apply_tfms = no_tfms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.data.add_test((input_folder/\"test_images\").ls(),label=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.data.test_ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions for test set\n# preds, _ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.unique(preds.numpy(),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ys.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.unique(ys.numpy(),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.imshow(ys[100][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.imshow(preds[120][3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# open_image(data.valid_ds.items[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# open_mask(get_y_fn(data.valid_ds.items[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_images = get_image_files(input_folder/\"test_images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_images = get_image_files(input_folder/\"train_images\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}