{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install segmentation-models-pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T09:42:20.423854Z","iopub.execute_input":"2022-04-04T09:42:20.424698Z","iopub.status.idle":"2022-04-04T09:42:36.971149Z","shell.execute_reply.started":"2022-04-04T09:42:20.424575Z","shell.execute_reply":"2022-04-04T09:42:36.970131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install albumentations==0.5.2","metadata":{"execution":{"iopub.status.busy":"2022-04-04T09:42:36.974393Z","iopub.execute_input":"2022-04-04T09:42:36.974718Z","iopub.status.idle":"2022-04-04T09:42:46.925074Z","shell.execute_reply.started":"2022-04-04T09:42:36.974679Z","shell.execute_reply":"2022-04-04T09:42:46.923894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os     # 文件操作API\nimport cv2    # opencvAPI\nimport pdb    # 程序调试API\nimport time   # 时间API\nimport warnings  # 警告API\nimport random    # 随机数生成API\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm # 进度条\nfrom sklearn.model_selection import train_test_split # 将数据集分成训练集和测试集的API\nimport torch\nimport torch.nn as nn                  #  神经网络包\nfrom torch.nn import functional as F   #  神经网络的函数\nimport torch.optim as optim            #  优化器\n\n#  设置 torch.backends.cudnn.benchmark=True 将会让程序在开始时花费一点额外时间，\n#  为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速\nimport torch.backends.cudnn as cudnn\n# 导入数据集相关的模块Dataset是导入外部数据集时使用的API，sampler用来对数据进行采样\nfrom torch.utils.data import DataLoader, Dataset, sampler\n# 画图API\nfrom matplotlib import pyplot as plt\n# albumentations 是数据增强的API\n# HorizontalFlip 围绕Y轴水平翻转\n# VerticalFlip 围绕X轴垂直翻转\n# ShiftScaleRotate 随机应用仿射变换：平移，缩放和旋转\nfrom albumentations import HorizontalFlip, VerticalFlip, ShiftScaleRotate\n# 归一化，图片裁剪，组合器，高斯噪声\nfrom albumentations import Normalize, Resize, Compose, GaussNoise\n# 将图像数据从pillow转换到tensor模式\nfrom albumentations.pytorch import ToTensor\n# 图像分割的模型API\nimport segmentation_models_pytorch as smp\n# 忽略警告\nwarnings.filterwarnings(\"ignore\")\n\n\n\n# 以下的操作都是保证实验结果具有可以复现性\nseed = 69\n# 将随机数种子锚定为69，设置随机数种子可以使每一次生成随机数据的时候结果相同\nrandom.seed(seed)\n# 主要是为了禁止hash随机化，使得实验可复现\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\n# 将np随机数种子锚定为69\nnp.random.seed(seed)\n# 将GPU的随机数种子锚定为69\ntorch.cuda.manual_seed(seed)\n# 每次返回的卷积算法是确定的，使cuda保证每次结果一样，使得实验可复现，也相当于锚定\ntorch.backends.cudnn.deterministic = True\n# 定义图片的尺寸\nSIZE = (256, 1600)\n\n# 定义数据的路径\n# 提交模板\nsample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\n# 训练集标签\ntrain_df_path = '../input/severstal-steel-defect-detection/train.csv'\n# 原文件夹\ndata_folder = '../input/severstal-steel-defect-detection/'\n# 训练集图片\ntrain_data_folder = '../input/severstal-steel-defect-detection/train_images/'\n# 测试集图片\ntest_data_folder = '../input/severstal-steel-defect-detection/test_images/'\n# 读取csv文件成pandas.df的格式\ntrain_df = pd.read_csv(train_df_path)\n\n# RLE to Mask\n# RLE转化成Mask\ndef rle2mask(rle, shape):\n    # 获取出shape的宽和高\n    height, width = shape[0], shape[1]\n    # 创建出一个一维全0的np数组，数据个数是width*height，其中的数据类型是uint8型\n    mask = np.zeros(width * height, dtype=np.uint8)\n\n    # if rle is not np.nan:\n    if not isinstance(rle, float):\n        # 将str类型的rle中的字符串按照空格强行分开，返回一个字符串列表，用lable接受\n        label = rle.split()\n\n        # [m::n] #从a[m]开始，每跳 n 个取一个\n        # map(int,字符串数组)是对字符串数组的每个字符串转化成int型，也就是整体生成一个int型的列表\n        # 分别确定出游程编码的位置和长度，并且保存在int列表里\n        positions = map(int, label[0::2])\n        length = map(int, label[1::2])\n\n        '''\n        >>> a = [1,2,3]\n        >>> b = [4,5,6]\n        >>> c = [4,5,6,7,8]\n        >>> zipped = zip(a,b)     # 打包为元组的列表\n        [(1, 4), (2, 5), (3, 6)]\n        '''\n\n        # zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表\n        for pos, le in zip(positions, length):\n            # mask中对应的值变为1，由此实现了rle向mask的转换\n            mask[pos:(pos + le)] = 1\n\n    '''\n    a = np.array([1,2,3,4,5,6])\n    a\n    array([1, 2, 3, 4, 5, 6])\n\n    a.reshape(3,2)\n    array([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n    a.reshape(3,2, order='F')\n    array([[1, 4],\n       [2, 5],\n       [3, 6]])\n\n    '''\n    # 将一维数组转换成二维的，形成二维mask数组,order='F'是将数组进行竖着排列的\n    # 为何要进行转置？因为rle的编码流程是：从上到下（越界则从左到右）\n    return mask.reshape(shape[0], shape[1], order='F')\n\n\n# Mask转化成RLE\ndef mask2rle(mask):\n    # 将数组变成一维的(先进行.T转置，再进行压缩一维的处理)\n    # 为何要进行转置？因为rle的编码流程是：从上到下（越界则从左到右）\n    mask = mask.T.flatten()\n    # 将数组进行复制\n    pixels = np.concatenate([mask])\n\n    \"\"\"\n    p = np.concatenate([[1,2,3,4,5]])\n    p\n    array([1, 2, 3, 4, 5])\n\n    p[:-1]\n    array([1, 2, 3, 4])\n\n    p[1:]\n    array([2, 3, 4, 5])\n\n    runs = np.where(p[1:] != p[:-1])\n    print(runs)\n    type(runs)\n    (array([0, 1, 2, 3, 4], dtype=int64),)\n    tuple\n\n    runs = np.where(p[1:] != p[:-1])[0]\n    print(runs)\n    type(runs)\n    [0 1 2 3 4]\n    numpy.ndarray\n    \"\"\"\n    # np.where(条件)，若条件满足，返回索引值,但是返回的是一个元组(很坑)\n    # 必须通过np.where(条件)[0]来将返回的值变成一个np数组类别\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    # 将runs中的值写入到字符串中，每个元素之间用空格隔开\n    return ' '.join(str(x) for x in runs)\n\n\n# Mask生成函数(参数分别为：竖直方向上的索引，csv文件的的df，以及图片的尺寸)\ndef make_mask(row_id, df, shape):\n    # 将row_id一行的name给提取出来，保存fname中\n    fname = df.iloc[row_id].name\n    # 将row_id一行的所有标签给提取出来，保存labels中\n    labels = df.iloc[row_id][:4]\n    # 初始化定义对应高和宽的全0二维数组\n    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n\n    for idx, label in enumerate(labels.values):\n        # 给mask特征人工增加两个维度，因为在torch中的数据是(batch_size,通道数,宽,高)的格式\n        masks[:, :, idx] = mask = rle2mask(label, shape)\n    return fname, masks # 返回名称和masks\n\n\n# 图片的处理器模块\ndef get_transforms(phase, mean, std):\n    # 定义一个列表存放对数据进行处理的子处理器\n    list_transforms = []\n    # 就调用albumentations中的一些方法，并且传入一些参数，使之能对图片进行处理\n    if phase == 'train':\n        # 如果是训练集，就以0.5的比例进行水平和竖直翻转\n        list_transforms.extend([HorizontalFlip(p=0.5), VerticalFlip(p=0.5)])\n    # 同样是albumentations中的一些方法，对图片进行归一化(传入参数)和tensor化处理\n    list_transforms.extend([Normalize(mean=mean, std=std, p=1),ToTensor()])\n    # 将子处理器进行组合，形成一个大处理器，并且将大处理器当作该函数的返回值\n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\n# 将dataset类进行重写构成数据集生成器\nclass SteelDataset(Dataset):\n    def __init__(self, df, data_folder, mean, std, phase):\n        self.df = df  # 读取csv文件后生成的df\n        self.root = data_folder  # 数据所在的文件夹路径\n        self.mean = mean  # 平均值\n        self.std = std    # 标准差\n        self.phase = phase  # 训练集和测试集的标志\n        self.transforms = get_transforms(phase, mean, std)  # 将均值和标准差传到图片处理器中\n        self.fnames = self.df.index.tolist()  # 将df对象的索引变成一个列表来存放\n        self.shape = SIZE  # 图片的尺寸\n\n    # 定义该类的__getitem__函数(根据索引来返回处理后的数据)\n    def __getitem__(self, idx):\n        # 用两个参数来保存make_mask生成的名称和masks标签\n        image_id, mask = make_mask(idx, self.df, self.shape)\n        # 根据该图片的具体名称来定位图片路径\n        image_path = os.path.join(self.root, 'train_images',  image_id)\n        # 提取出该图片的BGR张量矩阵\n        img = cv2.imread(image_path)\n        # 用处理器对tensor图片和masks进行处理\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']  # img来获取处理好的图片\n        mask = augmented['mask']  # mask来获取处理好的mask\n        # 将图片从BGR变成RGB格式\n        mask = mask[0].permute(2, 0, 1)\n        # 将处理好的数据进行返回\n        return img, mask\n\n    # 返回df对象的长度\n    def __len__(self):\n        return len(self.fnames)\n\n\n# 定义数据加载器\ndef Data_Provider(data_folder, df_path, phase, mean=None, std=None, batch_size=4, num_workers=2):\n    df = pd.read_csv(df_path)  # 根据路径创建csv文件的df对象\n    # 将df对象ClassId列的数都变为int类型\n    df['ClassId'] = df['ClassId'].astype(int)\n\n    df = df.pivot(index='ImageId', columns='ClassId', values='EncodedPixels')\n    df['defects'] = df.count(axis=1)\n    # 将数据集的标签分为训练标签和测试标签\n    train, valid = train_test_split(df, test_size=0.2, stratify=df['defects'])\n    # 如果标签是train就用train更新df,否则就用valid更新df\n    df = train if phase == 'train' else valid\n    # 生成数据集\n    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n    # 数据加载器\n    dataloader = DataLoader(\n        image_dataset,   # 数据集为刚刚生成的image_dataset\n        batch_size=batch_size,\n        num_workers=num_workers,  # 并行数\n        pin_memory=True,          # 利用锁页内存，加快GPU的传输速度(如果PC的RAM过小就不能用了)\n        shuffle=True)             # 打乱数据集\n    # 将数据加载器返回\n    return dataloader\n\n\n# Dice分数计算函数(评估指标)\ndef dice_metric(probability, truth, threshold=0.5, reduction='none'):\n    batch_size = len(truth)\n    with torch.no_grad():\n        probability = probability.view(batch_size, -1)\n        truth = truth.view(batch_size, -1)\n        assert (probability.shape == truth.shape)\n\n        p = (probability > threshold).float().to(device)\n        t = (truth > 0.5).float().to(device)\n        t_sum = t.sum(-1)\n        p_sum = p.sum(-1)\n        neg_index = torch.nonzero(t_sum == 0).to(device)\n        pos_index = torch.nonzero(t_sum >= 1).to(device)\n\n        dice_neg = (p_sum == 0).float().to(device)\n        dice_pos = 2 * (p * t).sum(-1) / ((p + t).sum(-1))\n        dice_neg = dice_neg[neg_index]\n        dice_pos = dice_pos[pos_index]\n        dice = torch.cat([dice_pos, dice_neg])\n        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n        dice = dice.mean().item()\n\n        num_neg = len(neg_index)\n        num_pos = len(pos_index)\n\n    return dice, dice_neg, dice_pos, num_neg, num_pos\n\n\n# IoU计算函数(评估指标)\ndef predict(X, threshold):  # 将实数输出结果转化为0-1格式的Mask\n    Xp = np.copy(X)\n    return (Xp > threshold).astype('uint8')\n\n\n# 比较IoU\ndef compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n    pred[label == ignore_index] = 0\n    ious = []\n    for c in classes:\n        label_c = label == c\n        if only_present and np.sum(label_c) == 0:\n            ious.append(np.nan)\n            continue\n        pred_c = pred == c\n        intersection = np.logical_and(pred_c, label_c).sum()\n        union = np.logical_or(pred_c, label_c).sum()\n        if union != 0:\n            ious.append(intersection / union)\n    return ious if ious else [1]\n\n\ndef compute_iou_batch(outputs, labels, classes=None):\n    ious = []\n    preds = np.copy(outputs)\n    labels = np.array(labels.cpu().numpy())\n    for pred, label in zip(preds, labels):\n        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n    iou = np.nanmean(ious)\n    return iou\n\nclass Meter:\n    def __init__(self, phase, epoch):\n        self.base_threshold = 0.5\n        self.base_dice_scores = []\n        self.dice_neg_scores = []\n        self.dice_pos_scores = []\n        self.iou_scores = []\n\n    # 更新函数，用于将iou得分存放在iou_scores列表中\n    def update(self, targets, outputs):\n        probs = torch.sigmoid(outputs)\n        dice, dice_neg, dice_pos, _, _ = dice_metric(probs, targets, self.base_threshold)\n        self.base_dice_scores.append(dice)\n        self.dice_pos_scores.append(dice_pos)\n        self.dice_neg_scores.append(dice_neg)\n        preds = predict(probs, self.base_threshold)\n        iou = compute_iou_batch(preds, targets, classes=[1])\n        self.iou_scores.append(iou)\n\n    def get_metrics(self):\n        dice = np.mean(self.base_dice_scores)\n        dice_neg = np.mean(self.dice_neg_scores)\n        dice_pos = np.mean(self.dice_pos_scores)\n        dices = [dice, dice_neg, dice_pos]\n        iou = np.nanmean(self.iou_scores)\n        return dices, iou\n\n# 训练过程中每一epoch的日志记录，用于训练后的打印操作\ndef epoch_log(phase, epoch, epoch_loss, meter, start):\n    dices, iou = meter.get_metrics()\n    dice, dice_neg, dice_pos = dices\n    print(\"Phase: %s | Epoch: %2d | Loss: %0.4f | IoU: %0.4f | dice: %0.4f\"\n          % (phase, epoch, epoch_loss, iou, dice))\n    return dice, iou\n\n\nclass Trainer(object):\n    '''This class takes care of training and validation of our model'''\n    def __init__(self, model):\n        self.num_workers = 6\n        self.batch_size = {\"train\": 4, \"valid\": 2}     # 训练集和测试集的batch_size\n        self.accumulation_steps = 128 // self.batch_size['train']  # gradient accumulation梯度累积\n        self.lr = 1e-4  # 学习率\n        self.num_epochs = 50  # 训练轮数\n        self.best_loss = float(\"inf\")  # 初始化最好的训练损失值(初始值是正无穷大)\n        self.best_dice = 0.0\n        self.phases = [\"train\", \"valid\"]  # 两个选项\n        self.device = torch.device(\"cuda:0\")\n        # torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n        self.net = model  # 神经网络模型\n        self.criterion = torch.nn.BCEWithLogitsLoss()     # 损失函数\n        # model.parameters()与model.state_dict()是查看网络参数的方法。一般来说，前者多见于优化器的初始化\n        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)   # 优化器\n        self.max_lr_changes = 1\n        self.lr_changes = 0\n        self.valid_losses = []         # 测试集的loss列表\n        self.patience = 2\n        self.lr_reset_epoch = 0\n        self.best_valid_loss = 1000.   # 初始化测试集上最好的loss\n        self.net = self.net.to(self.device)   # 将神经网络模型转移到GPU上\n        cudnn.benchmark = True   # 优化运行效率\n\n        # 数据加载器(字典类型)  此处有两个数据加载器，一个对应数据集，一个对应测试集，两者也就batch_size不同\n        self.dataloaders = {\n            phase: Data_Provider(\n                data_folder=data_folder,\n                df_path=train_df_path,\n                phase=phase,\n                mean=(0.485, 0.456, 0.406),\n                std=(0.229, 0.224, 0.225),\n                batch_size=self.batch_size[phase],\n                num_workers=self.num_workers)\n            for phase in self.phases}\n        self.losses = {phase: [] for phase in self.phases}      # 保存损失值的列表\n        self.iou_scores = {phase: [] for phase in self.phases}  # 保存iou评分的列表\n        self.dice_scores = {phase: [] for phase in self.phases} # 保存dice评分的列表\n\n    #  返回函数:用于返回损失值和输出值\n    def forward(self, images, targets):\n        images = images.to(self.device)  # 将图片载入GPU\n        masks = targets.to(self.device)  # 将目标mask载入GPU\n        outputs = self.net(images)       # 神经网络模型的输出值\n        loss = self.criterion(outputs, masks)   # 计算损失值\n        # 将损失值和输出值进行返回\n        return loss, outputs\n\n    # 迭代函数:\n    def iterate(self, epoch, phase):\n        meter = Meter(phase, epoch)\n        start = time.strftime(\"%H:%M:%S\")    # 记录下开始的时间\n        batch_size = self.batch_size[phase]  # 根据字典索引来取出对应的batch_size\n        self.net.train(phase == \"train\")     # 如果选项为训练集就将网络切换到训练模式\n        dataloader = self.dataloaders[phase] # 将构造方法中的数据载入器根据对应的字典索引取出来\n        running_loss = 0.0                   # 初始化总loss的值\n        total_batches = len(dataloader)      # 数据载入器中有多少个小batch\n        # 如果标签是训练，就将数据加载器用进度条进行包装，使之在训练过程中内容可视化，否则就不包装\n        tk = tqdm(dataloader, total=total_batches) if phase == \"train\" else dataloader\n        # 清空网络中的梯度\n        self.optimizer.zero_grad()\n\n        # 该循环的作用就是用小的batch_size多次迭代来实现和大batch_size一样的效果(相当于训练一个epoch)\n        # enumerate(tk) 将数据加上一个索引序列，每一个batch都有一个编号itr，其中有若干图像和目标的masks\n        for itr, batch in enumerate(tk):\n            # 在batch中取出图像和目标mask\n            images, targets = batch\n            # 将两者载入到GPU上\n            images = images.to(device)\n            targets = targets.to(device)\n            # 将这些数据进行计算后再返回，得到损失值和输出值\n            loss, outputs = self.forward(images, targets)\n            # 损失函数与总计累积步数相除(为的是后面求加权,以及减小权重的改变量)\n            loss = loss / self.accumulation_steps\n            # print('\\r itr: %s, loss: %s' % (itr, loss.detach().cpu().item()), end='')\n            if phase == \"train\":\n                # 如果标签是训练集的话就利用loss进行反向传播(但是因为Loss被整除了,所以网络中权重改变量要小不少)\n                loss.backward()\n                if (itr + 1) % self.accumulation_steps == 0:\n                    # 如果达到了累积步数，就用优化器进行权重参数的更新，并且对梯度进行清零(相当于放大了batch_size)\n                    self.optimizer.step()       # 对权重进行优化\n                    self.optimizer.zero_grad()  # 清空网络中的梯度\n                # 由于数据加载器被进度条进行了包装，set_description()的作用是再进度条的前面动态显示\n                # 在显示的时候将loss进行了还原，item()返回的是tensor中的值，且只能返回单个值（标量），不能返回向量\n                tk.set_description(f'train_loss (loss={loss.item() * self.accumulation_steps:.5f})')\n\n            # 将每一个batch中的损失值(该损失值被大幅缩小)进行相加\n            running_loss += loss.item()\n\n            # detach()的作用是返回一个新的tensor，从当前计算图中分离下来的，但是仍指向原变量的存放位置\n            # 而且得到的这个新tensor永远不需要计算其梯度，不具有grad\n            # 但是使用detach返回的tensor和原始的tensor共同一个内存，即一个修改另一个也会跟着改变\n            # cpu()的作用是将数据转移到CPU上\n            outputs = outputs.detach().cpu()\n            # 每计算完一个小batch就将iou_scores的得分存入列表中\n            meter.update(targets, outputs)\n\n        # 每一轮的小batch损失值的均值\n        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n        # 每一轮的两个评分\n        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(dice)\n        self.iou_scores[phase].append(iou)\n        torch.cuda.empty_cache()  # 对显存进行释放\n        return epoch_loss\n\n\n    # 训练开始的函数\n    def start(self):\n        # 进行多轮训练的循环\n        for epoch in range(self.num_epochs):\n            # 执行迭代，完成一个epoch，并返回该轮的平均loss\n            train_loss = self.iterate(epoch, \"train\")\n            # state是一轮训练完成后所保存的信息(在读取时也要按照格式来读取)\n            state = {\n                \"epoch\": epoch,                 # 训练轮数\n                \"best_loss\": self.best_loss,    # 最佳损失值\n                \"state_dict\": self.net.state_dict(),      # 模型权重的参数\n                \"optimizer\": self.optimizer.state_dict()  # 优化器的一些参数\n                }\n            # 执行迭代，完成epoch，并返回测试集平均的loss\n            valid_loss = self.iterate(epoch, \"valid\")\n            # 返回测试集的dice评分\n            valid_dice = self.dice_scores[\"valid\"][epoch]\n            # 将测试集的loss保存在valid_losses列表中\n            self.valid_losses.append(valid_loss)\n            if valid_loss < self.best_valid_loss:\n                # 若有更小的测试集损失值，就更新最佳测试集损失值\n                self.best_valid_loss = valid_loss\n\n            # 深度学习的早停法\n            elif (self.patience and epoch - self.lr_reset_epoch > self.patience and\n                  min(self.valid_losses[-self.patience:]) > self.best_valid_loss):\n                # \"patience\" epochs without improvement\n                self.lr_changes += 1\n                if self.lr_changes > self.max_lr_changes:  # 早期停止\n                    break\n                self.lr /= 5  # 学习率衰减\n                self.lr_reset_epoch = epoch\n                # 将优化器中的lr进行修改(若lr发生修改，对相应的优化器也要进行修改)以实现动态学习率\n                self.optimizer.param_groups[0]['lr'] = self.lr\n                print('lr updated to {}'.format(self.optimizer.param_groups[0]['lr']))\n            if valid_dice > self.best_dice:\n                # 若测试集上的dice评分大于最好的dice，就将state字典中新增best_dice索引\n                # 将valid_dice的内容写入其中作为value，并且将best_dice进行更新，最后进行state的保存\n                state[\"best_dice\"] = self.best_dice = valid_dice\n                torch.save(state, \"./models/epoch{}-dice{:.4f}.pth\".format(epoch, valid_dice))\n\n\nif __name__ == '__main__':\n    # 载入神经网络模型\n    model = smp.FPN('efficientnet-b0', encoder_weights='imagenet', classes=4)\n    if not os.path.exists('models'):\n        os.makedirs('models')  # 用于储存模型\n    # 定义计算场景(GPU)，并显示\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    model = model.to(device)   # 将模型传入到GPU\n    model_trainer = Trainer(model)   # 将模型传入到Trainer类中\n    model_trainer.start()  # 开始训练","metadata":{"execution":{"iopub.status.busy":"2022-04-04T09:42:46.935526Z","iopub.execute_input":"2022-04-04T09:42:46.935874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}