{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Steel Defect Detection\nThis is starter kernel.<BR>\nI used many kernels as a reference for creating this kernel. Especially,<BR>\n[\"clear mask visualization and simple eda (GoldFish)\"](https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda) for image data visualization.<BR>\n[\"RLE functions - Run Lenght Encode & Decode (Paulo Pinto)\"](https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode) for rle encode-decode.<BR>\n[\"Intro - chest xray, DICOM, viz, U-nets - full data (Jesper)\"](https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data#Vanilla-Unet) for model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install tensorflow-gpu==1.14","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\n\nimport numpy as np # linear algebra\nimport pandas as pd\n#pd.set_option(\"display.max_rows\", 101)\nimport math\n\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 10\nimport seaborn as sns\nfrom PIL import Image\n\nfrom collections import Counter\nfrom collections import defaultdict\n\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import *\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# if tf.test.gpu_device_name():\n#     print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n# else:\n#     print(\"Please install GPU version of TF\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"DIRin1 = \"../input/severstal-steel-defect-detection\"\nDIRin_train= \"../input/prevtrain-steel\"\nprint(\"DIRin1 =\", os.listdir(DIRin1))\nDIRtrain = os.path.join(DIRin1,\"train_images\")\nDIRtest = os.path.join(DIRin1,\"test_images\")\n\nDIRin2 = \"../input/defect-detection-training\"\n#print(\"DIRin2 =\", os.listdir(DIRin2))\n# save path\n#weights_path = os.path.join(DIRin2,\"DefectDetection.h5\")\n#history_path = os.path.join(DIRin2,\"DefectDetection_history.csv\")\n\nprint(\"Num of Train img\\t:\",len(os.listdir(DIRtrain)))\nprint(\"Num of Test img\\t\\t:\",len(os.listdir(DIRtest)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training is inadequate at the regular time of the one-hour competition. So I traind 50 epochs on my local PC (about 3 hours). And This kernel does not perform any further training, but uses pre-learned weights data.<BR>\nIf you want to train, set `NoTRAIN = False`.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"##### Training conditions ##### \nbatch_size = 5\n\n#NoTRAIN = True    # True:No further training, use pre-learned weights\n#RESUME = False    # True:Resume Training, False:Start from the beginning\n\nNoTRAIN = False    # True:No further training, use pre-learned weights\nRESUME = False    # True:Resume Training, False:Start from the beginning\n\nif RESUME:\n    initial_epoch = 10    # initial_epoch when training resumes\nelse:\n    initial_epoch = 0\nepochs = initial_epoch + 10\nsteps_per_epoch = 200","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Data confirmation","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(DIRin_train, \"train.csv\"))\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Transform class to column\ntrain_df['fname'], train_df['cls'] = zip(*train_df['ImageId_ClassId'].str.split('_'))\ntrain_df['cls'] = train_df['cls'].astype(int)\ntrain_df = train_df.pivot(index='fname',columns='cls',values='EncodedPixels')\ntrain_df['defects'] = train_df.count(axis=1)\n#train_df.reset_index()\ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Number of defects for each class\nclass_defects = len(train_df) - train_df.isnull().sum() # class毎の欠陥数\nclass_defects[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# check images size\ntrain_size = defaultdict(int)\ntest_size = defaultdict(int)\n\nfor fPath in Path(DIRtrain).iterdir():\n    img = Image.open(fPath)\n    train_size[img.size] += 1\nfor fPath in Path(DIRtest).iterdir():\n    img = Image.open(fPath)\n    test_size[img.size] += 1\n    \nprint(\"train_img_size :\",train_size)\nprint(\"test_img_size  :\",test_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"palet = [(250, 230, 20), (30, 200, 241), (200, 30, 250), (250,60,20)]\n\nfig, ax = plt.subplots(1, 4, figsize=(6, 2))\nfor i in range(4):\n    ax[i].axis('off')\n    ax[i].imshow(np.ones((10, 40, 3), dtype=np.uint8) * palet[i])\n    ax[i].set_title(\"class{}\".format(i+1))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def mask2rgba(mask):\n    rgba_list = []\n    for idx in range(4):    # idx: class id\n        rgba = cv2.cvtColor(mask[:, :, idx], cv2.COLOR_GRAY2RGBA)\n        rgba[:, :, :3] = rgba[:, :, :3] /255 * palet[idx]\n        rgba_list.append(rgba)\n    return rgba_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def make_mask(row_id):\n    fname = train_df.iloc[row_id].name\n\n    labels = train_df.iloc[row_id][:4]\n    masks = np.zeros((256, 1600, 4), dtype=np.uint8)    # 4:class 1～4 (ch:0～3)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            mask = np.zeros(256 * 1600, dtype=np.uint8)\n            for pos, le in zip(positions, length):\n                mask[pos:(pos + le)] = 255\n            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n    return fname, masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def show_mask_image(row_id, contour = True):\n    name, mask = make_mask(row_id)\n    img = cv2.imread(os.path.join(DIRtrain, name))\n\n    if contour:\n        for ch in range(4):\n            contours, _ = cv2.findContours(mask[:, :, ch],\n                            cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n            for i in range(0, len(contours)):\n                cv2.polylines(img, contours[i], True, palet[ch], 2)\n    else:\n        for ch in range(4):\n            img[mask[:,:,ch]==255] = palet[ch]\n        \n    fig, ax = plt.subplots(figsize=(7,7))\n    ax.set_title(name)\n    ax.imshow(img)\n    ax.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# classify defects\nidx_class_1 = list(filter(lambda r:not pd.isna(train_df.iloc[r,0]), range(len(train_df))))\nidx_class_2 = list(filter(lambda r:not pd.isna(train_df.iloc[r,1]), range(len(train_df))))\nidx_class_3 = list(filter(lambda r:not pd.isna(train_df.iloc[r,2]), range(len(train_df))))\nidx_class_4 = list(filter(lambda r:not pd.isna(train_df.iloc[r,3]), range(len(train_df))))\n# Nouber of defects class\nidx_no_defect = list(filter(lambda r:train_df.iloc[r,4] == 0, range(len(train_df))))\nidx_1_defect = list(filter(lambda r:train_df.iloc[r,4] == 1, range(len(train_df))))\nidx_class_multi = list(filter(lambda r:train_df.iloc[r,4] >= 2, range(len(train_df))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# no defect sumple\nfor idx in idx_no_defect[:3]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# class_1 defect sumple (Yellow)\nfor idx in idx_class_1[:3]:\n    show_mask_image(idx, contour=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# class_2 defect sumple (lightblue)\nfor idx in idx_class_2[:3]:\n    show_mask_image(idx, contour=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# class_3 defect sumple (purple)\nfor idx in idx_class_3[:3]:\n    show_mask_image(idx, contour=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# class_4 defect sumple (red)\nfor idx in idx_class_4[:3]:\n    show_mask_image(idx, contour=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# contain multi class defects\nfor idx in idx_class_multi[:3]:\n    show_mask_image(idx, contour=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# # U-Net\n# # https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data#Vanilla-Unet\n\n# input_shape = (256, 1600, 1)\n# inputs = Input(input_shape)\n\n# c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n# c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n# p1 = MaxPooling2D((2, 2)) (c1)\n\n# c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n# c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n# p2 = MaxPooling2D((2, 2)) (c2)\n\n# c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n# c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n# p3 = MaxPooling2D((2, 2)) (c3)\n\n# c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n# c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n# p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n# c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n# c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n# p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n# c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n# c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\n# u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n# u6 = concatenate([u6, c5])\n# c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n# c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n# u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n# u71 = concatenate([u71, c4])\n# c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n# c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\n# u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n# u7 = concatenate([u7, c3])\n# c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n# c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n# u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n# u8 = concatenate([u8, c2])\n# c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n# c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n# u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n# u9 = concatenate([u9, c1], axis=3)\n# c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n# c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n# outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n# model = Model(inputs=[inputs], outputs=[outputs])\n\n# # Load pre-traind weights\n# if (NoTRAIN or RESUME) and os.path.exists(weights_path):\n#     model.load_weights(weights_path)\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nK.tensorflow_backend._get_available_gpus()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from keras import backend as K\nfrom keras.layers import Layer\n\n\nclass MaxPoolingWithArgmax2D(Layer):\n    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n        self.padding = padding\n        self.pool_size = pool_size\n        self.strides = strides\n\n    def call(self, inputs, **kwargs):\n        padding = self.padding\n        pool_size = self.pool_size\n        strides = self.strides\n        if K.backend() == \"tensorflow\":\n            ksize = [1, pool_size[0], pool_size[1], 1]\n            padding = padding.upper()\n            strides = [1, strides[0], strides[1], 1]\n            output, argmax = K.tf.nn.max_pool_with_argmax(\n                inputs, ksize=ksize, strides=strides, padding=padding\n            )\n        else:\n            errmsg = \"{} backend is not supported for layer {}\".format(\n                K.backend(), type(self).__name__\n            )\n            raise NotImplementedError(errmsg)\n        argmax = K.cast(argmax, K.floatx())\n        return [output, argmax]\n\n    def compute_output_shape(self, input_shape):\n        ratio = (1, 2, 2, 1)\n        output_shape = [\n            dim // ratio[idx] if dim is not None else None\n            for idx, dim in enumerate(input_shape)\n        ]\n        output_shape = tuple(output_shape)\n        return [output_shape, output_shape]\n\n    def compute_mask(self, inputs, mask=None):\n        return 2 * [None]\n\n\nclass MaxUnpooling2D(Layer):\n    def __init__(self, size=(2, 2), **kwargs):\n        super(MaxUnpooling2D, self).__init__(**kwargs)\n        self.size = size\n\n    def call(self, inputs, output_shape=None):\n        updates, mask = inputs[0], inputs[1]\n        with K.tf.variable_scope(self.name):\n            mask = K.cast(mask, \"int32\")\n            input_shape = K.tf.shape(updates, out_type=\"int32\")\n            #  calculation new shape\n            if output_shape is None:\n                output_shape = (\n                    input_shape[0],\n                    input_shape[1] * self.size[0],\n                    input_shape[2] * self.size[1],\n                    input_shape[3],\n                )\n            self.output_shape1 = output_shape\n\n            # calculation indices for batch, height, width and feature maps\n            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n            batch_range = K.reshape(\n                K.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n            )\n            b = one_like_mask * batch_range\n            y = mask // (output_shape[2] * output_shape[3])\n            x = (mask // output_shape[3]) % output_shape[2]\n            feature_range = K.tf.range(output_shape[3], dtype=\"int32\")\n            f = one_like_mask * feature_range\n\n            # transpose indices & reshape update values to one dimension\n            updates_size = K.tf.size(updates)\n            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n            values = K.reshape(updates, [updates_size])\n            ret = K.tf.scatter_nd(indices, values, output_shape)\n            return ret\n\n    def compute_output_shape(self, input_shape):\n        mask_shape = input_shape[1]\n        return (\n            mask_shape[0],\n            mask_shape[1] * self.size[0],\n            mask_shape[2] * self.size[1],\n            mask_shape[3],\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \\\n            / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from keras.layers import Input\nfrom keras.layers.convolutional import Convolution2D,Conv2D\nfrom keras.layers.core import Activation, Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\n#from layers import MaxPoolingWithArgmax2D, MaxUnpooling2D\n\n\ndef segnet(input_shape, n_labels, kernel=2, pool_size=(2, 2), output_mode=\"softmax\"):\n    # encoder\n    inputs = Input(shape=input_shape)\n\n    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n    conv_1 = BatchNormalization()(conv_1)\n    conv_1 = Activation(\"relu\")(conv_1)\n    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n    conv_2 = BatchNormalization()(conv_2)\n    conv_2 = Activation(\"relu\")(conv_2)\n\n    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n\n    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n    conv_3 = BatchNormalization()(conv_3)\n    conv_3 = Activation(\"relu\")(conv_3)\n    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n    conv_4 = BatchNormalization()(conv_4)\n    conv_4 = Activation(\"relu\")(conv_4)\n\n    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n\n    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n    conv_5 = BatchNormalization()(conv_5)\n    conv_5 = Activation(\"relu\")(conv_5)\n    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n    conv_6 = BatchNormalization()(conv_6)\n    conv_6 = Activation(\"relu\")(conv_6)\n    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n    conv_7 = BatchNormalization()(conv_7)\n    conv_7 = Activation(\"relu\")(conv_7)\n\n    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n\n    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n    conv_8 = BatchNormalization()(conv_8)\n    conv_8 = Activation(\"relu\")(conv_8)\n    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n    conv_9 = BatchNormalization()(conv_9)\n    conv_9 = Activation(\"relu\")(conv_9)\n    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n    conv_10 = BatchNormalization()(conv_10)\n    conv_10 = Activation(\"relu\")(conv_10)\n\n    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n\n    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n    conv_11 = BatchNormalization()(conv_11)\n    conv_11 = Activation(\"relu\")(conv_11)\n    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n    conv_12 = BatchNormalization()(conv_12)\n    conv_12 = Activation(\"relu\")(conv_12)\n    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n    conv_13 = BatchNormalization()(conv_13)\n    conv_13 = Activation(\"relu\")(conv_13)\n\n    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n    print(\"Build enceder done..\")\n\n    # decoder\n\n    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n\n    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n    conv_14 = BatchNormalization()(conv_14)\n    conv_14 = Activation(\"relu\")(conv_14)\n    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n    conv_15 = BatchNormalization()(conv_15)\n    conv_15 = Activation(\"relu\")(conv_15)\n    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n    conv_16 = BatchNormalization()(conv_16)\n    conv_16 = Activation(\"relu\")(conv_16)\n\n    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n\n    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n    conv_17 = BatchNormalization()(conv_17)\n    conv_17 = Activation(\"relu\")(conv_17)\n    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n    conv_18 = BatchNormalization()(conv_18)\n    conv_18 = Activation(\"relu\")(conv_18)\n    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n    conv_19 = BatchNormalization()(conv_19)\n    conv_19 = Activation(\"relu\")(conv_19)\n\n    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n\n    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n    conv_20 = BatchNormalization()(conv_20)\n    conv_20 = Activation(\"relu\")(conv_20)\n    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n    conv_21 = BatchNormalization()(conv_21)\n    conv_21 = Activation(\"relu\")(conv_21)\n    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n    conv_22 = BatchNormalization()(conv_22)\n    conv_22 = Activation(\"relu\")(conv_22)\n\n    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n\n    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n    conv_23 = BatchNormalization()(conv_23)\n    conv_23 = Activation(\"relu\")(conv_23)\n    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n    conv_24 = BatchNormalization()(conv_24)\n    conv_24 = Activation(\"relu\")(conv_24)\n\n    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n\n    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n    conv_25 = BatchNormalization()(conv_25)\n    conv_25 = Activation(\"relu\")(conv_25)\n    conv_26 = Convolution2D(32, (kernel, kernel), padding=\"same\")(conv_25)\n    conv_26 = BatchNormalization()(conv_26)\n    conv_26 = Activation(\"relu\")(conv_26)\n    conv_26 = Convolution2D(16, (kernel, kernel), padding=\"same\")(conv_26)\n    conv_26 = BatchNormalization()(conv_26)\n    conv_26 = Activation(\"relu\")(conv_26)\n    conv_26 = Convolution2D(8, (kernel, kernel), padding=\"same\")(conv_26)\n    conv_26 = BatchNormalization()(conv_26)\n    conv_26 = Activation(\"relu\")(conv_26)\n    #conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_26)\n    \n    outputs = Conv2D(4, (1, 1), activation='softmax') (conv_26)\n#    conv_26 = BatchNormalization()(conv_26)\n#     conv_26 = Reshape(\n#         (input_shape[0] * input_shape[1], n_labels),\n#         input_shape=(input_shape[0], input_shape[1], n_labels),\n#     )(conv_26)\n\n    #outputs = Activation(output_mode)(conv_26)\n    print(\"Build decoder done..\")\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def build_model(img_w, img_h, filters):\n#     n_labels = 2\n\n#     kernel = 3\n\n#     encoding_layers = [\n#         Conv2D(64, (kernel, kernel), input_shape=(img_h, img_w, 3), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(64, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         MaxPooling2D(),\n\n#         Convolution2D(128, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(128, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         MaxPooling2D(),\n\n#         Convolution2D(256, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(256, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(256, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         MaxPooling2D(),\n\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         MaxPooling2D(),\n\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         MaxPooling2D(),\n#     ]\n\n#     autoencoder =Sequential()\n#     autoencoder.encoding_layers = encoding_layers\n\n#     for l in autoencoder.encoding_layers:\n#         autoencoder.add(l)\n\n#     decoding_layers = [\n#         UpSampling2D(),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n\n#         UpSampling2D(),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(512, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(256, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n\n#         UpSampling2D(),\n#         Convolution2D(256, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(256, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(128, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n\n#         UpSampling2D(),\n#         Convolution2D(128, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(64, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n\n#         UpSampling2D(),\n#         Convolution2D(64, (kernel, kernel), padding='same'),\n#         BatchNormalization(),\n#         Activation('relu'),\n#         Convolution2D(n_labels, (1, 1), padding='valid', activation=\"sigmoid\"),\n#         BatchNormalization(),\n#     ]\n#     autoencoder.decoding_layers = decoding_layers\n#     for l in autoencoder.decoding_layers:\n#         autoencoder.add(l)\n\n#     autoencoder.add(Reshape((n_labels, img_h * img_w)))\n#     autoencoder.add(Permute((2, 1)))\n#     autoencoder.add(Activation('softmax'))\n\n#     #with open('model_5l.json', 'w') as outfile:\n#     #    outfile.write(json.dumps(json.loads(autoencoder.to_json()), indent=2))\n#     autoencoder.summary()\n#     return autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model=build_model(256,1600,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tem=input_shape[0] * input_shape[1]\n# print(input_shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"input_shape = (256,1600,1)\n\nmodel=segnet(input_shape,4)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install q tensorflow==1.13.1\n# !pip install q keras==1.2.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install q tensorflow==1.13.1\n# !pip install q keras==1.2.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# def dice_coef(y_true, y_pred, smooth=1):\n#     y_true_f = K.flatten(y_true)\n#     y_pred_f = K.flatten(y_pred)\n#     intersection = K.sum(y_true_f * y_pred_f)\n#     return (2. * intersection + smooth) \\\n#             / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# optimizer = Adam()\n# model.compile(optimizer, 'binary_crossentropy', metrics=[dice_coef])\n\n# Compile the model\n#model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_grayscale(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 2\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019, \n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# # Train Data Generator\n# def Xy_generator(ids, batch_size):\n#     Xs = []; ys = []\n#     while True:\n#         for i in ids:\n#             name, mask = make_mask(i)\n#             img = cv2.imread(os.path.join(DIRtrain, name),\n#                              cv2.IMREAD_GRAYSCALE)\n#             img = img[..., np.newaxis]    # Add channel axis\n#             img = img / 255.           # 0～1\n#             mask = mask / 255.         # 0～1\n#             Xs.append(img); ys.append(mask)\n#             if len(Xs) == batch_size:\n#                 X = np.array(Xs); y = np.array(ys)\n#                 Xs = []; ys = []\n#                 yield [X, y]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# # Train Data\n# train_ids, val_ids = train_test_split(range(len(train_df)), test_size=0.2)\n# train_gen = Xy_generator(train_ids, batch_size)\n# val_gen = Xy_generator(val_ids, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # generator test\n# for X, y in Xy_generator(range(len(train_df)), 4):\n#     break\n\n# print('X.shape:',X.shape, '\\ny.shape:',y.shape)\n\n# row = 0\n# # from train_df\n# show_mask_image(row, contour=True)\n# # from generator\n# fig, axs = plt.subplots(5, figsize=(7,7))\n# axs[0].imshow(X[row,:,:,0])\n# axs[0].axis('off')\n# axs[0].set_title(train_df.iloc[row].name)\n# for i in range(4):\n#     axs[i+1].imshow(y[row,:,:,i])\n#     axs[i+1].axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Callback\n#checkpoint = ModelCheckpoint(\"DefectDetection.h5\", monitor='val_dice_coef',\n                           #verbose=1,save_best_only=True, mode='max')\n#callbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Fit\n# # if NoTRAIN == False or RESUME:\n# history = model.fit_generator(generator=train_gen,\n#                               steps_per_epoch=10,\n#                               #initial_epoch=initial_epoch,\n#                               epochs=10,\n#                               validation_data=val_gen,\n#                               validation_steps = len(val_ids)//5,\n#                               verbose=2,\n#                              shuffle=True\n#                               #callbacks=callbacks_list\n#                                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Plot the loss and dice_coef curves\nif (NoTRAIN or RESUME) and os.path.exists(history_path):\n    hist_df = pd.read_csv(history_path)        # Load previous training history\nif RESUME and os.path.exists(history_path):\n    hist_df1 = pd.DataFrame(history.history)[['loss','val_loss','dice_coef','val_dice_coef']]\n    hist_df = pd.concat([hist_df, hist_df1], ignore_index=True)    # Concat history\nelif NoTRAIN == False and RESUME == False:\n    hist_df = pd.DataFrame(history.history)[['loss','val_loss','dice_coef','val_dice_coef']]\n\n# Plot\nfig, ax = plt.subplots(1,2,figsize=(10, 3))\n\nax[0].plot(hist_df['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist_df['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist_df['dice_coef'], color='b', label=\"Training dice_coef\")\nax[1].plot(hist_df['val_dice_coef'], color='r',label=\"Validation dice_coef\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Save history (for next Resume)\nhist_df.to_csv(\"DefectDetection_history.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Load the weights that had the best score for predict\nif NoTRAIN == False or RESUME:\n    model.load_weights(\"DefectDetection.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Binarize the mask output by NN\ndef binarize(masks, th = 0.5):\n    # Maximum value of each channel per pixel\n    mask_max = np.zeros_like(masks[:,:,0])\n    mask_max = np.fmax(masks[:,:,0],masks[:,:,1])\n    mask_max = np.fmax(mask_max,masks[:,:,2])\n    mask_max = np.fmax(mask_max,masks[:,:,3])\n    # Remove non-maximum pixels\n    m = np.zeros_like(masks)\n    for ch in range(4):\n        m[:,:,ch] = (masks[:,:,ch] == mask_max) * masks[:,:,ch]\n    # Binarization\n    m = (m>th) * 1\n    return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def show_predict_img(df, row):\n    if df == \"train_df\":\n        name = train_df.iloc[row].name\n        img = cv2.imread(os.path.join(DIRtrain, name),\n                             cv2.IMREAD_GRAYSCALE)\n    else:\n        if df == \"submit_df\":\n            name = test_df.iloc[row//4,0].split('_')[0]\n        elif df == \"test_df\":\n            name = test_df.iloc[row,0]\n        img = cv2.imread(os.path.join(DIRtest, name),\n                             cv2.IMREAD_GRAYSCALE)\n\n    img_ = img[..., np.newaxis]    # Add channel axis\n    img_ = img_[np.newaxis, ...]    # Add batch axis\n    img_ = img_ / 255.              # 0～1\n\n    pred_masks = model.predict(img_)\n    bin_masks = binarize(pred_masks[0, ...], 0.5)\n\n    fig, axs = plt.subplots(5,2, figsize=(12, 6))\n    axs[0,0].imshow(img)\n    axs[0,0].axis('off')\n    axs[0,0].set_title(name)\n    axs[0,1].axis('off')\n    axs[0,1].set_title(\"after binarize\")\n    for i in range(4):\n        axs[i+1,0].imshow(pred_masks[0,:,:,i])\n        axs[i+1,0].axis('off')\n        axs[i+1,0].set_title('class '+ str(i+1))\n        axs[i+1,1].imshow(bin_masks[:,:,i])\n        axs[i+1,1].axis('off')\n        axs[i+1,1].set_title('class '+ str(i+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# predict sumple\nshow_predict_img(\"train_df\", 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submit_df = pd.read_csv(os.path.join(DIRin1,'sample_submission.csv'))\nsubmit_df['EncodedPixels'] = np.nan\nsubmit_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"temp_df = pd.DataFrame()\ntemp_df['ImageId'] = submit_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_df = pd.DataFrame(temp_df['ImageId'].unique(), columns=['ImageId'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def mask2rle(mask):\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[:-1:2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def build_rles(masks):\n    width, height, depth = masks.shape\n    masks = binarize(masks, th = 0.5)\n    rles = [mask2rle(masks[:, :, i]) for i in range(depth)]\n\n    return rles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Predict test images\nfor i, line in tqdm(test_df.iterrows()):\n    img = cv2.imread(os.path.join(DIRtest, line['ImageId']),\n                     cv2.IMREAD_GRAYSCALE)\n    img = img[..., np.newaxis]    # Add channel axis\n    img = img[np.newaxis, ...]    # Add butch axis\n    img = img / 255.              # 0～1\n    pred_masks = model.predict(img)[0]\n    rles = build_rles(pred_masks)\n    for j in range(4):\n        if len(rles[j])>0:\n            submit_df.iloc[i*4+j,1] = rles[j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submit_df.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Number of Defect Detection\nsubmit_df['EncodedPixels'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Detected sumple\nshow_predict_img(\"submit_df\",26)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submit_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}