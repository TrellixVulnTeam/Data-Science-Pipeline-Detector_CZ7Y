{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this kernel\n\n* **Preprocessing**: Discard all of the training data that have all 4 masks missing. We will only train on images that have at least 1 mask, so that our classifier does not overfit on empty masks.\n* **Step 1 - Discard Images**: Use the DenseNet classifier trained in [this kernel](https://www.kaggle.com/xhlulu/severstal-steel-predict-missing-masks) to predict all of the test images that will have all 4 masks missing. We will automatically set the RLEs of those images to null.\n* **Step 2 - SegNet**: Train the same model from [Simple Keras SegNet Boilerplate](https://github.com/ykamikawa/tf-keras-SegNet/blob/master/model.py) on the \"filtered\" training data. Then, perform inference only on test images that were not discarded in step 1.\n* **Submission**: We will now combine the dataframe containing the discarded test images with the dataframe containing test images predicted in step 2, and submit everything.\n\n\n## Changelog\n* V8: Changed sign of the `missing_model` threshold, since we are only keeping the ones with low probability of having no defect.\n* V9: Fixed import for the discarding CNNs, which was updated to DenseNet.\n\n\n## References\n* Data generator: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n* RLE encoding and decoding: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n* Architecture:https://arxiv.org/abs/1511.00561\n* Mask encoding: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/data\n* Step 1 Original Kernel: https://www.kaggle.com/xhlulu/severstal-steel-predict-missing-masks\n* Step 2 Original Kernel: https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/prevtrain-steel/train.csv')\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count_df.shape)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsub_df['ImageId'] = sub_df['ImageId'].apply(lambda x: x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Remove test images without defects\n\nMost of the stuff below is hidden, since it's copied from my previous kernels.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def load_img(code, base, resize=True):\n    path = f'{base}/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    \n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"BATCH_SIZE = 10\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_imgs,\n        directory='../input/severstal-steel-defect-detection/test_images',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ntest_gen = create_test_gen()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_model = load_model('../input/severstal-predict-missing-masks/model.h5')\nremove_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Beware: Messy code below!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_missing_pred = remove_model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)\n\ntest_imgs['allMissing'] = test_missing_pred\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_test_imgs = test_imgs[test_imgs['allMissing'] < 0.5]\nprint(filtered_test_imgs.shape)\nfiltered_test_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`filtered_sub_df` contains all of the images with at least one mask. `null_sub_df` contains all the images with exactly 4 missing masks.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_mask = sub_df['ImageId'].isin(filtered_test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(\n    lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\nfiltered_test_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nfiltered_sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Keras Seg-Net\n\nMost of the stuff below is hidden, since it's copied from my previous kernels.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Utility Functions","execution_count":null},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Generator","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_grayscale(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 4\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019, \n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# def build_model(input_shape):\n#     inputs = Input(input_shape)\n\n#     c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n#     c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n#     p1 = MaxPooling2D((2, 2)) (c1)\n\n#     c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n#     c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n#     p2 = MaxPooling2D((2, 2)) (c2)\n\n#     c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n#     c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n#     p3 = MaxPooling2D((2, 2)) (c3)\n\n#     c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n#     c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n#     p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n#     c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n#     c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n#     p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n#     c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n#     c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\n#     u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n#     u6 = concatenate([u6, c5])\n#     c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n#     c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n#     u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n#     u71 = concatenate([u71, c4])\n#     c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n#     c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\n#     u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n#     u7 = concatenate([u7, c3])\n#     c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n#     c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n#     u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n#     u8 = concatenate([u8, c2])\n#     c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n#     c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n#     u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n#     u9 = concatenate([u9, c1], axis=3)\n#     c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n#     c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n#     outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n#     model = Model(inputs=[inputs], outputs=[outputs])\n#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n    \n#     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nfrom keras.layers import Layer\n\n\nclass MaxPoolingWithArgmax2D(Layer):\n    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n        self.padding = padding\n        self.pool_size = pool_size\n        self.strides = strides\n\n    def call(self, inputs, **kwargs):\n        padding = self.padding\n        pool_size = self.pool_size\n        strides = self.strides\n        if K.backend() == \"tensorflow\":\n            ksize = [1, pool_size[0], pool_size[1], 1]\n            padding = padding.upper()\n            strides = [1, strides[0], strides[1], 1]\n            output, argmax = K.tf.nn.max_pool_with_argmax(\n                inputs, ksize=ksize, strides=strides, padding=padding\n            )\n        else:\n            errmsg = \"{} backend is not supported for layer {}\".format(\n                K.backend(), type(self).__name__\n            )\n            raise NotImplementedError(errmsg)\n        argmax = K.cast(argmax, K.floatx())\n        return [output, argmax]\n\n    def compute_output_shape(self, input_shape):\n        ratio = (1, 2, 2, 1)\n        output_shape = [\n            dim // ratio[idx] if dim is not None else None\n            for idx, dim in enumerate(input_shape)\n        ]\n        output_shape = tuple(output_shape)\n        return [output_shape, output_shape]\n\n    def compute_mask(self, inputs, mask=None):\n        return 2 * [None]\n\n\nclass MaxUnpooling2D(Layer):\n    def __init__(self, size=(2, 2), **kwargs):\n        super(MaxUnpooling2D, self).__init__(**kwargs)\n        self.size = size\n\n    def call(self, inputs, output_shape=None):\n        updates, mask = inputs[0], inputs[1]\n        with K.tf.variable_scope(self.name):\n            mask = K.cast(mask, \"int32\")\n            input_shape = K.tf.shape(updates, out_type=\"int32\")\n            #  calculation new shape\n            if output_shape is None:\n                output_shape = (\n                    input_shape[0],\n                    input_shape[1] * self.size[0],\n                    input_shape[2] * self.size[1],\n                    input_shape[3],\n                )\n            self.output_shape1 = output_shape\n\n            # calculation indices for batch, height, width and feature maps\n            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n            batch_range = K.reshape(\n                K.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n            )\n            b = one_like_mask * batch_range\n            y = mask // (output_shape[2] * output_shape[3])\n            x = (mask // output_shape[3]) % output_shape[2]\n            feature_range = K.tf.range(output_shape[3], dtype=\"int32\")\n            f = one_like_mask * feature_range\n\n            # transpose indices & reshape update values to one dimension\n            updates_size = K.tf.size(updates)\n            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n            values = K.reshape(updates, [updates_size])\n            ret = K.tf.scatter_nd(indices, values, output_shape)\n            return ret\n\n    def compute_output_shape(self, input_shape):\n        mask_shape = input_shape[1]\n        return (\n            mask_shape[0],\n            mask_shape[1] * self.size[0],\n            mask_shape[2] * self.size[1],\n            mask_shape[3],\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input\nfrom keras.layers.convolutional import Convolution2D,Conv2D\nfrom keras.layers.core import Activation, Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\n#from layers import MaxPoolingWithArgmax2D, MaxUnpooling2D\n\n\ndef segnet(input_shape, n_labels, kernel=2, pool_size=(2, 2), output_mode=\"softmax\"):\n    # encoder\n    inputs = Input(shape=input_shape)\n\n    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n    conv_1 = BatchNormalization()(conv_1)\n    conv_1 = Activation(\"relu\")(conv_1)\n    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n    conv_2 = BatchNormalization()(conv_2)\n    conv_2 = Activation(\"relu\")(conv_2)\n\n    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n\n    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n    conv_3 = BatchNormalization()(conv_3)\n    conv_3 = Activation(\"relu\")(conv_3)\n    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n    conv_4 = BatchNormalization()(conv_4)\n    conv_4 = Activation(\"relu\")(conv_4)\n\n    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n\n    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n    conv_5 = BatchNormalization()(conv_5)\n    conv_5 = Activation(\"relu\")(conv_5)\n    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n    conv_6 = BatchNormalization()(conv_6)\n    conv_6 = Activation(\"relu\")(conv_6)\n    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n    conv_7 = BatchNormalization()(conv_7)\n    conv_7 = Activation(\"relu\")(conv_7)\n\n    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n\n    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n    conv_8 = BatchNormalization()(conv_8)\n    conv_8 = Activation(\"relu\")(conv_8)\n    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n    conv_9 = BatchNormalization()(conv_9)\n    conv_9 = Activation(\"relu\")(conv_9)\n    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n    conv_10 = BatchNormalization()(conv_10)\n    conv_10 = Activation(\"relu\")(conv_10)\n\n    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n\n    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n    conv_11 = BatchNormalization()(conv_11)\n    conv_11 = Activation(\"relu\")(conv_11)\n    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n    conv_12 = BatchNormalization()(conv_12)\n    conv_12 = Activation(\"relu\")(conv_12)\n    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n    conv_13 = BatchNormalization()(conv_13)\n    conv_13 = Activation(\"relu\")(conv_13)\n\n    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n    print(\"Build enceder done..\")\n\n    # decoder\n\n    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n\n    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n    conv_14 = BatchNormalization()(conv_14)\n    conv_14 = Activation(\"relu\")(conv_14)\n    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n    conv_15 = BatchNormalization()(conv_15)\n    conv_15 = Activation(\"relu\")(conv_15)\n    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n    conv_16 = BatchNormalization()(conv_16)\n    conv_16 = Activation(\"relu\")(conv_16)\n\n    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n\n    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n    conv_17 = BatchNormalization()(conv_17)\n    conv_17 = Activation(\"relu\")(conv_17)\n    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n    conv_18 = BatchNormalization()(conv_18)\n    conv_18 = Activation(\"relu\")(conv_18)\n    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n    conv_19 = BatchNormalization()(conv_19)\n    conv_19 = Activation(\"relu\")(conv_19)\n\n    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n\n    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n    conv_20 = BatchNormalization()(conv_20)\n    conv_20 = Activation(\"relu\")(conv_20)\n    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n    conv_21 = BatchNormalization()(conv_21)\n    conv_21 = Activation(\"relu\")(conv_21)\n    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n    conv_22 = BatchNormalization()(conv_22)\n    conv_22 = Activation(\"relu\")(conv_22)\n\n    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n\n    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n    conv_23 = BatchNormalization()(conv_23)\n    conv_23 = Activation(\"relu\")(conv_23)\n    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n    conv_24 = BatchNormalization()(conv_24)\n    conv_24 = Activation(\"relu\")(conv_24)\n\n    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n\n    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n#     conv_25 = BatchNormalization()(conv_25)\n#     conv_25 = Activation(\"relu\")(conv_25)\n#     conv_26 = Convolution2D(32, (kernel, kernel), padding=\"same\")(conv_25)\n#     conv_26 = BatchNormalization()(conv_26)\n#     conv_26 = Activation(\"relu\")(conv_26)\n#     conv_26 = Convolution2D(16, (kernel, kernel), padding=\"same\")(conv_26)\n#     conv_26 = BatchNormalization()(conv_26)\n#     conv_26 = Activation(\"relu\")(conv_26)\n#     conv_26 = Convolution2D(8, (kernel, kernel), padding=\"same\")(conv_26)\n#     conv_26 = BatchNormalization()(conv_26)\n#     conv_26 = Activation(\"relu\")(conv_26)\n#     #conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_26)\n    \n    outputs = Conv2D(4, (1, 1), activation='softmax') (conv_25)\n#    conv_26 = BatchNormalization()(conv_26)\n#     conv_26 = Reshape(\n#         (input_shape[0] * input_shape[1], n_labels),\n#         input_shape=(input_shape[0], input_shape[1], n_labels),\n#     )(conv_26)\n\n    #outputs = Activation(output_mode)(conv_26)\n    print(\"Build decoder done..\")\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (256,1600,1)\n\nmodel=segnet(input_shape,4)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checkpoint = ModelCheckpoint(\n#     'model.h5', \n#     monitor='val_loss', \n#     verbose=0, \n#     save_best_only=True, \n#     save_weights_only=False,\n#     mode='auto'\n# )\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    #callbacks=[checkpoint],\n    use_multiprocessing=False,\n    workers=1,\n    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['dice_coef', 'val_dice_coef']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict masks on non-discarded images","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"model.load_weights('model.h5')\ntest_df = []\n\nfor i in range(0, filtered_test_imgs.shape[0], 300):\n    batch_idx = list(\n        range(i, min(filtered_test_imgs.shape[0], i + 300))\n    )\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=filtered_test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        target_df=filtered_sub_df,\n        batch_size=1,\n        n_classes=4\n    )\n    \n    batch_pred_masks = model.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = filtered_test_imgs['ImageId'].iloc[b]\n        image_df = filtered_sub_df[filtered_sub_df['ImageId'] == filename].copy()\n        \n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n        \n        image_df['EncodedPixels'] = pred_rles\n        test_df.append(image_df)\n        \n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_df = pd.concat(test_df)\nprint(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we combine results from the predicted masks with the rest of images that our first CNN classified as having all 4 masks missing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission_df = pd.concat([test_df, null_sub_df])\nprint(final_submission_df.shape)\nfinal_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}