{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg \nimport matplotlib.pyplot as plt \nimport numpy as np\nimport copy\nimport pandas as pd\nimport cv2\nimport pandas as pd\ntrain=pd.read_csv(\"/kaggle/input/severstal-steel-defect-detection/train.csv\")\ntrain['imageId']=train['ImageId_ClassId'].map(lambda x : x[0:-2])\ntrain['isFailurePresent']=train['EncodedPixels'].map(lambda x : 0 if pd.isnull(x) else 1)\ntrain['defectType']=train['ImageId_ClassId'].map(lambda x : x[-1])\n\ndef getMask(encoding):\n    mask=np.zeros(256*1600,dtype=np.uint8)\n    encoding=encoding.split(' ')\n    for curMaskPoint in list(zip([x for i,x in enumerate(encoding) if i%2==0],[x for i,x in enumerate(encoding) if i%2==1])):\n        position=int(curMaskPoint[0])\n        length=int(curMaskPoint[1])\n        mask[position-1:position+length-1] = 1\n    mask=mask.reshape(256,1600,order='F')\n    return(mask)\n\ntrain['mask']=train.apply(lambda row : getMask(row['EncodedPixels']) if row['isFailurePresent']==1 else 0,axis=1)\ntrain.head(10)\nprint(\"Cell Execution Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imageList=train['imageId'].unique()\nimageListLen=len(imageList)\nfor curImageBatchCount in range(20):\n    trainingX=[]\n    trainingY=[]\n    for curImageIndex in range(curImageBatchCount*100,(curImageBatchCount+1)*100):\n        curImageY=[]\n        subData=train[train['imageId']==imageList[curImageIndex]]\n        img = np.array(mpimg.imread(\"../input/severstal-steel-defect-detection/train_images/{0}\".format(imageList[curImageIndex])) )\n        for defectType in ['1','2','3','4']:\n            curMask=subData[subData['defectType']==defectType]['mask'].values\n            if(len(curMask)==1):\n                curMask=np.zeros((256,1600))\n            curImageY.append(curMask)\n        trainingX.append(img)\n        trainingY.append(curImageY)\n    trainingX=np.array(trainingX).reshape(-1,3,256,1600).astype(np.float32)\n    trainingY=np.array(trainingY).reshape(-1,4,256,1600).astype(np.float32)\n    np.save(\"./../trainingX_FullImage_{0}\".format(curImageBatchCount),trainingX)\n    np.save(\"./../trainingY_FullImage_{0}\".format(curImageBatchCount),trainingY)\n    print(\"Completed for {0} \".format(curImageBatchCount))\n            \nprint(\"Cell Execution Completed\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using a pretrained model\nfrom torchvision import models\nimport torch\nimport random\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom collections import OrderedDict \nimport numpy as np\n\n# ALEXNET MODEL\nalexnet = models.alexnet(pretrained=True)\n\nclass Flatten(nn.Module):\n    def forward(self, input):\n        #print(\"Size of the input is {0}\".format(input.size()))\n        return input.view(-1, 4 * 256 * 100)\n\ndef resize2d(img, size):\n    return (F.adaptive_avg_pool2d(img, size))\n    \nclass Transfer(nn.Module):\n    def __init__(self):\n        super(Transfer, self).__init__()\n        self.transferModelFeatures=models.alexnet(pretrained=True).features\n        self.conv4=nn.ConvTranspose2d(in_channels=256,out_channels=256,kernel_size=2,stride=1,padding=0)\n        self.relu4=nn.ReLU()\n        #self.conv5=nn.ConvTranspose2d(in_channels=2048,out_channels=4096,kernel_size=2,stride=1,padding=0)\n        #self.relu5=nn.ReLU()\n        #self.conv6=nn.ConvTranspose2d(in_channels=1024,out_channels=2048,kernel_size=2,stride=1,padding=0)\n        #self.relu6=nn.ReLU()\n        self.flatten=Flatten()\n        self.smax=nn.Softmax(dim=1)\n        \n    def forward(self,x):\n        #print(\"Size is {0}\".format(x.size()))\n        x=self.transferModelFeatures(x)\n        #print(\"Size is {0}\".format(x.size()))\n        x=F.relu(self.conv4(x))\n        #print(\"Size is {0}\".format(x.size()))\n        x=self.smax(self.flatten(x))\n        #print(\"Size is {0}\".format(x.view(-1,4,128,100).size()))\n        return(x.view(-1,4,256,100))\n        \n\nmodel=Transfer()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.BCELoss()\nepochRange=10\nminiBatches=8\nbatchSize=16\n\nfor epoch in range(epochRange):\n    for trainingCount in range(20):\n        trainingX=np.load(\"./../trainingX_FullImage_{0}.npy\".format(trainingCount))\n        trainingY=np.load(\"./../trainingY_FullImage_{0}.npy\".format(trainingCount))\n        totalLoss=0\n        for curMiniBatch in range(miniBatches):\n            choiceList=np.random.choice(trainingX.shape[0],batchSize)\n            inputs=Variable(torch.from_numpy(trainingX[choiceList,:,:,:]))\n            #print(\"Size of inputs is {0}\".format(inputs.size()))\n            labels=Variable(torch.from_numpy(trainingY[[choiceList]]))\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            # forward + backward + optimize\n            outputs = model(inputs)\n            loss = criterion(resize2d(outputs, (256,1600)).view(-1,1), labels.view(-1,1))\n            totalLoss=totalLoss + loss\n        totalLoss.backward()\n        optimizer.step()\n        if(epoch % 1==0):\n            print(\"Epoch : {0} trainingCount : {1} Total Loss : {2}\".format(epoch,trainingCount,totalLoss))    \nprint(\"Cell Execution Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Predictions\n\n# Convert to run length encoding\ndef getRLE(imgMask):\n    rle=''\n    x=0\n    while(x < imgMask.shape[0]):\n        if(imgMask[x]==1):\n            rle=rle + ' ' + str(x)  \n            while(imgMask[x]==1):\n                x=x+1\n            rle=rle + ' ' + str(x) \n        x=x+1\n    return(rle)\n\n# Read the test Data\ntest=pd.read_csv(\"/kaggle/input/severstal-steel-defect-detection/sample_submission.csv\")\ntest['imageId']=test['ImageId_ClassId'].map(lambda x : x[0:-2])\ntest['defectType']=test['ImageId_ClassId'].map(lambda x : x[-1])\nfor curRowIndex,curRow in test.iterrows():\n    curImage=curRow['imageId']\n    curDefect=curRow['defectType']\n    curImageClassId=curRow['ImageId_ClassId']\n    img = np.array(mpimg.imread(\"../input/severstal-steel-defect-detection/test_images/{0}\".format(curImage)) )\n    imgMask=np.zeros((4,img.shape[0],img.shape[1]))\n    # Get Predictions\n    predictions=model(Variable(torch.from_numpy(img.reshape(1,3,256,1600).astype(np.float32))))\n    predictions=predictions.detach().numpy()\n    predictions=cv2.resize(predictions.reshape(4,64,400),(256,1600))\n    #cv2.resize(model(Variable(torch.from_numpy(img.reshape(1,3,256,1600).astype(np.float32)))).detach().numpy().reshape(4,256,100),(4,256,1600))\n    predictions[predictions > 0.8]=1\n    predictions[predictions <= 0.8]=0\n    imgMask=predictions\n    imgMask=imgMask.reshape(-1)\n    for defectType in range(1,5):\n        if(np.sum(imgMask==1)>0):\n            curRLE=getRLE(imgMask[defectType-1])\n        else:\n            curRLE=''\n        test.loc[(test['imageId']==curImage) & (test['defectType']==str(defectType)),'EncodedPixels']=curRLE\n\ntest[['ImageId_ClassId','EncodedPixels']].to_csv('./../Submission1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import torch\n#import random\n#import torch.nn as nn\n#import torch.nn.functional as F\n#import torch.optim as optim\n#from torch.autograd import Variable\n#from collections import OrderedDict \n#import numpy as np\n#\n#class Flatten(nn.Module):\n#    def forward(self, input):\n#        #print(\"Size of the input is {0}\".format(input.size()))\n#        return input.view(-1, 256 * 7 * 49)\n#\n#class Transfer(nn.Module):\n#    def __init__(self):\n#        super(Transfer, self).__init__()\n#        self.SequentialModel1 = nn.Sequential(OrderedDict([\n#        ('transferModelFeatures' , models.alexnet(pretrained=True).features),\n#        ('flatten' , Flatten()),\n#        ('fc1' , nn.Linear(256*7*49,512)),\n#        ('relu1', nn.ReLU()),\n#        ('fc2' , nn.Linear(512,5)),\n#        ('smax',nn.Softmax(dim=1))\n#        ]))\n#        #self.transferModelFeatures=models.alexnet(pretrained=True).features\n#        #256, 7, 49\n#        #self.flatten=Flatten()\n#        #self.fc1=nn.Linear(256*7*49,5)\n#        #self.smax=nn.Softmax(dim=1)\n#        \n#    def forward(self,x):\n#        x=self.SequentialModel1(x)\n#        #x=self.transferModelFeatures(x)\n#        #print(\"Size of x is {0}\".format(x.size()))\n#        #x=self.flatten(x)\n#        #print(\"Size of x is {0}\".format(x.size()))\n#        #x=self.fc1(x)\n#        #print(\"Size of x is {0}\".format(x.size()))\n#        #x=self.smax(x)\n#        #print(\"Size of x is {0}\".format(x.size()))\n#        return(x)\n#        \n#    \n#model=Transfer()\n#optimizer = optim.Adam(model.parameters(), lr=0.01)\n#criterion = nn.CrossEntropyLoss()\n#epochRange=100\n#miniBatches=16\n#batchSize=32\n#\n#import random\n#trainingX=np.load(\"./../trainingX_{0}.npy\".format('0'))\n#trainingY=np.load(\"./../trainingY_{0}.npy\".format('0'))\n#for epoch in range(epochRange):\n#    for trainingCount in range(1):\n#        #trainingX=np.load(\"./../trainingX_{0}.npy\".format(trainingCount))\n#        #trainingY=np.load(\"./../trainingY_{0}.npy\".format(trainingCount))\n#        totalLoss=0\n#        for curMiniBatch in range(miniBatches):\n#            choiceList=np.random.choice(trainingX.shape[0],batchSize)\n#            inputs=Variable(torch.from_numpy(trainingX[choiceList,:,:,:].astype(np.float32)))\n#            #print(\"Size of inputs is {0}\".format(inputs.size()))\n#            labels=Variable(torch.from_numpy(trainingY[[choiceList]])).type(torch.long)\n#            # zero the parameter gradients\n#            optimizer.zero_grad()\n#            # forward + backward + optimize\n#            outputs = model(inputs)\n#            #print(\"Before entering the loss criterion outputs={0} and labels={1}\".format(outputs.size(),labels.size()))\n#            loss = criterion(outputs, labels)\n#            totalLoss=totalLoss + loss\n#        totalLoss.backward()\n#        optimizer.step()\n#        if(epoch % 1==0):\n#            print(\"Epoch : {0} trainingCount : {1} Total Loss : {2}\".format(epoch,trainingCount,totalLoss))    \n#            \n#gradCamTestData=trainingX[0].reshape(1,3,256,1600).astype(np.float32)\n#gradCamTestDataTorch=Variable(torch.from_numpy(gradCamTestData))\n#print(\"Shape of the transformed data\")\n#print(alexnet.features(gradCamTestDataTorch).shape)            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#################\n### GRAD CAM\n#################\n\n#import cv2\n#import matplotlib.pyplot as plt\n#%matplotlib inline\n\n#class GetGradients():\n#    def __init__(self, model, gradLayer, stopLayer):\n#        self.model = model\n#        self.gradLayer = gradLayer\n#        self.stopLayer = stopLayer\n#        self.gradient=None\n\n#    def captureGradient(self, grad):\n#        self.gradient=grad\n        \n#    def getObserveLayerGradient(self):\n#        return(self.gradient)\n\n#    def __call__(self, x):\n#        layerOutput=None\n#        for name, module in model._modules['SequentialModel1']._modules.items():\n#            x = module(x)\n#            if name == self.gradLayer:\n#                x.register_hook(self.captureGradient)\n#                layerOutput=x\n#            if name == self.stopLayer:\n#                break\n#        return layerOutput, x.view(x.size()[0],-1)\n\n#class GradCam:\n#    def __init__(self, model,gradLayer,stopLayer):\n#        self.model = model\n#        self.model.eval()\n#        self.gradLayer=gradLayer\n#        self.stopLayer=stopLayer\n#        self.getGradients = GetGradients(self.model,self.gradLayer,self.stopLayer)\n\n#    def forward(self, input):\n#        return self.model(input) \n\n#    def __call__(self, input):\n#        gradLayerActivations,stopLayerOutput = self.getGradients(input)\n#        print(\"Grad Layer Activations\")\n#        print(gradLayerActivations)\n#        print(\"stopLayerOutput\")\n#        print(stopLayerOutput)\n#        print(\"Size of stopLayerOutput is {0}\".format(stopLayerOutput.size()))\n#        # Getting the index which saw the maximum activation\n#        index = np.argmax(stopLayerOutput.detach().numpy())\n#        print(\"The index is {0}\".format(index))\n#        # Recreate the Last Layer with only that index active\n#        one_hot = np.zeros((1, stopLayerOutput.size()[-1]), dtype = np.float32)\n#        one_hot[0][index] = 1\n#        one_hot = Variable(torch.from_numpy(one_hot), requires_grad = True)\n#        one_hot = torch.sum(one_hot * stopLayerOutput)\n#        # Releasing all the accumulated Grads\n#        self.model.zero_grad()\n#        # Backward propagation from the layer\n#        one_hot.backward(retain_graph=True)\n#        gradLayerGradients = self.getGradients.getObserveLayerGradient().detach().numpy()\n#        # We will be doing it only for a single image hence 0\n#        gradLayerActivations = gradLayerActivations.detach().numpy()[0,:]\n#        # For each channel and image, we will be summing up the activations, hence summing up width and height a.k.a 2 and 3\n#        # We add an index of 0 because we are doing it only for a single image\n#        weights = np.mean(gradLayerGradients, axis = (2, 3))[0, :]\n#        # The dimensions of the image are the height and width only of the activations at that time\n#        gradCam = np.zeros(gradLayerActivations.shape[1 : ], dtype = np.float32)\n#        for channelIndex, channelWeight in enumerate(weights):\n#            gradCam += channelWeight * gradLayerActivations[channelIndex, :, :]\n#        # This is a rough RELU truncation\n#        gradCam = np.maximum(gradCam, 0)\n#        # Resize it to the original image\n#        gradCam = cv2.resize(gradCam, (256, 1600))\n#        print(\"Size of gradCam is {0}\".format(gradCam.shape))\n#        print(gradCam)\n#        # Scale the GradCam Mask\n#        gradCam = gradCam - np.min(gradCam)\n#        gradCam = gradCam / np.max(gradCam)\n#        print(\"Size of gradCam is {0}\".format(gradCam.shape))\n#        return(gradCam)\n    \n#gradCamTestData=trainingX[0].reshape(1,3,256,1600).astype(np.float32)\n#gradCamTestDataTorch=Variable(torch.from_numpy(gradCamTestData))\n\n#grad_cam = GradCam(model,\"transferModelFeatures\",\"fc1\")\n#mask = grad_cam(gradCamTestDataTorch)\n    \n#plt.imshow(gradCamTestData.reshape(256,1600,3).astype(int))\n#plt.show()\n#plt.imshow(mask.reshape(256,1600))\n#plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}