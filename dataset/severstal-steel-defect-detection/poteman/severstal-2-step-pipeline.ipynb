{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"! python ../input/mlcomp/mlcomp/mlcomp/setup.py","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport cv2\nimport albumentations as A\nfrom tqdm import tqdm_notebook\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.jit import load\n\nfrom mlcomp.contrib.transform.albumentations import ChannelTranspose\nfrom mlcomp.contrib.dataset.classify import ImageDataset\nfrom mlcomp.contrib.transform.rle import rle2mask, mask2rle\nfrom mlcomp.contrib.transform.tta import TtaWrap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_se_resnext50_32x4d = \\\n    load('../input/severstal-mlcomp-catalyst-train-0-90672-offline/unet_se_resnext50_32x4d.pth').cuda()\nunet_mobilenet2 = load('../input/severstal-mlcomp-catalyst-train-0-90672-offline/unet_mobilenet2.pth').cuda()\nunet_resnet34 = load('../input/severstal-mlcomp-catalyst-train-0-90672-offline/unet_resnet34.pth').cuda()\n\n# unet_se_resnext50_32x4d = \\\n#     load('../input/severstal-mlcomp-catalyst-train-0-90672-offline/unet_se_resnext50_32x4d.pth')\n# unet_mobilenet2 = load('../input/severstal-mlcomp-catalyst-train-0-90672-offline/unet_mobilenet2.pth')\n# unet_resnet34 = load('../input/severstal-mlcomp-catalyst-train-0-90672-offline/unet_resnet34.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.listdir('../input/severstal-mlcomp-catalyst-train-0-90672-offline')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count_df.shape)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Remove test images without defects\n\nMost of the stuff below is hidden, since it's copied from my previous kernels."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def load_img(code, base, resize=True):\n    path = f'{base}/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    \n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"BATCH_SIZE = 64\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_imgs,\n        directory='../input/severstal-steel-defect-detection/test_images',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ntest_gen = create_test_gen()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_model = load_model('../input/severstal-predict-missing-masks/model.h5')\nremove_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_missing_pred = remove_model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)\n\ntest_imgs['allMissing'] = test_missing_pred\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_test_imgs = test_imgs[test_imgs['allMissing'] < 0.9996]\nprint(filtered_test_imgs.shape)\nfiltered_test_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`filtered_sub_df` contains all of the images with at least one mask. `null_sub_df` contains all the images with exactly 4 missing masks."},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_mask = sub_df['ImageId'].isin(filtered_test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(\n    lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\nfiltered_test_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\n# filtered_sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# step 2: severstal-mlcomp-catalyst-infer-0-90672"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model:\n    def __init__(self, models):\n        self.models = models\n    \n    def __call__(self, x):\n        res = []\n        x = x.cuda()\n        with torch.no_grad():\n            for m in self.models:\n                res.append(m(x))\n        res = torch.stack(res)\n        return torch.mean(res, dim=0)\n\nmodel = Model([unet_se_resnext50_32x4d, unet_mobilenet2, unet_resnet34])\n\ndef create_transforms(additional):\n    res = list(additional)\n    # add necessary transformations\n    res.extend([\n        A.Normalize(\n            mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n        ),\n        ChannelTranspose()\n    ])\n    res = A.Compose(res)\n    return res\n\nimg_folder = '/kaggle/input/severstal-steel-defect-detection/test_images'\nbatch_size = 2\nnum_workers = 0\n\n# Different transforms for TTA wrapper\ntransforms = [\n    [],\n    [A.HorizontalFlip(p=1)]\n]\n\ntransforms = [create_transforms(t) for t in transforms]\ndatasets = [TtaWrap(ImageDataset(img_folder=img_folder, transforms=t), tfms=t) for t in transforms]\nloaders = [DataLoader(d, num_workers=num_workers, batch_size=batch_size, shuffle=False) for d in datasets]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds = [0.5, 0.5, 0.5, 0.5]\nmin_area = [600, 600, 1000, 2000]\n\nres = []\n# Iterate over all TTA loaders\ntotal = len(datasets[0])//batch_size\nfor loaders_batch in tqdm_notebook(zip(*loaders), total=total):\n    preds = []\n    image_file = []\n    for i, batch in enumerate(loaders_batch):\n#         features = batch['features']\n        features = batch['features'].cuda()\n        p = torch.sigmoid(model(features))\n        # inverse operations for TTA\n        p = datasets[i].inverse(p)\n        preds.append(p)\n        image_file = batch['image_file']\n    \n    # TTA mean\n    preds = torch.stack(preds)\n    preds = torch.mean(preds, dim=0)\n    preds = preds.detach().cpu().numpy()\n    \n    # Batch post processing\n    for p, file in zip(preds, image_file):\n        file = os.path.basename(file)\n        # Image postprocessing\n        for i in range(4):\n            p_channel = p[i]\n            imageid_classid = file+'_'+str(i+1)\n            p_channel = (p_channel>thresholds[i]).astype(np.uint8)\n            if p_channel.sum() < min_area[i]:\n                p_channel = np.zeros(p_channel.shape, dtype=p_channel.dtype)\n            \n            res.append({\n                'ImageId_ClassId': imageid_classid,\n                'EncodedPixels': mask2rle(p_channel)\n            })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_sub_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((df.loc[df['ImageId_ClassId'].isin(list(null_sub_df[\"ImageId_ClassId\"])),'EncodedPixels'] != '').sum() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['ImageId_ClassId'].isin(list(null_sub_df[\"ImageId_ClassId\"])), 'EncodedPixels'] = ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)\t","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}