{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport glob\nfrom fastai.vision import *\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_train = '../input/severstal-steel-defect-detection/train_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_test = '../input/severstal-steel-defect-detection/test_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(path + 'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = df['ClassId'].hist(bins=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2 = df.groupby(['ImageId']).agg({'ClassId': lambda x: list(x),'EncodedPixels': lambda x: list(x)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2['ImageId'] = df_2.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2 = df_2.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2 = df_2[['ImageId', 'ClassId', 'EncodedPixels']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def func(x, y):\n    a = ['','','','']\n    for i, j in zip(x, y):\n        a[i-1] = j\n        \n    return a      \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2['EncodedPixels'] = df_2.apply(lambda x: func(x['ClassId'], x['EncodedPixels']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = open_image(path_train + df_2['ImageId'][5])\nimg.show(figsize=(20,10))\nprint(img.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Маски для тренировочной выборки(train_images) закодированы(Run Lenght Encode или RLE) - \"кодирование длины пробега от пикселя\". Данная кодировка содержит два значения: первое -начальная позиция(номер пикселя); второе - длина пробега от этого пикселя. \nПиксели нумеруются сверху вниз, затем слева направо: 1 - пиксель (1,1), 2 - пиксель (2,1) и т. д. \nПримеры:\nНапример значения «1 3» подразумевают начало пробега с пикселя (1,1)(включительно), длиною 3 пикселя, то есть пиксели(1,1); (1,2); (1,3).\n\nУказание значений «1 3 10 5» подразумевает, что пиксели 1,2,3,10,11,12,13,14 включены в маску. \n\nРазмер изображений тренировочной выборки 256(вертикаль) * 1600(горизонталь)\n\nДля значения 29102 5:\nстартовая позиция на пикселе: \nсмещенному вправо по нашему изображению на 29102 // 256 = 113 пикселей\nсмещенному вниз на 29102 % 256 = 174 пикселя.\nПолучаем позицию с индексами (173, 113), учитываем, что индексация у нас начинается с 0.\nДалее со стартовой позиции включаем в нашу маску ещё 4 пикселя вниз, итого 5 пикселей: \n(173, 112); (174, 112); (175, 112); (176, 112); (177, 112)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_decode_3(mask_rle:str, shape=(256, 1600))->NPArrayMask:\n    \"Return an image array from run-length encoded string `mask_rle` with `shape`.\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n    starts -= 1    # Отнимаем от всех стартовых значений 1 т.к. индексация с 0.\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint)\n    for a, b in zip(starts, ends): img[a:b] = 1\n    img = img.reshape(shape, order='F')\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def open_mask_rle_2(mask_rle:str, shape=(256, 1600))->ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode_3(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(-1, shape[0], shape[1])\n    #return ImageSegment(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_encode_3(img:NPArrayMask, shape=(256, 1600))->str:\n    \"Return run-length encoding string from `img`.\"\n    pixels = np.concatenate([[0], img.flatten(order='F') , [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2['EncodedPixels'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rle_decode_3(df_2['EncodedPixels'][1][2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageSegment(open_mask_rle_2(df_2['EncodedPixels'][1][2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = rle_decode_3(df_2['EncodedPixels'][1][2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rle_encode_3(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fn = path_train + df_2['ImageId'][5]\nimg = open_image(fn)\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = open_mask_rle_2(df_2['EncodedPixels'].iloc[5][3])\nImageSegment(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = open_mask_rle_2(df_2['EncodedPixels'].iloc[5][2])\nImageSegment(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['ImageId'] == 'db4867ee8.jpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2['EncodedPixels'].iloc[40]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['ImageId'] == '000f6bf48.jpg']['EncodedPixels'].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df_2[df_2['ImageId'] == '000f6bf48.jpg']['EncodedPixels']:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fn = path_train + df_2.index['db4867ee8.jpg']\nfn = path_train + '000f6bf48.jpg'\n#print(fn)\nimg = open_image(fn)\nshape = img.shape[-2:]\n#print(shape)\n#img = open_image(fn)\nfinal_mask = torch.zeros((1, *shape))\n#for i, rle in enumerate(df_2['EncodedPixels'].iloc[5]):\n#for i, rle in enumerate(df_2['EncodedPixels'].loc['db4867ee8.jpg']):  \nfor i, rle in enumerate(df_2[df_2['ImageId'] == '000f6bf48.jpg']['EncodedPixels'].item()):\n    #print(rle)\n    if isinstance(rle, str):\n        mask = open_mask_rle_2(rle)\n        #print(mask.shape)\n        final_mask += (i + 1) * mask\n#mask = open_mask_rle_2(df_train['EncodedPixels'].iloc[0])\nfinal_mask_2 = ImageSegment(final_mask)\n_,axs = plt.subplots(3,1, figsize=(20,10))\nimg.show(ax=axs[0], title='no mask')\nimg.show(ax=axs[1], y=final_mask_2, title='masked')\nfinal_mask_2.show(ax=axs[2], title='mask only', alpha=1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_y_fn(fn):\n    #print(fn)\n    #fn = fn.replace(path_train, '')\n    x = df_train[df_train['ImageId'] == fn]['EncodedPixels'].item()\n    #print('!')\n    return open_mask_rle_2(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_y_fn_mcl(fn):\n    #print(fn)\n    final_mask = torch.zeros((1, 256, 1600))\n    for i, rle in enumerate(df_2[df_2['ImageId'] == fn]['EncodedPixels'].item()):\n    #for i, rle in enumerate(df_2['EncodedPixels'].loc[fn]):    \n        if isinstance(rle, str):\n            mask = open_mask_rle_2(rle)\n            #print('mask=', mask.shape)\n            final_mask += (i + 1) * mask\n    return ImageSegment(final_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_y_fn_mcl('000f6bf48.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SegmentationLabelList(SegmentationLabelList):\n    def open(self, fn): return get_y_fn_mcl(fn)\n    \nclass SegmentationItemList(SegmentationItemList):\n    _label_cls = SegmentationLabelList","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list = (SegmentationItemList\n                .from_df(df_2, path_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#codes = ['0','1']\ntrain_list = (SegmentationItemList\n                .from_df(df_2, path_train)\n                .split_by_rand_pct()\n                .label_from_df(cols='ImageId', label_cls=SegmentationLabelList, classes=[0, 1, 2, 3, 4])\n                #.transform(get_transforms(), size=256,resize_method=ResizeMethod.SQUISH, tfm_y=True)\n                .transform(get_transforms(), size=(128, 800),resize_method=ResizeMethod.SQUISH, tfm_y=True)\n                #.transform(get_transforms(flip_vert=True), tfm_y=True)\n                .databunch(bs=10, num_workers=10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list.show_batch(rows=3, figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_func(input, target):\n    smooth = 0\n    input = input[:,1,:,:]\n    iflat = input.flatten().float()\n    tflat = target.flatten().float()\n    intersection = (iflat * tflat).sum()\n    return ((2. * intersection + smooth) /\n              (iflat.sum() + tflat.sum() + smooth))\n\ndef dice(input:Tensor, targs:Tensor, iou:bool=False)->Rank0Tensor:\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n,-1)\n    targs = targs.view(n,-1)\n    intersect = (input * targs).sum().float()\n    union = (input+targs).sum().float()\n    if not iou: return (2. * intersect / union if union > 0 else union.new([1.]).squeeze())\n    else: return intersect / (union-intersect+1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn = unet_learner(train_list, models.resnet18, pretrained=False, metrics=[dice], wd=1e-3, model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = unet_learner(train_list, models.resnet18, pretrained=False, metrics=[dice], wd=1e-3, model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_find(learn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,max_lr = 1e-2)    # 40","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_find(learn)\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(20,max_lr = slice(1e-3,1e-2))    # 40","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(20, max_lr = 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(20, max_lr = 1e-4) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.fit_one_cycle(20, max_lr = 1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.fit_one_cycle(20, max_lr = 1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.save('stage-1')\n#learn.export(\"/kaggle/working/steel-1.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('trained_model_1')\nlearn.export(\"/kaggle/working/trained_model_1.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = load_learner('/kaggle/working/', 'trained_model_1.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = unet_learner(train_list, models.resnet18, pretrained=False, metrics=[dice], wd=1e-3, model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = learn.load(\"trained_model_1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,max_lr = 1e-5)    # 40","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_lr(show_moms=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\nprint(len(submit))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.sort_values(by=['ImageId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir(path=path_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a = learn.predict(open_image(path_test + '86c1f219f.jpg'))[1].data.numpy()\na = rle_decode_3(df_2['EncodedPixels'][1][2])\nb = a.flatten(order='F')\nd = {1: '', 2: '', 3: '', 4: ''}\nfor start, count in zip (rle_encode_3(a).split(' ')[::2], rle_encode_3(a).split(' ')[1::2]):\n    #print(start)\n    #print(b[int(start)-1])\n    d[b[int(start)-1]] += str(start) + ' ' +  str(count) + ' '\nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[3] = '294661 251 294917 251 295173 251 295429 251 295685 251 295941 251 296197 251 296453 251 296709 251 296965 251 297221 251 297477 251'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = '86c1f219f.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_list = []\nfor i in d:\n    sub_list += [[img_name, i, d[i]]]\nsub_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_list = []\nfor img_name in files:\n    #print(img_name)\n    pred = learn.predict(open_image(path_test + img_name))[1].data.numpy()\n    print(Imagese)\n    #print(pred)\n    pred_fl = pred.flatten(order='F')\n    rle_enc = rle_encode_3(pred).split(' ')\n    #print(rle_enc)\n    d = {1: '', 2: '', 3: '', 4: ''}\n    for start, count in zip (rle_enc[::2], rle_enc[1::2]):\n        #print(start)\n        #print(pred_fl[int(start)-1])\n        d[pred_fl[int(start)-1]] += str(start) + ' ' +  str(count) + ' '\n        \n    for i in d:\n        sub_list += [[img_name, i, d[i]]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2['EncodedPixels'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2['EncodedPixels'].iloc[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = rle_decode_3(df_2['EncodedPixels'].iloc[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fl = pred.flatten(order='F')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rle_enc = rle_encode_3(pred).split(' ')\nrle_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {1: '', 2: '', 3: '', 4: ''}\nfor start, count in zip (rle_enc[::2], rle_enc[1::2]):\n    print(start)\n    print(pred_fl[int(start)-1])\n    d[pred_fl[int(start)-1]] += str(start) + ' ' +  str(count) + ' '","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = learn.predict(open_image(path_test + '289d347d9.jpg'))[1].data.numpy()\npred_fl = pred.flatten(order='F')\nrle_enc = rle_encode_3(pred).split(' ')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rle_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rle_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fl[55153+5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fl[2740-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fl[2616-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(sub_list, columns=['ImageId', 'EncodedPixels', 'ClassId'])\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = np.where(a != 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a[0][38][612]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count = len(files)\nresults = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_length(label_vec):\n    encode_list = encode(label_vec)\n    index = 1\n    class_dict = {}\n    for i in encode_list:\n        if i[1] != len(codes)-1:\n            if i[1] not in class_dict.keys():\n                class_dict[i[1]] = []\n            class_dict[i[1]] = class_dict[i[1]] + [index, i[0]]\n        index += i[0]\n    return class_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import groupby","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode(input_string):\n    return [(len(list(g)), k) for k,g in groupby(input_string)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"codes = ['0','1','2','3', '4'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, img in tqdm(enumerate(files)):\n    img_name = img\n    pred = learn.predict(open_image(path_test + img))[1].data.numpy().flatten()\n    class_dict = run_length(pred)\n    print(class_dict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, img in tqdm(enumerate(files)):\n    img_name = img\n    pred = learn.predict(open_image(path_test + img))[1].data.numpy().flatten()\n    class_dict = run_length(pred)\n    if len(class_dict) == 0:\n        for i in range(4):\n            results.append([img_name+ \"_\" + str(i+1), ''])\n    else:\n        for key, val in class_dict.items():\n            results.append([img_name + \"_\" + str(key+1), \" \".join(map(str, val))])\n        for i in range(4):\n            if i not in class_dict.keys():\n                results.append([img_name + \"_\" + str(i+1), ''])\n        \n        \n    if i%20==0:\n        print(\"\\r{}/{}\".format(i, test_count), end=\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = list(path_test.glob(\"**/*.jpg\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predictions(path_test, learn):\n    # predicts = get_predictions(path_test, learn)\n    learn.model.cuda()\n    files = list(path_test.glob(\"**/*.jpg\"))    #<---------- HERE\n    test_count = len(files)\n    results = []\n    for i, img in enumerate(files):\n        img_name = img.stem + '.jpg'\n        pred = learn.predict(open_image(img))[1].data.numpy().flatten()\n        class_dict = run_length(pred)\n        if len(class_dict) == 0:\n            for i in range(4):\n                results.append([img_name+ \"_\" + str(i+1), ''])\n        else:\n            for key, val in class_dict.items():\n                results.append([img_name + \"_\" + str(key+1), \" \".join(map(str, val))])\n            for i in range(4):\n                if i not in class_dict.keys():\n                    results.append([img_name + \"_\" + str(i+1), ''])\n        \n        \n        if i%20==0:\n            print(\"\\r{}/{}\".format(i, test_count), end=\"\")\n    return results    \n\nsub_list = get_predictions(path_test, learn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_list = (SegmentationItemList\n                .from_df(df_2, path_train)\n                .split_by_rand_pct()\n                .label_from_df(cols='ImageId', label_cls=SegmentationLabelList, classes=[0, 1, 2, 3, 4])\n                .transform(get_transforms(), size=256,resize_method=ResizeMethod.SQUISH, tfm_y=True)\n                #.transform(get_transforms(flip_vert=True), tfm_y=True)\n                .databunch(bs=10, num_workers=10))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}