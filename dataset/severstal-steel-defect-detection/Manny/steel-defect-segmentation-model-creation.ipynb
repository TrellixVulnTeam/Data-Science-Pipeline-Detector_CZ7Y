{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport time\nfrom random import randint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rleToMask(rleString,height,width):\n    rows,cols = height,width\n    rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n    rlePairs = np.array(rleNumbers).reshape(-1,2)\n    img = np.zeros(rows*cols,dtype=np.uint8)\n    for index,length in rlePairs:\n        index -= 1\n        img[index:index+length] = 1\n    img = img.reshape(cols,rows)\n    img = img.T\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DF = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/train.csv')\nDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showSegmentation(image,rle):\n    mask = rleToMask(rle,image.shape[0],image.shape[1])\n    plt.figure(figsize=(20,10))\n    plt.subplot(2,1,1)\n    plt.imshow(image)\n    plt.subplot(2,1,2)\n    plt.imshow(np.expand_dims(mask,axis=2)*image,cmap='gray')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(5):\n    img_name = DF[~DF.EncodedPixels.isna()].sample().ImageId_ClassId.values[0]\n    rlePixels = (str(DF[DF.ImageId_ClassId.str.contains(img_name)].EncodedPixels.values[0]))\n    img = plt.imread('/kaggle/input/severstal-steel-defect-detection/train_images/'+img_name[:-2])\n    print(img.shape)\n    showSegmentation(img,rlePixels)\n    plt.title('Segmentation for Class: '+img_name[-1])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LabelsToNumpyMasks(Labels,height,width):\n    Tensor = np.zeros((height,width),dtype=np.uint8)\n    for name,rle in Labels.values:\n        if str(rle) != 'nan':\n#             print(rle)\n            Tensor+=int(name[-1])*rleToMask(rle,height,width)\n        else:\n            pass\n    return Tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"   \nclass Masks(Dataset):\n\n    def __init__(self, csv_file, transform=None):\n        super(Masks,self).__init__()\n        self.csv = pd.read_csv(csv_file)\n        self.filenames = np.unique(self.csv.ImageId_ClassId.apply(lambda x: x[:-2]).values)\n        self.transform=transform\n        \n    def __len__(self):\n        \n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        \n        Labels = self.csv[self.csv.ImageId_ClassId.str.contains(self.filenames[idx])]\n        masks = LabelsToNumpyMasks(Labels,256,1600)\n        sample = {'name':self.filenames[idx], 'masks': masks}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample\n\ntheMasks = Masks('/kaggle/input/severstal-steel-defect-detection/train.csv')\nprint(len(theMasks))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = theMasks[randint(0,len(theMasks))]\n\nplt.figure(figsize=(20,10))\nplt.imshow(sample['masks'],cmap='winter')\nplt.title(sample['name'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! mkdir ../masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def noCollate(batch):\n    return batch[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maskLoader = DataLoader(theMasks,num_workers=28,shuffle=False,batch_size=1,collate_fn=noCollate)\n\nfor j,batch in enumerate(maskLoader):\n    np.save(os.path.join('/kaggle/masks/',batch[\"name\"]),batch[\"masks\"])\n    print(\"Completion: {}/{}\".format(j+1,len(maskLoader)),end='\\r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SteelDefectSegmentationDataset(Dataset):\n\n    def __init__(self, csv_file,\n                 root_dir,mask_dir,\n                 transform=None):\n        super(SteelDefectSegmentationDataset,self).__init__()\n        self.root_dir = root_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n        _, _, files = next(os.walk(self.root_dir))\n        self.filenames = files\n\n    def __len__(self):\n        \n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir,\n                                self.filenames[idx])\n        image = plt.imread(img_name)\n        masks_name = os.path.join(self.mask_dir,\n                                self.filenames[idx]+'.npy')\n        masks = np.load(masks_name)\n        sample = {'name':img_name,'image': image, 'masks': masks}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steel_dataset = SteelDefectSegmentationDataset(csv_file='/kaggle/input/severstal-steel-defect-detection/train.csv',\n                                               root_dir='/kaggle/input/severstal-steel-defect-detection/train_images/',\n                                               mask_dir='/kaggle/masks')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = steel_dataset[randint(0,len(steel_dataset))]\nplt.imshow(test[\"image\"])\nplt.show()\nplt.imshow(test[\"masks\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models.segmentation import deeplabv3_resnet101\nfrom torchvision.models import resnet101\ntheNet = deeplabv3_resnet101(num_classes=5).cuda()\nbackNet = deeplabv3_resnet101(pretrained=True).cuda()\nfor param in backNet.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theNet.backbone = backNet.backbone","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theNet.classifier.state_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretend = theNet(torch.randn(5,3,256,256).cuda())[\"out\"]\npretend.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(deeplabv3_resnet101(num_classes=5).cuda(),'/kaggle/working/ResDeepLabv3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.transforms import functional as F\nfrom torchvision import transforms as T\nfrom random import uniform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ToPIL(object):\n    def __call__(self, sample):\n        sample[\"image\"] = T.ToPILImage()(sample[\"image\"])\n        sample[\"masks\"] = T.ToPILImage()(sample[\"masks\"])\n        return sample\n    \nclass Resize(object):\n    def __init__(self,size):\n        self.size=size\n    def __call__(self, sample):\n        sample[\"image\"] = T.Resize(self.size,interpolation=2)(sample[\"image\"])\n        sample[\"masks\"] = T.Resize(self.size,interpolation=0)(sample[\"masks\"])\n        return sample\nclass RandomColorJitter(object):\n    def __call__(self, sample):\n        sample[\"image\"] = T.ColorJitter(0.5,0.5,0.5,0)(sample[\"image\"])\n        return sample\n\nclass Affine(object):\n    def __call__(self, sample):\n        rndAngle = uniform(-30,30)\n        rndTranslate = (uniform(0,sample[\"image\"].size[0]/3),\n                        uniform(0,sample[\"image\"].size[1]/3))\n        rndShear = [uniform(0,30) for _ in range(2)]\n        sample[\"image\"] = F.affine(sample[\"image\"],\n                                   angle=rndAngle,\n                                   translate=rndTranslate,\n                                   scale=1,\n                                   shear=rndShear)\n        sample[\"masks\"] = F.affine(sample[\"masks\"],\n                                   angle=rndAngle,\n                                   translate=rndTranslate,\n                                   scale=1,\n                                   shear=rndShear)\n        return sample\n\nclass HFlip(object):\n    def __call__(self, sample):\n        sample[\"image\"] = F.hflip(sample[\"image\"])\n        sample[\"masks\"] = F.hflip(sample[\"masks\"])\n        return sample\nclass VFlip(object):\n    def __call__(self, sample):\n        sample[\"image\"] = F.vflip(sample[\"image\"])\n        sample[\"masks\"] = F.vflip(sample[\"masks\"])\n        return sample\nclass Perspective(object):\n    def __call__(self,sample):\n        perp = T.RandomPerspective()\n        params = perp.get_params(sample[\"image\"].size[0],sample[\"image\"].size[1],0.5)\n        sample['image']=F.perspective(sample[\"image\"],*params,3)\n        sample['masks']=F.perspective(sample[\"masks\"],params[0],params[1],0)\n        return sample\n\nclass ToTensor(object):\n    def __call__(self, sample):\n        sample[\"image\"] = T.ToTensor()(sample[\"image\"])\n        sample[\"masks\"] = torch.LongTensor(np.array(sample[\"masks\"]))\n        return sample\n    \nclass Normalize(object):\n    def __call__(self, sample):\n        sample[\"image\"] = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(sample[\"image\"])\n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steel_dataset = SteelDefectSegmentationDataset(csv_file='/kaggle/input/severstal-steel-defect-detection/train.csv',\n                                               root_dir='/kaggle/input/severstal-steel-defect-detection/train_images/',\n                                               mask_dir='/kaggle/masks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 6\nprint(n)\ntest = steel_dataset[n]\nplt.figure(figsize=(20,6))\nplt.subplot(2,1,1)\nplt.imshow(test[\"image\"])\nplt.xticks(ticks=[]);plt.yticks(ticks=[])\nplt.subplot(2,1,2)\nplt.imshow(test[\"masks\"])\nplt.xticks(ticks=[]);plt.yticks(ticks=[])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = ToPIL()(steel_dataset[n])\n# def test_randomperspective(self):\n#     for _ in range(10):\n#         height = random.randint(24, 32) * 2\n#         width = random.randint(24, 32) * 2\n#         img = torch.ones(3, height, width)\n#         to_pil_image = transforms.ToPILImage()\n#         img = to_pil_image(img)\n#         perp = transforms.RandomPerspective()\n#         startpoints, endpoints = perp.get_params(width, height, 0.5)\n#         tr_img = F.perspective(img, startpoints, endpoints)\n#         tr_img2 = F.to_tensor(F.perspective(tr_img, endpoints, startpoints))\n#         tr_img = F.to_tensor(tr_img)\n#         assert img.size[0] == width and img.size[1] == height\n#         assert torch.nn.functional.mse_loss(tr_img, F.to_tensor(img)) + 0.3 > \\\n#             torch.nn.functional.mse_loss(tr_img2, F.to_tensor(img))\nperp=T.RandomPerspective()\nparams = perp.get_params(sample['image'].size[0],sample['image'].size[1],0.5)\nplt.imshow(sample['image'])\nplt.show()\nplt.imshow(F.perspective(sample[\"image\"],params[0],params[1],3))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(27,3))\nfor i in range(0,3):\n    test = Affine()(ToPIL()(steel_dataset[n]))\n    plt.subplot(2,3,i+1)\n    plt.imshow(test[\"image\"])\n    plt.xticks(ticks=[]);plt.yticks(ticks=[])\n    plt.subplot(2,3,i+4)\n    plt.imshow(test[\"masks\"])\n    plt.xticks(ticks=[]);plt.yticks(ticks=[])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(27,3))\nfor i in range(0,3):\n    test = Perspective()(ToPIL()(steel_dataset[n]))\n    plt.subplot(2,3,i+1)\n    plt.imshow(test[\"image\"])\n    plt.xticks(ticks=[]);plt.yticks(ticks=[])\n    plt.subplot(2,3,i+4)\n    plt.imshow(test[\"masks\"])\n    plt.xticks(ticks=[]);plt.yticks(ticks=[])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,3))\ntest = HFlip()(ToPIL()(steel_dataset[n]))\nplt.subplot(2,2,1)\nplt.imshow(test[\"image\"])\nplt.xticks(ticks=[]);plt.yticks(ticks=[])\nplt.subplot(2,2,3)\nplt.imshow(test[\"masks\"])\nplt.xticks(ticks=[]);plt.yticks(ticks=[])\n\ntest = VFlip()(ToPIL()(steel_dataset[n]))\nplt.subplot(2,2,2)\nplt.imshow(test[\"image\"])\nplt.xticks(ticks=[]);plt.yticks(ticks=[])\nplt.subplot(2,2,4)\nplt.imshow(test[\"masks\"])\nplt.xticks(ticks=[]);plt.yticks(ticks=[])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steel_dataset = SteelDefectSegmentationDataset(\n    csv_file='/kaggle/input/severstal-steel-defect-detection/train.csv',\n    root_dir='/kaggle/input/severstal-steel-defect-detection/train_images/',\n    mask_dir='/kaggle/masks/',\n    transform=T.Compose([ToPIL(),Resize((128,800)),\n                         T.RandomApply([T.RandomApply([RandomColorJitter(),\n                                                      Affine(),HFlip(),VFlip(),Perspective()],\n                                                     p=0.7)],\n                                       p=0.7)\n#                          ToTensor()\n                        ]))\ntrain_loader = torch.utils.data.DataLoader(steel_dataset, batch_size=1, \n                                           shuffle=True,num_workers=4,collate_fn=lambda x: x[0])\n\nfor idx,batch in enumerate(train_loader):\n    plt.figure(figsize=(20,10))\n    plt.subplot(2,1,1)\n    plt.imshow(batch[\"image\"])\n    plt.subplot(2,1,2)\n    plt.imshow(batch[\"masks\"])\n    plt.show()\n    if idx>3:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import SubsetRandomSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4\n\nTrainSet = SteelDefectSegmentationDataset(\n    csv_file='/kaggle/input/severstal-steel-defect-detection/train.csv',\n    root_dir='/kaggle/input/severstal-steel-defect-detection/train_images/',\n    mask_dir='/kaggle/masks/',\n    transform=T.Compose([ToPIL(),Resize((128,800)),\n                         T.RandomApply([T.RandomApply([RandomColorJitter(),\n                                                      Affine(),HFlip(),VFlip(),Perspective()],\n                                                     p=0.7)],\n                                       p=0.7),\n                         ToTensor(),Normalize()\n                        ]))\n\nValSet = SteelDefectSegmentationDataset(\n    csv_file='/kaggle/input/severstal-steel-defect-detection/train.csv',\n    root_dir='/kaggle/input/severstal-steel-defect-detection/train_images/',\n    mask_dir='/kaggle/masks/',\n    transform=T.Compose([ToPIL(),Resize((128,800)),\n                         ToTensor(),Normalize()\n                        ]))\nseed=42\ntrainSplit = 0.9\nindices = list(range(len(TrainSet)))\nnp.random.seed(seed)\nnp.random.shuffle(indices)\ntrainIndices,valIndices = indices[:int(trainSplit*len(TrainSet))],indices[int(trainSplit*len(TrainSet)):]\ntrain_loader = torch.utils.data.DataLoader(TrainSet, batch_size=batch_size, \n                                           shuffle=False,\n                                           num_workers=8,\n                                           pin_memory=1,\n                                           sampler=SubsetRandomSampler(trainIndices))\nval_loader = torch.utils.data.DataLoader(ValSet, batch_size=batch_size, \n                                           shuffle=False,\n                                         num_workers=8,\n                                         pin_memory=1,\n                                         sampler=SubsetRandomSampler(valIndices))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 1e-4\ntorch.cuda.empty_cache()\nlossFunc = torch.nn.CrossEntropyLoss()\noptim = torch.optim.SGD(filter(lambda param: param.requires_grad,theNet.parameters()),lr=LR)\nepochs = 30\nTrainingLosses = torch.zeros(epochs)\nValidationLosses = torch.zeros(epochs)\ncount = 1\nfor i in range(epochs):\n    print(' ')\n    sumLosses=torch.cuda.FloatTensor([0])\n    theNet = theNet.train()\n    for idx,batch in enumerate(train_loader):\n        batch['image'] = batch['image'].cuda()\n        batch['masks'] = batch['masks'].cuda()\n        pred = (theNet(batch['image']))[\"out\"]\n        loss = lossFunc(pred,batch['masks'])\n        loss.backward()\n        optim.step()\n        optim.zero_grad()\n        sumLosses+=loss.detach()\n        count+=1\n        print(' Training Completion: {}%'.\n              format(round((count)/(epochs*len(train_loader))*100,3)),end='\\r')\n        del pred, loss\n    print(' Mean Training Loss: {}, Epoch: {}'.format(np.round(sumLosses.detach().cpu().numpy()/len(train_loader),5),i+1))\n\n    print(' ')\n    TrainingLosses[i]=(sumLosses.cpu()/len(train_loader))\n    sumLosses=torch.cuda.FloatTensor([0])\n    theNet = theNet.eval()\n    with torch.no_grad():\n        for idx,batch in enumerate(val_loader):\n            batch['image'] = batch['image'].cuda()\n            batch['masks'] = batch['masks'].cuda()\n            pred = theNet(batch['image'])[\"out\"]\n            loss = lossFunc(pred,batch['masks'])\n            sumLosses+=loss.detach()\n            print(' Validation Completion: {}/{}'.\n                  format(idx+1,len(val_loader)),end='\\r')\n            del pred, loss\n\n    ValidationLosses[i]=(sumLosses.cpu()/len(val_loader))\n    print(' Mean Validation Loss: {}'.format(np.round(sumLosses.detach().cpu().numpy()/len(val_loader),5)))\n    print(' ')\n    torch.save(theNet.classifier.state_dict(),'/kaggle/working/ResDeepLabv3Headstate'+str(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Learning rate was: \"+str(LR))\nprint(\"Lowest Training Loss: {}\".format(np.array(TrainingLosses).min()))\nprint(\"Lowest Validation Loss: {}, at epoch: {}\".format(np.array(ValidationLosses).min(),np.array(ValidationLosses).argmin()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(TrainingLosses,'-b')\nplt.plot(ValidationLosses,'-r')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}