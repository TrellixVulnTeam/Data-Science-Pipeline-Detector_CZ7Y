{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torch.utils.data.sampler import SubsetRandomSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rleToMask(rleString,height,width):\n    rows,cols = height,width\n    rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n    rlePairs = np.array(rleNumbers).reshape(-1,2)\n    img = np.zeros(rows*cols,dtype=np.uint8)\n    for index,length in rlePairs:\n        index -= 1\n        img[index:index+length] = 1\n    img = img.reshape(cols,rows)\n    img = img.T\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DF = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/train.csv')\nDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showSegmentation(image,rle):\n    mask = rleToMask(rle,image.shape[0],image.shape[1])\n    plt.figure()\n    plt.imshow(image)\n    plt.figure()\n    plt.imshow(mask)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 5\nimg_name = DF[~DF.EncodedPixels.isna()].iloc[n,0][:-2]\nrlePixels = DF[~DF.EncodedPixels.isna()].iloc[n,1]\n\nshowSegmentation(plt.imread('/kaggle/input/severstal-steel-defect-detection/train_images/'+img_name),rlePixels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LabelsToNumpyMasks(Labels,height,width):\n    Tensor = np.zeros((height,width,len(Labels)),dtype=np.uint8)\n    for name,rle in Labels.values:\n        if str(rle) != 'nan':\n#             print(rle)\n            Tensor[:,:,int(name[-1])-1]=rleToMask(rle,height,width)\n        else:\n            pass\n    NoClass = (Tensor.sum(axis=2,keepdims=1)<1).astype(np.uint8)\n    TotalTensor = np.dstack((Tensor,NoClass))\n    return TotalTensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SteelDefectSegmentationDataset(Dataset):\n\n    def __init__(self, csv_file, root_dir, transform=None):\n        \n        self.segmentationRLE = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        _, _, files = next(os.walk(self.root_dir))\n        self.filenames = files\n\n    def __len__(self):\n        \n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir,\n                                self.filenames[idx])\n        image = plt.imread(img_name)\n        Labels = self.segmentationRLE[self.segmentationRLE.ImageId_ClassId.str.contains(self.filenames[idx])]\n        masks = LabelsToNumpyMasks(Labels,image.shape[0],image.shape[1])\n        sample = {'name':img_name,'image': image, 'masks': masks}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass ToTensor(object):\n    def __call__(self, sample):\n        image, masks = sample['image'], sample['masks']\n        # swap color axis because\n        # numpy image: H x W x C\n        # torch image: C X H X W\n        image = image.transpose((2, 0, 1))\n        masks = masks.transpose((2,0,1))\n        return {'name':sample['name'],\n                'image': torch.FloatTensor(image),\n                'masks': torch.argmax(torch.FloatTensor(masks),dim=0)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsteel_dataset = SteelDefectSegmentationDataset(csv_file='/kaggle/input/severstal-steel-defect-detection/train.csv',\n                                               root_dir='/kaggle/input/severstal-steel-defect-detection/train_images/',transform=ToTensor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class tinyUNet(torch.nn.Module):\n    def __init__(self,in_channels=3,\n                 filters1=64,filters2 = 128,filters3=256,\n                 out_classes=5,\n                 filter_size=3,Pools=4):\n        super(tinyUNet,self).__init__()\n        self.Conv1 = torch.nn.Sequential(\n            torch.nn.BatchNorm2d(in_channels),\n            torch.nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=filters1,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(\n                in_channels=filters1,\n                out_channels=filters1,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU())\n        self.Down1 = torch.nn.MaxPool2d(Pools)\n        self.Conv2 = torch.nn.Sequential(\n            torch.nn.BatchNorm2d(filters1),\n            torch.nn.Conv2d(\n                in_channels=filters1,\n                out_channels=filters2,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(\n                in_channels=filters2,\n                out_channels=filters2,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU())\n        self.Down2 = torch.nn.MaxPool2d(Pools)\n        self.Conv3 = torch.nn.Sequential(\n            torch.nn.BatchNorm2d(filters2),\n            torch.nn.Conv2d(\n                in_channels=filters2,\n                out_channels=filters3,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(\n                in_channels=filters3,\n                out_channels=filters3,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU())\n        self.Up1 = torch.nn.ConvTranspose2d(\n            in_channels=filters3,\n            out_channels=filters2,\n            kernel_size=Pools,\n            stride=Pools,\n            padding=0)\n        self.Conv4 = torch.nn.Sequential(\n            torch.nn.BatchNorm2d(filters2+filters2),\n            torch.nn.Conv2d(\n                in_channels=filters2+filters2,\n                out_channels=filters2,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(\n                in_channels=filters2,\n                out_channels=filters2,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU())\n        self.Up2 = torch.nn.ConvTranspose2d(\n            in_channels=filters2,\n            out_channels=filters1,\n            kernel_size=Pools,\n            stride=Pools,\n            padding=0)\n        self.Conv5 = torch.nn.Sequential(\n            torch.nn.BatchNorm2d(filters1+filters1),\n            torch.nn.Conv2d(\n                in_channels=filters1+filters1,\n                out_channels=filters1,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(\n                in_channels=filters1,\n                out_channels=filters1,\n                kernel_size = filter_size,\n                padding=(filter_size-1)//2,\n                stride=1),\n            torch.nn.ReLU())\n        self.Out = torch.nn.Conv2d(in_channels=filters1,\n                                   out_channels=out_classes,\n                                   kernel_size=1,\n                                   padding=0,\n                                   stride=1)\n        \n        \n    \n    def forward(self,Input):\n        self.Conv1Out = self.Conv1(Input)\n        self.Down1Out = self.Down1(self.Conv1Out)\n        self.Conv2Out = self.Conv2(self.Down1Out)\n        self.Down2Out = self.Down2(self.Conv2Out)\n        self.Conv3Out = self.Conv3(self.Down2Out)\n        self.Up1Out = self.Up1(self.Conv3Out)\n        self.Conv4Out = self.Conv4(torch.cat((self.Conv2Out,self.Up1Out),dim=1))\n        self.Up2Out = self.Up2(self.Conv4Out)\n        self.Conv5Out = self.Conv5(torch.cat((self.Conv1Out,self.Up2Out),dim=1))\n        self.Logit = self.Out(self.Conv5Out)\n        return self.Logit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomRotateTensor(object):\n    def __call__(self,sample):\n        image,masks = sample['image'],sample['masks']\n        \n        randomRotation = np.random.randint(0,6)\n        if randomRotation == 0:\n            return {'name':sample['name'],\n                    'image':image.flip(2).transpose(3,2),\n                    'masks':masks.flip(1).transpose(2,1)}\n        if randomRotation == 1:\n            return {'name':sample['name'],\n                    'image':image.transpose(3,2).flip(2),\n                    'masks':masks.transpose(2,1).flip(1)}\n        if randomRotation == 2:\n            return {'name':sample['name'],\n                    'image':image.flip(3),\n                    'masks':masks.flip(2)}\n        if randomRotation == 3:\n            return {'name':sample['name'],\n                    'image':image.flip(2),\n                    'masks':masks.flip(1)}\n        if randomRotation == 4:\n            return {'name':sample['name'],\n                    'image':image.flip(3).flip(2),\n                    'masks':masks.flip(2).flip(1)}\n        if randomRotation == 5:\n            return {'name':sample['name'],\n                    'image':image,\n                    'masks':masks}\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Rotator = RandomRotateTensor()\nbatch_size = 4\nvalidation_split = .1\n# Creating data indices for training and validation splits:\ndataset_size = len(steel_dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nnp.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(steel_dataset, batch_size=batch_size, \n                                           sampler=train_sampler,num_workers=batch_size)\nvalidation_loader = torch.utils.data.DataLoader(steel_dataset, batch_size=batch_size,\n                                                sampler=valid_sampler,num_workers=batch_size)\ntheNet = tinyUNet().to('cuda')\ntorch.cuda.empty_cache()\nLR = 5e-3\nlossFunc = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(theNet.parameters(),lr=LR)\nepochs = 10\nValidationLosses = []\ncount=1\nfor i in range(epochs):\n    print(' ')\n    for idx,batch in enumerate(train_loader):\n        batch['image'] = batch['image'].cuda()\n        batch['masks'] = batch['masks'].cuda()\n        rotBatch = Rotator(batch)\n        pred = theNet(rotBatch['image'])\n        loss = lossFunc(pred,rotBatch['masks'])\n        loss.backward()\n        optim.step()\n        optim.zero_grad()\n\n        print(' Training Completion: {}%'.\n              format(round((count)/(epochs*len(train_loader))*100,3)),end='\\r')\n        count+=1\n        del pred, loss\n    print(' ')\n    sumLosses=0\n    with torch.set_grad_enabled(False):\n        for j,batch in enumerate(validation_loader):\n            pred = theNet(batch['image'].to('cuda'))\n            loss = lossFunc(pred,batch['masks'].to('cuda'))\n            sumLosses+=loss.detach().cpu().numpy()\n            del pred, loss\n            print(' Validating: {}%'.format(round((j+1)/len(validation_loader)*100)),end='\\r')\n    ValidationLoss=sumLosses/len(validation_loader)\n    print(' Validation Loss: {}'.format(round(ValidationLoss,5)))\n    ValidationLosses.append(ValidationLoss)\n    torch.save(theNet.state_dict(),'/kaggle/working/miniUNet'+str(i))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(ValidationLosses)\nplt.show()\n\nprint('Validation Loss was lowest for epoch index: {}'.\n      format(np.argmin(np.array(ValidationLosses))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}