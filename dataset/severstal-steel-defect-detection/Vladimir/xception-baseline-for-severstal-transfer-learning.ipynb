{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\nfrom tensorflow.python.keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom skimage.color import gray2rgb\nimport tensorflow as tf\n\nimport keras\nfrom keras.layers import UpSampling2D, Conv2D, Activation, Conv2DTranspose\nfrom keras import Model\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras.applications.xception import preprocess_input\nfrom imgaug import augmenters as iaa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32 # 8 # 16 # 4 # 64 # 128 # 8\nEPOCHS = 80 # 95\nIMG_SIZE = 256\n\ntrain_dir = '../input/severstal-steel-defect-detection/train_images'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, list_ids, image_dir, batch_size=32,\n                 img_h=256, img_w=256, shuffle=False):\n        \n        self.list_ids = list_ids\n        self.image_dir = image_dir\n        self.batch_size = batch_size\n        self.img_h = img_h\n        self.img_w = img_w\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_ids)) / self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        list_ids_temp = [self.list_ids[k] for k in indexes]\n        # generate data\n        \n        X, y = self.__data_generation(list_ids_temp)\n#         X = self.augmentor(X)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.list_ids))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, list_ids_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n        y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n        \n        for idx, id in enumerate(list_ids_temp):\n            file_path =  os.path.join(self.image_dir, id)\n            \n            image = cv2.imread(file_path, 1)\n            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            \n            '''\n            image = self.__load_grayscale(file_path)\n            \n            # Store samples\n            image_resized = gray2rgb(image[:,:,0])\n            '''\n                        \n            mask = np.empty((self.img_h, self.img_w, 1))\n            \n            rle_name = id + '_' + '4'\n            rle = df_train[df_train['ImageId_ClassId'] == rle_name]['EncodedPixels'].values[0]\n            \n            class_mask = rle_to_mask(rle, width=1600, height=256) \n            class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n            mask = class_mask_resized\n            \n            X[idx,] = image_resized\n            y[idx,] = np.expand_dims(mask, -1)\n        \n#         X = self.augmentor(X)\n        \n        # normalize \n        X = X / 255\n        y = (y > 0).astype(int)\n            \n        return X, y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (self.img_w, self.img_h))\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def augmentor(self, images):\n        'Apply data augmentation'\n        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n        seq = iaa.Sequential(\n            [\n                iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n                iaa.Fliplr(),\n                iaa.Flipud(),\n                iaa.ElasticTransformation(alpha=50, sigma=5)\n                ],random_order=True\n        )\n        return seq.augment_images(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\nprint(len(df_train))\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'Only 4 class'\ndf_train = df_train[df_train['EncodedPixels'].notnull()].reset_index(drop=True)\ndf_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['ImageId'] = df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\nlistdir = df_train['ImageId'].values\ntrain, valid = train_test_split(listdir, train_size=0.8)\nprint(train[:2], valid[:2])\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_to_mask(rle_string, height, width):\n    \n    rows, cols = height, width\n    img = np.zeros(rows * cols, dtype=np.uint8)\n    if len(str(rle_string)) > 1:\n        rle_numbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1, 2)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n    else: img = np.zeros(cols*rows)\n    img = img.reshape(cols, rows)\n    img = img.T\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in DataGenerator(df_train['ImageId'], \n                          '../input/severstal-steel-defect-detection/train_images', \n                          batch_size=32, img_h=256, img_w=256, shuffle=True):\n    break\n    \nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(x[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(y[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'metric and loss function for evaluation'\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef loss_dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return -K.log((2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'load pretrained model'\nfrom keras.applications import Xception\nbase_model = Xception(weights=None, input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False)\nbase_model.load_weights('../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_out = base_model.output # (8, 8)\nconv1 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (base_out) # (8, 16, 16)\nup = UpSampling2D(8, interpolation='bilinear')(conv1) # (8, 128, 128)\nconv2 = Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same') (up) # (1, 256, 256)\nconv3 = Conv2D(1, (1, 1))(conv2)\nconv4 = Activation('sigmoid')(conv3)\n\nlr=1e-6 # 1e-4 # 1e-6 # 1e-5 # 1e-4 # 0.0001 # 1e-2 # 1e-3\nmodel = Model(input=base_model.input, output=conv4)\noptimizer = keras.optimizers.RMSprop(lr=lr) # keras.optimizers.Adam(lr=lr) # keras.optimizers.Adam(lr=lr, decay=1e-6) #  # , decay = 1e-6\nmodel.compile(optimizer=optimizer, loss=loss_dice_coef, metrics=[dice_coef]) # decay = 1e-6\n\n# model.summary()\n# for i, layer in enumerate(base_model.layers):\n#     print(\"{} {}\".format(i, layer.__class__.__name__))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(train, train_dir, batch_size=BATCH_SIZE, shuffle=True)\ntrain_size = len(train)\nprint(train_size)\n\nval_generator = DataGenerator(valid, train_dir, batch_size=BATCH_SIZE)\ntrain_size = len(valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use ModelCheckpoint and ReduceLROnPlateau callbacks. ModelCheckpoint monitors the loss metric  after each epoch and prints out whether the metric has improved. ReduceLROnPlateau reduces learning rate when a metric has stopped improving during a number of epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import *\n\n\nclass CyclicLR(Callback):\n    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n    The method cycles the learning rate between two boundaries with\n    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n    The amplitude of the cycle can be scaled on a per-iteration or \n    per-cycle basis.\n    This class has three built-in policies, as put forth in the paper.\n    \"triangular\":\n        A basic triangular cycle w/ no amplitude scaling.\n    \"triangular2\":\n        A basic triangular cycle that scales initial amplitude by half each cycle.\n    \"exp_range\":\n        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n        cycle iteration.\n    For more detail, please see paper.\n    \n    # Example\n        ```python\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., mode='triangular')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```\n    \n    Class also supports custom scaling functions:\n        ```python\n            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., scale_fn=clr_fn,\n                                scale_mode='cycle')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```    \n    # Arguments\n        base_lr: initial learning rate which is the\n            lower boundary in the cycle.\n        max_lr: upper boundary in the cycle. Functionally,\n            it defines the cycle amplitude (max_lr - base_lr).\n            The lr at any cycle is the sum of base_lr\n            and some scaling of the amplitude; therefore \n            max_lr may not actually be reached depending on\n            scaling function.\n        step_size: number of training iterations per\n            half cycle. Authors suggest setting step_size\n            2-8 x training iterations in epoch.\n        mode: one of {triangular, triangular2, exp_range}.\n            Default 'triangular'.\n            Values correspond to policies detailed above.\n            If scale_fn is not None, this argument is ignored.\n        gamma: constant in 'exp_range' scaling function:\n            gamma**(cycle iterations)\n        scale_fn: Custom scaling policy defined by a single\n            argument lambda function, where \n            0 <= scale_fn(x) <= 1 for all x >= 0.\n            mode paramater is ignored \n        scale_mode: {'cycle', 'iterations'}.\n            Defines whether scale_fn is evaluated on \n            cycle number or cycle iterations (training\n            iterations since start of cycle). Default is 'cycle'.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_lr=0.001,\n        max_lr=0.006,\n        step_size=2000.0,\n        mode=\"triangular\",\n        gamma=1.0,\n        scale_fn=None,\n        scale_mode=\"cycle\",\n    ):\n        super(CyclicLR, self).__init__()\n\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.step_size = step_size\n        self.mode = mode\n        self.gamma = gamma\n        if scale_fn == None:\n            if self.mode == \"triangular\":\n                self.scale_fn = lambda x: 1.0\n                self.scale_mode = \"cycle\"\n            elif self.mode == \"triangular2\":\n                self.scale_fn = lambda x: 1 / (2.0 ** (x - 1))\n                self.scale_mode = \"cycle\"\n            elif self.mode == \"exp_range\":\n                self.scale_fn = lambda x: gamma ** (x)\n                self.scale_mode = \"iterations\"\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        self.clr_iterations = 0.0\n        self.trn_iterations = 0.0\n        self.history = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None, new_step_size=None):\n        \"\"\"Resets cycle iterations.\n        Optional boundary/step size adjustment.\n        \"\"\"\n        if new_base_lr != None:\n            self.base_lr = new_base_lr\n        if new_max_lr != None:\n            self.max_lr = new_max_lr\n        if new_step_size != None:\n            self.step_size = new_step_size\n        self.clr_iterations = 0.0\n\n    def clr(self):\n        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n        if self.scale_mode == \"cycle\":\n            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n        else:\n            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(\n                self.clr_iterations\n            )\n\n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())\n\n    def on_batch_end(self, epoch, logs=None):\n\n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault(\"lr\", []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault(\"iterations\", []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n\n        K.set_value(self.model.optimizer.lr, self.clr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, # factor=0.1 #0.2\n                                      patience=8, min_lr=1e-5) # 1e-6 # patience=5  # min_lr=1e-5 # 0.000001 # 0.0001\n\ncyclic_lr = CyclicLR(\n                mode=\"triangular\",\n                base_lr=1e-6,\n                max_lr=1e-4,\n                step_size=8 * (train_size / BATCH_SIZE),\n            )\n\n# Add model checkpoint\ncheckpoint = ModelCheckpoint(\"model_out.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True)\n\nes = EarlyStopping(monitor=\"loss\", mode=\"min\", verbose=1, patience=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = model.fit_generator(generator=train_generator,\n                              validation_data=val_generator,\n                              epochs=EPOCHS,\n                              callbacks=[checkpoint, cyclic_lr],\n                              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# unfreeze the final set of CONV layers and make them trainable\nfor layer in base_model.layers[129:]: # 122:]: # 122 - 3 last Conv layers (Conv2D) # 126 - 2 last Conv layers (SeparableConv2D's) # 129\n    layer.trainable = True\n\n# lr=1e-6 #1e-2 # 1e-3 # 0.01 # 0.001\n# optimizer = keras.optimizers.RMSprop(lr=lr) # keras.optimizers.Adam(lr=lr) # keras.optimizers.Adam(lr=lr) #  # \nmodel.compile(optimizer=optimizer, loss=loss_dice_coef, metrics=[dice_coef]) # 0.0001\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n%%time\nhistory = model.fit_generator(generator=train_generator, \n                              epochs=80, #90, # 50, # 35, # 5 #EPOCHS,\n                              validation_data=val_generator,\n#                               steps_per_epoch=train_size//BATCH_SIZE,\n                              callbacks=[checkpoint, reduce_lr], # cyclic_lr], # [ checkpoint, es],\n                              verbose=1) #, shuffle=True)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\n\nplt.plot(np.arange(len(history.history['loss'])) + 1, history.history['loss'], label='loss')\nplt.plot(np.arange(len(history.history['val_loss'])) + 1, history.history['val_loss'], label='val_loss')\n\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x)\nplt.imshow(np.squeeze(pred[3] > 0.5).astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfiles=os.listdir(\"../input/severstal-steel-defect-detection/test_images/\")\nlen(testfiles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_img = []\nfor fn in tqdm_notebook(testfiles):\n        img = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+fn )\n        img = cv2.resize(img,(IMG_SIZE, IMG_SIZE))       \n        test_img.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npredict = model.predict(np.array(test_img))\nprint(len(predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npred_rle = []\nfor img in tqdm_notebook(predict):\n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<0.5] = 0\n    tmp[tmp>0] = 1\n    pred_rle.append(mask_to_rle(tmp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_t = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+ testfiles[4])\nplt.imshow(img_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_t = rle_to_mask(pred_rle[4], 256, 1600)\nplt.imshow(mask_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv( '../input/severstal-steel-defect-detection/sample_submission.csv', converters={'EncodedPixels': lambda e: ' '} )\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor fn, rle in zip(testfiles, pred_rle):\n    sub['EncodedPixels'][(sub['ImageId_ClassId'].apply(lambda x: x.split('_')[0]) == fn) & \\\n                        (sub['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4'))] = rle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_s = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+ sub['ImageId_ClassId'][47].split('_')[0])\nplt.imshow(img_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_s = rle_to_mask(sub['EncodedPixels'][47], 256, 1600)\nplt.imshow(mask_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}