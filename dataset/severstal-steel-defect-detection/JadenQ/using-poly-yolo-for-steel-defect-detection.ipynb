{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Poly-Yolo for steel defect detection\n### This [model](http://https://gitlab.com/irafm-ai/poly-yolo/-/tree/master/poly_yolo) can be used in objective detection and instance segmentation\nThanks IRAFM AI for creating this work, and also thanks the following notebooks as references.\n\nhttps://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda/notebook\n\nhttps://www.kaggle.com/rishabhiitbhu/unet-starter-kernel-pytorch-lb-0-88\n\nSegmentation problem to objective detection problem.","metadata":{}},{"cell_type":"markdown","source":"## Load data and other settings","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Custom files instruction\nyolo_anchors.txt and *yolo_classes.txt* should be customized according to your dataset\nThe yolo_anchor can be calculated using K-means in the following code(using *kmeans.py*) and add *yolo_classes.txt* by oneself, for this competition, the classes are '1,2,3,4'.","metadata":{}},{"cell_type":"code","source":"import sys\npackage_path = '../input/polyyolo/poly_yolo_simple/'\nsys.path.append(package_path)\npackage_path = '../input/polyyolo/'\nsys.path.append(package_path)\nimport poly_yolo_new as yolo\n# poly_yolo_new is different from poly_yolo only in the use of multi-gpu, new version disable it becuase of keras version\ninput_dir = \"../input/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\npd.set_option(\"display.max_rows\", 101)\nimport os\nprint(os.listdir(\"../input\"))\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 15\nimport seaborn as sns\nfrom collections import Counter\nfrom PIL import Image\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nfrom pathlib import Path\nimport cv2\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/severstal-steel-defect-detection/train.csv\")\nsample_df = pd.read_csv(\"../input/severstal-steel-defect-detection/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess training data and submission data to unify public&private board data","metadata":{}},{"cell_type":"code","source":"train_original = train_df.copy()\ndef trans_train(train_df):\n    train_format = []\n    for indexs, content in train_df.iterrows():\n        ImageId = content[0]\n        ClassId = content[1]\n        EncodedPixels = content[2]\n        classes = [1,2,3,4]\n        for class_ in classes:\n            name = str(ImageId) + '_' + str(class_)\n            val_name = str(ImageId) + '_' + str(ClassId)\n            if name == val_name:\n                pixel = EncodedPixels\n            else: pixel = ''\n            train_format.append([name, pixel])\n    train_df_new = pd.DataFrame(train_format, columns=['ImageId_ClassId', 'EncodedPixels'])\n    return train_df_new\n\nif len(train_df.columns) == 3:\n    train_df = trans_train(train_df)\nelse: print('continue')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check image data and visualize the masks","metadata":{}},{"cell_type":"code","source":"train_size_dict = defaultdict(int)\ntrain_path = Path(\"../input/severstal-steel-defect-detection/train_images/\")\n\nfor img_name in train_path.iterdir():\n    img = Image.open(img_name)\n    train_size_dict[img.size] += 1\n    \ntest_size_dict = defaultdict(int)\ntest_path = Path(\"../input/severstal-steel-defect-detection/test_images/\")\n\nfor img_name in test_path.iterdir():\n    img = Image.open(img_name)\n    test_size_dict[img.size] += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# color of masks\npalette = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n# anchor_mask size: all images are in this size\nwidth = 1600\nheight = 256\nclasses_num = 4\n\n# return the mask\ndef name_and_mask(start_idx, width, height, classes_num):\n    col = start_idx\n    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n\n    labels = train_df.iloc[col:col+4, 1]\n    mask = np.zeros((height, width, classes_num), dtype=np.uint8)\n\n    for idx, label in enumerate(labels.values):\n        if label is not '':\n            mask_label = np.zeros(width*height, dtype=np.uint8)\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            for pos, le in zip(positions, length):\n                mask_label[pos-1:pos+le-1] = 1\n            mask[:, :, idx] = mask_label.reshape(height, width, order='F')\n    return img_names[0], mask\n\ndef show_mask_image(col, width, height, classes_num):\n    name, mask = name_and_mask(col,width, height, classes_num)\n    img = cv2.imread(str(train_path / name))\n    fig, ax = plt.subplots(figsize=(15, 15))\n    # use 4 contours to category the 4 classes\n    for ch in range(4):\n        contours, _ = cv2.findContours(mask[:, :, ch], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n        for i in range(0, len(contours)):\n            cv2.polylines(img, contours[i], True, palette[ch], 2)\n    ax.set_title(name)\n    ax.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 4, figsize=(15, 5))\nfor i in range(4):\n    ax[i].axis('off')\n    ax[i].imshow(np.ones((50, 50, 3), dtype=np.uint8) * palette[i])\n    ax[i].set_title(\"class color: {}\".format(i+1))\nfig.suptitle(\"each class colors\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs = [12,16,20,24,32]\nfor idx in idxs:\n    show_mask_image(idx, width, height, classes_num)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using Kmeans to Create anchor files","metadata":{}},{"cell_type":"markdown","source":"#### From segmentation data to anchor data","metadata":{}},{"cell_type":"code","source":"name, mask = name_and_mask(12,width, height, classes_num)\nmask.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask -> width * height, only one number to indicate class\n# flat into one layer (according to the links above, we know that there is no case of overlap defects)\n\ndef mask_format(mask, width, height):\n#     mask_format = np.zeros(width*height, dtype=np.uint8)\n#     mask_format = mask_format.reshape(height, width, order='F')\n#     for i in range(height):\n#         for j in range(width):\n#             mask_format[i][j] = sum(mask[i][j])\n    mask_format1 = mask[:,:,0]\n    mask_format2 = mask[:,:,1]\n    mask_format3 = mask[:,:,2]\n    mask_format4 = mask[:,:,3]\n    return mask_format1, mask_format2, mask_format3, mask_format4\n\nmask_format1,mask_format2,mask_format3,mask_format4  = mask_format(mask, width, height)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# bbox = find_bbox(mask_format4)\n# for item in bbox:\n#     [x1,y1,x2,y2] = [item[0], item[1], item[0] + item[2], item[1] + item[3]]\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_bbox(mask):\n    _, labels, stats, centroids = cv2.connectedComponentsWithStats(mask.astype(np.uint8))\n    stats = stats[stats[:,4].argsort()]\n    return stats[:-1]\n\ndef draw_box(mask_format):\n    from  matplotlib import patches\n    ax = plt.axes()\n    plt.imshow(mask_format,cmap='bone')\n    bboxs = find_bbox(mask_format)\n    for j in bboxs: \n        rect = patches.Rectangle((j[0],j[1]),j[2],j[3],linewidth=1,edgecolor='r',facecolor='none')\n        ax.add_patch(rect)\n    plt.show() \n\n# find out what type of defect this image has\nprint('pixel number of 4 types of defects:')\nprint(sum(sum(mask_format1)),sum(sum(mask_format2)),sum(sum(mask_format3)),sum(sum(mask_format4)))\n\ndraw_box(mask_format4)\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load pretrained model","metadata":{}},{"cell_type":"code","source":"# model1 = yolo.YOLO(model_path='../input/polyyolo/poly_yolo.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}