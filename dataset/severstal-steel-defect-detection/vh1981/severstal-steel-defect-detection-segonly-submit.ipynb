{"cells":[{"metadata":{"id":"NIO8fcOCVWHO","colab_type":"text"},"cell_type":"markdown","source":"# Severstal: Steel Defect Detection - Segmentation Model Only - Submit\n\n### About this kernel:\n\n- This is 1-Pass Segmentation-only notebook.\n- 5 classification(0 ~ 3 defect, 4 non-defect) model\n\n\n"},{"metadata":{"id":"jHnupr5jFXEw","colab_type":"code","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":82},"outputId":"78803b07-e801-4c99-8236-82102170ddf4"},"cell_type":"code","source":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"id":"9-SVviVV5aQd","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"from pathlib import Path\nimport shutil\n\n\nINPUT_PATH = \"../input\"\n    \nBOOTSTRAP = False\n\nDF_TRAIN_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/train.csv\")\nDF_TEST_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/sample_submission.csv\")\n\nTRAIN_IMAGE_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/train_images\")\nTEST_IMAGE_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/test_images\")\nDATA_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection-data-files\")\n\nGENERATE_WEIGHTS = False\nUSE_CALLBACK = True\n\nEPOCHS = 16\nif BOOTSTRAP:\n    EPOCHS = 1\nCHANNELS = 3\n\nMODEL_NAME = \"model_single_segmentation.h5\"\n\ndata_dir_path = \"../input/severstal-steel-defect-detection-data-files\"\nif os.path.exists(data_dir_path):\n    for fname in os.listdir(data_dir_path):\n        filepath = os.path.join(data_dir_path, fname)\n        print(filepath)\n        if os.path.isfile(filepath):\n            if GENERATE_WEIGHTS == True:\n                if fname.find(\"h5\") > 0:\n                    continue\n                if fname.find(\"json\") > 0:\n                    continue\n            destfilepath = os.path.join(\"./\", fname)\n            print(\"copy file \", filepath, \" to \", destfilepath)\n            shutil.copy(filepath, destfilepath)\n                \n","execution_count":null,"outputs":[]},{"metadata":{"id":"FJhZK2NER240","colab_type":"text"},"cell_type":"markdown","source":"## EDA"},{"metadata":{"id":"RvkWfsLvCwL-","colab_type":"code","outputId":"7e47cfe1-40c2-4785-fe2c-75286e3e8ec5","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":"train_df = pd.read_csv(DF_TRAIN_PATH)\n'''\nmake ImageId / ClassId / hasMask\n'''\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1]) \ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","outputId":"15c61f32-fd09-4738-d1d6-7cde84a8e17a","trusted":true,"id":"DmxtnkFArIZR","colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":"# 이미지 중에 hasMask가 하나라도 있는 것을 구분하기 위해 ImageId로 정렬하고\n# sum을 적용한다. 숫자가 아닌 column은 적용시 사라진다.\n\nmask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","outputId":"5435fb0c-83f4-4d08-a6c9-d5522477d5b2","trusted":true,"id":"XGnG32JDsH-l","colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"8gaFz3sl9Hxf","colab_type":"text"},"cell_type":"markdown","source":"## RLE functions\n\npad & contour functions from https://www.kaggle.com/titericz/building-and-visualizing-masks"},{"metadata":{"id":"Ps4CvDXl9D_V","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    '''\n    rle: run-length as string formated (start length)\n    shape: (height, width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    height, width = input_shape[:2]\n    \n    mask= np.zeros(width * height).astype(np.uint8)\n    \n    \"\"\"    \n    RLE가 (시작점,길이)의 반복이므로, 짝수/홀수로 분리해서 시작점 배열과\n    길이 배열을 만든다.\n    s[1:] : 1부터 끝까지\n    s[1:][::2] : s[1:]배열에 2씩 건너뛰며 추출한 값들의 배열을 얻는다.\n    \"\"\"\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n    \n    for index, start in enumerate(starts):\n        begin = int(start - 1)\n        end = int(begin + lengths[index])        \n        mask[begin : end] = 1\n        \n    \"\"\"    \n    img의 pixel 순서는 좌측 세로줄부터 위에서 아래쪽으로 이어지므로 순서에 맞게\n    만들어서 넘겨야 한다.\n    width/height는 행과 열에 맞게 [height, width, ...] 로 만들어야 한다.\n\n    ex) width=4, height=3인 경우\n    \n    s = [1,2,3,4,5,6,7,8,9,10,11,12]\n        => 1,2,3이 좌측 첫번쩨 세로줄, 4,5,6은 두번째 줄\n\n    s.reshape(4,3) :\n    [[ 1  2  3]\n     [ 4  5  6]\n     [ 7  8  9]\n     [10 11 12]]\n\n    s.reshape(4,3).T :\n    [[ 1  4  7 10]\n     [ 2  5  8 11]\n     [ 3  6  9 12]]\n    \"\"\"\n    return mask.reshape(width, height).T\n\n# https://www.kaggle.com/titericz/building-and-visualizing-masks\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask \n\ndef build_masks(rles, input_shape):\n    depth = 5\n    masks = np.zeros((*input_shape, depth))\n\n    assert len(rles) == 4    \n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n\n    #print(\"masks.shape \", masks.shape)\n    m2 = np.sum(masks, axis=-1).astype('bool')\n    m2 = np.logical_not(m2).astype('int')\n    m2 = m2.reshape(input_shape[0], input_shape[1], 1)\n    \n    #print(\"masks.shape = \", masks.shape, \"m2.shape\",  m2.shape)\n    masks[:, :, 4] = m2.reshape(input_shape) #masks.shape =  (256, 1600, 5) m2.shape (256, 1600, 1)\n    \n    return masks #(256, 1600, 4)\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles\n","execution_count":null,"outputs":[]},{"metadata":{"id":"VkpJXP6I1C2D","colab_type":"code","outputId":"a312b4ec-9dca-4b3f-f699-a7654f8935eb","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"columns = 1\nrows = 8\nfig = plt.figure(figsize=(10,5 * rows))\ndf = train_df\nimport math\n\ngrp = mask_count_df['ImageId'].values\n\nax_idx = 1\nfor filename in grp:\n    if ax_idx > rows * columns * 2:\n        break\n    \n    subdf = df[df['ImageId'] == filename].reset_index()\n    row = ax_idx\n    col = 0\n    fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n\n    # show defect mask\n    img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, filename ))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    for _, row in subdf.iterrows():        \n        pixels = str(row['EncodedPixels'])\n        if pixels != 'nan' and len(pixels) > 10:\n            #print(row['EncodedPixels'], type(row['EncodedPixels']))\n            mask = rle2mask(row['EncodedPixels'], (256,1600))\n            mask = mask2pad(mask,pad=3)\n            mask = mask2contour(mask,width=4)\n            # print(img.shape, mask.shape)\n            classId = int(row['ClassId'])\n            img[mask == 1, classId % 3] = 255\n    plt.imshow(img)\n    ax_idx += 1\n\n    # show non-defect mask\n    fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n    img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, filename ))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    rles = subdf['EncodedPixels'].values # 1개의 이미지마다 4개씩 있음(대부분 비어있음)\n    masks = build_masks(rles, input_shape=(256,1600)) #(256, 1600, 4)\n\n    no_defect_mask = masks[:, :, 4] # set defect mask\n    # print(\"img.shape:\", img.shape)\n    # print(\"no_defect_mask.shape:\", no_defect_mask.shape)\n    # print(masks.shape, no_defect_mask.shape)\n    img[no_defect_mask == 1, 0] = 255\n\n    plt.imshow(img)\n    ax_idx += 1\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"kSkeZrJvPo3a","colab_type":"text"},"cell_type":"markdown","source":"\nkeras.utils.Sequence를 상속해서 custom DataGenerator를 생성한다.\n\n다음 메소드 구현이 필요하다.\n\n- def __len__(self):\n    - 1 epoch당 batch의 수\n- def __getitem__(self, index):\n    - 해당 index batch의 데이터(X, y)를 리턴한다.\n- def on_epoch_end(self):\n    - 각 epoch이 끝날 때마다 호출된다. "},{"metadata":{"id":"ppIl_nCcF-xQ","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=TRAIN_IMAGE_PATH,\n                 batch_size=32, dim=(256, 1600), n_channels=CHANNELS,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df # ImageId로 label(4 masks)을 가져올 때 사용한다.\n        self.list_IDs = list_IDs # df.index\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    ##########################################################\n    # DataGenerator Sub Methods:\n    ##########################################################\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n\n        # 갯수가 빠질듯.\n        ret = 0\n        if (len(self.list_IDs) % self.batch_size) > 0:\n            ret = int(len(self.list_IDs) / self.batch_size) + 1\n        else:\n            ret = int(np.floor(len(self.list_IDs) / self.batch_size))\n        \n        return ret\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        \"\"\"\n        batch 하나에 해당하는 데이터(train이면 X,y, predict면 X 만)를 만들어서 리턴한다.        \n        \"\"\"\n        # Generate indexes of the batch\n        start = index * self.batch_size\n        end = min(len(self.list_IDs), (index + 1) * self.batch_size)\n        #print(\"start/end = \", start, end)\n        #indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n        indexes = self.indexes[start : end]\n\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]        \n        #print(\"list_IDs_batch :\", list_IDs_batch)\n        X = self.__generate_X(list_IDs_batch)\n        # X.shape : (16, 256, 1600, 1)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n\n        \n    def on_epoch_end(self):        \n        'Updates indexes after each epoch'        \n        self.indexes = np.arange(len(self.list_IDs)) # 그냥 0 ~ n까지 배열\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    ##########################################################\n    \n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((len(list_IDs_batch), *self.dim, self.n_channels)) #(?, h, w, 채널수(1))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):            \n            im_name = self.df['ImageId'].loc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            #img = self.__load_grayscale(img_path)\n            img = self.__load_rgb(img_path)\n\n            #print(\"im_name\", im_name)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((len(list_IDs_batch), *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].loc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            # y값은 RLE를 읽고 mask로 만들어서 사용\n            rles = image_df['EncodedPixels'].values # 1개의 이미지마다 4개씩 있음(대부분 비어있음)\n            masks = build_masks(rles, input_shape=self.dim) #(256, 1600, 5)\n            \n            y[i, ] = masks\n        \n        return y #(batch_size, 256, 1600, 5)\n    \n    def __load_grayscale(self, img_path):\n        \"\"\"\n        load image as grayscale\n        \"\"\"\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.        \n        img = np.expand_dims(img, axis=-1) # [h, w] => [h, w, 1]\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check Generator works correctly."},{"metadata":{"id":"qMziBPwF1oXO","colab_type":"code","outputId":"600ae252-edd9-46b6-85e2-503381fe1106","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"TEST_INDEX = 18\n\n# TEST :\n\ndef test_DataGenerator_src(index = 0):\n    BATCH_SIZE = 16    \n    rows = BATCH_SIZE\n    columns = 1\n    \n    train_idx = non_missing_train_idx.index\n\n    fig = plt.figure(figsize=(16, BATCH_SIZE * 4))    \n\n    ax_idx = 1\n    for i in range(BATCH_SIZE):\n        if ax_idx > rows * columns * 2:\n            break\n\n        cur_row = mask_count_df.loc[train_idx[BATCH_SIZE * index + i]]\n        filename = cur_row['ImageId']\n        #print(train_idx[BATCH_SIZE * index + i], filename, cur_row['hasMask'])\n        image_df = train_df[train_df['ImageId'] == filename] # ImageId마다 4개씩 있음.\n        image_df = image_df.fillna(\"\")\n\n        fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n        img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, filename ))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        for _, row in image_df.iterrows():\n            #print(\"row['EncodedPixels']\", type(row['EncodedPixels']), row['EncodedPixels'])\n            if len(str(row['EncodedPixels'])) > 0 :\n                mask = rle2mask(row['EncodedPixels'], (256,1600))\n                mask = mask2pad(mask,pad=3)\n                mask = mask2contour(mask,width=4)\n                classId = int(row['ClassId'])\n                img[mask == 1, (classId - 1) % 3] = 255                \n        plt.imshow(img)\n        ax_idx += 1\n\n        fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n        img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, filename ))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        masks = build_masks(image_df['EncodedPixels'].values, input_shape=(256,1600))\n        non_defect_mask = masks[:, :, 4]\n        img[non_defect_mask > 0, 0] = 255\n        plt.imshow(img)\n        ax_idx += 1\n        \n    plt.show()\n    \ntest_DataGenerator_src(TEST_INDEX)","execution_count":null,"outputs":[]},{"metadata":{"id":"edERAYpkgHH7","colab_type":"code","outputId":"a3fe08b1-225f-46d0-e71c-191228592173","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"# TEST :\n\ndef test_DataGenerator(index = 0):\n    BATCH_SIZE = 16\n\n    rows = BATCH_SIZE\n    columns = 1    \n    \n    train_idx = non_missing_train_idx.index\n\n    fig = plt.figure(figsize=(16, 4 * BATCH_SIZE))\n\n    gen = DataGenerator(\n        train_idx,\n        df=mask_count_df,\n        target_df=train_df,\n        batch_size=BATCH_SIZE, \n        n_classes=5)\n\n    X, y = gen.__getitem__(index)\n\n    print(\"X.shape :\", X.shape)\n    print(\"y.shape :\", y.shape)    \n\n    ax_idx = 1\n    for i in range(BATCH_SIZE):\n        if ax_idx > rows * columns * 2:\n            break\n            \n        img = X[i]\n        img = img * 255\n        img = img.astype(int)\n\n        fig.add_subplot(rows * 2, columns, ax_idx).set_title(str(i))\n\n        for mask_index in range(4):\n            mask = y[i, :, :, mask_index]\n            mask = mask2pad(mask,pad=3)\n            mask = mask2contour(mask,width=4)\n            y[i, :, :, mask_index] = mask\n            k = y[i, :, :, mask_index]            \n            img[k == 1, mask_index % 3] = 255        \n        plt.imshow(img)\n        ax_idx += 1\n\n        fig.add_subplot(rows * 2, columns, ax_idx).set_title(str(i))        \n        img = X[i]\n        img = img * 255\n        img = img.astype(int)\n        no_defect_mask = y[i, :, :, 4]\n        img[no_defect_mask > 0, 0] = 255\n        plt.imshow(img)\n        ax_idx += 1\n        \n    plt.show()\n\n    \ntest_DataGenerator(TEST_INDEX)","execution_count":null,"outputs":[]},{"metadata":{"id":"jP7gNq9nGA7l","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"BATCH_SIZE = 8\n\ntrain_idx, val_idx = train_test_split(\n    mask_count_df.index, # 모든 파일을 입력으로 사용해야 하므로 non_missing_train_idx.index를 사용하지 않음\n    random_state=2019,\n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx,\n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE,\n    n_classes=5)\n\nval_generator = DataGenerator(\n    val_idx,\n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE,\n    n_classes=5)","execution_count":null,"outputs":[]},{"metadata":{"id":"Uet7yeHSGceE","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    print(y_true.shape, y_pred.shape)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"id":"uxiTA7TTTXpi","colab_type":"text"},"cell_type":"markdown","source":"## Modeling\n\nUNet 모델을 사용(base는 resnet34)해서 모델을 만든다.\n\n>input  : (256, 1600, 3) <br>\n>output : (256, 1600, 5)\n\ntrain 데이터를 보면 defect 영역은 겹치지 않는 것으로 보이므로 해당 문제를 각각의 pixel에 대한 classification 문제로 바꿔볼 수 있다.\n\n0/1/2/3의 defect 종류와 no_defect를 표현하는 mask까지 합쳐서 출력이 5개의 channel이 되도록 모델을 구성한다.\n\n\n\n\n\n\n\n"},{"metadata":{"id":"o3DNwYVGpiqF","colab_type":"code","outputId":"9ec70a85-f481-4d37-889f-24bc5b2bb7fb","colab":{"base_uri":"https://localhost:8080/","height":415},"trusted":true},"cell_type":"code","source":"# https://github.com/qubvel/segmentation_models\n\n# ! pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"id":"jqYKJ5S7VnYb","colab_type":"code","trusted":true,"outputId":"b5c52aaa-dcdf-401c-a09a-91f45689209d","colab":{"base_uri":"https://localhost:8080/","height":613}},"cell_type":"code","source":"# import segmentation_models as sm\n# from segmentation_models import Unet\n# import keras\n\n# def build_model():\n\n#     # class는 5가 되어야 하고, activation -> softmax, loss : cross entropy\n#     preprocess = sm.get_preprocessing('resnet34')\n#     model = Unet(backbone_name='resnet34', input_shape=(256,1600, 3), classes=5, activation='softmax')\n\n#     \"\"\"\n#     loss 함수를 교체해 가면서 테스트해볼 수 있다.\n#         - dice_loss\n#         - bce_dice_loss\n#     \"\"\"\n#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n#     print(\"Model Input => Output : \", model.input_shape, \" ======> \", model.output_shape)\n\n#     #model.summary()\n\n#     return model\n\n# model = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pretrained_model():\n    \"\"\"\n    get model with loaded weight & json model file\n    \"\"\"\n    model_json_file_name = MODEL_NAME.split('.')[0] + \".json\"\n    json_file = open(model_json_file_name, \"r\")\n    loaded_model_json = json_file.read()\n    json_file.close()\n    loaded_model = model_from_json(loaded_model_json)\n    loaded_model.load_weights(MODEL_NAME)\n    loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n    print(\"Loaded Model Input => Output : \", loaded_model.input_shape, \" ======> \", loaded_model.output_shape)\n    return loaded_model\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"omZfhyIFVpPX","colab_type":"code","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"41063467-785e-4eb7-e376-413efe591933"},"cell_type":"code","source":"# from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n\n# es = EarlyStopping(monitor='val_acc', min_delta=0, patience = 3, verbose=1, mode='max')\n\n# rl = ReduceLROnPlateau(monitor = 'val_acc', factor = 0.5, patience = 2,\n#                        min_lr=0.0000001,\n#                        verbose=1, \n#                        mode='max')\n\n# checkpoint = ModelCheckpoint(\n#     MODEL_NAME, \n#     monitor='val_acc',\n#     verbose=1,\n#     save_best_only=True,\n#     save_weights_only=False,\n#     mode='max')\n\n# if GENERATE_WEIGHTS:\n#     history = None\n    \n#     history = model.fit_generator(\n#         train_generator,\n#         validation_data=val_generator,\n#         callbacks=[es, rl, checkpoint],\n#         use_multiprocessing=False,\n#         workers=1,\n#         epochs=EPOCHS)\n    \n#     # save model as json file\n#     # weight is already stored by callback(checkpoint)\n#     model_json = model.to_json()\n#     model_json_file_name = MODEL_NAME.split('.')[0] + \".json\"\n#     with open(model_json_file_name, \"w\") as json_file: \n#         json_file.write(model_json)\n    \n#     hdf = pd.DataFrame(history.history)\n#     hdf[['loss', 'val_loss']].plot()\n#     hdf[['acc', 'val_acc']].plot()\n#     #hdf[['dice_coef', 'val_dice_coef']].plot()\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델로 train/submit 이미지로 inference해서 출력한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\n# model = build_model()\n# model.load_weights(MODEL_NAME)\nmodel = get_pretrained_model()\n\ncheck_df = mask_count_df.sample(10)\n\ngen = DataGenerator(\n        check_df.index,\n        df=mask_count_df,\n        target_df=train_df,\n        batch_size=BATCH_SIZE, \n        n_classes=5,\n        shuffle=False)\n\npredict = model.predict_generator(gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_one_hot(targets, nb_classes):\n    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n    return res.reshape(list(targets.shape)+[nb_classes])\n\n# pb = np.argmax(predict, axis=-1)\n# pc = get_one_hot(pb.reshape(-1), 5)\n# pd = pc.reshape(predict.shape)\n\ndef pred_to_onehot(pred):\n    retval = np.argmax(pred, axis=-1)\n    retval = get_one_hot(retval.reshape(-1), 5)\n    retval = retval.reshape(pred.shape)\n    return retval","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pred_to_onehot(predict)\n\nrows = 10\ncolumns = 1\n\nfig = plt.figure(figsize=(16, 4 * rows))\n\nax_idx=1\nfor index, bindex, in enumerate(check_df.index):\n    if ax_idx > rows * columns * 2:\n        break\n            \n    fname = check_df['ImageId'].loc[bindex]\n    image_df = train_df[train_df['ImageId'] == fname]\n\n    fig.add_subplot(rows * 2, columns, ax_idx).set_title(fname)\n    img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, fname ))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    ax_idx += 1\n\n    fig.add_subplot(rows * 2, columns, ax_idx).set_title(fname)\n    for mask_index in range(4):\n        mask = pred[index, :, :, mask_index]        \n        img[mask == 1, mask_index % 3] = 255\n    plt.imshow(img)\n    ax_idx += 1\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"yXmMa49ROzMs","colab_type":"text"},"cell_type":"markdown","source":"## Submission\n\ntest 이미지를 먼저 mask가 존재하는지 여부를 판별해주는 모델로 inference해서 mask가 모두 없는 이미지와 존재하는 이미지로 구분한다. <br>\n다음에 mask가 존재하는 것으로 예측된 이미지들을 위에서 훈련시킨 모델로 예측하여 mask를 생성한다."},{"metadata":{"id":"-TZKoLnI9SvB","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def get_test_imgs_df():\n    '''\n    이미지 파일 DataFrame 생성\n    '''\n    test_df = []\n    for fname in os.listdir(TEST_IMAGE_PATH):\n        test_df.append(fname)        \n\n    test_df = pd.DataFrame({'ImageId' : test_df, 'EncodedPixels' : ''})    \n    ret = test_df[['ImageId']].reset_index()\n    return ret\n\n\ndef get_test_df():\n    '''\n    이미지 mask DataFrame 생성\n    '''\n    test_df = []\n    for fname in os.listdir(TEST_IMAGE_PATH):\n        filepath = os.path.join(TEST_IMAGE_PATH, fname)    \n        if os.path.isfile(filepath):\n            for i in range(4):\n                img_cls = fname + \"_\" + str(i + 1)\n                test_df.append(img_cls)\n    \n    test_df = pd.DataFrame({'ImageId_ClassId' : test_df, 'EncodedPixels' : ''})\n    test_df['ImageId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n    test_df['ClassId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n    test_df['EncodedPixels'] = \"\"\n    test_df.reset_index()\n    \n    return test_df","execution_count":null,"outputs":[]},{"metadata":{"id":"F7UeAc4I4IBf","colab_type":"text"},"cell_type":"markdown","source":"mask의 픽셀 수가 일정 수 이하일 때에는 defect가 없는 것으로 판단한다.\n\n\nEncodedPixels 항목을 모두 비워놓는 submission이 LB 0.85 이상이 나오므로 false positive를 확실히 배재하는 것이 좋은 방법이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################################################################################\n# FIXME : TEST CODE:\n#######################################################################################\n\nfrom keras.backend import clear_session\nimport gc\n\ndef show_test_prediction_head(n=60):\n\n    # Reset Keras Session\n    def clear_memory():\n        clear_session()\n        for i in range(20):\n            gc.collect()\n\n    clear_memory()\n    TEST_BATCH_SIZE = n\n\n    test_df = get_test_df()\n    test_images_df = get_test_imgs_df()    \n\n    batch_idx = list(range(0, min(test_images_df.shape[0], TEST_BATCH_SIZE)))\n    print(\"running: \", 0, \" - \", min(test_images_df.shape[0], TEST_BATCH_SIZE))\n\n#     model = build_model()\n#     model.load_weights(MODEL_NAME)\n    model = get_pretrained_model()\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_images_df,\n        base_path = TEST_IMAGE_PATH,\n        target_df=test_df, #label mask를 만들 때 사용하는 DataFrame. mode = 'predict' 인 경우 필요없음.\n        mode = 'predict',\n        batch_size=TEST_BATCH_SIZE,\n        shuffle=False,\n        n_classes=5)\n\n    src_generator = DataGenerator(\n        batch_idx,\n        df=test_images_df,\n        base_path = TEST_IMAGE_PATH,\n        target_df=test_df,\n        batch_size=TEST_BATCH_SIZE,\n        shuffle=False,\n        n_classes=5)\n\n    X, _ = src_generator.__getitem__(0)\n    \n    # make prediction\n    predict = model.predict_generator(test_generator)\n    pred = pred_to_onehot(predict)\n\n    columns = 1\n    rows = TEST_BATCH_SIZE\n    fig = plt.figure(figsize=(12, 3 * rows))\n\n    ax_idx = 1\n    for i in range(rows):\n        if ax_idx > rows * columns:\n            break\n            \n        # add plot\n        fig.add_subplot(rows, columns, ax_idx).set_title(str(i))\n        \n        # source image\n        img = X[i]\n        img = img * 255\n        img = img.astype(int)    \n\n        # draw mask over image\n        for mask_index in range(4):\n            k = pred[i, :, :, mask_index]            \n            img[k == 1, mask_index % 3] = 255\n        plt.imshow(img)\n        ax_idx += 1\n\n    plt.show()\n\n# show_test_prediction_head()\n\n#######################################################################################","execution_count":null,"outputs":[]},{"metadata":{"id":"2g-CO8UBVuP7","colab_type":"code","trusted":true,"outputId":"fe35427e-1e62-4f6d-fd88-7a15585b71e4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"cell_type":"code","source":"from keras.backend import clear_session\nimport gc\n\n# Reset Keras Session\ndef clear_memory():\n    clear_session()\n    for i in range(20):\n        gc.collect()\n\nclear_memory()\n\nTEST_BATCH_SIZE = 100\ndf_submit = []\nMIN_MASK_PIXEL_THRESHOLD = 3500\n\ntest_df = get_test_df()\ntest_images_df = get_test_imgs_df()\n\n# 하나의 이미지마다 동일 크기의 5개 mask 이미지가 생성되기 때문에\n# 메모리 소비가 커서 나눠서 처리해야 한다.\nfor batch_start in range(0, test_images_df.shape[0], TEST_BATCH_SIZE):\n    batch_idx = list(range(batch_start, min(test_images_df.shape[0], batch_start + TEST_BATCH_SIZE)))\n    print(\"running: \", batch_start, \" - \", min(test_images_df.shape[0], batch_start + TEST_BATCH_SIZE))\n\n#     model = build_model()\n#     model.load_weights(MODEL_NAME)\n    model = get_pretrained_model()\n\n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_images_df,\n        base_path = TEST_IMAGE_PATH,\n        target_df=test_df,\n        mode = 'predict',\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        n_classes=5)\n    \n    predict = model.predict_generator(test_generator)\n    pred = pred_to_onehot(predict)\n\n    for index, bindex, in enumerate(batch_idx):\n        fname = test_images_df['ImageId'].loc[bindex]\n        image_df = test_df[test_df['ImageId'] == fname]\n\n        pred_masks = pred[index, ]\n        #print(\"pred_masks.shape :\", pred_masks.shape)\n\n        # threshold 이하 pixel 수는 모두 없앤다.\n        for mask_index in range(4):\n            pixelcnt = np.count_nonzero(pred_masks[:,:,mask_index])        \n            if pixelcnt < MIN_MASK_PIXEL_THRESHOLD:\n                pred_masks[:,:,mask_index] = 0\n\n        pred_masks = pred_masks[:, :, :-1] # drop non-defect mask values\n        pred_rles = build_rles(pred_masks)\n        image_df['EncodedPixels'] = pred_rles        \n        df_submit.append(image_df)\n    \n    clear_memory()\n\ndf_submit = pd.concat(df_submit)\nprint(df_submit.shape[0])\ndf_submit.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"_eU3u_f-EYAe","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"df_temp = df_submit\n\ndf_temp['maskPixelCount'] = df_temp['EncodedPixels'].map(str).apply(len)\ndf_temp = df_temp.sort_values(['maskPixelCount'], ascending=[False])\ndf_temp = df_temp.reset_index()\n\ncolumns = 1\nrows = 20\nfig = plt.figure(figsize=(20, 6 * rows))\n\nax_idx = 1\nfor index, row in df_temp.iterrows():\n    if ax_idx > rows * columns:\n        break\n\n    print(\"index:\", index, \"imageid\", row[\"ImageId\"], \"class\", row[\"ClassId\"])\n\n    filename = row['ImageId']\n    fig.add_subplot(rows, columns, ax_idx).set_title(filename)\n    img = cv2.imread(os.path.join(TEST_IMAGE_PATH, filename))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    mask = rle2mask(row['EncodedPixels'], (256,1600))\n    img[mask == 1, 0] = 255\n            \n    plt.imshow(img)\n    ax_idx += 1\n        \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit.head(20)","execution_count":null,"outputs":[]},{"metadata":{"id":"kNEhdwj0Enkc","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"df_submit[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Severstal: Steel Defect Detection - Segmentation Model Only","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}