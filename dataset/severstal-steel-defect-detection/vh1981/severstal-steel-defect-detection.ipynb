{"cells":[{"metadata":{"id":"NIO8fcOCVWHO","colab_type":"text"},"cell_type":"markdown","source":"# Severstal: Steel Defect Detection"},{"metadata":{"id":"HWiqbNv5SHXv","colab_type":"text"},"cell_type":"markdown","source":"Thanks for sharing :\nhttps://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline"},{"metadata":{"id":"dHCrhS4G4yyR","colab_type":"code","outputId":"520bd388-322b-497b-861c-d5249506cf5b","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":"import sys\nIN_COLAB = 'google.colab' in sys.modules\n!nvidia-smi -L","execution_count":null,"outputs":[]},{"metadata":{"id":"pE4BzBu148rq","colab_type":"code","outputId":"743aa182-ae72-42f4-9a40-313fc32ac8b6","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":"# colab에서 구동하는 경우 서버의 구글 드라이브 파일을 다운받는다.\n\nimport os\n#input.zip : https://drive.google.com/open?id=1Cb9kjJ40Sc7hs3TtDREGjdytH7479PKu\n#model.h5 : https://drive.google.com/open?id=1CnF0Ailc2s8ob0JieXrhTK4u1YEr_HaD\n#model_predict_missing_mask.h5 : https://drive.google.com/open?id=1Sr6D8utBeOEnQ3BUGEdCCwPkYiPfY_uM\n\ndef download_file_gd(file_id, fpathname, unzip=False):\n    from google_drive_downloader import GoogleDriveDownloader as gdd\n    if os.path.exists(fpathname) == False:\n        gdd.download_file_from_google_drive(file_id=file_id, dest_path=fpathname, unzip=unzip, showsize=False)\n    else:\n        print(fpathname, \": already downloaded\")\n\nfiles = {\n    \"1Cb9kjJ40Sc7hs3TtDREGjdytH7479PKu\" : \"./input/severstal-steel-defect-detection/input.zip\", \n    \"1CnF0Ailc2s8ob0JieXrhTK4u1YEr_HaD\" : \"./model.h5\", \n    \"1Sr6D8utBeOEnQ3BUGEdCCwPkYiPfY_uM\" : \"./input/severstal-steel-defect-detection-data-files/model_predict_missing_mask.h5\", \n}\n\nif IN_COLAB:\n    for f in files:\n        print(f, files[f])\n        download_file_gd(file_id=f, fpathname=files[f], unzip=(files[f].find(\".zip\") >= 0))\n        \n    # unzip train/test zip file\n    import zipfile\n    zipfile.ZipFile(\"./input/severstal-steel-defect-detection/train_images.zip\").extractall(\"./input/severstal-steel-defect-detection/train_images\")\n    zipfile.ZipFile(\"./input/severstal-steel-defect-detection/test_images.zip\").extractall(\"./input/severstal-steel-defect-detection/test_images\")        \n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"jHnupr5jFXEw","colab_type":"code","trusted":true,"outputId":"6aa3da03-2b53-40a2-c819-0470e00ac089","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"id":"9-SVviVV5aQd","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"from pathlib import Path\nimport shutil\n\n#sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n\nINPUT_PATH = \"./input\"\nif IN_COLAB == False:\n    INPUT_PATH = \"../input\"\n\nDF_TRAIN_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/train.csv\")\nDF_TEST_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/sample_submission.csv\")\n\nTRAIN_IMAGE_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/train_images\")\nTEST_IMAGE_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection/test_images\")\nDATA_PATH = os.path.join(INPUT_PATH, \"severstal-steel-defect-detection-data-files\")\n\nGENERATE_WEIGHTS = True\n\nEPOCHS = 12\n\nUSE_CALLBACK = True\n    \nif IN_COLAB == False:    \n    data_dir_path = \"../input/severstal-steel-defect-detection-data-files\"\n    if os.path.exists(data_dir_path):\n        for fname in os.listdir(data_dir_path):\n            filepath = os.path.join(data_dir_path, fname)\n            print(filepath)\n            if os.path.isfile(filepath):\n                if GENERATE_WEIGHTS == True:\n                    if fname.find(\"h5\") > 0:\n                        continue\n                destfilepath = os.path.join(\"./\", fname)\n                print(\"copy file \", filepath, \" to \", destfilepath)\n                shutil.copy(filepath, destfilepath)\n                \n","execution_count":null,"outputs":[]},{"metadata":{"id":"RvkWfsLvCwL-","colab_type":"code","outputId":"e6b0dba6-ed81-4bae-fffa-e1fd6a10dbbf","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":"train_df = pd.read_csv(DF_TRAIN_PATH)\n'''\nimage 파일명과 ClassId가 _로 연결되어 있어서 분리해서 별도 column으로 만든다.\n'''\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"oSLgN60II-_w","colab_type":"code","outputId":"b65a280f-7267-4e39-e9c1-7fa3b3b8a971","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":"# 이미지 중에 hasMask가 하나라도 있는 것을 구분하기 위해 ImageId로 정렬하고\n# sum을 적용한다. 숫자가 아닌 column은 적용시 사라진다.\n\nmask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"jXjHQUQdlclA","colab_type":"code","outputId":"f0be2a6e-3374-476c-f604-03eda6e1755c","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"8gaFz3sl9Hxf","colab_type":"text"},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"id":"Ps4CvDXl9D_V","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    '''\n    rle: run-length as string formated (start length)\n    shape: (height, width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    height, width = input_shape[:2]\n    \n    mask= np.zeros(width * height).astype(np.uint8)\n    \n    \"\"\"    \n    RLE가 (시작점,길이)의 반복이므로, 짝수/홀수로 분리해서 시작점 배열과\n    길이 배열을 만든다.\n    s[1:] : 1부터 끝까지\n    s[1:][::2] : s[1:]배열에 2씩 건너뛰며 추출한 값들의 배열을 얻는다.\n    \"\"\"\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n    \n    for index, start in enumerate(starts):\n        begin = int(start - 1)\n        end = int(begin + lengths[index])        \n        mask[begin : end] = 1\n        \n    \"\"\"    \n    img의 pixel 순서는 좌측 세로줄부터 위에서 아래쪽으로 이어지므로 순서에 맞게\n    만들어서 넘겨야 한다.\n    width/height는 행과 열에 맞게 [height, width, ...] 로 만들어야 한다.\n\n    ex) width=4, height=3인 경우\n    \n    s = [1,2,3,4,5,6,7,8,9,10,11,12]\n        => 1,2,3이 좌측 첫번쩨 세로줄, 4,5,6은 두번째 줄\n\n    s.reshape(4,3) :\n    [[ 1  2  3]\n     [ 4  5  6]\n     [ 7  8  9]\n     [10 11 12]]\n\n    s.reshape(4,3).T :\n    [[ 1  4  7 10]\n     [ 2  5  8 11]\n     [ 3  6  9 12]]\n    \"\"\"\n    return mask.reshape(width, height).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)    \n    \n    return masks #(256, 1600, 4)\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles\n","execution_count":null,"outputs":[]},{"metadata":{"id":"YscHYz27QLXH","colab_type":"text"},"cell_type":"markdown","source":"train 이미지의 defect를 표시한다.<br>\n한 이미지 당 4개 class의 defect mask가 있다. <br>\nclass마다 RGB값을 max로 해서 출력한다.(3색이므로 부득이하게 class 1과 4는 동일하게 함)"},{"metadata":{"id":"DgVG86y1Ov1U","colab_type":"code","outputId":"a1ea1b5f-dced-430e-9057-421bc45c0a0f","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"cell_type":"code","source":"columns = 1\nrows = 10\nfig = plt.figure(figsize=(20,80))\ndf = train_df[train_df['hasMask']] #mask가 있는 것만 추린다.\n\ndf_maskCnt = pd.DataFrame({'maskCount' : df.groupby('ImageId').size()})\ndf = pd.merge(df, df_maskCnt, on=\"ImageId\")\ndf = df[df['maskCount'] > 1]\ndf = df.sort_values(by='maskCount', ascending=False) # 최대한 valid한 mask가 많은 것을 보여주도록\n\ngrp = df.groupby('ImageId')\n\nax_idx = 1\nfor filename, g in grp:\n    if ax_idx > rows * columns * 2:\n        break\n    \n    subdf = df[df['ImageId'] == filename].reset_index()\n    row = ax_idx\n    col = 0\n\n    fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n    img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, filename ))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n    \n    plt.imshow(img)\n    \n    ax_idx += 1\n    fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n\n    for _, row in subdf.iterrows():\n        mask = rle2mask(row['EncodedPixels'], (256,1600))\n        classId = int(row['ClassId'])                \n        img[mask == 1, classId % 3] = 255        \n            \n    plt.imshow(img)\n    ax_idx += 1\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"kSkeZrJvPo3a","colab_type":"text"},"cell_type":"markdown","source":"\nkeras.utils.Sequence를 상속해서 Custom DataGenerator를 생성한다.\n\n다음 메소드 구현이 필요하다.\n\n    def __len__(self):\n        1 epoch당 batch의 수\n    def __getitem__(self, index):\n        해당 index batch의 데이터(X, y)를 리턴한다.\n    def on_epoch_end(self):\n        각 epoch이 끝날 때마다 호출된다. "},{"metadata":{"id":"ppIl_nCcF-xQ","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=TRAIN_IMAGE_PATH,\n                 batch_size=32, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs # df.index\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    ##########################################################\n    # DataGenerator Sub Methods:\n    ##########################################################\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n\n        # 갯수가 빠질듯.\n        ret = 0\n        if (len(self.list_IDs) % self.batch_size) > 0:\n            ret = int(len(self.list_IDs) / self.batch_size) + 1\n        else:\n            ret = int(np.floor(len(self.list_IDs) / self.batch_size))\n\n        #print(\"ret=\", ret)\n        return ret\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        \"\"\"\n        batch 하나에 해당하는 데이터(train이면 X,y, predict면 X 만)를 만들어서 리턴한다.        \n        \"\"\"\n        # Generate indexes of the batch\n        start = index * self.batch_size\n        end = min(len(self.list_IDs), (index + 1) * self.batch_size)\n        #print(\"start/end = \", start, end)\n        #indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n        indexes = self.indexes[start : end]\n\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]        \n        #print(\"list_IDs_batch :\", list_IDs_batch)\n        X = self.__generate_X(list_IDs_batch)\n        # X.shape : (16, 256, 1600, 1)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n\n        \n    def on_epoch_end(self):        \n        'Updates indexes after each epoch'        \n        self.indexes = np.arange(len(self.list_IDs)) # 그냥 0 ~ n까지 배열\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    ##########################################################\n    \n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((len(list_IDs_batch), *self.dim, self.n_channels)) #(?, h, w, 채널수(1))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):            \n            im_name = self.df['ImageId'].loc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_grayscale(img_path)           \n\n            #print(\"im_name\", im_name)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((len(list_IDs_batch), *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].loc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            # y값은 RLE를 읽고 mask로 만들어서 사용\n            rles = image_df['EncodedPixels'].values # 1개의 이미지마다 4개씩 있음(대부분 비어있음)\n            masks = build_masks(rles, input_shape=self.dim) #(256, 1600, 4)\n            \n            y[i, ] = masks\n        \n        return y #(batch_size, 256, 1600, 4)\n    \n    def __load_grayscale(self, img_path):\n        \"\"\"\n        이미지를 gray-scale로 읽어서 돌려준다.\n        \"\"\"\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.        \n        img = np.expand_dims(img, axis=-1) # [h, w] => [h, w, 1]\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"id":"_WbSSgleWCRW","colab_type":"code","outputId":"af49bc72-c4f2-409d-b9c8-c2fccf21ba51","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"non_missing_train_idx.index\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"qMziBPwF1oXO","colab_type":"code","outputId":"ef07c49b-04df-48f5-f76f-d8b50138e174","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"TEST_INDEX = 18\n\n\n# TEST :\n\ndef test_DataGenerator_src(index = 0):\n    BATCH_SIZE = 16\n    \n    train_idx = non_missing_train_idx.index\n\n    fig = plt.figure(figsize=(20,80))\n\n    columns = 1\n    rows = BATCH_SIZE\n\n    ax_idx = 1\n    for i in range(BATCH_SIZE):\n        if ax_idx > rows * columns:\n            break\n\n        cur_row = mask_count_df.loc[train_idx[BATCH_SIZE * index + i]]\n        filename = cur_row['ImageId']\n        print(train_idx[BATCH_SIZE * index + i], filename, cur_row['hasMask'])\n        image_df = train_df[train_df['ImageId'] == filename] # ImageId마다 4개씩 있음.\n        image_df = image_df.fillna(\"\")\n\n        fig.add_subplot(rows, columns, ax_idx).set_title(filename)\n        img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, filename ))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        for _, row in image_df.iterrows():\n            #print(\"row['EncodedPixels']\", type(row['EncodedPixels']), row['EncodedPixels'])\n            if len(str(row['EncodedPixels'])) > 0 :\n                mask = rle2mask(row['EncodedPixels'], (256,1600))\n                classId = int(row['ClassId'])\n                img[mask == 1, (classId - 1) % 3] = 255\n                \n        plt.imshow(img)\n        ax_idx += 1\n        \n    plt.show()\n    \ntest_DataGenerator_src(TEST_INDEX)","execution_count":null,"outputs":[]},{"metadata":{"id":"edERAYpkgHH7","colab_type":"code","outputId":"c31a2982-c142-42a4-8cf3-3d56b98335a6","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"# TEST :\n\ndef test_DataGenerator(index = 0):\n    BATCH_SIZE = 16\n    \n    train_idx = non_missing_train_idx.index    \n\n    fig = plt.figure(figsize=(20,80))\n\n    gen = DataGenerator(\n        train_idx,\n        df=mask_count_df,\n        target_df=train_df,\n        batch_size=BATCH_SIZE, \n        n_classes=4,\n        shuffle=False)\n\n    X, y = gen.__getitem__(index)\n\n    print(\"X.shape :\", X.shape)\n    print(\"y.shape :\", y.shape)\n\n    columns = 1\n    rows = BATCH_SIZE\n\n    ax_idx = 1\n    for i in range(BATCH_SIZE):\n        if ax_idx > rows * columns:\n            break\n            \n        img = X[i].reshape(X[i].shape[0], X[i].shape[1])\n        img = img * 255\n        img = img.astype(int)\n        img = np.stack((img, img, img), axis=2)    \n\n        fig.add_subplot(rows, columns, ax_idx).set_title(str(i))\n\n        for mask in range(4):\n            k = y[i, :, :, mask]\n            #print(\"k.shape\", k.shape)\n            img[k == 1, mask % 3] = 255\n                \n        plt.imshow(img)\n        ax_idx += 1\n        \n    plt.show()\n\n    \ntest_DataGenerator(TEST_INDEX)","execution_count":null,"outputs":[]},{"metadata":{"id":"jP7gNq9nGA7l","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019,\n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx,\n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE,\n    n_classes=4\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"Uet7yeHSGceE","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    print(y_true.shape, y_pred.shape)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"id":"uxiTA7TTTXpi","colab_type":"text"},"cell_type":"markdown","source":"   ### build model"},{"metadata":{"id":"jqYKJ5S7VnYb","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def build_model(input_shape):\n    \"\"\"\n    input : [batch_size, h, w, 1] 그레이스케일 이미지\n    output : [batch_size, h, w, 4] 4 defect mask (class 1~4)\n    \"\"\"\n    inputs = Input(input_shape)\n\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n    \n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    print(\"u6:\", u6.shape, \"c5:\", c5.shape)\n        \n    # u6 : (?, ?, ?, 64)  c5 : (?, 16, 100, 64)\n    u6 = concatenate([u6, c5]) # axis가 지정되어 있지 않으면 마지막 dim에 붙는다.\n    # u6 : (?, 16, 100, 128)\n\n    print(\"u6 after:\", u6.shape, \"c5:\", c5.shape)\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4]) # channel이 64가 된다.\n    c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3]) # channel=64\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2]) # channel=32\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3) # channel=16\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n    # y의 channel이 4이므로 출력 채널도 4로 맞춘다. 크기는 입력과 동일하게 한다.\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"omZfhyIFVpPX","colab_type":"code","outputId":"c33a3f80-7428-49fe-965d-a0e294be710c","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"cell_type":"code","source":"model = build_model((256, 1600, 1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"LwugBnBcVrH4","colab_type":"code","trusted":true,"outputId":"e9bdda76-daf7-44bb-8f78-915116c4727d","colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n\nes = EarlyStopping(monitor='val_dice_coef', min_delta=0, patience = 3, verbose=1, mode='max')\n\nrl = ReduceLROnPlateau(monitor = 'val_dice_coef', factor = 0.5, patience = 2,\n                       min_lr=0.0000001,\n                       verbose=1, \n                       mode='max')\n\ncheckpoint = ModelCheckpoint(\n    './model.h5', \n    monitor='val_dice_coef',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='max'\n)\n\nif GENERATE_WEIGHTS:\n    history = None\n    if USE_CALLBACK:\n        history = model.fit_generator(\n            train_generator,\n            validation_data=val_generator,\n            callbacks=[es, rl, checkpoint],\n            use_multiprocessing=False,\n            workers=1,\n            epochs=EPOCHS)\n    else :\n        history = model.fit_generator(\n            train_generator,\n            validation_data=val_generator,\n            callbacks=[checkpoint],\n            use_multiprocessing=False,\n            workers=1,\n            epochs=10)\n    \n    hdf = pd.DataFrame(history.history)\n    hdf[['loss', 'val_loss']].plot()\n    hdf[['dice_coef', 'val_dice_coef']].plot()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"yXmMa49ROzMs","colab_type":"text"},"cell_type":"markdown","source":"## Submission\n\ntest 이미지를 먼저 mask가 존재하는지 여부를 판별해주는 모델로 inference해서 mask가 모두 없는 이미지와 존재하는 이미지로 구분한다. <br>\n다음에 mask가 존재하는 것으로 예측된 이미지들을 위에서 훈련시킨 모델로 예측하여 mask를 생성한다."},{"metadata":{"id":"-TZKoLnI9SvB","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"def get_test_imgs_df():\n    '''\n    Test 이미지 디렉토리의 이미지 파일명을 사용해서 ImageId가 \n    파일명을 가지고 있는 DataFrame을 생성한다.\n    '''\n    test_df = []\n    for fname in os.listdir(TEST_IMAGE_PATH):\n        filepath = os.path.join(TEST_IMAGE_PATH, fname)    \n        if os.path.isfile(filepath):\n            for i in range(4):\n                img_cls = fname + \"_\" + str(i + 1)\n                test_df.append(img_cls)\n\n    test_df = pd.DataFrame({'ImageId_ClassId' : test_df, 'EncodedPixels' : ''})\n    test_df['ImageId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n    test_df['ClassId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n\n    test_df['EncodedPixels'] = \"\"\n\n    test_image_df = test_df.groupby('ImageId').agg(np.sum).reset_index()\n    test_image_df = test_image_df[['ImageId']]\n    test_image_df.reset_index()\n    test_image_df.head(20)\n    return test_image_df\n\n\ndef get_test_df():\n    '''\n    Test 이미지 디렉토리의 이미지들로 ImageId_ClassId를 가진 DataFrame을 만든다.\n    '''\n    test_df = []\n    for fname in os.listdir(TEST_IMAGE_PATH):\n        filepath = os.path.join(TEST_IMAGE_PATH, fname)    \n        if os.path.isfile(filepath):\n            for i in range(4):\n                img_cls = fname + \"_\" + str(i + 1)\n                test_df.append(img_cls)\n\n    test_df = pd.DataFrame({'ImageId_ClassId' : test_df, 'EncodedPixels' : ''})\n    test_df['ImageId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n    test_df['ClassId'] = test_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n    test_df['EncodedPixels'] = \"\"\n    test_df.reset_index()\n    \n    return test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"7VLFjL6aOzMt","colab_type":"code","colab":{}},"cell_type":"code","source":"BATCH_SIZE = 64\ntest_imgs = get_test_imgs_df()\nprint(TEST_IMAGE_PATH)\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_imgs,\n        #directory='../input/severstal-steel-defect-detection/test_images',\n        directory= TEST_IMAGE_PATH,\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False)\n\ntest_gen = create_test_gen()\n\nclassify_model = load_model(os.path.join(DATA_PATH, \"model_predict_missing_mask.h5\"))\nclassify_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3gK0KPbGOzMv","colab_type":"code","colab":{}},"cell_type":"code","source":"test_missing_pred = classify_model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)\n\n# print(test_imgs.shape)\n# print(len(test_missing_pred))\n\ntest_imgs['allMissing'] = test_missing_pred\ntest_imgs.head()\n\nplt.figure(figsize=(10, 5))\ntest_imgs2 = test_imgs.sort_values(by=['allMissing'])\nplt.plot(test_imgs2['allMissing'].values)\nplt.xlabel(\"count\")\nplt.ylabel(\"allMissing\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"zGhzWQg5OzMx","colab_type":"code","colab":{}},"cell_type":"code","source":"filtered_test_imgs = test_imgs[test_imgs['allMissing'] < 0.5]\nprint(filtered_test_imgs.shape)\nfiltered_test_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"xUhZo804OzMz","colab_type":"code","colab":{}},"cell_type":"code","source":"sub_df = get_test_df()\n\nfiltered_mask = sub_df['ImageId'].isin(filtered_test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\n#null_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(lambda x: ' ')\n\nfiltered_sub_df['EncodedPixels'] = \"\"\nnull_sub_df['EncodedPixels'] = \"\"\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\nfiltered_test_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nprint(\"filtered images: \")\nprint(filtered_test_imgs.head())\n\nprint(\"filtered df: \")\nprint(filtered_sub_df.head())\n\nprint(\"null df: \")\nprint(null_sub_df.head())","execution_count":null,"outputs":[]},{"metadata":{"id":"2g-CO8UBVuP7","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"from keras.backend import clear_session\nimport gc\n\n# Reset Keras Session\ndef clear_memory():\n    clear_session()\n    for i in range(20):\n        gc.collect()  \n\nclear_memory()\n\ntest_df = get_test_df() #test image DataFrame\n\nTEST_BATCH_SIZE = 100\ndf_submit = []\nMIN_MASK_PIXEL_THRESHOLD = 3500\n\ntest_image_df = filtered_test_imgs\n\n# 하나의 이미지마다 동일 크기의 4개 mask 이미지가 생성되기 때문에\n# 메모리 소비가 커서 나눠서 처리해야 한다.\nfor batch_start in range(0, test_image_df.shape[0], TEST_BATCH_SIZE):\n    batch_idx = list(range(batch_start, min(test_image_df.shape[0], batch_start + TEST_BATCH_SIZE)))\n    print(\"running: \", batch_start, \" - \", min(test_image_df.shape[0], batch_start + TEST_BATCH_SIZE))\n\n    model = build_model((256, 1600, 1))\n    model.load_weights('model.h5')\n\n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_image_df,\n        base_path = TEST_IMAGE_PATH,\n        target_df=test_df,\n        mode = 'predict',\n        batch_size=BATCH_SIZE,\n        n_classes=4)\n    \n    predict = model.predict_generator(test_generator)\n\n    for index, bindex, in enumerate(batch_idx):\n        fname = test_image_df['ImageId'].iloc[bindex]\n        image_df = test_df[test_df['ImageId'] == fname]\n\n        pred_masks = predict[index, ].round().astype(int)        \n        #print(\"pred_masks.shape :\", pred_masks.shape)\n\n        for mask_index in range(4):\n            pixelcnt = np.count_nonzero(pred_masks[:,:,mask_index])\n            #print(index, mask_index, pixelcnt)\n            if pixelcnt < MIN_MASK_PIXEL_THRESHOLD:\n                pred_masks[:,:,mask_index] = 0\n\n        pred_rles = build_rles(pred_masks)\n\n        #print(len(pred_rles))\n\n        image_df['EncodedPixels'] = pred_rles        \n        df_submit.append(image_df)\n    \n    clear_memory()\n\ndf_submit = pd.concat(df_submit)\ndf_submit = pd.concat([df_submit, null_sub_df])\n\nprint(df_submit.shape[0])\ndf_submit.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"_eU3u_f-EYAe","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"df_temp = df_submit\n\ndf_temp['maskPixelCount'] = df_temp['EncodedPixels'].map(str).apply(len)\ndf_temp = df_temp.sort_values(['maskPixelCount'], ascending=[False])\ndf_temp = df_temp.reset_index()\n#df_temp.head(80)\n\ncolumns = 1\nrows = 20\nfig = plt.figure(figsize=(20,80))\n\nax_idx = 1\nfor index, row in df_temp.iterrows():\n    if ax_idx > rows * columns:\n        break\n\n    print(\"index:\", index, \"imageid\", row[\"ImageId\"], \"class\", row[\"ClassId\"])\n\n    filename = row['ImageId']\n    fig.add_subplot(rows, columns, ax_idx).set_title(filename)\n    img = cv2.imread(os.path.join(TEST_IMAGE_PATH, filename))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    mask = rle2mask(row['EncodedPixels'], (256,1600))\n    img[mask == 1, 0] = 255\n            \n    plt.imshow(img)\n    ax_idx += 1\n        \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"kNEhdwj0Enkc","colab_type":"code","trusted":true,"colab":{}},"cell_type":"code","source":"df_submit[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Ouk8Q0NXOzM4","colab_type":"code","colab":{}},"cell_type":"code","source":"#df_submit[['ImageId_ClassId']].head(20)\ndf_submit[['ImageId_ClassId']].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"BlZiK5V9OzM6","colab_type":"code","colab":{}},"cell_type":"code","source":"df2 = pd.read_csv(DF_TEST_PATH)\ndf2.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"jJU6nfwiOzM-","colab_type":"code","colab":{}},"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks('.') # input argument is specified folder","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Severstal_ Steel Defect Detection","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}