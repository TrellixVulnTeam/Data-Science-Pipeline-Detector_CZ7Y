{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport os\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Locate training and test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect the input folder\n!cd ../input/ ;ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the number of data\nbase_dir = '/kaggle/input'\ntrain_image_dir = os.path.join(base_dir, 'train_images')\ntest_image_dir = os.path.join(base_dir, 'test_images')\ntrain_list = os.listdir(train_image_dir)\ntest_list = os.listdir(test_image_dir)\nprint('Number of training images:', len(train_list))\nprint('Number of test images:', len(test_list))\n\n# See some names\nprint(train_list[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process training labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in training labels and inspect\nlabel_all = pd.read_csv(os.path.join(base_dir,'train.csv'))\nlabel_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect 0002cc93b.jpg\nsample_image_name = '0002cc93b.jpg'\nsample_image = plt.imread(os.path.join(train_image_dir, sample_image_name))\nprint(sample_image.shape)\nplt.imshow(sample_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill nan with empty string, which is prepared for decoding the run-length encoding(rle)\nlabel_all.EncodedPixels.fillna('', inplace=True)\nlabel_all.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this task, I am going to use a U-net model with outputs of 4 layers for the four defection classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate colunms of ImageId and ClassId, in order to combine four EncodedPixels of the same image\nnew_df = label_all.ImageId_ClassId.str.split('_', expand=True)\nlabel_all['ImageId'] = new_df[0]\nlabel_all['ClassId'] = new_df[1]\nlabel_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group label all labels for each image together to form a dictionary {Id : list of 4 EncodedPixels }\nlabels = {}\n# for imageId in label_all.ImageId[0:][::4]:\n#     labels[imageId] = label_all.EncodedPixels[label_all.ImageId==imageId].to_numpy()\n\n'THe above is too slow...'\n\nfor i in range(0,len(label_all.ImageId),4):\n    labels[label_all.ImageId[i]] = list(label_all.EncodedPixels[i:i+4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define some functions for decoding and encoding rle"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decode the run-length encoding \ndef decode_rle(encodes: list, shape=sample_image.shape[0:2]):\n    \"\"\"\n    encodes : a list of 4 run-length encodes of a target image ID. \n    Return decoded mask of 4 classed defects in an array of shape 4, x, y.\n    \"\"\"\n    x, y = shape\n    decoded_images = np.empty((4, x, y))\n    \n    for j in range(4):\n        decoded = np.zeros((x*y))\n        \n        encode = encodes[j]\n        if encode:\n            split_num = encode.split()\n            for i in range(0, len(split_num), 2):\n                start_pixel = int(split_num[i])\n                run_length = int(split_num[i+1])\n                decoded[start_pixel-1 : start_pixel-1+run_length] = 1\n        decoded_image = decoded.reshape(y, x).T\n        \n        decoded_images[j] = decoded_image\n        \n    return decoded_images\n\n# Test with sample image\ndecoded_sample_image = decode_rle(labels[sample_image_name])\nplt.imshow(decoded_sample_image[0], cmap='gray')\nprint(decoded_sample_image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode rle from masks\ndef encode_rle(masks):\n    \"\"\"\n    mask: shape is (classes, height, width)\n    Return a list of 4 rle for a same image.\n    \"\"\"\n    classes, height, width = masks.shape\n    encoded_rle = ['', '', '', '']\n    \n    for i in range(classes):\n        longer = masks[i,].T.flatten()\n        longer = np.concatenate(([0], longer, [0]))\n        condition = (longer[1:] != longer[:-1])\n        pixels_that_changes = np.where(condition)[0] + 1 \n        # this return the starts and ends point of the offset difference\n        # [0] is to reduce the array dimension\n        # + 1 is to change from index to pixel number \n        \n        # Change even bit into the difference between adjacent odd and even, which is the length\n        pixels_that_changes[1::2] -= pixels_that_changes[:-1:2]\n        \n        encoded_rle[i] = \" \".join(str(x) for x in pixels_that_changes)\n    return encoded_rle\n\n# Test\nprint(encode_rle(decoded_sample_image))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define loss for this task\ncopied from https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\n\nThis task use dice coefficent to measure result.\n\n2∗|X∩Y|/ (|X|+|Y|)\n\nBuild score and loss in tensorflow."},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = tf.keras.backend.flatten(y_true)\n    y_pred_f = tf.keras.backend.flatten(y_pred)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = tf.keras.backend.flatten(y_true)\n    y_pred_f = tf.keras.backend.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * tf.keras.backend.sum(intersection) + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define model \nWanted to try a MLP, but too many parameters.  \nUse [U-net](https://arxiv.org/pdf/1505.04597.pdf) taken from \nhttps://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Design model: U-net\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.losses import binary_crossentropy\n\ndef build_model(input_shape):\n    inputs = Input(input_shape)\n\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    u6 = concatenate([u6, c5])\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4])\n    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate model \nmodel = build_model((256, 1600, 1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generator data on the fly\nSee https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n\nDue to limited RAM, have to use generator to generate data while decoding labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    \n    def __init__(self, list_IDs, labels=None, batch_size=32, dim=(256, 1600), n_channels=3, n_classes=4,\n                 shuffle=True, data_dir=train_image_dir, train=False):\n        'Initialization'\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.dim = dim\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.data_dir = data_dir\n        self.train = train\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X = self.__data_generation_X(list_IDs_temp)\n        \n        if self.train:\n            y = self.__data_generation_y(list_IDs_temp)\n            return X, y\n        else:\n            return X\n\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation_X(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            img = cv2.imread(os.path.join(self.data_dir, ID), cv2.IMREAD_GRAYSCALE)\n            img = img.astype(np.float32)\n            img = np.expand_dims(img, axis=-1)\n            # Normalise image \n            X[i,] = img / 255\n        return X\n    \n    def __data_generation_y(self, list_IDs_temp):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_temp):\n            # Store class\n            y[i,] = decode_rle(self.labels[ID]).transpose(1,2,0)\n            # Transpose 4, x, y to x, y, 4\n        return y        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List train and validation data, preparing for DataGenerator\ntrain_ID = train_list[:10000]\nvalid_ID = train_list[10000:]\n\n# Generate data\nparams = {'labels': labels,\n          'dim': (256, 1600),\n          'batch_size': 16,\n          'n_channels': 1,\n          'n_classes': 4,\n          'shuffle': True,\n          'data_dir': train_image_dir,\n          'train': True}\n\n# Generators\ntraining_generator = DataGenerator(train_ID, **params)\nvalidation_generator = DataGenerator(valid_ID, **params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n# Set checkpoint\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_dice_coef', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\n# Train model on dataset\nhistory = model.fit_generator(generator=training_generator,\n                      validation_data=validation_generator,\n                      validation_steps=int(len(valid_ID) / 16),  # add this to prevent first epoch freeze at the last step\n                      callbacks=[checkpoint],\n                      use_multiprocessing=False,\n                      workers=1,\n                      epochs=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference on test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the test list from the submission file\nsubmission_df = pd.read_csv('../input/sample_submission.csv')\nsubmission_df['ImageId'] = submission_df.ImageId_ClassId.apply(lambda x: x.split('_')[0])\ntest_list = submission_df.ImageId.unique()\ntest_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict: send prediction data in minibath and save all results in a df [imageId, predicted_rle]\n\nmodel.load_weights('model.h5')\n\npredict_params = {'dim': (256, 1600),\n                  'batch_size': 1,\n                  'n_channels': 1,\n                  'n_classes': 4,\n                  'shuffle': False,\n                  'data_dir': test_image_dir}\ntest_batch_size = 500\n\nresult_df = []\n\n# Loop over serveral batches to save RAM\nfor batch_index in range(0, len(test_list), test_batch_size):\n    image_Ids = test_list[batch_index : min(len(test_list), batch_index+test_batch_size)]\n    \n    # Loop within one batch to read in test images\n    test_generator = DataGenerator(image_Ids, **predict_params)\n\n    # Make prediction using the batch\n    test_results = model.predict_generator(test_generator, workers=1, use_multiprocessing=False, verbose=1)\n\n    # Loop over the result to extract\n    for ID, prediction in zip(image_Ids, test_results):\n        current_ID_df = submission_df[submission_df.ImageId == ID].copy()\n\n        prediction = prediction.round().astype(int)\n        predict_rle = encode_rle(prediction.transpose(2,0,1))\n\n        current_ID_df['EncodedPixels'] = predict_rle\n        result_df.append(current_ID_df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Output for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use submission file imageId_classId to search for result to generate output\nresult_df = pd.concat(result_df)\nresult_df.drop(columns='ImageId', inplace=True)\nresult_df.to_csv('submission.csv', index=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.head(15)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}