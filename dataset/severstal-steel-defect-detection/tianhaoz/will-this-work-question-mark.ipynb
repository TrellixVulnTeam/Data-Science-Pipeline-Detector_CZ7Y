{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# My imports\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom matplotlib.image import imread\nfrom tqdm import tqdm\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"num_train_images = len(os.listdir(\"../input/train_images\"))\nprint('Training image count: ', num_train_images)\nnum_test_images = len(os.listdir(\"../input/test_images\"))\nprint('Testing image count: ', num_test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train_data = pd.read_csv('../input/train.csv').dropna().reset_index(drop=True)\nprint('Num of training data: ', len(raw_train_data))\nraw_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv')\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode2img(shape, encoded_pixels):\n    img = np.zeros(shape)\n    regions = len(encoded_pixels) // 2\n    for r in range(regions):\n        idx = 2 * r\n        start_pixel = int(encoded_pixels[idx])\n        span = int(encoded_pixels[idx + 1])\n        col_cnt = shape[0]\n        for offset in range(span):\n            current_pixel = start_pixel + offset\n            current_x = current_pixel % col_cnt\n            current_y = current_pixel // col_cnt\n            img[current_x, current_y] = 1\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train_image_filename = '000a4bcdd.jpg'\nprint('filename: ', sample_train_image_filename)\nsample_train_image = imread('../input/train_images/' + sample_train_image_filename)\nprint('image size: ', sample_train_image.shape)\nprint('image color scale: ', np.max(sample_train_image), '~', np.min(sample_train_image))\nplt.figure(figsize=(20,4))\nimshow(sample_train_image)\nplt.show()\nfor idx in range(len(raw_train_data)):\n    img_id_class = raw_train_data.loc[idx]['ImageId_ClassId'].strip().split('_')\n    img_id = img_id_class[0]\n    img_class = img_id_class[1]\n    if img_id == sample_train_image_filename:\n        sample_train_mask_encode = raw_train_data.loc[idx]['EncodedPixels'].strip().split(' ')\n        sample_train_mask = encode2img(sample_train_image.shape[:2], sample_train_mask_encode)\n        sample_train_mask_img = sample_train_mask\n        plt.figure(figsize=(20,4))\n        imshow(sample_train_mask_img, cmap='gray')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_train_label(img_id, raw_label):\n    train_img = imread('../input/train_images/' + img_id)\n    class_cnt = 4\n    label_shape = (train_img.shape[0], train_img.shape[1], class_cnt)\n    label_img = np.zeros(label_shape)\n    for idx in range(len(raw_label)):\n        img_id_class = raw_label.loc[idx]['ImageId_ClassId'].strip().split('_')\n        img_id = img_id_class[0]\n        img_class = int(img_id_class[1]) - 1\n        if img_id == sample_train_image_filename:\n            train_mask_encode = raw_label.loc[idx]['EncodedPixels'].strip().split(' ')\n            train_mask = encode2img(sample_train_image.shape[:2], sample_train_mask_encode)\n            label_img[:,:,img_class] = train_mask\n    normalized_train_img = np.array(train_img) / 255\n    return normalized_train_img, label_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = []\nlabel_set = []\nfor train_image_filename in tqdm(os.listdir(\"../input/train_images\")[:30]):\n    train_img, label_img = generate_train_label(train_image_filename, raw_train_data)\n    train_set.append(train_img)\n    label_set.append(label_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=4, kernel_size=(1,1), activation='relu')\n])\nmodel.compile(\n    optimizer=tf.train.RMSPropOptimizer(0.01),\n    loss=tf.keras.losses.categorical_crossentropy,\n    metrics=[tf.keras.metrics.categorical_accuracy]\n)\ntrain_data = np.array(train_set)\ntrain_label = np.array(label_set)\nprint('train data shape: ', train_data.shape, ', train label shape: ', train_label.shape)\nmodel.fit(train_data, train_label, epochs=10, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = []\nfor test_image_filename in tqdm(os.listdir(\"../input/test_images\")[:100]):\n    test_img = np.array(imread('../input/test_images/' + test_image_filename))\n    test_set.append(test_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = np.array(test_set)\nprint('test data shape: ', test_data.shape)\nresult = model.predict(test_data, batch_size=1, verbose=1)\nprint('prediction shape: ', result.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2encoded(mask):\n    col_cnt = mask.shape[0]\n    row_cnt = mask.shape[1]\n    pixel_cnt = col_cnt * row_cnt\n    encoded_pixels = []\n    start_col = -1\n    start_row = -1\n    span = 0\n    counting = False\n    pairs = []\n    for current_pixel in range(pixel_cnt):\n        current_row = current_pixel % col_cnt\n        current_col = current_pixel // col_cnt\n        if mask[current_row, current_col] > 0.5:\n            if not counting:\n                counting = True\n                span = 1\n                start_col = current_col\n                start_row = current_row\n            else:\n                span += 1\n        else:\n            if counting:\n                pairs.append(current_pixel)\n                pairs.append(span)\n            counting = False\n            span = 0\n            start_col = -1\n            start_row = -1\n    return encoded_pixels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_cnt = result.shape[0]\nclass_cnt = result.shape[3]\nfor p in tqdm(range(predict_cnt)):\n    for c in range(class_cnt):\n        current_mask = result[p,:,:,c]\n        encoded_mask = mask2encoded(current_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}