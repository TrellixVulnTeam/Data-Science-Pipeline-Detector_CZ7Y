{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nfrom PIL import Image\nimport torch\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T09:57:05.054328Z","iopub.execute_input":"2021-09-21T09:57:05.054675Z","iopub.status.idle":"2021-09-21T09:57:09.686625Z","shell.execute_reply.started":"2021-09-21T09:57:05.054595Z","shell.execute_reply":"2021-09-21T09:57:09.685493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version\n!pip freeze | grep torch","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:24:51.958723Z","iopub.execute_input":"2021-09-21T08:24:51.959054Z","iopub.status.idle":"2021-09-21T08:24:56.684456Z","shell.execute_reply.started":"2021-09-21T08:24:51.959022Z","shell.execute_reply":"2021-09-21T08:24:56.683458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Loading the dataset","metadata":{}},{"cell_type":"code","source":"class Steel_Data(torch.utils.data.Dataset):\n    def __init__(self, csv_file, mode='train', transform=None):\n        \n        self.mode = mode # 'train', 'val' or 'test'\n        self.data_list = []\n        self.category = []\n        self.transform = transform\n        \n        with open(csv_file, newline='') as csvfile:\n            reader = csv.DictReader(csvfile) #用dictionary的方式讀取csv的資料\n            for row in reader:\n                self.data_list.append(row['ImageId']) #將key 為 file_path的value讀進data_list\n                if mode != 'test':\n                    self.category.append(int(row['ClassId'])-1)\n        if mode == 'train':\n            self.data_list = self.data_list[0:6000]\n            self.category = self.category[0:6000]\n        if mode == 'val':\n            self.data_list = self.data_list[6000:7096]\n            self.category = self.category[6000:7096] \n\n    def __getitem__(self, index):\n\n        data = Image.open('../input/severstal-steel-defect-detection/train_images/'+ self.data_list[index])\n        if self.transform is not None:\n            data = self.transform(data)\n        if self.mode == 'test':\n            return data\n        category = torch.tensor(int(self.category[index]))\n        return data, category\n\n    def __len__(self):\n        return len(self.data_list)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:59:47.486012Z","iopub.execute_input":"2021-09-21T09:59:47.486328Z","iopub.status.idle":"2021-09-21T09:59:47.497846Z","shell.execute_reply.started":"2021-09-21T09:59:47.486302Z","shell.execute_reply":"2021-09-21T09:59:47.496834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1 Data augmentation \n\nData augmentation are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data.\n\nPytorch use `torchvision.transforms` to do data augmentation.\n[You can see all function here.](https://pytorch.org/docs/stable/torchvision/transforms.html)\n\n**NOTICE**: There are some operations may not be necessary for predict, so we should write one for train and one for others.\n\n(**Slide.07 page.49**)","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n# For TRAIN\n########################################################################\n#  TODO: use transforms.xxx method to do some data augmentation        #\n#  This one is for training, find the composition to get better result #\n########################################################################\ntransforms_train = transforms.Compose([\ntransforms.Resize((256, 256)),         #將照片固定為196x196的大小\ntransforms.RandomCrop((224, 224)),      #將照片隨機裁減為224x224的大小\ntransforms.RandomHorizontalFlip(p=0.5), #0.5的機率是否水平翻轉\ntransforms.RandomVerticalFlip(p=0.5),   #0.5的機率是否垂直翻轉\ntransforms.RandomRotation(degrees=(-90, 90)),  #隨機地在-90~90度間旋轉\ntransforms.ToTensor(),  #將照片轉成tensor 並且將數值都轉換成0~1 \ntransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n]) #標準化 \n########################################################################\n#                           End of your code                           #\n########################################################################\n\n# For VAL, TEST\n########################################################################\n#  TODO: use transforms.xxx method to do some data augmentation        #\n#  This one is for validate and test,                                  #\n#  NOTICE some operation we usually not use in this part               #\n########################################################################\ntransforms_test = transforms.Compose([\ntransforms.Resize((256, 256)),\ntransforms.CenterCrop((224, 224)),\ntransforms.ToTensor(),\ntransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n########################################################################\n#                           End of your code                           #\n########################################################################","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:59:54.500025Z","iopub.execute_input":"2021-09-21T09:59:54.500939Z","iopub.status.idle":"2021-09-21T09:59:54.512868Z","shell.execute_reply.started":"2021-09-21T09:59:54.500888Z","shell.execute_reply":"2021-09-21T09:59:54.511498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Instantiate dataset","metadata":{}},{"cell_type":"code","source":"dataset_train = Steel_Data('../input/severstal-steel-defect-detection/train.csv', mode='train',transform=transforms_train)\ndataset_val = Steel_Data('../input/severstal-steel-defect-detection/train.csv', mode='val', transform=transforms_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:59:57.036879Z","iopub.execute_input":"2021-09-21T09:59:57.037863Z","iopub.status.idle":"2021-09-21T09:59:58.266068Z","shell.execute_reply.started":"2021-09-21T09:59:57.037813Z","shell.execute_reply":"2021-09-21T09:59:58.265027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The first image's shape in dataset_train :\", dataset_train.__getitem__(0)[0].size()) #[0]means data\nprint(\"There are\", dataset_train.__len__(), \"images in dataset_train.\")\nprint('-'*50)\n\nprint(\"The first image's shape in dataset_val :\", dataset_val.__getitem__(0)[0].size()) #[0]means data\nprint(\"There are\", dataset_val.__len__(), \"images in dataset_val.\")\n\n# 224x224 because of transformation","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:00:01.72412Z","iopub.execute_input":"2021-09-21T10:00:01.724804Z","iopub.status.idle":"2021-09-21T10:00:01.853711Z","shell.execute_reply.started":"2021-09-21T10:00:01.724776Z","shell.execute_reply":"2021-09-21T10:00:01.852783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 DataLoader \n\n`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:\n+ `shuffle` : set to `True` to have the data reshuffled at every epoch\n+ `batch_size` : how many samples per batch to load\n\nSee [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset_val, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:00:26.755825Z","iopub.execute_input":"2021-09-21T10:00:26.756182Z","iopub.status.idle":"2021-09-21T10:00:26.762179Z","shell.execute_reply.started":"2021-09-21T10:00:26.756154Z","shell.execute_reply":"2021-09-21T10:00:26.76106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Implement CNN using PyTorch","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Define a Convolutional Neural Network\n\nTry to design and train a deep convolutional network from scratch to predict the class label of a flower image. \n\nYou can refer to last assignment about image_classifier, and try to go deep and use more method for better model.","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn \nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.models as models\nresnet101=torchvision.models.resnet101(pretrained=True)\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.cnn_model = resnet101\n        self.fc1 = nn.Sequential(\n            nn.Linear(1000, 500),\n            nn.ReLU(),\n            nn.BatchNorm1d(500),\n            nn.Dropout(p=0.4),\n            nn.Linear(500, 4))\n    def forward(self, x):\n        x = self.cnn_model(x)\n        out = self.fc1(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:00:28.86993Z","iopub.execute_input":"2021-09-21T10:00:28.870745Z","iopub.status.idle":"2021-09-21T10:00:38.598646Z","shell.execute_reply.started":"2021-09-21T10:00:28.870702Z","shell.execute_reply":"2021-09-21T10:00:38.597578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net()\ndevice = torch.device('cuda')\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:02:15.443035Z","iopub.execute_input":"2021-09-21T10:02:15.443624Z","iopub.status.idle":"2021-09-21T10:02:15.467733Z","shell.execute_reply.started":"2021-09-21T10:02:15.443569Z","shell.execute_reply":"2021-09-21T10:02:15.466819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Debug your code","metadata":{}},{"cell_type":"code","source":"x = torch.rand(32, 3, 224, 224) # generate fake data\nx = x.to(device)\nout = model(x) # output of category and attribute\nprint(out)\nprint(out.shape)\n_,p=torch.max(out.data,1)\nprint(p)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:00:54.964964Z","iopub.execute_input":"2021-09-21T10:00:54.965266Z","iopub.status.idle":"2021-09-21T10:00:55.259139Z","shell.execute_reply.started":"2021-09-21T10:00:54.965236Z","shell.execute_reply":"2021-09-21T10:00:55.257995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3  Define loss and optimizer","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\ncriterion = nn.CrossEntropyLoss() # CrossEntropyLoss function combines both a SoftMax activation \n                                  # and a cross entropy loss function in the same function \n                                  # 這正是為什麼我們沒有在最後用 SoftMax轉換的原因\noptimizer = torch.optim.SGD(model.parameters(), lr=0.005,momentum=0.9)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:01:02.340268Z","iopub.execute_input":"2021-09-21T10:01:02.340571Z","iopub.status.idle":"2021-09-21T10:01:02.355288Z","shell.execute_reply.started":"2021-09-21T10:01:02.340543Z","shell.execute_reply":"2021-09-21T10:01:02.354327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Train the model","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Train function\nLet's define train function.  \nIt will iterate input data 1 epoch and update model with optmizer.  \nFinally, calculate mean loss and total accuracy.\n\nHint: [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html#torch-max)","metadata":{}},{"cell_type":"code","source":"def train(input_data, model, criterion, optimizer):\n    '''\n    Argement:\n    input_data -- iterable data, typr torch.utils.data.Dataloader is prefer\n    model -- nn.Module, model contain forward to predict output\n    criterion -- loss function, used to evaluate goodness of model\n    optimizer -- optmizer function, method for weight updating\n    '''\n    model.train()\n    total_count = 0\n    acc_count = 0\n    total_run = 0\n    total_f1_score = 0\n    for i, data in enumerate(input_data, 0):\n        images, categorys = data[0].to(device), data[1].to(device)\n        \n        ########################################################################\n        # TODO: Forward, backward and optimize                                 #\n        # 1. zero the parameter gradients                                      #\n        # 2. process input through the network                                 #\n        # 3. compute the loss                                                  #\n        # 4. propagate gradients back into the network’s parameters            #\n        # 5. Update the weights of the network                                 #\n        ########################################################################\n        # Run the forward \n        outputs = model(images)\n        loss = criterion(outputs, categorys) \n\n        # Backward and perform optimization\n        optimizer.zero_grad() #將梯度初始化為0，這步很關鍵，因為每次我們使用的batch不同，導致loss不同，因此梯度函數不同\n        loss.backward() #進行反向傳播\n        optimizer.step() #藉由反向傳播的結果計算梯度\n        ########################################################################\n        #                           End of your code                           #\n        ########################################################################\n\n\n        ########################################################################\n        # TODO: Get the counts of correctly classified images                  #\n        # 1. get the model predicted result                                    #\n        # 2. sum the number of this batch predicted images                     #\n        # 3. sum the number of correctly classified                            #\n        # 4. save this batch's loss into loss_list                             #\n        # dimension of outputs: [batch_size, number of classes]                #\n        # Hint 1: use outputs.data to get no auto_grad                         #\n        # Hint 2: use torch.max()                                              #\n        ########################################################################\n        _, predicted = torch.max(outputs.data,1) #返回每一行中最大值的那个元素，且返回其索引\n        total_count += categorys.size(0) #x.size(0)指的是batch size (目前設定為32)\n        acc_count += (predicted == categorys).sum().item() #分類正確的總數量\n        total_run += 1\n        ########################################################################\n        #                           End of your code                           #\n        ########################################################################\n\n    # Compute this epoch accuracy and loss\n    acc = acc_count / total_count\n\n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:02:55.019419Z","iopub.execute_input":"2021-09-21T10:02:55.019718Z","iopub.status.idle":"2021-09-21T10:02:55.03252Z","shell.execute_reply.started":"2021-09-21T10:02:55.01969Z","shell.execute_reply":"2021-09-21T10:02:55.031287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val(input_data, model, criterion, optimizer):\n    model.eval()\n    \n    total_count = 0\n    acc_count = 0\n    total_run = 0\n    total_f1_score = 0\n    with torch.no_grad():\n        for data in input_data:\n            images, categorys = data[0].to(device), data[1].to(device)\n\n            ####################################################################\n            # TODO: Get the predicted result and loss                          #\n            # 1. process input through the network                             #\n            # 2. compute the loss                                              #\n            # 3. get the model predicted result                                #\n            # 4. get the counts of correctly classified images                 #\n            # 5. save this batch's loss into loss_list                         #\n            ####################################################################\n            outputs_val = model(images)\n            loss = criterion(outputs_val, categorys)\n\n            _, predicted = torch.max(outputs_val.data,1)\n            total_count += categorys.size(0)\n            acc_count += (predicted == categorys).sum().item()\n            total_run += 1\n            ####################################################################\n            #                         End of your code                         #\n            ####################################################################\n\n    acc = acc_count / total_count\n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:03:01.742073Z","iopub.execute_input":"2021-09-21T10:03:01.742428Z","iopub.status.idle":"2021-09-21T10:03:01.753143Z","shell.execute_reply.started":"2021-09-21T10:03:01.742397Z","shell.execute_reply":"2021-09-21T10:03:01.751742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################\n# You can adjust those hyper parameters to loop for max_epochs times           #\n################################################################################\nmax_epochs = 50\nlog_interval = 1 # print acc and loss in per log_interval time\n################################################################################\n#                               End of your code                               #\n################################################################################\ntrain_acc_list = []\nval_acc_list = []\n\nfor epoch in range(1, max_epochs + 1):\n    print('=' * 20, 'Epoch', epoch, '=' * 20)\n    train_acc = train(train_loader, model, criterion, optimizer)\n    val_acc = val(val_loader, model, criterion, optimizer)\n\n    train_acc_list.append(train_acc)\n    val_acc_list.append(val_acc)\n    if epoch % log_interval == 0:\n        print('Train Acc: {:.6f}'.format(train_acc))\n        print('Val Acc: {:.6f}'.format(val_acc))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:03:25.808Z","iopub.execute_input":"2021-09-21T10:03:25.808325Z"},"trusted":true},"execution_count":null,"outputs":[]}]}