{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_DIR = '../input/severstal-steel-defect-detection/'\nTEST_SIZE = 0.3\nRANDOM_STATE = 123\n\nNUM_TRAIN_SAMPLES = 20 # The number of train samples used for visualization\nNUM_VAL_SAMPLES = 20 # The number of val samples used for visualization\nCOLORS = ['b', 'g', 'r', 'm'] # Color of each class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\nfrom shutil import copyfile\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\nfrom plotly import subplots\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.graph_objs import *\nfrom plotly.graph_objs.layout import Margin, YAxis, XAxis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"legacy_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\n\nfor img_id, img_df in tqdm_notebook(df.groupby('ImageId')):\n    for i in range(1, 5):\n        avail_classes = list(img_df.ClassId)\n\n        row = dict()\n        row['ImageId_ClassId'] = img_id + '_' + str(i)\n\n        if i in avail_classes:\n            row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n        else:\n            row['EncodedPixels'] = np.nan\n        \n        legacy_df = legacy_df.append(row, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = legacy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['HavingDefection'] = df['EncodedPixels'].map(lambda x: 0 if x is np.nan else 1)\n\nimage_col = np.array(df['Image'])\nimage_files = image_col[::4]\nall_labels = np.array(df['HavingDefection']).reshape(-1, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_img_class_1 = np.sum(all_labels[:, 0])\nnum_img_class_2 = np.sum(all_labels[:, 1])\nnum_img_class_3 = np.sum(all_labels[:, 2])\nnum_img_class_4 = np.sum(all_labels[:, 3])\nprint('Class 1: {} images'.format(num_img_class_1))\nprint('Class 2: {} images'.format(num_img_class_2))\nprint('Class 3: {} images'.format(num_img_class_3))\nprint('Class 4: {} images'.format(num_img_class_4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_figures(\n    sizes,\n    pie_title,\n    start_angle,\n    bar_title,\n    bar_ylabel,\n    labels=('Class 1', 'Class 2', 'Class 3', 'Class 4'),\n    colors=None,\n    explode=(0, 0, 0, 0.1),\n):\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n    y_pos = np.arange(len(labels))\n    barlist = axes[0].bar(y_pos, sizes, align='center')\n    axes[0].set_xticks(y_pos, labels)\n    axes[0].set_ylabel(bar_ylabel)\n    axes[0].set_title(bar_title)\n    if colors is not None:\n        for idx, item in enumerate(barlist):\n            item.set_color(colors[idx])\n\n    def autolabel(rects):\n        \"\"\"\n        Attach a text label above each bar displaying its height\n        \"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            axes[0].text(\n                rect.get_x() + rect.get_width()/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontweight='bold'\n            )\n\n    autolabel(barlist)\n    \n    pielist = axes[1].pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=start_angle, counterclock=False)\n    axes[1].axis('equal')\n    axes[1].set_title(pie_title)\n    if colors is not None:\n        for idx, item in enumerate(pielist[0]):\n            item.set_color(colors[idx])\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('[THE WHOLE DATASET]')\n\nsum_each_class = np.sum(all_labels, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\nsum_each_sample = np.sum(all_labels, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(image_files, all_labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train:', X_train.shape)\nprint('y_train:', y_train.shape)\nprint('X_val:', X_val.shape)\nprint('y_val:', y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('[TRAINING SET]')\n\nsum_each_class = np.sum(y_train, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(y_train, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('[VALIDATION SET]')\n\nsum_each_class = np.sum(y_val, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(y_val, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_samples(samples):\n    for sample in samples:\n        fig, ax = plt.subplots(figsize=(15, 10))\n        img_path = os.path.join(DATASET_DIR, 'train_images', sample[0])\n        img = cv2.imread(img_path)\n\n        # Get annotations\n        labels = df[df['ImageId_ClassId'].str.contains(sample[0])]['EncodedPixels']\n\n        patches = []\n        for idx, rle in enumerate(labels.values):\n            if rle is not np.nan:\n                mask = rle2mask(rle)\n                contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n                for contour in contours:\n                    poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=1, edgecolor=COLORS[idx], fill=False)\n                    patches.append(poly_patch)\n        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet)\n\n        ax.imshow(img/255)\n        ax.set_title('{} - ({})'.format(sample[0], ', '.join(sample[1].astype(np.str))))\n        ax.add_collection(p)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pairs = np.array(list(zip(X_train, y_train)))\ntrain_samples = train_pairs[np.random.choice(train_pairs.shape[0], NUM_TRAIN_SAMPLES, replace=False), :]\n\nshow_samples(train_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pairs = np.array(list(zip(X_val, y_val)))\nval_samples = val_pairs[np.random.choice(val_pairs.shape[0], NUM_VAL_SAMPLES, replace=False), :]\n\nshow_samples(val_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=legacy_df\ndel df_train['Image']\ndel df_train['HavingDefection']\ntrain_df = df.fillna(-1)\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\ngrouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)\ndef rle_to_mask(rle_string, height, width):  \n    rows, cols = height, width\n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(rows*cols, dtype=np.uint8)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate sum of the pixels for the mask per class id\ntrain_df['mask_pixel_sum'] = train_df.apply(lambda x: rle_to_mask(x['EncodedPixels'], width=1600, height=256).sum(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_ids = ['1','2','3','4']\nmask_count_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].count() for class_id in class_ids]\npixel_sum_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].sum() for class_id in class_ids]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=class_ids, values=mask_count_per_class, name=\"Mask Count\"), 1, 1)\nfig.add_trace(Pie(labels=class_ids, values=pixel_sum_per_class, name=\"Pixel Count\"), 1, 2)\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Mask & Pixel Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Mask', x=0.18, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Pixel', x=0.80, y=0.5, font_size=20, showarrow=False)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot a histogram and boxplot combined of the mask pixel sum per class Id\nfig = px.histogram(train_df[train_df['mask_pixel_sum']!=0][['ClassId','mask_pixel_sum']], \n                   x=\"mask_pixel_sum\", y=\"ClassId\", color=\"ClassId\", marginal=\"box\")\n\nfig['layout'].update(title='Histogram and Boxplot of Sum of Mask Pixels Per Class')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\n\nimport keras\nfrom keras.layers.convolutional import Conv2DTranspose\nfrom keras.layers.merge import concatenate\nfrom keras.layers import UpSampling2D, Conv2D, Activation, Input, Dropout, MaxPooling2D\nfrom keras import Model\nfrom keras import backend as K\nfrom keras.layers.core import Lambda","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr = legacy_df\nprint(len(tr))\ntr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def keras_generator(batch_size):\n    while True:\n        x_batch = []\n        y_batch = []\n        \n        for i in range(batch_size):            \n            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n            img = cv2.imread( '../input/severstal-steel-defect-detection/train_images/'+fn )\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n            \n            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n            \n            img = cv2.resize(img, (img_size, img_size))\n            mask = cv2.resize(mask, (img_size, img_size))\n            \n            x_batch += [img]\n            y_batch += [mask]\n                                    \n        x_batch = np.array(x_batch)\n        y_batch = np.array(y_batch)\n\n        yield x_batch, np.expand_dims(y_batch, -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in keras_generator(4):\n    break\n    \nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(x[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(y[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model\n\ninputs = Input((256, 256, 3))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Fit model\nbatch_size = 16\nresults = model.fit_generator(keras_generator(batch_size), \n                              steps_per_epoch=100,\n                              epochs=10) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport cv2\nimport os\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport keras\nimport json\nimport tqdm\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\nimport gc\nfrom segmentation_models import Unet\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import Sequence\nfrom keras.optimizers import Adam\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 2019\nBATCH_SIZE = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf = legacy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf['ImageId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntraindf['ClassId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntraindf['hasMask'] = ~traindf['EncodedPixels'].isna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts = traindf.groupby('ImageId')['hasMask'].sum().reset_index()\nmask_counts.sort_values(by = 'hasMask', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts['hasMask'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts = mask_counts.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=3,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_index = mask_counts.index\ntrn_idx, val_idx = train_test_split(all_index, test_size = 0.2, random_state = seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(\n    trn_idx, \n    df=mask_counts,\n    target_df=traindf,\n    batch_size=BATCH_SIZE, \n    n_classes=4,\n    random_state = seed\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_counts,\n    target_df=traindf,\n    batch_size=BATCH_SIZE, \n    n_classes=4,\n    random_state = seed\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Unet('resnet18', classes=4, activation='softmax', input_shape = (256,1600,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(Adam(lr = 0.005), loss=bce_jaccard_loss, metrics=[iou_score, dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'Unet_resnet18.h5', \n    monitor='val_loss', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nreducelr = ReduceLROnPlateau(monitor = 'val_loss', min_lr = 1e-6, factor = 0.1, verbose = 1, patience = 5)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, reducelr],\n    use_multiprocessing=True,\n    workers=6,\n    epochs=1\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = legacy_df\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count_df.shape)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def load_img(code, base, resize=True):\n    path = f'{base}/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    \n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"BATCH_SIZE = 64\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_imgs,\n        directory='../input/severstal-steel-defect-detection/test_images',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ntest_gen = create_test_gen()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_model = load_model('../input/severstal-predict-missing-masks/model.h5')\nremove_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_missing_pred = remove_model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)\n\ntest_imgs['allMissing'] = test_missing_pred\ntest_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_test_imgs = test_imgs[test_imgs['allMissing'] < 0.5]\nprint(filtered_test_imgs.shape)\nfiltered_test_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_mask = sub_df['ImageId'].isin(filtered_test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(\n    lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\nfiltered_test_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nfiltered_sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_grayscale(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019, \n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def build_model(input_shape):\n    inputs = Input(input_shape)\n\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    u6 = concatenate([u6, c5])\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4])\n    c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model = build_model((256, 1600, 1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_loss', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint],\n    use_multiprocessing=False,\n    workers=1,\n    epochs=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['dice_coef', 'val_dice_coef']].plot()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}