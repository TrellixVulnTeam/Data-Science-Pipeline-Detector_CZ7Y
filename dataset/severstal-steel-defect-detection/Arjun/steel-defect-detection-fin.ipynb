{"cells":[{"metadata":{"_uuid":"92362752-5605-43c9-ba47-d157100fafb0","_cell_guid":"c9c58fbe-ca03-46e2-ae98-59c62a5a98be","trusted":true},"cell_type":"code","source":"DATASET_DIR = '../input/severstal-steel-defect-detection/'\nTEST_SIZE = 0.3\nRANDOM_STATE = 123\n\nNUM_TRAIN_SAMPLES = 20 # The number of train samples used for visualization\nNUM_VAL_SAMPLES = 20 # The number of val samples used for visualization\nCOLORS = ['b', 'g', 'r', 'm'] # Color of each class","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"55f5355b-5d5b-460e-9b81-1a7f19efd352","_cell_guid":"f6f78bfa-ad1d-4bf0-b408-ca0a6b614dbe","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\nfrom shutil import copyfile\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\nfrom plotly import subplots\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.graph_objs import *\nfrom plotly.graph_objs.layout import Margin, YAxis, XAxis","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f706a1d5-4e9c-4386-a501-e5f1a91ab8ae","_cell_guid":"e58aa38d-2259-4cf1-972d-b3b3281f44d1","trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"3b79f6cb-a2c8-4b6f-ada6-7b7608ff69ec","_cell_guid":"637bc24c-fd86-421e-9621-34e6834c1535","trusted":true},"cell_type":"code","source":"df.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"79e088d4-066f-4403-af02-b7e2f39ca42a","_cell_guid":"d05a8f37-4cdd-4031-9e8e-4168ce0c4688","trusted":true},"cell_type":"markdown","source":"##### Convert training data-frame to the legacy version"},{"metadata":{"_uuid":"5f3c3be9-dd82-4efc-bbdb-628da41d7149","_cell_guid":"7915ba44-27b4-40c1-aff9-f61150d4be8b","trusted":true},"cell_type":"code","source":"legacy_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\n\nfor img_id, img_df in tqdm_notebook(df.groupby('ImageId')):\n    for i in range(1, 5):\n        avail_classes = list(img_df.ClassId)\n\n        row = dict()\n        row['ImageId_ClassId'] = img_id + '_' + str(i)\n\n        if i in avail_classes:\n            row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n        else:\n            row['EncodedPixels'] = np.nan\n        \n        legacy_df = legacy_df.append(row, ignore_index=True)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"737e46a0-1017-4fb1-bcc5-debaed241b5c","_cell_guid":"a8017a6c-0390-42eb-872c-0fb199b73c49","trusted":true},"cell_type":"code","source":"legacy_df.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"2ebdc9e6-90a8-47a3-8a47-d4720239ffc4","_cell_guid":"b0dbf28a-32a5-4e64-9d5e-a1b85893aa61","trusted":true},"cell_type":"code","source":"df = legacy_df","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f9538fb6-0a69-4469-85bb-e9a440bf97dd","_cell_guid":"073bb7e7-120a-43e9-ab31-68fb79b5c50e","trusted":true},"cell_type":"markdown","source":"##### Continue the preprocessing process"},{"metadata":{"_uuid":"f2ea5916-e813-4fb2-b8aa-e712d7e86503","_cell_guid":"f33f1708-1f5f-418a-9655-d0de97a77ec7","trusted":true},"cell_type":"code","source":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['HavingDefection'] = df['EncodedPixels'].map(lambda x: 0 if x is np.nan else 1)\n\nimage_col = np.array(df['Image'])\nimage_files = image_col[::4]\nall_labels = np.array(df['HavingDefection']).reshape(-1, 4)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"d1018106-2ecd-4ba5-bc02-d3bc2c70a78e","_cell_guid":"425c3034-4a85-4ffb-91a7-c593a453b02f","trusted":true},"cell_type":"code","source":"num_img_class_1 = np.sum(all_labels[:, 0])\nnum_img_class_2 = np.sum(all_labels[:, 1])\nnum_img_class_3 = np.sum(all_labels[:, 2])\nnum_img_class_4 = np.sum(all_labels[:, 3])\nprint('Class 1: {} images'.format(num_img_class_1))\nprint('Class 2: {} images'.format(num_img_class_2))\nprint('Class 3: {} images'.format(num_img_class_3))\nprint('Class 4: {} images'.format(num_img_class_4))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a34406db-60a9-4fb9-bf66-7d4381f30215","_cell_guid":"5cdcd01b-d56c-4881-b0d2-99e0baf02cb0","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"def plot_figures(\n    sizes,\n    pie_title,\n    start_angle,\n    bar_title,\n    bar_ylabel,\n    labels=('Class 1', 'Class 2', 'Class 3', 'Class 4'),\n    colors=None,\n    explode=(0, 0, 0, 0.1),\n):\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n    y_pos = np.arange(len(labels))\n    barlist = axes[0].bar(y_pos, sizes, align='center')\n    axes[0].set_xticks(y_pos, labels)\n    axes[0].set_ylabel(bar_ylabel)\n    axes[0].set_title(bar_title)\n    if colors is not None:\n        for idx, item in enumerate(barlist):\n            item.set_color(colors[idx])\n\n    def autolabel(rects):\n        \"\"\"\n        Attach a text label above each bar displaying its height\n        \"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            axes[0].text(\n                rect.get_x() + rect.get_width()/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontweight='bold'\n            )\n\n    autolabel(barlist)\n    \n    pielist = axes[1].pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=start_angle, counterclock=False)\n    axes[1].axis('equal')\n    axes[1].set_title(pie_title)\n    if colors is not None:\n        for idx, item in enumerate(pielist[0]):\n            item.set_color(colors[idx])\n\n    plt.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"bec353a4-881c-4bcd-8316-320507ec744d","_cell_guid":"80b2d13e-c681-40e2-abc1-74b6c461db05","trusted":true},"cell_type":"code","source":"print('[THE WHOLE DATASET]')\n\nsum_each_class = np.sum(all_labels, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\nsum_each_sample = np.sum(all_labels, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"2806fb75-e0ba-44b5-bf21-792ff9f2d1fb","_cell_guid":"2445fd5f-b7a4-4fee-b73f-2bae4f80644b","trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(image_files, all_labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9148b6d1-5161-4f84-805e-80e35b9e822a","_cell_guid":"3f71d3b0-beb1-42a6-a3f8-034c61b75701","trusted":true},"cell_type":"code","source":"print('X_train:', X_train.shape)\nprint('y_train:', y_train.shape)\nprint('X_val:', X_val.shape)\nprint('y_val:', y_val.shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"3c713838-41fd-40d0-a257-46360d3acc7c","_cell_guid":"fda4c0b0-7fd5-4c5b-bd7e-42eec51e3611","trusted":true},"cell_type":"code","source":"print('[TRAINING SET]')\n\nsum_each_class = np.sum(y_train, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(y_train, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8ed243e6-93ea-4bdb-a42c-8013012f0803","_cell_guid":"07f60609-b694-4dda-b745-9d068f293c44","trusted":true},"cell_type":"code","source":"print('[VALIDATION SET]')\n\nsum_each_class = np.sum(y_val, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(y_val, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"70e15595-3b8b-4268-9d35-1d9389b8aad8","_cell_guid":"4ca1f5e6-19e0-45fb-9d24-0ca7c57e67ad","trusted":true},"cell_type":"code","source":"def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"3c8e8c72-1723-4538-9218-92fb8d2d20ff","_cell_guid":"ce0c7b37-6a7b-4d29-9801-a0e6154d8afa","trusted":true},"cell_type":"code","source":"def show_samples(samples):\n    for sample in samples:\n        fig, ax = plt.subplots(figsize=(15, 10))\n        img_path = os.path.join(DATASET_DIR, 'train_images', sample[0])\n        img = cv2.imread(img_path)\n\n        # Get annotations\n        labels = df[df['ImageId_ClassId'].str.contains(sample[0])]['EncodedPixels']\n\n        patches = []\n        for idx, rle in enumerate(labels.values):\n            if rle is not np.nan:\n                mask = rle2mask(rle)\n                contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n                for contour in contours:\n                    poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=1, edgecolor=COLORS[idx], fill=False)\n                    patches.append(poly_patch)\n        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet)\n\n        ax.imshow(img/255)\n        ax.set_title('{} - ({})'.format(sample[0], ', '.join(sample[1].astype(np.str))))\n        ax.add_collection(p)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        plt.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"27a1b469-3488-4412-8756-81601454651e","_cell_guid":"fa835105-98d9-457c-84df-1f8ae65d4ccf","trusted":true},"cell_type":"code","source":"train_pairs = np.array(list(zip(X_train, y_train)))\ntrain_samples = train_pairs[np.random.choice(train_pairs.shape[0], NUM_TRAIN_SAMPLES, replace=False), :]\n\nshow_samples(train_samples)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b8723f00-4a6c-46cc-9e85-1443c6bda7ef","_cell_guid":"be402011-01ed-42d2-932e-e3dd0c4b3216","trusted":true},"cell_type":"code","source":"val_pairs = np.array(list(zip(X_val, y_val)))\nval_samples = val_pairs[np.random.choice(val_pairs.shape[0], NUM_VAL_SAMPLES, replace=False), :]\n\nshow_samples(val_samples)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"e4698b5f-28fe-42d3-b8be-cbffd14d4845","_cell_guid":"fdc28e74-5d91-4eb9-ad48-3cd9f70a0d1a","trusted":true},"cell_type":"code","source":"df_train=legacy_df\ndel df_train['Image']\ndel df_train['HavingDefection']\ntrain_df = df.fillna(-1)\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\ngrouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)\ndef rle_to_mask(rle_string, height, width):  \n    rows, cols = height, width\n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(rows*cols, dtype=np.uint8)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8551c6e1-8a0d-4152-9295-d4605d14c20c","_cell_guid":"e93b61fe-6f12-4001-9a80-683b44521227","trusted":true},"cell_type":"code","source":"# calculate sum of the pixels for the mask per class id\ntrain_df['mask_pixel_sum'] = train_df.apply(lambda x: rle_to_mask(x['EncodedPixels'], width=1600, height=256).sum(), axis=1)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"198c7728-dacf-4032-bc74-1999e12106c9","_cell_guid":"238cc0f8-d32d-4686-af86-1a0cda67d64c","trusted":true},"cell_type":"code","source":"class_ids = ['1','2','3','4']\nmask_count_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].count() for class_id in class_ids]\npixel_sum_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].sum() for class_id in class_ids]","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"10d07046-0d07-49b4-b17d-af665ffc95a2","_cell_guid":"e68066a8-18b3-4466-b486-dcaea087c48c","trusted":true},"cell_type":"code","source":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=class_ids, values=mask_count_per_class, name=\"Mask Count\"), 1, 1)\nfig.add_trace(Pie(labels=class_ids, values=pixel_sum_per_class, name=\"Pixel Count\"), 1, 2)\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Mask & Pixel Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Mask', x=0.18, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Pixel', x=0.80, y=0.5, font_size=20, showarrow=False)])\nfig.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"cf6649e1-1ed7-485c-85d6-2ae90b164ebd","_cell_guid":"4f9bb204-b474-4a78-96b1-8d314b6c1963","trusted":true},"cell_type":"code","source":"# plot a histogram and boxplot combined of the mask pixel sum per class Id\nfig = px.histogram(train_df[train_df['mask_pixel_sum']!=0][['ClassId','mask_pixel_sum']], \n                   x=\"mask_pixel_sum\", y=\"ClassId\", color=\"ClassId\", marginal=\"box\")\n\nfig['layout'].update(title='Histogram and Boxplot of Sum of Mask Pixels Per Class')\n\nfig.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c295b85c-cf1e-43f8-a473-b33007e07874","_cell_guid":"a4d3d1d6-ac39-4ff3-8c73-b2a9fbb238af","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a3dc751e-bcf6-4ea8-aa48-dfca596cbaf2","_cell_guid":"2087fd89-a3df-4e49-bc7d-6b1932cc98c6","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/severstal-steel-defect-detection/train.csv\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b457564f-c179-4195-91fe-43c29ac78641","_cell_guid":"cf2a3d24-eae1-4dec-9565-3da9a74e622d","trusted":true},"cell_type":"code","source":"df.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"fee8f2ee-6a89-442b-a024-5a1146fad4c6","_cell_guid":"45d91d66-2071-475d-9f49-4e8f4c4ea970","trusted":true},"cell_type":"markdown","source":"##### Convert training data-frame to the legacy version"},{"metadata":{"_uuid":"a85b1b6c-bcaf-420f-8788-32ec4716acfc","_cell_guid":"a45307ce-416f-47cc-9577-1b283ef37092","trusted":true},"cell_type":"code","source":"legacy_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\n\nfor img_id, img_df in tqdm_notebook(df.groupby('ImageId')):\n    for i in range(1, 5):\n        avail_classes = list(img_df.ClassId)\n\n        row = dict()\n        row['ImageId_ClassId'] = img_id + '_' + str(i)\n\n        if i in avail_classes:\n            row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n        else:\n            row['EncodedPixels'] = np.nan\n        \n        legacy_df = legacy_df.append(row, ignore_index=True)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"0beda6cf-7fc2-425c-af67-b29010759e00","_cell_guid":"f44f0e94-9d0a-4119-9b74-faf191cd7e93","trusted":true},"cell_type":"code","source":"legacy_df.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7b9d2edc-a56f-4bec-9848-93b3badab9ef","_cell_guid":"0150d04e-af30-4003-8cb4-866295143ef2","trusted":true},"cell_type":"code","source":"data = legacy_df\n\ndata.info()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"6648c075-4d79-4989-ab9f-87bda10d9215","_cell_guid":"347d982b-4cfa-45ff-8ffd-e45bc88fc6a4","trusted":true},"cell_type":"code","source":"defects = data[pd.notna(data.EncodedPixels)]\ndefects.EncodedPixels = 1\ndefects.info()\nprint(defects)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"267b5d64-b424-440f-9e34-c97d07d0247f","_cell_guid":"fbe36312-9497-404e-9004-1bceaa38144f","trusted":true},"cell_type":"code","source":"print((data.EncodedPixels).isnull())\nNoDefects = data[(data.EncodedPixels).isnull()]\nNoDefects.EncodedPixels = 0\nNoDefects.info()\nprint(NoDefects)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"65babe2e-1706-4d4e-9868-017d37034837","_cell_guid":"cd1ba7a2-4464-4e0c-ad56-20f301696f72","trusted":true},"cell_type":"code","source":"dataset= NoDefects.sample(defects.shape[0])\ndataset = dataset.append(defects,ignore_index=True)\ndataset = dataset.sample(frac=1, replace=True, random_state=1)\ndataset","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"88e9981f-e2cb-492c-b80b-0d106aafe405","_cell_guid":"c2bbbc28-ad42-4293-b4f5-2584a670dcff","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfilename = str(dataset.sample(1).ImageId_ClassId.values)[2:]\nfilename = filename[:-4]\nfilename = \"../input/severstal-steel-defect-detection/train_images/\"+filename\nprint(filename)\n\nimg=mpimg.imread(filename)\nimgplot = plt.imshow(img)\nplt.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7cb363c6-8405-4888-90b8-b09038a11b05","_cell_guid":"728a4482-235f-4651-8ee6-fad0782bc54a","trusted":true},"cell_type":"raw","source":"split train, val, test"},{"metadata":{"_uuid":"cfb350ec-82a7-4438-9e9a-21c5e4e253a6","_cell_guid":"11785264-122c-43e2-abf3-283557489406","trusted":true},"cell_type":"code","source":"val = dataset[0:1000]\ntest = dataset[1000:2000]\ntrain = dataset[2000:]\ntrain.info","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"493f9df1-246c-4fd0-8e16-20c3491aedd3","_cell_guid":"a4a6b913-5d7c-4dd4-9732-eca148694468","trusted":true},"cell_type":"code","source":"from skimage.feature import hog\nimport cv2\n\ndef my_extractHOG(filename):\n    filename = str(filename)\n    filename = filename[:-2]\n    filename = \"../input/severstal-steel-defect-detection/train_images/\" + filename\n    img = mpimg.imread(filename)\n    img = cv2.resize(img, dsize=(600, 70), interpolation=cv2.INTER_CUBIC)\n    print(str(i)+\"/\"+str(train.ImageId_ClassId.shape[0]))\n    img = img / 256\n    fd,hog_image = hog(img, orientations=8, pixels_per_cell=(ppc,ppc),cells_per_block=(4, 4),block_norm= 'L2',visualize=True)\n    return fd,hog_image\n\nppc = 16\nhog_images = []\nhog_features = []\n\nfor i, filename in enumerate(train.ImageId_ClassId):\n    fd,hog_image = my_extractHOG(filename)\n    if i<6 : hog_images.append(hog_image) # save some of images for example purpose only\n    hog_features.append(fd)\nprint (hog_features)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"09b99a1b-e5b3-49e7-a36d-aedc3494bed0","_cell_guid":"00e8a57d-62d6-4b5d-abe8-80a22be7233e","trusted":true},"cell_type":"code","source":"plt.imshow(hog_images[3])\nprint(hog_features[3].shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f82c1e4e-c416-487a-a9fa-0f227b84d74d","_cell_guid":"ed6ec84f-9148-49f0-8fed-dd6501e6bc45","trusted":true},"cell_type":"markdown","source":"svm"},{"metadata":{"_uuid":"b9ee560a-83b9-46fd-8d06-d66363849f72","_cell_guid":"bfbdaab8-53a7-4e1a-aa20-4b6e9d5454bf","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclf = SVC(gamma='auto')\nprint(train.EncodedPixels.values.shape)\ny = train.EncodedPixels.values\nX = np.array(hog_features)\nprint(X.shape)\nclf.fit(X,y)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b11e875b-bf83-4141-8aa1-f2a3e3f743eb","_cell_guid":"105e4566-a36c-44db-bcfe-4024e1ba8c95","trusted":true},"cell_type":"markdown","source":"test SVM predictions"},{"metadata":{"_uuid":"54a9304d-bb81-4f9b-8789-6fe5913f94cd","_cell_guid":"9b65bbd8-fd5e-403d-96e2-0ba091d1e4d7","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ny_scores = [] # init array\nhog_features2 = []\nfor i, filename in enumerate(test.ImageId_ClassId):\n    fd,hog_image = my_extractHOG(filename)\n    out = clf.predict([np.array(fd)])\n    y_scores.append(out)\n    print(len(y_scores))\n    hog_features2.append(fd)\ny_true = test.EncodedPixels.values\ny_scores = np.array(y_scores)\nroc_auc_score(y_true, y_scores)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"3f55e8df-7530-4149-9bf5-0688efb5c24b","_cell_guid":"4b91f090-a611-410a-b62b-24bb1ae3da85","trusted":true},"cell_type":"markdown","source":"catboost"},{"metadata":{"_uuid":"9fa90842-007e-4788-a49b-5d9708676c61","_cell_guid":"d8e22247-14bc-4025-baaf-b410beac63a1","trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool\ncat_features = [0]\nX = 10000 * X\nX = X.astype(int)\nprint(X)\ny.astype(int)\nprint(y)\nXval = 10000*np.array(hog_features2)\nprint(Xval)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"78adf2ab-fa1e-485a-9f71-da306c37b70a","_cell_guid":"7f39c4f8-940c-47cf-8db6-eefa2cb02c7b","trusted":true},"cell_type":"raw","source":"train"},{"metadata":{"_uuid":"d568180f-c131-4dcd-9a63-464cf53689c0","_cell_guid":"cb0170ce-bac8-49aa-aee3-b1a75e3f1855","trusted":true},"cell_type":"code","source":"train_dataset = Pool(data=X,\n                     label=y,\n                     cat_features=cat_features)\n\neval_dataset = Pool(data=Xval.astype(int),\n                    label=y_true,\n                    cat_features=cat_features)\n\n# Initialize CatBoostClassifier\nmodel = CatBoostClassifier(iterations=300,\n                           learning_rate=1,\n                           depth=2,\n                           custom_metric='AUC')\n# Fit model\nmodel.fit(train_dataset, eval_set=eval_dataset, use_best_model=True)\n# Get predicted classes\npreds_class = model.predict(eval_dataset)\nprint(preds_class)\n# Get predicted probabilities for each class\npreds_proba = model.predict_proba(eval_dataset)\n# Get predicted RawFormulaVal\npreds_raw = model.predict(eval_dataset,\n                          prediction_type='RawFormulaVal')\nprint(model.get_best_score())\nmodel.save_model('1layer_catboost')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"64d32a99-38b0-4553-a181-218a75e91fe2","_cell_guid":"4f602997-1fbd-4779-83e5-2b49ef87793b","trusted":true},"cell_type":"markdown","source":"Simple example of U-net for segmentation in Keras"},{"metadata":{"_uuid":"67dc2fab-6c0a-4bc6-a18b-3d3c14e1d25f","_cell_guid":"081bd973-f6f5-4484-bec5-6099bf346bc6","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\n\nimport keras\nfrom keras.layers.convolutional import Conv2DTranspose\nfrom keras.layers.merge import concatenate\nfrom keras.layers import UpSampling2D, Conv2D, Activation, Input, Dropout, MaxPooling2D\nfrom keras import Model\nfrom keras import backend as K\nfrom keras.layers.core import Lambda","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8d69dd7a-9306-4c4f-9df4-e42125bf7118","_cell_guid":"6b63232d-03e9-4e57-9bab-5c7d0d9e9af1","trusted":true},"cell_type":"code","source":"DATASET_DIR = '../input/severstal-steel-defect-detection'\ndf = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"61ea5aa6-7beb-475c-b30e-f87836a5be5f","_cell_guid":"1e4a775e-2f84-4c44-99eb-c769f8ce318a","trusted":true},"cell_type":"code","source":"df.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9cb579fd-5711-4285-aa00-b1d1b506c234","_cell_guid":"c77b1be2-930f-41a9-906b-e221e69a3bd8","trusted":true},"cell_type":"markdown","source":"##### Convert training data-frame to the legacy version"},{"metadata":{"_uuid":"1937000f-cc1a-41ad-9708-702218593ca3","_cell_guid":"3272d3c0-72fb-43d4-983b-d9f829c5a2fb","trusted":true},"cell_type":"code","source":"legacy_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\n\nfor img_id, img_df in tqdm_notebook(df.groupby('ImageId')):\n    for i in range(1, 5):\n        avail_classes = list(img_df.ClassId)\n\n        row = dict()\n        row['ImageId_ClassId'] = img_id + '_' + str(i)\n\n        if i in avail_classes:\n            row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n        else:\n            row['EncodedPixels'] = np.nan\n        \n        legacy_df = legacy_df.append(row, ignore_index=True)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"6bd907ab-fb97-4783-9143-18375d9c1150","_cell_guid":"a49c3b9a-4cb7-420c-a059-9d610ec5fda4","trusted":true},"cell_type":"code","source":"legacy_df.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"d3c9a991-2e9d-41f3-9960-ff2dcdb15c7a","_cell_guid":"08a9e42e-89f9-435a-9464-035de0ed3ba8","trusted":true},"cell_type":"code","source":"tr = legacy_df\n\ntr.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c05358da-4338-4bc5-9eef-c5167bc18cfe","_cell_guid":"4d97e6bc-df0d-4cf0-99b2-fce4a10c63a6","trusted":true},"cell_type":"code","source":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"86795b31-2191-491a-a36b-e5679f5c0ccb","_cell_guid":"d2d9e1d7-4018-40bc-9dbf-68192fc61485","trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9e2ec4a9-ff73-4161-a187-8ee6ab99287f","_cell_guid":"21319e64-0fc5-453c-a861-a130e8173d3a","trusted":true},"cell_type":"code","source":"img_size = 256","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"baed0577-35c4-48ec-99cc-f48c5660e185","_cell_guid":"cb113e1d-5c30-4e87-af04-67cbbb5d7a90","trusted":true},"cell_type":"code","source":"def keras_generator(batch_size):\n    while True:\n        x_batch = []\n        y_batch = []\n        \n        for i in range(batch_size):            \n            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n            img = cv2.imread( '../input/severstal-steel-defect-detection/train_images/'+fn )\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n            \n            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n            \n            img = cv2.resize(img, (img_size, img_size))\n            mask = cv2.resize(mask, (img_size, img_size))\n            \n            x_batch += [img]\n            y_batch += [mask]\n                                    \n        x_batch = np.array(x_batch)\n        y_batch = np.array(y_batch)\n\n        yield x_batch, np.expand_dims(y_batch, -1)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9b6e3332-ee47-47cd-a127-2776909639e3","_cell_guid":"2f554e7f-1cc4-49c1-9d8e-f4b37f33b512","trusted":true},"cell_type":"code","source":"for x, y in keras_generator(4):\n    break\n    \nprint(x.shape, y.shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"95b2a83e-574a-4920-88c7-f5086eca11a4","_cell_guid":"696dd5f1-9356-4c6d-a168-9efdc22993b4","trusted":true},"cell_type":"code","source":"plt.imshow(x[3])","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"d7c27e91-ca15-4496-a531-f9af4a093b9c","_cell_guid":"bdb19f74-2c32-4b70-ad60-c54d601ba9e6","trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(y[3]))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"74cca637-0a07-452c-bd22-b155dfbc40a8","_cell_guid":"eab2b2c5-a705-4133-b545-902da6cadbaf","trusted":true},"cell_type":"code","source":"","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"876a70fb-f6b0-463f-b751-8b25ab3220f3","_cell_guid":"a8e37975-1e57-433b-a166-ae19de837016","trusted":true},"cell_type":"code","source":"#Model\n\ninputs = Input((256, 256, 3))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"33b06ec2-473b-4596-80fd-8c87c745c36b","_cell_guid":"535e8147-82cb-4f0f-b555-c5258313395a","trusted":true},"cell_type":"code","source":"%%time\n# Fit model\nbatch_size = 16\nresults = model.fit_generator(keras_generator(batch_size), \n                              steps_per_epoch=100,\n                              epochs=1)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"dcba2394-b79b-490b-8c13-9524e526849c","_cell_guid":"96cf6498-3388-4771-808a-3ace0af7407c","trusted":true},"cell_type":"code","source":"pred = model.predict(x)\nplt.imshow(np.squeeze(pred[3]))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"bd8df120-7d1e-4fc9-81f5-79f0a4541ee1","_cell_guid":"11237291-9bad-40ba-8d96-814e5f735318","trusted":true},"cell_type":"code","source":"testfiles=os.listdir(\"../input/severstal-steel-defect-detection/test_images/\")\nlen(testfiles)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c0374b0e-07d8-4b32-8a17-bddaace4f61b","_cell_guid":"4f97eb20-80ba-412e-b438-2d5dd4d8968f","trusted":true},"cell_type":"code","source":"%%time\ntest_img = []\nfor fn in tqdm_notebook(testfiles):\n        img = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+fn )\n        img = cv2.resize(img,(img_size,img_size))       \n        test_img.append(img)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"dea326c8-89e5-401d-aa0a-5136c71dda68","_cell_guid":"dc5342ab-1dd6-44bb-8a2e-136abb7077d3","trusted":true},"cell_type":"code","source":"%%time\npredict = model.predict(np.asarray(test_img))\nprint(len(predict))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"e3fdfc0d-b6b6-40be-b94e-5e205d7557d8","_cell_guid":"8d015d9d-f929-4a5c-8092-3168cc39019e","trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(stnartpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"06063b98-8ee2-4276-a9b5-d41bd871faf6","_cell_guid":"2138b37b-076c-4f2e-9ea0-0987ba1ec6e3","trusted":true},"cell_type":"code","source":"%%time\npred_rle = []\nfor img in predict:      \n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<np.mean(img)] = 0\n    tmp[tmp>0] = 1\n    pred_rle.append(mask2rle(tmp))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"91d0c6c2-fed3-4fa2-b791-f015526491f7","_cell_guid":"4e0efe22-bb8e-4d21-a065-dc4330fba956","trusted":true},"cell_type":"code","source":"img_t = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+ testfiles[4])\nplt.imshow(img_t)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9eab59a2-5122-4958-b380-5c5a43cef4ae","_cell_guid":"94d55410-ca89-4af1-9540-db7cc5dd0a8f","trusted":true},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"4595fd70-cf79-402b-bb46-52e141570979","_cell_guid":"573ed9f2-d813-480b-9265-d7de4797b8b7","trusted":true},"cell_type":"code","source":"mask_t = rle2mask(pred_rle[4], img.shape)\nplt.imshow(mask_t)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ca816caa-ad9b-4ae5-ac18-a913c77aad69","_cell_guid":"1904469e-9997-4723-bbf0-d2de5d399e4d","trusted":true},"cell_type":"code","source":"sub = pd.read_csv( '../input/submission/submission_tta.csv' )\nsub.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"1b9cf761-04a0-4832-b3b0-f8cea47f0857","_cell_guid":"9559101c-1a86-4e5e-8faf-7998700c13e9","trusted":true},"cell_type":"code","source":"%%time\nfor fn, rle in zip(testfiles, pred_rle):\n    sub['EncodedPixels'][sub['ImageId_ClassId'].apply(lambda x: x.split('_')[0]) == fn] = rle","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"124334da-fc1d-45c8-b282-579fa0b00132","_cell_guid":"531bcd50-09ab-419d-b238-0ca63a5c67e0","trusted":true},"cell_type":"code","source":"sub.head(8)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8e4d933a-d5b2-42c5-b06f-64d7cdeea470","_cell_guid":"3bbf7563-2b44-489f-ba47-10eb4cdad569","trusted":true},"cell_type":"code","source":"img_s = cv2.imread( '../input/severstal-steel-defect-detection/test_images/'+ sub['ImageId_ClassId'][16].split('_')[0])\nplt.imshow(img_s)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ccff0d12-04c2-4bff-a0dc-4585d3fa767d","_cell_guid":"dedcea27-4006-4260-9497-2a3d1a738a30","trusted":true},"cell_type":"code","source":"mask_s = rle2mask(sub['EncodedPixels'][16], (256, 1600))\nplt.imshow(mask_s)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ac52f2fa-98fe-4445-9206-beff5ad4115e","_cell_guid":"5337ec46-e6c6-4440-b088-ceab43a4f21b","trusted":true},"cell_type":"code","source":"sub.to_csv('submission_tta.csv', index=False)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"74a6953b-2a50-43dc-ab0b-787ddba25b99","_cell_guid":"d860dcf7-f87b-4373-b546-fb9793ef9ffd","trusted":true},"cell_type":"code","source":"sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a639660f-9d2d-46b2-a23d-bb3e82df0db9","_cell_guid":"4a062de3-bf13-4370-a1e6-4ec74be2a650","trusted":true},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}