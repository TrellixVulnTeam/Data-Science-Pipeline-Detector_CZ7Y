{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir /local_packages\n!cp ../input/offline-packages/pretrainedmodels.xy /local_packages/pretrainedmodels-0.7.4.tar.gz\n!cp ../input/offline-packages/efficientnet_pytorch.xy /local_packages/efficientnet_pytorch-0.6.3.tar.gz\n!cp ../input/offline-packages/segmentation_models_pytorch-0.2.0-py3-none-any.whl /local_packages/segmentation_models_pytorch-0.2.0-py3-none-any.whl\n!cp ../input/offline-packages/timm-0.4.12-py3-none-any.whl /local_packages/timm-0.4.12-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:02.577392Z","iopub.execute_input":"2021-11-10T10:35:02.577695Z","iopub.status.idle":"2021-11-10T10:35:06.085637Z","shell.execute_reply.started":"2021-11-10T10:35:02.577617Z","shell.execute_reply":"2021-11-10T10:35:06.084464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /local_packages","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:06.09236Z","iopub.execute_input":"2021-11-10T10:35:06.094713Z","iopub.status.idle":"2021-11-10T10:35:06.809742Z","shell.execute_reply.started":"2021-11-10T10:35:06.094667Z","shell.execute_reply":"2021-11-10T10:35:06.80882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U --no-index --find-links /local_packages segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:06.812417Z","iopub.execute_input":"2021-11-10T10:35:06.813283Z","iopub.status.idle":"2021-11-10T10:35:19.240169Z","shell.execute_reply.started":"2021-11-10T10:35:06.813219Z","shell.execute_reply":"2021-11-10T10:35:19.239197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/offline-packages/inceptionv4-8e4777a0.pth /root/.cache/torch/hub/checkpoints/","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:19.242847Z","iopub.execute_input":"2021-11-10T10:35:19.243078Z","iopub.status.idle":"2021-11-10T10:35:24.713556Z","shell.execute_reply.started":"2021-11-10T10:35:19.243048Z","shell.execute_reply":"2021-11-10T10:35:24.712598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\nmodel = smp.Unet(\n    encoder_name=\"inceptionv4\",\n    encoder_weights=\"imagenet\",\n    in_channels=1,\n    classes=4,                   \n)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:24.715632Z","iopub.execute_input":"2021-11-10T10:35:24.716094Z","iopub.status.idle":"2021-11-10T10:35:33.493328Z","shell.execute_reply.started":"2021-11-10T10:35:24.716054Z","shell.execute_reply":"2021-11-10T10:35:33.492521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\nfrom albumentations.pytorch import ToTensorV2\nimport torch.utils.data as data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-10T10:35:33.494815Z","iopub.execute_input":"2021-11-10T10:35:33.495364Z","iopub.status.idle":"2021-11-10T10:35:35.524274Z","shell.execute_reply.started":"2021-11-10T10:35:33.495298Z","shell.execute_reply":"2021-11-10T10:35:35.523541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.525574Z","iopub.execute_input":"2021-11-10T10:35:35.525844Z","iopub.status.idle":"2021-11-10T10:35:35.532001Z","shell.execute_reply.started":"2021-11-10T10:35:35.525809Z","shell.execute_reply":"2021-11-10T10:35:35.531162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, mean, std):\n        self.root = root\n        self.fnames = list(set(os.listdir('../input/severstal-steel-defect-detection/test_images')))\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensorV2(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.534168Z","iopub.execute_input":"2021-11-10T10:35:35.534669Z","iopub.status.idle":"2021-11-10T10:35:35.550558Z","shell.execute_reply.started":"2021-11-10T10:35:35.534619Z","shell.execute_reply":"2021-11-10T10:35:35.549786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.552143Z","iopub.execute_input":"2021-11-10T10:35:35.552473Z","iopub.status.idle":"2021-11-10T10:35:35.562857Z","shell.execute_reply.started":"2021-11-10T10:35:35.552437Z","shell.execute_reply":"2021-11-10T10:35:35.56213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\ntest_data_folder = \"../input/severstal-steel-defect-detection/test_images\"","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.565567Z","iopub.execute_input":"2021-11-10T10:35:35.565928Z","iopub.status.idle":"2021-11-10T10:35:35.572246Z","shell.execute_reply.started":"2021-11-10T10:35:35.565891Z","shell.execute_reply":"2021-11-10T10:35:35.571541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize test dataloader\nbest_threshold = 0.5\nnum_workers = 2\nbatch_size = 4\nprint('best_threshold', best_threshold)\nmin_size = 3500\nmean = np.mean((0.485, 0.456, 0.406))\nstd = np.mean((0.229, 0.224, 0.225))\ntestset = DataLoader(\n    TestDataset(test_data_folder, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.573604Z","iopub.execute_input":"2021-11-10T10:35:35.573964Z","iopub.status.idle":"2021-11-10T10:35:35.610765Z","shell.execute_reply.started":"2021-11-10T10:35:35.573929Z","shell.execute_reply":"2021-11-10T10:35:35.610042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize mode and load trained weights\nckpt_path = \"../input/unetmodelfile/model.pth\"\ndevice = torch.device(\"cuda\")\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.611959Z","iopub.execute_input":"2021-11-10T10:35:35.612625Z","iopub.status.idle":"2021-11-10T10:35:35.616137Z","shell.execute_reply.started":"2021-11-10T10:35:35.612588Z","shell.execute_reply":"2021-11-10T10:35:35.615381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# start prediction\npredictions = []\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold, min_size)\n            rle = mask2rle(pred)\n            name = fname + f'_{cls+1}'\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T10:35:35.617539Z","iopub.execute_input":"2021-11-10T10:35:35.618261Z","iopub.status.idle":"2021-11-10T10:35:35.628303Z","shell.execute_reply.started":"2021-11-10T10:35:35.618202Z","shell.execute_reply":"2021-11-10T10:35:35.627516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}