{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nWelcome to the Severstal: Steel Defect Detection competition. This competition is a two-fold competition: classify the type of steel defect, and also segment the parts of the image that contain the defect.\n\nIn this kernel, I will do a quick EDA and then I will convert to a classification problem for future kernels.\n"},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../input/severstal-steel-defect-detection'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the training set csv file:"},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_dir = Path('../input/severstal-steel-defect-detection')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(comp_dir/'train.csv')\ntrain_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at this we can see that the format is to fill in the EncodedPixels columens only at the rows  for the identified class for the selected image. For example, 0002cc93b.jpg has a label of 1, 00031f466.jpg has no defects, and 0007a71bf.jpg has a label of 3."},{"metadata":{},"cell_type":"markdown","source":"### Conversion to classification\n\nI believe that one possible strategy for this competition would be to perhaps first create a classifier and have separate segmentation models for each of the defect types. As a first step to do this, I reformat the data, converting it into a multi-label classification problem."},{"metadata":{},"cell_type":"markdown","source":"Lazy conversion to classification labels:"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\nfor i in range(len(train_df)):\n    if type(train_df.EncodedPixels[i]) == str:\n        labels.append(1)\n    else:\n        labels.append(0)\nlabels = np.array(labels)\nlabels = labels.reshape((int(len(train_df)/4),4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_0 = np.array(len(labels) - np.sum(np.sum(labels,axis=0)))\nbar_plot = np.append(label_0[None].T,np.sum(labels,axis=0))\nplt.bar(np.array(['none','0','1','2','3']),bar_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Most common is no defect, and defect of type 2. In fact we see that 10% of the labels have no label and 10% have are label of type 2:\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_0/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot[3]/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now convert this to something fastai can view."},{"metadata":{"trusted":true},"cell_type":"code","source":"images_df = pd.DataFrame(train_df.iloc[::4,:].ImageId_ClassId.str[:-2].reset_index(drop=True))\nlabels_df = pd.DataFrame(labels.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proc_train_df= pd.concat((images_df,labels_df),1)\nproc_train_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load into fastai:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(proc_train_df,path=comp_dir,folder='train_images')\n        .split_by_rand_pct(0.2)\n        .label_from_df(cols=[1,2,3,4])\n        .transform(get_transforms())\n        .databunch(bs=16)\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.train_ds[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the images have a fixed size of 256x1600."},{"metadata":{},"cell_type":"markdown","source":"## Training a classifier\n\nLet's create a classifier using fastai."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n        os.makedirs('/tmp/.cache/torch/checkpoints/')\n!cp '../input/resnet50/resnet50.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.metrics import *\nlearn = cnn_learner(data,models.resnet50,metrics=accuracy_thresh)\nlearn.model_dir = Path('../models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1,2e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5,slice(1e-6,1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(learn.validate())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}