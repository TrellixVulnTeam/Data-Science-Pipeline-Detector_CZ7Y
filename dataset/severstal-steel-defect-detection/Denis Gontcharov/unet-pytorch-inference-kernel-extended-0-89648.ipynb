{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Extension notes\n\nThis notebook is an extension of [Rishabh's](https://www.kaggle.com/rishabhiitbhu) [inference kernel](https://www.kaggle.com/rishabhiitbhu/unet-pytorch-inference-kernel). <br>\nIf you find this notebook useful, don't forget to give his notebook an upvote as well. <br>\nI want to thank Rishabh for not only providing the original kernel, but also assisting me with my questions in the comments.\n\nThe notebook is configured to submit results of a U-net architecture with (1) resnet and (2) se_resnet encoders. <br>\nThe following encoders are supported in this notebook:\n\n* (1) resnet18, resnet34, resnet50, resnet101, resnet152\n* (2) senet154, se_resnet50, se_resnet101, se_resnet152, se_resnext50_32x4d, se_resnext101_32x4d\n\nYou can train a model offline with any of the above encoders and submit the results using this notebook.\n\nFour locally trained models are available in this notebook:\n\n1. resnet18_20_epochs.pth the model from the original notebook\n2. senet50_20_epochs.pth a U-net using a pretrained se_resnet50 encoder.\n3. senext50_30_epochs.pth a U-net using a pretrained se_resnext50_32x4d.\n4. senext50_30_epochs_high_threshold.pth a U-net using a pretrained se_resnext50_32x4d encoder where the base_threshold was set to 0.8.\n\nFor the U-net model with the senext50 encoder, setting the base_threshold from 0.5 to 0.8 <br>\nimproved the score from 0.88776 to 0.89648 leaving everything else the same. \n"},{"metadata":{},"cell_type":"markdown","source":"### package_path instructions\n\nChange the *package_path*:\n\n* to *'../input/resnetunetmodelcode'* if you use a (1) resnet encoder \n* to *'../input/senetunetmodelcode'* if you use a (2) senet encoder."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null\n# package_path = '../input/resnetunetmodelcode'\npackage_path = '../input/senetunetmodelcode'\nimport sys\nsys.path.append(package_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\n# from albumentations.torch import ToTensor was renamed to:\nfrom albumentations.pytorch import ToTensor\nimport torch.utils.data as data\nfrom senet_unet_model_code import Unet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Available models\n\nThis notebook contains three model.pth files that were trained locally. "},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/pretrainedmodels\n!ls ../input/resnetunetmodelcode\n!ls ../input/resnetmodels\n!ls ../input/senetunetmodelcode\n!ls ../input/senetmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std):\n        self.root = root\n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensor(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\ntest_data_folder = \"../input/severstal-steel-defect-detection/test_images\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize test dataloader\nbest_threshold = 0.5\nnum_workers = 2\nbatch_size = 4\nprint('best_threshold', best_threshold)\nmin_size = 3500\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model selection instructions\n\nIf you want to use a model included in this notebook:\n\n1. Uncomment the corresponding ckpt_path.\n2. Write the encoder name (see above) into the Unet() call.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize mode and load trained weights\n# ckpt_path = \"../input/resnetmodels/resnet18_20_epochs.pth\"\n# ckpt_path = \"../input/senetmodels/senet50_20_epochs.pth\"\nckpt_path = \"../input/senetmodels/senext50_30_epochs.pth\"\ndevice = torch.device(\"cuda\")\n# change the encoder name in the Unet() call.\nmodel = Unet('se_resnext50_32x4d', encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start prediction\npredictions = []\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold, min_size)\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Refrences (from Rishabh's original notebook):\n\nFew kernels from which I've borrowed some code:\n\n* https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n* https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n\nA big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https://www.kaggle.com/abhishek), [@Yury](https://www.kaggle.com/deyury), [@Heng](https://www.kaggle.com/hengck23), [@Ekhtiar](https://www.kaggle.com/ekhtiar), [@lafoss](https://www.kaggle.com/iafoss), [@Siddhartha](https://www.kaggle.com/meaninglesslives), [@xhulu](https://www.kaggle.com/xhlulu), and the list goes on.."},{"metadata":{},"cell_type":"markdown","source":"Do upvote if you liked my kernel :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}