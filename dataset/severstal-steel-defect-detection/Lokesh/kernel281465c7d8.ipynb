{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os, gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image \nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/'\ntrain = pd.read_csv(path + 'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).values\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, preprocess=None, info={}):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index): \n        X =np.empty((self.batch_size,128,800,3),dtype=np.float32)\n        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f).resize((800,128))\n            if self.subset == 'train': \n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess!=None: X = self.preprocess(X)\n        if self.subset == 'train': return X, y\n        else: return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13.5,2.5))\nbar = plt.bar( [1,2,3,4],100*np.mean( train2.iloc[:,1:5]!='',axis=0) )\nplt.title('Percent Training Images with Defect', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Defect Type')\nplt.xticks([1,2,3,4])\nfor rect in bar:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=16)\nplt.ylim((0,50)); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# DEFECTIVE IMAGE SAMPLES\nfilenames = {}\ndefects = list(train2[train2['e1']!=''].sample(3).index)\ndefects += list(train2[train2['e2']!=''].sample(3).index)\ndefects += list(train2[train2['e3']!=''].sample(7).index)\ndefects += list(train2[train2['e4']!=''].sample(3).index)\n\n# DATA GENERATOR\ntrain_batches = DataGenerator(train2[train2.index.isin(defects)],shuffle=True,info=filenames)\nprint('Images and masks from our Data Generator')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\n# DISPLAY IMAGES WITH DEFECTS\nfor i,batch in enumerate(train_batches):\n    plt.figure(figsize=(14,50)) #20,18\n    for k in range(16):\n        plt.subplot(16,1,k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        extra = 'has defect'\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            msk = mask2pad(msk,pad=3)\n            msk = mask2contour(msk,width=2)\n            if np.sum(msk)!=0: extra += ' '+str(j+1)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        plt.title(filenames[16*i+k]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nfrom keras.models import load_model\n\n# https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\n\n# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = load_model(r'../input/lokkrish/unet.model.14.hdf5',custom_objects={'dice_coef':dice_coef})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_testdata(a):\n\n    data = []\n    c = 1\n\n    for i in range(a.shape[0]-1):\n        if a[i]+1 == a[i+1]:\n            c += 1\n            if i == a.shape[0]-2:\n                data.append(str(a[i-c+2]))\n                data.append(str(c))\n\n        if a[i]+1 != a[i+1]:\n            data.append(str(a[i-c+1]))\n            data.append(str(c))\n            c = 1\n\n    data = \" \".join(data)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_path = \"../input/severstal-steel-defect-detection/test_images/\"\n\n# test_list = os.listdir(test_path)\n\n# data = []\n\n# for fn in test_list:\n#     abs_name = test_path + fn\n#     a = Image.open(abs_name).resize((800,128))\n#     x=np.expand_dims(a, axis=0)\n#     pred = model1.predict(x)\n#     for i in range(4):\n#         pred_fi = pred[:,:,i+1].T.flatten()\n#         pred_fi = np.where(pred_fi > 0.3, 1, 0)\n#         pred_fi_id = np.where(pred_fi == 1)\n#         pred_fi_id = make_testdata(pred_fi_id[0])\n#         x = [fn + \"_\" + str(i+1), pred_fi_id]\n#         data.append(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns = ['ImageId_ClassId', 'EncodedPixels']\n# d = pd.DataFrame(data=data, columns=columns, dtype='str')\n\n# def expand(x):\n#     new_val = ''\n#     val = x.split(' ')\n#     for char in val:\n#         doub = str(int(char)*2)\n#         new_val = new_val+doub+' '\n#         new_val[:-1]\n#     return new_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['ImageId_ClassId', 'EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#d = pd.DataFrame(data=data, columns=columns, dtype='str')\n#d['EncodedPixels'] = d['EncodedPixels'].apply(lambda x: expand(x) if x!='' else '')\nd = pd.read_csv(r'../input/submission7/submission(4).csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nd['EncodedPixels'] = d['EncodedPixels'].apply(lambda x:(str(x)[:-1]) if len(str(x))>0 else str(\"\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['EncodedPixels'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['EncodedPixels'].replace('na', '', regex=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}