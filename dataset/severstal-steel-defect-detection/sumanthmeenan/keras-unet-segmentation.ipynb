{"cells":[{"metadata":{"_uuid":"834591ca-8654-4fb7-8f7b-634da56de8d6","_cell_guid":"43a609dc-de22-464f-8242-8380a1886960","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, \nimport cv2\n# Input data files are available in the \"../input/\" directory\nimport os\nimport matplotlib.pyplot as plt\nimport itertools\n# import segmentation_models as sm\nimport keras\nimport random\n# from iteration_utilities import unique_everseen\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"336c3450-3a26-448c-9728-607b5a1ba87e","_cell_guid":"969f23f4-c383-496d-8edf-882f7984849f","trusted":true},"cell_type":"code","source":"#list(os.walk('/kaggle/input'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"321ea1f7-f7ee-4028-bbc1-3bc6dfd2995b","_cell_guid":"6deb8330-1022-4650-b366-235738c83f10","trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3dae910-4b95-4e10-b206-7ed5de5d936c","_cell_guid":"a0dc916f-3ec0-4f1f-8380-46f42db77392","trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79002dad-3dd0-49dd-bb2f-5fcde7bf717f","_cell_guid":"8294b48a-9f27-476f-9b8f-6469bfbc75d4","trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac3d100c-1ee1-442d-a882-364dd4bf1484","_cell_guid":"beed06e4-1f73-4c38-aae9-f2015cf4af3a","trusted":true},"cell_type":"code","source":"dir1 = '/kaggle/input/severstal-steel-defect-detection/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cbab2f4-ef9a-4b6e-8277-4e5d2be107b6","_cell_guid":"aa41112b-27d4-4b33-8bb9-b40540e0265e","trusted":true},"cell_type":"code","source":"df = pd.read_csv(dir1 + 'train.csv')\ndf.head()\n#Each image is given along with its class id","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f10adb6-efb0-4593-bce4-dc55bd950aef","_cell_guid":"dc325da5-6f0e-4d5e-816a-ea6c9fb51e10","trusted":true},"cell_type":"code","source":"df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d31fef66-52bc-476c-a7f1-390d825a1455","_cell_guid":"46d4af38-8529-4762-a898-a32bbfe1f3e2","trusted":true},"cell_type":"code","source":"len(os.listdir(dir1 + 'train_images/'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a13fd486-3696-4735-add7-f15cd486aafb","_cell_guid":"bd46709d-2b06-4378-a891-0c99aa5bd8a9","trusted":true},"cell_type":"code","source":"len(os.listdir(dir1 + 'test_images/'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f792b6be-a310-4a60-a855-d0b647bb4a8b","_cell_guid":"8e0d63b7-b887-4c46-b9ab-2c19c41a38d2","trusted":true},"cell_type":"code","source":"def visualize_img():\n    num = np.random.randint(0, len(os.listdir(dir1 + 'train_images/')))\n    img = cv2.imread(dir1 + 'train_images/'+os.listdir(dir1 + 'train_images/')[num])\n    print(img.shape)\n    print(os.listdir(dir1 + 'train_images/')[num])\n\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, \n\nimport cv2\n\n# Input data files are available in the \"../input/\" directory\n\nimport os\n\nimport matplotlib.pyplot as plt\n\nimport itertools\n\n# import segmentation_models as sm\n\nimport keras\n\nimport random\n\n# from iteration_utilities import unique_everseen\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n\n#     for filename in filenames:\n\n#         print(os.path.join(dirname, filename))\n\nUsing TensorFlow backend.\n\n#list(os.walk('/kaggle/input'))\n\nos.listdir('/kaggle/')\n\n['lib', 'input', 'config', 'working']\n    plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb0d299e-c6eb-45d8-a2c9-49302a699544","_cell_guid":"d078cd15-2c4b-46c1-ad3f-3c31acc867d4","trusted":true},"cell_type":"code","source":"visualize_img()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e331af6-dbec-4cb6-876e-f7dc76eb4704","_cell_guid":"774d2292-8ce3-4a75-8fda-e6b05f37db49","trusted":true},"cell_type":"code","source":"df.loc[df['ImageId_ClassId'].isin(['f380e604c.jpg_{}'.format(i) for i in range(1,5)])]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a875058b-d92f-44fb-bac6-90a9252520e2","_cell_guid":"3a996afa-d6e0-4c49-86b2-0b0868b21e10","trusted":true},"cell_type":"code","source":"df[df['ImageId_ClassId'] == 'f380e604c.jpg_3']['EncodedPixels'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76295ed7-c396-42b5-ac04-ddf89118dcdc","_cell_guid":"2d4d1f43-ca7d-4285-9f55-6ad49e41d557","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f4fa1d6-a43c-4322-83f1-7fc4ced68f1c","_cell_guid":"0326bc39-ecfb-4172-973d-94ad84debc85","trusted":true},"cell_type":"code","source":"df['ImageId'] = [i.split('_')[0] for i in df['ImageId_ClassId'].tolist()]\ndf['ClassId'] = [i.split('_')[1] for i in df['ImageId_ClassId'].tolist()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87b15712-fdfe-4402-9f3f-50a3164aad8c","_cell_guid":"991c62dd-d81d-4d2b-961d-76641a9b97a3","trusted":true},"cell_type":"code","source":"uniq_ids = list(np.unique(df['ImageId']))\nlen(uniq_ids)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7844d2cc-16da-4835-afb6-2aa1004a1336","_cell_guid":"f2b33fd9-7438-4c7b-96c3-55ad925bf2a0","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c1ba7fc-bba6-489a-9dd7-cdba79871aef","_cell_guid":"a95107cc-afbf-4b24-b9da-a1db31570676","trusted":true},"cell_type":"code","source":"df['EncodedPixels'] = df['EncodedPixels'].replace(np.nan, 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"399518c8-0a78-422c-9505-0c2fd0780787","_cell_guid":"4dab5949-2b81-4b0b-9cc9-5a2b72f32751","trusted":true},"cell_type":"code","source":"df.head(8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6853116-1fd7-48c7-946e-3d5510b2b61d","_cell_guid":"f03ff9aa-f6ec-429d-a2ed-feeb86b11f03","trusted":true},"cell_type":"code","source":"#Total images available for training are 12568 for each class\ndf['ClassId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d97216f-4995-4c25-8f9e-4c9377306dc3","_cell_guid":"fe1ea6f2-b08b-4576-ab53-6ace8588656e","trusted":true},"cell_type":"code","source":"df1 = df[df['EncodedPixels']!=0]\ndf1.head(8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b1442fa-8b3b-4aa3-b4a0-e090625a0e8b","_cell_guid":"2fb4f93a-2c49-4ec3-99ed-7cb1833867b5","trusted":true},"cell_type":"code","source":"df1['ClassId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c9a1f0a-096b-435b-8786-4d16dbf07651","_cell_guid":"53ef90c5-6813-49fa-89bb-35a51e1f2e3c","trusted":true},"cell_type":"code","source":"class_id_1 = df1[df1['ClassId'] == '1']['ImageId'].tolist()\nclass_id_2 = df1[df1['ClassId'] == '2']['ImageId'].tolist()\nclass_id_3 = df1[df1['ClassId'] == '3']['ImageId'].tolist()\nclass_id_4 = df1[df1['ClassId'] == '4']['ImageId'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e68c89e-3acd-444e-9ae6-65ef5d596931","_cell_guid":"fcc8768b-a6cf-4732-8e4f-50e34e1d8c2f","trusted":true},"cell_type":"code","source":"len(class_id_1),len(class_id_2),len(class_id_3),len(class_id_4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03dd3339-a247-4074-9e4a-5609cde0e80b","_cell_guid":"b62bac45-7b12-4eb4-a007-0196788f1036","trusted":true},"cell_type":"code","source":"all_defect_images = class_id_1 + class_id_2 + class_id_3 + class_id_4\ndefect_images = list(set(all_defect_images))\nall_images = list(set(df['ImageId']))\nnon_defect_images = [i for i in all_images if i not in defect_images]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"646ba246-6275-4bc4-867d-cff8b37cfb61","_cell_guid":"b753b70e-7433-4a1e-85fe-4d831dcf0b4e","trusted":true},"cell_type":"code","source":"len(defect_images), len(non_defect_images)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc82d87f-9ab7-4ad8-8ce8-ded0a742140c","_cell_guid":"41e47689-eab3-4000-bb9b-ee653efc99a9","trusted":true},"cell_type":"code","source":"train_images = defect_images[:5800] + non_defect_images[:100]\nvalid_images = defect_images[5800:6200] + non_defect_images[100:300]\nprint(len(train_images), len(valid_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(4)\nrandom.shuffle(train_images)\nrandom.shuffle(valid_images)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a35f01cd-4f3e-49cb-91ca-a18f28858138","_cell_guid":"330505b6-f526-405f-97dc-180671aa839e","trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b2dbe96-f93a-4a70-b4a9-b24ebae95aae","_cell_guid":"d31b4eac-8b52-4777-93ed-73ed7008bbe2","trusted":true},"cell_type":"code","source":"mask_imgs = df1['ImageId'].tolist()\nprint(len(mask_imgs))\nprint(len(np.unique(mask_imgs)))\n# print(len(list(unique_everseen(mask_imgs))))\nmulti_masks = pd.Series(mask_imgs).value_counts() \nmulti_masks = multi_masks[multi_masks > 1].index.tolist()\nprint(len(multi_masks))\n# multi_masks","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cfe0b4d-d73c-4203-b633-22431fed3f2a","_cell_guid":"eea734fb-3392-4738-aa81-c3f983739974","trusted":true},"cell_type":"code","source":"rle = df1[df1['ImageId'] == '0002cc93b.jpg']['EncodedPixels'].tolist()\nrle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"130f7043-2c72-4a19-a36a-8a5acf18b9ae","_cell_guid":"10633449-7e8a-41a2-9817-7d92aa13457f","trusted":true},"cell_type":"code","source":"print(len(rle[0].split(' ')))\n# rle[0].split(' ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e793e24-f088-472c-8022-bc5b21e0d41f","_cell_guid":"977fa5d7-7a69-44d2-8dd9-7282a99c656e","trusted":true},"cell_type":"code","source":"rle = list(map(int, rle[0].split(' ')))\n# rle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3db0e6d-85cc-47c5-abee-46e8c22b39ef","_cell_guid":"f418047f-67fd-47ec-b398-f73849660b34","trusted":true},"cell_type":"code","source":"pixel,pixel_count = [],[]\nx23=[pixel.append(rle[i]) if i%2==0 else pixel_count.append(rle[i]) for i in range(0, len(rle))]\n# print('pixel starting points:\\n',pixel)\n# print('pixel counting:\\n', pixel_count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5348b4a2-792d-43ba-9b5e-ef50a9a65ef2","_cell_guid":"c3259f38-1b16-4d45-a1e0-3932cb39fcc9","trusted":true},"cell_type":"code","source":"rle_pixels = [list(range(pixel[i],pixel[i]+pixel_count[i])) for i in range(0, len(pixel))]\n# print('rle_pixels\\n:', rle_pixels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7804f619-0836-4270-b7f3-1de3813ec9b0","_cell_guid":"2a8d48f6-4654-4e6f-9f2e-c63a93d89d6b","trusted":true},"cell_type":"code","source":"rle_mask_pixels = sum(rle_pixels,[]) \n# rle_mask_pixels = list(itertools.chain.from_iterable(rle_pixels))\n# print('rle mask pixels:\\n', rle_mask_pixels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"751258e6-b771-424f-aba1-db5f3a9f2e6c","_cell_guid":"1de29a1a-777f-4717-9d97-16c09b0dd5a2","trusted":true},"cell_type":"code","source":"image = cv2.imread(dir1 + 'train_images/'+ '0002cc93b.jpg')\nprint('shape of image is:', image.shape)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f297143-3fdf-400e-859d-1b732f7a6fbd","_cell_guid":"1d85ed5f-63a9-4ff8-9884-8c859e6d25e2","trusted":true},"cell_type":"code","source":"def load_img_df(img):\n    df2 = df[df['ImageId'] == img]\n    return df2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40973e01-cd6e-439f-b3f4-bcf58c14aa70","_cell_guid":"f3209c04-f223-4a8a-aa66-c9748a9e1b2f","trusted":true},"cell_type":"code","source":"def rle2mask(en_pix):\n    en_pixels = [list(map(int, en_pix[0].split(' ')))]\n    en_pixels = sum(en_pixels,[]) \n    pixel,pixel_count = [],[]\n    [pixel.append(en_pixels[i]) if i%2==0 else pixel_count.append(en_pixels[i]) for i in range(0, len(en_pixels))]\n    rle_pixels = [list(range(pixel[i],pixel[i]+pixel_count[i])) for i in range(0, len(pixel))]\n    rle_mask_pixels = sum(rle_pixels,[]) \n\n    return rle_mask_pixels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32b5758a-50d4-4ca3-b462-887d67f280e9","_cell_guid":"935547b3-8f9d-45c5-afbf-8d610b90e364","trusted":true},"cell_type":"code","source":"def image_mask(img,image,j):\n    l, b = image.shape[0], image.shape[1]\n    df3 = load_img_df(img)\n    en_pix = df3[df3['ClassId']==str(j)]['EncodedPixels'].tolist()\n    mask = np.zeros((l,b), dtype=int)\n#     print('en_pix',en_pix)\n    if (en_pix == []) or (en_pix == [0]):\n        return mask\n    else:\n        mask_img = np.zeros((l*b,1), dtype=int)\n        rle_mask_pixels = rle2mask(en_pix)\n        mask_img[rle_mask_pixels] = 1\n        mask = np.reshape(mask_img, (b, l)).T\n        return mask","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f11452e-6669-4522-bf9d-3e6572caf660","_cell_guid":"a1e82a29-ef42-4957-b413-b23bed292aa9","trusted":true},"cell_type":"code","source":"def display_image_mask(img):\n    fig, ax = plt.subplots(nrows=5, ncols=1, figsize = (10,10)) \n    images = []\n    image = cv2.imread(dir1 + 'train_images/' + img)\n    for j in range(1,5):\n        mask = image_mask(img,image,j)\n        images.append(mask)\n    images.append(1-sum(images))\n    for im,ax in zip(images, ax.flatten()):\n#         print(np.unique(im, return_counts=True))\n        ax.imshow(im, cmap = 'gray')\n#         print(np.unique(im, return_counts = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(0, len(mask_imgs)//1000):\n#     img55 = mask_imgs[i]\n#     l3 = []\n#     try:\n#         display_image_mask(img = img55)\n#     except:\n#         l3.append(mask_imgs[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac3c50c8-4cec-4597-9f76-dba06d07a2e8","_cell_guid":"c46d6997-0de6-4c51-9182-125ac6920b4d","trusted":true},"cell_type":"code","source":"#Display image and masks for random image\nimg5 = mask_imgs[np.random.randint(0, len(mask_imgs))]\nplt.title('input image {}'.format(img5))\nplt.imshow(cv2.imread(dir1 + 'train_images/' + img5))  \ndisplay_image_mask(img = img5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c8b5578-f43b-4f9a-bc53-91f0b5a83605","_cell_guid":"4b2118cf-0580-4f8e-8784-38b670693cde","trusted":true},"cell_type":"code","source":"#Cross check mask class ids wrt dataframe\ndf[df['ImageId'] == img5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"681bfa78-a908-46a4-afa8-8bb61f9c3a04","_cell_guid":"aa4dd762-2642-4354-badb-1b34d19eab25","trusted":true},"cell_type":"code","source":"def return_image_mask(img):\n    image = cv2.imread(img)\n    mask1 = np.zeros((256,1600,4), dtype = int)\n    for j in range(1,5):\n        mask = image_mask(img,image,j)\n        mask1[:,:,j-1] = mask\n#     mask1[:,:,0] = 1-np.sum(mask1, axis=2)\n    return image,mask1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\nfrom keras.optimizers import SGD, RMSprop, Adadelta\nfrom keras import backend as K\nfrom keras import losses\n\ncheckpoint_path = '/kaggle/working/UNET_sep_28.hdf5'\nweights_path = '/kaggle/working/UNET_sep_28.hdf5'\nbatch_size = 4\nCLASSES = 4\nsgd = SGD(lr=0.00146, decay=1e-6, momentum=0.9, nesterov=False)\ncheckpointer = ModelCheckpoint(monitor='loss',filepath=checkpoint_path,\n                               verbose=1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, verbose=1, min_delta=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unet(input_size = (256,1600,3)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n#     drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n#     drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n    merge6 = concatenate([conv4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n#     conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(4, 1, activation = 'softmax')(conv9)\n\n    model = Model(input = inputs, output = conv10)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = unet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smooth = 1\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_multilabel(y_true, y_pred, numLabels=CLASSES):\n    dice=0\n    for index in range(numLabels):\n        dice -= dice_coef(y_true[:,:,index], y_pred[:,:,index])\n    return dice\n\ndef dice_coef_nd(y_true, y_pred):\n    y_true_f = y_true.flatten()\n    y_pred_f = y_pred.flatten()\n    intersection = np.sum(y_true_f * y_pred_f)\n    return 2.*intersection, (np.sum(y_true_f)+np.sum(y_pred_f))\n\ndef dice_loss(y_true,y_pred):\n    return K.constant(1.0) - dice_coef(y_true,y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n                  optimizer=sgd,\n                  metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_gen(images,batch_size):\n    while True:\n        indices = random.sample(range(0, len(images)), batch_size)\n        all_images,all_masks = [],[]\n        for i in indices:\n#             print(images[i])\n            im,op = return_image_mask(dir1+'train_images/'+images[i])\n            all_images += [im]\n            all_masks += [op]\n\n        x = np.array(all_images)/255\n        y = np.array(all_masks)\n        yield (x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_gen(train_images, batch_size),\n                    steps_per_epoch=len(train_images)//batch_size, epochs=2,\n                   callbacks=[checkpointer,reduce_lr])\nmodel.save_weights(checkpoint_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dir1 + 'test_images/' + os.listdir(dir1 + 'test_images/')[78]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = unet()\nmodel.load_weights(weights_path)\ntest = model.predict(np.expand_dims(cv2.imread(x), 0)/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape\ntest1 = np.reshape(test, (256,1600,4))\nnp.unique(test1, return_counts = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agm = np.argmax(test1, axis = 2)\nagm.shape\nnp.unique(agm, return_counts = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split into 5 channel mask after prediction\npred = np.zeros((256,1600,5), dtype = int)\nfor i in range(5):\n    pred[:,:,i] = ((agm[:,:] == i)*255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualise results\nfig1, ax1 = plt.subplots(nrows=4, ncols=1, figsize = (10,10)) \nfor ij,axes in zip(range(4), ax1.flatten()):\n#     print(axes)\n    axes.imshow(pred[:,:,ij], cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig2, ax2 = plt.subplots(nrows=4, ncols=1, figsize = (10,10)) \nfor ij,axes in zip(range(4), ax2.flatten()):\n    axes.imshow(pred[:,:,ij], cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/sample_submission.csv')\nsubmission.EncodedPixels = ''\nsubmission.to_csv(\"submission.csv\", index= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}