{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model_weight = '/kaggle/input/unet-exception/unet_exception_15-0.0138'\npath = '/kaggle/input/severstal-steel-defect-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_threshold = 512\nmask_bound_1 = 0.10\nmask_bound_2 = 0.05\nmask_bound_3 = 0.5\nmask_bound_4 = 0.5\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16 ,subset ='train', shuffle = False, preprocess = None, info={}):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset =='train':\n            self.data_path = path +'train_images/'\n#         elif self.subset =='valid':\n#             self.data_path = path +'train_images/'\n        elif self.subset =='test':\n            self.data_path = path + 'test_images/'\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    def __getitem__(self,index):\n        x = np.empty((self.batch_size, 128, 800, 3), dtype=np.float32)\n        y = np.empty((self.batch_size, 128, 800, 4), dtype=np.int8)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size + i] =f \n            x[i,]=Image.open(self.data_path + f).resize((800,128))\n            if self.subset =='train':\n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess !=None : x= self.preprocess(x)\n        if self.subset == 'train' : return x,y\n        else: return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, load_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n# config = tf.ConfigProto()\n# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n# session = tf.Session(config= config)\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def masks_reduce(masks):\n    \n    for idx in range(masks.shape[-1]):\n        label_num, labeled_mask = cv2.connectedComponents(masks[:,:,idx].astype(np.uint8))\n        reduced_mask = np.zeros(masks.shape[:2],np.float32)\n        \n        for label in range(1, label_num):\n            single_label_mask = (labeled_mask == label)\n            if single_label_mask.sum() > mask_threshold:\n                reduced_mask[single_label_mask] = 1\n        \n        masks[:,:,idx] = reduced_mask\n        \n    return masks\n\ndef masks_reduce2(masks):\n    for idx in range(masks.shape[-1]):\n        if np.sum(masks[:,:,idx]) < mask_threshold:\n            masks[:,:,idx] = np.zeros(masks.shape[:2], dtype = np.uint8)\n    return masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model(model_weight, custom_objects={'dice_coef' : dice_coef})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = pd.read_csv(os.path.join(path, 'train.csv'))\n# train['ImageId'] = train['ImageId_ClassId'].map(lambda x : x.split('.')[0] + '.jpg')\n# train2 = pd.DataFrame({'ImageId' : train['ImageId'][::4]})\n# train2['e1'] = train['EncodedPixels'][::4].values\n# train2['e2'] = train['EncodedPixels'][1::4].values\n# train2['e3'] = train['EncodedPixels'][2::4].values\n# train2['e4'] = train['EncodedPixels'][3::4].values\n# train2.reset_index(inplace=True, drop =True)\n# train2.fillna('',inplace=True)\n# train2['count'] = np.sum(train2.iloc[:,1:]!='', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# idx = int(0.8*len(train2))\n# train_batches = DataGenerator(train2.iloc[:idx],batch_size= 16, shuffle=True)\n# valid_batches = DataGenerator(train2.iloc[idx:],batch_size= 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_df_resize = []\n# for i in range(0,train2.iloc[idx:].shape[0], 300):\n#     batch_idx = list(range(i, min(train2.iloc[idx:].shape[0] , i+300)))\n#     valid_generator = DataGenerator(\n#         train2.iloc[idx:].iloc[batch_idx], subset = 'valid', batch_size = 1)\n#     valid_preds =model.predict_generator(valid_generator, verbose = 1)\n    \n#     for j, b in tqdm(enumerate(batch_idx)):\n#         filename = train2.iloc[idx:]['ImageId'].iloc[b]\n#         image_df = train[train['ImageId'] == filename].copy()\n        \n#         pred_masks = np.squeeze(np.round(valid_preds[j,])).astype(np.uint8)\n# #         pred_masks = test_preds[j, ].round().astype(int)\n#         pred_masks_re = cv2.resize(pred_masks, (1600,256))\n\n#         pred_rles = build_rles(pred_masks)\n#         image_df['EncodedPixels'] = pred_rles\n#         valid_df_resize.append(image_df)\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_resize = pd.concat(valid_df_resize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_resize.reset_index(inplace=True, drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_set = train[train['ImageId'].isin(valid_batches.df['ImageId'].values)].copy()\n# val_set.reset_index(inplace = True, drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_resize.shape, val_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_resize.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_set2 = pd.DataFrame({'ImageId' : val_set['ImageId'][::4]})\n# val_set2['e1'] = val_set['EncodedPixels'][::4].values\n# val_set2['e2'] = val_set['EncodedPixels'][1::4].values\n# val_set2['e3'] = val_set['EncodedPixels'][2::4].values\n# val_set2['e4'] = val_set['EncodedPixels'][3::4].values\n# val_set2.reset_index(inplace=True, drop =True)\n# val_set2.fillna('',inplace=True)\n# val_set2['count'] = np.sum(val_set2.iloc[:,1:]!='', axis = 1).values\n# val_set2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filenames = {}\n# defects = list(val_set2[val_set2['e1']!=''].sample(3).index)\n# defects += list(val_set2[val_set2['e2']!=''].sample(3).index)\n# defects += list(val_set2[val_set2['e3']!=''].sample(7).index)\n# defects += list(val_set2[val_set2['e4']!=''].sample(3).index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_batches = DataGenerator(val_set2[val_set2.index.isin(defects)],batch_size= 16, shuffle=False,info=filenames )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, batch in enumerate(valid_batches):\n#     plt.figure(figsize=(14,50))\n#     for k in range(16):\n#         plt.subplot(16,1, k+1)\n#         img = batch[0][k,]\n#         img = Image.fromarray(img.astype('uint8'))\n#         img = np.array(img)\n# #         print(img.shape)\n#         extra = ' has defect'\n#         for j in range(4):\n#             msk = batch[1][k, : , : , j]\n#             msk = mask2pad(msk, pad =3)\n#             msk = mask2contour(msk, width =2)\n#             if np.sum(msk)!=0 :\n#                 extra +=' ' + str(j+1)\n#             if j==0:\n#                 img[msk==1,0]==235\n#                 img[msk==1,1]=235\n#             elif j==1:\n#                 img[msk==1,1]=210\n#             elif j==2:\n#                 img[msk==1,2]=255\n#             elif j==3:\n#                 img[msk==1,0]=255\n#                 img[msk==1,2]=255\n#         plt.title(filenames[16*i+k] + extra)\n#         plt.axis('off')\n#         plt.imshow(img)\n#     plt.subplots_adjust(wspace = 0.05)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class DataGenerator_Resize(keras.utils.Sequence):\n#     def __init__(self, df, batch_size = 16 ,subset ='train', shuffle = False, preprocess = None, info={}):\n#         super().__init__()\n#         self.df = df\n#         self.shuffle = shuffle\n#         self.subset = subset\n#         self.batch_size = batch_size\n#         self.preprocess = preprocess\n#         self.info = info\n        \n#         if self.subset =='train':\n#             self.data_path = path +'train_images/'\n#         elif self.subset =='valid':\n#             self.data_path = path +'train_images/'\n#         elif self.subset =='test':\n#             self.data_path = path + 'test_images/'\n#         self.on_epoch_end()\n        \n#     def __len__(self):\n#         return int(np.floor(len(self.df) / self.batch_size))\n    \n#     def on_epoch_end(self):\n#         self.indexes = np.arange(len(self.df))\n#         if self.shuffle == True:\n#             np.random.shuffle(self.indexes)\n#     def __getitem__(self,index):\n#         x = np.empty((self.batch_size, 256, 1600, 3), dtype=np.float32)\n#         y = np.empty((self.batch_size, 256, 1600, 4), dtype=np.int8)\n#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n#         for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n#             self.info[index*self.batch_size + i] =f \n#             x[i,]=Image.open(self.data_path + f).resize((1600,256))\n#             if self.subset =='train':\n#                 for j in range(4):\n#                     y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n#         if self.preprocess !=None : x= self.preprocess(x)\n#         if self.subset == 'train' : return x,y\n#         else: return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def rle2maskResize(rle):\n#     # CONVERT RLE TO MASK \n#     if (pd.isnull(rle))|(rle==''): \n#         return np.zeros((256,1600) ,dtype=np.uint8)\n    \n#     height= 256\n#     width = 1600\n#     mask= np.zeros( width*height ,dtype=np.uint8)\n\n#     array = np.asarray([int(x) for x in rle.split()])\n#     starts = array[0::2]-1\n#     lengths = array[1::2]    \n#     for index, start in enumerate(starts):\n#         mask[int(start):int(start+lengths[index])] = 1\n    \n#     return mask.reshape( (height,width), order='F' )[::1,::1]\n\n# def mask2contour(mask, width=3):\n#     # CONVERT MASK TO ITS CONTOUR\n#     w = mask.shape[1]\n#     h = mask.shape[0]\n#     mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n#     mask2 = np.logical_xor(mask,mask2)\n#     mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n#     mask3 = np.logical_xor(mask,mask3)\n#     return np.logical_or(mask2,mask3) \n\n# def mask2pad(mask, pad=2):\n#     # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n#     w = mask.shape[1]\n#     h = mask.shape[0]\n    \n#     # MASK UP\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n#         mask = np.logical_or(mask,temp)\n#     # MASK DOWN\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n#         mask = np.logical_or(mask,temp)\n#     # MASK LEFT\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n#         mask = np.logical_or(mask,temp)\n#     # MASK RIGHT\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n#         mask = np.logical_or(mask,temp)\n    \n#     return mask ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_resize2 = pd.DataFrame({'ImageId' : valid_resize['ImageId'][::4]})\n# val_resize2['e1'] = valid_resize['EncodedPixels'][::4].values\n# val_resize2['e2'] = valid_resize['EncodedPixels'][1::4].values\n# val_resize2['e3'] = valid_resize['EncodedPixels'][2::4].values\n# val_resize2['e4'] = valid_resize['EncodedPixels'][3::4].values\n# val_resize2.reset_index(inplace=True, drop =True)\n# val_resize2.fillna('',inplace=True)\n# val_resize2['count'] = np.sum(val_resize2.iloc[:,1:]!='', axis = 1).values\n# val_resize2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_batches_resize = DataGenerator_Resize(val_resize2[val_resize2.index.isin(defects)],batch_size= 16, shuffle=False,info=filenames )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, batch in enumerate(valid_batches_resize):\n#     plt.figure(figsize=(14,50))\n#     for k in range(16):\n#         plt.subplot(16,1, k+1)\n#         img = batch[0][k,]\n#         img = Image.fromarray(img.astype('uint8'))\n#         img = np.array(img)\n# #         print(img.shape)\n#         extra = ' has defect'\n#         for j in range(4):\n#             msk = batch[1][k, : , : , j]\n#             msk = mask2pad(msk, pad =3)\n#             msk = mask2contour(msk, width =2)\n#             if np.sum(msk)!=0 :\n#                 extra +=' ' + str(j+1)\n#             if j==0:\n#                 img[msk==1,0]==235\n#                 img[msk==1,1]=235\n#             elif j==1:\n#                 img[msk==1,1]=210\n#             elif j==2:\n#                 img[msk==1,2]=255\n#             elif j==3:\n#                 img[msk==1,0]=255\n#                 img[msk==1,2]=255\n#         plt.title(filenames[16*i+k] + extra)\n#         plt.axis('off')\n#         plt.imshow(img)\n#     plt.subplots_adjust(wspace = 0.05)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(path + 'sample_submission.csv')\ntest['ImageId'] = test['ImageId_ClassId'].map(lambda x: x.split('_')[0])\n# test_batches = DataGenerator(test.iloc[::4],subset='test',batch_size=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['ImageId'] = train['ImageId_ClassId'].map(lambda x : x.split('.')[0] + '.jpg')\ntest2 = pd.DataFrame({'ImageId' : test['ImageId'][::4]})\ntest2['e1'] = test['EncodedPixels'][::4].values\ntest2['e2'] = test['EncodedPixels'][1::4].values\ntest2['e3'] = test['EncodedPixels'][2::4].values\ntest2['e4'] = test['EncodedPixels'][3::4].values\ntest2.reset_index(inplace=True, drop =True)\ntest2.fillna('',inplace=True)\ntest2['count'] = np.sum(test2.iloc[:,1:]!='', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from multiprocessing import Pool","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_generator = DataGenerator(test2, subset = 'test', batch_size=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_preds = model.predict_generator(test_generator,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def post_preprocess(preds):\n#     print(preds[0][0][0])\n    \n    pred_masks = np.zeros((len(preds), 256,1600,4))\n    for k in range(0,len(preds)):\n#         mask = np.squeeze(np.round(preds[k,]))\n        mask = np.squeeze(preds[k,])\n        mask_1 = np.array(mask[:,:,0] > mask_bound_1, dtype=np.uint8)\n        mask_1 = mask2pad(mask_1, pad=2)\n        mask_1 = np.array(mask2contour(mask_1,width=3),dtype=np.uint8)\n        \n        mask_2 = np.array(mask[:,:,1] > mask_bound_2, dtype=np.uint8)\n        mask_2 = mask2pad(mask_2, pad=2)\n        mask_2 = np.array(mask2contour(mask_2,width=3), dtype=np.uint8)\n        \n        mask_3 = np.array(mask[:,:,2] > mask_bound_3, dtype=np.uint8)\n        mask_3 = mask2pad(mask_3, pad=2)\n        mask_3 = np.array(mask2contour(mask_3,width=3), dtype=np.uint8)\n        \n        \n        mask_4 = np.array(mask[:,:,3] > mask_bound_4, dtype=np.uint8)\n        mask_4 = mask2pad(mask_4, pad=2)\n        mask_4 = np.array(mask2contour(mask_4,width=3), dtype=np.uint8)\n        mask_re = np.stack([mask_1,mask_2,mask_3,mask_4], axis =2)\n#         mask  = np.array(mask > mask_bound, dtype=np.uint8)\n        mask_re = cv2.resize(mask_re, (1600,256))\n        mask_re = masks_reduce(mask_re)\n        pred_masks[k] = mask_re\n#         gc.collect()\n    return pred_masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def paralleize_numpy(preds, func, cores = 6):\n#     print(\"Bound : {}, Threshold : {}\".format(mask_bound, mask_threshold))\n    np_split = np.array_split(preds, cores )\n    pool = Pool(cores)\n    res_np = np.concatenate(pool.map(func, np_split))\n    pool.close()\n    pool.join()\n    return res_np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.cpu_count()\n\n\n#         mask_1 = np.array(mask[:,:,0] > mask_bound_1, dtype=np.uint8)\n#         mask_2 = np.array(mask[:,:,1] > mask_bound_2, dtype=np.uint8)\n#         mask_3 = np.array(mask[:,:,2] > mask_bound_2, dtype=np.uint8)\n#         mask_4 = np.array(mask[:,:,3] > mask_bound_3, dtype=np.uint8)\n#         mask_re = np.stack([mask_1,mask_2,mask_3,mask_4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_resize = []\nfor i in tqdm(range(0,test2.shape[0], 30)):\n    batch_idx = list(range(i, min(test2.shape[0] , i+30)))\n    test_generator = DataGenerator(\n        test2.iloc[batch_idx], subset = 'test', batch_size = 1)\n    test_preds =model.predict_generator(test_generator, verbose = 1)\n    test_preds_pp = paralleize_numpy(test_preds, post_preprocess, cores=2).astype(np.int32)\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = test2['ImageId'].iloc[b]\n        image_df = test[test['ImageId'] == filename].copy()\n        pred_rles = build_rles(test_preds_pp[j])\n        image_df['EncodedPixels'] = pred_rles\n        test_df_resize.append(image_df)\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask_threshold = 1024\n# mask_bound = 0.5\n# E1 - 0, E2 - 0 E3 - 572 E4 -127\n# mask_threshold = 256\n# mask_bound = 0.5\n# E1 - 0, E2 - 0 E3 - 680 E4 -150\n# mask_threshold = 0\n# mask_bound = 0.5\n#E1 - 0, E2 - 0 E3 - 745 E4 -162\n\ntest_df_resize = pd.concat(test_df_resize)\nprint(test_df_resize.shape)\ntest_df_resize.head()\ntest_df_resize[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask_threshold = 256\n# mask_bound = 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df_resize2 = []\n# for i in tqdm(range(0,test2.shape[0], 30)):\n#     batch_idx = list(range(i, min(test2.shape[0] , i+30)))\n#     test_generator = DataGenerator(\n#         test2.iloc[batch_idx], subset = 'test', batch_size = 1)\n#     test_preds =model.predict_generator(test_generator, verbose = 1)\n#     test_preds_pp = paralleize_numpy(test_preds, post_preprocess, cores=2).astype(np.int32)\n    \n#     for j, b in tqdm(enumerate(batch_idx)):\n#         filename = test2['ImageId'].iloc[b]\n#         image_df = test[test['ImageId'] == filename].copy()\n#         pred_rles = build_rles(test_preds_pp[j])\n#         image_df['EncodedPixels'] = pred_rles\n#         test_df_resize2.append(image_df)\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask_threshold = 0\n# mask_bound = 0.5\n# test_df_resize3 = []\n# for i in tqdm(range(0,test2.shape[0], 30)):\n#     batch_idx = list(range(i, min(test2.shape[0] , i+30)))\n#     test_generator = DataGenerator(\n#         test2.iloc[batch_idx], subset = 'test', batch_size = 1)\n#     test_preds =model.predict_generator(test_generator, verbose = 1)\n#     test_preds_pp = paralleize_numpy(test_preds, post_preprocess, cores=2).astype(np.int32)\n    \n#     for j, b in tqdm(enumerate(batch_idx)):\n#         filename = test2['ImageId'].iloc[b]\n#         image_df = test[test['ImageId'] == filename].copy()\n#         pred_rles = build_rles(test_preds_pp[j])\n#         image_df['EncodedPixels'] = pred_rles\n#         test_df_resize3.append(image_df)\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# test_df_resize = pd.concat(test_df_resize)\n# print(test_df_resize.shape)\n# test_df_resize.head()\n# test_df_resize[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test2_1 = pd.DataFrame({'ImageId' : test_df_resize['ImageId'][::4]})\n# test2_1['ImageId'] = test_df_resize['ImageId_ClassId'].map(lambda x : x.split('.')[0] + '.jpg')\n\n# test2_1['e1'] = test_df_resize['EncodedPixels'][::4].values\n# test2_1['e2'] = test_df_resize['EncodedPixels'][1::4].values\n# test2_1['e3'] = test_df_resize['EncodedPixels'][2::4].values\n# test2_1['e4'] = test_df_resize['EncodedPixels'][3::4].values\n# test2_1.reset_index(inplace=True, drop =True)\n# test2_1.fillna('',inplace=True)\n# test2_1['count'] = np.sum(test2_1.iloc[:,1:]!='', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\n#     \"E1 - {}, E2 - {} E3 - {} E4 -{}\".format(\n#         test2_1[test2_1['e1']!=''].shape[0],\n#         test2_1[test2_1['e2']!=''].shape[0],\n#         test2_1[test2_1['e3']!=''].shape[0],\n#         test2_1[test2_1['e4']!=''].shape[0],)\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df_resize2 = pd.concat(test_df_resize2)\n# print(test_df_resize2.shape)\n# test_df_resize2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test2_2 = pd.DataFrame({'ImageId' : test_df_resize2['ImageId'][::4]})\n# test2_2['ImageId'] = test_df_resize2['ImageId_ClassId'].map(lambda x : x.split('.')[0] + '.jpg')\n\n# test2_2['e1'] = test_df_resize2['EncodedPixels'][::4].values\n# test2_2['e2'] = test_df_resize2['EncodedPixels'][1::4].values\n# test2_2['e3'] = test_df_resize2['EncodedPixels'][2::4].values\n# test2_2['e4'] = test_df_resize2['EncodedPixels'][3::4].values\n# test2_2.reset_index(inplace=True, drop =True)\n# test2_2.fillna('',inplace=True)\n# test2_2['count'] = np.sum(test2_2.iloc[:,1:]!='', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\n#     \"E1 - {}, E2 - {} E3 - {} E4 -{}\".format(\n#         test2_2[test2_2['e1']!=''].shape[0],\n#         test2_2[test2_2['e2']!=''].shape[0],\n#         test2_2[test2_2['e3']!=''].shape[0],\n#         test2_2[test2_2['e4']!=''].shape[0],)\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df_resize3 = pd.concat(test_df_resize3)\n# print(test_df_resize3.shape)\n# test_df_resize3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test2_3 = pd.DataFrame({'ImageId' : test_df_resize3['ImageId'][::4]})\n# test2_3['ImageId'] = test_df_resize3['ImageId_ClassId'].map(lambda x : x.split('.')[0] + '.jpg')\n\n# test2_3['e1'] = test_df_resize3['EncodedPixels'][::4].values\n# test2_3['e2'] = test_df_resize3['EncodedPixels'][1::4].values\n# test2_3['e3'] = test_df_resize3['EncodedPixels'][2::4].values\n# test2_3['e4'] = test_df_resize3['EncodedPixels'][3::4].values\n# test2_3.reset_index(inplace=True, drop =True)\n# test2_3.fillna('',inplace=True)\n# test2_3['count'] = np.sum(test2_3.iloc[:,1:]!='', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\n#     \"E1 - {}, E2 - {} E3 - {} E4 -{}\".format(\n#         test2_3[test2_3['e1']!=''].shape[0],\n#         test2_3[test2_3['e2']!=''].shape[0],\n#         test2_3[test2_3['e3']!=''].shape[0],\n#         test2_3[test2_3['e4']!=''].shape[0],)\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## version 10\n# test_df_resize = []\n# for i in range(0,test2.shape[0], 300):\n#     batch_idx = list(range(i, min(test2.shape[0] , i+300)))\n#     test_generator = DataGenerator(\n#         test2.iloc[batch_idx], subset = 'test', batch_size = 1)\n#     test_preds =model.predict_generator(test_generator, verbose = 1)\n    \n#     for j, b in tqdm(enumerate(batch_idx)):\n#         filename = test2['ImageId'].iloc[b]\n#         image_df = test[test['ImageId'] == filename].copy()\n        \n#         pred_masks = np.squeeze(np.round(test_preds[j,])).astype(np.uint8)\n# #         pred_masks = test_preds[j, ].round().astype(int)\n#         pred_masks_re = cv2.resize(pred_masks, (1600,256))\n        \n\n#         pred_rles = build_rles(pred_masks_re)\n#         image_df['EncodedPixels'] = pred_rles\n#         test_df_resize.append(image_df)\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df_resize = pd.concat(test_df_resize)\n# print(test_df_resize.shape)\n# test_df_resize.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df_resize.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# final_test_df = test_df_resize.drop_duplicates(inplace=False, subset=['ImageId_ClassId'])\n# test_df_resize[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df = []\n# for i in range(0,test2.shape[0], 300):\n#     batch_idx = list(range(i, min(test2.shape[0] , i+300)))\n#     test_generator = DataGenerator(\n#         test2.iloc[batch_idx], subset = 'test', batch_size = 1)\n#     test_preds =model.predict_generator(test_generator, verbose = 1)\n    \n#     for j, b in tqdm(enumerate(batch_idx)):\n#         filename = test2['ImageId'].iloc[b]\n#         image_df = test[test['ImageId'] == filename].copy()\n        \n#         pred_masks = np.squeeze(np.round(test_preds[j,])).astype(np.uint8)\n# #         pred_masks = test_preds[j, ].round().astype(int)\n#         pred_masks_re = cv2.resize(pred_masks, (1600,256))\n\n#         pred_rles = build_rles(pred_masks_re)\n#         image_df['EncodedPixels'] = pred_rles\n#         test_df.append(image_df)\n#     gc.collect()\n        \n        \n        \n        \n#         masks = np.squeeze(np.round(test_preds[j,]))\n# #         print(masks)\n# #         print(aaaa)\n#         masks = np.array(masks >mask_bound, dtype=np.uint8 )\n#         masks = cv2.resize(masks, (1600, 256))\n        \n#         masks =masks_reduce(masks)\n# #         print(masks.shape)\n# #         print(image_df)\n        \n# #         for idx in range(masks.shape[-1]):\n# # #             print(image_df['ImageId_ClassId'][idx])\n# # #             print(masks[:,:,idx])\n# # #             print('=====')\n# # #             image_df['EncodedPixels'][idx] = \n# # #             image_df = image_df.append(pd.DataFrame([[image_df['ImageId_ClassId'][idx], mask2rle(masks[:,:,idx])]], \n# # #                                                       columns = [\"ImageId_ClassId\", \"EncodedPixels\"]))\n# #             pred_rles = build_rles(masks)\n# #             image_df['EncodedPixels'][idx] = pred_rles\n        \n        \n#         pred_rles = build_rles(masks)\n        \n#         image_df['EncodedPixels'] = pred_rles\n#         test_df.append(image_df)\n        \n# #         pred_masks = test_preds[j, ].round().astype(int)\n# #         pred_rles = build_rles(pred_masks)\n        \n# #         image_df['EncodedPixels'] = pred_rles\n# #         test_df.append(image_df)\n#     gc.collect()\n\n\n# test_df = []\n# for i in range(0,test.shape[0], 300):\n#     batch_idx = list(range(i, min(test.shape[0] , i+300)))\n#     test_generator = DataGenerator(\n#         test.iloc[batch_idx], subset = 'test', batch_size = 1)\n#     test_preds =model.predict_generator(test_generator, verbose = 1)\n    \n#     for j, b in tqdm(enumerate(batch_idx)):\n#         filename = test['ImageId'].iloc[b]\n#         image_df = test[test['ImageId'] == filename].copy()\n        \n#         pred_masks = test_preds[j, ].round().astype(int)\n#         pred_rles = build_rles(pred_masks)\n        \n#         image_df['EncodedPixels'] = pred_rles\n#         test_df.append(image_df)\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = pd.read_csv(os.path.join(path, 'train.csv'))\n# train['ImageId'] = train['ImageId_ClassId'].map(lambda x : x.split('.')[0] + '.jpg')\n# train2 = pd.DataFrame({'ImageId' : train['ImageId'][::4]})\n# train2['e1'] = train['EncodedPixels'][::4].values\n# train2['e2'] = train['EncodedPixels'][1::4].values\n# train2['e3'] = train['EncodedPixels'][2::4].values\n# train2['e4'] = train['EncodedPixels'][3::4].values\n# train2.reset_index(inplace=True, drop =True)\n# train2.fillna('',inplace=True)\n# train2['count'] = np.sum(train2.iloc[:,1:]!='', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_set = train2.iloc[idx:].copy()\n# val_set.reset_index(inplace =)\n# defects = list(val_set[val_set['e1']!=''].sample(3).index)\n# defects += list(val_set[val_set['e2']!=''].sample(3).index)\n# defects += list(val_set[val_set['e3']!=''].sample(7).index)\n# defects += list(val_set[val_set['e4']!=''].sample(3).index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# idx = int(0.8*len(train2))\n# valid_batches = DataGenerator(train2.iloc[idx:],batch_size= 16, shuffle=False,info=val_set )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, batch in enumerate(valid_batches):\n#     plt.figure(figsize=(14,50))\n#     for k in range(16):\n#         plt.subplot(16,1, k+1)\n#         img = batch[0][k,]\n#         img = Image.fromarray(img.astype('uint8'))\n#         img = np.array(img)\n# #         print(img.shape)\n#         extra = ' has defect'\n#         for j in range(4):\n#             msk = batch[1][k, : , : , j]\n#             msk = mask2pad(msk, pad =3)\n#             msk = mask2contour(msk, width =2)\n#             if np.sum(msk)!=0 :\n#                 extra +=' ' + str(j+1)\n#             if j==0:\n#                 img[msk==1,0]==235\n#                 img[msk==1,1]=235\n#             elif j==1:\n#                 img[msk==1,1]=210\n#             elif j==2:\n#                 img[msk==1,2]=255\n#             elif j==3:\n#                 img[msk==1,0]=255\n#                 img[msk==1,2]=255\n# #         plt.title(val_set[16*i+k] + extra)\n#         plt.axis('off')\n#         plt.imshow(img)\n#     plt.subplots_adjust(wspace = 0.05)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df = pd.concat(test_df)\n# print(test_df.shape)\n# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class DataGenerator(keras.utils.Sequence):\n#     def __init__(self, df, batch_size = 16 ,subset ='train', shuffle = False, preprocess = None, info={}):\n#         super().__init__()\n#         self.df = df\n#         self.shuffle = shuffle\n#         self.subset = subset\n#         self.batch_size = batch_size\n#         self.preprocess = preprocess\n#         self.info = info\n        \n#         if self.subset =='train':\n#             self.data_path = path +'train/'\n#         elif self.subset =='valid':\n#             self.data_path = path +'train/'\n#         elif self.subset =='test':\n#             self.data_path = path + 'test/'\n#         self.on_epoch_end()\n        \n#     def __len__(self):\n#         return int(np.floor(len(self.df) / self.batch_size))\n    \n#     def on_epoch_end(self):\n#         self.indexes = np.arange(len(self.df))\n#         if self.shuffle == True:\n#             np.random.shuffle(self.indexes)\n#     def __getitem__(self,index):\n#         x = np.empty((self.batch_size, 256, 1600, 3), dtype=np.float32)\n#         y = np.empty((self.batch_size, 256, 1600, 4), dtype=np.int8)\n#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n#         for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n#             self.info[index*self.batch_size + i] =f \n#             x[i,]=Image.open(self.data_path + f).resize((1600,256))\n#             if self.subset =='train':\n#                 for j in range(4):\n#                     y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n#         if self.preprocess !=None : x= self.preprocess(x)\n#         if self.subset == 'train' : return x,y\n#         else: return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def rle2maskResize(rle):\n#     # CONVERT RLE TO MASK \n#     if (pd.isnull(rle))|(rle==''): \n#         return np.zeros((256,1600) ,dtype=np.uint8)\n    \n#     height= 256\n#     width = 1600\n#     mask= np.zeros( width*height ,dtype=np.uint8)\n\n#     array = np.asarray([int(x) for x in rle.split()])\n#     starts = array[0::2]-1\n#     lengths = array[1::2]    \n#     for index, start in enumerate(starts):\n#         mask[int(start):int(start+lengths[index])] = 1\n    \n#     return mask.reshape( (height,width), order='F' )[::1,::1]\n\n# def mask2contour(mask, width=3):\n#     # CONVERT MASK TO ITS CONTOUR\n#     w = mask.shape[1]\n#     h = mask.shape[0]\n#     mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n#     mask2 = np.logical_xor(mask,mask2)\n#     mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n#     mask3 = np.logical_xor(mask,mask3)\n#     return np.logical_or(mask2,mask3) \n\n# def mask2pad(mask, pad=2):\n#     # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n#     w = mask.shape[1]\n#     h = mask.shape[0]\n    \n#     # MASK UP\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n#         mask = np.logical_or(mask,temp)\n#     # MASK DOWN\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n#         mask = np.logical_or(mask,temp)\n#     # MASK LEFT\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n#         mask = np.logical_or(mask,temp)\n#     # MASK RIGHT\n#     for k in range(1,pad,2):\n#         temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n#         mask = np.logical_or(mask,temp)\n    \n#     return mask ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_batches = ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i,batch in enumerate(valid_batches):\n#     plt.figure(figsize=(20,36))\n#     for k in range(16):\n#         plt.subplot(16,2,2*k+1)\n#         img = batch[0][k,]\n#         img = Image.fromarray(img.astype('uint8'))\n#         img = np.array(img)\n#         dft = 0\n#         extra = '  has defect '\n#         for j in range(4):\n#             msk = batch[1][k,:,:,j]\n#             if np.sum(msk)!=0: \n#                 dft=j+1\n#                 extra += ' '+str(j+1)\n#             msk = mask2pad(msk,pad=2)\n#             msk = mask2contour(msk,width=3)\n#             if j==0: # yellow\n#                 img[msk==1,0] = 235 \n#                 img[msk==1,1] = 235\n#             elif j==1: img[msk==1,1] = 210 # green\n#             elif j==2: img[msk==1,2] = 255 # blue\n#             elif j==3: # magenta\n#                 img[msk==1,0] = 255\n#                 img[msk==1,2] = 255\n#         if extra=='  has defect ': extra =''\n#         plt.title('Train '+train2.iloc[16*i+k,0]+extra)\n#         plt.axis('off') \n#         plt.imshow(img)\n#         plt.subplot(16,2,2*k+2) \n#         if dft!=0:\n#             msk = preds[16*i+k,:,:,dft-1]\n#             plt.imshow(msk)\n#         else:\n#             plt.imshow(np.zeros((256,1600)))\n#         plt.axis('off')\n#         mx = np.round(np.max(msk),3)\n#         plt.title('Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n#     plt.subplots_adjust(wspace=0.05)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df = pd.concat(test_df)\n# print(test_df.shape)\n# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# final_test_df = test_df.drop_duplicates(inplace=False, subset=['ImageId_ClassId'])\n# final_test_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}