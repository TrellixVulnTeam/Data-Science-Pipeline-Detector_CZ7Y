{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null # no output\npackage_path = '../input/unetmodelscript' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom model import Unet # import Unet model from the script","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tqdm.notebook import tqdm_notebook as tqdm\nimport seaborn as sns\nimport albumentations  as albu\nfrom albumentations.pytorch import ToTensor\nimport random\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nimport torchvision\nfrom torchvision import models\nfrom torch.autograd import Function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 乱数のシードを設定\nseed = 1234\nrandom.seed(seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# データ読み込み"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = \"../input/severstal-steel-defect-detection/\"\ninput_dir_Train  = os.path.join(input_dir, 'train_images')\ninput_dir_Test  = os.path.join(input_dir, 'test_images')\nfilelist_Train = os.listdir(input_dir_Train)\nfilelist_Test = os.listdir(input_dir_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread(os.path.join(input_dir_Test, filelist_Test[0]))\nplt.imshow(image)\nplt.xticks([])\nplt.yticks([])\nplt.savefig('image.jpg')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_path = os.path.join(input_dir, 'train.csv')\ndf = pd.read_csv(df_path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_df(df):\n    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n    df['defects'] = df.count(axis=1)\n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=seed)\n    return train_df, val_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, val_df = make_df(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_path = os.path.join(input_dir, 'sample_submission.csv')\ntest_df = pd.read_csv(test_df_path)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndef get_augmentation(mean, std, phase):\n    \n    if phase == 'train':\n        transform = [\n            albu.HorizontalFlip(p=0.5),\n            albu.VerticalFlip(p=0.5),\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    else:\n        transform = [\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    \n    return albu.Compose(transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataloader作成"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_mask(index, df):\n    filename = df.iloc[index].name\n    labels = df.iloc[index, :4]\n    masks = np.zeros((256, 1600, 4), dtype=np.float32)\n    for idx, label in enumerate(labels):\n        if label is not np.nan:\n            mask = np.zeros((256*1600), dtype=np.uint8)\n            pixels = label.split(' ')\n            pixels = [pixels[i:i+2] for i in range(0, len(pixels), 2)]\n            for pixel in pixels:\n                pos, le = pixel\n                pos, le = int(pos), int(le)\n                mask[pos-1:pos+le-1] = 1\n            masks[:,:,idx] = mask.reshape(256, 1600, order = 'F')\n    return filename, masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ValDataset(torch.utils.data.Dataset):\n    def __init__(self, df, input_dir, phase):\n        self.df = df\n        self.input_dir = input_dir\n        self.transforms = get_augmentation(mean, std, phase) \n        self.phase = phase\n    def __getitem__(self, idx):\n        filename, mask = make_mask(idx, self.df)\n        image = cv2.imread(os.path.join(self.input_dir, filename))\n        augmented = self.transforms(image=image, mask=mask)\n        image, mask = augmented['image'], augmented['mask']\n        mask = mask[0].permute(2, 0, 1)\n        return image, mask\n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, input_dir, df, phase):\n        self.input_dir = input_dir\n        self.fnames = df['ImageId'].unique().tolist()\n        self.transforms = get_augmentation(mean, std, phase)\n        self.phase = phase\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        image = cv2.imread(os.path.join(self.input_dir, fname))\n        augmented = self.transforms(image=image)\n        image = augmented['image']\n        return fname, image\n    def __len__(self):\n        return len(self.fnames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataset = ValDataset(val_df, input_dir_Train, phase = 'val')\n\n# 動作確認\nindex = 0\nimage, mask = val_dataset.__getitem__(index) \nprint(image.size())\nplt.imshow(image.to('cpu').detach().numpy().copy()[0])\nplt.show()\nprint(mask.size())\nplt.imshow(mask.to('cpu').detach().numpy().copy()[2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = TestDataset(input_dir_Test, test_df, phase = 'test')\n\n# 動作確認\nindex = 0\nfname, image = test_dataset.__getitem__(index) \nprint('filename : {}'.format(fname))\nprint(image.size())\nplt.imshow(image.to('cpu').detach().numpy().copy()[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4\n\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n\n# 動作確認\nbatch_iterator = iter(test_dataloader)  # イテレータに変換\nfname, inputs = next(\n    batch_iterator)  # 1番目の要素を取り出す\nprint(inputs.size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ネットワークを用意"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18 = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)\nresnet34 = Unet(\"resnet34\", encoder_weights=\"imagenet\", classes=4, activation=None)\nresnet50 = Unet(\"resnet50\", encoder_weights=\"imagenet\", classes=4, activation=None)\n\nresnet18.load_state_dict(torch.load(\"../input/resnet-weights/resnet18_CP18.pth\"))\nresnet34.load_state_dict(torch.load(\"../input/resnet-weights/resnet34_CP19.pth\"))\nresnet50.load_state_dict(torch.load(\"../input/resnet-weights/resnet50_CP16.pth\"))\n\nprint('ネットワーク設定完了：学習済みの重みをロードしました')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 推論を実行"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coeff(pred, mask):\n    with torch.no_grad():\n        batch_size = len(pred)\n        pred = pred.view(batch_size, -1) # Flatten\n        mask = mask.view(batch_size, -1)  # Flatten\n        pred = (pred>0.5).float()\n        mask = (mask>0.5).float()\n        smooth = 0.0001\n        intersection = (pred * mask).sum()\n        dice_pos = (2. * intersection + smooth) / (pred.sum() + mask.sum() + smooth) \n        intersection = ((pred + mask) == 0).sum()\n        dice_neg = (2. * intersection + smooth) / ((pred == 0).sum() + (mask == 0).sum() + smooth)\n        dice = (dice_pos + dice_neg) / 2.0\n        return dice.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validate one model\ndef validate(model, dataloader):\n    # 初期設定\n    # GPUが使えるかを確認\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"使用デバイス：\", device)\n\n    # ネットワークをGPUへ\n    model = model.to(device)\n\n    # ネットワークがある程度固定であれば、高速化させる\n    torch.backends.cudnn.benchmark = True\n    \n    num_val_imgs = len(val_dataloader.dataset)\n    batch_size = val_dataloader.batch_size\n    \n    epoch_acc = 0.0\n    with torch.no_grad():\n        for img, mask in tqdm(val_dataloader):\n            \n            model.eval()\n            \n            # GPUが使えるならGPUにデータを送る\n            img = img.to(device)\n            mask = mask.to(device)\n\n            output = model(img)\n                \n            prob = torch.sigmoid(output)\n            prob = prob.to('cpu').detach()\n            mask = mask.to('cpu').detach()\n            \n            # ダイス係数の合計を更新\n            epoch_acc += dice_coeff(prob, mask)\n    print('Accuracy : {}'.format(epoch_acc / num_val_imgs * batch_size))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validate ensumble model\ndef validate_ensumble(model1, model2, model3, val_dataloader):\n    # 初期設定\n    # GPUが使えるかを確認\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"使用デバイス：\", device)\n\n    # ネットワークをGPUへ\n    model1 = model1.to(device)\n    model2 = model2.to(device)\n    model3 = model3.to(device)\n\n    # ネットワークがある程度固定であれば、高速化させる\n    torch.backends.cudnn.benchmark = True\n    \n    num_val_imgs = len(val_dataloader.dataset)\n    batch_size = val_dataloader.batch_size\n    \n    epoch_acc = 0.0\n    with torch.no_grad():\n        for img, mask in tqdm(val_dataloader):\n            \n            model1.eval()\n            model2.eval()\n            model3.eval()\n            \n            # GPUが使えるならGPUにデータを送る\n            img = img.to(device)\n            mask = mask.to(device)\n\n            output1 = model1(img)\n            output2 = model2(img)\n            output3 = model3(img)\n            \n            prob1 = torch.sigmoid(output1)\n            prob2 = torch.sigmoid(output2)\n            prob3 = torch.sigmoid(output3)\n            \n            prob = (prob1 + prob2 + prob3) / 3.0\n            \n            prob = prob.to('cpu').detach()\n            mask = mask.to('cpu').detach()\n            \n            # ダイス係数の合計を更新\n            epoch_acc += dice_coeff(prob, mask)\n    print('Accuracy : {}'.format(epoch_acc / num_val_imgs * batch_size))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resnet18 Validation\nvalidate(resnet18, val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resnet34 Validation\nvalidate(resnet34, val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resnet50 Validation\nvalidate(resnet50, val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resnet Ensumble Validation\nvalidate_ensumble(resnet18, resnet34, resnet50, val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show and Save predicted image\ndef predict_show(index, test_dataloader, model, spath=None):\n    \n    # 初期設定\n    # GPUが使えるかを確認\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"使用デバイス：\", device)\n\n    # ネットワークをGPUへ\n    model = model.to(device)\n\n    # ネットワークがある程度固定であれば、高速化させる\n    torch.backends.cudnn.benchmark = True\n    \n    with torch.no_grad():\n        \n        model.eval()\n        \n        fname, img = test_dataloader.dataset.__getitem__(index)\n        \n        img = img.unsqueeze(0)\n        \n        # GPUが使えるならGPUにデータを送る\n        img = img.to(device)\n            \n        output = model(img)\n            \n        prob = torch.sigmoid(output)\n        prob = (prob>0.5).float()\n            \n        img = img.to('cpu').detach().numpy().copy()[0,0]\n        prob = prob.to('cpu').detach().numpy().copy()[0,2]\n            \n        print(\"元画像\")\n        print(\"filename : {}\".format(fname))\n        plt.imshow(cv2.resize(img, (1600, 256), interpolation=cv2.INTER_NEAREST))\n        plt.xticks([])\n        plt.yticks([])\n        plt.show()\n        print(\"予測画像\")\n        plt.imshow(cv2.resize(prob, (1600, 256), interpolation=cv2.INTER_NEAREST))\n        plt.xticks([])\n        plt.yticks([])\n        if spath is not None:\n            save_path = os.path.join(spath, '{}_pred.jpg'.format(fname[:-4]))\n            plt.savefig(save_path)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_path  = \"./predicts\"\n\nif os.path.exists(save_path) == False:\n    os.makedirs(save_path)\n\nindex = 0\npredict_show(index, test_dataloader, resnet34, save_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    \n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def post_process(pred, min_size):\n    \n    mask = cv2.resize(pred, (1600, 256), interpolation=cv2.INTER_NEAREST)\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 初期設定\n# GPUが使えるかを確認\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"使用デバイス：\", device)\n\n# ネットワークをGPUへ\nmodel = resnet34.to(device)\n\n# ネットワークがある程度固定であれば、高速化させる\ntorch.backends.cudnn.benchmark = True    \n\nmin_size = 3500\n\npredictions = []\nfor i, batch in enumerate(tqdm(test_dataloader)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = (batch_preds>0.5).float()\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, min_size)\n            rle = mask2rle(pred)\n            if rle != '':\n                predictions.append([fname, rle, cls+1])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId', 'EncodedPixels', 'ClassId'])\ndf.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}