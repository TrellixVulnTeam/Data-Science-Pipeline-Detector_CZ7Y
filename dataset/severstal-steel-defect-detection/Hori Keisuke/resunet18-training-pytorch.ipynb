{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null # no output\npackage_path = '../input/unetmodelscript' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom model import Unet # import Unet model from the script","execution_count":null,"outputs":[]},{"metadata":{"id":"xDJkrByvHrVt","executionInfo":{"status":"ok","timestamp":1604177363153,"user_tz":-540,"elapsed":632,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tqdm.notebook import tqdm_notebook as tqdm\nimport seaborn as sns\nimport albumentations  as albu\nfrom albumentations.pytorch import ToTensor\nimport random\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nimport torchvision\nfrom torchvision import models\nfrom torch.autograd import Function","execution_count":null,"outputs":[]},{"metadata":{"id":"fQtNdjceHrVy","executionInfo":{"status":"ok","timestamp":1604177364380,"user_tz":-540,"elapsed":697,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"# 乱数のシードを設定\nseed = 1234\nrandom.seed(seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"id":"SUkDLitXHrV0","executionInfo":{"status":"ok","timestamp":1604177365049,"user_tz":-540,"elapsed":533,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"save_dir_weights  = \"./weights\"\nsave_dir_logs  = \"./logs\"\n\nif os.path.exists(save_dir_weights) == False:\n    os.makedirs(save_dir_weights)\nif os.path.exists(save_dir_logs) == False:\n    os.makedirs(save_dir_logs)","execution_count":null,"outputs":[]},{"metadata":{"id":"jiiZKphfHrV4"},"cell_type":"markdown","source":"# データ確認"},{"metadata":{"id":"QmU5Q_bcHrV5"},"cell_type":"markdown","source":"## 画像データ"},{"metadata":{"id":"KnYOMC8RHrV5","executionInfo":{"status":"ok","timestamp":1604175728886,"user_tz":-540,"elapsed":694,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"cae74a03-1bda-4177-ed41-1586bf8783aa","trusted":true},"cell_type":"code","source":"input_dir = \"../input/severstal-steel-defect-detection/\"\ninput_dir_Train  = os.path.join(input_dir, 'train_images')\ninput_dir_Test  = os.path.join(input_dir, 'test_images')\nfilelist_Train = os.listdir(input_dir_Train)\nfilelist_Test = os.listdir(input_dir_Test)\nprint('train data size : {}'.format(len(filelist_Train)))\nprint('test data size : {}'.format(len(filelist_Test)))","execution_count":null,"outputs":[]},{"metadata":{"id":"CqYqyQ-vHrV9","executionInfo":{"status":"ok","timestamp":1604175728887,"user_tz":-540,"elapsed":419,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"index = 0\npath = os.path.join(input_dir_Train, filelist_Train[0])\nimage = cv2.imread(path)","execution_count":null,"outputs":[]},{"metadata":{"id":"XVtVVFzJHrV_","executionInfo":{"status":"ok","timestamp":1604175729885,"user_tz":-540,"elapsed":1193,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"777e62d3-21c4-43fa-fd00-1e7743e8e1f6","trusted":true},"cell_type":"code","source":"plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"id":"XvPegZreHrWB","executionInfo":{"status":"ok","timestamp":1604175729887,"user_tz":-540,"elapsed":936,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"0706e274-5963-404e-cc77-83eab5855a1d","trusted":true},"cell_type":"code","source":"print('image shape : {}'.format(image.shape))","execution_count":null,"outputs":[]},{"metadata":{"id":"gJGpa_xxHrWF"},"cell_type":"markdown","source":"## csvファイル"},{"metadata":{"id":"qUZ0o-lhHrWF","executionInfo":{"status":"ok","timestamp":1604175731106,"user_tz":-540,"elapsed":1033,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"bb0e37bd-234e-4ea4-e76e-1fee0528100c","trusted":true},"cell_type":"code","source":"df_path = os.path.join(input_dir, 'train.csv')\ndf = pd.read_csv(df_path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"4JtOa9L9HrWJ","executionInfo":{"status":"ok","timestamp":1604175731108,"user_tz":-540,"elapsed":844,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"1f302bbe-a442-45c3-92d8-c26519d69b07","trusted":true},"cell_type":"code","source":"print('defect num : {}'.format(df['ImageId'].nunique()))\nprint('no defect num : {}'.format(len(filelist_Train) - df['ImageId'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"id":"IIsyka8OHrWL","executionInfo":{"status":"ok","timestamp":1604175732048,"user_tz":-540,"elapsed":1518,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"29ffd96f-0ee1-4c89-df79-30dbb938117f","trusted":true},"cell_type":"code","source":"defect_class = np.zeros((4))\nfor i in tqdm(range(len(df))):\n    class_id = df.iloc[i]['ClassId']\n    defect_class[class_id - 1] += 1","execution_count":null,"outputs":[]},{"metadata":{"id":"PXMOHbLbHrWP","executionInfo":{"status":"ok","timestamp":1604175732523,"user_tz":-540,"elapsed":1467,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"98c1c679-831f-49ff-cb7f-336d87fd5b21","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.barplot(x=np.arange(1, 5), y=defect_class, ax=ax)\nax.set_title(\"the number of images for each class\")\nax.set_xlabel(\"class\")","execution_count":null,"outputs":[]},{"metadata":{"id":"oy-SzlJ2HrWS"},"cell_type":"markdown","source":"# マスク画像作成"},{"metadata":{"id":"icnc44L5HrWT","executionInfo":{"status":"ok","timestamp":1604175732525,"user_tz":-540,"elapsed":1017,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"def make_df(df):\n    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n    df['defects'] = df.count(axis=1)\n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=seed)\n    return train_df, val_df","execution_count":null,"outputs":[]},{"metadata":{"id":"pi2A9iEaHrWW","executionInfo":{"status":"ok","timestamp":1604175733529,"user_tz":-540,"elapsed":451,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"train_df, val_df = make_df(df)","execution_count":null,"outputs":[]},{"metadata":{"id":"p5KpD64CHrWa","executionInfo":{"status":"ok","timestamp":1604175733825,"user_tz":-540,"elapsed":445,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"def make_mask(index, df):\n    filename = df.iloc[index].name\n    labels = df.iloc[index, :4]\n    masks = np.zeros((256, 1600, 4), dtype=np.float32)\n    for idx, label in enumerate(labels):\n        if label is not np.nan:\n            mask = np.zeros((256*1600), dtype=np.uint8)\n            pixels = label.split(' ')\n            pixels = [pixels[i:i+2] for i in range(0, len(pixels), 2)]\n            for pixel in pixels:\n                pos, le = pixel\n                pos, le = int(pos), int(le)\n                mask[pos-1:pos+le-1] = 1\n            masks[:,:,idx] = mask.reshape(256, 1600, order = 'F')\n    return filename, masks","execution_count":null,"outputs":[]},{"metadata":{"id":"tUcV0UfAHrWe","executionInfo":{"status":"ok","timestamp":1604175734380,"user_tz":-540,"elapsed":776,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"ec760704-9792-4b66-c6d5-65dd2859f07f","trusted":true},"cell_type":"code","source":"f, m = make_mask(0, train_df)\nprint('file name : {}'.format(f))\nplt.imshow(cv2.imread(os.path.join(input_dir_Train, f)))\nplt.show()\nplt.imshow(m[:,:,2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"5PsOD6g1HrWh"},"cell_type":"markdown","source":"# Data Augmentation"},{"metadata":{"id":"iqM7ggHqHrWi","executionInfo":{"status":"ok","timestamp":1604175735209,"user_tz":-540,"elapsed":751,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndef get_augmentation(mean, std, phase):\n    \n    if phase == 'train':\n        transform = [\n            albu.HorizontalFlip(p=0.5),\n            albu.VerticalFlip(p=0.5),\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    else:\n        transform = [\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    \n    return albu.Compose(transform)","execution_count":null,"outputs":[]},{"metadata":{"id":"b1guoLWzHrWk"},"cell_type":"markdown","source":"# DataLoader作成"},{"metadata":{"id":"5P0Opu6hHrWk","executionInfo":{"status":"ok","timestamp":1604175735658,"user_tz":-540,"elapsed":507,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, df, input_dir, phase):\n        self.df = df\n        self.input_dir = input_dir\n        self.transforms = get_augmentation(mean, std, phase) \n        self.phase = phase\n    def __getitem__(self, idx):\n        filename, mask = make_mask(idx, self.df)\n        image = cv2.imread(os.path.join(self.input_dir, filename))\n        augmented = self.transforms(image=image, mask=mask)\n        image, mask = augmented['image'], augmented['mask']\n        mask = mask[0].permute(2, 0, 1)\n        return image, mask\n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{"id":"2jlrf_b8HrWq","executionInfo":{"status":"ok","timestamp":1604175737459,"user_tz":-540,"elapsed":1868,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"d1955ad7-7936-4984-9717-9699d617fbda","trusted":true},"cell_type":"code","source":"train_dataset = MyDataset(train_df, input_dir_Train, phase = 'train')\nval_dataset = MyDataset(val_df, input_dir_Train, phase = 'val')\n\n# 動作確認\nindex = 0\nimage, mask = train_dataset.__getitem__(index) \nprint(image.size())\nplt.imshow(image.to('cpu').detach().numpy().copy()[0])\nplt.show()\nprint(mask.size())\nplt.imshow(mask.to('cpu').detach().numpy().copy()[2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"vwOIGAdVHrWt","executionInfo":{"status":"ok","timestamp":1604175738346,"user_tz":-540,"elapsed":2258,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"abf5c446-0d06-4d0d-9740-2a65d8477d5a","trusted":true},"cell_type":"code","source":"batch_size = 4\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=6)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)\n\ndataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n\n# 動作確認\nbatch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\ninputs, labels = next(batch_iterator)  # 1番目の要素を取り出す\nprint('inputs size : {}'.format(inputs.size()))\nprint('labels size : {}'.format(labels.size()))","execution_count":null,"outputs":[]},{"metadata":{"id":"CM9f-ys956pt"},"cell_type":"markdown","source":"# ネットワークモデル作成"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /tmp/.cache/torch/checkpoints/\n!cp ../input/resnet18/resnet18.pth /tmp/.cache/torch/checkpoints/resnet18-5c106cde.pth","execution_count":null,"outputs":[]},{"metadata":{"id":"hicLpOQ5HrWz","executionInfo":{"status":"error","timestamp":1604175778392,"user_tz":-540,"elapsed":3138,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"outputId":"ac866de1-2f90-4612-e01f-7b24d7122641","trusted":true},"cell_type":"code","source":"model = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)\n\nmodel.train()\n\nprint('ネットワーク設定完了：訓練モードに設定しました')","execution_count":null,"outputs":[]},{"metadata":{"id":"6JKExGCJeVLe"},"cell_type":"markdown","source":"# 損失関数を定義"},{"metadata":{"id":"9ZBsaLY6HrW6","executionInfo":{"status":"ok","timestamp":1604174251738,"user_tz":-540,"elapsed":13204,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()","execution_count":null,"outputs":[]},{"metadata":{"id":"HR49QdZJHrW-"},"cell_type":"markdown","source":"# 最適化手法を決定"},{"metadata":{"id":"7xJECfpKHrW_","executionInfo":{"status":"ok","timestamp":1604174251741,"user_tz":-540,"elapsed":13194,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(\n    model.parameters(), lr=5e-4\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"MhCA-6JIHrXB"},"cell_type":"markdown","source":"# 学習・検証を実施"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coeff(pred, mask):\n    with torch.no_grad():\n        batch_size = len(pred)\n        pred = pred.view(batch_size, -1) # Flatten\n        mask = mask.view(batch_size, -1)  # Flatten\n        pred = (pred>0.5).float()\n        mask = (mask>0.5).float()\n        smooth = 0.0001\n        intersection = (pred * mask).sum()\n        dice_pos = (2. * intersection + smooth) / (pred.sum() + mask.sum() + smooth) \n        intersection = ((pred + mask) == 0).sum()\n        dice_neg = (2. * intersection + smooth) / ((pred == 0).sum() + (mask == 0).sum() + smooth)\n        dice = (dice_pos + dice_neg) / 2.0\n        return dice.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders_dict, num_epoch, optimizer, criterion, train_loss, train_acc, val_loss, val_acc):\n    # 初期設定\n    # GPUが使えるかを確認\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"使用デバイス：\", device)\n\n    # ネットワークをGPUへ\n    model = model.to(device)\n\n    # ネットワークがある程度固定であれば、高速化させる    \n    torch.backends.cudnn.benchmark = True\n    \n    num_train_imgs = len(dataloaders_dict['train'].dataset)\n    num_val_imgs = len(dataloaders_dict['val'].dataset)\n    batch_size = dataloaders_dict['train'].batch_size\n    \n    for epoch in range(num_epoch):\n    \n        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n        print('-------------')\n    \n        #---- Train section\n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        for img, mask in tqdm(dataloaders_dict['train']):\n        \n            model.train()\n\n            # GPUが使えるならGPUにデータを送る   \n            img = img.to(device) \n            mask = mask.to(device)\n\n            # optimizerを初期化\n            optimizer.zero_grad()\n        \n            output = model(img)\n            loss =  criterion(output, mask)\n        \n            # 訓練時はバックプロパゲーション\n            loss.backward()\n            optimizer.step()\n        \n            # 結果の計算\n            epoch_loss += loss.item() # lossの合計を更新\n\n            prob = torch.sigmoid(output)\n            prob = prob.to('cpu').detach()\n            mask = mask.to('cpu').detach()\n        \n            # ダイス係数の合計を更新\n            epoch_acc += dice_coeff(prob, mask)\n        \n        train_loss.append(epoch_loss / num_train_imgs * batch_size)\n        train_acc.append(epoch_acc / num_train_imgs * batch_size)\n        \n        print('Train {} finished'.format(epoch + 1))\n        print('Loss : {}'.format(epoch_loss / num_train_imgs * batch_size))\n        print('Accuracy : {}'.format(epoch_acc / num_train_imgs * batch_size))\n    \n        #---- Val section\n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        with torch.no_grad():\n            for img, mask in tqdm(dataloaders_dict['val']):\n            \n                model.eval()\n            \n                # GPUが使えるならGPUにデータを送る\n                img = img.to(device)\n                mask = mask.to(device)\n\n                output = model(img)\n                loss = criterion(output, mask)\n                \n                # 結果の計算\n                epoch_loss += loss.item() # lossの合計を更新\n\n                prob = torch.sigmoid(output)\n                prob = prob.to('cpu').detach()\n                mask = mask.to('cpu').detach()\n            \n                # ダイス係数の合計を更新\n                epoch_acc += dice_coeff(prob, mask)\n            \n        val_loss.append(epoch_loss / num_val_imgs * batch_size)\n        val_acc.append(epoch_acc / num_val_imgs * batch_size)\n        \n        print('Valid {} finished'.format(epoch + 1))\n        print('Loss : {}'.format(epoch_loss / num_val_imgs * batch_size))\n        print('Accuracy : {}'.format(epoch_acc / num_val_imgs * batch_size))\n        \n        torch.save(model.state_dict(), '{}CP{}.pth'.format('./weights/resnet18_', epoch + 1))\n        print('Checkpoint {} saved'.format(epoch + 1)) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss = []\ntrain_acc = []\nval_loss = []\nval_acc = []\nnum_epoch = 20\ntrain_model(model, dataloaders_dict, num_epoch, optimizer, criterion, train_loss, train_acc, val_loss, val_acc)","execution_count":null,"outputs":[]},{"metadata":{"id":"YRwEUyIXHrXM"},"cell_type":"markdown","source":"# 可視化"},{"metadata":{"id":"i2_arA2eHrXP","executionInfo":{"status":"aborted","timestamp":1604174505062,"user_tz":-540,"elapsed":266443,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"plt.title('Resnet18')\nplt.xlabel(\"Epoch\")\nplt.plot(list(range(num_epoch)), train_acc, val_acc)\nplt.ylabel(\"Acc\")\nplt.legend(['Training Accuracy', 'Validation Accuracy'])\nplt.tight_layout()\nplt.grid(True)\nplt.savefig(\"./logs/acc.png\")","execution_count":null,"outputs":[]},{"metadata":{"id":"x_llhXHTHrXR","executionInfo":{"status":"aborted","timestamp":1604174505064,"user_tz":-540,"elapsed":266437,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"plt.title('Resnet18')\nplt.xlabel(\"Epoch\")\nplt.plot(list(range(num_epoch)), train_loss, val_loss)\nplt.ylabel(\"Loss\")\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.tight_layout()\nplt.grid(True)\nplt.savefig(\"./logs/loss.png\")","execution_count":null,"outputs":[]},{"metadata":{"id":"S_xEvLuVHrXT","executionInfo":{"status":"aborted","timestamp":1604174505065,"user_tz":-540,"elapsed":266430,"user":{"displayName":"堀圭佑","photoUrl":"","userId":"11216001278090624984"}},"trusted":true},"cell_type":"code","source":"    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}