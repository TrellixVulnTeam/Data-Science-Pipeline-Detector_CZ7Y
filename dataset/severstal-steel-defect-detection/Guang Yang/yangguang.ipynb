{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\nimport cv2\nimport six\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.regularizers import l2\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.core import Activation, SpatialDropout2D\nfrom keras.layers.merge import concatenate,add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\nfrom keras.layers import Conv2D, Concatenate, MaxPooling2D\nfrom keras.layers import UpSampling2D, Dropout, BatchNormalization\nfrom tqdm import tqdm_notebook\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.utils import conv_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.engine import InputSpec\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport random\nprint(os.listdir('../input/severstal-steel-defect-detection/'))\n\n#train_df 所有训练集图片的csv\ntrain_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\nval_sub_df = train_df.copy()#use when predict val\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n# print('#train_df 所有训练集图片的csv')\n# print(train_df.shape)\n# print(train_df.head())\nprint('#val_sub_df 所有csv')\nprint(val_sub_df.head())\n\n\n\n#repeat different class images\nclass_1_repeat = 32        # repeat class 1 examples x times\nclass_2_repeat = 60\nclass_3_repeat = 1\nclass_4_repeat = 32\n\n\n\n\nclass_1_img_id = train_df[((~ train_df['EncodedPixels'].isna())&(train_df['ClassId'] == '1'))]#897\nclass_1_img_id_index = np.repeat(class_1_img_id.index, class_1_repeat)\nclass_2_img_id = train_df[((~ train_df['EncodedPixels'].isna())&(train_df['ClassId'] == '2'))]#247\nclass_2_img_id_index = np.repeat(class_2_img_id.index, class_2_repeat)\nclass_3_img_id = train_df[((~ train_df['EncodedPixels'].isna())&(train_df['ClassId'] == '3'))]#5150\nclass_3_img_id_index = np.repeat(class_3_img_id.index, 1)\nclass_4_img_id = train_df[((~ train_df['EncodedPixels'].isna())&(train_df['ClassId'] == '4'))]#801\nclass_4_img_id_index = np.repeat(class_4_img_id.index, class_4_repeat)\n\n\nrepeated_train_image_ids = np.concatenate([class_2_img_id_index,class_1_img_id_index,class_3_img_id_index,class_4_img_id_index])\n# repeated_train_image_ids = non_missing_train_idx.index\nrandom.shuffle(repeated_train_image_ids)\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n\n    mask = np.zeros(width * height).astype(np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start + lengths[index])] = 1\n        current_position += lengths[index]\n\n    return mask.reshape(height, width).T\n\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    # print(\"rles depth :\"+str(depth))#4\n    masks = np.zeros((*input_shape, depth))\n\n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n\n    return masks\n\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n\n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n\n    return rles\n\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=3,  ####输入的通道数该为3\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n\n        X = self.__generate_X(list_IDs_batch)\n\n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n\n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n\n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = self.base_path+'/'+im_name#f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)  # 该为彩色3通道\n\n            # Store samples\n            X[i,] = img\n\n        return X\n\n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n\n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n\n            y[i,] = masks\n\n        return y\n\n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n\n    def __load_rgb(self, img_path):\n        #         print('load_rgb')\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img\n\nBATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    repeated_train_image_ids,#non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019,\n    test_size=0.05\n)\n\ntrain_generator = DataGenerator(\n    train_idx,\n    df=train_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE,\n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx,\n    df=train_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE,\n    n_classes=4\n)\n\n\n########build unet model ###########\n\ndef handle_block_names(stage):\n    conv_name = 'decoder_stage{}_conv'.format(stage)\n    bn_name = 'decoder_stage{}_bn'.format(stage)\n    relu_name = 'decoder_stage{}_relu'.format(stage)\n    up_name = 'decoder_stage{}_upsample'.format(stage)\n    return conv_name, bn_name, relu_name, up_name\n\n\ndef Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n                     batchnorm=False, skip=None):\n\n    def layer(input_tensor):\n\n        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n\n        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n\n        if skip is not None:\n            x = Concatenate()([x, skip])\n\n        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'1')(x)\n        if batchnorm:\n            x = BatchNormalization(name=bn_name+'1')(x)\n        x = Activation('relu', name=relu_name+'1')(x)\n\n        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n        if batchnorm:\n            x = BatchNormalization(name=bn_name+'2')(x)\n        x = Activation('relu', name=relu_name+'2')(x)\n\n        return x\n    return layer\n\n\ndef Transpose2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n                      transpose_kernel_size=(4,4), batchnorm=False, skip=None):\n\n    def layer(input_tensor):\n\n        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n\n        x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate,\n                            padding='same', name=up_name)(input_tensor)\n        if batchnorm:\n            x = BatchNormalization(name=bn_name+'1')(x)\n        x = Activation('relu', name=relu_name+'1')(x)\n\n        if skip is not None:\n            x = Concatenate()([x, skip])\n\n        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n        if batchnorm:\n            x = BatchNormalization(name=bn_name+'2')(x)\n        x = Activation('relu', name=relu_name+'2')(x)\n\n        return x\n    return layer\n\n\ndef build_unet(backbone, classes, last_block_filters, skip_layers,\n               n_upsample_blocks=5, upsample_rates=(2,2,2,2,2),\n               block_type='upsampling', activation='sigmoid',\n               **kwargs):\n\n    input = backbone.input\n    x = backbone.output\n\n    if block_type == 'transpose':\n        up_block = Transpose2D_block\n    else:\n        up_block = Upsample2D_block\n\n    # convert layer names to indices\n    skip_layers = ([get_layer_number(backbone, l) if isinstance(l, str) else l\n                    for l in skip_layers])\n    for i in range(n_upsample_blocks):\n\n        # check if there is a skip connection\n        if i < len(skip_layers):\n#             print(backbone.layers[skip_layers[i]])\n#             print(backbone.layers[skip_layers[i]].output)\n            skip = backbone.layers[skip_layers[i]].output\n        else:\n            skip = None\n\n        up_size = (upsample_rates[i], upsample_rates[i])\n        filters = last_block_filters * 2**(n_upsample_blocks-(i+1))\n\n        x = up_block(filters, i, upsample_rate=up_size, skip=skip, **kwargs)(x)\n\n    if classes < 2:\n        activation = 'sigmoid'\n######################################################################################################################\n    x = Conv2D(classes, (3,3), padding='same', name='final_conv')(x)\n    print('Conv2D classes',classes)\n    x = Activation(activation, name=activation)(x)\n\n    model = Model(input, x)\n\n    return model\n\n########build  resnet34 #######\ndef _bn_relu(input):\n    \"\"\"Helper to build a BN -> relu block\n    \"\"\"\n    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n    return Activation(\"relu\")(norm)\n\n\ndef _conv_bn_relu(**conv_params):\n    \"\"\"Helper to build a conv -> BN -> relu block\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=kernel_regularizer)(input)\n        return _bn_relu(conv)\n\n    return f\n\n\ndef _bn_relu_conv(**conv_params):\n    \"\"\"Helper to build a BN -> relu -> conv block.\n    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        activation = _bn_relu(input)\n        return Conv2D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=kernel_regularizer)(activation)\n\n    return f\n\n\ndef _shortcut(input, residual):\n    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n    \"\"\"\n    # Expand channels of shortcut to match residual.\n    # Stride appropriately to match residual (width, height)\n    # Should be int if network architecture is correctly configured.\n    input_shape = K.int_shape(input)\n    residual_shape = K.int_shape(residual)\n    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n\n    shortcut = input\n    # 1 X 1 conv if shape is different. Else identity.\n    if stride_width > 1 or stride_height > 1 or not equal_channels:\n        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n                          kernel_size=(1, 1),\n                          strides=(stride_width, stride_height),\n                          padding=\"valid\",\n                          kernel_initializer=\"he_normal\",\n                          kernel_regularizer=l2(0.0001))(input)\n\n    return add([shortcut, residual])\n\n\ndef basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n    \"\"\"\n\n    def f(input):\n\n        if is_first_block_of_first_layer:\n            # don't repeat bn->relu since we just did bn->relu->maxpool\n            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n                           strides=init_strides,\n                           padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=l2(1e-4))(input)\n        else:\n            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n                                  strides=init_strides)(input)\n\n        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n        return _shortcut(input, residual)\n\n    return f\n\n\ndef _residual_block(block_function, filters, repetitions, is_first_layer=False):\n    \"\"\"Builds a residual block with repeating bottleneck blocks.\n    \"\"\"\n\n    def f(input):\n        for i in range(repetitions):\n            init_strides = (1, 1)\n            if i == 0 and not is_first_layer:\n                init_strides = (2, 2)\n            input = block_function(filters=filters, init_strides=init_strides,\n                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n        return input\n\n    return f\n\n\ndef _handle_dim_ordering():\n    global ROW_AXIS\n    global COL_AXIS\n    global CHANNEL_AXIS\n    if K.image_dim_ordering() == 'tf':\n        ROW_AXIS = 1\n        COL_AXIS = 2\n        CHANNEL_AXIS = 3\n    else:\n        CHANNEL_AXIS = 1\n        ROW_AXIS = 2\n        COL_AXIS = 3\n\n\ndef _get_block(identifier):\n    if isinstance(identifier, six.string_types):\n        res = globals().get(identifier)\n        if not res:\n            raise ValueError('Invalid {}'.format(identifier))\n        return res\n    return identifier\n\n\nclass ResnetBuilder(object):\n    @staticmethod\n    def build(input_shape, block_fn, repetitions, input_tensor):\n        _handle_dim_ordering()\n        if len(input_shape) != 3:\n            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n\n        # Permute dimension order if necessary\n        if K.image_dim_ordering() == 'tf':\n            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n\n        # Load function from str if needed.\n        block_fn = _get_block(block_fn)\n\n        if input_tensor is None:\n            img_input = Input(shape=input_shape)\n        else:\n            if not K.is_keras_tensor(input_tensor):\n                img_input = Input(tensor=input_tensor, shape=input_shape)\n            else:\n                img_input = input_tensor\n\n        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(img_input)\n        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n\n        block = pool1\n        filters = 64\n        for i, r in enumerate(repetitions):\n            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n            filters *= 2\n\n        # Last activation\n        block = _bn_relu(block)\n\n        model = Model(inputs=img_input, outputs=block)\n        return model\n\n    @staticmethod\n    def build_resnet_34(input_shape, input_tensor):\n        return ResnetBuilder.build(input_shape, basic_block, [3, 4, 6, 3], input_tensor)\n\n\n##########unet  with resnet34 encoder #############\ndef UResNet34(input_shape=(None, None, 3), classes=4, decoder_filters=16, decoder_block_type='upsampling',\n                       encoder_weights=None, input_tensor=None, activation='sigmoid', **kwargs):\n\n    backbone = ResnetBuilder.build_resnet_34(input_shape=input_shape,input_tensor=input_tensor)\n\n    skip_connections = list([97,54,25])  # for resnet 34\n    model = build_unet(backbone, classes, decoder_filters,\n                       skip_connections, block_type=decoder_block_type,\n                       activation=activation, **kwargs)\n    model.name = 'u-resnet34'\n\n    return model\nmodel = UResNet34(input_shape=(3,256,1600))\nmodel.summary()\n\n\n##########define loss function ################\nfrom keras.losses import binary_crossentropy\nfrom keras import backend as K\n\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\ndef focal_loss(y_true, y_pred):\n    gamma = 0.75\n    alpha = 0.25\n    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n\n    pt_1 = K.clip(pt_1, 1e-3, .999)\n    pt_0 = K.clip(pt_0, 1e-3, .999)\n\n    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.sum(\n        (1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n\n\n# Focal Loss + DICE LOSS\ndef mixedLoss(y_true, y_pred, alpha=0.01):\n    return alpha * focal_loss(y_true, y_pred) - K.log(dice_loss(y_true, y_pred))\n\n# #lovasz loss\n# def lovasz_grad(gt_sorted):\n#     \"\"\"\n#     Computes gradient of the Lovasz extension w.r.t sorted errors\n#     See Alg. 1 in paper\n#     \"\"\"\n#     gts = tf.reduce_sum(gt_sorted)\n#     intersection = gts - tf.cumsum(gt_sorted)\n#     union = gts + tf.cumsum(1. - gt_sorted)\n#     jaccard = 1. - intersection / union\n#     jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n#     return jaccard\n#\n#\n#\n#\n# def lovasz_hinge_flat(logits, labels):\n#     \"\"\"\n#     Binary Lovasz hinge loss\n#       logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n#       labels: [P] Tensor, binary ground truth labels (0 or 1)\n#       ignore: label to ignore\n#     \"\"\"\n#\n#     def compute_loss():\n#         labelsf = tf.cast(labels, logits.dtype)\n#         signs = 2. * labelsf - 1.\n#         errors = 1. - logits * tf.stop_gradient(signs)\n#         errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n#         gt_sorted = tf.gather(labelsf, perm)\n#         grad = lovasz_grad(gt_sorted)\n#         loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n#         return loss\n#\n#     # deal with the void prediction case (only void pixels)\n#     loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n#                    lambda: tf.reduce_sum(logits) * 0.,\n#                    compute_loss,\n#                    strict=True,\n#                    name=\"loss\"\n#                    )\n#     return loss\n\n\nmodel.compile(loss=binary_crossentropy, optimizer=\"adadelta\", metrics=[\"accuracy\"])#dice_loss\n\n#########training ##########################\n# early_stopping = EarlyStopping(patience=10, verbose=1)\n# model_checkpoint = ModelCheckpoint(\"./keras.model\",\n#                                    save_best_only=True,\n#                                    verbose=0, save_weights_only=False,\n#                                     mode='auto')\n# reduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)\n\n# epochs = 20\n\n\n# history = model.fit_generator( train_generator,\n#     validation_data=val_generator,\n#                     epochs=epochs,\n#                     callbacks=[early_stopping, model_checkpoint, reduce_lr],\n#                     use_multiprocessing=False,\n#                     workers=1\n#                    )#callbacks=[early_stopping, model_checkpoint, reduce_lr],\n\n\n# print(history.history)\n# with open('history.json', 'w+') as f:\n#     historyDecoder = history.history\n#     for k in historyDecoder.keys():\n#         historyDecoder[k] = list(map(float, historyDecoder[k]))\n#     json.dump((historyDecoder), f)\n# print(historyDecoder)\n# with open('history.json','r') as f:\n#     history2 = json.load(f)\n#     print(history2)\n# history_df = pd.DataFrame(history2)\n# history_df[['loss', 'val_loss']].plot()\n# history_df[['acc', 'val_acc']].plot()\n# # plt.show()\n\n\n# predict val\n# model = load_model('./keras.model')\n\nval_image = train_df.loc[val_idx]\nval_image = pd.DataFrame(val_image['ImageId'].unique(), columns=['ImageId'])\nval_df = []\n\nfor i in range(0, val_image.shape[0], 500):\n    batch_idx = list(\n        range(i, min(val_image.shape[0], i + 500))\n    )\n\n    val_generator = DataGenerator(\n        batch_idx,\n        df=val_image,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/train_images',\n        target_df=val_sub_df,\n        batch_size=1,\n        n_classes=4\n    )\n\n    batch_pred_masks = model.predict_generator(\n        val_generator,\n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = val_image['ImageId'].iloc[b]\n        image_df = val_sub_df[val_sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j,].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n\n        image_df['EncodedPixels'] = pred_rles\n        val_df.append(image_df)\n\nval_df = pd.concat(val_df)\nval_df.drop(columns='ImageId', inplace=True)\nval_df.to_csv('../input/severstal-steel-defect-detection/val_create.csv', index=False)\n\n\n\n\n\n\n\n\n\n# predict and submit\nsub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\n# print('test_imgs  num'+test_imgs.shape)\ntest_df = []\n\nfor i in range(0, test_imgs.shape[0], 500):\n    batch_idx = list(\n        range(i, min(test_imgs.shape[0], i + 500))\n    )\n\n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        target_df=sub_df,\n        batch_size=1,\n        n_classes=4\n    )\n\n    batch_pred_masks = model.predict_generator(\n        test_generator,\n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n\n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = test_imgs['ImageId'].iloc[b]\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n\n        pred_masks = batch_pred_masks[j,].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n\n        image_df['EncodedPixels'] = pred_rles\n        test_df.append(image_df)\n\ntest_df = pd.concat(test_df)\ntest_df.drop(columns='ImageId', inplace=True)\ntest_df.to_csv('../input/severstal-steel-defect-detection/submission.csv', index=False)\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}