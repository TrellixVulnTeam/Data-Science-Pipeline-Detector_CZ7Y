{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Детектор дефектов проката стали (Для портфолио)\n\n    Оригинальный датасет взят из соревнования https://www.kaggle.com/c/severstal-steel-defect-detection/\n  \n    На руках у нас датасет с множеством картинок 1280 x 204 х 3, в большинстве своем серых тонов или темных (требуется нормализация).\n    \n    Представены дефекты металлических поверхностей в 4 классах [1, 2, 3, 4]\n    И также представлены маски дефектов для каждого класса в виде RLE\n    \n    Для работы я выбрал я выбрал Semantic Segmentational U-net модель (она же заняла топ-1 на соревновании), без последнего слоя активации torch.sigmoid() (добавлю на тесте, чтобы получить вероятности)\n    https://arxiv.org/abs/1505.04597\n    https://github.com/qubvel/segmentation_models.pytorch\n    \n    Это модель в энкодере которого лежит ResNet, а декодер и bottleneck'и свои.\n    В блоки декодера они добавили Attention слои для создания связей между блоками\n\n    Цель Semantic Segmentational - выделить области относящиеся к одному классу.\n\n    Для данной задачи так же можно использовать R-CNN c Instance Segmentational, но для этого нужно будет дополнительно сегментировать каждый дефект отдельно (чуть больше кода...)\n\n    Обучал на домашней RTX 3070, R-CNN тяжелее чем U-Net, экономим время...\n    Kaggle предоставляет ГПУ, но таймаут в ~60 минут заставляет постоянно сидеть у экрана.\n\n    Обучение одной эпохи:\n    Kaggle T100 ~ 24 min\n    RTX 3070    ~  7 min\n\n    Функции потерь мы используем:\n     ↓ BCEWithLogitsLoss (Binary Cross Entropy) - хорошо работает для multilabel классификации\n     ↑ F_1 - также работает как метрика  для multilabel\n     ↑ IoU - Intesection over Union, хорошо показывает совпадение зон маски и таргета, multilabel\n     ↑ Dice - также хорошо определяет сходства двух multilabel выборокб похожа на IoU\n\n    Обычно BCEWithLogitsLoss и Dice наиболее часто используются для моделей сегментации.\n\n    Для дстижения лучших результатов мы делаем аугументацию изображений для каждого батча.\n    \n    Полученные результаты обучения модели:\n\n    Эпоха: 14\n    bce_loss:    0.02103   Характеризует расстояния между маской и таргетом  (0 к 0 он тоже приближает, если нет дефектов)\n    iou_scores:  0.56879   (0,4 - считается плохим уровнем, 0,7 - хороший, 0,9 - отличный)\n\n    f_scores:    0.46668   в 46% случаев я угадываю дефект в ключе one vs rest (это в 2 раза чаще, чем если бы я это делал наугад 25%...)\n\n    dice_scores: 0.56879   Еще одна бинарная мера сходства, очень похожая на IoU","metadata":{"_cell_guid":"9b12ba02-d138-445b-a847-6c7809a6cdd8","_uuid":"c887a772-4ba2-40dd-a08b-cfdddea8b776","papermill":{"duration":0.024284,"end_time":"2021-01-12T13:33:44.745695","exception":false,"start_time":"2021-01-12T13:33:44.721411","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport time\n\nfrom typing import Optional, Tuple\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\n\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport pickle\n\nfrom albumentations import HorizontalFlip, VerticalFlip, RandomBrightnessContrast,  ShiftScaleRotate, Normalize, Compose, GaussNoise, ElasticTransform\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm\n\n!pip install segmentation_models_pytorch\nimport segmentation_models_pytorch as smp # https://github.com/qubvel/segmentation_models.pytorch\n\n# Install gdown\n!conda install -y gdown\n\n%matplotlib inline","metadata":{"_cell_guid":"3170f4e6-ec12-4d61-a012-977317a0f5dc","_uuid":"16bea135-6c2f-4d73-889c-02f41e82b18f","papermill":{"duration":17.370379,"end_time":"2021-01-12T13:34:02.139297","exception":false,"start_time":"2021-01-12T13:33:44.768918","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:45:34.862447Z","iopub.execute_input":"2022-03-10T08:45:34.862767Z","iopub.status.idle":"2022-03-10T08:46:53.915817Z","shell.execute_reply.started":"2022-03-10T08:45:34.862734Z","shell.execute_reply":"2022-03-10T08:46:53.914972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1R5yFU2h-55BtEE4pdxGz8z33Pqb5EidU\n!gdown --id 1mR_7Jakg8_MmfEPYFX5LeieCWrwqonHB","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T08:46:53.917883Z","iopub.execute_input":"2022-03-10T08:46:53.918154Z","iopub.status.idle":"2022-03-10T08:47:01.286258Z","shell.execute_reply.started":"2022-03-10T08:46:53.918127Z","shell.execute_reply":"2022-03-10T08:47:01.285126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Смотрим датасеты","metadata":{"papermill":{"duration":0.029845,"end_time":"2021-01-12T13:34:02.199962","exception":false,"start_time":"2021-01-12T13:34:02.170117","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# loading dataset\nDATA_DIR = '../input/severstal-steel-defect-detection'\n\nTRAIN_IMG_DIR = DATA_DIR + '/train_images'                    # Contains training images\nTEST_IMG_DIR = DATA_DIR + '/test_images'                      # Contains test images\n\nTRAIN_CSV = DATA_DIR + '/train.csv'                       # Contains real labels for training images\nTEST_CSV = DATA_DIR + '/sample_submission.csv'            # Contains dummy labels for test image\nTRAINED_WEIGHTS = ''                   # Contains trained weights\nTRAINED_METRICS = 'last_model.pkl'     # Contains trained metrics\nSUBMISSION_FILE = 'submission.csv'     # Contains trined labels for test image\nPRE_TRAINED_WEIGHTS = ''\n\n\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)","metadata":{"_cell_guid":"f572cf7b-8dc4-4107-ae0b-c238fa6cd1b7","_uuid":"db987ee9-a488-49ca-af49-bfb18da080c9","papermill":{"duration":0.410175,"end_time":"2021-01-12T13:34:02.639748","exception":false,"start_time":"2021-01-12T13:34:02.229573","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:01.298567Z","iopub.execute_input":"2022-03-10T08:47:01.301223Z","iopub.status.idle":"2022-03-10T08:47:01.682578Z","shell.execute_reply.started":"2022-03-10T08:47:01.301169Z","shell.execute_reply":"2022-03-10T08:47:01.681671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"_cell_guid":"7f6405c0-4932-4b72-add5-49abe373af21","_uuid":"dcb95d2b-51c1-4984-ba7d-3bd74be0b741","papermill":{"duration":0.048912,"end_time":"2021-01-12T13:34:02.718898","exception":false,"start_time":"2021-01-12T13:34:02.669986","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:01.685192Z","iopub.execute_input":"2022-03-10T08:47:01.685823Z","iopub.status.idle":"2022-03-10T08:47:01.703124Z","shell.execute_reply.started":"2022-03-10T08:47:01.685782Z","shell.execute_reply":"2022-03-10T08:47:01.702472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'колличество записей: {len(train_df)}')","metadata":{"_cell_guid":"39711f63-df46-467e-8223-6ca53102c025","_uuid":"64d452e2-719d-467d-a8d4-5ff7d9f5afb2","papermill":{"duration":0.039219,"end_time":"2021-01-12T13:34:02.788278","exception":false,"start_time":"2021-01-12T13:34:02.749059","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:01.706683Z","iopub.execute_input":"2022-03-10T08:47:01.70697Z","iopub.status.idle":"2022-03-10T08:47:01.71182Z","shell.execute_reply.started":"2022-03-10T08:47:01.706939Z","shell.execute_reply":"2022-03-10T08:47:01.710698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"_cell_guid":"3e706dd6-f69a-4a4d-87e7-8e268ab02a58","_uuid":"431701f6-3e77-428e-a678-19914abb09bb","papermill":{"duration":0.043645,"end_time":"2021-01-12T13:34:02.862894","exception":false,"start_time":"2021-01-12T13:34:02.819249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:01.715098Z","iopub.execute_input":"2022-03-10T08:47:01.715696Z","iopub.status.idle":"2022-03-10T08:47:01.727252Z","shell.execute_reply.started":"2022-03-10T08:47:01.715655Z","shell.execute_reply":"2022-03-10T08:47:01.726289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{"_cell_guid":"fe5440d3-445d-4222-af98-d1d68b612fe3","_uuid":"7026d523-e94f-4c51-9af2-be94479d5a18","papermill":{"duration":0.032177,"end_time":"2021-01-12T13:34:02.926997","exception":false,"start_time":"2021-01-12T13:34:02.89482","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def survey(df_in: pd.DataFrame):\n    \"\"\"\n    Считаем колличество масок и классов ('maskCount', 'ImageId')\n    \"\"\"\n    df_maskCnt = pd.DataFrame({'maskCount' : df_in.groupby('ImageId').size()})\n    df_out = pd.merge(df_in, df_maskCnt, on='ImageId')\n    df_out = df_out.sort_values(by=['maskCount', 'ImageId'], ascending=False)\n\n    df_out['ClassIds'] = pd.Series(dtype=object)\n\n    for i, row_i in df_out.iterrows():\n        ClassId_list = []\n        for j, row_j in df_out.loc[df_out['ImageId'] == row_i['ImageId']].iterrows():\n            ClassId_list.append(row_j['ClassId'])\n        df_out.at[i,'ClassIds'] = ClassId_list\n    return df_out\n\ndf = survey(train_df)\ndf.head(15)","metadata":{"_cell_guid":"0c37703a-7f72-42a4-a6f3-d9a04a098b5a","_uuid":"f75600f5-329b-4e63-9e5e-4fb62fa02abe","papermill":{"duration":13.066416,"end_time":"2021-01-12T13:34:16.027684","exception":false,"start_time":"2021-01-12T13:34:02.961268","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:01.729648Z","iopub.execute_input":"2022-03-10T08:47:01.730005Z","iopub.status.idle":"2022-03-10T08:47:14.673393Z","shell.execute_reply.started":"2022-03-10T08:47:01.729968Z","shell.execute_reply":"2022-03-10T08:47:14.672269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def class_id2index(val: int):\n    \"\"\" Кодируем ClassId to index in masks\"\"\"\n    return int(val-1)\n\ndef index2class_id(val: int):\n    \"\"\" Декодируем index to ClassId in masks\"\"\"\n    return int(val+1)\n\ndef counter_func(df_in):\n    \"\"\"\n    Считаем статистику по классам на датафрейме\n    \"\"\"\n    length = 4\n    counter = np.zeros(length, dtype=int)\n    total = 0\n    for i in range(length):\n        try:\n            index = class_id2index(df_in.index[i])\n            counter[index] = df_in.iloc[i, 0]  \n        except:\n            continue\n        \n        \n    total = counter.sum()\n    return total, counter ","metadata":{"papermill":{"duration":0.043103,"end_time":"2021-01-12T13:34:16.103222","exception":false,"start_time":"2021-01-12T13:34:16.060119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:14.675026Z","iopub.execute_input":"2022-03-10T08:47:14.675446Z","iopub.status.idle":"2022-03-10T08:47:14.686655Z","shell.execute_reply.started":"2022-03-10T08:47:14.675404Z","shell.execute_reply":"2022-03-10T08:47:14.685454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_distribution(df_in: pd.DataFrame):\n    \"\"\"\n    Функция выдает распределение по дефектам и классам\n    :param df_in:\n    :return:\n    \"\"\"\n    mask_count_df_pivot = pd.DataFrame({'ClassCount' : df_in.groupby('ImageId').size()})\n    mask_count_df_pivot = pd.DataFrame({'Num' : mask_count_df_pivot.groupby('ClassCount').size()})\n    mask_count_df_pivot.sort_values('ClassCount', ascending=True, inplace=True)\n\n    ClassId_count_df = df_in.set_index([\"ImageId\", \"ClassId\"]).groupby(level='ClassId').count()\n\n    class_total, class_counter = counter_func(ClassId_count_df)\n    mask_total, mask_counter = counter_func(mask_count_df_pivot)\n    return class_total, class_counter, mask_total, mask_counter\n\n\nclass_total, class_counter, mask_total, mask_counter = get_distribution(df)\n\nprint(\"\"\"Total cnt defected: {0},\n1 class defect: {1},\n2 class defect: {2},\n3 class defect: {3},\n4 class defect: {4}\n\"\"\".format(class_total, *class_counter))\n\nprint(\"\"\"Total cnt images: {0},\nwith one defect:    {1},\nwith two defects:   {2},\nwith three defects: {3},\nwith four defects:  {4}\n\"\"\".format(mask_total, *mask_counter))","metadata":{"_cell_guid":"ecca8b3b-c8b9-4e6d-ae3c-5480248868f0","_uuid":"539f0dc3-35a2-44e7-bf92-f267d797d19c","papermill":{"duration":0.071104,"end_time":"2021-01-12T13:34:16.206297","exception":false,"start_time":"2021-01-12T13:34:16.135193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:47:14.688156Z","iopub.execute_input":"2022-03-10T08:47:14.688727Z","iopub.status.idle":"2022-03-10T08:47:14.735595Z","shell.execute_reply.started":"2022-03-10T08:47:14.688684Z","shell.execute_reply":"2022-03-10T08:47:14.734863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_cls_distrib = [[class_total, *class_counter],\n                   ]\n\ncompare_defects_distrib = [[mask_total, *mask_counter],\n                   ]\nlabels = ['Total cnt', '1 class', '2 class', '3 class', '4 class']\nx = np.arange(len(labels))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(15,4))\n\np1 = ax.bar(x, compare_cls_distrib[0], width, label='Train dataset')\n\nax.set_title('Class distribution')\nax.set_ylabel('cnt')\nax.set_xticklabels(['']+labels)\nax.legend()\n\nplt.show()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T09:15:09.958442Z","iopub.execute_input":"2022-03-10T09:15:09.9588Z","iopub.status.idle":"2022-03-10T09:15:10.109829Z","shell.execute_reply.started":"2022-03-10T09:15:09.958766Z","shell.execute_reply":"2022-03-10T09:15:10.108872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Распределение не равномерное...**","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"# RLE-Mask utility functions","metadata":{"_cell_guid":"be7f90b2-b124-46fc-a535-87357120a989","_uuid":"b4f58602-371d-429b-865e-b18eb5c14fd0","papermill":{"duration":0.032096,"end_time":"2021-01-12T13:34:16.272087","exception":false,"start_time":"2021-01-12T13:34:16.239991","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\ndef mask2rle(img: np.array):\n    \"\"\"\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated (start length)  RLE\n    \"\"\"\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    if rle == np.nan:\n        return ''\n    else:\n        return rle #returns a string formated (start length)\n\ndef rle2mask(mask_rle: str, input_shape: Tuple[int, int, int]=(256,1600,1)):\n    \n    \"\"\"    \n    img\n    The pixel order of the line is from top to bottom from the left vertical line.\n     It must be made and handed over.\n     width/height should be made [height, width, ...] to fit the rows and columns.\n\n     example when width=4, height=3\n    \n    s = [1,2,3,4,5,6,7,8,9,10,11,12]\n        => 1,2,3 First row on the left, second row on 4,5,6\n    \n    mask_rle: run-length as string formated (start length)\n    shape: (height,width)!!!  of array to return\n    Returns numpy array, 1 - mask, 0 - background\n    \"\"\"\n\n    height, width = input_shape[:2]\n\n    \"\"\"\n    RLE\n    Is a repetition of (start point, length), so divide it by even/odd and start point array\n     Create an array of lengths.\n     s[1:]: from 1 to the end\n     s[1:][::2]: Skip 2 by s[1:] to get an array of extracted values.\n    \"\"\"\n\n    mask = np.zeros(width * height, dtype=np.uint8)\n    if mask_rle is not np.nan:\n        s = mask_rle.split()\n        array = np.asarray([int(x) for x in s])\n        starts = array[0::2]\n        lengths = array[1::2]\n\n        for index, start in enumerate(starts):\n            begin = int(start - 1)\n            end = int(begin + lengths[index])\n            mask[begin : end] = 1\n\n    \"\"\"\n    img\n    The pixel order of the line is from top to bottom from the left vertical line.\n     It must be made and handed over.\n     width/height should be made [height, width, ...] to fit the rows and columns.\n\n     ex) When width=4, height=3\n\n    s = [1,2,3,4,5,6,7,8,9,10,11,12]\n        => 1,2,3 First row on the left, second row on 4,5,6\n\n    s.reshape(4,3) :\n    [[ 1  2  3]\n     [ 4  5  6]\n     [ 7  8  9]\n     [10 11 12]]\n\n    s.reshape(4,3).T :\n    [[ 1  4  7 10]\n     [ 2  5  8 11]\n     [ 3  6  9 12]]\n    \"\"\"\n\n    rle_mask = mask.reshape(width, height).T\n    return rle_mask\n\n# Test RLE functions\nassert mask2rle(rle2mask(df['EncodedPixels'].iloc[0]))==df['EncodedPixels'].iloc[0]\nassert mask2rle(rle2mask('1 1'))=='1 1'\nassert mask2rle(np.zeros((256, 1600), np.float32)) == ''","metadata":{"papermill":{"duration":0.060375,"end_time":"2021-01-12T13:34:16.364759","exception":false,"start_time":"2021-01-12T13:34:16.304384","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:36.704114Z","iopub.execute_input":"2022-03-10T08:48:36.704464Z","iopub.status.idle":"2022-03-10T08:48:36.729601Z","shell.execute_reply.started":"2022-03-10T08:48:36.704431Z","shell.execute_reply":"2022-03-10T08:48:36.728664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_masks(rle_labels: pd.DataFrame, input_shape: Tuple[int, int, int]=(256, 1600, 4)):\n    \"\"\"\n    Строит маску вида [256, 1600, 4] из rle_labels входящего датафрейма\n    :param rle_labels: pd.DataFrame ImageId, ClassId, RLE\n    :param input_shape: (height, width) of array to return\n    :return: masks #(256, 1600, 4)\n    \"\"\"\n    masks = np.zeros(input_shape)\n    for _, val in rle_labels.iterrows():\n        masks[:, :, class_id2index(val['ClassId'])] = rle2mask(val['EncodedPixels'], input_shape)\n    return masks #(256, 1600, 4)\n\ndef make_mask(row_id_in: int, df_in: pd.DataFrame,  input_shape_in: Tuple[int, int, int] = (256, 1600, 4)):\n    \"\"\"\n    По индексу записи в датафрейме, возвращает, image_id и mask [256, 1600, 4]\n    :param row_id_in: int\n    :param df_in: pd.DatFrame\n    :param input_shape_in: Tuple[int] = (256, 1600, 4))\n    :return: fname, masks\n    \"\"\"\n    fname = df_in.iloc[row_id_in].ImageId\n    rle_labels = df_in[df_in['ImageId'] == fname][['ImageId', 'ClassId', 'EncodedPixels']]\n    masks = build_masks(rle_labels, input_shape=input_shape_in) #(256, 1600, 4)\n    return fname, masks","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:48:37.462313Z","iopub.execute_input":"2022-03-10T08:48:37.462679Z","iopub.status.idle":"2022-03-10T08:48:37.472178Z","shell.execute_reply.started":"2022-03-10T08:48:37.462646Z","shell.execute_reply":"2022-03-10T08:48:37.471151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(df_in: pd.DataFrame, img_dir: str, trained_df_in: pd.DataFrame = None):\n    \"\"\"\n    Вьюха, показывает несколько изображений с наибольшим колличеством классов брака,\n    в случаее указания trained_df_in, сравнивает два изображения по их id\n    :param df_in:\n    :param img_dir:\n    :param trained_df_in:\n    \"\"\"\n    local_df = df_in\n    local_trained_df = trained_df_in\n    columns = 1\n    if type(trained_df_in) == pd.DataFrame:\n        rows = 15\n    else:\n        rows = 10\n    \n    \n    fig = plt.figure(figsize=(20,100))\n    \n    def sorter(local_df):\n        local_df = local_df.sort_values(by=['maskCount', 'ImageId'], ascending=False)\n        # Паказывает изображения с наибольшим колличеством классов брака\n        grp = local_df['ImageId'].drop_duplicates()[0:rows]\n        return grp\n\n    ax_idx = 1\n    for filename in sorter(df_in):\n        if ax_idx > rows * columns * 2:\n            break\n\n        subdf = local_df[local_df['ImageId'] == filename].reset_index()\n        # Выбирает файл с масками\n\n        fig.add_subplot(rows * 2, columns, ax_idx).set_title(filename)\n        img = cv2.imread(os.path.join(img_dir, filename ))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_2 = cv2.imread(os.path.join(img_dir, filename ))\n        img_2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n\n        # Паказывает маски из целевого датафрейма\n            \n        ax_idx += 1\n        fig.add_subplot(rows * 2, columns, ax_idx).\\\n            set_title(filename + '      Highlighted defects ClassIds: ' + str(subdf['ClassIds'][0]))\n\n        colors = [(255, 51, 51),(255,255,51), (51,255,51), (51,51,255)]\n        masks = build_masks(subdf, (256, 1600, 4)) # маски (256, 1600, 4)\n        masks_len = masks.shape[2] # get 4\n        \n        for i in range(masks_len):\n            img[masks[:, :, i] == 1] = colors[i]\n\n        plt.imshow(img)\n        ax_idx += 1\n\n\n        # Показывает маски из второго датафрейма (для сравнения)\n        if type(trained_df_in) == pd.DataFrame:\n            subdf_trained = local_trained_df[local_trained_df['ImageId'] == filename].reset_index()\n            # Вибираем файлы с масками\n            fig.add_subplot(rows * 2, columns, ax_idx).\\\n                set_title('Trained  '+ filename + '      Highlighted defects ClassIds: ' + str(subdf['ClassIds'][0]))\n\n            colors = [(204, 51, 51),(204,204,51), (51,204,51), (51,51,204)]\n            masks = build_masks(subdf_trained, (256, 1600, 4)) # маски (256, 1600, 4)\n            masks_len = masks.shape[2] # get 4\n\n            for i in range(masks_len):\n                img_2[masks[:, :, i] == 1] = colors[i]\n\n            plt.imshow(img_2)\n            ax_idx += 1\n        \n    print(\"Class 1 = Red   (bubbles/splashes)\",\n          \"Class 2 = Yelow (folds/foliations inside the metal)\",\n          \"Class 3 = Green (scratches received during the movement of the sheet/rolled)\",\n          \"Class 4 = Blue  (foliations, surges, carvings, significant defects)\", sep='\\n')\n    plt.show()\n    \nshow_images(df, TRAIN_IMG_DIR)","metadata":{"papermill":{"duration":5.435614,"end_time":"2021-01-12T13:34:21.907252","exception":false,"start_time":"2021-01-12T13:34:16.471638","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:37.86283Z","iopub.execute_input":"2022-03-10T08:48:37.86316Z","iopub.status.idle":"2022-03-10T08:48:43.281626Z","shell.execute_reply.started":"2022-03-10T08:48:37.863127Z","shell.execute_reply":"2022-03-10T08:48:43.280461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Класс 1 = Красный (Пузырьки/брызги)**\n\n**Класс 2 = Желтый  (Складки/слоения внутри металла)**\n\n**Класс 3 = Зеленый (Царапины полученные при движении листа\\проката)**\n\n**Класс 4 = Синий (Слоения, Наплывы, карвины, существенные дефекты)**\n\n**2й и 3й классы очень похожи между собой, визуально сложно отличить Царапину от Складки/слоения... также распределение классов сдвинуто в пользу карапин (3 класса)**\n\n**Есть подозрения в плохой разметке датасета...**\n\n**Распледеление классов не равномерное, но возможно оно характерно прокату.**\n\n**Нормализовать классы по колличеству можно, но, это приведет к значительному уменьшению датасета, что скажется на качестве обученной модели.**\n\n**Т.к. цель стоит больше в определении мест брака, пока нет смысла в выравнивании классов.**\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"# Datasets & Data Loaders","metadata":{"_cell_guid":"1252d879-b0b3-4df1-8f7f-fc1494b81645","_uuid":"dec91fdc-7857-4ed9-ba17-d2c0a2da0fe0","papermill":{"duration":0.112674,"end_time":"2021-01-12T13:34:22.135204","exception":false,"start_time":"2021-01-12T13:34:22.02253","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class SteelDataset(Dataset):\n    \"\"\"\n    Класс по созданию датасета идущую в модель\n    \"\"\"\n    def __init__(self,\n                 df_in: pd.DataFrame,\n                 data_folder_in: str,\n                 mean_in: Optional[Tuple[float]],\n                 std_in: Optional[Tuple[float]],\n                 phase_in: str):\n        \"\"\"\n        :param df_in: pd.DataFrame\n        :param data_folder_in: str\n        :param mean_in: Optional[Tuple[float]]\n        :param std_in: Optional[Tuple[float]]\n        :param phase_in: str\n        \"\"\"\n\n        self.df = df_in\n        self.root = data_folder_in\n        \n        self.mean = mean_in\n        self.std = std_in\n        self.phase = phase_in\n        self.transforms = get_transforms(phase_in = self.phase, mean_in = self.mean, std_in = self.std)\n        self.indices = self.df.index.tolist()\n\n    def __getitem__(self, idx: int):\n        \"\"\"\n        :param idx: int\n        :return: img, mask\n        \"\"\"\n        image_name, mask = make_mask(idx, self.df)\n        image_path = os.path.join(self.root,  image_name)\n        img = cv2.imread(image_path)\n\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image'] # 3x256x1600\n        if self.phase == \"test\":\n            return image_name, img\n        else:    \n            mask = augmented['mask'] # 256x1600x4\n            mask = mask.permute(2, 0, 1)\n\n            return img, mask\n\n    def __len__(self):\n        return len(self.indices)\n\n\ndef get_transforms(phase_in: str, mean_in: Optional[Tuple[float]], std_in: Optional[Tuple[float]]):\n    \"\"\"\n    Возвращает список аугументаций для датасета\n    :param phase_in: str\n    :param mean_in: Optional[Tuple[float]\n    :param std_in: Optional[Tuple[float]\n    :return: list_trfms\n    \"\"\"\n    list_transforms = []\n    if phase_in == \"train\":\n        list_transforms.extend(\n            [\n                HorizontalFlip(p=0.25), # only horizontal flip as of now\n                VerticalFlip(p=0.25), \n                RandomBrightnessContrast(p=0.25),  \n                ShiftScaleRotate(p=0.25), \n                GaussNoise(p=0.25), \n                ElasticTransform(p=0.25)\n            ]\n        )\n    list_transforms.extend(\n        [\n            Normalize(mean=mean_in, std=std_in),\n            ToTensorV2()\n        ]\n    )\n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\ndef batch_mean_std(df_in: pd.DataFrame, data_folder_in: str):\n    \"\"\"\n    На данный момент не используется, оставил на случай, вдруг решу отойти от использования стандартных\n\n    Возвращает mean std для всего датасета, дальше применятся будет на каждом батче\n    :param df_in: pd.DataFrame\n    :param data_folder_in: str\n    :return: images_mean, images_std\n    \"\"\"\n    # thanks to ronaldokun from jovian.ml\n    # https://jovian.ml/forum/t/assignment-4-in-class-data-science-competition/1564/268\n    mean_total = []\n    std_total = []\n    print('df len: {0}'.format(len(df)))\n    df_loc =  df_in['ImageId']\n    print(df.head())\n    \n    for i, filename in df_loc.items():\n        img = cv2.imread(os.path.join(data_folder_in, filename), cv2.COLOR_BGR2RGB)\n        img = img/255.0 # to [0,1]\n\n        mean_total.append(img.reshape(-1, 3).mean(0)) \n        std_total.append((img**2).reshape(-1, 3).mean(0))\n\n    # те самые mean std\n    images_mean =  np.array(mean_total).mean(0)\n    images_std =  np.sqrt(np.array(std_total).mean(0) - images_mean**2)\n    return images_mean, images_std\n    \n\ndef provider(\n    data_folder: str,\n    df_in: pd.DataFrame,\n    phase_in: str,\n    mean_in: Optional[Tuple[float, float, float]] = None,\n    std_in: Optional[Tuple[float, float, float]] = None,\n    batch_size: int =8,\n    num_workers: int =4,\n):\n    \"\"\"\n    Создает кастомный dataloader для обучения модели\n    :param data_folder: str\n    :param df_in: pd.DataFrame\n    :param phase_in: str\n    :param mean_in: Optional[Tuple[float]]\n    :param std_in: Optional[Tuple[float]]\n    :param batch_size: int\n    :param num_workers: int\n    :return: dataloader\n    \"\"\"\n\n    data_folder_loc = data_folder\n    df_loc = df_in\n    phase_loc = phase_in\n    mean_loc = mean_in\n    std_loc = std_in    \n\n    # для фаз \"train\" \"val\"\n    # делаем два сета, с рандомным разбиением\n    if phase_loc != \"test\":\n        train_df_loc, val_df_loc = train_test_split(df_loc, test_size=0.2, stratify=df_in[\"maskCount\"], random_state=42)\n\n        df_loc = train_df_loc if phase_loc == \"train\" else val_df_loc\n\n       \n    image_dataset = SteelDataset(df_in = df_loc, \n                                 data_folder_in = data_folder_loc, \n                                 mean_in = mean_loc, \n                                 std_in = std_loc, \n                                 phase_in = phase_loc\n                                ) # img, mask\n\n    dataloader = DataLoader(\n        image_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True\n    )\n\n    return dataloader\n\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    return device","metadata":{"_cell_guid":"76b17769-b3cf-4fc6-8534-b30c21564189","_uuid":"e32d7349-b2cf-4d8a-822f-4c5db4abf7e4","papermill":{"duration":0.145622,"end_time":"2021-01-12T13:34:22.390774","exception":false,"start_time":"2021-01-12T13:34:22.245152","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:43.283614Z","iopub.execute_input":"2022-03-10T08:48:43.283993Z","iopub.status.idle":"2022-03-10T08:48:43.329146Z","shell.execute_reply.started":"2022-03-10T08:48:43.283947Z","shell.execute_reply":"2022-03-10T08:48:43.328034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metric functions\nIoU, F, Dice метрические функции, логер.","metadata":{"_cell_guid":"84fc0dd1-946d-4711-98b5-d563ee3c9093","_uuid":"534f8e55-fc8c-49c1-a0bf-4bdfbdc5942f","papermill":{"duration":0.108099,"end_time":"2021-01-12T13:34:22.606644","exception":false,"start_time":"2021-01-12T13:34:22.498545","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Meter:\n    \"\"\"\n    Измеритель в модели за эпоху\n    F_scores\n    iou_scores\n    Dice_scores\n    накапливает между батчами и выдает в конце эпохи\n    \"\"\"\n    def __init__(self, phase: str, epoch: int, ):\n        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n        self.F_scores = []\n        self.iou_scores = []\n        self.Dice_scores = []\n\n    def update(self, targets: torch.Tensor, outputs: torch.Tensor):\n        \"\"\"\n        Считает и добавляет результаты батча в историю эпохи\n        targets: torch.tensor([0..1])\n        outputs: torch.tensor([-1..1])\n         \"\"\"\n        probs = torch.sigmoid(outputs) # torch.tensor([0..1])\n        \n        F, iou, Dice = compute_batch(probs, targets, self.base_threshold)\n        self.iou_scores.append(iou)\n        self.F_scores.append(F)\n        self.Dice_scores.append(Dice)\n\n    def get_metrics(self):\n        \"\"\"\n        Возвращает метрики накопленные в эпохе\n        :return:\n        \"\"\"\n        F = np.nanmean(self.F_scores)\n        iou = np.nanmean(self.iou_scores)\n        Dice = np.nanmean(self.Dice_scores)\n        return F, iou, Dice\n\ndef epoch_log(phase, epoch, lr, epoch_loss, meter):\n    \"\"\"Логер в принт метрик за итерацию фазы\"\"\"\n\n    F, iou, Dice  = meter.get_metrics()\n    print(\"\"\"Phase: {0:s}\n    Epoch: {1:d} | \\u2193 Lr: {2:.8} | \\u2193 BCE_loss: {3:.8} | \\u2191 F: {4:.4} | \\u2191 IoU: {5:.4} | \\u2191 Dice: {6:.4}\n    \"\"\".format(phase, epoch, lr, epoch_loss, F, iou, Dice))\n    return F, iou, Dice \n\n\ndef confusion_matrix_and_union(prediction: torch.Tensor, truth: torch.Tensor, threshold: int):\n    \"\"\"\n    Считает элементы confusion matrix и union для отдельно взятой моски и ее таргета\n    TP, FP, FN, TN, U \n    \"\"\"\n    assert prediction.shape == truth.shape # [4x256x1600]\n    \n    #flatten label and prediction tensors\n    prediction = prediction.view(-1) # [1638400]\n    truth = truth.view(-1) # [1638400]\n    \n    prob = (prediction >= threshold).int()\n    label = (truth).int()\n    not_prob = (1-prob)\n    not_label = (1-label)\n    \n\n    TP = (prob&label).sum().to(torch.float32)           # zero if Truth=0 or Prediction=0\n    FP = (prob&not_label).sum().to(torch.float32)       # zero if Truth=0 or Prediction=1\n    FN = (not_prob&label).sum().to(torch.float32)       # zero if Truth=1 or Prediction=0\n    TN = (not_prob&not_label).sum().to(torch.float32)   # if Truth=1 or Prediction=1\n    U = (prob|label).sum().to(torch.float32)            # zero if both are 0\n\n    return TP, FP, FN, TN, U \n\ndef compute_ious(TP: torch.Tensor, U: torch.Tensor):\n    \"\"\"Считает iou для одной ground truth mask и predicted mask\"\"\"\n    \n    iou = (TP + 1e-12) / (U + 1e-12)  # We smooth our devision to avoid 0/0\n    \n    return iou\n\ndef compute_F_score(TP: torch.Tensor, FP: torch.Tensor, FN: torch.Tensor, beta=1):\n    \"\"\"Считает F для одной ground truth mask и predicted mask\"\"\"\n    eps = 1e-12\n    precision = torch.mean(TP / (TP + FP + eps))\n    recall = torch.mean(TP / (TP + FN + eps))\n    \n    F = ((1 + beta**2) * precision * recall / (beta**2 * precision + recall + eps))\n    \n    return F\n\ndef compute_Dice(prediction: torch.Tensor, truth: torch.Tensor, TP: torch.Tensor, threshold: int, reduction='mean'):\n    \"\"\"Считает Dice для одной ground truth mask и predicted mask\"\"\"\n\n    assert prediction.shape == truth.shape # [4x256x1600]\n    \n    #flatten label and prediction tensors\n    prediction = prediction.view(-1) # [1638400]\n    truth = truth.view(-1) # [1638400]\n    \n    prob = (prediction >= threshold).float()\n    label = (truth).float()\n    \n    intersection = TP.sum()\n    prob_sum = prob.sum()\n    label_sum = label.sum()\n    \n    Dice = (2. * intersection + 1e-12) / (prob_sum + label_sum + 1e-12)\n\n    return Dice\n\n\ndef compute_batch(prediction: torch.Tensor, truth: torch.Tensor, threshold: int):\n    \"\"\"Считает средние F IoU Dice для батча ground truth mask и predicted mask\"\"\"\n    Fs = []\n    ious = []\n    Dices = []\n\n    # batch shape [4x4x256x1600]\n    for preds, labels in zip(prediction, truth):\n        # [4x256x1600]\n        # Здесь можно увидеть персональную метриу для каждого изображения\n        \n        TP, FP, FN, TN, U = confusion_matrix_and_union(preds, labels, threshold)\n\n        Fs.append(np.array(compute_F_score(TP, FP, FN, beta=1)).mean()) # [4]\n        ious.append(np.array(compute_ious(TP, U)).mean()) # [4]\n        Dices.append(np.array(compute_Dice(preds, labels, TP, threshold)).mean()) # [4]\n\n    F = np.array(Fs).mean()\n    iou = np.array(ious).mean()\n    Dice = np.array(Dices).mean()\n\n    return F, iou, Dice\n","metadata":{"_cell_guid":"b0f894a4-a426-4fb1-b11d-de8c47733c5d","_uuid":"c46faf86-ef5a-448e-a8ce-2f95f8b16154","papermill":{"duration":0.144446,"end_time":"2021-01-12T13:34:22.8595","exception":false,"start_time":"2021-01-12T13:34:22.715054","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:43.331227Z","iopub.execute_input":"2022-03-10T08:48:43.331988Z","iopub.status.idle":"2022-03-10T08:48:43.378308Z","shell.execute_reply.started":"2022-03-10T08:48:43.33194Z","shell.execute_reply":"2022-03-10T08:48:43.377164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model initialization","metadata":{"_cell_guid":"bd9481b2-a584-4d2c-a6d9-9239a55c5124","_uuid":"29d90272-5d66-4e99-bad6-8725ae5bfe86","papermill":{"duration":0.11094,"end_time":"2021-01-12T13:34:23.078871","exception":false,"start_time":"2021-01-12T13:34:22.967931","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model = smp.Unet(\"resnet50\", encoder_weights=\"imagenet\", classes=4, activation=None)\n#print(type(model))","metadata":{"_cell_guid":"88df57b1-e388-4af8-9921-fcb538e39028","_uuid":"53ee5ddc-5cdf-412f-89c4-c3828c0575d8","papermill":{"duration":1.899996,"end_time":"2021-01-12T13:34:25.088132","exception":false,"start_time":"2021-01-12T13:34:23.188136","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:43.380025Z","iopub.execute_input":"2022-03-10T08:48:43.380605Z","iopub.status.idle":"2022-03-10T08:48:50.526109Z","shell.execute_reply.started":"2022-03-10T08:48:43.380568Z","shell.execute_reply":"2022-03-10T08:48:50.525189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model # uncomment to take a deeper look","metadata":{"_cell_guid":"728c1788-ff70-45f5-9013-9873bddb3ab3","_uuid":"583c0580-9be8-44e6-b035-0ecf9ab32268","papermill":{"duration":0.129365,"end_time":"2021-01-12T13:34:25.32749","exception":false,"start_time":"2021-01-12T13:34:25.198125","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:50.528965Z","iopub.execute_input":"2022-03-10T08:48:50.529358Z","iopub.status.idle":"2022-03-10T08:48:50.533685Z","shell.execute_reply.started":"2022-03-10T08:48:50.529306Z","shell.execute_reply":"2022-03-10T08:48:50.532509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer(object):\n    \"\"\"Класс для обучения и валидации модели\"\"\"\n    def __init__(self, model_in, df_in: pd.DataFrame, image_root: str, epochs_in: int = 0,weights_root_in: str = TRAINED_WEIGHTS):\n        \"\"\"\n        :param epochs_in:\n        :param model_in:\n        :param df_in:\n        \"\"\"\n        self.df_local = df_in\n        self.num_workers = 2\n        self.batch_size = {\"train\": 4, \"val\": 4, \"test\": 16}\n        self.train_phases = [\"train\", \"val\"]\n        self.image_root = image_root\n        self.epochs_in = epochs_in\n\n        self.device = get_default_device()\n        print (f'Traininig on device: {self.device}')\n\n        self.weights = weights_root_in\n        self.net = model_in\n\n        self.dataloader = {\n            phase: provider(\n                data_folder=image_root,\n                df_in=self.df_local,\n                phase_in=phase,\n                mean_in=(0.485, 0.456, 0.406),\n                std_in=(0.229, 0.224, 0.225),\n                batch_size=self.batch_size[phase],\n                num_workers=self.num_workers\n            )\n            for phase in self.train_phases\n        }\n\n    def forward(self, images, targets_in=None):\n        \"\"\"Отправляет в модель маску и картинку, если маски нет, отправляет нули\"\"\"\n        if targets_in is None:\n            targets_shape = list(images.shape)  # [4,3,256,1600]\n            targets_shape[1] = 4 # [4,4,256,1600]\n            targets = torch.zeros(*targets_shape)\n        else:\n            targets = targets_in\n\n        images = images.to(self.device)\n        masks = targets.to(self.device)\n        outputs = self.net(images)\n\n        if targets_in is None:\n            loss = None\n        else:\n            loss = self.criterion(outputs, masks)\n        return loss, outputs\n\n\n    def iterate(self, epoch: int, phase: str):\n        \"\"\"\n        Итератор по бачам внутри одной эпохи\n        :param epoch:\n        :param phase:\n        :return:\n        \"\"\"\n        meter = Meter(phase, epoch)\n        start = time.strftime(\"%H:%M:%S\")\n        print(f\"Starting epoch: {epoch} | phase: {phase} | started at: {start}\")\n        self.net.train(phase == \"train\")\n        dataloader = self.dataloader[phase]\n        running_loss = 0.0\n        total_batches = len(dataloader)\n        tk0 = tqdm(dataloader, total=total_batches) # progress bar\n\n        self.optimizer.zero_grad()\n        for itr, batch in enumerate(tk0): # replace `dataloader` with `tk0` for tqdm\n            images, targets = batch\n\n            loss, outputs = self.forward(images, targets)\n            loss = loss / self.accumulation_steps\n            if phase == \"train\":\n                loss.backward()\n                if (itr + 1 ) % self.accumulation_steps == 0:\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()  # обнуляем градиент для каждого батча\n            running_loss += loss.item()\n            outputs = outputs.detach().cpu()\n            meter.update(targets, outputs)\n            tk0.set_postfix(BCE_loss=(running_loss / ((itr + 1)))) #\n            \n        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n\n\n        iou, F, Dice = epoch_log(phase, epoch, self.last_lr, epoch_loss, meter)\n        if phase == 'train':\n            self.lr_rates.append(self.last_lr)\n\n        self.losses[phase].append(epoch_loss)\n        self.iou_scores[phase].append(iou)\n        self.F_scores[phase].append(F)\n        self.Dice_scores[phase].append(Dice)\n        torch.cuda.empty_cache()\n        return epoch_loss\n\n    def start(self):\n        \"\"\"\n        Метод запуска обучения модели\n        Пока без входных параметров, но в случае необходимости быстро переделывается.\n\n        optimizer = Adam\n        criterion = BCEWithLogitsLoss\n        scheduler_expr = ExponentialLR  общий шедулер снижения lr\n        scheduler_r_on_plateau = ReduceLROnPlateau  шедулер в случае обнаружения минимума\n        early stopp = 5\n\n        каждый батч имеет аугументацию\n        сохраняет лучшую модель каждую эпоху\n        Сохраняет историю обучения в конце обучения\n        :return:\n        \"\"\"\n        # параметры обучения\n        self.lr = 5e-3\n        self.gamma = 0.75  # lr_scheduler lr decay\n        self.last_lr = float(self.lr)\n        self.num_epochs = self.epochs_in # 20\n        self.best_loss = float(\"inf\")\n\n        self.accumulation_steps = 32 // self.batch_size['train']\n        self.criterion = nn.BCEWithLogitsLoss() #\n        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr) #\n\n        # постепенно снижаем lr из эпохи в эпоху\n        self.scheduler_expr = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=self.gamma) #\n\n        # находим минимум lr в случае плато...\n        self.scheduler_r_on_plateau = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=2, factor=0.1, verbose=True)\n\n        self.best_ago_max = 5  # Early stop epochs max\n        self.best_ago = 0 # Early stop epochs cnt\n        self.net = self.net.to(self.device)\n        cudnn.benchmark = True\n\n        self.losses = {phase: [] for phase in self.train_phases}\n        self.iou_scores = {phase: [] for phase in self.train_phases}\n        self.F_scores = {phase: [] for phase in self.train_phases}\n        self.Dice_scores = {phase: [] for phase in self.train_phases}\n        self.lr_rates = []\n        for epoch in range(self.num_epochs):\n            self.iterate(epoch, \"train\")\n            state = {\n                \"epoch\": epoch,\n                \"best_loss\": self.best_loss,\n                \"state_dict\": self.net.state_dict(),\n                \"optimizer\": self.optimizer.state_dict(),\n            }\n            with torch.no_grad():\n                # torch.no_grad() используется вместо self.net.eval()\n                val_loss = self.iterate(epoch, \"val\")\n                self.scheduler_r_on_plateau.step(val_loss)\n                self.scheduler_expr.step()\n                self.last_lr = min(float(self.scheduler_r_on_plateau.optimizer.param_groups[0]['lr']), float(self.scheduler_expr.get_last_lr()[0]))\n\n            if val_loss < self.best_loss:\n                print(\"******** New optimal found, saving state ********\")\n                state[\"best_loss\"] = self.best_loss = val_loss\n                torch.save(state, f'{self.weights}{epoch}__{self.best_loss}.pth')\n                self.best_ago = 0\n            else:\n                self.best_ago += 1\n\n            if self.best_ago == self.best_ago_max:\n                print(f'Early stopping at epoch {epoch}')\n                torch.save(state, f'{self.weights}{epoch}_last__{self.best_loss}.pth')\n                break\n\n        model_results = {\n            'losses' : self.losses,\n            'iou_scores' : self.iou_scores,\n            'f_scores' : self.F_scores,\n            'dice_scores' : self.Dice_scores,\n            'lr_rates' : self.lr_rates\n        }\n\n        with open(self.weights, 'wb') as fp:\n            pickle.dump(model_results, fp)\n\n","metadata":{"_cell_guid":"d325a192-1674-494b-804c-936774ee4cf2","_uuid":"b7e7de64-0f40-4b41-af2e-2b2cb615ac4d","papermill":{"duration":0.14386,"end_time":"2021-01-12T13:34:25.580152","exception":false,"start_time":"2021-01-12T13:34:25.436292","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:50.535791Z","iopub.execute_input":"2022-03-10T08:48:50.53616Z","iopub.status.idle":"2022-03-10T08:48:50.579349Z","shell.execute_reply.started":"2022-03-10T08:48:50.536122Z","shell.execute_reply":"2022-03-10T08:48:50.578533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Tester(Trainer):\n    def __init__(self, model_in, df_in: pd.DataFrame, image_root: str, epochs_in: int = 0,\n                 weights_root_in: str = TRAINED_WEIGHTS):\n        \"\"\"\n        Класс для тестирования модели, на основе Trainer класса\n        :param model_in:\n        :param df_in:\n        :param image_root:\n        :param epochs_in:\n        :param weights_root_in:\n        \"\"\"\n\n        self.df_local = df_in\n        self.num_workers = 2\n        self.batch_size = {\"train\": 4, \"val\": 4, \"test\": 16}\n        self.train_phases = [\"train\", \"val\"]\n        self.image_root = image_root\n        self.epochs_in = epochs_in\n\n        self.device = get_default_device()\n        print (f'Traininig on device: {self.device}')\n\n        self.weigths_root = weights_root_in\n        self.net = model_in\n\n        self.dataloader = provider(\n                data_folder=self.image_root,\n                df_in=df_in,\n                phase_in = 'test',\n                mean_in=(0.485, 0.456, 0.406),\n                std_in=(0.229, 0.224, 0.225),\n                batch_size=self.batch_size['test'],\n                num_workers=self.num_workers\n            )\n\n    def process(self, probability, threshold, min_size):\n        \"\"\"\n        Постобработка для каждой предсказанной mask, если площадь пятна ниже  min_size, то маска будет пустой\n        :param probability:\n        :param threshold:\n        :param min_size:\n        :return:\n        \"\"\"\n        mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1] # (256, 1600)\n        num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n        predictions = np.zeros((256, 1600), np.float32)\n\n        for c in range(1, num_component):\n            p = (component == c)\n            if p.sum() > min_size:\n                predictions[p] = 1 # (4, 256, 1600)\n        return predictions\n\n    def rle_encode(self, fnames, batch_preds):\n        for fname, pred_mask in zip(fnames, batch_preds):\n            for cls, pred_mask in enumerate(pred_mask):\n                pred_mask = self.process(pred_mask, self.best_threshold, self.min_size)  # (4, 256, 1600)\n                rle = mask2rle(pred_mask)\n                if rle != '':\n                    cls = index2class_id(cls)\n                    pred_loc = [fname, cls, rle]\n                    self.predicted_pixels.append(pred_loc)\n\n    def iterate(self, epoch: int, phase: str):\n        \"\"\"\n        Итератор по единственной эпохе\n        :param epoch:\n        :param phase:\n        :return:\n        \"\"\"\n        start = time.strftime(\"%H:%M:%S\")\n        print(f\"Starting epoch: {epoch} | phase: {phase} | started at: {start}\")\n        batch_size = self.batch_size[phase]\n        self.net.train(phase == \"test\")\n        dataloader = self.dataloader\n        total_batches = len(dataloader)\n        tk0 = tqdm(dataloader, total=total_batches) # progress bar\n\n        for itr, batch in enumerate(tk0): # replace `dataloader` with `tk0` for tqdm\n            fnames, images = batch\n\n            _, outputs = self.forward(images)\n            outputs = torch.sigmoid(outputs)\n            # пропустили через последний активатор-сигмойду, в итоге приведем к [0, 1]\n\n            outputs = outputs.detach().cpu().numpy()\n\n            self.rle_encode(fnames, outputs)\n\n        torch.cuda.empty_cache()\n\n\n    def start(self):\n        \"\"\"\n        Метод запуска предсказания модели\n        Пока без входных параметров, но в случае необходимости быстро переделывается.\n\n        каждый батч только нормализуется\n        площадь дефектов ограничивается min_size = 100 пикселей\n        преобразование масок в RLE для submission\n        :return:\n        \"\"\"\n        self.state = torch.load(self.weigths_root)\n        self.net.to(self.device)  #\n\n        self.net.load_state_dict(self.state[\"state_dict\"])\n\n        self.min_size = 50 # 3500 # min total of pixels on the mask\n\n        self.best_threshold = 0.25 # 0.5\n        self.predicted_pixels = [] # np.zeros((4, 256, 1600), np.float32)\n\n\n        with torch.no_grad():\n            self.iterate(0, \"test\")\n\n        # save predictions to submission.csv\n        self.df = pd.DataFrame(self.predicted_pixels, columns=['ImageId', 'ClassId', 'EncodedPixels'])\n        self.df.to_csv(SUBMISSION_FILE, index=False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T08:48:50.581047Z","iopub.execute_input":"2022-03-10T08:48:50.581522Z","iopub.status.idle":"2022-03-10T08:48:50.608518Z","shell.execute_reply.started":"2022-03-10T08:48:50.581484Z","shell.execute_reply":"2022-03-10T08:48:50.607511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_trainer = Trainer(epochs_in = 100, model_in = model, df_in = df, image_root = TRAIN_IMG_DIR,\n#                       weights_root_in = PRE_TRAINED_WEIGHTS)\n# model_trainer.start()  # uncomment to start training\n#\n# del model_trainer\n# torch.cuda.empty_cache()","metadata":{"papermill":{"duration":5.698696,"end_time":"2021-01-12T13:34:31.634934","exception":false,"start_time":"2021-01-12T13:34:25.936238","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:50.611706Z","iopub.execute_input":"2022-03-10T08:48:50.612009Z","iopub.status.idle":"2022-03-10T08:48:50.621079Z","shell.execute_reply.started":"2022-03-10T08:48:50.611981Z","shell.execute_reply":"2022-03-10T08:48:50.620151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Графики обучения","metadata":{"papermill":{"duration":0.215168,"end_time":"2021-01-12T13:34:32.054058","exception":false,"start_time":"2021-01-12T13:34:31.83889","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with open(TRAINED_METRICS, 'rb') as fp:\n    metrics_score = pickle.load(fp)\n\ndef plot_lr(scores, name):\n    \"\"\"\n    Рисует график lr\n    \"\"\"\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores)), scores, label=f'train {name}  log')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name} log')\n    plt.xticks(range(len(scores)))\n    plt.yscale(\"log\")\n    plt.legend()\n    plt.show()\n\n\ndef plot_scores(scores, name):\n    \"\"\"\n    Рисует графики метрик\n    \"\"\"\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name} log')\n    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name} log')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name} log')\n    plt.xticks(range(len(scores[\"train\"])))\n    plt.yscale(\"log\")\n    plt.legend()\n    plt.show()\n\nplot_lr(metrics_score['lr_rates'], \"Learning rate\")\nplot_scores(metrics_score['losses'], \"BCE loss\")\nplot_scores(metrics_score['iou_scores'], \"IoU score\")\nplot_scores(metrics_score['f_scores'], \"F score\")\nplot_scores(metrics_score['dice_scores'], \"Dice score\")","metadata":{"_cell_guid":"ea3006e8-cb51-4c15-8ae0-8493b93d84ec","_uuid":"6ac8996e-8c88-4f5c-b0cc-1a61e9308f27","papermill":{"duration":0.740907,"end_time":"2021-01-12T13:34:33.039176","exception":false,"start_time":"2021-01-12T13:34:32.298269","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:50.622355Z","iopub.execute_input":"2022-03-10T08:48:50.622624Z","iopub.status.idle":"2022-03-10T08:48:52.484591Z","shell.execute_reply.started":"2022-03-10T08:48:50.622588Z","shell.execute_reply":"2022-03-10T08:48:52.483434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**На 14 Эпохах переобучения замечено небыло**","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"epoch = metrics_score['losses']['val'].index(min(metrics_score['losses']['val']))\n\ndef find_best_score(metric_scores):\n    \"\"\"Из сохраненной истории обучения достает лучший результат\"\"\"\n    epoch = metrics_score['losses']['val'].index(min(metrics_score['losses']['val']))\n    bce_loss = metrics_score['losses']['val'][14]\n    iou_scores = metrics_score['iou_scores']['val'][14]\n    f_scores = metrics_score['f_scores']['val'][14]\n    dice_scores = metrics_score['dice_scores']['val'][14]\n\n    print(\"\"\"best scores\n    epoch: {0}\n    bce_loss: {1}\n    iou_scores: {2}\n    f_scores: {3}\n    dice_scores: {4}\"\"\".format(epoch, bce_loss, iou_scores, f_scores, dice_scores))\n\nfind_best_score(metrics_score)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T08:48:52.486434Z","iopub.execute_input":"2022-03-10T08:48:52.487012Z","iopub.status.idle":"2022-03-10T08:48:52.501422Z","shell.execute_reply.started":"2022-03-10T08:48:52.486969Z","shell.execute_reply":"2022-03-10T08:48:52.500396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test prediction and submission\n","metadata":{"_cell_guid":"d4139321-34b2-4cbb-ac58-731ba0e285ee","_uuid":"7cdcf243-77b9-4f4e-8576-c8eb3e47f7ed","papermill":{"duration":0.111825,"end_time":"2021-01-12T13:34:33.264228","exception":false,"start_time":"2021-01-12T13:34:33.152403","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Тестируем на трейн сете обученную модель...**","metadata":{"papermill":{"duration":0.111308,"end_time":"2021-01-12T13:34:33.734928","exception":false,"start_time":"2021-01-12T13:34:33.62362","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Делаем датасет подобный sample_submission.csv\npredicted_train_df = df.iloc[:, :1].drop_duplicates()\npredicted_train_df['EncodedPixels'] =  '1 409600'\npredicted_train_df['ClassId'] =  0\npredicted_train_df.head()","metadata":{"papermill":{"duration":0.133037,"end_time":"2021-01-12T13:34:33.98304","exception":false,"start_time":"2021-01-12T13:34:33.850003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:57.342569Z","iopub.execute_input":"2022-03-10T08:48:57.34291Z","iopub.status.idle":"2022-03-10T08:48:57.361517Z","shell.execute_reply.started":"2022-03-10T08:48:57.342876Z","shell.execute_reply":"2022-03-10T08:48:57.360635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRE_TRAINED_WEIGHTS = PRE_TRAINED_WEIGHTS+'14_0.021031175681085493.pth'","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T08:48:57.862361Z","iopub.execute_input":"2022-03-10T08:48:57.862707Z","iopub.status.idle":"2022-03-10T08:48:57.866901Z","shell.execute_reply.started":"2022-03-10T08:48:57.862675Z","shell.execute_reply":"2022-03-10T08:48:57.865758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tester = Tester(model_in = model,\n                      df_in = predicted_train_df,\n                      image_root = TRAIN_IMG_DIR,\n                      weights_root_in = PRE_TRAINED_WEIGHTS)","metadata":{"papermill":{"duration":310.106172,"end_time":"2021-01-12T13:39:44.201915","exception":false,"start_time":"2021-01-12T13:34:34.095743","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:48:58.75041Z","iopub.execute_input":"2022-03-10T08:48:58.750752Z","iopub.status.idle":"2022-03-10T08:48:58.776065Z","shell.execute_reply.started":"2022-03-10T08:48:58.750718Z","shell.execute_reply":"2022-03-10T08:48:58.774685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tester.start()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T08:48:59.142396Z","iopub.execute_input":"2022-03-10T08:48:59.14274Z","iopub.status.idle":"2022-03-10T08:54:46.513518Z","shell.execute_reply.started":"2022-03-10T08:48:59.142709Z","shell.execute_reply":"2022-03-10T08:54:46.512645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_train_df = pd.read_csv(SUBMISSION_FILE)\npredicted_train_df = survey(predicted_train_df)\npredicted_train_df.head()","metadata":{"papermill":{"duration":17.818553,"end_time":"2021-01-12T13:40:02.135175","exception":false,"start_time":"2021-01-12T13:39:44.316622","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:54:46.515576Z","iopub.execute_input":"2022-03-10T08:54:46.515848Z","iopub.status.idle":"2022-03-10T08:55:03.50617Z","shell.execute_reply.started":"2022-03-10T08:54:46.51582Z","shell.execute_reply":"2022-03-10T08:55:03.505311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_class_total, val_class_counter, val_mask_total, val_mask_counter = get_distribution(predicted_train_df)\nprint(\"\"\"Total cnt defected: {0},\n1 class defect: {1},\n2 class defect: {2},\n3 class defect: {3},\n4 class defect: {4}\n\"\"\".format(val_class_total, *val_class_counter))\n\nprint(\"\"\"Total cnt images: {0},\nwith one defect:    {1},\nwith two defects:   {2},\nwith three defects: {3},\nwith four defects:  {4}\n\"\"\".format(val_mask_total, *val_mask_counter))","metadata":{"papermill":{"duration":0.15436,"end_time":"2021-01-12T13:40:02.40347","exception":false,"start_time":"2021-01-12T13:40:02.24911","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T08:55:03.507521Z","iopub.execute_input":"2022-03-10T08:55:03.507863Z","iopub.status.idle":"2022-03-10T08:55:03.542467Z","shell.execute_reply.started":"2022-03-10T08:55:03.507825Z","shell.execute_reply":"2022-03-10T08:55:03.541574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_cls_distrib = [[class_total, *class_counter],\n                   [val_class_total, *val_class_counter]\n                   ]\n\ncompare_defects_distrib = [[mask_total, *mask_counter],\n                   [val_mask_total, *val_mask_counter]\n                   ]\n\nlabels = ['Total cnt', '1 class', '2 class', '3 class', '4 class']\nx = np.arange(len(labels))\nwidth = 0.35\n\nfig, ax = plt.subplots(2, 1, figsize=(15,7))\n\np1 = ax[0].bar(x - width/2, compare_cls_distrib[0], 0.35, label='Ground Truth')\np2 = ax[0].bar(x + width/2, compare_cls_distrib[1], 0.35, label='Predicted')\n\nax[0].set_title('Class distribution over')\nax[0].set_ylabel('cnt')\nax[0].set_xticklabels(['Total cnt']+labels)\nax[0].legend()\n\nt1 = ax[1].bar(x - width/2, compare_defects_distrib[0], 0.35, label='Ground Truth')\nt2 = ax[1].bar(x + width/2, compare_defects_distrib[1], 0.35, label='Predicted')\n\nax[1].set_title('Class count per img distribution')\nax[1].set_ylabel('cnt')\nax[1].set_xticklabels(['']+labels)\nax[1].legend()\n\n\nplt.show()\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T09:14:11.782965Z","iopub.execute_input":"2022-03-10T09:14:11.783286Z","iopub.status.idle":"2022-03-10T09:14:12.075787Z","shell.execute_reply.started":"2022-03-10T09:14:11.783253Z","shell.execute_reply":"2022-03-10T09:14:12.074899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Распределение предсказанных классов и фактических, колличество классов на изображение примерно одинаковое.**\n","metadata":{"papermill":{"duration":0.113434,"end_time":"2021-01-12T13:40:02.631291","exception":false,"start_time":"2021-01-12T13:40:02.517857","status":"completed"},"tags":[]}},{"cell_type":"code","source":"show_images(df[:], TRAIN_IMG_DIR, predicted_train_df)","metadata":{"papermill":{"duration":5.761327,"end_time":"2021-01-12T13:40:08.506124","exception":false,"start_time":"2021-01-12T13:40:02.744797","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T09:06:58.343209Z","iopub.execute_input":"2022-03-10T09:06:58.3436Z","iopub.status.idle":"2022-03-10T09:07:05.408539Z","shell.execute_reply.started":"2022-03-10T09:06:58.343567Z","shell.execute_reply":"2022-03-10T09:07:05.407391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Как мы видим, предсказание часто близко к ground truth. Не идеально... Как и предпологалось 2 и 3 классы очень похожи для модели. Возможно есть какойто трюк, чтобы их лучше различать, либо объеденить их в один класс.**\n\n**Обучали 14 эпох, но это не предел имея больше вычислительных мощностей.**","metadata":{"papermill":{"duration":0.175061,"end_time":"2021-01-12T13:40:08.857837","exception":false,"start_time":"2021-01-12T13:40:08.682776","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Предсказываем на тестовом датасете**","metadata":{"papermill":{"duration":0.17024,"end_time":"2021-01-12T13:40:09.198482","exception":false,"start_time":"2021-01-12T13:40:09.028242","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Готовим submission датасет\nmodel_tester = Tester(model_in = model, df_in = test_df, image_root = TEST_IMG_DIR, weights_root_in = PRE_TRAINED_WEIGHTS)\nmodel_tester.start()","metadata":{"papermill":{"duration":229.262806,"end_time":"2021-01-12T13:43:58.639529","exception":false,"start_time":"2021-01-12T13:40:09.376723","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T09:07:05.410745Z","iopub.execute_input":"2022-03-10T09:07:05.411303Z","iopub.status.idle":"2022-03-10T09:11:58.917118Z","shell.execute_reply.started":"2022-03-10T09:07:05.411259Z","shell.execute_reply":"2022-03-10T09:11:58.915914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_df = pd.read_csv(SUBMISSION_FILE)\npredicted_df = survey(predicted_df)\npredicted_df.head()","metadata":{"papermill":{"duration":12.220898,"end_time":"2021-01-12T13:44:11.031579","exception":false,"start_time":"2021-01-12T13:43:58.810681","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T09:11:58.922852Z","iopub.execute_input":"2022-03-10T09:11:58.925444Z","iopub.status.idle":"2022-03-10T09:12:13.043333Z","shell.execute_reply.started":"2022-03-10T09:11:58.925401Z","shell.execute_reply":"2022-03-10T09:12:13.042435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_class_total, test_class_counter, test_mask_total, test_mask_counter = get_distribution(predicted_df)\n\nprint(\"\"\"Total cnt defected: {0},\n1 class defect: {1},\n2 class defect: {2},\n3 class defect: {3},\n4 class defect: {4}\n\"\"\".format(test_class_total, *test_class_counter))\n\nprint(\"\"\"Total cnt images: {0},\nwith one defect:    {1},\nwith two defects:   {2},\nwith three defects: {3},\nwith four defects:  {4}\n\"\"\".format(test_mask_total, *test_mask_counter))","metadata":{"papermill":{"duration":0.211712,"end_time":"2021-01-12T13:44:11.418527","exception":false,"start_time":"2021-01-12T13:44:11.206815","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-10T09:12:13.044728Z","iopub.execute_input":"2022-03-10T09:12:13.045099Z","iopub.status.idle":"2022-03-10T09:12:13.076021Z","shell.execute_reply.started":"2022-03-10T09:12:13.045053Z","shell.execute_reply":"2022-03-10T09:12:13.075131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_cls_distrib = [[class_total, *class_counter],\n                   [test_class_total, *test_class_counter]\n                   ]\n\ncompare_defects_distrib = [[mask_total, *mask_counter],\n                   [test_mask_total, *test_mask_counter]\n                   ]\nlabels = ['Total cnt', '1 class', '2 class', '3 class', '4 class']\nx = np.arange(len(labels))\nwidth = 0.35\n\nfig, ax = plt.subplots(2, 1, figsize=(15,7))\n\np1 = ax[0].bar(x - width/2, compare_cls_distrib[0], 0.35, label='Train dataset')\np2 = ax[0].bar(x + width/2, compare_cls_distrib[1], 0.35, label='Test dataset')\n\nax[0].set_title('Class distribution')\nax[0].set_ylabel('cnt')\nax[0].set_xticklabels(['']+labels)\nax[0].set_xticklabels(['Total cnt']+labels)\nax[0].legend()\n\nt1 = ax[1].bar(x - width/2, compare_defects_distrib[0], 0.35, label='Train dataset')\nt2 = ax[1].bar(x + width/2, compare_defects_distrib[1], 0.35, label='Test dataset')\n\nax[1].set_title('Class count per img distribution')\nax[1].set_ylabel('cnt')\nax[1].set_xticklabels(['']+labels)\nax[1].legend()\n\n\nplt.show()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-10T09:15:48.901886Z","iopub.execute_input":"2022-03-10T09:15:48.9022Z","iopub.status.idle":"2022-03-10T09:15:49.212964Z","shell.execute_reply.started":"2022-03-10T09:15:48.90217Z","shell.execute_reply":"2022-03-10T09:15:49.212247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(predicted_df, TEST_IMG_DIR)","metadata":{"papermill":{"duration":5.136778,"end_time":"2021-01-12T13:44:16.728516","exception":false,"start_time":"2021-01-12T13:44:11.591738","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-03-10T09:13:38.462222Z","iopub.execute_input":"2022-03-10T09:13:38.462602Z","iopub.status.idle":"2022-03-10T09:13:43.678971Z","shell.execute_reply.started":"2022-03-10T09:13:38.462568Z","shell.execute_reply":"2022-03-10T09:13:43.676464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}