{"cells":[{"metadata":{"id":"DdNWYqk0wp0t","colab_type":"code","outputId":"4f95fe0d-2e7f-4614-f40d-cd1aa80e047d","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, sys\nimport shutil\nfrom distutils.dir_util import copy_tree\nfrom shutil import unpack_archive\nfrom subprocess import check_output\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Output Folder. Copy Input Folder to Output Folder.\n# We will be using directory '../outputs' for data manipulation and analysis.\n\nshutil.os.mkdir(\"../outputs/\")\nfromDirectory = '../input/severstal-steel-defect-detection/'\ntoDirectory = '../outputs'\ncopy_tree(fromDirectory, toDirectory)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify the copy has been done successfully.\n\nfileList = os.listdir('../outputs')\nfor f in fileList:\n    print(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../outputs/train.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"w1p4jamdyrmM","colab_type":"code","outputId":"ce0aca74-f6a3-453b-c1e3-f7e46f945329","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"# List if imageId in the Train Folder which have Defects\nimageId = pd.DataFrame(train_data['ImageId'])\nimageId.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imageId.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyze the train_data by ClassId\ntrain_data[\"ClassId\"].value_counts(ascending=True, dropna = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize defect classes on a barplot\n\ndefect_visual = train_data[\"ClassId\"].value_counts()\nplt.figure(figsize=(7,4))\nsns.barplot(defect_visual.index, defect_visual.values, alpha = 0.8)\nplt.title(\"Number of Steel Defect in Train Dataset\")\nplt.xlabel(\"Defect Class\")\nplt.ylabel(\"Defect Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_path = Path(\"../outputs/train_images\")\nimages = [f for f in os.listdir(images_path)]\n\n# No. of Images in Training Folder\nlen(images)","execution_count":null,"outputs":[]},{"metadata":{"id":"cTc763b5UYjQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Create Validation Set from Training Set\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(images, train_size=0.8)","execution_count":null,"outputs":[]},{"metadata":{"id":"SPVUIQ7wV5Q8","colab_type":"code","outputId":"569aa958-735e-4c1b-b66b-54c641b150ae","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"# No. of Images Used for Training\nlen(train)","execution_count":null,"outputs":[]},{"metadata":{"id":"TvIppgsQV-Kb","colab_type":"code","outputId":"ea22f81f-b2b4-409e-96c8-4970cc4f4dc0","colab":{"base_uri":"https://localhost:8080/","height":119},"trusted":true},"cell_type":"code","source":"# Create Validation Folder\n\nval_folder = shutil.os.mkdir('../outputs/val_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confirm that val_folder has been created.\nfileList = os.listdir('../outputs')\nfor f in fileList:\n    print(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_folder = Path(\"../outputs/val_images\")\ntrain_folder = Path(\"../outputs/train_images\")","execution_count":null,"outputs":[]},{"metadata":{"id":"QgIe_oamV-GG","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Move Validation Images to Validation Folder\nimport shutil\n\nfor i in images:\n  if (i not in train):\n    old_path = \"../outputs/train_images/\" + i\n    new_path = '../outputs/val_images/' + i\n    shutil.move(old_path, new_path)","execution_count":null,"outputs":[]},{"metadata":{"id":"9rY2j8_l6VY4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Create Folders to Seperate Images With and Without Defects\nshutil.os.mkdir(\"../outputs/train_images/y\")\nshutil.os.mkdir(\"../outputs/train_images/n\")\nshutil.os.mkdir(\"../outputs/val_images/y\")\nshutil.os.mkdir(\"../outputs/val_images/n\")","execution_count":null,"outputs":[]},{"metadata":{"id":"yVcLtwHY8jkh","colab_type":"code","outputId":"bfe1e99e-b65b-4e5e-cd78-9d7ae7490cb6","colab":{"base_uri":"https://localhost:8080/","height":51},"trusted":true},"cell_type":"code","source":"# Extract imageId with Defects into an Array\nfor index, row in imageId.iteritems():\n  values = row.values\n\nvalues","execution_count":null,"outputs":[]},{"metadata":{"id":"2nX_O-bcyr6K","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Categorize Images in Training Folder\nfor i in train:\n  old_path = '../outputs/train_images/' + i\n  if (i in values):\n    new_path = '../outputs/train_images/y/' + i\n  else: \n    new_path = '../outputs/train_images/n/' + i\n  shutil.move(old_path, new_path)","execution_count":null,"outputs":[]},{"metadata":{"id":"te9sgbq_XSTN","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Categorize Images in Validation Folder\nfor i in val:\n  old_path = '../outputs/val_images/' + i\n  if (i in values):\n    new_path = '../outputs/val_images/y/' + i\n  else: \n    new_path = '../outputs/val_images/n/' + i\n  shutil.move(old_path, new_path)","execution_count":null,"outputs":[]},{"metadata":{"id":"z2eC38VwXfat","colab_type":"code","outputId":"fb21271d-3fa3-4d66-f35b-24ee372af7be","colab":{"base_uri":"https://localhost:8080/","height":85},"trusted":true},"cell_type":"code","source":"# List Folders and Number of Files (Validation)\nprint(\"Directory, Number of Files\")\nfor root, subdirs, files in os.walk(val_folder):\n    print(root, len(files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List Folders and Number of Files (Train)\nprint(\"Directory, Number of Files\")\nfor root, subdirs, files in os.walk(train_folder):\n    print(root, len(files))","execution_count":null,"outputs":[]},{"metadata":{"id":"p3Bu-MT-i8wA","colab_type":"code","outputId":"618f3b86-495b-4e68-8d4a-d65cf58c28d5","colab":{"base_uri":"https://localhost:8080/","height":80},"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\n\ndef recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"id":"SJM-rORIjI6e","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# All Images will be Rescaled by 1./255. We Apply Data Augmentation Here.\ntrain_datagen = ImageDataGenerator(rotation_range=40,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   rescale=1./255,\n                                   shear_range=0.1,\n                                   zoom_range=0.1,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"id":"SuP0VQo8qxrH","colab_type":"code","outputId":"24206c98-0432-4892-e40a-8f93e9622b94","colab":{"base_uri":"https://localhost:8080/","height":51},"trusted":true},"cell_type":"code","source":"bs = 24 \nimg_size = (256, 512)\n\ntrain_gen = train_datagen.flow_from_directory(\n    directory=train_folder,\n    target_size=img_size,\n    batch_size=bs,\n    class_mode='binary'\n)\n\ntest_gen = test_datagen.flow_from_directory(\n    directory=val_folder,\n    target_size=img_size,\n    batch_size=bs,\n    class_mode='binary'\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"uzCRN33sxI4Y","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from keras.applications import DenseNet121\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Flatten, Dense, Dropout, BatchNormalization\n\ndef buildModel1():\n  dense_net = DenseNet121(\n      include_top=False,\n      input_shape=(256, 512, 3), # (width, height, colorchannel)\n      weights='imagenet'\n  )\n\n  model = Sequential()\n  model.add(dense_net)\n  model.add(GlobalAveragePooling2D())\n  model.add(BatchNormalization())\n  model.add(Dropout(0.5))\n  model.add(Dense(512, activation='relu'))\n  model.add(BatchNormalization())\n  model.add(Dropout(0.5))\n  model.add(Dense(1, activation='sigmoid'))\n\n  model.compile(\n      loss='binary_crossentropy',\n      optimizer='adam',\n      metrics=['accuracy', f1_m, precision_m, recall_m]\n  )\n\n  return model","execution_count":null,"outputs":[]},{"metadata":{"id":"jR-NENCsxXjh","colab_type":"code","outputId":"f6fbd86d-3fc2-4e5c-8890-9ab0407d4e21","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"history1 = buildModel1().fit_generator(\n          train_gen, # train generator has 12568 train images but we are not using all of them\n          steps_per_epoch=524, # training 12568 images = 786 steps x 16 images per batch\n          epochs=25,\n          validation_data=test_gen, # validation generator has 5,000 validation images\n          validation_steps=158 # validating on 2514 images = 158 steps x 16 images per batch\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"mFmsohkQVjiZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"a09GZRpNSSta","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"CZ4041_V1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}