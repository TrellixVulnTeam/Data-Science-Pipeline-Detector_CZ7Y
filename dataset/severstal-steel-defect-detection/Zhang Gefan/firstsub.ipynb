{"cells":[{"metadata":{"_uuid":"b85df64d-46db-4515-9801-7eda74011977","_cell_guid":"c7220651-2318-4ca5-a87b-dbc0a6cf82de","trusted":true},"cell_type":"code","source":"from keras.utils import Sequence\nimport os\nimport glob\nimport math\nimport numpy as np\n\nbatch_size = 16\ntest_images = glob.glob('../input/severstal-steel-defect-detection/test_images/*')\n\n\ndef msk_encode(msk):\n    if np.max(msk) == 0:\n        return np.nan\n    msk = msk.flatten(order='F')\n    msk = np.diff(msk, prepend=0, append=0)\n    start, = np.where(msk == 1)\n    length, = np.where(msk == -1)\n    length -= start\n    start += 1\n    ecd = np.stack([start, length], axis=0).flatten(order='F')\n    return ' '.join(map(str, ecd))\n\n\nclass TestDataFeeder(Sequence):\n\n    def __init__(self):\n        self.testset_dirs = test_images\n        self.batch_size = batch_size\n        self.length = len(self.testset_dirs)\n\n    def __getitem__(self, index):\n        import matplotlib.pyplot as plt\n        import cv2\n        i_start = index * self.batch_size\n        i_end = min(self.length, (index + 1) * self.batch_size)\n        x1, x2, y = [], [], []\n        for i in range(i_start, i_end):\n            y_i = self.testset_dirs[i]\n            x1_i = plt.imread(y_i).copy().astype(np.float32)\n            x2_i = cv2.resize(x1_i, dsize=(0, 0), fx=0.5, fy=0.5)\n\n            x1_i -= np.mean(x1_i, keepdims=True)\n            x1_i /= (np.std(x1_i, keepdims=True) + 1e-6)\n\n            x2_i -= np.mean(x2_i, keepdims=True)\n            x2_i /= (np.std(x2_i, keepdims=True) + 1e-6)\n\n            x1.append(x1_i)\n            x2.append(x2_i)\n\n            y_i = os.path.split(y_i)[1]\n            y.append(y_i)\n        return [np.stack(x1, axis=0), np.stack(x2, axis=0)], y\n\n    def __len__(self):\n        return math.ceil(self.length / self.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a625983a-3e0e-46ce-a2fc-9a77d90d5959","_cell_guid":"f81b7324-6b88-4e06-84c4-afd9f499cdee","trusted":true},"cell_type":"code","source":"from multiprocessing import Process, Queue\n\n\ndef pre_processing_worker(q, num, total):\n    feeder = TestDataFeeder()\n    print('worker', num + 1, 'of', total, 'started!')\n    for i in range(num, len(feeder), total):\n        q.put(feeder[i], block=True)\n    del feeder\n\n\ninput_queue = Queue(maxsize=32)\nworker_num = 1\n\nworkers = [\n    Process(\n        target=pre_processing_worker,\n        args=(input_queue, i, worker_num)\n    )\n    for i in range(worker_num)\n]\nfor w in workers:\n    w.start()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc3377d7-0003-46ed-8f3e-fdefce06429b","_cell_guid":"a9360417-9450-4572-bb11-38f93a8a1493","trusted":true},"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.initializers import Initializer\n\n\nclass Swish(Layer):\n    def call(self, inputs):\n        return tf.nn.swish(inputs)\n\n\nclass DropConnect(Layer):\n    def __init__(self, drop_connect_rate=0.0, **kwargs):\n        super().__init__(**kwargs)\n        self.drop_connect_rate = drop_connect_rate\n\n    def call(self, inputs, training=None):\n        def drop_connect():\n            keep_prob = 1.0 - self.drop_connect_rate\n\n            # Compute drop_connect tensor\n            batch_size = tf.shape(inputs)[0]\n            random_tensor = keep_prob\n            random_tensor += tf.random_uniform(\n                [batch_size, 1, 1, 1], dtype=inputs.dtype\n            )\n            binary_tensor = tf.floor(random_tensor)\n            output = tf.div(inputs, keep_prob) * binary_tensor\n            return output\n\n        return K.in_train_phase(drop_connect, inputs, training=training)\n\n    def get_config(self):\n        config = super().get_config()\n        config[\"drop_connect_rate\"] = self.drop_connect_rate\n        return config\n\n\nclass EfficientConv2DKernelInitializer(Initializer):\n    def __call__(self, shape, dtype=K.floatx(), **kwargs):\n        kernel_height, kernel_width, _, out_filters = shape\n        fan_out = int(kernel_height * kernel_width * out_filters)\n        return tf.random_normal(\n            shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype\n        )\n\n\ndmy = 'binary_crossentropy'\n\nmdlcls = load_model(\n    '../input/steelclsv2/weights.09-0.97.hdf5',\n    custom_objects={\n        'Swish': Swish,\n        'DropConnect': DropConnect,\n        'EfficientConv2DKernelInitializer': EfficientConv2DKernelInitializer,\n        'tp1': dmy, 'tp2': dmy, 'tp3': dmy, 'tp4': dmy,\n        't1': dmy, 't2': dmy, 't3': dmy, 't4': dmy,\n        'p1': dmy, 'p2': dmy, 'p3': dmy, 'p4': dmy,\n        'tp': dmy, 'p': dmy, 't': dmy,\n        'focal': dmy\n    }\n)\nmdlseg = load_model(\n    '../input/steelseg/weights.20-4.48.hdf5',\n    custom_objects={\n        'Dice_CE_FPsup_Loss': dmy, 'GDL': dmy,\n        'dice': dmy, 'I': dmy, 'C': dmy, 'T': dmy,\n        'da': dmy, 'pa': dmy,\n        'd1': dmy, 'p1': dmy, 'd2': dmy, 'p2': dmy,\n        'd3': dmy, 'p3': dmy, 'd4': dmy, 'p4': dmy\n    }\n)\n\ninputcls = mdlcls.layers[0].input\noutputcls = mdlcls.layers[-1].output\nfor l in mdlcls.layers:\n    l.name = 'cls_' + l.name\noutputcls = Reshape(target_shape=(1, 1, 4))(outputcls)\n\ninputseg = mdlseg.layers[0].input\noutputseg = mdlseg.layers[-1].output\nfor l in mdlseg.layers:\n    l.name = 'seg_' + l.name\noutputseg = Lambda(lambda x: x[:, :, :, 1:], output_shape=(256, 1600, 4))(outputseg)\noutputs = Multiply()([outputcls, outputseg])\n\nmdl = Model(input=[inputseg, inputcls], outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e2a14a8-d3e2-4e1d-b719-f6bb46fbf23e","_cell_guid":"2a79e091-0608-4628-808a-bbcc9b6e5bef","trusted":true},"cell_type":"code","source":"from tqdm import trange\nimport pandas as pd\n\nsubmission_list = []\n\nfor i in trange(math.ceil(len(test_images) / batch_size)):\n    x, x_id = input_queue.get(block=True, timeout=100)\n    y = mdl.predict(\n        x=x,\n        batch_size=batch_size,\n        verbose=0\n    )\n    for j, x_j_id in enumerate(x_id):\n        for k in range(1, 5):\n            msk = np.round(y[j, :, :, k - 1])\n            ep = msk_encode(msk)\n            submission_list.append({'ImageId_ClassId': x_j_id + '_' + str(k), 'EncodedPixels': ep})\n\nsubmission_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\nsubmission_df = submission_df.append(submission_list).set_index('ImageId_ClassId').sort_index()\nsubmission_df.to_csv('submission.csv')\n\nfor w in workers:\n    w.join()\n\nprint(submission_df)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}