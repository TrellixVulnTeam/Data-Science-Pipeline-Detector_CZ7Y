{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/severstal-steel-defect-detection/train.csv\")\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Here we prepare the dataset for a training "},{"metadata":{},"cell_type":"markdown","source":"# Here we get set of rows with notnull masks in the EncodedPixels column an set to 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"defects = data[pd.notna(data.EncodedPixels)]\ndefects.EncodedPixels = 1\ndefects.info()\nprint(defects)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we get rows without data in the EncodedPixels column and set class to 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"print((data.EncodedPixels).isnull())\nNoDefects = data[(data.EncodedPixels).isnull()]\nNoDefects.EncodedPixels = 0\nNoDefects.info()\nprint(NoDefects)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we combine same number of images from both classes, and shuffle them"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset= NoDefects.sample(defects.shape[0])\ndataset = dataset.append(defects,ignore_index=True)\ndataset = dataset.sample(frac=1, replace=True, random_state=1)\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"show image example"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfilename = str(dataset.sample(1).ImageId_ClassId.values)[2:]\nfilename = filename[:-4]\nfilename = \"../input/severstal-steel-defect-detection/train_images/\"+filename\nprint(filename)\n\nimg=mpimg.imread(filename)\nimgplot = plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"split train, val, test"},{"metadata":{"trusted":true},"cell_type":"code","source":"val = dataset[0:1000]\ntest = dataset[1000:2000]\ntrain = dataset[2000:]\ntrain.info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convolutional network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n        self.bn = nn.BatchNorm2d(out_channels, eps=1e-5)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\n\n\nclass Inception(nn.Module):\n\n  def __init__(self):\n    super(Inception, self).__init__()\n    self.branch1x1 = BasicConv2d(128, 32, kernel_size=1, padding=0)\n    self.branch1x1_2 = BasicConv2d(128, 32, kernel_size=1, padding=0)\n    self.branch3x3_reduce = BasicConv2d(128, 24, kernel_size=1, padding=0)\n    self.branch3x3 = BasicConv2d(24, 32, kernel_size=3, padding=1)\n    self.branch3x3_reduce_2 = BasicConv2d(128, 24, kernel_size=1, padding=0)\n    self.branch3x3_2 = BasicConv2d(24, 32, kernel_size=3, padding=1)\n    self.branch3x3_3 = BasicConv2d(32, 32, kernel_size=3, padding=1)\n\n  def forward(self, x):\n    branch1x1 = self.branch1x1(x)\n\n    branch1x1_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n    branch1x1_2 = self.branch1x1_2(branch1x1_pool)\n\n    branch3x3_reduce = self.branch3x3_reduce(x)\n    branch3x3 = self.branch3x3(branch3x3_reduce)\n\n    branch3x3_reduce_2 = self.branch3x3_reduce_2(x)\n    branch3x3_2 = self.branch3x3_2(branch3x3_reduce_2)\n    branch3x3_3 = self.branch3x3_3(branch3x3_2)\n\n    outputs = [branch1x1, branch1x1_2, branch3x3, branch3x3_3]\n    return torch.cat(outputs, 1)\n\n\nclass CRelu(nn.Module):\n\n  def __init__(self, in_channels, out_channels, **kwargs):\n    super(CRelu, self).__init__()\n    self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n    self.bn = nn.BatchNorm2d(out_channels, eps=1e-5)\n\n  def forward(self, x):\n    x = self.conv(x)\n    x = self.bn(x)\n    x = torch.cat([x, -x], 1)\n    x = F.relu(x, inplace=True)\n    return x\n\n\nclass FaceBoxes(nn.Module):\n\n  def __init__(self, phase, num_classes):\n    super(FaceBoxes, self).__init__()\n    self.phase = phase\n    self.num_classes = num_classes\n\n    self.conv1 = CRelu(3, 24, kernel_size=7, stride=4, padding=3)\n    self.conv2 = CRelu(48, 64, kernel_size=5, stride=2, padding=2)\n\n    self.inception1 = Inception()\n    self.inception2 = Inception()\n    self.inception3 = Inception()\n\n    self.conv3_1 = BasicConv2d(128, 128, kernel_size=1, stride=1, padding=0)\n    self.conv3_2 = BasicConv2d(128, 256, kernel_size=3, stride=2, padding=1)\n\n    self.conv4_1 = BasicConv2d(256, 128, kernel_size=1, stride=1, padding=0)\n    self.conv4_2 = BasicConv2d(128, 256, kernel_size=3, stride=2, padding=1)\n    \n    self.FC = nn.Linear(6656, 1, bias=True)\n\n    self.softmax = nn.Softmax()\n    \n    self.sigmoid = nn.Sigmoid()\n\n    if self.phase == 'train':\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                if m.bias is not None:\n                    nn.init.xavier_normal_(m.weight.data)\n                    m.bias.data.fill_(0.02)\n                else:\n                    m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n  \n  def forward(self, x):\n\n    x = self.conv1(x)\n    x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n    x = self.conv2(x)\n    x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n    x = self.inception1(x)\n    x = self.inception2(x)\n    x = self.inception3(x)\n\n    x = self.conv3_1(x)\n    x = self.conv3_2(x)\n\n    x = self.conv4_1(x)\n    x = self.conv4_2(x)\n    x = x.reshape(-1)\n    \n    x = self.FC(x)\n    \n    output = self.sigmoid(x)\n    \n    return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndef validation():\n    y_scores = [] # init array\n    hog_features2 = []\n    for i, filename in enumerate(test.ImageId_ClassId):\n        filename = str(filename)\n        filename = filename[:-2]\n        filename = \"../input/severstal-steel-defect-detection/train_images/\" + filename\n        img = mpimg.imread(filename)\n        img = (img - 125)/256\n        # swap color axis because\n        # numpy image: H x W x C\n        # torch image: C X H X W\n        img = img.transpose((2, 0, 1))\n        out = net(Variable(torch.from_numpy(img).unsqueeze(0).float()).cuda())\n        y_scores.append(out.item())\n    y_true = test.EncodedPixels.values\n    y_scores = np.array(y_scores)\n    print (\"ROC-AUC scores \" + str(roc_auc_score(y_true, y_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom torch.autograd import Variable\nimport torch.optim as optim\n\nnum_classes = 2\nmomentum = 0.9\nweight_decay = 5e-4\ninitial_lr = 1e-3\n\n\nnet = FaceBoxes('train', num_classes)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnet = net.to(device)\noptimizer = optim.Adam(net.parameters(), lr=initial_lr)\nCrossloss = nn.CrossEntropyLoss()\nerror=[]\nfor epoch in range(1,25):\n    print(\"epoch \" +str(epoch))\n    for i, filename in enumerate(train.ImageId_ClassId):\n        filename = str(filename)\n        filename = filename[:-2]\n        filename = \"../input/severstal-steel-defect-detection/train_images/\" + filename\n        img = mpimg.imread(filename)\n        #img = cv2.resize(img, dsize=(600, 70), interpolation=cv2.INTER_CUBIC)\n\n        img = (img - 125)/256\n        # swap color axis because\n        # numpy image: H x W x C\n        # torch image: C X H X W\n        img = img.transpose((2, 0, 1))\n\n\n\n        output = net(Variable(torch.from_numpy(img).unsqueeze(0).float()).cuda())\n        target = torch.from_numpy(np.array(train.EncodedPixels.values[i]))\n        optimizer.zero_grad()\n        loss = - 0.001*(target * torch.log(output) + (1-target)* torch.log(1-output))\n        loss.backward()\n        optimizer.step()\n\n        #print(str(i)+\"/\"+str(train.ImageId_ClassId.shape[0]) + \" loss = \" + str(1000 * loss.data[0]) + \" target =\" + str(target.data))\n        error.append(1000*loss.item())\n    print(\" mean loss \" + str(np.mean(np.array(error[-100:-1]))))\n    validation()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"learning process"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(error)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}