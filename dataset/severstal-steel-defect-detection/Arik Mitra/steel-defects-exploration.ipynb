{"cells":[{"metadata":{},"cell_type":"markdown","source":"Purely a practice and exploratory kernel","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I thank author of https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline for the code for the text data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv( \"../input/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(train)\nprint(df.columns)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n#df['ClassId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n#df.head()\n#df['hasmask'] = ~ df['EncodedPixels'].isna()\n#df.head()\n#mask_count_df = df1.groupby('ImageId').agg(np.sum).reset_index()\n#mask_count_df.sort_values('hasmask', ascending=False, inplace=True)\n#print(mask_count_df.shape)\n#mask_count_df.head()\n#sub_df = pd.read_csv('../input/sample_submission.csv')\n#sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n#test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\n#test_imgs.head()\n#non_missing_train_id = mask_count_df[mask_count_df['hasmask'] > 0]\n#non_missing_train_id.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[ df['EncodedPixels'].notnull() ]\nprint( df.shape )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks to https://www.kaggle.com/titericz for the code","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ndef rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height,width), k=1 ) )\n\nfig=plt.figure(figsize=(20,100))\ncolumns = 2\nrows = 50\nfor i in range(1, 100+1):\n    fig.add_subplot(rows, columns, i)\n    \n    fn = df['ImageId'].iloc[i].split('_')[0]\n    img = cv2.imread( '../input/train_images/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask( df['EncodedPixels'].iloc[i], img.shape  )\n    img[mask==1,0] = 255\n    \n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image processing practice","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"../input/train_images\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadImages(path):\n    # Put files into lists and return them as one list of size 4\n    image_files = sorted([os.path.join(path, file)\n         for file in os.listdir(path) if      file.endswith('.jpg')])\n \n    return image_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = loadImages(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display one image\ndef display_one(a, title1 = \"Original\"):\n    plt.imshow(a), plt.title(title1)\n    plt.xticks([]), plt.yticks([])\n    plt.show()\n    \n    \n# Display two images\ndef display(a, b, title1 = \"Original\", title2 = \"Edited\"):\n    plt.subplot(121), plt.imshow(a), plt.title(title1)\n    plt.xticks([]), plt.yticks([])\n    plt.subplot(122), plt.imshow(b), plt.title(title2)\n    plt.xticks([]), plt.yticks([])\n    plt.show()\n    \n    \n# Preprocessing\ndef processing(data):\n    # loading image\n    # Getting 3 images to work with \n    img = [cv2.imread(i, cv2.IMREAD_UNCHANGED) for i in data[:3]]\n    print('Original size',img[0].shape)\n    # --------------------------------\n    # setting dim of the resize\n    height = 220\n    width = 220\n    dim = (width, height)\n    res_img = []\n    for i in range(len(img)):\n        res = cv2.resize(img[i], dim, interpolation=cv2.INTER_LINEAR)\n        res_img.append(res)\n\n    # Checking the size\n    print(\"RESIZED\", res_img[1].shape)\n    \n    # Visualizing one of the images in the array\n    original = res_img[1]\n    display_one(original)\n    \n    no_noise = []\n    for i in range(len(res_img)):\n        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n        no_noise.append(blur)\n\n\n    image = no_noise[1]\n    display(original, image, 'Original', 'Blured')\n    \n    # Segmentation\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\n# Displaying segmented images\n    display(original, thresh, 'Original', 'Segmented')\n    \n    # Further noise removal\n    kernel = np.ones((3, 3), np.uint8)\n    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n\n# sure background area\n    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n\n# Finding sure foreground area\n    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n\n# Finding unknown region\n    sure_fg = np.uint8(sure_fg)\n    unknown = cv2.subtract(sure_bg, sure_fg)\n\n#Displaying segmented back ground\n    display(original, sure_bg, 'Original', 'Segmented Background')\n    \n    # Marker labelling\n    ret, markers = cv2.connectedComponents(sure_fg)\n\n# Add one to all labels so that sure background is not 0, but 1\n    markers = markers + 1\n\n# Now, marking the region of unknown with zero\n    markers[unknown == 255] = 0\n\n    markers = cv2.watershed(image, markers)\n    image[markers == -1] = [255, 0, 0]\n\n# Displaying markers on the image\n    display(image, markers, 'Original', 'Marked')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processing(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}