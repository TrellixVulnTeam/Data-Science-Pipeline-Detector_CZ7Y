{"cells":[{"metadata":{},"cell_type":"markdown","source":"### UNet Inference kernel\n\nThis kernel is an inference kernel of my [UNet starter kernel](https://www.kaggle.com/rishabhiitbhu/unet-starter-kernel-pytorch-lb-0-888). \nDon't forget to add the `model.pth` file generated from the starter kernel as dataset to predict on the test set.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# What this is doing? please refer to my above linked kernel\n!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null\npackage_path = '../input/unetmodelscript'\nimport sys\nsys.path.append(package_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\nfrom albumentations.torch import ToTensor\nimport torch.utils.data as data\nfrom model import Unet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std):\n        self.root = root\n        #df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensor(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\ntest_data_folder = \"../input/severstal-steel-defect-detection/test_images\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize test dataloader\nbest_threshold = 0.5\nnum_workers = 2\nbatch_size = 4\nprint('best_threshold', best_threshold)\nmin_size = 3500\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize mode and load trained weights\nckpt_path = \"../input/unet-starter-kernel-pytorch-lb-0-88/model.pth\"\ndevice = torch.device(\"cuda\")\nmodel = Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start prediction\npredictions = []\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold, min_size)\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            #clsid = cls+1\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n#df.set_index('ImageId_ClassId', inplace=True)\ndf.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../working","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **clear mask visualization and simple eda**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\npd.set_option(\"display.max_rows\", 101)\nimport os\nprint(os.listdir(\"../input\"))\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 15\nimport seaborn as sns\nfrom collections import Counter\nfrom PIL import Image\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nfrom pathlib import Path\nimport cv2\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(\"../working/submission.csv\")\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_dict = defaultdict(int)\n\nkind_class_dict = defaultdict(int)\n\nno_defects_num = 0\ndefects_num = 0\n\nfor col in range(0, len(submission_df), 4):\n    img_names = [str(i).split(\"_\")[0] for i in submission_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n        \n    labels = submission_df.iloc[col:col+4, 1]\n    if labels.isna().all():\n        no_defects_num += 1\n    else:\n        defects_num += 1\n    \n    kind_class_dict[sum(labels.isna().values == False)] += 1\n        \n    for idx, label in enumerate(labels.isna().values.tolist()):\n        if label == False:\n            class_dict[idx+1] += 1\n\nprint(\"the number of images with no defects: {}\".format(no_defects_num))\nprint(\"the number of images with defects: {}\".format(defects_num))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.barplot(x=list(class_dict.keys()), y=list(class_dict.values()), ax=ax)\nax.set_title(\"the number of images for each class\")\nax.set_xlabel(\"class\")\nclass_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size_dict = defaultdict(int)\ntest_path = Path(\"../input/severstal-steel-defect-detection/test_images/\")\n\nfor img_name in test_path.iterdir():\n    img = Image.open(img_name)\n    test_size_dict[img.size] += 1\n\ntest_size_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n\ndef name_and_mask(start_idx):\n    col = start_idx\n    img_names = [str(i).split(\"_\")[0] for i in submission_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n\n    labels = submission_df.iloc[col:col+4, 1]\n    mask = np.zeros((256, 1600, 4), dtype=np.uint8)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            mask_label = np.zeros(1600*256, dtype=np.uint8)\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            for pos, le in zip(positions, length):\n                mask_label[pos-1:pos+le-1] = 1\n            mask[:, :, idx] = mask_label.reshape(256, 1600, order='F')\n    return img_names[0], mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_mask_image(col):\n    name, mask = name_and_mask(col)\n    img = cv2.imread(str(test_path / name))\n    fig, ax = plt.subplots(figsize=(15, 15))\n\n    for ch in range(4):\n        contours, _ = cv2.findContours(mask[:, :, ch], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n        for i in range(0, len(contours)):\n            cv2.polylines(img, contours[i], True, palet[ch], 2)\n    ax.set_title(name)\n    ax.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_no_defect = []\nidx_class_1 = []\nidx_class_2 = []\nidx_class_3 = []\nidx_class_4 = []\nidx_class_multi = []\nidx_class_triple = []\n\nfor col in range(0, len(submission_df), 4):\n    img_names = [str(i).split(\"_\")[0] for i in submission_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n        \n    labels = submission_df.iloc[col:col+4, 1]\n    if labels.isna().all():\n        idx_no_defect.append(col)\n    elif (labels.isna() == [False, True, True, True]).all():\n        idx_class_1.append(col)\n    elif (labels.isna() == [True, False, True, True]).all():\n        idx_class_2.append(col)\n    elif (labels.isna() == [True, True, False, True]).all():\n        idx_class_3.append(col)\n    elif (labels.isna() == [True, True, True, False]).all():\n        idx_class_4.append(col)\n    elif labels.isna().sum() == 1:\n        idx_class_triple.append(col)\n    else:\n        idx_class_multi.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_1[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_2[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_3[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_4[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_multi[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_triple:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}