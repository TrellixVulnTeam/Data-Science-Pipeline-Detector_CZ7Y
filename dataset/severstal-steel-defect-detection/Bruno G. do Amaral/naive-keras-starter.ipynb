{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom tqdm import tqdm_notebook\nfrom operator import itemgetter\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_images_train = 1000 # Limited for a kernel","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv', nrows=n_images_train*4)\ntrain_images_path = Path('../input/train_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform class to col\ndf_train['fname'], df_train['cls'] = zip(*df_train['ImageId_ClassId'].str.split('_'))\ndf_train['cls'] = df_train['cls'].astype(int)\ndf_train_pivot = df_train.pivot('fname', 'cls', 'EncodedPixels')\ndf_train_pivot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, width, height):\n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(width, height), k=1 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def row_to_xy(row:pd.Series, image_path, return_weights=False, weights_border_size=50):\n    fname = row.name\n    X = cv2.imread(str(image_path / fname), cv2.IMREAD_GRAYSCALE).astype(np.float32) / 127.5 - 1\n    X = X[..., np.newaxis]  # Add channel info\n\n    height, width = X.shape[:2]\n\n    y = np.zeros((height, width, 5), dtype=np.uint8)  # Add class-zero\n    for cls in range(1, 5):\n        if isinstance(row[cls], str):\n            y[:, :, cls] = rle2mask(row[cls], width, height)\n\n    assert y.sum(-1).max() <= 1, f\"Invalid image anntation for {fname}\"\n    \n    # Add zero-class channel\n    y[..., 0] = 1-y.sum(axis=-1)\n    \n    # Return weights (will give wight to non-zero class)\n    if return_weights:\n        # Dilate and apply blur to focus on border of class\n        sw = cv2.blur(cv2.dilate(y[..., 1:].max(-1) * 255, np.ones((weights_border_size, weights_border_size))), (weights_border_size//2, weights_border_size//2))\n        sw = sw.astype(np.float32) / 255\n    \n        # Sample-weight will be used as input (trick to get it to work on latest channel)\n        return [X, sw[..., np.newaxis]], y\n    else:\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = row_to_xy(df_train_pivot.iloc[0], train_images_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nplt.imshow(X[..., 0], cmap='gray', interpolation='bilinear')\ncolors = 'rgbk'\nfor cls in range(1, 5):\n    plt.contour(y[..., cls], colors=colors[cls-1]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split df in train and valida\ndf_train_pivot, df_valid_pivot = train_test_split(df_train_pivot, test_size=0.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import *\nfrom keras.models import Model\nfrom keras.utils import Sequence\nfrom keras.optimizers import *\nfrom keras.callbacks import *\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import ceil\n\nclass SteelDataset(Sequence):\n    def __init__(self, df_pivot, batch_size, image_path, with_sw=True):\n        self.df_pivot = df_pivot\n        self.batch_size = batch_size\n        self.row_to_xy = partial(row_to_xy, image_path=image_path, return_weights=with_sw)\n        self.with_sw = with_sw\n\n    def __len__(self):\n        return ceil(self.df_pivot.shape[0] / self.batch_size)\n\n    def __getitem__(self, idx):\n        batch_df = self.df_pivot.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n        n_batch = len(batch_df)\n        \n        X_batch = np.empty((n_batch, 256, 1600, 1), dtype=np.float32)\n        y_batch = np.empty((n_batch, 256, 1600, 5), dtype=np.float32)\n        \n        if self.with_sw:\n            sw_batch = np.empty((n_batch, 256, 1600, 1), dtype=np.float32)\n        \n            for i, (_, row) in enumerate(batch_df.iterrows()):\n                (X_batch[i], sw_batch[i]), y_batch[i] = self.row_to_xy(row)\n            \n            # SW will be used as input (trick to make it work on output)\n            return {'img': X_batch, 'sw': sw_batch}, y_batch\n        else:\n            for i, (_, row) in enumerate(batch_df.iterrows()):\n                X_batch[i], y_batch[i] = self.row_to_xy(row)\n                \n            return X_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_train = SteelDataset(df_train_pivot, 4, train_images_path)\nseq_valid = SteelDataset(df_valid_pivot, 4, train_images_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xsw, y = seq_train[0]\nX = Xsw['img']\nsw = Xsw['sw']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape, y.shape, sw.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 1, figsize=(20, 10))\nax[0].imshow(X[2, ..., 0], cmap='gray', vmin=-1, vmax=1)\nax[1].imshow(y[2, ..., 1:].max(-1), vmin=0, vmax=1)\nax[2].imshow(sw[2, ..., 0], vmin=0, vmax=1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_p = 0.1\ninp = Input((256, 1600, 1), name='img')\ninp_sw = Input((256, 1600, 1), name='sw')\n\nconvs_configs = [\n    [\n        (32, 3, 1),\n    ], [\n        (64, 3, 1),\n        (64, 3, 2),\n        (64, 3, 3),\n        (64, 3, 4),\n    ], [\n        (64, 3, 1),\n        (64, 3, 2),\n        (64, 3, 3),\n        (64, 3, 4),\n    ]\n]\n\nx = inp\nfor g, conv_group_config in enumerate(convs_configs):\n    x_group = []\n    for c, (n_filters, kernel_size, dilation_rate) in enumerate(conv_group_config):\n        conv = Conv2D(n_filters, kernel_size, dilation_rate=dilation_rate, padding='same', name=f'conv_{g}_{c}')(x)\n        x_group.append(conv)\n        \n    if len(x_group) == 1:\n        x = x_group[0]\n    else:\n        x = Add(name=f'add_{g}')(x_group)\n        \n    x = BatchNormalization(name=f'bn_{g}')(x)\n    x = Activation('relu', name=f'relu_{g}')(x)\n    x = SpatialDropout2D(drop_p, name=f'drop_{g}')(x)\n\n# Create one output for each model\nx_outs = []\nmodels_cls = []\nfor cls in range(5):\n    x_out = Conv2D(1, 1, use_bias=False)(x)  # Remove bias in order to avoid overfit\n    model_cls = Model(inp, x_out)\n    x_outs.append(x_out)\n    models_cls.append(model_cls)\nx_out_all = concatenate(x_outs, -1)\nx_out_all = Activation('softmax')(x_out_all)\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\n\ndef dice_coef_loss_func(mask):\n    def dice_coef_loss(y_true, y_pred):\n        return 1-dice_coef(y_true * mask, y_pred * mask)\n    return dice_coef_loss\n\nmodel = Model([inp, inp_sw], x_out_all)\nmodel_no_sw = Model(inp, x_out_all)\n\noptim = Adam()\nmodel.compile(optim, dice_coef_loss_func(inp_sw), metrics=['accuracy', dice_coef])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cbs = [\n    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.1, verbose=True)\n]\n\nhistory = model.fit_generator(seq_train, epochs=15, validation_data=seq_valid, callbacks=cbs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history)[['loss', 'val_loss']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Based on https://gist.github.com/JDWarner/6730747\ndef dice(im1, im2, empty_score=1.0):\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n\n    im_sum = im1.sum() + im2.sum()\n    if im_sum == 0:\n        return empty_score\n\n    # Compute Dice coefficient\n    intersection = np.logical_and(im1, im2)\n\n    return 2. * intersection.sum() / im_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_valid_pred = SteelDataset(df_valid_pivot, 16, train_images_path, with_sw=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_valid = len(df_valid_pivot)\ny_true_cls = np.empty((n_valid, 256, 1600), dtype=np.bool)\ny_pred_cls = np.empty((n_valid, 256, 1600), dtype=np.float32)\n\n# Use model cls to predict each class (will avoid out of memory)\nfor cls in range(2, 5):\n    model_cls = models_cls[cls]\n    i = 0\n    for X, y in tqdm_notebook(seq_valid_pred):\n        n_batch = len(X)\n        y_pred = model_cls.predict(X)  # Note that predict will run BEFORE softmax. So output is free from 0-1 range\n        \n        y_true_cls[i:i+n_batch] = (y[..., cls] > 0)\n        y_pred_cls[i:i+n_batch] = y_pred[..., 0]\n        \n        i += n_batch\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vmin, vmax = np.percentile(y_pred_cls.ravel(), [0.1, 99.9])\nvmin, vmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(y_pred_cls.ravel(), bins=51, range=(vmin, vmax));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = (vmin + vmax) / 2\ndice(y_true_cls, y_pred_cls > t0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thres = np.linspace(vmin, vmax, 51)\ndices = np.array([dice(y_true_cls, y_pred_cls > t) for t in tqdm_notebook(thres)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(thres, dices);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.optimize import minimize\ndef loss(x):\n    r = dice(y_true_cls, y_pred_cls > x[0])\n    print(x,r)\n    return -r\nminimize(loss, [t0], method='Nelder-Mead')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minimize?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_cls = y_pred.argmax(-1)\ny_pred_cls.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.bincount(y_pred_cls.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"*Work in progress... still need to make submission process*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}