{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/qubvel/segmentation_models\n!pip install albumentations\n\nimport os, sys, gc\n\nimport pandas as pd\nimport numpy  as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm.auto       import tqdm\nfrom multiprocessing import Pool, cpu_count\n\nfrom cv2        import resize\nfrom skimage.io import imread as skiImgRead\n\nfrom sklearn.model_selection import KFold, train_test_split\n\nfrom segmentation_models           import Unet, get_preprocessing\nfrom segmentation_models.utils     import set_trainable\nfrom segmentation_models.losses    import DiceLoss, BinaryCELoss, BinaryFocalLoss, JaccardLoss\nfrom segmentation_models.metrics   import IOUScore, FScore\n\nimport keras.backend as K\n\nfrom keras.utils     import Sequence\nfrom keras.models    import load_model\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_H  = 256\nIMG_W  = 1600\n\nZOOM_H = 128\nZOOM_W = 800\n\nBACKBONE = 'seresnext50'\npreprocess_input = get_preprocessing(BACKBONE)\n\nDATA_DIR  = '../input'\nTRAIN_DIR = 'train_images'\nTEST_DIR  = 'test_images'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RLE -> MASK & MASK -> RLE"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_decode(rle_mask):\n    '''\n    rle_mask: run-length as string formated (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = rle_mask.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(IMG_W*IMG_H, dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(IMG_W,IMG_H).T\n\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n# from https://www.kaggle.com/robertkag/rle-to-mask-converter\ndef rle_to_mask(rle_string,height,width):\n    '''\n    convert RLE(run length encoding) string to numpy array\n\n    Parameters: \n    rleString (str): Description of arg1 \n    height (int): height of the mask\n    width (int): width of the mask \n\n    Returns: \n    numpy.array: numpy array of the mask\n    '''\n    rows, cols = height, width\n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rleNumbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rlePairs = np.array(rleNumbers).reshape(-1,2)\n        img = np.zeros(rows*cols,dtype=np.uint8)\n        for index,length in rlePairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img\n    \n# Thanks to the authors of: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\ndef mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load table"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_pix_inpool(df_col):\n    pool = Pool()\n    res = pool.map( count_pix, df_col.items() )\n    pool.close()\n    pool.join()\n    return res\n\ndef count_pix(row):\n    v = row[1]\n    if v == ' -1' or v is np.nan or type(v) != str:\n        return np.nan\n    else:\n        return rle_decode(v).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv  = pd.read_csv( os.path.join( DATA_DIR, 'train.csv') )\n\ntrain_csv[['ImageId','Class']] = train_csv['ImageId_ClassId'].str.split('_',expand=True)\n\ntrain_csv['Class']    = train_csv['Class'].astype(np.int)\ntrain_csv['npixel']   = count_pix_inpool( train_csv['EncodedPixels'] )\ntrain_csv['withMask'] = ~train_csv['npixel'].isnull()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(train_csv['npixel'])\nplt.xscale('log')\nplt.legend().set_visible(False)\nplt.xlabel('# of pixel is mask')\nplt.ylabel('Density')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot( data=train_csv.dropna().groupby('Class').count().reset_index(), x='Class',y='ImageId' )\nplt.ylabel('# of Images')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\n\nsns.boxplot(\n    data=train_csv.dropna(),\n    x = 'Class',\n    y = 'npixel',\n    ax = ax,\n)\nax.set_yscale('log')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot( \n    data = train_csv.dropna().groupby('ImageId').count().groupby('Class').count().reset_index(),\n    x = 'Class',\n    y = 'ImageId_ClassId'\n)\nplt.ylabel('# of Class in One Image')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(\n    x       = (train_csv.groupby('ImageId')['withMask'].any().value_counts()/train_csv['ImageId'].unique().shape[0]).values,\n    labels  = (train_csv.groupby('ImageId')['withMask'].any().value_counts()/train_csv['ImageId'].unique().shape[0]).index,\n    autopct = '%3.1f %%',\n    shadow  = True,\n    labeldistance = 1.1,\n    startangle  = 90,\n    pctdistance = 0.6\n);\nplt.title('Image with Mask or Not');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DROP_NO_MASK_FRACTION = 0.0\n\nbalanced_train_csv = (\n    train_csv.set_index('ImageId')\n    .drop(\n        train_csv.set_index('ImageId').drop(\n            train_csv['ImageId'].unique()[train_csv.groupby('ImageId')['withMask'].any()]\n        ).sample( frac = DROP_NO_MASK_FRACTION ).index\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImgMaskGenerator(Sequence):\n\n    def __init__(self, \n                 img_ids, data_dir, data_df,\n                 image_shape  = (256,256,3), \n                 masks_channels = 1,\n                 augmentor = None,\n                 bg_tag = False,\n                 batch_size=8, shuffle=True):\n        '''\n        Initialization\n        '''\n        if bg_tag:\n            bg = 1\n        else:\n            bg = 0\n        \n        self.img_ids     = img_ids\n        self.data_dir    = data_dir\n        self.data_df     = data_df\n        self.image_shape = image_shape\n        self.masks_shape = image_shape[:2] + (masks_channels+bg,)\n        self.batch_size  = batch_size\n        self.augmentor   = augmentor,\n        self.bg          = bg\n        self.shuffle     = shuffle\n        self.idxs        = np.arange(len(self.img_ids))\n        self.on_epoch_end()\n\n    def __len__(self):\n        '''\n        Denotes the number of batches per epoch\n        '''\n        return int(np.ceil(len(self.img_ids) / float(self.batch_size)))\n\n    def __getitem__(self, idx, augmentation=False):\n        '''\n        Generate one batch of data\n        '''\n        \n        end_idx = idx + self.batch_size\n        \n        batch_x = np.zeros( (self.batch_size,) + self.image_shape )\n        batch_y = np.zeros( (self.batch_size,) + self.masks_shape )\n\n        batch_img_ids = self.img_ids[idx:end_idx]\n        \n        for i,img_id in enumerate(batch_img_ids):\n            if augmentation:\n                x, y = self._load_paired_data(img_id, augmentation=self.augmentor)\n            else:\n                x, y = self._load_paired_data(img_id, augmentation=None)\n\n            batch_x[i] += x\n            batch_y[i] += y\n\n        return batch_x, batch_y\n    \n    def on_epoch_end(self):\n        '''\n        Updates indexes after each epoch\n        '''\n        if self.shuffle == True:\n            np.random.shuffle(self.idxs)\n            \n    def _load_paired_data(self, img_id, augmentation=None):\n        height, width = self.image_shape[:2]\n        \n        img_fp = os.path.join( self.data_dir, img_id )\n        image = skiImgRead(img_fp)\n        image = resize(image, (width,height))\n        masks = np.zeros( self.masks_shape )\n        \n        if self.bg == 1:\n            masks = masks[:,:,:-1]\n        \n\n        for cls, row in self.data_df.loc[img_id].set_index('Class').iterrows():\n            if row['EncodedPixels'] is np.nan:\n                mask = np.zeros((height, width))\n            else:\n                mask = rle_decode(row['EncodedPixels'])\n                mask = resize(mask, (width,height))\n\n            masks[:,:,cls-1] += mask\n\n        if self.bg == 1:\n            bg_mask = np.ones(self.image_shape[:2]) - masks.max(axis=-1)\n            masks = np.dstack([masks,bg_mask])\n        \n        if augmentation:\n            augmented = augmentation(image=image, mask=masks)\n            image = augmented['image']\n            masks = augmented['mask']\n\n        image = preprocess_input(image)\n        return image, masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    Compose, OneOf, ToFloat, PadIfNeeded, Resize, NoOp, \n    Flip, HorizontalFlip, VerticalFlip, RandomRotate90, ShiftScaleRotate, Transpose,\n    Blur, MotionBlur, MedianBlur, JpegCompression, Cutout,\n    RandomCrop, RandomScale, RandomSizedCrop, CenterCrop,\n    RandomContrast, RandomBrightness, RandomBrightnessContrast, CLAHE, RandomGamma,\n    RGBShift, GaussNoise, HueSaturationValue,\n    GridDistortion, ElasticTransform, OpticalDistortion,\n    IAASharpen, IAAPiecewiseAffine, IAAAdditiveGaussianNoise\n)\n\naug = Compose([\n    OneOf([\n        NoOp(),\n        Flip(),\n        HorizontalFlip(),\n        VerticalFlip(),\n    ], p=1), \n    \n    OneOf([\n        NoOp(),\n        Blur(blur_limit=3),\n        MedianBlur(blur_limit=3),\n        MotionBlur(blur_limit=3),\n        JpegCompression(),\n    ], p=0.3),\n    \n    OneOf([\n        NoOp(),\n        RandomGamma(),\n        RandomContrast(),\n        RandomBrightness(),\n        RandomBrightnessContrast(),\n        CLAHE(),\n     ], p=0.3),\n\n    OneOf([\n        NoOp(),\n        GaussNoise(),\n        HueSaturationValue(),\n        Cutout(num_holes=8, max_h_size=4, max_w_size=8),\n        IAAAdditiveGaussianNoise(),\n    ], p=0.3),\n    \n    OneOf([\n        NoOp(),\n        OpticalDistortion(),\n        GridDistortion(),\n        RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    ], p=0.2),\n    \n    OneOf([\n        NoOp(),\n        CenterCrop(height=ZOOM_H, width=ZOOM_W//2),\n        RandomCrop(height=ZOOM_H, width=ZOOM_W//2),\n        RandomScale(),\n        RandomSizedCrop(min_max_height=(ZOOM_H/2, ZOOM_H), height=ZOOM_H, width=ZOOM_W),\n    ],p=0.3),\n    \n    IAASharpen(p=0.2), \n    ShiftScaleRotate(rotate_limit=10, p=0.3),\n\n    PadIfNeeded(min_height=ZOOM_H,min_width=ZOOM_W, p=1),\n    Resize(height=ZOOM_H, width=ZOOM_W, p=1),\n    ToFloat(max_value=1),\n], p=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_ids = np.array( balanced_train_csv.index.unique().tolist() )\ntrain_img_ids.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_gen = ImgMaskGenerator( \n    img_ids  = train_img_ids, \n    data_dir = os.path.join( DATA_DIR, TRAIN_DIR),\n    data_df  = balanced_train_csv,\n    image_shape  = (ZOOM_H,ZOOM_W,3), \n    masks_channels  = 4,\n#     bg_tag=1,\n    batch_size=8, shuffle=True\n)\n\nfig, axs = plt.subplots(ncols=2, nrows=5, figsize=(10, 5), sharex=True, sharey=True)\n\nfor i, img_id in enumerate( np.random.choice(train_img_ids, 5) ):\n    x, y = total_gen._load_paired_data(img_id)\n    \n    axs[i,0].set_xlabel(img_id)\n    axs[i,0].imshow(x)\n    axs[i,1].imshow(np.sum(y,axis=-1))\n\naxs[0,0].set_title('Input')\naxs[0,1].set_title('Mask')\n\nplt.xticks([])\nplt.yticks([])\n\nplt.show()\n\ndel total_gen;\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_test(y_true, y_pred, smooth=1, axis=None):\n    \"\"\"Generate the 'Dice' coefficient for the provided prediction.\n    Args:\n        y_true: The expected/desired output mask.\n        y_pred: The actual/predicted mask.\n    Returns:\n        The Dice coefficient between the expected and actual outputs. Values\n        closer to 1 are considered 'better'.\n    \"\"\"\n    if axis is None:\n        y_true_f = y_true.flatten()\n        y_pred_f = y_pred.flatten()\n        intersection = np.sum(y_true_f * y_pred_f)\n        return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n    else:\n        intersection = np.sum(y_true * y_pred, axis=axis)\n        dice = (2. * intersection + smooth) / (np.sum(y_true, axis=axis) + np.sum(y_pred, axis=axis) + smooth)\n        return np.mean(dice)\n\ndef dice_coef(y_true, y_pred, smooth=1, axis=None):\n    \"\"\"Generate the 'Dice' coefficient for the provided prediction.\n    Args:\n        y_true: The expected/desired output mask.\n        y_pred: The actual/predicted mask.\n    Returns:\n        The Dice coefficient between the expected and actual outputs. Values\n        closer to 1 are considered 'better'.\n    \"\"\"\n    if axis is None:\n        y_true_f = K.flatten(y_true)\n        y_pred_f = K.flatten(y_pred)\n        intersection = K.sum(y_true_f * y_pred_f)\n        return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    else:\n        intersection = K.sum(y_true * y_pred, axis=axis)\n        dice = (2. * intersection + smooth) / (K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + smooth)\n        return K.mean(dice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ids, holdout_ids = train_test_split(train_img_ids, random_state=42, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_gen = ImgMaskGenerator( \n    img_ids  = train_ids,\n    data_dir = os.path.join( DATA_DIR, TRAIN_DIR ),\n    data_df  = balanced_train_csv,\n    image_shape    = (ZOOM_H,ZOOM_W,3), \n    masks_channels = 4,\n    bg_tag         = False,\n    augmentor      = None,\n    batch_size=BATCH_SIZE, shuffle=True,\n)\n\nvalid_gen = ImgMaskGenerator( \n    img_ids  = holdout_ids,\n    data_dir = os.path.join( DATA_DIR, TRAIN_DIR ),\n    data_df  = balanced_train_csv,\n    image_shape    = (ZOOM_H,ZOOM_W,3), \n    masks_channels = 4,\n    bg_tag         = False,\n    augmentor      = None,\n    batch_size=BATCH_SIZE, shuffle=True,\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Unet(\n    BACKBONE,\n    encoder_weights='imagenet',\n    classes=4,\n    activation='sigmoid',\n    input_shape=(ZOOM_H, ZOOM_W, 3),\n)\n\nmodel.compile(\n    optimizer = 'Adam', \n    loss = BinaryCELoss() + DiceLoss(), # v2\n    metrics = [\n        IOUScore(      threshold=0.5, per_image=True),\n        FScore(beta=2, threshold=0.5, per_image=True),\n    ]\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbest_model_fp = './best_model.h5'\n\ncheckpoint = ModelCheckpoint(\n    filepath=best_model_fp,\n    monitor='val_f2-score', mode='max', \n    save_best_only=True, save_weights_only=False, \n    verbose=1\n)\nreduce_lr  = ReduceLROnPlateau(\n    monitor='val_loss', mode='min', \n    factor=0.3, patience=8, min_lr=0.00001, \n    verbose=1\n)\nearlyStop  = EarlyStopping(\n    monitor='val_f2-score', mode='max', \n    min_delta=0, patience=15, \n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    generator        = train_gen,\n    validation_data  = valid_gen,\n    steps_per_epoch  = len(train_gen),\n    validation_steps = len(valid_gen)//2,\n    epochs           = 40,\n    callbacks        = [ checkpoint, reduce_lr, earlyStop ],\n\n    use_multiprocessing = True,\n    workers = 2,\n    verbose = 2,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots( nrows=1, ncols=3, figsize=(16,3) )\n\nlos       = model.history.history['loss']\nvlos      = model.history.history['val_loss']\ndicecoef  = model.history.history['f2-score']\nvdicecoef = model.history.history['val_f2-score']\niou       = model.history.history['iou_score']\nviou      = model.history.history['val_iou_score']\n\nepochs = np.arange(1, len(los)+1)\n\naxs[0].plot(epochs, los,       label='Training loss')\naxs[0].plot(epochs, vlos,      label='Validation loss')\naxs[1].plot(epochs, dicecoef,  label='dice_coef')\naxs[1].plot(epochs, vdicecoef, label='Validation dice_coef')\naxs[2].plot(epochs, iou,       label='IOU')\naxs[2].plot(epochs, viou,      label='Validation IOU')\n\naxs[0].legend()\naxs[1].legend()\naxs[2].legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 10\nfig, axs = plt.subplots(ncols=3, nrows=n, figsize=(10, n), sharex=True, sharey=True)\n\nfor i, img_id in enumerate( np.random.choice(holdout_ids, n) ):\n    x, y = valid_gen._load_paired_data(img_id)\n    yp = model.predict( np.expand_dims(x, axis=0) )\n    ys = np.sum( (yp[0]>0.5)+0, axis=-1 )\n\n    axs[i,0].set_ylabel(img_id, rotation=0, ha='right')\n    axs[i,0].imshow(x)\n    axs[i,1].imshow(np.sum(y,axis=-1))\n    axs[i,2].imshow(ys)\n\n\naxs[0,0].set_title('Input')\naxs[0,1].set_title('Mask')\naxs[0,2].set_title('Predict')\n\nplt.xticks([])\nplt.yticks([])\n\nplt.subplots_adjust(wspace=0.05,hspace=0.001,bottom=0.05,top=0.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dice_ts = {}\n\nthresholds = np.arange(0.3, 1.0, 0.05)\n\nfor img_id in tqdm(holdout_ids):\n    x, y = valid_gen._load_paired_data(img_id)\n    yp = model.predict(np.expand_dims(x,axis=0))[0]\n    \n    for t in thresholds:\n        yp = ((yp>t)+0)\n        dice_t = dice_test(y[:,:,:4],yp[:,:,:4], axis=(0,1))\n\n        if t not in dice_ts.keys():\n            dice_ts[t] = []\n\n        dice_ts[t].append(dice_t)\n            \ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for t in thresholds:\n    dice_ts[t] = np.array( dice_ts[t] ).mean()\n\ndice_ts = pd.Series(dice_ts)[thresholds].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_best_index = np.argmax(dice_ts) \ndice_best = dice_ts[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, dice_ts)\nplt.plot(threshold_best, dice_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Dice\")\nplt.title(\"Threshold vs Dice ({}, {})\".format(threshold_best, dice_best))\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 10\nfig, axs = plt.subplots(ncols=3, nrows=n, figsize=(10, n), sharex=True, sharey=True)\n\nfor i, img_id in enumerate( np.random.choice(holdout_ids, n) ):\n    x, y = valid_gen._load_paired_data(img_id)\n    yp = model.predict( np.expand_dims(x, axis=0) )\n    ys = np.sum( (yp[0]>threshold_best)+0, axis=-1 )\n\n    axs[i,0].set_ylabel(img_id, rotation=0, ha='right')\n    axs[i,0].imshow(x)\n    axs[i,1].imshow(np.sum(y,axis=-1))\n    axs[i,2].imshow(ys)\n\n\naxs[0,0].set_title('Input')\naxs[0,1].set_title('Mask')\naxs[0,2].set_title('Predict')\n\nplt.xticks([])\nplt.yticks([])\n\nplt.subplots_adjust(wspace=0.05,hspace=0.001,bottom=0.05,top=0.5)\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}