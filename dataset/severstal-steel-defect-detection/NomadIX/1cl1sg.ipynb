{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# ===========================================================================================\n# In kernel used segmentation model library (https://github.com/qubvel/segmentation_models)\n# ===========================================================================================\nimport os\nimport cv2\nimport time\nimport pandas as pd\nimport numpy as np\nfrom os import listdir\nfrom os.path import isfile, join\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom skimage.morphology import remove_small_objects\nfrom skimage import measure\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef preprocess(X):\n    return (X - 110.0) / 1.0\n\ntest_images_path = \"/kaggle/input/severstal-steel-defect-detection/test_images/\"\nclassifier_model_folder = \"/kaggle/input/1cl1sg-a/\"\nsegmentator_model_folder = \"/kaggle/input/1cl1sg-d/\"\nbin_classifier_file = \"model_data_v1.3.epoch06-loss0.00882-accuracy0.9973.hdf5\" # \"rn34-bcl-v10.0a1-E35_loss-0.0105_val_loss-0.0004.h5\"\nsegmentator_4C_file = \"rn34-sg-v2.1a-E23_loss-0.0093_val_loss-0.0012.h5\" # \"rn34-sg4c-v0.7a-E38_loss-0.0023_val_loss-0.0044.h5\" # \"rn34-sg4c-v0.7a1-E12_loss-0.0025_val_loss-0.0014.h5\"\ncustom_objects = { \"dice_coef\": dice_coef }\n\nimg_w = 1600\nimg_h = 256\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# ===================================================================\n# Load Keras model (binary classifier and segmentator)\ndef LoadModels():\n    bin_classifier = load_model(classifier_model_folder + bin_classifier_file, custom_objects, compile=False)\n    bin_classifier.compile(optimizer = Adam(lr=0.00075), loss = \"binary_crossentropy\", metrics = [\"acc\"])\n\n    segmentator_4C = load_model(segmentator_model_folder + segmentator_4C_file, custom_objects, compile=False)\n    segmentator_4C.compile(optimizer = Adam(lr=0.00075), loss = \"binary_crossentropy\", metrics = [dice_coef])\n    print(\"Models are loaded succesfully\")\n\n    return bin_classifier, segmentator_4C","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ===================================================================\n# Create list of files for prediction\n# Returned list contains full path for all files\ndef CreateFilesListInFolder(images_path=test_images_path):\n    files = [f for f in listdir(images_path) if isfile(join(images_path, f))]\n    files = list(map(lambda x: images_path + x, files))\n    files_count = len(files)\n    print(\"Total count of files in folder: {0}\".format(files_count))\n    return files\n\n\n# ===================================================================\n# Returns run length as string formated\ndef mask2rle(img):\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\n# min_size_arr4D = [85, 200, 20, 20]\nmin_size_arr4D = [43, 100, 10, 10]\n# ===================================================================\n# Remove small objects\n# data_tensor - 4D-tensor with shape (samples, height, width, depth)\n# min_size_arr - length equal to data_tensor depth\ndef RemoveSmallObjectsIn4D(data_tensor, min_size_arr=min_size_arr4D):\n    res_tensor = data_tensor.copy()\n    samples, height, width, depth = data_tensor.shape\n    for ix in range(samples):\n        for idp in range(depth):\n            img = measure.label(data_tensor[ix, :, :, idp], background=0)\n            remove_small_objects(img, min_size=min_size_arr[idp], in_place=True)\n            res_tensor[ix, :, :, idp] = img\n    return res_tensor\n\n\n# =============================================================================\n# Prepare one image for test\n# fname - full path to file, img_shape = (height, width)\ndef PrepareImageForTest(fname, img_shape, color_mode, use_median_blur=False):\n    h, w = img_shape\n    name = os.path.basename(fname)\n    X = cv2.imread(fname, color_mode)\n    if color_mode != cv2.IMREAD_GRAYSCALE:\n        X = cv2.cvtColor(X, cv2.COLOR_BGR2RGB)\n\n    if use_median_blur: X = cv2.medianBlur(X, 3)\n    X = cv2.resize(X, (w, h))\n    return X\n\n\n# =============================================================================\n# Prepare test batch of images for prediction\n# files_list contains full path to file\ndef CreateTestBatch(files_list, batch_size, img_shape, color_mode):\n    last_ix = batch_size if len(files_list) > batch_size else len(files_list)\n\n    if color_mode == cv2.IMREAD_GRAYSCALE:\n        color_planes = 1\n    else:\n        color_planes = 3\n\n    h, w = img_shape\n    files = files_list[:last_ix]\n    # X = np.empty((batch_size, h, w, color_planes), dtype = np.float32)\n    X = np.empty((len(files), h, w, color_planes), dtype = np.float32)\n    for ix, fname in enumerate(files):\n        Xi = PrepareImageForTest(fname, img_shape, color_mode, use_median_blur=True)\n        if color_mode == cv2.IMREAD_GRAYSCALE:\n            Xi = Xi.reshape(h, w, 1)\n        X[ix,] = Xi\n    return X, files\n\n\n# ====================================================================\n# Predict defected / non-defected samples\ndef PredictDefectedSamples(files, model, batch_size = 250, threshold = 0.5):\n    print(\"Classification defected/ non defected samples has started\")\n    files_count = len(files)\n    batches_count = files_count // batch_size\n    if (batches_count * batch_size) != files_count: batches_count += 1\n    print(\"Total count of files for classification: {0}\".format(files_count))\n\n    df_non_defected = pd.DataFrame(columns=[\"ImageId_ClassId\", \"EncodedPixels\"])\n    defected_images = []\n\n    for i in range(batches_count):\n        start_pos = i * batch_size\n        end_pos = start_pos + batch_size\n        if end_pos > files_count: end_pos = files_count\n\n        filesi = files[start_pos : end_pos]\n        X, fls = CreateTestBatch(files_list=filesi, batch_size=batch_size, img_shape=(128, 800), color_mode=cv2.IMREAD_COLOR)\n\n        print(\"Predicting files: from {0} to {1}\".format(start_pos, end_pos))\n        prediction_vector = model.predict(preprocess(X))\n\n        for pr_ix in range(len(filesi)):\n            if prediction_vector[pr_ix] >= threshold:\n                # Image predicted as contains defect\n                defected_images.append(filesi[pr_ix])\n            else:\n                # Image predicted as non-defected\n                fn = os.path.basename(filesi[pr_ix])\n                file_name, file_extension = os.path.splitext(fn)\n                for clsid in range(4):\n                    img_class = file_name + file_extension + \"_\" + str(clsid + 1)\n                    df_non_defected = df_non_defected.append(\n                        {'ImageId_ClassId': img_class, 'EncodedPixels': \"\"},\n                        ignore_index=True)\n\n    print(\"Classification defected/ non defected samples has finished\")\n    return df_non_defected, defected_images\n\n\n# ====================================================================\n# Make segmentation of defected samples by classes\ndef SegmentDefectsByClasses(files, model, batch_size=250, threshold=0.5, visualize=False):\n    print(\"Segmentation has started\")\n    files_count = len(files)\n    batches_count = files_count // batch_size\n    if (batches_count * batch_size) != files_count: batches_count += 1\n    df_submission = pd.DataFrame(columns=[\"ImageId_ClassId\", \"EncodedPixels\"])\n    print(\"Total count of files for segmentation: {0}\".format(files_count))\n\n\n    for i in range(batches_count):\n        start_pos = i * batch_size\n        end_pos = start_pos + batch_size\n        if end_pos > files_count: end_pos = files_count\n\n        filesi = files[start_pos: end_pos]\n        X, fls = CreateTestBatch(files_list=filesi, batch_size=batch_size, img_shape=(128, 800),\n                                 color_mode=cv2.IMREAD_COLOR)\n\n        print(\"Predicting files: from {0} to {1}\".format(start_pos, end_pos))\n        prediction_tensor = model.predict(preprocess(X))\n#         prediction_tensor = RemoveSmallObjectsIn4D(prediction_tensor, min_size_arr4D)\n\n        # Save predictions\n        for ix, file in enumerate(filesi):\n            for clsid in range(4):\n                fn = os.path.basename(file)\n                file_name, file_extension = os.path.splitext(fn)\n                img_class = file_name + file_extension + \"_\" + str(clsid + 1)\n                mask = prediction_tensor[ix, :, :, clsid]                   # 128 x  800\n                maskb = cv2.resize(mask, (img_w, img_h), cv2.INTER_CUBIC)   # 256 x 1600\n                maskb[maskb > threshold] = 1\n                maskb[maskb <= threshold] = 0\n                rle_mask = mask2rle(maskb)\n                df_submission = df_submission.append(\n                    {'ImageId_ClassId': img_class, 'EncodedPixels': rle_mask},\n                    ignore_index=True)\n\n                # Visualize prediction\n                if visualize:\n                    vimg = cv2.imread(file)\n                    vimg = cv2.cvtColor(vimg, cv2.COLOR_BGR2RGB)\n                    for clp in range(3):\n                        vimg[maskb == 1, clp] = color_masks1[clsid][clp]\n                    cv2.imwrite(visualize_prediction_path + \"c\" + str(clsid + 1) + \"/\" + file_name + \".png\", vimg)\n\n    print(\"Segmentation has finished\")\n    return df_submission\n\n\ndef mask_threshold_check(prediction: pd.DataFrame):\n    threshold = {'1': 1062, '2': 1212, '3': 2785, '4': 3500}\n    th = prediction['EncodedPixels'].apply(lambda x: x if pd.isna(x) else sum([int(elem) for elem in x.split(' ')[1::2]]))\n    cl = prediction['ImageId_ClassId'].str.split('_', expand=True)[1]\n    counter = 0\n    for i in prediction.index:\n        if th[i] < threshold[cl[i]]:\n            prediction.at[i, 'EncodedPixels'] = np.nan\n            counter += 1\n    print(f'Count of removed masks = {counter}')\n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    start_time = time.time()\n    bin_classifier, segmentator_4C = LoadModels()\n    \n    test_files = CreateFilesListInFolder(images_path=test_images_path)\n    df_non_defected, list_defected_samples = PredictDefectedSamples(test_files, bin_classifier, batch_size=250, threshold=0.3)\n    end_time = time.time()\n    print(\"Defecten/ non defected images prediction time: {0} min\".format((end_time - start_time) / 60))\n    print(\"Non-defected samples found: {0}\".format(len(df_non_defected) / 4))\n    print(\"Defected samples found: {0}\".format(len(list_defected_samples)))\n    df_non_defected.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Rewrite results for binary classification\n# df = pd.read_csv(\"/kaggle/input/1cl1sg-b/reschinas.csv\")\n# df0 = df[df[\"ClassId\"] == 0]\n# df1 = df0.copy()\n# df2 = df0.copy()\n# df3 = df0.copy()\n# df4 = df0.copy()\n# df1[\"ImageId_ClassId\"] = df1[\"ImageId\"] + \"_1\"\n# df2[\"ImageId_ClassId\"] = df1[\"ImageId\"] + \"_2\"\n# df3[\"ImageId_ClassId\"] = df1[\"ImageId\"] + \"_3\"\n# df4[\"ImageId_ClassId\"] = df1[\"ImageId\"] + \"_4\"\n# df_non_defected = pd.concat([df1, df2, df3, df4], ignore_index=True).reset_index(drop=True)\n# df_non_defected[\"EncodedPixels\"] = \"\"\n# df_non_defected = df_non_defected.drop([\"ClassId\", \"ImageId\"], 1)\n# df_non_defected = df_non_defected.sort_values(by=[\"ImageId_ClassId\"])\n\n# list_defected_samples = df[df[\"ClassId\"] == 1][\"ImageId\"].to_list()\n# list_defected_samples = list(map(lambda x: test_images_path + x, list_defected_samples))\n# # df_non_defected.head()\n# print(list_defected_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    start_time = time.time()\n    df_segmentation = SegmentDefectsByClasses(list_defected_samples, segmentator_4C, batch_size=250, threshold=0.6, visualize=False)\n    end_time = time.time()\n    print(\"Segmentation time: {0} min\".format((end_time - start_time) / 60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    df_submission = pd.concat([df_non_defected, df_segmentation], ignore_index=True).reset_index(drop=True)\n    df_submission = df_submission.sort_values(by=[\"ImageId_ClassId\"])\n    \n#     df1 = df_submission[df_submission[\"EncodedPixels\"] != \"\"]\n#     df2 = df_submission[df_submission[\"EncodedPixels\"] == \"\"]\n#     df1[\"EncodedPixels\"] = \"1 1\"\n#     df_submission = pd.concat([df1, df2], ignore_index=True).reset_index(drop=True)\n#     df_submission[\"EncodedPixels\"] = \"1 1\"\n\n#     df = df_submission.copy()\n#     df[\"ClassId\"] = df[\"ImageId_ClassId\"].str[-1:].astype(int)\n#     df1 = df[df[\"ClassId\"] == 4]\n#     df2 = df[df[\"ClassId\"] != 4]\n#     df1[\"EncodedPixels\"] = \"\"\n#     df_submission = pd.concat([df1, df2], ignore_index=True).reset_index(drop=True)\n#     df_submission = df_submission.drop('ClassId', 1)\n#     df_submission = df_submission.sort_values(by=[\"ImageId_ClassId\"])\n#     df_submission[\"EncodedPixels\"] = \"1 1\"\n    \n#     df_submission = mask_threshold_check(df_submission)\n    df_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_submission.head(100)\n# df = df_submission[df_submission[\"EncodedPixels\"] == \"\"]\n# df.head(50)\n# df_submission.head(50)\n# df_segmentation.head()\n# df_non_defected.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}