{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id=\"toc\"></a>\n# Table of Contents\n1. [Configure parameters](#configure_parameters)\n1. [Import modules](#import_modules)\n1. [Get annotations](#get_annotations)\n1. [Draw some charts for input dataset](#draw_some_charts_for_input_dataset)\n1. [Get encoded pixels of each class for each image](#get_encoded_pixels_of_each_class_for_each_image)\n1. [Split dataset into training and validation sets](#split_dataset_into_training_and_validation_sets)\n1. [Draw some charts for training and validation sets](#draw_some_charts_for_training_and_validation_sets)\n1. [Visualize some images and corresponding labels](#visualize_some_images_and_corresponding_labels)\n1. [Copy images into right folders](#copy_images_into_right_folders)\n1. [Zip training and validation sets](#zip_training_and_validation_sets)\n1. [Post process annotations](#post_process_annotations)\n1. [Save annotations](#save_annotations)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"configure_parameters\"></a>\n# Configure parameters\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_DIR = '../input/severstal-steel-defect-detection/'\nTEST_SIZE = 0.3\nRANDOM_STATE = 123\n\nNUM_TRAIN_SAMPLES = 20 # The number of train samples used for visualization\nNUM_VAL_SAMPLES = 20 # The number of val samples used for visualization\nCOLORS = ['b', 'g', 'r', 'm'] # Color of each class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"import_modules\"></a>\n# Import modules\n[Back to Table of Contents](#toc)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\n\nfrom shutil import copyfile\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"get_annotations\"></a>\n# Get annotations\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Convert training data-frame to the legacy version"},{"metadata":{"trusted":true},"cell_type":"code","source":"legacy_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\n\nfor img_id, img_df in tqdm_notebook(df.groupby('ImageId')):\n    for i in range(1, 5):\n        avail_classes = list(img_df.ClassId)\n\n        row = dict()\n        row['ImageId_ClassId'] = img_id + '_' + str(i)\n\n        if i in avail_classes:\n            row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n        else:\n            row['EncodedPixels'] = np.nan\n        \n        legacy_df = legacy_df.append(row, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"legacy_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = legacy_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Continue the preprocessing process"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['HavingDefection'] = df['EncodedPixels'].map(lambda x: 0 if x is np.nan else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_col = np.array(df['Image'])\nimage_files = image_col[::4]\nall_labels = np.array(df['HavingDefection']).reshape(-1, 4)\n\nnum_img_class_1 = np.sum(all_labels[:, 0])\nnum_img_class_2 = np.sum(all_labels[:, 1])\nnum_img_class_3 = np.sum(all_labels[:, 2])\nnum_img_class_4 = np.sum(all_labels[:, 3])\nprint('Class 1: {} images'.format(num_img_class_1))\nprint('Class 2: {} images'.format(num_img_class_2))\nprint('Class 3: {} images'.format(num_img_class_3))\nprint('Class 4: {} images'.format(num_img_class_4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"draw_some_charts_for_input_dataset\"></a>\n# Draw some charts for input dataset\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_figures(\n    sizes,\n    pie_title,\n    start_angle,\n    bar_title,\n    bar_ylabel,\n    labels=('Class 1', 'Class 2', 'Class 3', 'Class 4'),\n    colors=None,\n    explode=(0, 0, 0, 0.1),\n):\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n    y_pos = np.arange(len(labels))\n    barlist = axes[0].bar(y_pos, sizes, align='center')\n    axes[0].set_xticks(y_pos, labels)\n    axes[0].set_ylabel(bar_ylabel)\n    axes[0].set_title(bar_title)\n    if colors is not None:\n        for idx, item in enumerate(barlist):\n            item.set_color(colors[idx])\n\n    def autolabel(rects):\n        \"\"\"\n        Attach a text label above each bar displaying its height\n        \"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            axes[0].text(\n                rect.get_x() + rect.get_width()/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontweight='bold'\n            )\n\n    autolabel(barlist)\n    \n    pielist = axes[1].pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=start_angle, counterclock=False)\n    axes[1].axis('equal')\n    axes[1].set_title(pie_title)\n    if colors is not None:\n        for idx, item in enumerate(pielist[0]):\n            item.set_color(colors[idx])\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('[THE WHOLE DATASET]')\n\nsum_each_class = np.sum(all_labels, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\nsum_each_sample = np.sum(all_labels, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=list(unique),\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"get_encoded_pixels_of_each_class_for_each_image\"></a>\n# Get encoded pixels of each class for each image\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"annotations = np.array(df['EncodedPixels']).reshape(-1, 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"split_dataset_into_training_and_validation_sets\"></a>\n# Split dataset into training and validation sets\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(image_files, annotations, test_size=TEST_SIZE, random_state=RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train:', X_train.shape)\nprint('y_train:', y_train.shape)\nprint('X_val:', X_val.shape)\nprint('y_val', y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"draw_some_charts_for_training_and_validation_sets\"></a>\n# Draw some charts for training and validation sets\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('[TRAINING SET]')\n\ntmp = y_train.reshape(-1)\ntmp = list(map(lambda x: 0 if x is np.nan else 1, tmp))\ntrain_labels = np.array(tmp).reshape(-1, 4)\n\nsum_each_class = np.sum(train_labels, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(train_labels, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=list(unique),\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('[VALIDATION SET]')\n\ntmp = y_val.reshape(-1)\ntmp = list(map(lambda x: 0 if x is np.nan else 1, tmp))\nval_labels = np.array(tmp).reshape(-1, 4)\n\nsum_each_class = np.sum(val_labels, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(val_labels, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=list(unique),\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"visualize_some_images_and_corresponding_labels\"></a>\n# Visualize some images and corresponding labels\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_samples(samples):\n    for sample in samples:\n        fig, ax = plt.subplots(figsize=(16, 10))\n        img_path = os.path.join(DATASET_DIR, 'train_images', sample[0])\n        img = cv2.imread(img_path)\n\n        patches = []\n        for idx, rle in enumerate(sample[1]):\n            if rle is not np.nan:\n                mask = rle2mask(rle)\n                contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n                for contour in contours:\n                    poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=1, edgecolor=COLORS[idx], facecolor=COLORS[idx], fill=True)\n                    patches.append(poly_patch)\n        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet, alpha=0.3)\n\n        ax.imshow(img/255)\n        ax.set_title(sample[0])\n        ax.add_collection(p)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pairs = np.array(list(zip(X_train, y_train)))\ntrain_samples = train_pairs[np.random.choice(train_pairs.shape[0], NUM_TRAIN_SAMPLES, replace=False), :]\n\nshow_samples(train_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pairs = np.array(list(zip(X_val, y_val)))\nval_samples = val_pairs[np.random.choice(val_pairs.shape[0], NUM_VAL_SAMPLES, replace=False), :]\n\nshow_samples(val_samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"copy_images_into_right_folders\"></a>\n# Copy images into right folders\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir train_images\n!mkdir val_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image_file in tqdm_notebook(X_train):\n    src = os.path.join(DATASET_DIR, 'train_images', image_file)\n    dst = os.path.join('./train_images', image_file)\n    copyfile(src, dst)\n\nfor image_file in tqdm_notebook(X_val):\n    src = os.path.join(DATASET_DIR, 'train_images', image_file)\n    dst = os.path.join('./val_images', image_file)\n    copyfile(src, dst)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"zip_training_and_validation_sets\"></a>\n# Zip training and validation sets\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!apt install zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r -m -1 -q train_images.zip ./train_images\n!zip -r -m -1 -q val_images.zip ./val_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"post_process_annotations\"></a>\n# Post process annotations\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y_train.reshape(-1)\ny_val = y_val.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.repeat(X_train, 4)\nX_val = np.repeat(X_val, 4)\n\nX_train = X_train.reshape(-1, 4)\nX_val = X_val.reshape(-1, 4)\n\nindices = np.array(['_1', '_2', '_3', '_4'])\n\nX_train += indices\nX_val += indices\n\nX_train = X_train.reshape(-1)\nX_val = X_val.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id=\"save_annotations\"></a>\n# Save annotations\n[Back to Table of Contents](#toc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = {\n    'ImageId_ClassId': X_train,\n    'EncodedPixels': y_train\n}\n\nval_set = {\n    'ImageId_ClassId': X_val,\n    'EncodedPixels': y_val\n}\n\ntrain_df = pd.DataFrame(train_set)\nval_df = pd.DataFrame(val_set)\n\ntrain_df.to_csv('./train.csv', index=False)\nval_df.to_csv('./val.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}