{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# $\\color{ORANGE}{\\text{U-NET IN STEEL   }}$\n\n![maninsteel](https://wallpapercave.com/wp/Me1VNXE.jpg)","metadata":{}},{"cell_type":"code","source":"#Libraries mostly torch\nimport os\nimport json\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob\n\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\nfrom keras.models import Model, load_model \nimport gc\n!pip install segmentation-models\n!pip install git+https://github.com/qubvel/segmentation_models\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-16T19:21:52.423582Z","iopub.execute_input":"2021-06-16T19:21:52.424Z","iopub.status.idle":"2021-06-16T19:22:21.99505Z","shell.execute_reply.started":"2021-06-16T19:21:52.423961Z","shell.execute_reply":"2021-06-16T19:22:21.993463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\ntrainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\ndata=pd.read_csv(trainCsv)\ndata.ClassId=data.ClassId.astype(int)\n\ntrain_Img_Id = []\ntrain_class_Id = []\nfor i in os.listdir(trainImgPath):\n    for j in range(1,5):\n        train_Img_Id.append(i)\n        train_class_Id.append(j)\ntrain_Imgs = pd.DataFrame({'ImageId':train_Img_Id,'ClassId':train_class_Id})\ntrain_Imgs.head(10)\n ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:21.997432Z","iopub.execute_input":"2021-06-16T19:22:21.997797Z","iopub.status.idle":"2021-06-16T19:22:22.951212Z","shell.execute_reply.started":"2021-06-16T19:22:21.997763Z","shell.execute_reply":"2021-06-16T19:22:22.950302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.merge(train_Imgs,data ,how='outer', on=['ImageId','ClassId']) \ntrain_data = train_data.fillna('') \ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:22.952423Z","iopub.execute_input":"2021-06-16T19:22:22.95287Z","iopub.status.idle":"2021-06-16T19:22:23.016061Z","shell.execute_reply.started":"2021-06-16T19:22:22.952836Z","shell.execute_reply":"2021-06-16T19:22:23.014535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.pivot_table(train_data, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\ntrain_data = train_data.reset_index() # add Index column to one level with classID   \ntrain_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4'] \nhas_defect = []\nstratify = []\nfor index,row in train_data.iterrows():\n    if row.Defect_1 or row.Defect_2 or row.Defect_3 or row.Defect_4: \n        has_defect.append(1)\n    else:\n        has_defect.append(0) \n    if row.Defect_1 != '':\n        stratify.append(1)\n    elif row.Defect_2 != '':\n        stratify.append(2)\n    elif row.Defect_3:\n        stratify.append(3)\n    elif row.Defect_4:\n        stratify.append(4)\n    else:\n        stratify.append(0)\n        \ntrain_data[\"has_defect\"] = has_defect \ntrain_data[\"stratify\"] = stratify \n\ntrain_data.head(5) ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:23.01773Z","iopub.execute_input":"2021-06-16T19:22:23.018032Z","iopub.status.idle":"2021-06-16T19:22:30.896418Z","shell.execute_reply.started":"2021-06-16T19:22:23.018003Z","shell.execute_reply":"2021-06-16T19:22:30.895424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WIDTH=288\nHEIGHT=288\nTRAINING_SIZE=7095\n\nx_train, x_test = train_test_split(train_data, test_size = 0.1, stratify=train_data['stratify'], random_state=42)\nx_train, x_val = train_test_split(x_train, test_size = 0.2, stratify = x_train['stratify'], random_state=42)\nprint(x_train.shape, x_val.shape, x_test.shape) ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:30.899305Z","iopub.execute_input":"2021-06-16T19:22:30.899618Z","iopub.status.idle":"2021-06-16T19:22:30.936129Z","shell.execute_reply.started":"2021-06-16T19:22:30.899587Z","shell.execute_reply":"2021-06-16T19:22:30.934998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_classification = x_train[['ImageId','has_defect']]\nx_val_classification = x_val[['ImageId','has_defect']]\nx_test_classification = x_test[['ImageId','has_defect']] \nprint(x_train_classification.shape , x_val_classification.shape,x_test_classification.shape)\nx_train_classification.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:30.940728Z","iopub.execute_input":"2021-06-16T19:22:30.941002Z","iopub.status.idle":"2021-06-16T19:22:30.961471Z","shell.execute_reply.started":"2021-06-16T19:22:30.940973Z","shell.execute_reply":"2021-06-16T19:22:30.960057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator \ntrain_datagen = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_data_generator = train_datagen.flow_from_dataframe(\n        dataframe=x_train_classification.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=\"has_defect\",\n        target_size=(WIDTH,HEIGHT),\n        batch_size=16,\n        class_mode='binary') \n\nvalid_data_generator = test_datagen.flow_from_dataframe(\n        dataframe=x_val_classification.astype(str),\n        directory=trainImgPath,\n        x_col=\"ImageId\",\n        y_col=\"has_defect\",\n        target_size=(WIDTH,HEIGHT),\n        batch_size=16,\n        class_mode='binary') ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:30.963121Z","iopub.execute_input":"2021-06-16T19:22:30.963561Z","iopub.status.idle":"2021-06-16T19:22:53.417275Z","shell.execute_reply.started":"2021-06-16T19:22:30.963526Z","shell.execute_reply":"2021-06-16T19:22:53.416311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The UNET was developed by Olaf Ronneberger et al.[1] for Bio Medical Image Segmentation. The architecture contains two paths. First path is the contraction path (also called as the encoder) which is used to capture the context in the image. The encoder is just a traditional stack of convolutional and max pooling layers. The second path is the symmetric expanding path (also called as the decoder) which is used to enable precise localization using transposed convolutions. Thus it is an end-to-end fully convolutional network. it only contains Convolutional layers and does not contain any Dense layer because of which it can accept image of any size. \n\n*[1]Ronneberger, O., Fischer, P., & Brox, T. (2015, October). U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention (pp. 234-241). Springer, Cham.*\n\n![unet](https://pubs.rsc.org/image/article/2020/ra/c9ra05877j/c9ra05877j-f1_hi-res.gif)","metadata":{}},{"cell_type":"code","source":"Classification_Model = keras.applications.xception.Xception(include_top = False, input_shape = (HEIGHT,WIDTH,3))\n\nlayer = Classification_Model.output\nlayer = GlobalAveragePooling2D()(layer)\n\nlayer = Dense(1024, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(512, activation='relu')(layer)\nlayer = BatchNormalization()(layer)\nlayer = Dropout(0.3)(layer)\n\nlayer = Dense(64, activation='relu')(layer)\npredictions = Dense(1, activation='sigmoid')(layer)\nmodel = Model(inputs=Classification_Model.input, outputs=predictions)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:53.418742Z","iopub.execute_input":"2021-06-16T19:22:53.419061Z","iopub.status.idle":"2021-06-16T19:22:56.795112Z","shell.execute_reply.started":"2021-06-16T19:22:53.419029Z","shell.execute_reply":"2021-06-16T19:22:56.79345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nTraining = model.fit_generator(train_data_generator, validation_data = valid_data_generator, epochs = 30, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:22:56.797088Z","iopub.execute_input":"2021-06-16T19:22:56.797515Z","iopub.status.idle":"2021-06-16T19:23:59.14644Z","shell.execute_reply.started":"2021-06-16T19:22:56.79748Z","shell.execute_reply":"2021-06-16T19:23:59.144152Z"},"trusted":true},"execution_count":null,"outputs":[]}]}