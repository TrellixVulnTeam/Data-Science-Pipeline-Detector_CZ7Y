{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Code for masking defects in steel**\n* Code is pretty much same as my previous notebook except here i am using Densenet instead of Unet"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D,Dropout,Concatenate,Conv2DTranspose\nfrom keras.utils import Sequence\nfrom sklearn.utils import shuffle\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport keras.applications as KA\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,TensorBoard\nfrom albumentations import (\n    PadIfNeeded,\n    HorizontalFlip,\n    VerticalFlip,    \n    CenterCrop,    \n    Crop,\n    Compose,\n    Transpose,\n    RandomRotate90,\n    ElasticTransform,\n    GridDistortion, \n    OpticalDistortion,\n    RandomSizedCrop,\n    OneOf,\n    CLAHE,\n    RandomBrightnessContrast,    \n    RandomGamma    \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_path='../input/severstal-steel-defect-detection/train.csv'\ntest_df_path='../input/severstal-steel-defect-detection/sample_submission.csv'\ntrain_img_path='../input/severstal-steel-defect-detection/train_images/'\ntest_img_path='../input/severstal-steel-defect-detection/test_images/'\nmodel_path='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=32\nHEIGHT,WIDTH=128,128\nEPOCHS=8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train data\ntrain_df=pd.read_csv(train_df_path)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ImageId_ClassId']=[train_img_path+ix for ix in train_df['ImageId_ClassId']]\n#Fill Empty Encoding with 0\ntrain_df['EncodedPixels'].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create list of list containing image index with their respective encoding\ntrain_data=[]\nfor ix in tqdm(range(0,train_df.shape[0],4)):\n    tmp=[]\n    tmp.append(train_df.loc[ix,'ImageId_ClassId'].split('_')[0]+'_'+train_df.loc[ix,'ImageId_ClassId'].split('_')[1])\n    for j in range(ix,ix+4):\n        tmp.append(train_df.loc[j,'EncodedPixels'])\n    train_data.append(tmp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RLE to Mask Converter** [https://www.kaggle.com/robertkag/rle-to-mask-converter](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rleToMask(rleString,height,width,h,w,resize=False):\n    rows,cols = height,width\n    rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n    rlePairs = np.array(rleNumbers).reshape(-1,2)\n    img = np.zeros(rows*cols,dtype=np.float32)\n    for index,length in rlePairs:\n        index -= 1\n        img[index:index+length] = 1.0\n    img = img.reshape(cols,rows)\n    img = img.T\n    if resize:\n        img=cv2.resize(img,(h,w))\n    return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot Some samples**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Image Plotting Along with masks\nclass_color=['Reds','Blues','Greens','Oranges']\nh,w=256,1600\nfig=plt.figure(figsize=(12,12))\nrows,cols=6,1\nfor i in range(1,rows*cols+1):\n    img=cv2.imread(train_data[i-1][0])\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    fig.add_subplot(rows,cols,i)\n    plt.imshow(img)\n    for j in range(4):\n        msk_encode=train_data[i-1][j+1]\n        if msk_encode==0:\n            continue\n        else:\n            mask=rleToMask(msk_encode,256,1600,256,256)\n            plt.imshow(img,cmap='gray')\n            plt.imshow(mask,cmap=class_color[j],alpha=0.2)            \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train,val=train_test_split(train_data,test_size=0.15,random_state=13)\nprint('Train Size: {}'.format(len(train)))\nprint('Val Size: {}'.format(len(val)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**index Seperator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sep_indexes(indexes_):\n    img_tmp=[]\n    mask_tmp=[]\n    for ix in indexes_:\n        img_tmp.append(ix[0])\n        mask_tmp.append(ix[1:])\n    return img_tmp,mask_tmp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AUGMENTATION FUNCTION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def aug_fx(image,mask):\n    aug = PadIfNeeded(p=1, min_height=HEIGHT, min_width=WIDTH)\n    augmented = aug(image=image, mask=mask)\n    \n    aug = CenterCrop(p=1, height=HEIGHT, width=WIDTH)\n    augmented = aug(image=augmented['image'], mask=augmented['mask'])\n    \n    aug = HorizontalFlip(p=1)\n    augmented = aug(image=augmented['image'], mask=augmented['mask'])\n    \n    aug = VerticalFlip(p=1)\n    augmented = aug(image=augmented['image'], mask=augmented['mask'])\n    \n    aug = Transpose(p=1)\n    augmented = aug(image=augmented['image'], mask=augmented['mask'])\n    \n    aug = RandomRotate90(p=1)\n    augmented = aug(image=augmented['image'], mask=augmented['mask'])\n    \n    aug = GridDistortion(p=1)\n    augmented = aug(image=augmented['image'], mask=augmented['mask'])    \n    \n    return augmented['image'],augmented['mask']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DataGenerator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class customGenerator(Sequence):\n    def __init__(self,data_list,batch_size,height,width,is_train=True):\n        self.indexes,self.mask_ids=sep_indexes(data_list)\n        self.batch_size=batch_size\n        self.height=height\n        self.width=width\n        self.is_train=is_train\n    \n    def __len__(self):\n        return int(np.ceil(len(self.indexes)/self.batch_size))\n    \n    def __getitem__(self,idx):\n        batch_x=self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n        batch_y=self.mask_ids[idx*self.batch_size:(idx+1)*self.batch_size]\n        if self.is_train:\n            return self.train_generator(batch_x,batch_y)\n        else:\n            return self.val_generator(batch_x,batch_y)\n    \n    def on_epoch_end(self):\n        if(self.is_train):\n            self.indexes,self.mask_ids = shuffle(self.indexes,self.mask_ids)\n        else:\n            pass\n    \n    def load_images(self,img_ids):\n        tmp=np.zeros((len(img_ids),self.height,self.width,3))\n        for ix,id_ in enumerate(img_ids):\n            img=cv2.imread(id_)\n            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n            img=img.astype(np.float32) / 255.\n            img=cv2.resize(img,(self.height,self.width))\n            #img=np.expand_dims(img,-1)\n            tmp[ix]=img\n        return tmp\n    \n    def load_masks(self,mask_ids_):\n        tmp=np.zeros((len(mask_ids_),self.height,self.width,4))\n        for ix,enc in enumerate(mask_ids_):\n            for j,enc_ in enumerate(enc):\n                if enc_==0:\n                    continue\n                else:\n                    mask=rleToMask(enc_,256,1600,self.height,self.width,resize=True)\n                    tmp[ix,:,:,j]=mask\n        return tmp\n    \n    def train_generator(self,batch_x,batch_y):\n        image_batch=self.load_images(batch_x)\n        mask_batch=self.load_masks(batch_y)\n        \n        #Augmentation\n        for ix in range(len(image_batch)):\n            image_batch[ix],mask_batch[ix]=aug_fx(image_batch[ix],mask_batch[ix])\n            \n        return image_batch,mask_batch\n    \n    def val_generator(self,batch_x,batch_y):\n        image_batch=self.load_images(batch_x)\n        mask_batch=self.load_masks(batch_y)\n        return image_batch,mask_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen=customGenerator(train,BATCH_SIZE,HEIGHT,WIDTH)\nval_gen=customGenerator(val,BATCH_SIZE,HEIGHT,WIDTH,is_train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MODEL-Densenet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.densenet import DenseNet121\nbase_model=DenseNet121(weights=model_path,input_shape=(128,128,3),include_top=False)\nx=UpSampling2D(16)(base_model.output)\nx=Conv2D(64,(3,3),strides=1,activation='relu',padding='same')(x)\nx=UpSampling2D(2)(x)\nx=Conv2D(32,(3,3),strides=1,activation='relu',padding='same')(x)\nout = Conv2D(4, 1, activation = 'sigmoid')(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(base_model.input,out)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer=Adam(0.0001),metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps=int(np.ceil(len(train)/BATCH_SIZE))\nval_steps=int(np.ceil(len(val)/BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc=ModelCheckpoint('seg_model.h5',monitor='val_loss',mode='min',save_best_only=True,period=1,verbose=1)\nrop=ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=2,min_lr=0.0000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit_generator(train_gen,epochs=EPOCHS,steps_per_epoch=train_steps,\n                    validation_data=val_gen,validation_steps=val_steps,use_multiprocessing=True,callbacks=[mc,rop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'b',color='green', label='Training loss')\nplt.plot(epochs, val_loss, 'b', color='red',label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\ndc = history.history['dice_coef']\nval_dc = history.history['val_dice_coef']\nplt.plot(epochs, dc, 'b',color='green', label='Training Dice Coef.')\nplt.plot(epochs, val_dc, 'b', color='red',label='Validation Dice Coef.')\nplt.title('Training and validation Dice Coef.')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_testdata(a):\n\n    data = []\n    c = 1\n\n    for i in range(a.shape[0]-1):\n        if a[i]+1 == a[i+1]:\n            c += 1\n            if i == a.shape[0]-2:\n                data.append(str(a[i-c+2]))\n                data.append(str(c))\n\n        if a[i]+1 != a[i+1]:\n            data.append(str(a[i-c+1]))\n            data.append(str(c))\n            c = 1\n\n    data = \" \".join(data)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test Images\ntest_df=pd.read_csv(test_df_path)\nmodel.load_weights('seg_model.h5')\n\nenc_masks=[]\nfor ix in tqdm(range(0,test_df.shape[0],4)):\n    img_ix=test_df.loc[ix,'ImageId_ClassId']\n    img_ix=img_ix.split('_')[0]\n    img=cv2.imread(os.path.join(test_img_path,img_ix))\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    img=img.astype(np.float32) / 255.\n    img=cv2.resize(img,(HEIGHT,WIDTH))\n    #img=np.expand_dims(img,-1)\n    img=np.expand_dims(img,0)\n    pred_mask=model.predict(img)\n    pred_mask=cv2.resize(pred_mask[0],(1600,256))\n    for i in range(4):\n        pred_fi = pred_mask[:,:,i].T.flatten()\n        pred_fi = np.where(pred_fi > 0.5, 1, 0)\n        pred_fi_id = np.where(pred_fi == 1)\n        pred_fi_id = make_testdata(pred_fi_id[0])\n        x = [img_ix + \"_\" + str(i+1), pred_fi_id]\n        enc_masks.append(x)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['ImageId_ClassId', 'EncodedPixels']\nd = pd.DataFrame(data=enc_masks, columns=columns, dtype='str')\nd.to_csv(\"submission.csv\",index=False)\nprint(d)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}