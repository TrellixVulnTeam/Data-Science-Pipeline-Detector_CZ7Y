{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we propose to solve the problem of steel defection detection using U-Net famous architechture. In this first notebook, we will train a U-Net model. The output of this notebook is the wieghts of the model that will be used in the second notebook in order to make submission.\n\nWe use the pretrained U-Net model from https://github.com/qubvel/segmentation_models.pytorch. Due to the fact that Internet is not allowed in this competition, we will create a kaggle Dataset from this repo, and we will install it via pip. It is to not that we need to install https://github.com/Cadene/pretrained-models.pytorch manually becaus internet is not allowed."},{"metadata":{},"cell_type":"markdown","source":"## Installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install \"../input/pretrainedmodelspytorch/\" > /dev/null\n!pip install \"../input/segmentation-models-dataset\" > /dev/null\n!pip install -U catalyst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch, catalyst\n\ntorch.__version__, catalyst.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\n\nimport segmentation_models_pytorch as smp\nimport albumentations as albu\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"ENCODER = 'se_resnext50_32x4d'\n# ENCODER = 'inceptionresnetv2'\n# ENCODER = 'dpn98'\nENCODER_WEIGHTS = 'imagenet'\nDEVICE = \"cuda\"\nACTIVATION = 'sigmoid'\n\ndevice = torch.device(DEVICE)\nnum_epochs = 10\n\nlogdir = \"../logs/segmentation\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper Fucntions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_img(x, folder: str='train_images'):\n    \"\"\"\n    Return image based on image name and folder.\n    \"\"\"\n    data_folder = f\"{path}/{folder}\"\n    image_path = os.path.join(data_folder, x)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef rle_decode(mask_rle: str = '', shape: tuple = (256, 1600)):\n    '''\n    Decode rle encoded mask.\n    \n    :param mask_rle: run-length as string formatted (start length)\n    :param shape: (height, width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n\n\ndef make_mask(df, row_id, shape: tuple = (256, 1600)):\n    \"\"\"\n    Create mask based on df, image name and shape.\n    \"\"\"\n    encoded_masks = df.iloc[row_id]\n    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n\n    for idx, label in enumerate(encoded_masks.values):\n        if label is not np.nan:\n            mask = rle_decode(label)\n            masks[:, :, idx] = mask\n            \n    return masks\n\n\ndef to_tensor(x, **kwargs):\n    \"\"\"\n    Convert image or mask.\n    \"\"\"\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef mask2rle(img):\n    '''\n    Convert mask to rle.\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n        \ndef post_process(probability, threshold, min_size):\n    \"\"\"\n    Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored\n    \"\"\"\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((350, 525), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num\n\n\ndef get_training_augmentation():\n    train_transform = [\n\n        albu.HorizontalFlip(p=0.5),\n        # albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0),\n        # albu.GridDistortion(p=0.5),\n        # albu.OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n        # albu.Resize(320, 640)\n    ]\n    return albu.Compose(train_transform)\n\n\ndef get_validation_augmentation():\n    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n    test_transform = [\n        albu.HorizontalFlip(p=0.0)\n    ]\n    return albu.Compose(test_transform)\n\n\ndef get_preprocessing(preprocessing_fn):\n    \"\"\"Construct preprocessing transform\n    \n    Args:\n        preprocessing_fn (callbale): data normalization function \n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n    \n    \"\"\"\n    \n    _transform = [\n        albu.Lambda(image=preprocessing_fn),\n        albu.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return albu.Compose(_transform)\n\n\ndef dice(img1, img2):\n    img1 = np.asarray(img1).astype(np.bool)\n    img2 = np.asarray(img2).astype(np.bool)\n\n    intersection = np.logical_and(img1, img2)\n\n    return 2. * intersection.sum() / (img1.sum() + img2.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I/- Explore Dataset"},{"metadata":{},"cell_type":"markdown","source":"## 1) Create Dataset and DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SteelDefectionDataset(Dataset):\n    def __init__(self, df, datatype: str = 'train', transforms = None, preprocessing=None):\n        self.df = df\n        \n        self.img_ids = list(df.index)\n        \n        if datatype != 'test':\n            self.data_folder = \"../input/severstal-steel-defect-detection/train_images/\"\n        else:\n            self.data_folder = \"../input/severstal-steel-defect-detection/test_images\"\n        \n        self.transforms = transforms\n        self.preprocessing = preprocessing\n\n    def __getitem__(self, idx):\n        image_name = self.img_ids[idx]\n        mask = make_mask(self.df, idx)\n        image_path = os.path.join(self.data_folder, image_name)\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']\n        mask = augmented['mask']\n        \n        if self.preprocessing:\n            preprocessed = self.preprocessing(image=img, mask=mask)\n            return preprocessed\n        else:\n            return augmented\n\n    def __len__(self):\n        return len(self.img_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/severstal-steel-defect-detection/train.csv\")\n# https://www.kaggle.com/amanooo/defect-detection-starter-u-net\ndf['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\ndf['ClassId'] = df['ClassId'].astype(int)\ndf = df.pivot(index='ImageId', columns='ClassId', values='EncodedPixels')\ndf['defects'] = df.count(axis=1)\ndf = df[df['defects'] > 0]\n\ntrain, valid = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n\ntrain = train.drop(columns=[\"defects\"])\nvalid = valid.drop(columns=[\"defects\"])\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n\ntrain_dataset = SteelDefectionDataset(df=train, datatype='train', \n                                      transforms = get_training_augmentation(),\n                                      preprocessing=get_preprocessing(preprocessing_fn))\n\nvalid_dataset = SteelDefectionDataset(df=valid, datatype='val', \n                                      transforms = get_validation_augmentation(),\n                                      preprocessing=get_preprocessing(preprocessing_fn))\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n\nloaders = {\n    \"train\": train_loader,\n    \"valid\": valid_loader\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Visualise Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"to_show_dataset = SteelDefectionDataset(df=train, datatype='train',\n                                       transforms=get_training_augmentation())\n\nfor ii in range(5):\n    idx = np.random.randint(len(to_show_dataset))\n    sample =  to_show_dataset[idx]\n    image, masks = sample['image'], sample['mask']\n    f, ax = plt.subplots(1, 5, figsize=(24, 24))\n\n    ax[0].imshow(image)\n    for i in range(4):\n        ax[i + 1].imshow(masks[:, :, i])\n        ax[i + 1].set_title(f'Mask {i}', fontsize=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II/-Train the Model"},{"metadata":{},"cell_type":"markdown","source":"## 1) Create the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom catalyst.contrib.criterion import DiceLoss, IoULoss\nfrom catalyst.dl import SupervisedRunner\n\n\nmodel = torch.load(\"../input/fpn-se-resnet50-epoch20/fpn_se_resnext50_32x4d.pth\")\n# model = smp.FPN(encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS,  classes=4, activation=ACTIVATION)\n# model = smp.Unet(encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS,  classes=4, activation=ACTIVATION)\n\ncriterion = {\n    \"dice\": DiceLoss(),\n    \"iou\": IoULoss(),\n    \"bce\": nn.BCEWithLogitsLoss()\n}\n\n# Create optimizer\noptimizer = torch.optim.Adam([\n    {'params': model.decoder.parameters(), 'lr': 1e-5}, \n    \n    # decrease lr for encoder in order not to permute \n    # pre-trained weights with large gradients on training start\n    {'params': model.encoder.parameters(), 'lr': 1e-6},  \n])\n\n\nscheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=3, verbose=True)\n\nrunner = SupervisedRunner(device=device, input_key=\"image\", input_target_key=\"mask\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Launch Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catalyst.dl.callbacks import DiceCallback, IouCallback, CriterionCallback, CriterionAggregatorCallback\n\n\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    \n    # our dataloaders\n    loaders=loaders,\n    \n    callbacks=[\n        # Each criterion is calculated separately.\n        CriterionCallback(\n            input_key=\"mask\",\n            prefix=\"loss_dice\",\n            criterion_key=\"dice\"\n        ),\n        CriterionCallback(\n            input_key=\"mask\",\n            prefix=\"loss_iou\",\n            criterion_key=\"iou\"\n        ),\n        CriterionCallback(\n            input_key=\"mask\",\n            prefix=\"loss_bce\",\n            criterion_key=\"bce\",\n            multiplier=0.8\n        ),\n        \n        # And only then we aggregate everything into one loss.\n        CriterionAggregatorCallback(\n            prefix=\"loss\",\n            loss_keys=[\"loss_dice\", \"loss_iou\", \"loss_bce\"],\n            loss_aggregate_fn=\"sum\" # or \"mean\"\n        ),\n        \n        # metrics\n        DiceCallback(input_key=\"mask\"),\n        IouCallback(input_key=\"mask\"),\n    ],\n    \n    # path to save logs\n    logdir=logdir,\n    \n    num_epochs=num_epochs,\n    \n    # save our best checkpoint by IoU metric\n    main_metric=\"iou\",\n    # IoU needs to be maximized.\n    minimize_metric=False,  \n    # prints train logs\n    verbose=True\n)\n\ntorch.save(model, './best_model.pth')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}