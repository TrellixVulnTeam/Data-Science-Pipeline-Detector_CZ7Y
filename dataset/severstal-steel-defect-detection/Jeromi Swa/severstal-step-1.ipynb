{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import os\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd  \n\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam, Nadam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_folder = os.path.join('/kaggle/input','/severstal-steel-defect-detection/train_images')\ntest_folder = os.path.join('/kaggle/input','/severstal-steel-defect-detection/test_images')\n\ntrain_images_set = set()\ntest_images_set = set()\n\ncount=0\nfor dirname, _, filenames in os.walk('/kaggle/input/severstal-steel-defect-detection'):\n    count=0\n    for filename in filenames:\n        count+=1\n        if dirname == '/kaggle/input/severstal-steel-defect-detection/train_images':\n            train_images_set.add(filename)\n        if dirname == '/kaggle/input/severstal-steel-defect-detection/test_images':\n            test_images_set.add(filename)\n\n    if dirname == '/kaggle/input/severstal-steel-defect-detection/train_images':\n        no_train_images = count\n        print(dirname)\n        print(\"no_train_images >\", count)\n    if dirname == '/kaggle/input/severstal-steel-defect-detection/test_images':\n        no_test_images = count\n        print(dirname)\n        print(\"no_test_images >\", count)\n        \n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Importing the DataSet</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv').sort_values(by=['ImageId'])\nsubmission_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\n\nprint(\"train_df Shape (Summation of 'no_defect_class_for_image_i' from image i to j):\", train_df.shape, \"\\nsubmission_df Shape:\", submission_df.shape)\ndisplay(train_df.head()) # Summation of \"no_defect_class_for_image_i\" from image i to j\ndisplay(submission_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_have_defects_set = set(train_df['ImageId'].unique())\ntrain_images_no_defects_set = train_images_set - train_images_have_defects_set\nno_unique_train_images_no_defects = len(train_images_no_defects_set)\ntest_images_set = set(submission_df['ImageId'].unique())\n\nprint(\"Number of images in train_df that have defects >>>\", len(train_images_have_defects_set), \"\\nsubmission_df unique >>>\", len(test_images_set))\nprint(\"\\nTotal no of train images >>>\", no_train_images)\nprint(\"Therefore, Number of images that have no defects >>>\", str(no_unique_train_images_no_defects))\ntrain_images_have_defects_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_no_defects_df = pd.DataFrame({\"ImageId\" : list(train_images_no_defects_set)})\ntrain_images_no_defects_df['allMissing'] = 1\ntrain_images_have_defects_df = pd.DataFrame({\"ImageId\" : list(train_images_have_defects_set)})\ntrain_images_have_defects_df['allMissing'] = 0\nframes = [train_images_no_defects_df, train_images_have_defects_df]\ntrain_nan_df = pd.concat(frames, ignore_index=True)\n\nprint(train_nan_df.shape)\ndisplay(train_nan_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\ntest_nan_df = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ndisplay(test_nan_df.head())\ntest_nan_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img(code, base, resize=True):\n    path = f'{base}/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../tmp/train'\nvalidate_path(train_path)\n\nfor code in tqdm(train_nan_df['ImageId']):\n    img = load_img(\n        code,\n        base='/kaggle/input/severstal-steel-defect-detection/train_images'\n    )\n    path = code.replace('.jpg', '')\n    cv2.imwrite(f'{train_path}/{path}.png', img)\n    \ntrain_nan_df['ImageId'] = train_nan_df['ImageId'].apply(\n    lambda x: x.replace('.jpg', '.png')\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nVALIDATION_SPLIT = 0.15\n\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.1,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,\n        rotation_range=10,\n        height_shift_range=0.1,\n        width_shift_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        rescale=1/255.,\n        validation_split=VALIDATION_SPLIT\n    )\n\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_nan_df,\n        directory='../input/severstal-steel-defect-detection/test_images/',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ndef create_flow(datagen, subset):\n    return datagen.flow_from_dataframe(\n        train_nan_df, \n        directory=train_path,\n        x_col='ImageId', \n        y_col='allMissing', \n        class_mode='raw',\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        subset=subset\n    )\n\n# Using original generator\ndata_generator = create_datagen()\ntrain_gen = create_flow(data_generator, 'training')\nval_gen = create_flow(data_generator, 'validation')\ntest_gen = create_test_gen()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    densenet = DenseNet121(\n        include_top=False,\n        input_shape=(256,256,3),\n        weights='/kaggle/input/keras-pretrain-model-weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    )\n    \n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Nadam(),\n        metrics=['accuracy', f1_m, precision_m, recall_m]\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_steps = train_nan_df.shape[0] / BATCH_SIZE\n\ncheckpoint = ModelCheckpoint(\n    '../tmp/model.h5', \n    monitor='val_accuracy', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=5,\n    verbose=1,\n    min_lr=0.5e-6\n)\n\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch=total_steps * 0.85,\n    validation_data=val_gen,\n    validation_steps=total_steps * 0.15,\n    epochs=60,\n    callbacks=[checkpoint, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.to_csv('history.csv', index=False)\ndisplay(history_df)\nhistory_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../tmp/dense121_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('../tmp/dense121_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df[['lr']].plot()\nplt.title('Model Learning Rate')\nplt.ylabel('Learning Rate')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df[['loss', 'val_loss']].plot()\nplt.title('Model loss')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_nan_df['allMissing'] = y_test\n\ntrain_nan_df.to_csv('train_missing_count.csv', index=False)\ntest_nan_df.to_csv('test_missing_count.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df[['accuracy', 'val_accuracy']].plot()\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df[['f1_m', 'val_f1_m']].plot()\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df[['precision_m', 'val_precision_m']].plot()\nplt.title('Model precision')\nplt.ylabel('Precision')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df[['recall_m', 'val_recall_m']].plot()\nplt.title('Model recall')\nplt.ylabel('Recall')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\n\ndef recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All Images will be Rescaled by 1./255. We Apply Data Augmentation Here.\ntrain_datagen = ImageDataGenerator(rotation_range=40,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   rescale=1./255,\n                                   shear_range=0.1,\n                                   zoom_range=0.1,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 16 \nimg_size = (256, 512)\n\ntrain_gen = train_datagen.flow_from_directory(\n    directory=train_folder,\n    target_size=img_size,\n    batch_size=bs,\n    class_mode='binary'\n)\n\ntest_gen = test_datagen.flow_from_directory(\n    directory=val_folder,\n    target_size=img_size,\n    batch_size=bs,\n    class_mode='binary'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import DenseNet121\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Flatten, Dense, Dropout, BatchNormalization\n\ndef buildModel1():\n  dense_net = DenseNet121(\n      include_top=False,\n      input_shape=(256, 512, 3), # (width, height, colorchannel)\n      weights='/kaggle/input/keras-pretrain-model-weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n  )\n\n  model = Sequential()\n  model.add(dense_net)\n  model.add(GlobalAveragePooling2D())\n  model.add(BatchNormalization())\n  model.add(Dropout(0.5))\n  model.add(Dense(512, activation='relu'))\n  model.add(BatchNormalization())\n  model.add(Dropout(0.5))\n  model.add(Dense(1, activation='sigmoid'))\n\n  model.compile(\n      loss='binary_crossentropy',\n      optimizer='adam',\n      metrics=['accuracy', f1_m, precision_m, recall_m]\n  )\n\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = buildModel1().fit_generator(\n          train_gen, # train generator has 12568 train images but we are not using all of them\n          steps_per_epoch=786, # training 12568 images = 786 steps x 16 images per batch\n          epochs=25,\n          validation_data=test_gen, # validation generator has 5,000 validation images\n          validation_steps=158 # validating on 2514 images = 158 steps x 16 images per batch\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}