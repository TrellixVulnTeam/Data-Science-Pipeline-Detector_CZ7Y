{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-03-11T01:55:39.991458Z","iopub.status.busy":"2021-03-11T01:55:39.990631Z","iopub.status.idle":"2021-03-11T01:55:47.869779Z","shell.execute_reply":"2021-03-11T01:55:47.868422Z"},"papermill":{"duration":7.910853,"end_time":"2021-03-11T01:55:47.870059","exception":false,"start_time":"2021-03-11T01:55:39.959206","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021717,"end_time":"2021-03-11T01:55:47.914206","exception":false,"start_time":"2021-03-11T01:55:47.892489","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:55:47.964861Z","iopub.status.busy":"2021-03-11T01:55:47.964193Z","iopub.status.idle":"2021-03-11T01:55:48.006343Z","shell.execute_reply":"2021-03-11T01:55:48.006904Z"},"papermill":{"duration":0.070958,"end_time":"2021-03-11T01:55:48.007078","exception":false,"start_time":"2021-03-11T01:55:47.93612","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nprint(submission_df.shape)\nsubmission_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:55:48.061439Z","iopub.status.busy":"2021-03-11T01:55:48.060429Z","iopub.status.idle":"2021-03-11T01:55:48.071618Z","shell.execute_reply":"2021-03-11T01:55:48.072512Z"},"papermill":{"duration":0.042417,"end_time":"2021-03-11T01:55:48.072723","exception":false,"start_time":"2021-03-11T01:55:48.030306","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"unique_test_images = submission_df['ImageId'].unique()\nlen(unique_test_images)\ntest_df = pd.DataFrame(unique_test_images, columns=['ImageId'])\nprint(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:55:48.125102Z","iopub.status.busy":"2021-03-11T01:55:48.12419Z","iopub.status.idle":"2021-03-11T01:55:48.127716Z","shell.execute_reply":"2021-03-11T01:55:48.12704Z"},"papermill":{"duration":0.031171,"end_time":"2021-03-11T01:55:48.127871","exception":false,"start_time":"2021-03-11T01:55:48.0967","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"TEST_PATH = '../input/severstal-steel-defect-detection/test_images/'\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:55:48.180626Z","iopub.status.busy":"2021-03-11T01:55:48.179721Z","iopub.status.idle":"2021-03-11T01:55:48.182604Z","shell.execute_reply":"2021-03-11T01:55:48.183205Z"},"papermill":{"duration":0.031542,"end_time":"2021-03-11T01:55:48.183369","exception":false,"start_time":"2021-03-11T01:55:48.151827","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nIMAGE_SIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:55:48.256512Z","iopub.status.busy":"2021-03-11T01:55:48.252332Z","iopub.status.idle":"2021-03-11T01:56:04.116375Z","shell.execute_reply":"2021-03-11T01:56:04.11558Z"},"papermill":{"duration":15.907514,"end_time":"2021-03-11T01:56:04.116578","exception":false,"start_time":"2021-03-11T01:55:48.209064","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submit_test_gen = ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_df,\n        directory='../input/severstal-steel-defect-detection/test_images/',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:56:04.196305Z","iopub.status.busy":"2021-03-11T01:56:04.195405Z","iopub.status.idle":"2021-03-11T01:57:41.821548Z","shell.execute_reply":"2021-03-11T01:57:41.822557Z"},"papermill":{"duration":97.670899,"end_time":"2021-03-11T01:57:41.822764","exception":false,"start_time":"2021-03-11T01:56:04.151865","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model = load_model('../input/severstaldensenetmodel/CNNDenseNet2classes.h5_20210309')\n\nimport math\n# We take the ceiling because we do not drop the remainder of the batch\ncompute_steps_per_epoch = lambda x: int(math.ceil(1. * x / BATCH_SIZE))\n\nSTEP_SIZE_TEST = compute_steps_per_epoch(test_df.shape[0])\nprint('predicting...')\n\nsubmit_test = model.predict(\n    submit_test_gen,\n    steps=STEP_SIZE_TEST,\n    verbose=1\n)\n\ntest_df['defect_label'] = (submit_test > 0.5).astype(\"int32\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:57:42.015628Z","iopub.status.busy":"2021-03-11T01:57:42.014473Z","iopub.status.idle":"2021-03-11T01:57:42.022504Z","shell.execute_reply":"2021-03-11T01:57:42.021806Z"},"papermill":{"duration":0.107002,"end_time":"2021-03-11T01:57:42.022646","exception":false,"start_time":"2021-03-11T01:57:41.915644","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"cell_type":"code","source":"test_df.defect_label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:57:42.217122Z","iopub.status.busy":"2021-03-11T01:57:42.21634Z","iopub.status.idle":"2021-03-11T01:57:42.247821Z","shell.execute_reply":"2021-03-11T01:57:42.247081Z"},"papermill":{"duration":0.130903,"end_time":"2021-03-11T01:57:42.248011","exception":false,"start_time":"2021-03-11T01:57:42.117108","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test_df_defect =  test_df[test_df['defect_label'] == 1].copy()\ntest_df_defect.shape","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:57:42.44394Z","iopub.status.busy":"2021-03-11T01:57:42.442504Z","iopub.status.idle":"2021-03-11T01:57:42.4505Z","shell.execute_reply":"2021-03-11T01:57:42.451095Z"},"papermill":{"duration":0.108973,"end_time":"2021-03-11T01:57:42.451263","exception":false,"start_time":"2021-03-11T01:57:42.34229","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test_df_noDefect =  test_df[test_df['defect_label'] == 0].copy()\ntest_df_noDefect.shape","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.094433,"end_time":"2021-03-11T01:57:42.640637","exception":false,"start_time":"2021-03-11T01:57:42.546204","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Functions"},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:57:42.898307Z","iopub.status.busy":"2021-03-11T01:57:42.897177Z","iopub.status.idle":"2021-03-11T01:57:42.92652Z","shell.execute_reply":"2021-03-11T01:57:42.92732Z"},"papermill":{"duration":0.182126,"end_time":"2021-03-11T01:57:42.927577","exception":false,"start_time":"2021-03-11T01:57:42.745451","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:57:43.223484Z","iopub.status.busy":"2021-03-11T01:57:43.222354Z","iopub.status.idle":"2021-03-11T01:57:43.241178Z","shell.execute_reply":"2021-03-11T01:57:43.242455Z"},"papermill":{"duration":0.18029,"end_time":"2021-03-11T01:57:43.242701","exception":false,"start_time":"2021-03-11T01:57:43.062411","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=3,\n                 n_classes=4, random_state=2021, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name].copy().reset_index()\n\n            masks = np.zeros((*self.dim, self.n_classes))\n            \n            for j in range(len(image_df)):\n                rle = image_df.loc[j,'EncodedPixels']\n                cls =  image_df.loc[j,'ClassId']\n                masks[:, :, cls-1] = rle2mask(rle, self.dim)\n    \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:57:43.51755Z","iopub.status.busy":"2021-03-11T01:57:43.515619Z","iopub.status.idle":"2021-03-11T01:57:43.518291Z","shell.execute_reply":"2021-03-11T01:57:43.518818Z"},"papermill":{"duration":0.136962,"end_time":"2021-03-11T01:57:43.519004","exception":false,"start_time":"2021-03-11T01:57:43.382042","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.09505,"end_time":"2021-03-11T01:57:43.709278","exception":false,"start_time":"2021-03-11T01:57:43.614228","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Load Model"},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-03-11T01:57:43.90639Z","iopub.status.busy":"2021-03-11T01:57:43.905589Z","iopub.status.idle":"2021-03-11T01:57:44.706477Z","shell.execute_reply":"2021-03-11T01:57:44.705784Z"},"papermill":{"duration":0.901304,"end_time":"2021-03-11T01:57:44.706638","exception":false,"start_time":"2021-03-11T01:57:43.805334","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dependencies = {\n    'dice_coef': dice_coef\n}\n\nmodel = load_model('../input/severstal-segmentation-unetxception-20210312/Segmentation_UnetXception_20210312.h5', custom_objects=dependencies )","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-03-11T01:57:44.911591Z","iopub.status.busy":"2021-03-11T01:57:44.910621Z","iopub.status.idle":"2021-03-11T01:59:43.371262Z","shell.execute_reply":"2021-03-11T01:59:43.370455Z"},"papermill":{"duration":118.568068,"end_time":"2021-03-11T01:59:43.371463","exception":false,"start_time":"2021-03-11T01:57:44.803395","status":"completed"},"scrolled":false,"tags":[],"trusted":true},"cell_type":"code","source":"df = []\nstep = 300\n\nfor i in range(0, test_df_defect.shape[0], step):\n    batch_idx = list(\n        range(i, min(test_df_defect.shape[0], i + step))\n    )\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_df_defect,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        target_df=test_df_defect,\n        batch_size=1,\n        n_classes=4\n    )\n    \n    batch_pred_masks = model.predict(\n        test_generator, \n        verbose=1,\n        )\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = test_df_defect['ImageId'].iloc[b]\n      \n        data = {'ImageId':  [filename, filename, filename, filename],\n        'ClassId': [1,2,3,4],\n        'EncodedPixels': ['','','','' ]\n        }\n        image_df = pd.DataFrame(data, columns = ['ImageId','ClassId','EncodedPixels'])\n\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n        for i in range(4):\n            image_df.loc[i,'EncodedPixels'] = pred_rles[i]\n        \n        df.append(image_df)\n\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.648055,"end_time":"2021-03-11T01:59:44.637773","exception":false,"start_time":"2021-03-11T01:59:43.989718","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Submission"},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:59:45.739713Z","iopub.status.busy":"2021-03-11T01:59:45.713954Z","iopub.status.idle":"2021-03-11T01:59:46.861905Z","shell.execute_reply":"2021-03-11T01:59:46.86248Z"},"papermill":{"duration":1.701762,"end_time":"2021-03-11T01:59:46.862667","exception":false,"start_time":"2021-03-11T01:59:45.160905","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df = pd.concat(df)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:59:47.924231Z","iopub.status.busy":"2021-03-11T01:59:47.923183Z","iopub.status.idle":"2021-03-11T01:59:47.928172Z","shell.execute_reply":"2021-03-11T01:59:47.927453Z"},"papermill":{"duration":0.54331,"end_time":"2021-03-11T01:59:47.928311","exception":false,"start_time":"2021-03-11T01:59:47.385001","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df.head(30)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.524141,"end_time":"2021-03-11T01:59:48.976571","exception":false,"start_time":"2021-03-11T01:59:48.45243","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Now, we combine results from the predicted masks with the rest of images that our first CNN classified as having all 4 masks missing."},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:59:50.048383Z","iopub.status.busy":"2021-03-11T01:59:50.047349Z","iopub.status.idle":"2021-03-11T01:59:50.052138Z","shell.execute_reply":"2021-03-11T01:59:50.051541Z"},"papermill":{"duration":0.547996,"end_time":"2021-03-11T01:59:50.052298","exception":false,"start_time":"2021-03-11T01:59:49.504302","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"cell_type":"code","source":"test_df_noDefect.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T01:59:54.97221Z","iopub.status.busy":"2021-03-11T01:59:54.967993Z","iopub.status.idle":"2021-03-11T02:00:04.894227Z","shell.execute_reply":"2021-03-11T02:00:04.895071Z"},"papermill":{"duration":14.319311,"end_time":"2021-03-11T02:00:04.895317","exception":false,"start_time":"2021-03-11T01:59:50.576006","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"tt = []\nfor img in test_df_noDefect.index:\n        image_df = pd.DataFrame(columns = ['ImageId','ClassId','EncodedPixels'])\n        for i in range(4):\n            image_df.loc[i,'EncodedPixels'] = np.nan\n            image_df.loc[i,'ClassId'] = i+1\n            image_df.loc[i,'ImageId'] = test_df_noDefect.loc[img, \"ImageId\"]            \n       \n        tt.append(image_df)\n\ntt = pd.concat(tt)\nprint(tt.shape)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:06.177831Z","iopub.status.busy":"2021-03-11T02:00:06.176937Z","iopub.status.idle":"2021-03-11T02:00:06.196087Z","shell.execute_reply":"2021-03-11T02:00:06.197363Z"},"papermill":{"duration":0.730044,"end_time":"2021-03-11T02:00:06.197616","exception":false,"start_time":"2021-03-11T02:00:05.467572","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"final_submission_df = pd.concat([df, tt])\nprint(final_submission_df.shape)\nfinal_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:07.346473Z","iopub.status.busy":"2021-03-11T02:00:07.344376Z","iopub.status.idle":"2021-03-11T02:00:07.347306Z","shell.execute_reply":"2021-03-11T02:00:07.347915Z"},"papermill":{"duration":0.550949,"end_time":"2021-03-11T02:00:07.348107","exception":false,"start_time":"2021-03-11T02:00:06.797158","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"final_submission_df[\"EncodedPixels\"] = final_submission_df[\"EncodedPixels\"].apply(lambda x: np.nan if x == '' else x)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:08.423711Z","iopub.status.busy":"2021-03-11T02:00:08.422809Z","iopub.status.idle":"2021-03-11T02:00:08.426482Z","shell.execute_reply":"2021-03-11T02:00:08.42701Z"},"papermill":{"duration":0.553843,"end_time":"2021-03-11T02:00:08.427213","exception":false,"start_time":"2021-03-11T02:00:07.87337","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"final_submission_df[\"ClassId\"] = final_submission_df[\"ClassId\"].astype(str)\nfinal_submission_df['ImageId_ClassId'] = final_submission_df['ImageId']  + \"_\" + final_submission_df[\"ClassId\"]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:09.490778Z","iopub.status.busy":"2021-03-11T02:00:09.489742Z","iopub.status.idle":"2021-03-11T02:00:09.495581Z","shell.execute_reply":"2021-03-11T02:00:09.494976Z"},"papermill":{"duration":0.542663,"end_time":"2021-03-11T02:00:09.49572","exception":false,"start_time":"2021-03-11T02:00:08.953057","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"final_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:10.564375Z","iopub.status.busy":"2021-03-11T02:00:10.563335Z","iopub.status.idle":"2021-03-11T02:00:11.066716Z","shell.execute_reply":"2021-03-11T02:00:11.066059Z"},"papermill":{"duration":1.03848,"end_time":"2021-03-11T02:00:11.066929","exception":false,"start_time":"2021-03-11T02:00:10.028449","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"final_submission_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission-xceptionUnet2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:12.12764Z","iopub.status.busy":"2021-03-11T02:00:12.126735Z","iopub.status.idle":"2021-03-11T02:00:12.130224Z","shell.execute_reply":"2021-03-11T02:00:12.130962Z"},"papermill":{"duration":0.534633,"end_time":"2021-03-11T02:00:12.131181","exception":false,"start_time":"2021-03-11T02:00:11.596548","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import os\nprint(\"Done.\")\nprint(os.listdir())","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-11T02:00:13.190723Z","iopub.status.busy":"2021-03-11T02:00:13.189912Z","iopub.status.idle":"2021-03-11T02:00:13.193263Z","shell.execute_reply":"2021-03-11T02:00:13.193782Z"},"papermill":{"duration":0.535112,"end_time":"2021-03-11T02:00:13.193977","exception":false,"start_time":"2021-03-11T02:00:12.658865","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Create a sepertate file to submit the result. \n'''\nimport pandas as pd\n\ns = pd.read_csv('../input/csvfiles/submission.csv')\n\ns.to_csv('submission.csv',index=False)\ns.head()\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}