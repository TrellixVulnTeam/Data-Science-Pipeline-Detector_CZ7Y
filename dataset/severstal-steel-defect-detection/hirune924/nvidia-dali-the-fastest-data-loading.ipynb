{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NVIDIA DALI\nDeep learning applications require complex, multi-stage pre-processing data pipelines. Such data pipelines involve compute-intensive operations that are carried out on the CPU. For example, tasks such as: load data from disk, decode, crop, random resize, color and spatial augmentations and format conversions, are mainly carried out on the CPUs, limiting the performance and scalability of training and inference.\n\nIn addition, the deep learning frameworks have multiple data pre-processing implementations, resulting in challenges such as portability of training and inference workflows, and code maintainability.\n\nNVIDIA Data Loading Library (DALI) is a collection of highly optimized building blocks, and an execution engine, to accelerate the pre-processing of the input data for deep learning applications. DALI provides both the performance and the flexibility for accelerating different data pipelines as a single library. This single library can then be easily integrated into different deep learning training and inference applications.\n\n* https://github.com/NVIDIA/DALI\n* https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/index.html\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Install NVIDIA DALI"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"pip install --extra-index-url https://developer.download.nvidia.com/compute/redist/cuda/10.0 nvidia-dali","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normal Data Loading(PyTorch)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport glob\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom PIL import Image\nclass BasicDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = glob.glob('../input/severstal-steel-defect-detection/train_images/*.jpg')\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.img_list[idx])\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n                        transforms.Resize((224, 224)),\n                        transforms.RandomHorizontalFlip(),\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ndata_loader = DataLoader(\n                BasicDataset(transform=transform),\n                    batch_size=64, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstart_time = time.time()\nfor image in tqdm(data_loader):\n    image = image.cuda()\n    pass\nbasic_time = time.time() - start_time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# jpeg4py"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!apt-get install libturbojpeg0\n!pip install jpeg4py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import jpeg4py as jpeg\nclass jpeg4pyDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = glob.glob('../input/severstal-steel-defect-detection/train_images/*.jpg')\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        image = jpeg.JPEG(self.img_list[idx]).decode()\n        image = Image.fromarray(image)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n                        transforms.Resize((224, 224)),\n                        transforms.RandomHorizontalFlip(),\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ndata_loader = DataLoader(\n                jpeg4pyDataset(transform=transform),\n                    batch_size=64, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstart_time = time.time()\nfor image in tqdm(data_loader):\n    image = image.cuda()\n    pass\njpeg4py_time = time.time() - start_time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# jpeg4py + albumentations"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations\nclass jpeg4pyalbDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = glob.glob('../input/severstal-steel-defect-detection/train_images/*.jpg')\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        image = jpeg.JPEG(self.img_list[idx]).decode()\n\n        if self.transform is not None:\n            image = self.transform(**{\"image\": image})\n\n        return torch.from_numpy(image['image'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = albumentations.Compose([\n                        albumentations.Resize(height=224, width=224, interpolation=1, always_apply=True, p=1),\n                        albumentations.Flip(always_apply=False, p=0.5),\n                        albumentations.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=True, p=1.0)])\ndata_loader = DataLoader(\n                jpeg4pyalbDataset(transform=transform),\n                    batch_size=64, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstart_time = time.time()\nfor image in tqdm(data_loader):\n    image = image.cuda()\n    pass\njpeg4pyalb_time = time.time() - start_time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import jpeg4py as jpeg\nclass jpeg4pyDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = glob.glob('../input/severstal-steel-defect-detection/train_images/*.jpg')\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        image = jpeg.JPEG(self.img_list[idx]).decode()\n        image = Image.fromarray(image)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading by using DALI"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nvidia.dali.pipeline import Pipeline\nfrom nvidia.dali.plugin.pytorch import DALIGenericIterator\nimport nvidia.dali.ops as ops\nimport nvidia.dali.types as types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DALIPipeline(Pipeline):\n    def __init__(self, batch_size, num_threads, device_id):\n        super(DALIPipeline, self).__init__(batch_size, num_threads, device_id)\n        self.img_list = glob.glob('../input/severstal-steel-defect-detection/train_images/*.jpg')\n\n        dummy_label = [0]*len(self.img_list)\n        df = pd.DataFrame({'data' : self.img_list, 'label' : dummy_label})\n        df.to_csv('dali.txt', header=False, index=False, sep=' ')\n        \n        self.input = ops.FileReader(file_root='.', file_list='dali.txt')\n        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.RGB)\n        self.resize = ops.Resize(device = \"gpu\",\n                                 image_type = types.RGB,\n                                 resize_x=224., resize_y=224.)\n        self.cmn = ops.CropMirrorNormalize(device = \"gpu\",\n                                            output_dtype = types.FLOAT,\n                                            mirror = 1,\n                                            image_type = types.RGB,\n                                            mean = [128., 128., 128.],\n                                            std = [1., 1., 1.])\n    def define_graph(self):\n        images, labels = self.input(name=\"Reader\")\n        images = self.decode(images)\n        images = self.resize(images)\n        output = self.cmn(images)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DALICustomIterator(DALIGenericIterator):\n    def __init__(self, pipelines, output_map, size, auto_reset=False, fill_last_batch=True, dynamic_shape=False, last_batch_padded=False):\n        super(DALICustomIterator, self).__init__(pipelines, output_map, size, auto_reset, fill_last_batch, dynamic_shape, last_batch_padded)\n\n    def __len__(self):\n        return int(self._size / self.batch_size) + 1\n\n    def __next__(self):\n        if self._first_batch is not None:\n            batch = self._first_batch\n            self._first_batch = None\n            return batch\n        feed = super().__next__()\n        data = feed[0]['data']\n        return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DALIDataLoader(batch_size):\n    num_gpus = 1\n    pipes = [DALIPipeline(batch_size=batch_size, num_threads=2, device_id=device_id) for device_id in range(num_gpus)]\n\n    pipes[0].build()\n    dali_iter = DALICustomIterator(pipes, ['data'], pipes[0].epoch_size(\"Reader\"), auto_reset=True)\n    return dali_iter\ndata_loader = DALIDataLoader(batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstart_time = time.time()\nfor image in tqdm(data_loader):\n    # image is already on GPU\n    image = image\n    pass\ndali_time = time.time() - start_time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('simple data loader         : {}'.format(basic_time))\nprint('jpeg4py data loader        : {}'.format(jpeg4py_time))\nprint('jpeg4py + alb data loader  : {}'.format(jpeg4pyalb_time))\nprint('dali data loader           : {}'.format(dali_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DALI IS THE BEST!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}