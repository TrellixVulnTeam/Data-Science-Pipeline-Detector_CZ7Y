{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multilabel Image Classification_ fastai\n\nIn order to predict RLE segments of the steel images in the test set, I've decided to first train a model that predicts whether or not an image has defects. Although, to make it more interesting, my model is going to predict how many defects a steel image has. As you will see later in my analysis, an image can have 0-3 defects. \n\nThe aim of this kernel is to train a **cnn_learner with resnet34 architecture** and save the weights of the model (if I can figure out how to save and reuse the model in another kernel! :P) and also export the predicted labels for the test set so that I can exclude those images in my segmentation solution.\n\nPeople who inspired the idea are [Mayur Kulkarni](https://www.kaggle.com/mayurkulkarni/fastai-simple-model-0-88-lb) and [xhlulu](https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline). Please go and check out their kernels and vote up their kernels if you like their approach. \n\nAlso, thanks to [Jeremy Howard](https://www.kaggle.com/jhoward) for his great deep learning tutorials. I'm following his instructions while still trying to get my head round how to use _fastai_, so bear with me Jeremy! :D    "},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import required libraries\nimport numpy as np \nimport pandas as pd \nfrom fastai import *\nfrom fastai.vision import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing import image\nfrom pathlib import Path\nimport os\nimport glob  # used for loading multiple files\n# import PIL \n!mkdir -p /tmp/.cache/torch/checkpoints/\n# !cp /input/resnet34/resnet34.pth /tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### File operations"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# root directory\npath = Path(\"../input/severstal-steel-defect-detection\");\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_train_img = path/'train_images';\npath_test_img = path/'test_images';","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sneak peek in the train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get a list of filenames in the train image directory\nfnames = get_image_files(path_train_img)\nfnames[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels in the train.csv file  \ntrain = pd.read_csv(path/'train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations:**\n\n_ClassId_ is attached to the filename. Each filename has 4 classes 1-4 and each class does or does not have a mask (run Length Encoding) associated to it. Mask is represented as NaN when there does not an RLE string for a _ClassId_. An image may have none, one or multiple RLE codes.  "},{"metadata":{},"cell_type":"markdown","source":"### Visualize images and masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to plot an image\ndef plot_img(ImageId):\n    img_id = ImageId+'.jpg'\n    img = open_image(str(path_train_img) + '/'+img_id)\n    return img\n\n# function to plot a mask of an image\ndef plot_mask(ImageId_ClassId):\n    mask = open_mask_rle(train.loc[lambda df: df[\"ImageId_ClassId\"] == ImageId_ClassId, \"EncodedPixels\"].values[0], shape=(256, 1600))\n    mask = ImageSegment(mask.data.transpose(2, 1))\n    return mask\n\ndef plot_img_mask(ImageId,ClassId):\n    defect_img = plot_img(ImageId)\n    defect_mask = plot_mask(ImageId+'.jpg_'+str(ClassId))\n    defect_img.show(y=defect_mask, figsize=(20, 10), title = 'image & its masks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img('0002cc93b')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_mask('0002cc93b.jpg_1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img('fff02e9c5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_mask('fff02e9c5.jpg_3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img('000f6bf48')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_mask('000f6bf48.jpg_4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize mask and image in one plot\nplot_img_mask('000f6bf48',4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Construct Masks from RLE strings"},{"metadata":{},"cell_type":"markdown","source":"I liked Mayur's idea on pivoting the labels for each class (class1-class4) so that we'll have one line per _ImageId_. I believe this will prevent overfitting when splitting the data into train and validation i.e. no ImageId will leak from train to the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/mayurkulkarni/fastai-simple-model-0-88-lb\ndef train_pivot(train_csv):\n    df = pd.read_csv(train_csv)\n\n    def group_func(df, i):\n        reg = re.compile(r'(.+)_\\d$')\n        return reg.search(df['ImageId_ClassId'].loc[i]).group(1)\n\n    group = df.groupby(lambda i: group_func(df, i))\n\n    df = group.agg({'EncodedPixels': lambda x: list(x)})\n\n    df['ImageId'] = df.index\n    df = df.reset_index(drop=True)\n\n    df[[f'EncodedPixels_{k}' for k in range(1, 5)]] = pd.DataFrame(df['EncodedPixels'].values.tolist())\n    \n    df = df.drop(columns='EncodedPixels')\n    train_df = df.fillna(value=' ')\n    return train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_pivot(str(path)+'/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding a flag to determine whether or not an image has defects\ntrain_df['has_defects'] = 0\ntrain_df.loc[(train_df['EncodedPixels_1'] != ' ') |  (train_df['EncodedPixels_2'] != ' ') | (train_df['EncodedPixels_3'] != ' ')\n            | (train_df['EncodedPixels_4'] != ' '), 'has_defects'] = 1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are' ,train_df[train_df.has_defects == 1].shape[0] , 'images with defects and' , train_df[train_df.has_defects == 0].shape[0]\n      , 'without defects in the training set') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the original dataframe where there are 4 lines for each ImageId, I calculate the number of defects for each image\n\ntmp = train.copy()\ntmp['ImageId'] = tmp['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntmp['ClassId'] = tmp['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntmp['has_defects'] = tmp.EncodedPixels.apply(lambda x: 1 if not pd.isnull(x) else 0)\ndefects = pd.DataFrame(tmp.groupby(by=\"ImageId\")['has_defects'].sum())\ndefects.reset_index(inplace=True)  # convert the image_id which is an index to a column so that the dataframes can be joined on that\ndefects.rename(columns={\"has_defects\": \"no_of_defects\"},inplace=True) # rename the aggregated column ready for the join \ndefects.head()\n\n\n# add the no_of_defects to the labels dataframe\n\ntrain_df = train_df.merge(defects, left_on='ImageId', right_on='ImageId', how='left')\ntrain_df.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df.no_of_defects)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.no_of_defects.value_counts().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of steel images more than 1 defects\ntrain_df[train_df.no_of_defects > 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# an example image with 2 defects: class 3 & class 4\nplot_img('fd26ab9ad')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img_mask('fd26ab9ad','3')\nplot_img_mask('fd26ab9ad','4')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model : Image Classifier to predict non-defect images in the test set\n\nI use the number of defects as the dependent variable in my classifier. Here, I create a subset of the train_df dataframe that contains the ImageId and no_of_defects columns to predict number of defects."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_clf = train_df[['ImageId','no_of_defects']] \ntrain_clf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the specific data format called ImageDataBunch required by the fastai models. It bundles the actual training images\n# in the image directory with the labels we loaded into a dataframe \nnp.random.seed(42)\nbs = 64\ndata = ImageDataBunch.from_df(path_train_img, train_clf, ds_tfms=get_transforms(), size=256, bs=bs, test=path_test_img\n                                  ).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(7,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.classes)\nlen(data.classes),data.c","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model with Resnet34"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet34, metrics=error_rate, model_dir=\"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('DefectClass_stage-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !mkdir exports","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.export()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(9, figsize=(15,11))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.most_confused(min_val=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ingest more data into the model to improve error_rate\nlearn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=slice(1e-04,1e-03))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('DefectClass_stage-2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(9, figsize=(15,11))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.most_confused(min_val=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Can our model do any better by fine-tunning even more?"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(1, max_lr=slice(1e-05,1e-04))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('DefectClass_stage-3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.most_confused(min_val=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(is_test=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning up"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.widgets import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds, idxs = DatasetFormatter().from_toplosses(learn, n_imgs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageCleaner(ds, idxs, path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds, idxs = DatasetFormatter().from_similars(learn)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}