{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Install MLComp library(offline version):","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As the competition does not allow commit with the kernel that uses internet connection, we use offline installation","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"! python ../input/mlcomp/mlcomp/setup.py","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import required libraries","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport cv2\nimport albumentations as A\nfrom tqdm import tqdm_notebook\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.jit import load\n\nfrom mlcomp.contrib.transform.albumentations import ChannelTranspose\nfrom mlcomp.contrib.dataset.classify import ImageDataset\nfrom mlcomp.contrib.transform.rle import rle2mask, mask2rle\nfrom mlcomp.contrib.transform.tta import TtaWrap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Catalyst allows to trace models. That is an extremely useful features in Pytorch since 1.0 version: \n\nhttps://pytorch.org/docs/stable/jit.html\n\nNow we can load models without re-defining them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unet = load('../input/severstaleffnet/traced_effnetb7_mixup_retrain.pth').cuda()\ncls = load('../input/severstall-effnetb0-fimal-stage/traced_model.pth').cuda()\ncls_alt = load('../input/severstaleffnet/traced_effnetb0_lovasz.pth').cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Models' mean aggregator","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Create TTA transforms, datasets, loaders","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def create_transforms(additional):\n    res = list(additional)\n    # add necessary transformations\n    res.extend([\n        A.Normalize(\n            mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n        ),\n        ChannelTranspose()\n    ])\n    res = A.Compose(res)\n    return res\n\nimg_folder = '/kaggle/input/severstal-steel-defect-detection/test_images'\nbatch_size = 1\nnum_workers = 0\n\n# Different transforms for TTA wrapper\ntransforms = [\n    [],\n    [A.HorizontalFlip(p=1)],\n    [A.VerticalFlip(p=1)],\n]\n\ntransforms = [create_transforms(t) for t in transforms]\ndatasets = [TtaWrap(ImageDataset(img_folder=img_folder, transforms=t), tfms=t) for t in transforms]\nloaders = [DataLoader(d, num_workers=num_workers, batch_size=batch_size, shuffle=False) for d in datasets]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loaders' mean aggregator","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"class Classifier:\n    def __init__(self, model):\n        self.model = model\n    \n    def __call__(self, loaders_batch):\n        with torch.no_grad():\n            preds = []\n            image_file = []\n            for i, batch in enumerate(loaders_batch):\n                features = batch['features'].cuda()\n                pred_raw, _ = model(features)\n                p = torch.sigmoid(pred_raw)\n                image_file = batch['image_file']\n\n                # inverse operations for TTA\n                p = datasets[i].inverse(p)\n                preds.append(p)\n\n            # TTA mean\n            preds = torch.stack(preds)\n            preds = torch.mean(preds, dim=0)\n            preds = preds.detach().cpu().numpy()\n\n            # Batch post processing\n            p_img = []\n            for p, file in zip(preds, image_file):\n                file = os.path.basename(file)\n                # Image postprocessing\n                for i in range(4):\n                    p_channel = p[i]\n                    p_channel = (p_channel>thresholds[i]).astype(np.uint8)\n                    if p_channel.sum() < min_area[i]:\n                        p_channel = np.zeros(p_channel.shape, dtype=p_channel.dtype)\n                    p_img.append(p_channel)\n        return p_img\n\n\nclass Model:\n    def __init__(self, models):\n        self.models = models\n    \n    def __call__(self, x):\n        res = []\n        labels = []\n        x = x.cuda()\n        with torch.no_grad():\n            for m in self.models:\n                masks, label = m(x)\n                res.append(masks)\n                labels.append(label)\n        res = torch.stack(res)\n        labels = torch.stack(labels)\n        return torch.mean(res, dim=0), torch.mean(labels, dim=0)\n\nmodel = cls_alt\n# cls2 = Classifier(cls_alt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nl = torch.tensor([1, 0])\nif np.count_nonzero(l):\n    print('yay')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds = [0.6, 0.99, 0.6, 0.6] # [0.5, 0.5, 0.5, 0.5] | [0.55, 0.55, 0.55, 0.55] | [0.6, 0.99, 0.6, 0.6]\nmin_area = [600, 600, 1000, 2000] # instead of 900 -> 1000 in old version\n\nres = []\n# Iterate over all TTA loaders\ntotal = len(datasets[0])//batch_size\nwith torch.no_grad():\n    for loaders_batch in tqdm_notebook(zip(*loaders), total=total):\n        preds = []\n        image_file = []\n        labels = []\n        for i, batch in enumerate(loaders_batch):\n            features = batch['features'].cuda()\n            output = model(features)\n            pred_raw, label = output\n            labels.append(label)\n            p = torch.sigmoid(pred_raw)\n            image_file = batch['image_file']\n\n            # inverse operations for TTA\n            p = datasets[i].inverse(p)\n            preds.append(p)\n    \n        # TTA mean\n        preds = torch.stack(preds)\n        preds = torch.mean(preds, dim=0)\n        preds = preds.detach().cpu().numpy()\n        labels = torch.stack(labels)\n        labels = torch.mean(labels, dim=0)\n        labels = labels.detach().cpu().numpy()  # has shape (1, 4)\n        labels = labels[0] \n    \n        # Batch post processing\n        for p, file in zip(preds, image_file):\n            file = os.path.basename(file)\n            # Image postprocessing\n            for i in range(4):\n                p_channel = np.zeros((256, 1600), dtype=np.uint8)\n                imageid_classid = file+'_'+str(i+1)\n                if labels[i] > 0:\n                    p_channel = p[i]\n                    p_channel = (p_channel>thresholds[i]).astype(np.uint8)\n                    if p_channel.sum() < min_area[i]:\n                        p_channel = np.zeros(p_channel.shape, dtype=p_channel.dtype)\n\n                res.append({\n                    'ImageId_ClassId': imageid_classid,\n                    'EncodedPixels': mask2rle(p_channel)\n                })\n        \ndf = pd.DataFrame(res)\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(res)\ndf = df.fillna('')\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogram of predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\ndf['empty'] = df['EncodedPixels'].map(lambda x: not x)\ndf[df['empty'] == False]['Class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\ndf = pd.read_csv('submission.csv')[:40]\ndf['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\n\nfor row in df.itertuples():\n    img_path = os.path.join(img_folder, row.Image)\n    img = cv2.imread(img_path)\n    mask = rle2mask(row.EncodedPixels, (1600, 256)) \\\n        if isinstance(row.EncodedPixels, str) else np.zeros((256, 1600))\n    if mask.sum() == 0:\n        continue\n    \n    fig, axes = plt.subplots(1, 2, figsize=(20, 60))\n    axes[0].imshow(img/255)\n    axes[1].imshow(mask*60)\n    axes[0].set_title(row.Image)\n    axes[1].set_title(row.Class)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}