{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['y_train.csv', 'sample_submission.csv', 'X_train.csv', 'X_test.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"testing = True #Set this to true for submission/False for cross validation\nX_train = pd.read_csv('../input/X_train.csv')\ny_train = pd.read_csv('../input/y_train.csv')\nX_train = pd.merge(X_train,y_train,on='series_id')\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX_train['surface'] = le.fit_transform(X_train['surface'])\nif(testing):\n    X_test = pd.read_csv('../input/X_test.csv')\n    X_test['series_id'] = X_test['series_id']+3810\n    X_test['group_id'] = 0\n    X_test['surface'] = 0\n    frames = [X_train,X_test]\n    X_train = pd.concat(frames)\n    X_train.reset_index(drop=True,inplace=True)\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"221072c02a371cac63d07e9592941c6e65bf8a42"},"cell_type":"code","source":"cols = list(X_train.columns.values)\ncols.remove('orientation_W')\ncols.insert(3,'orientation_W')\nX_train = X_train[cols]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71d24843e14f36b7c2b0860eea9b7d4c3e6f57a2","scrolled":false},"cell_type":"code","source":"num_meas = 128\nnum_series = X_train['series_id'].nunique()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"603241626d86bf9eeacb6ee9ed95d3ecec99e0fd","scrolled":false},"cell_type":"code","source":"def q_to_angle(q_val):\n    #We assume q_val is in this format: [qw, q1, q2, q3]\n    #And the quaternion is normalized\n    roll = np.arctan2(2*(q_val[0]*q_val[1] + q_val[2]*q_val[3]),1 - 2*(q_val[1]*q_val[1] + q_val[2]*q_val[2]))\n    pitch = np.arcsin(2*(q_val[0]*q_val[2] - q_val[3]*q_val[1]))\n    yaw = np.arctan2(2*(q_val[0]*q_val[3] + q_val[1]*q_val[2]),1 - 2*(q_val[2]*q_val[2] + q_val[3]*q_val[3]))\n    return np.array([roll, pitch, yaw])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf416b97ff135f37f7287bb331b5ac25b442bd71","scrolled":false},"cell_type":"code","source":"quat_arr = np.array(X_train[['orientation_W','orientation_X','orientation_Y','orientation_Z']])\neuler_arr = np.zeros([quat_arr.shape[0],3])\nfor n,arr in enumerate(quat_arr):\n    euler_arr[n] = q_to_angle(arr)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83569b323e21d295b47e5f0a8053b21b96dd0298","scrolled":true},"cell_type":"code","source":"X_train['roll'] = euler_arr[:,0]\nX_train['pitch'] = euler_arr[:,1]\nX_train['yaw'] = euler_arr[:,2]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39e0baed88650cc85b720cdc098ba8288681ca44","scrolled":true},"cell_type":"code","source":"cols = list(X_train.columns.values)\ncols.remove('group_id')\ncols.append('group_id')\ncols.remove('surface')\ncols.append('surface')\nX_train = X_train[cols]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a61e694bf681474b358a0862004de4973b428d9","scrolled":false},"cell_type":"code","source":"feat_cols = ['roll','pitch','yaw','angular_velocity_X','angular_velocity_Y','angular_velocity_Z','linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z']\nfeat_array = np.array(X_train[feat_cols])\nfeat_array = np.reshape(feat_array,[num_series,128,len(feat_cols)])\ngroup_array = np.array(X_train['group_id'])\ngroup_array = np.reshape(group_array,[num_series,128])\ngroup_array = group_array[:,0]\ntarget_array = np.array(X_train['surface'])\ntarget_array = np.reshape(target_array,[num_series,128])\ntarget_array = target_array[:,0]","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"537abf133ddfbb65dd2c7e29f5ceee444facaeee","scrolled":true},"cell_type":"code","source":"#Use the first order difference of the following features\n#Absolute Orientation features dont make sense to predict surface\ndelta_cols = ['roll','pitch','yaw']\nfor dc in delta_cols:\n    iia = feat_cols.index(dc)\n    np_arr = feat_array[:,:,iia]\n    roll_arr = np.copy(np_arr)\n    roll_arr[:,1:] = roll_arr[:,:-1]\n    np_arr = np_arr - roll_arr\n    feat_array[:,:,iia] = np_arr","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"194f265bd2cba051f61b1b1d529e0ddf9b1c37c8"},"cell_type":"code","source":"#Normalize each 128-pt sample to ensure there is no group related information left in the samples\nnorm_cols = ['linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z','angular_velocity_X','angular_velocity_Y','angular_velocity_Z']\nfor norm in norm_cols:\n    iia = feat_cols.index(norm)\n    np_arr = feat_array[:,:,iia]\n    mean_arr = np.mean(np_arr,1)\n    mean_arr = np.expand_dims(mean_arr,1)\n    mean_arr = np.repeat(mean_arr,num_meas,1)\n    np_arr = np_arr - mean_arr\n    feat_array[:,:,iia] = np_arr","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a31f546817b501b93a4855db477aa043c56c22d8"},"cell_type":"code","source":"def absfft(x):\n    return np.abs(np.fft.rfft(x))\n\nfeat_fft_array = np.copy(feat_array[:,:,3:])\nfeat_fft_array = np.apply_along_axis(absfft,1,feat_fft_array)\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b0c58012bd2144fcac6bb9f515340ab57393f07"},"cell_type":"code","source":"#Further normalization across the entire dataset to ensure NN inputs are zero-mean and unit standard deviation\n\nnum_sensor = feat_array.shape[2]\nfor i in range(num_sensor):\n    mean_s = np.mean(feat_array[:,:,i])\n    sd_s = np.std(feat_array[:,:,i])\n    feat_array[:,:,i] = (feat_array[:,:,i]-mean_s)/sd_s\n\nnum_sensor_fft = feat_fft_array.shape[2]\nfor i in range(num_sensor_fft):\n    mean_s = np.mean(feat_fft_array[:,:,i])\n    sd_s = np.std(feat_fft_array[:,:,i])\n    feat_fft_array[:,:,i] = (feat_fft_array[:,:,i]-mean_s)/sd_s","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"495ca800870408b60542ee298087f4253726dad4","scrolled":false},"cell_type":"code","source":"from keras.layers import Input,Dense, Dropout, BatchNormalization, SeparableConv1D, Reshape, LSTM, DepthwiseConv2D,AveragePooling2D, CuDNNLSTM, Concatenate\nfrom keras.models import Model\nfrom keras.backend import squeeze\nfrom keras.regularizers import l2\nkr = None\nnum_groups = np.unique(group_array).shape[0]\nnum_surfaces = np.unique(target_array).shape[0]\n\ndef get_net_with_fft_mag_only(dp):\n    inputs_t = Input(shape=(128,len(feat_cols)))\n    x = SeparableConv1D(32,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(inputs_t)\n    x = Dropout(dp)(x)\n    x = SeparableConv1D(64,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(x)\n    x = Dropout(dp)(x)\n    x = SeparableConv1D(128,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(x)\n    x = Dropout(dp)(x)\n    x = SeparableConv1D(256,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(x)\n    x = Reshape((256,))(x)\n    x = Dropout(dp)(x)\n    x = Dense(64, activation='relu',kernel_regularizer=kr)(x)\n    x = Dropout(dp)(x)\n    x = Dense(64, activation='relu')(x)\n    \n    inputs_f = Input(shape=(feat_fft_array.shape[1],feat_fft_array.shape[2]))\n    y = SeparableConv1D(32,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(inputs_f)\n    y = Dropout(dp)(y)\n    y = SeparableConv1D(64,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n    y = Dropout(dp)(y)\n    y = SeparableConv1D(128,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n    y = Dropout(dp)(y)\n    y = SeparableConv1D(128,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n    y = Dropout(dp)(y)\n    y = SeparableConv1D(256,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n    y = Reshape((256,))(y)\n    y = Dropout(dp)(y)\n    y = Dense(64, activation='relu',kernel_regularizer=kr)(y)\n    y = Dropout(dp)(y)\n    y = Dense(64, activation='relu')(y)\n    \n        \n    inputs = [inputs_t,inputs_f]\n    \n    z = Concatenate()([x,y])\n    z = Dense(64, activation='relu')(z)\n    predictions = Dense(num_surfaces, activation='softmax')(z)\n    model = Model(inputs=inputs, outputs=predictions)\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","execution_count":14,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"e384f3e8a2cc567b2c2a4be08bd2d05f6fd9d127"},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\ndepthwise = False\nfft_net = True\nif(not(testing)):\n    gkf = GroupKFold(3)\n    train_gen = gkf.split(X=feat_array,groups=group_array)\n    preds = np.zeros_like(target_array)\n    for train_idx,test_idx in train_gen:\n        #Test features\n        t_feats = feat_array[train_idx]\n        t_feats_fft = feat_fft_array[train_idx]\n        \n        #Validation features\n        v_feats = feat_array[test_idx]\n        v_feats_fft = feat_fft_array[test_idx]\n        \n        t_vals = target_array[train_idx]\n        v_vals = target_array[test_idx]\n        \n        pred_classes = np.zeros([v_vals.shape[0],num_surfaces,5])\n        for k in range(5): #5 time averaging to get more stable results\n            nnet = get_net_with_fft_mag_only(0.5)\n            nnet.fit(x=[t_feats,t_feats_fft],y=t_vals,batch_size=256,epochs=3000,validation_data=([v_feats,v_feats_fft],v_vals),verbose=2)\n            pred_classes[:,:,k] = nnet.predict([v_feats,v_feats_fft])\n        pred_classes = np.mean(pred_classes,axis=2)\n        pred_classes = np.argmax(pred_classes,axis=1)\n        preds[test_idx] = pred_classes\n        print('Val accuracy: ',accuracy_score(v_vals,pred_classes))\n        pred_classes = nnet.predict([t_feats,t_feats_fft])\n        pred_classes = np.argmax(pred_classes,axis=1)\n        print('Train accuracy: ',accuracy_score(t_vals,pred_classes))\n    print('5 Fold accuracy: ', accuracy_score(target_array,preds))\nelse:\n    t_feats = feat_array[:3810]\n    t_feats_fft = feat_fft_array[:3810]\n    t_vals = target_array[:3810]\n    v_feats = feat_array[3810:]\n    v_feats_fft = feat_fft_array[3810:]\n    pred_classes = np.zeros([v_feats.shape[0],num_surfaces,3])\n    for k in range(3):\n        nnet = get_net_with_fft_mag_only(0.5)\n        nnet.fit(x=[t_feats,t_feats_fft],y=t_vals,batch_size=256,epochs=3000,verbose=0)\n        pred_classes[:,:,k] = nnet.predict([v_feats,v_feats_fft])\n    pred_classes = np.mean(pred_classes,axis=2)\n    pred_classes = list(np.argmax(pred_classes,axis=1))\n    pred_classes = [le.inverse_transform([i])[0] for i in pred_classes]\n    sub_df = pd.read_csv('../input/sample_submission.csv')\n    sub_df['surface'] = pred_classes\n    sub_df.to_csv('submission.csv',index=False)","execution_count":15,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 2539 samples, validate on 1271 samples\nEpoch 1/3000\n - 7s - loss: 2.1861 - acc: 0.1705 - val_loss: 2.1583 - val_acc: 0.2549\nEpoch 2/3000\n - 0s - loss: 2.1423 - acc: 0.1792 - val_loss: 2.0742 - val_acc: 0.2549\nEpoch 3/3000\n - 0s - loss: 2.0778 - acc: 0.1792 - val_loss: 2.0238 - val_acc: 0.2549\nEpoch 4/3000\n - 0s - loss: 2.0435 - acc: 0.1792 - val_loss: 2.0601 - val_acc: 0.2549\nEpoch 5/3000\n - 0s - loss: 2.0230 - acc: 0.1733 - val_loss: 2.0530 - val_acc: 0.2549\nEpoch 6/3000\n - 0s - loss: 1.9782 - acc: 0.1776 - val_loss: 2.0119 - val_acc: 0.2612\nEpoch 7/3000\n - 0s - loss: 1.9079 - acc: 0.2343 - val_loss: 1.8881 - val_acc: 0.3407\nEpoch 8/3000\n - 0s - loss: 1.8361 - acc: 0.2505 - val_loss: 1.8080 - val_acc: 0.3249\nEpoch 9/3000\n - 0s - loss: 1.8059 - acc: 0.2753 - val_loss: 1.8248 - val_acc: 0.2911\nEpoch 10/3000\n - 0s - loss: 1.7888 - acc: 0.2848 - val_loss: 1.7336 - val_acc: 0.4091\nEpoch 11/3000\n - 0s - loss: 1.7563 - acc: 0.3088 - val_loss: 1.7540 - val_acc: 0.4052\nEpoch 12/3000\n - 0s - loss: 1.7463 - acc: 0.3100 - val_loss: 1.7308 - val_acc: 0.3847\nEpoch 13/3000\n - 0s - loss: 1.7479 - acc: 0.3001 - val_loss: 1.7592 - val_acc: 0.3698\nEpoch 14/3000\n - 0s - loss: 1.7298 - acc: 0.3108 - val_loss: 1.7389 - val_acc: 0.4437\nEpoch 15/3000\n - 0s - loss: 1.7220 - acc: 0.3285 - val_loss: 1.7457 - val_acc: 0.4437\nEpoch 16/3000\n - 0s - loss: 1.7163 - acc: 0.3364 - val_loss: 1.7111 - val_acc: 0.4013\nEpoch 17/3000\n - 0s - loss: 1.7138 - acc: 0.3407 - val_loss: 1.7753 - val_acc: 0.4052\nEpoch 18/3000\n - 0s - loss: 1.7036 - acc: 0.3375 - val_loss: 1.7061 - val_acc: 0.4603\nEpoch 19/3000\n - 0s - loss: 1.6897 - acc: 0.3576 - val_loss: 1.7710 - val_acc: 0.4068\nEpoch 20/3000\n - 0s - loss: 1.6725 - acc: 0.3497 - val_loss: 1.7077 - val_acc: 0.4524\nEpoch 21/3000\n - 0s - loss: 1.6522 - acc: 0.3564 - val_loss: 1.7356 - val_acc: 0.4689\nEpoch 22/3000\n - 0s - loss: 1.6380 - acc: 0.3627 - val_loss: 1.8177 - val_acc: 0.3501\nEpoch 23/3000\n - 0s - loss: 1.6216 - acc: 0.3773 - val_loss: 1.7721 - val_acc: 0.4516\nEpoch 24/3000\n - 0s - loss: 1.6070 - acc: 0.3852 - val_loss: 1.8435 - val_acc: 0.3454\nEpoch 25/3000\n - 0s - loss: 1.5774 - acc: 0.3781 - val_loss: 1.7498 - val_acc: 0.4658\nEpoch 26/3000\n - 0s - loss: 1.5653 - acc: 0.3978 - val_loss: 1.7906 - val_acc: 0.4170\nEpoch 27/3000\n - 0s - loss: 1.5516 - acc: 0.3994 - val_loss: 1.7694 - val_acc: 0.3863\nEpoch 28/3000\n - 0s - loss: 1.5481 - acc: 0.4021 - val_loss: 1.7456 - val_acc: 0.4493\nEpoch 29/3000\n - 0s - loss: 1.5233 - acc: 0.4100 - val_loss: 1.7325 - val_acc: 0.4335\nEpoch 30/3000\n - 0s - loss: 1.5163 - acc: 0.4218 - val_loss: 1.7708 - val_acc: 0.3839\nEpoch 31/3000\n - 0s - loss: 1.4931 - acc: 0.4206 - val_loss: 1.7497 - val_acc: 0.3761\nEpoch 32/3000\n - 0s - loss: 1.4707 - acc: 0.4309 - val_loss: 1.6924 - val_acc: 0.3816\nEpoch 33/3000\n - 0s - loss: 1.4658 - acc: 0.4368 - val_loss: 1.6886 - val_acc: 0.4256\nEpoch 34/3000\n - 0s - loss: 1.4235 - acc: 0.4577 - val_loss: 1.7521 - val_acc: 0.3753\nEpoch 35/3000\n - 0s - loss: 1.4264 - acc: 0.4443 - val_loss: 1.7651 - val_acc: 0.3950\nEpoch 36/3000\n - 0s - loss: 1.4054 - acc: 0.4451 - val_loss: 1.6453 - val_acc: 0.4359\nEpoch 37/3000\n - 0s - loss: 1.3813 - acc: 0.4699 - val_loss: 1.6312 - val_acc: 0.4390\nEpoch 38/3000\n - 0s - loss: 1.3838 - acc: 0.4608 - val_loss: 1.6314 - val_acc: 0.4217\nEpoch 39/3000\n - 0s - loss: 1.3653 - acc: 0.4750 - val_loss: 1.6108 - val_acc: 0.4493\nEpoch 40/3000\n - 0s - loss: 1.3437 - acc: 0.4864 - val_loss: 1.6315 - val_acc: 0.4477\nEpoch 41/3000\n - 0s - loss: 1.3275 - acc: 0.4970 - val_loss: 1.6448 - val_acc: 0.4359\nEpoch 42/3000\n - 0s - loss: 1.3047 - acc: 0.4907 - val_loss: 1.5634 - val_acc: 0.4359\nEpoch 43/3000\n - 0s - loss: 1.2835 - acc: 0.5163 - val_loss: 1.6224 - val_acc: 0.4304\nEpoch 44/3000\n - 0s - loss: 1.2710 - acc: 0.5242 - val_loss: 1.6226 - val_acc: 0.4264\nEpoch 45/3000\n - 0s - loss: 1.2623 - acc: 0.5317 - val_loss: 1.5455 - val_acc: 0.4375\nEpoch 46/3000\n - 0s - loss: 1.2431 - acc: 0.5321 - val_loss: 1.6108 - val_acc: 0.4406\nEpoch 47/3000\n - 0s - loss: 1.2338 - acc: 0.5313 - val_loss: 1.5455 - val_acc: 0.4729\nEpoch 48/3000\n - 0s - loss: 1.2152 - acc: 0.5471 - val_loss: 1.5805 - val_acc: 0.4603\nEpoch 49/3000\n - 0s - loss: 1.2038 - acc: 0.5502 - val_loss: 1.5540 - val_acc: 0.4650\nEpoch 50/3000\n - 0s - loss: 1.1886 - acc: 0.5549 - val_loss: 1.5018 - val_acc: 0.4689\nEpoch 51/3000\n - 0s - loss: 1.1849 - acc: 0.5443 - val_loss: 1.5216 - val_acc: 0.5059\nEpoch 52/3000\n - 0s - loss: 1.1700 - acc: 0.5703 - val_loss: 1.5091 - val_acc: 0.4933\nEpoch 53/3000\n - 0s - loss: 1.1630 - acc: 0.5534 - val_loss: 1.4467 - val_acc: 0.5020\nEpoch 54/3000\n - 0s - loss: 1.1358 - acc: 0.5731 - val_loss: 1.4698 - val_acc: 0.4902\nEpoch 55/3000\n - 0s - loss: 1.1286 - acc: 0.5790 - val_loss: 1.5501 - val_acc: 0.4831\nEpoch 56/3000\n - 0s - loss: 1.1083 - acc: 0.5841 - val_loss: 1.4788 - val_acc: 0.5075\nEpoch 57/3000\n - 0s - loss: 1.1113 - acc: 0.5762 - val_loss: 1.4502 - val_acc: 0.4925\nEpoch 58/3000\n - 0s - loss: 1.1018 - acc: 0.5809 - val_loss: 1.4230 - val_acc: 0.5138\nEpoch 59/3000\n - 0s - loss: 1.1098 - acc: 0.5774 - val_loss: 1.4780 - val_acc: 0.4996\nEpoch 60/3000\n - 0s - loss: 1.0745 - acc: 0.5790 - val_loss: 1.4713 - val_acc: 0.5043\nEpoch 61/3000\n - 0s - loss: 1.0648 - acc: 0.5916 - val_loss: 1.3881 - val_acc: 0.5153\nEpoch 62/3000\n - 0s - loss: 1.0495 - acc: 0.5967 - val_loss: 1.4286 - val_acc: 0.5067\nEpoch 63/3000\n - 0s - loss: 1.0464 - acc: 0.5959 - val_loss: 1.4666 - val_acc: 0.5083\nEpoch 64/3000\n - 0s - loss: 1.0441 - acc: 0.5935 - val_loss: 1.4042 - val_acc: 0.5563\nEpoch 65/3000\n - 0s - loss: 1.0465 - acc: 0.5947 - val_loss: 1.4084 - val_acc: 0.5547\nEpoch 66/3000\n - 0s - loss: 1.0221 - acc: 0.6128 - val_loss: 1.4299 - val_acc: 0.5075\nEpoch 67/3000\n - 0s - loss: 1.0089 - acc: 0.6168 - val_loss: 1.3992 - val_acc: 0.5389\nEpoch 68/3000\n - 0s - loss: 1.0133 - acc: 0.6109 - val_loss: 1.4465 - val_acc: 0.5098\nEpoch 69/3000\n - 0s - loss: 0.9998 - acc: 0.6089 - val_loss: 1.4723 - val_acc: 0.4988\nEpoch 70/3000\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d8632263d9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#5 time averaging to get more stable results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net_with_fft_mag_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_feats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_feats_fft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_feats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_feats_fft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mpred_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_feats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_feats_fft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}