{"cells":[{"metadata":{"_uuid":"70ac848abee33372f1fc984cff22a2666a1510f0"},"cell_type":"markdown","source":"## Introduction:\nRobots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment.\nIn this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors).\n\n## About Data: \nCareerCon has collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. \n\n## Objective:\nThe task is to predict which one of the nine floor types (carpet, tiles, concrete) the robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style \nstyle.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport plotly.offline as py \nfrom plotly.offline import init_notebook_mode, iplot\npy.init_notebook_mode(connected=True) # this code, allow us to work with offline plotly version\nimport plotly.graph_objs as go # it's like \"plt\" of matplot\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport gc\n\n\n# Any results you write to the current directory are saved as output.","execution_count":57,"outputs":[{"output_type":"stream","text":"['X_train.csv', 'sample_submission.csv', 'X_test.csv', 'y_train.csv']\n","name":"stdout"},{"output_type":"display_data","data":{"text/html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>","text/vnd.plotly.v1+html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"3e34f69dc39da43668ef2b31a5bc78a2f00e2c90","scrolled":false},"cell_type":"code","source":"X_train = pd.read_csv('../input/X_train.csv')\nX_train.head(3)","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"  row_id          ...            linear_acceleration_Z\n0    0_0          ...                          -9.7532\n1    0_1          ...                          -9.4128\n2    0_2          ...                          -8.7267\n\n[3 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>series_id</th>\n      <th>measurement_number</th>\n      <th>orientation_X</th>\n      <th>orientation_Y</th>\n      <th>orientation_Z</th>\n      <th>orientation_W</th>\n      <th>angular_velocity_X</th>\n      <th>angular_velocity_Y</th>\n      <th>angular_velocity_Z</th>\n      <th>linear_acceleration_X</th>\n      <th>linear_acceleration_Y</th>\n      <th>linear_acceleration_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0_0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.75853</td>\n      <td>-0.63435</td>\n      <td>-0.10488</td>\n      <td>-0.10597</td>\n      <td>0.107650</td>\n      <td>0.017561</td>\n      <td>0.000767</td>\n      <td>-0.74857</td>\n      <td>2.1030</td>\n      <td>-9.7532</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0_1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.75853</td>\n      <td>-0.63434</td>\n      <td>-0.10490</td>\n      <td>-0.10600</td>\n      <td>0.067851</td>\n      <td>0.029939</td>\n      <td>0.003385</td>\n      <td>0.33995</td>\n      <td>1.5064</td>\n      <td>-9.4128</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0_2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-0.75853</td>\n      <td>-0.63435</td>\n      <td>-0.10492</td>\n      <td>-0.10597</td>\n      <td>0.007275</td>\n      <td>0.028934</td>\n      <td>-0.005978</td>\n      <td>-0.26429</td>\n      <td>1.5922</td>\n      <td>-8.7267</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"y_train = pd.read_csv('../input/y_train.csv')\ny_train.head(3)","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"   series_id  group_id        surface\n0          0        13  fine_concrete\n1          1        31       concrete\n2          2        20       concrete","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>group_id</th>\n      <th>surface</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>13</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>31</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20</td>\n      <td>concrete</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"14178c56eab309c63986cdcd7de1d2576957433d"},"cell_type":"code","source":"X_test = pd.read_csv('../input/X_test.csv')\nX_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87344a081dfe0608e015f37140004a9103b1b9e7"},"cell_type":"markdown","source":"# Descriptive Statistics"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"1a77ddf0c56e91c8faef884dcd6b16e5c606dc62"},"cell_type":"code","source":"print('Size of Train Data')\nprint('Number of samples are: {0}\\nNumber of features are: {1}'.format(X_train.shape[0], X_train.shape[1]))\n\nprint('\\nSize of Test Data')\nprint('Number of samples are: {0}\\nNumber of features are: {1}'.format(X_test.shape[0], X_test.shape[1]))\n\nprint('\\nSize of Target Data')\nprint('Number of samples are: {0}\\nNumber of features are: {1}'.format(y_train.shape[0], y_train.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e9946fb562f644bd6bafa8b881e09c686afb4b2"},"cell_type":"markdown","source":"## Train Data Description"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"c7bcd5aea9bd259d6ccb60a17460365a7c57f1a4"},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c997188cebfe04de0f2287ef379b8cd396a16f3"},"cell_type":"markdown","source":"## Target surface type and their sample count"},{"metadata":{"trusted":true,"_uuid":"5b86605f9b26e4d5236fd3e3c6d94937dbe60960","_kg_hide-input":false},"cell_type":"code","source":"target = y_train['surface'].value_counts().reset_index().rename(columns = {'index' : 'target'})\ntarget","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"786a55a2d8d52fcba3db36c115e9170d16984131","_kg_hide-input":false},"cell_type":"code","source":"#sns.countplot(y='surface',data = y_train)\ntrace0 = go.Bar(\n    x = y_train['surface'].value_counts().index,\n    y = y_train['surface'].value_counts().values\n    )\n\ntrace1 = go.Pie(\n    labels = y_train['surface'].value_counts().index,\n    values = y_train['surface'].value_counts().values,\n    domain = {'x':[0.55,1]})\n\ndata = [trace0, trace1]\nlayout = go.Layout(\n    title = 'Frequency Distribution for surface/target data',\n    xaxis = dict(domain = [0,.50]))\n\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa07370c418b5e5814179617658eb74c71651349"},"cell_type":"markdown","source":"## Preprocessing data\n\n### Is there any missing data?"},{"metadata":{"trusted":true,"_uuid":"3829dec760a69f4e1d283afc906688998ec79458","_kg_hide-input":false},"cell_type":"code","source":"X_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4ccf370c0f1a0df7b629fb2c819854ebf8114de"},"cell_type":"markdown","source":"#### Observation: No missing data"},{"metadata":{"_uuid":"f03510dd8267322c693dbfd27e11364ddd0ef7b7"},"cell_type":"markdown","source":"### Is there any duplicate data?"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"8f708a49fcae5e7efe5147628a4d5d830b73435b"},"cell_type":"code","source":"X_train['is_duplicate'] = X_train.duplicated()\nX_train['is_duplicate'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f59513c7a1c24e1c9f22ff7d85824f4e658cf4b7"},"cell_type":"markdown","source":"#### Observation: There is no duplicate data"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"19f19ac2a9e52a64951ed175861146797c7f1deb"},"cell_type":"code","source":"X_train = X_train.drop(['is_duplicate'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1be64fe4734c0b66a6471aaa2c006d9ac3719570"},"cell_type":"markdown","source":"### Sorting based on series_id and measurement_number"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"9f5c8d51dd737aa3c00bbacc3b03263986b30355"},"cell_type":"code","source":"X_train_sort = X_train.sort_values(by = ['series_id', 'measurement_number'], ascending = True)\nX_train_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60618761456f01add7c20df75f9ffed60b7ac051"},"cell_type":"markdown","source":"### Correlation Matrix"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"812d5dcceee65b7b49a783dfc128e8a9f0b07ce3"},"cell_type":"code","source":"corr = X_train.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"209d7feaec5a2b84e716bc3712cbdc80f76ec512"},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (15,6))\n\nhm = sns.heatmap(X_train.iloc[:,3:].corr(),\n                ax = ax,\n                cmap = 'coolwarm',\n                annot = True,\n                fmt = '.2f',\n                linewidths = 0.05)\nfig.subplots_adjust(top=0.93)\nfig.suptitle('Orientation, Angular_velocity and Linear_accelaration Correlation Heatmap for Train dataset', \n              fontsize=14, \n              fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49382be75dbc0f8afdf3b35e64ab9dc642c72b55"},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (15,6))\n\nhm = sns.heatmap(X_test.iloc[:,3:].corr(),\n                ax = ax,\n                cmap = 'coolwarm',\n                annot = True,\n                fmt = '.2f',\n                linewidths = 0.05)\nfig.subplots_adjust(top=0.93)\nfig.suptitle('Orientation, Angular_velocity and Linear_accelaration Correlation Heatmap for Test dataset', \n              fontsize=14, \n              fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7935de051893834499a8819bfb0cb1cdae573c1"},"cell_type":"markdown","source":"**Observation:**\n*     orientation_X and orientation_W are strongly correlated\n*     orientation_Y and orientation_Z are strongly correlated\n*     linear_accelaration_Y and linear_accelaration_Z also has positive correlation\n*     angular_velocity_Y and angular_velocity_Z has negative correlation"},{"metadata":{"_uuid":"136694c6c89addd415d471e922b0f7396ab5400a"},"cell_type":"markdown","source":"### Box plot of angular_velocity, orientation and linear_accelaration data"},{"metadata":{"trusted":true,"_uuid":"37eca2bbd6ca4cca4085c876b44357ab3fd9ecfd","_kg_hide-input":false},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\nax = fig.add_subplot(311)\nax.set_title('Distribution of Orientation_X,Y,Z,W',\n             fontsize=14, \n             fontweight='bold')\nX_train.iloc[:,3:7].boxplot()\nax = fig.add_subplot(312)\nax.set_title('Distribution of Angular_Velocity_X,Y,Z',fontsize=14, \n             fontweight='bold')\nX_train.iloc[:,7:10].boxplot()\nax = fig.add_subplot(313)\nax.set_title('Distribution of linear_accelaration_X,Y,Z',fontsize=14, \n             fontweight='bold')\nX_train.iloc[:,10:13].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6853d35ad43c26185526284091006b1174bfb27"},"cell_type":"markdown","source":"**Observation**: There are many outliers in angular_velocity and linear accelaration data"},{"metadata":{"_uuid":"3b88953c5803cb1e8019a6569be204b1e14f4c13"},"cell_type":"markdown","source":"### Histogram plot for all features"},{"metadata":{"trusted":true,"_uuid":"bf1014b7cfabbe6af7d4a9ac0614ac4913cbf48e","_kg_hide-input":false},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i, col in enumerate(X_train.columns[3:]):\n    ax = plt.subplot(3, 4, i + 1)\n    sns.distplot(X_train[col], bins=100, label='train')\n    sns.distplot(X_test[col], bins=100, label='test')\n    ax.legend()   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df9abf210f80212a27b47eaca351d38b8ae61fed"},"cell_type":"markdown","source":"### Observation:\n*    Angular velocity are normally distributed infect they are symmetrical data distribution\n*    linear_accelaration are normally distributed/symmetrical distribution but average value is slightly negative for linear_accelaration_Z\n*    X,Y,Z,W orientation data are not symmetrical or bell shaped distributed. \n*         X,Y orientation data are distributed un-even between 1 to -1.\n*         Z,W orientation data are distributed un-even between 1.5 to -1.5\n\nSince orientation data is not linearly distributed, taking log of the orientation data may improve the results."},{"metadata":{"_uuid":"2c65c139f8b8feba981b855d72ea5764c3f95e7b"},"cell_type":"markdown","source":"### Feature distribution for each target value (surface)"},{"metadata":{"trusted":true,"_uuid":"d228c9af3602cade9773376aa48f24a6845160fb","_kg_hide-input":false},"cell_type":"code","source":"df = X_train.merge(y_train, on = 'series_id', how = 'inner')\ntargets = (y_train['surface'].value_counts()).index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adbe30df3646cc7d76edd93e5dd066227708387a","_kg_hide-input":false},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i,col in enumerate(df.columns[3:13]):\n    ax = plt.subplot(3,4,i+1)\n    ax = plt.title(col)\n    for surface in targets:\n        surface_feature = df[df['surface'] == surface]\n        sns.kdeplot(surface_feature[col], label = surface)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25b717e812d494e40f153423501b929aa74d4b23"},"cell_type":"markdown","source":"**Observation:**\n\n*     For hard tile surface we can see little jerk in orientation data.\n*     for orientation_X these data range is approx 0.5 to 1.0, \n*     for orientation_Y these data range is approx -1.0 to -0.5\n*     for orientation_Z these data range is approx -0.12 to -0.8\n*     for orientation_W these data range is approx 0.07 to 0.12 \n*     for angular velocity and linear accelaration data, there is a symmetry around mean in terms of data distribution.\n    "},{"metadata":{"_uuid":"d4ad1820b3f9510bf3d1ef22b735a60c8f19f430"},"cell_type":"markdown","source":"## Feature Enginnering\n\nFeature Enginnering is the process of using domain knowledge of the data to create features that make machine learning algorithms work.\nFeature engineering is fundamental to the application of machine learning, and is both difficult and expensive.\nThe features in your data are important to the predictive models you use and will influence the results you are going to achieve. The quality and quantity of the features will have great influence on whether the model is good or not.\n\n### Euler angles\nThe Euler angles are three angles introduced by Leonhard Euler to describe the orientation of a rigid body with respect to a fixed coordinate system.\n\n### Fast Fourier Transform Denoising"},{"metadata":{"trusted":true},"cell_type":"code","source":"series_dict = {}\nfor series in (X_train['series_id'].unique()):\n    series_dict[series] = X_train[X_train['series_id'] == series] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From: Code Snippet For Visualizing Series Id by @shaz13\ndef plotSeries(series_id):\n    style.use('ggplot')\n    plt.figure(figsize=(28, 16))\n    print(y_train[y_train['series_id'] == series_id]['surface'].values[0].title())\n    for i, col in enumerate(series_dict[series_id].columns[3:]):\n        if col.startswith(\"o\"):\n            color = 'red'\n        elif col.startswith(\"a\"):\n            color = 'green'\n        else:\n            color = 'blue'\n        if i >= 7:\n            i+=1\n        plt.subplot(3, 4, i + 1)\n        plt.plot(series_dict[series_id][col], color=color, linewidth=3)\n        plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSeries(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If for whatever reason you want to denoise the signal, you can use fast fourier transform. Detailed implementation of how it's done is out of the scope of this kernel. You can learn more about it here: https://en.wikipedia.org/wiki/Fast_Fourier_transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from @theoviel at https://www.kaggle.com/theoviel/fast-fourier-transform-denoising\ndef filter_signal(signal, threshold=1e3):\n    fourier = rfft(signal)\n    frequencies = rfftfreq(signal.size, d=20e-3/signal.size)\n    fourier[frequencies > threshold] = 0\n    return irfft(fourier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# denoise train and test angular_velocity and linear_acceleration data\nX_train_denoised = X_train.copy()\nX_test_denoised = X_test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's say that I want to denoise the signal on angular_velocity and linear_acceleration column"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy.fft import *\n\n# train\nfor col in X_train.columns:\n    if col[0:3] == 'ang' or col[0:3] == 'lin':\n        # Apply filter_signal function to the data in each series\n        denoised_data = X_train.groupby(['series_id'])[col].apply(lambda x: filter_signal(x))\n        \n        # Assign the denoised data back to X_train\n        list_denoised_data = []\n        for arr in denoised_data:\n            for val in arr:\n                list_denoised_data.append(val)\n                \n        X_train_denoised[col] = list_denoised_data\n        \n# test\nfor col in X_test.columns:\n    if col[0:3] == 'ang' or col[0:3] == 'lin':\n        # Apply filter_signal function to the data in each series\n        denoised_data = X_test.groupby(['series_id'])[col].apply(lambda x: filter_signal(x))\n        \n        # Assign the denoised data back to X_train\n        list_denoised_data = []\n        for arr in denoised_data:\n            for val in arr:\n                list_denoised_data.append(val)\n                \n        X_test_denoised[col] = list_denoised_data\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's look at the result:"},{"metadata":{"trusted":true},"cell_type":"code","source":"series_dict = {}\nfor series in (X_train_denoised['series_id'].unique()):\n    series_dict[series] = X_train_denoised[X_train_denoised['series_id'] == series] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSeries(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, our signal become much smoother than before. Here's a closer comparison:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24, 8))\nplt.title('linear_acceleration_X')\nplt.plot(X_train.angular_velocity_Z[128:256], label=\"original\");\nplt.plot(X_train_denoised.angular_velocity_Z[128:256], label=\"denoised\");\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Enginnering\nFeature Enginnering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. The features in your data are important to the predictive models you use and will influence the results you are going to achieve. The quality and quantity of the features will have great influence on whether the model is good or not.\n\n## Euler angles\nThe Euler angles are three angles introduced by Leonhard Euler to describe the orientation of a rigid body with respect to a fixed coordinate system."},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles\n#quaternion to eular\ndef quaternion_to_euler(qx,qy,qz,qw):\n    import math\n    # roll (x-axis rotation)\n    sinr_cosp = +2.0 * (qw * qx + qy + qz)\n    cosr_cosp = +1.0 - 2.0 * (qx * qx + qy * qy)\n    roll = math.atan2(sinr_cosp, cosr_cosp)\n    \n    # pitch (y-axis rotation)\n    sinp = +2.0 * (qw * qy - qz * qx)\n    if(math.fabs(sinp) >= 1):\n        pitch = copysign(M_PI/2, sinp)\n    else:\n        pitch = math.asin(sinp)\n        \n    # yaw (z-axis rotation)\n    siny_cosp = +2.0 * (qw * qz + qx * qy)\n    cosy_cosp = +1.0 - 2.0 * (qy * qy + qz * qz)\n    yaw = math.atan2(siny_cosp, cosy_cosp)\n    \n    return roll, pitch, yaw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eular_angle(data):\n    x, y, z, w = data['orientation_X'].tolist(), data['orientation_Y'].tolist(), data['orientation_Z'].tolist(), data['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    data['euler_x'] = nx\n    data['euler_y'] = ny\n    data['euler_z'] = nz\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = eular_angle(X_train_denoised)\ntest = eular_angle(X_test_denoised)\nprint(data.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering\n* calculate total angular velocity\n* calculate total linear accelearation\n* calculate total orientaion\n* calculate acceleration vs velocity\n* calculate total eular angle"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe_eng1(data):\n    data['total_angular_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 + data['angular_velocity_Z']**2)** 0.5\n    data['total_linear_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 + data['linear_acceleration_Z']**2)**0.5\n    data['total_orientation'] = (data['orientation_X']**2 + data['orientation_Y']**2 + data['orientation_Z']**2)**0.5\n    data['acc_vs_vel'] = data['total_linear_acc'] / data['total_angular_vel']\n    data['total_angle'] = (data['euler_x'] ** 2 + data['euler_y'] ** 2 + data['euler_z'] ** 2) ** 5\n    data['angle_vs_acc'] = data['total_angle'] / data['total_linear_acc']\n    data['angle_vs_vel'] = data['total_angle'] / data['total_angular_vel']\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = fe_eng1(data)\ntest = fe_eng1(test)\nprint(data.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe_eng2(data):\n    df = pd.DataFrame()\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n        #in statistics, the median absolute deviation (MAD) is a robust measure of the variablility of a univariate sample of quantitative data.\n        df[col + '_mad'] = data.groupby(['series_id'])[col].apply(lambda x: np.median(np.abs(np.diff(x))))\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndata = fe_eng2(data)\ntest = fe_eng2(test)\nprint(data.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\nNow our data file sample size is same as target sample size. our test file sample size is same as number of requested series_ids."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna(0, inplace = True)\ndata.replace(-np.inf, 0, inplace = True)\ndata.replace(np.inf, 0, inplace = True)\ntest.fillna(0, inplace = True)\ntest.replace(-np.inf, 0, inplace = True)\ntest.replace(np.inf, 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny_train['surface'] = le.fit_transform(y_train['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run Model:\n#### As this is a multi class classification problem. Lets try Random Forest Classifier algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=60)\npredicted = np.zeros((test.shape[0],9))\nmeasured= np.zeros((data.shape[0]))\nscore = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for times, (trn_idx, val_idx) in enumerate(folds.split(data.values,y_train['surface'].values)):\n    model = RandomForestClassifier(n_estimators=700, n_jobs = -1)\n    #model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\n    model.fit(data.iloc[trn_idx],y_train['surface'][trn_idx])\n    measured[val_idx] = model.predict(data.iloc[val_idx])\n    predicted += model.predict_proba(test)/folds.n_splits\n    score += model.score(data.iloc[val_idx],y_train['surface'][val_idx])\n    print(\"Fold: {} score: {}\".format(times,model.score(data.iloc[val_idx],y_train['surface'][val_idx])))\n    \n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average score', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(measured,y_train['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(12,5))\nsns.heatmap(pd.DataFrame(confusion_matrix(measured,y_train['surface'])),\n            ax = ax,\n            cmap = 'coolwarm',\n            annot = True,\n            fmt = '.2f',\n            linewidths = 0.05)\nfig.subplots_adjust(top=0.93)\nfig.suptitle('Confusion matrix, Actual vs Predicted label Correlation Heatmap', \n              fontsize=14, \n              fontweight='bold')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance**\n\nUnderstanding about important features will help us fine tuning feature enginnering as well accuracy improvement."},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis = 0)\nindices = np.argsort(importances)[::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = pd.DataFrame(importances, index = data.columns, columns = ['importance'])\nfeature_importances.sort_values('importance', ascending = False)\nfeature_importances.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances.sort_values('importance', ascending = False).plot(kind = 'bar', \n                         figsize = (35,8), \n                         color = 'r', \n                         yerr=std[indices], \n                        align = 'center')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances.sort_values('importance', ascending = False)[:100].plot(kind = 'bar',\n                                                                            figsize = (30,5),\n                                                                            color = 'g', \n                                                                            yerr=std[indices[:100]], \n                                                                            align = 'center')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"less_important_features = feature_importances.loc[feature_importances['importance'] < 0.0025]\nprint('There are {0} features their importance value is less then 0.0025'.format(less_important_features.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove less important features from train and test set.\nfor i, col in enumerate(less_important_features.index):\n    data = data.drop(columns = [col], axis = 1)\n    test = test.drop(columns = [col], axis = 1)\n    \ndata.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Run ML Model Again"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = np.zeros((test.shape[0],9))\nmeasured= np.zeros((data.shape[0]))\nscore = 0\nfor times, (trn_idx, val_idx) in enumerate(folds.split(data.values,y_train['surface'].values)):\n    model = RandomForestClassifier(n_estimators=700, n_jobs = -1)\n    #model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\n    model.fit(data.iloc[trn_idx],y_train['surface'][trn_idx])\n    measured[val_idx] = model.predict(data.iloc[val_idx])\n    predicted += model.predict_proba(test)/folds.n_splits\n    score += model.score(data.iloc[val_idx],y_train['surface'][val_idx])\n    print(\"Fold: {} score: {}\".format(times,model.score(data.iloc[val_idx],y_train['surface'][val_idx])))\n    \n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average score', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:**\n\nLooks like orientation features are Most important features. we can do further feature engineering around Orientation Feature. Lets remove low importance features and then run the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission['surface'] = le.inverse_transform(predicted.argmax(axis=1))\nsubmission.to_csv('rs_surface_submission6.csv', index=False)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ref:\n\nfeature engg kernel1: https://www.kaggle.com/jesucristo/1-robots-eda-rf-cval-0-73\nkernel 2: https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics/notebook\n\nfeature importance: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n\nmedian absolute deviation: https://en.wikipedia.org/wiki/Median_absolute_deviation\nQuaternions and 3rd rotation, explained interactively: https://www.youtube.com/watch?v=zjMuIxRvygQ https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles"},{"metadata":{"trusted":true,"_uuid":"06ef22c598dddbe5ada9e8d5c31f90f1583ebd46"},"cell_type":"markdown","source":"Thanks for stopping by. Please upvote if you like my kernel. \nStay Tuned for further Analaysis and model accuracy improvement."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}