{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['X_train.csv', 'sample_submission.csv', 'X_test.csv', 'y_train.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_X_train = pd.read_csv(\"../input/X_train.csv\")\ndf_X_test = pd.read_csv(\"../input/X_test.csv\")\ndf_y_train = pd.read_csv(\"../input/y_train.csv\")\n\ndef check_for_nas(df):\n    return sum(df.isnull().sum())\n\nprint(\"Number of na values in X_train: {}\".format(check_for_nas(df_X_train)))\nprint(\"Number of na values in X_test: {}\".format(check_for_nas(df_X_test)))\nprint(\"Number of na values in y_train: {}\".format(check_for_nas(df_y_train)))","execution_count":2,"outputs":[{"output_type":"stream","text":"Number of na values in X_train: 0\nNumber of na values in X_test: 0\nNumber of na values in y_train: 0\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"e4e90a022ae2c7d60942ec23849748d5cc042f95"},"cell_type":"markdown","source":"Check surface value counts"},{"metadata":{"trusted":true,"_uuid":"7ad6f08b24701ecdc0c0f86be1981435e8b0d35a"},"cell_type":"code","source":"df_y_train['surface'].value_counts()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"concrete                  779\nsoft_pvc                  732\nwood                      607\ntiled                     514\nfine_concrete             363\nhard_tiles_large_space    308\nsoft_tiles                297\ncarpet                    189\nhard_tiles                 21\nName: surface, dtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"b99595cd04fc910b0ca7c837472f37a2a22e1fd1"},"cell_type":"markdown","source":"Imbalance is apparent - need to think about this later"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c744098f3e39238f9264ce631aba4fb7d83d1041"},"cell_type":"code","source":"def convert_q_e(list_):\n    '''Convert quaternion to euler angles.\n    list_ has 4 elements in the order mentioned below\n    or_x - X orientation\n    or_y - Y orientation\n    or_z - Z orientation\n    or_w - W orientation\n    Returns a tuple of (roll,pitch,yaw)'''\n    or_x = list_[0]\n    or_y = list_[1] \n    or_z = list_[2] \n    or_w = list_[3] \n    \n    sinr_cosp = 2 * ((or_w * or_x) + (or_y * or_z))\n    cosr_cosp = 1 - 2 * ((or_x * or_x) + (or_y * or_y))\n    roll = np.arctan2(sinr_cosp, cosr_cosp)\n    \n    pitch = None\n    sinp = 2 * ((or_w * or_y) - (or_z * or_x))\n    if abs(sinp) >= 1:\n        pitch = np.copysign(np.pi/2,sinp)\n    else:\n        pitch = np.arcsin(sinp)\n    \n    siny_cosp = 2 * ((or_w * or_z) + (or_x * or_y))\n    cosy_cosp = 1 - 2 * ((or_y * or_y) + (or_z * or_z))\n    yaw = np.arctan2(siny_cosp, cosy_cosp)\n    \n    return(roll, pitch, yaw)\n\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"174a3cb2b87a67dbfde30478f03ed85a32d23151"},"cell_type":"markdown","source":"Replace orientaion_x/y/z/w in the dataframe with euler angles in both training and test sets"},{"metadata":{"trusted":true,"_uuid":"9666eff466a84173cfe9b51dcec93620bba37921"},"cell_type":"code","source":"# Using apply to convert orientation to euler angles\norientation_col_names = ['orientation_X','orientation_Y','orientation_Z','orientation_W']\ndf_X_train_euler = df_X_train.loc[:,orientation_col_names].apply(convert_q_e,axis=1,result_type='expand')\ndf_X_train_euler.rename(columns={0:'roll',1:'pitch',2:'yaw'},inplace = True)\n\ndf_X_test_euler = df_X_test.loc[:,orientation_col_names].apply(convert_q_e,axis=1,result_type='expand')\ndf_X_test_euler.rename(columns={0:'roll',1:'pitch',2:'yaw'}, inplace=True)\n    \n# df_X_train_processed = df_X_train.drop(orientation_col_names,axis=1)\ndf_X_train_processed = pd.concat([df_X_train,df_X_train_euler], axis = 1)\n# Need to remove row_id and measurement_number as they are redundant\nredundant_cols = ['row_id','measurement_number']\ndf_X_train_processed = df_X_train_processed.drop(redundant_cols,axis=1)\n\n# df_X_test_processed = df_X_test.drop(orientation_col_names,axis=1)\ndf_X_test_processed = pd.concat([df_X_test,df_X_test_euler],axis = 1)\ndf_X_test_processed = df_X_test_processed.drop(redundant_cols, axis = 1)\n   ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab41a84d779d8793d2dfff4fa231a6ebf5d13e76"},"cell_type":"code","source":"df_X_test_processed.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   series_id  orientation_X    ...        pitch       yaw\n0          0      -0.025773    ...    -0.014254  3.091597\n1          0      -0.025683    ...    -0.014411  3.091804\n2          0      -0.025617    ...    -0.014658  3.091975\n3          0      -0.025566    ...    -0.014712  3.092085\n4          0      -0.025548    ...    -0.014434  3.092079\n\n[5 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>orientation_X</th>\n      <th>orientation_Y</th>\n      <th>orientation_Z</th>\n      <th>orientation_W</th>\n      <th>angular_velocity_X</th>\n      <th>angular_velocity_Y</th>\n      <th>angular_velocity_Z</th>\n      <th>linear_acceleration_X</th>\n      <th>linear_acceleration_Y</th>\n      <th>linear_acceleration_Z</th>\n      <th>roll</th>\n      <th>pitch</th>\n      <th>yaw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.025773</td>\n      <td>-0.98864</td>\n      <td>-0.14801</td>\n      <td>0.003350</td>\n      <td>-0.006524</td>\n      <td>-0.001071</td>\n      <td>-0.027390</td>\n      <td>0.10043</td>\n      <td>4.2061</td>\n      <td>-5.5439</td>\n      <td>2.844733</td>\n      <td>-0.014254</td>\n      <td>3.091597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>-0.025683</td>\n      <td>-0.98862</td>\n      <td>-0.14816</td>\n      <td>0.003439</td>\n      <td>-0.113960</td>\n      <td>0.083987</td>\n      <td>-0.060590</td>\n      <td>-0.70889</td>\n      <td>3.9905</td>\n      <td>-8.0273</td>\n      <td>2.844432</td>\n      <td>-0.014411</td>\n      <td>3.091804</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>-0.025617</td>\n      <td>-0.98861</td>\n      <td>-0.14826</td>\n      <td>0.003571</td>\n      <td>-0.080518</td>\n      <td>0.114860</td>\n      <td>-0.037177</td>\n      <td>1.45710</td>\n      <td>2.2828</td>\n      <td>-11.2990</td>\n      <td>2.844239</td>\n      <td>-0.014658</td>\n      <td>3.091975</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>-0.025566</td>\n      <td>-0.98862</td>\n      <td>-0.14817</td>\n      <td>0.003609</td>\n      <td>0.070067</td>\n      <td>0.033820</td>\n      <td>-0.035904</td>\n      <td>0.71096</td>\n      <td>1.8582</td>\n      <td>-12.2270</td>\n      <td>2.844418</td>\n      <td>-0.014712</td>\n      <td>3.092085</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>-0.025548</td>\n      <td>-0.98866</td>\n      <td>-0.14792</td>\n      <td>0.003477</td>\n      <td>0.152050</td>\n      <td>-0.029016</td>\n      <td>-0.015314</td>\n      <td>3.39960</td>\n      <td>2.7881</td>\n      <td>-10.4100</td>\n      <td>2.844918</td>\n      <td>-0.014434</td>\n      <td>3.092079</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"693684976737eb97e8b212c4d73b4872514eba76"},"cell_type":"markdown","source":"## Feature engineering (Need to add many more features)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"5e5e0280d7aff287658a245ba95dea0bf5a908c9"},"cell_type":"markdown","source":"Series Ids need to be grouped by and channels that have sensor information from the physical work need to be aggregated. Following ideas for aggregating sensor values need to be tested\n1. angular velocity integration - this gives the angular distance traveled for the group - assume 1 millisecond delta for this calculation\n2. Mean of absolute of linear acceleration - as a proxy for acceleration and braking for the surface\n3. sum of absolute diffs of roll/pitch/yaw - Gives the total angle covered in each dimension - proxy to swiftness\n4. Angular_velocity diff means - as a proxy to velocity angular velocity changes, mostly for changes in direction\n5. Means of all columns\n6. Standard Devs of all columns\n7. Max of all columns\n8. Min\n9. Range\n10. Median\n11. Diff of Linear acceleration is a proxy for jerk - traaction and inertia are functions of jerk\n\n\n** In this run - not using cols_affected and letting transformations work on every channel **"},{"metadata":{"trusted":true,"_uuid":"2fcbdeec5250c1d9f49a5d70d1576f2b150c3e66"},"cell_type":"code","source":"# Function to address 1\nintegration = lambda x: 0.001 * (x.diff().sum())\n\n# Function to address 2\nmean_abs = lambda x:x.abs().mean()\n\n# Function to address 3\nsum_abs = lambda x:x.abs().sum()\n\n# Function to address 4\nmean_diff = lambda x:x.mean()\n\n# Function to address 11\ndef modified_mean_diff(x):\n    res = [0]\n    res.extend(list(np.diff(x)))\n    return np.mean(res)\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to create aggregates\ndef create_aggregates(df,function,appendage,cols_affected = None):\n    '''Returns an aggregate dataset based on group_by dataset. Appendage modifies colnames by adding this string to the end of the colname\n    df - Pandas Dataframe Object on which group by is performed\n    cols_affected - list of columns on which aggregation needs to be performed\n    function - function to aggregate groupby df on\n    appendage - string to modify colnames'''\n    if cols_affected:\n        cols_affected.append('series_id')\n        df_sub = df.loc[:,cols_affected].copy()\n        group_by_df = df_sub.groupby(by=['series_id'])\n    else:\n        group_by_df = df.groupby(by=['series_id'])\n    \n    df_ = group_by_df.agg(function).rename(mapper = lambda x:x + \"_\" + appendage, axis = 'columns').copy()\n    return df_\n    ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create feature datasets based on bullet points above. Merge them later as a final step\n#Step - 1\n#Train\ndf_X_train_step_1 = create_aggregates(df_X_train_processed,function=integration,appendage='integral')\n#Test\ndf_X_test_step_1 = create_aggregates(df_X_test_processed,function=integration,appendage='integral')\n\n#Step - 2\n#Train\ndf_X_train_step_2 = create_aggregates(df_X_train_processed,function=mean_abs,appendage='mean_abs')\n#Test\ndf_X_test_step_2 = create_aggregates(df_X_test_processed,function=mean_abs,appendage='mean_abs')\n\n#Step - 3\n#Train\ndf_X_train_step_3 = create_aggregates(df_X_train_processed,function=sum_abs,appendage='sum_abs')\n#Test\ndf_X_test_step_3 = create_aggregates(df_X_test_processed,function=sum_abs,appendage='sum_abs')\n\n#Step - 4\n#Train\ndf_X_train_step_4 = create_aggregates(df_X_train_processed,function=mean_diff,appendage='mean_diff')\n#Test\ndf_X_test_step_4 = create_aggregates(df_X_test_processed,function=mean_diff,appendage='mean_diff')\n\n#Step - 5\n#Train\ndf_X_train_step_5 = create_aggregates(df_X_train_processed,function=np.mean,appendage='mean')\n#Test\ndf_X_test_step_5 = create_aggregates(df_X_test_processed,function=np.mean,appendage='mean')\n\n#Step - 6\n#Train\ndf_X_train_step_6 = create_aggregates(df_X_train_processed,function=np.std,appendage='std')\n#Test\ndf_X_test_step_6 = create_aggregates(df_X_test_processed,function=np.std,appendage='std')\n\n#Step - 7 \n#Train\ndf_X_train_step_7 = create_aggregates(df_X_train_processed,function=np.max,appendage='max')\n#Test\ndf_X_test_step_7 = create_aggregates(df_X_test_processed,function=np.max,appendage='max')\n\n#Step - 8\n#Trainm\ndf_X_train_step_8 = create_aggregates(df_X_train_processed,function=np.min,appendage='min')\n#Test\ndf_X_test_step_8 = create_aggregates(df_X_test_processed,function=np.min,appendage='min')\n\n# Step-9\n#Train\ndf_X_train_step_9 = create_aggregates(df_X_train_processed,function=np.ptp,appendage='ptp')\n#Test\ndf_X_test_step_9 = create_aggregates(df_X_test_processed,function=np.ptp,appendage='ptp')\n\n# Step - 10\n#Train\ndf_X_train_step_10 = create_aggregates(df_X_train_processed,function=np.median,appendage='median')\n#Test\ndf_X_test_step_10 = create_aggregates(df_X_test_processed,function=np.median,appendage='median')\n\n# Step - 11\n#Train\ndf_X_train_step_11 = create_aggregates(df_X_train_processed,function=modified_mean_diff,appendage='mod_diff')\n#Test\ndf_X_test_step_11 = create_aggregates(df_X_test_processed,function=modified_mean_diff,appendage='mod_diff')","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_master = pd.concat([df_X_train_step_1,df_X_train_step_2,df_X_train_step_3,df_X_train_step_4,df_X_train_step_5,df_X_train_step_6,df_X_train_step_7,df_X_train_step_8,df_X_train_step_9,df_X_train_step_10,df_X_train_step_11],axis=1,join='inner')\nX_test_master = pd.concat([df_X_test_step_1,df_X_test_step_2,df_X_test_step_3,df_X_test_step_4,df_X_test_step_5,df_X_test_step_6,df_X_test_step_7,df_X_test_step_8,df_X_test_step_9,df_X_test_step_10,df_X_test_step_11],axis=1,join='inner')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_master.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"           orientation_X_integral      ...       yaw_mod_diff\nseries_id                              ...                   \n0                   -1.000000e-06      ...          -0.000027\n1                    3.200000e-07      ...          -0.000028\n2                   -4.900000e-06      ...          -0.000091\n3                    3.800000e-07      ...          -0.000024\n4                   -1.016000e-05      ...           0.000368\n\n[5 rows x 143 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orientation_X_integral</th>\n      <th>orientation_Y_integral</th>\n      <th>orientation_Z_integral</th>\n      <th>orientation_W_integral</th>\n      <th>angular_velocity_X_integral</th>\n      <th>angular_velocity_Y_integral</th>\n      <th>angular_velocity_Z_integral</th>\n      <th>linear_acceleration_X_integral</th>\n      <th>linear_acceleration_Y_integral</th>\n      <th>linear_acceleration_Z_integral</th>\n      <th>roll_integral</th>\n      <th>pitch_integral</th>\n      <th>yaw_integral</th>\n      <th>orientation_X_mean_abs</th>\n      <th>orientation_Y_mean_abs</th>\n      <th>orientation_Z_mean_abs</th>\n      <th>orientation_W_mean_abs</th>\n      <th>angular_velocity_X_mean_abs</th>\n      <th>angular_velocity_Y_mean_abs</th>\n      <th>angular_velocity_Z_mean_abs</th>\n      <th>linear_acceleration_X_mean_abs</th>\n      <th>linear_acceleration_Y_mean_abs</th>\n      <th>linear_acceleration_Z_mean_abs</th>\n      <th>roll_mean_abs</th>\n      <th>pitch_mean_abs</th>\n      <th>yaw_mean_abs</th>\n      <th>orientation_X_sum_abs</th>\n      <th>orientation_Y_sum_abs</th>\n      <th>orientation_Z_sum_abs</th>\n      <th>orientation_W_sum_abs</th>\n      <th>angular_velocity_X_sum_abs</th>\n      <th>angular_velocity_Y_sum_abs</th>\n      <th>angular_velocity_Z_sum_abs</th>\n      <th>linear_acceleration_X_sum_abs</th>\n      <th>linear_acceleration_Y_sum_abs</th>\n      <th>linear_acceleration_Z_sum_abs</th>\n      <th>roll_sum_abs</th>\n      <th>pitch_sum_abs</th>\n      <th>yaw_sum_abs</th>\n      <th>orientation_X_mean_diff</th>\n      <th>...</th>\n      <th>yaw_min</th>\n      <th>orientation_X_ptp</th>\n      <th>orientation_Y_ptp</th>\n      <th>orientation_Z_ptp</th>\n      <th>orientation_W_ptp</th>\n      <th>angular_velocity_X_ptp</th>\n      <th>angular_velocity_Y_ptp</th>\n      <th>angular_velocity_Z_ptp</th>\n      <th>linear_acceleration_X_ptp</th>\n      <th>linear_acceleration_Y_ptp</th>\n      <th>linear_acceleration_Z_ptp</th>\n      <th>roll_ptp</th>\n      <th>pitch_ptp</th>\n      <th>yaw_ptp</th>\n      <th>orientation_X_median</th>\n      <th>orientation_Y_median</th>\n      <th>orientation_Z_median</th>\n      <th>orientation_W_median</th>\n      <th>angular_velocity_X_median</th>\n      <th>angular_velocity_Y_median</th>\n      <th>angular_velocity_Z_median</th>\n      <th>linear_acceleration_X_median</th>\n      <th>linear_acceleration_Y_median</th>\n      <th>linear_acceleration_Z_median</th>\n      <th>roll_median</th>\n      <th>pitch_median</th>\n      <th>yaw_median</th>\n      <th>orientation_X_mod_diff</th>\n      <th>orientation_Y_mod_diff</th>\n      <th>orientation_Z_mod_diff</th>\n      <th>orientation_W_mod_diff</th>\n      <th>angular_velocity_X_mod_diff</th>\n      <th>angular_velocity_Y_mod_diff</th>\n      <th>angular_velocity_Z_mod_diff</th>\n      <th>linear_acceleration_X_mod_diff</th>\n      <th>linear_acceleration_Y_mod_diff</th>\n      <th>linear_acceleration_Z_mod_diff</th>\n      <th>roll_mod_diff</th>\n      <th>pitch_mod_diff</th>\n      <th>yaw_mod_diff</th>\n    </tr>\n    <tr>\n      <th>series_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.000000e-06</td>\n      <td>0.000001</td>\n      <td>2.700000e-07</td>\n      <td>-8.700000e-07</td>\n      <td>-0.000034</td>\n      <td>0.000003</td>\n      <td>0.000018</td>\n      <td>0.000214</td>\n      <td>-0.001300</td>\n      <td>-0.000944</td>\n      <td>-9.493624e-07</td>\n      <td>1.028808e-06</td>\n      <td>-0.000003</td>\n      <td>0.758666</td>\n      <td>0.634008</td>\n      <td>0.105474</td>\n      <td>0.106470</td>\n      <td>0.041248</td>\n      <td>0.026411</td>\n      <td>0.014996</td>\n      <td>0.764930</td>\n      <td>2.984195</td>\n      <td>9.320391</td>\n      <td>2.841734</td>\n      <td>0.025037</td>\n      <td>1.396035</td>\n      <td>97.10922</td>\n      <td>81.15298</td>\n      <td>13.500690</td>\n      <td>13.628110</td>\n      <td>5.279737</td>\n      <td>3.380616</td>\n      <td>1.919517</td>\n      <td>97.911042</td>\n      <td>381.976947</td>\n      <td>1193.0100</td>\n      <td>363.741973</td>\n      <td>3.204732</td>\n      <td>178.692530</td>\n      <td>-0.758666</td>\n      <td>...</td>\n      <td>1.393233</td>\n      <td>0.00131</td>\n      <td>0.00150</td>\n      <td>0.001530</td>\n      <td>0.001460</td>\n      <td>0.268060</td>\n      <td>0.152102</td>\n      <td>0.081901</td>\n      <td>4.71820</td>\n      <td>5.310983</td>\n      <td>6.2439</td>\n      <td>0.003720</td>\n      <td>0.002233</td>\n      <td>0.004169</td>\n      <td>-0.758530</td>\n      <td>-0.634270</td>\n      <td>-0.105500</td>\n      <td>-0.106555</td>\n      <td>-0.005082</td>\n      <td>-0.004037</td>\n      <td>0.006842</td>\n      <td>0.231665</td>\n      <td>3.40755</td>\n      <td>-9.42995</td>\n      <td>2.841582</td>\n      <td>-0.025049</td>\n      <td>1.396673</td>\n      <td>-0.000008</td>\n      <td>0.000010</td>\n      <td>0.000002</td>\n      <td>-0.000007</td>\n      <td>-0.000264</td>\n      <td>0.000022</td>\n      <td>0.000138</td>\n      <td>0.001674</td>\n      <td>-0.010153</td>\n      <td>-0.007373</td>\n      <td>-0.000007</td>\n      <td>8.037563e-06</td>\n      <td>-0.000027</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.200000e-07</td>\n      <td>0.000002</td>\n      <td>1.238000e-06</td>\n      <td>7.400000e-07</td>\n      <td>-0.000212</td>\n      <td>0.000029</td>\n      <td>0.000108</td>\n      <td>-0.002178</td>\n      <td>-0.000180</td>\n      <td>-0.000753</td>\n      <td>8.629812e-07</td>\n      <td>2.255212e-06</td>\n      <td>-0.000004</td>\n      <td>0.958606</td>\n      <td>0.241867</td>\n      <td>0.031650</td>\n      <td>0.146876</td>\n      <td>0.072018</td>\n      <td>0.035467</td>\n      <td>0.058881</td>\n      <td>0.796827</td>\n      <td>2.873462</td>\n      <td>9.388899</td>\n      <td>2.840129</td>\n      <td>0.010369</td>\n      <td>0.492731</td>\n      <td>122.70162</td>\n      <td>30.95897</td>\n      <td>4.051239</td>\n      <td>18.800070</td>\n      <td>9.218290</td>\n      <td>4.539781</td>\n      <td>7.536752</td>\n      <td>101.993821</td>\n      <td>367.803192</td>\n      <td>1201.7791</td>\n      <td>363.536528</td>\n      <td>1.327174</td>\n      <td>63.069540</td>\n      <td>-0.958606</td>\n      <td>...</td>\n      <td>-0.494641</td>\n      <td>0.00059</td>\n      <td>0.00196</td>\n      <td>0.001837</td>\n      <td>0.002220</td>\n      <td>0.538220</td>\n      <td>0.246410</td>\n      <td>0.250760</td>\n      <td>8.29360</td>\n      <td>8.834200</td>\n      <td>14.1831</td>\n      <td>0.004715</td>\n      <td>0.002964</td>\n      <td>0.004477</td>\n      <td>-0.958595</td>\n      <td>0.241890</td>\n      <td>0.031688</td>\n      <td>-0.146910</td>\n      <td>0.010344</td>\n      <td>-0.006330</td>\n      <td>0.003538</td>\n      <td>0.003571</td>\n      <td>2.75010</td>\n      <td>-9.41380</td>\n      <td>2.840183</td>\n      <td>-0.010446</td>\n      <td>-0.492860</td>\n      <td>0.000003</td>\n      <td>0.000012</td>\n      <td>0.000010</td>\n      <td>0.000006</td>\n      <td>-0.001656</td>\n      <td>0.000224</td>\n      <td>0.000844</td>\n      <td>-0.017017</td>\n      <td>-0.001403</td>\n      <td>-0.005886</td>\n      <td>0.000007</td>\n      <td>1.761885e-05</td>\n      <td>-0.000028</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-4.900000e-06</td>\n      <td>0.000003</td>\n      <td>9.000000e-07</td>\n      <td>-9.040000e-07</td>\n      <td>0.000079</td>\n      <td>-0.000006</td>\n      <td>-0.000059</td>\n      <td>-0.002076</td>\n      <td>-0.000574</td>\n      <td>-0.002513</td>\n      <td>6.939526e-07</td>\n      <td>7.779561e-07</td>\n      <td>-0.000012</td>\n      <td>0.512057</td>\n      <td>0.846171</td>\n      <td>0.129371</td>\n      <td>0.071082</td>\n      <td>0.048996</td>\n      <td>0.028078</td>\n      <td>0.029764</td>\n      <td>0.613776</td>\n      <td>2.951067</td>\n      <td>9.395783</td>\n      <td>2.845529</td>\n      <td>0.012195</td>\n      <td>2.055021</td>\n      <td>65.54334</td>\n      <td>108.30988</td>\n      <td>16.559440</td>\n      <td>9.098478</td>\n      <td>6.271455</td>\n      <td>3.594032</td>\n      <td>3.809751</td>\n      <td>78.563381</td>\n      <td>377.736515</td>\n      <td>1202.6602</td>\n      <td>364.227651</td>\n      <td>1.560956</td>\n      <td>263.042744</td>\n      <td>-0.512057</td>\n      <td>...</td>\n      <td>2.049684</td>\n      <td>0.00490</td>\n      <td>0.00289</td>\n      <td>0.001780</td>\n      <td>0.001157</td>\n      <td>0.294630</td>\n      <td>0.199756</td>\n      <td>0.104427</td>\n      <td>4.44630</td>\n      <td>7.464500</td>\n      <td>6.7548</td>\n      <td>0.003743</td>\n      <td>0.000939</td>\n      <td>0.011604</td>\n      <td>-0.512035</td>\n      <td>-0.846210</td>\n      <td>-0.129405</td>\n      <td>-0.071139</td>\n      <td>-0.003120</td>\n      <td>-0.010880</td>\n      <td>0.028323</td>\n      <td>0.174515</td>\n      <td>3.03375</td>\n      <td>-9.37440</td>\n      <td>2.845432</td>\n      <td>-0.012184</td>\n      <td>2.055114</td>\n      <td>-0.000038</td>\n      <td>0.000023</td>\n      <td>0.000007</td>\n      <td>-0.000007</td>\n      <td>0.000619</td>\n      <td>-0.000050</td>\n      <td>-0.000457</td>\n      <td>-0.016215</td>\n      <td>-0.004486</td>\n      <td>-0.019630</td>\n      <td>0.000005</td>\n      <td>6.077782e-06</td>\n      <td>-0.000091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.800000e-07</td>\n      <td>0.000001</td>\n      <td>2.850000e-07</td>\n      <td>7.200000e-07</td>\n      <td>0.000339</td>\n      <td>-0.000071</td>\n      <td>0.000073</td>\n      <td>-0.003095</td>\n      <td>-0.001076</td>\n      <td>0.002814</td>\n      <td>1.226530e-06</td>\n      <td>5.479731e-07</td>\n      <td>-0.000003</td>\n      <td>0.939169</td>\n      <td>0.310140</td>\n      <td>0.038955</td>\n      <td>0.142319</td>\n      <td>0.141238</td>\n      <td>0.034867</td>\n      <td>0.026243</td>\n      <td>1.172727</td>\n      <td>4.140862</td>\n      <td>9.451164</td>\n      <td>2.845777</td>\n      <td>0.015107</td>\n      <td>0.635656</td>\n      <td>120.21364</td>\n      <td>39.69794</td>\n      <td>4.986241</td>\n      <td>18.216810</td>\n      <td>18.078451</td>\n      <td>4.462933</td>\n      <td>3.359077</td>\n      <td>150.109006</td>\n      <td>530.030322</td>\n      <td>1209.7490</td>\n      <td>364.259493</td>\n      <td>1.933725</td>\n      <td>81.363929</td>\n      <td>-0.939169</td>\n      <td>...</td>\n      <td>-0.638340</td>\n      <td>0.00084</td>\n      <td>0.00204</td>\n      <td>0.001877</td>\n      <td>0.005030</td>\n      <td>0.920650</td>\n      <td>0.303930</td>\n      <td>0.158759</td>\n      <td>7.99660</td>\n      <td>17.568100</td>\n      <td>19.2859</td>\n      <td>0.010790</td>\n      <td>0.001053</td>\n      <td>0.004046</td>\n      <td>-0.939170</td>\n      <td>0.310115</td>\n      <td>0.038889</td>\n      <td>-0.142510</td>\n      <td>0.006709</td>\n      <td>0.000518</td>\n      <td>0.005856</td>\n      <td>0.317205</td>\n      <td>3.00885</td>\n      <td>-9.16170</td>\n      <td>2.845451</td>\n      <td>-0.015081</td>\n      <td>-0.635690</td>\n      <td>0.000003</td>\n      <td>0.000011</td>\n      <td>0.000002</td>\n      <td>0.000006</td>\n      <td>0.002651</td>\n      <td>-0.000553</td>\n      <td>0.000566</td>\n      <td>-0.024180</td>\n      <td>-0.008404</td>\n      <td>0.021983</td>\n      <td>0.000010</td>\n      <td>4.281039e-06</td>\n      <td>-0.000024</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.016000e-05</td>\n      <td>-0.000021</td>\n      <td>-3.524000e-06</td>\n      <td>-6.500000e-07</td>\n      <td>0.000013</td>\n      <td>0.000027</td>\n      <td>-0.000022</td>\n      <td>-0.000650</td>\n      <td>-0.000467</td>\n      <td>0.000692</td>\n      <td>1.658707e-06</td>\n      <td>1.007567e-07</td>\n      <td>0.000047</td>\n      <td>0.891301</td>\n      <td>0.428144</td>\n      <td>0.060056</td>\n      <td>0.136460</td>\n      <td>0.038324</td>\n      <td>0.046109</td>\n      <td>0.142385</td>\n      <td>0.349918</td>\n      <td>2.981498</td>\n      <td>9.349988</td>\n      <td>2.842442</td>\n      <td>0.009793</td>\n      <td>0.894147</td>\n      <td>114.08647</td>\n      <td>54.80246</td>\n      <td>7.687225</td>\n      <td>17.466930</td>\n      <td>4.905417</td>\n      <td>5.901899</td>\n      <td>18.225288</td>\n      <td>44.789454</td>\n      <td>381.631730</td>\n      <td>1196.7985</td>\n      <td>363.832589</td>\n      <td>1.253551</td>\n      <td>114.450875</td>\n      <td>-0.891301</td>\n      <td>...</td>\n      <td>-0.915040</td>\n      <td>0.01016</td>\n      <td>0.02094</td>\n      <td>0.003524</td>\n      <td>0.001940</td>\n      <td>0.184974</td>\n      <td>0.075533</td>\n      <td>0.150568</td>\n      <td>2.09851</td>\n      <td>4.476030</td>\n      <td>3.5260</td>\n      <td>0.002548</td>\n      <td>0.000834</td>\n      <td>0.047056</td>\n      <td>-0.890940</td>\n      <td>0.428865</td>\n      <td>0.060113</td>\n      <td>-0.136560</td>\n      <td>0.010157</td>\n      <td>0.047561</td>\n      <td>-0.146670</td>\n      <td>-0.054043</td>\n      <td>3.13565</td>\n      <td>-9.33280</td>\n      <td>2.842437</td>\n      <td>-0.009803</td>\n      <td>-0.895723</td>\n      <td>-0.000079</td>\n      <td>-0.000164</td>\n      <td>-0.000028</td>\n      <td>-0.000005</td>\n      <td>0.000103</td>\n      <td>0.000211</td>\n      <td>-0.000174</td>\n      <td>-0.005075</td>\n      <td>-0.003652</td>\n      <td>0.005409</td>\n      <td>0.000013</td>\n      <td>7.871615e-07</td>\n      <td>0.000368</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the datasets before proceeding to classification tasks\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nscaler = StandardScaler()\nX_train_master_scaled = scaler.fit_transform(X_train_master)\nX_test_master_scaled = scaler.fit_transform(X_test_master)\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Y_train is not numeric yet - convert using LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny_labels_encoded = le.fit_transform(df_y_train['surface'])","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Try a GDBT/RandomForest\nTrying on a GDBT before moving on to Neural Nets (Assuming Neural Nets are superior for this problem)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n\n# param_grid = {'n_estimators':[500],'max_depth':[5],'max_features':['log2']}\n\n# param_grid = {'n_estimators':[500]}\ngdbt = GradientBoostingClassifier()\n\n# gscv = GridSearchCV(estimator=gdbt,param_grid=param_grid,cv=5)\ngscv = GradientBoostingClassifier(n_estimators=500,max_depth=5,max_features='log2')\ngscv.fit(X_train_master_scaled,y_labels_encoded)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=5,\n              max_features='log2', max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=1, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=500,\n              n_iter_no_change=None, presort='auto', random_state=None,\n              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"Best score: {}\".format(gscv.best_score_))\n# print(\"Best Classifier: {}\".format(gscv.best_estimator_))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\ndef write_to_csv(test_array,classifier,encoder,output_file_name=\"predictions.csv\"):\n    '''Writes a sample csv\n    test_array - numpy array; this needs to be sorted on series_id\n    classifier - result from cross vaidation analysis\n    encoder - label encoder used for labels'''\n    predictions = classifier.predict(test_array)\n    transformed_predictions = list((encoder.inverse_transform(predictions)))\n    series_id = list(range(len(transformed_predictions)))\n    df_ = pd.DataFrame({'series_id':series_id,'surface':transformed_predictions})\n    df_.to_csv(output_file_name,index=False)\n    return df_\n    \n# write_to_csv(X_test_master_scaled,gscv.best_estimator_,le)\nwrite_to_csv(X_test_master_scaled,gscv,le)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"      series_id                 surface\n0             0                   tiled\n1             1                  carpet\n2             2                   tiled\n3             3                    wood\n4             4              soft_tiles\n5             5                concrete\n6             6                concrete\n7             7                concrete\n8             8                    wood\n9             9                    wood\n10           10           fine_concrete\n11           11                soft_pvc\n12           12                    wood\n13           13                soft_pvc\n14           14                   tiled\n15           15                    wood\n16           16                  carpet\n17           17                    wood\n18           18                soft_pvc\n19           19                soft_pvc\n20           20                soft_pvc\n21           21                  carpet\n22           22                soft_pvc\n23           23  hard_tiles_large_space\n24           24                concrete\n25           25                    wood\n26           26                concrete\n27           27                   tiled\n28           28                  carpet\n29           29                concrete\n...         ...                     ...\n3786       3786                   tiled\n3787       3787                concrete\n3788       3788  hard_tiles_large_space\n3789       3789                concrete\n3790       3790                concrete\n3791       3791  hard_tiles_large_space\n3792       3792                    wood\n3793       3793                    wood\n3794       3794                concrete\n3795       3795                concrete\n3796       3796  hard_tiles_large_space\n3797       3797                concrete\n3798       3798                    wood\n3799       3799                concrete\n3800       3800              soft_tiles\n3801       3801                    wood\n3802       3802           fine_concrete\n3803       3803                concrete\n3804       3804                concrete\n3805       3805                    wood\n3806       3806                concrete\n3807       3807                soft_pvc\n3808       3808                   tiled\n3809       3809  hard_tiles_large_space\n3810       3810                concrete\n3811       3811                soft_pvc\n3812       3812                  carpet\n3813       3813                concrete\n3814       3814                   tiled\n3815       3815                    wood\n\n[3816 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>surface</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>carpet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>carpet</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>carpet</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>hard_tiles_large_space</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>carpet</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3786</th>\n      <td>3786</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>3787</th>\n      <td>3787</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3788</th>\n      <td>3788</td>\n      <td>hard_tiles_large_space</td>\n    </tr>\n    <tr>\n      <th>3789</th>\n      <td>3789</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3790</th>\n      <td>3790</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3791</th>\n      <td>3791</td>\n      <td>hard_tiles_large_space</td>\n    </tr>\n    <tr>\n      <th>3792</th>\n      <td>3792</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>3793</th>\n      <td>3793</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>3794</th>\n      <td>3794</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3795</th>\n      <td>3795</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3796</th>\n      <td>3796</td>\n      <td>hard_tiles_large_space</td>\n    </tr>\n    <tr>\n      <th>3797</th>\n      <td>3797</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3798</th>\n      <td>3798</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>3799</th>\n      <td>3799</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3800</th>\n      <td>3800</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>3801</th>\n      <td>3801</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>3802</th>\n      <td>3802</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>3803</th>\n      <td>3803</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3804</th>\n      <td>3804</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3805</th>\n      <td>3805</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>3806</th>\n      <td>3806</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3807</th>\n      <td>3807</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>3808</th>\n      <td>3808</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>3809</th>\n      <td>3809</td>\n      <td>hard_tiles_large_space</td>\n    </tr>\n    <tr>\n      <th>3810</th>\n      <td>3810</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3811</th>\n      <td>3811</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>3812</th>\n      <td>3812</td>\n      <td>carpet</td>\n    </tr>\n    <tr>\n      <th>3813</th>\n      <td>3813</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3814</th>\n      <td>3814</td>\n      <td>tiled</td>\n    </tr>\n    <tr>\n      <th>3815</th>\n      <td>3815</td>\n      <td>wood</td>\n    </tr>\n  </tbody>\n</table>\n<p>3816 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Softmax regression using tensor-flow\nIdea is to build a neural-net in tensor-flow and perform softmax regression. Therefore, one-hot encoding needs to be performed so that each of the surface types is assigned a bit on a 9-bit vector\n\nconcrete - [1 0 0 0 0 0 0 0 0] <br/>\nsoft_pvc = [0 1 0 0 0 0 0 0 0] <br/>\n.\n.\nso on\n\nStart with a 2 - layer 128 -> 9 hidden unit neural network\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import OneHotEncoder\n# surface_labels = np.array(df_y_train['surface']).reshape(-1,1)\n# ohe = OneHotEncoder(handle_unknown='ignore')\n# surface_labels_ohe = ohe.fit_transform(surface_labels).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n\n# x = tf.placeholder(tf.float32,[None,X_train_master.shape[1]])\n\n# W1 = tf.Variable(tf.random.normal([X_train_master.shape[1],256]))\n# b1 = tf.Variable(tf.zeros([1,256]))\n# Z1 = tf.matmul(x,W1) + b1\n# sigma1 = tf.nn.relu(Z1)\n\n# W2 = tf.Variable(tf.random.normal([256,9]))\n# b2 = tf.Variable(tf.zeros([1,9]))\n# Z2 = tf.matmul(sigma1, W2) + b2\n# sigma2 = tf.nn.sigmoid(Z2)\n\n# y = tf.nn.softmax(sigma2)\n# y_ = tf.placeholder(tf.float32,[None,surface_labels_ohe.shape[1]])\n\n\n\n# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n# train_step = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cross_entropy)\n\n\n# init = tf.global_variables_initializer()\n\n# max_iter = 10000\n\n# with tf.Session() as sess:\n#     sess.run(init)\n#     iters = 0\n#     while iters < max_iter:\n# #         for i in range(X_train_master_scaled.shape[0]):\n# #         print(sess.run(W1,feed_dict={x:X_train_master_scaled[i,:].reshape(1,93),y_:surface_labels_ohe[i,:].reshape(1,9)}))\n#         sess.run(train_step,feed_dict={x:X_train_master_scaled.reshape(-1,93),y_:surface_labels_ohe.reshape(-1,9)})\n# #         print(sess.run(cross_entropy,feed_dict={x:X_train_master_scaled.reshape(-1,93),y_:surface_labels_ohe.reshape(-1,9)}))\n#         iters = iters + 1\n    \n#     prediction = tf.argmax(y,1)\n#     predicted_labels = prediction.eval(feed_dict={x: X_train_master_scaled.reshape(-1,93)})\n#     correct_prediction = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(y,1), tf.argmax(y_,1)),tf.float32)) / 3810\n#     print(correct_prediction.eval(feed_dict={x:X_train_master_scaled.reshape(-1,93),y_:surface_labels_ohe.reshape(-1,9)}))\n    \n#     print(prediction.eval(feed_dict={x: X_train_master_scaled.reshape(-1,93)}))\n    \n# y = tf.nn.softmax(tf.matmul(x,W) + b)\n\n# y_ = tf.placeholder(tf.float32,[None,surface_labels_ohe.shape[1]])\n\n# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n# train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n# sess = tf.Session()\n# tf.global_variables_initializer().run(session=sess)\n\n# train_features = X_train_master[10000:]\n# train_labels = surface_labels_ohe[10000:]\n\n# for _ in range(1000):\n#   batch_xs, batch_ys = train_features, train_labels\n#   sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\n    \n# sess.close()\n# # correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\nprediction = tf.argmax(y,1)\npredicted_labels = prediction.eval(feed_dict={x: train_features})\n# print(prediction.eval(feed_dict={x: train_features}))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = tf.Variable([0],dtype=tf.float32)\nx = tf.placeholder(tf.float32,[3,1])\ncost = x[0][0] * w ** 2 + x[1][0] * w + x[2][0]\ncoeff = np.array([[1],[-10],[25]])\nW1 = tf.Variable(tf.random.normal([X_train_master.shape[1],128]))\n\ntrain = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    print(sess.run(W1))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}