{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.metrics import *\nfrom keras.callbacks import *\n\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.callbacks import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7498bf996ce9eb63276d8689a52b42ea9acf999c"},"cell_type":"code","source":"x_train = pd.read_csv(\"../input/X_train.csv\")\nx_test = pd.read_csv(\"../input/X_test.csv\")\ny_train = pd.read_csv(\"../input/y_train.csv\")\nx_train.sort_values(['series_id', 'measurement_number'], inplace=True)\nx_test.sort_values(['series_id', 'measurement_number'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def quaternion_to_euler(x, y, z, w):\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n    return X, Y, Z\n\ndef extra_columns(df):\n    x, y, z, w = df['orientation_X'].tolist(), df['orientation_Y'].tolist(), df['orientation_Z'].tolist(), df['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    df['deuler_x'] = np.diff(np.array(nx), prepend=0)\n    df['deuler_y'] = np.diff(np.array(ny), prepend=0)\n    df['deuler_z'] = np.diff(np.array(nz), prepend=0)\n    for v in ['deuler_x', 'deuler_y', 'deuler_z']:\n        sel = df[v] > math.pi\n        df.loc[sel, v] = 2 * math.pi - df[v][sel]\n        sel = df[v] < -math.pi\n        df.loc[sel, v] = 2 * math.pi + df[v][sel]\n      \n    df['deuler_2'] = np.sqrt(df['deuler_x']**2 + df['deuler_y']**2 + df['deuler_z']**2)\n    df['angular_velocity_2'] = ((df['orientation_X'] * df['orientation_X'].shift(1) + \\\n                                 df['orientation_Y'] * df['orientation_Y'].shift(1) + \\\n                                 df['orientation_Z'] * df['orientation_Z'].shift(1)) / 1.001).apply(math.acos)\n    df['dorientation_aW'] = np.abs(np.diff(df['orientation_W'], prepend=0))\n    df['linear_acceleration'] = np.sqrt(df['linear_acceleration_X']**2 + df['linear_acceleration_Y']**2 + df['linear_acceleration_Z']**2)\n    df['angular_velocity'] = np.sqrt(df['angular_velocity_X']**2 + df['angular_velocity_Y']**2 + df['angular_velocity_Z']**2)\n    \n    df['linear_to_angular'] = df['linear_acceleration'] / (df['angular_velocity'] + 1e-6)\n    df['angular_to_linear'] = df['angular_velocity'] / (df['linear_acceleration'] + 1e-6)\n    return df\n\nx_train = extra_columns(x_train)\nx_test = extra_columns(x_test)\nvarnames = x_train.columns[3:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nplt.matshow(pd.concat([x_train, x_test]).drop(['row_id', 'series_id', 'measurement_number'], axis = 1).corr())\n# plt.xticks(np.arange(len(varnames)),varnames)\nplt.yticks(np.arange(len(varnames)),varnames)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_seq = []\nfor i in sorted(x_train['series_id'].unique()):\n    seq = x_train[x_train['series_id']==i]\n    seq = seq.sort_values(\"measurement_number\")\n    train_seq.append(seq.drop(['row_id', 'series_id', 'measurement_number'], axis = 1).values)\ntest_seq = []\nfor i in sorted(x_test['series_id'].unique()) :\n    seq = x_test[x_test['series_id']==i]\n    seq = seq.sort_values(\"measurement_number\")\n    test_seq.append(seq.drop(['row_id', 'series_id', 'measurement_number'], axis = 1).values)\n    \ntrain_seq = np.array(train_seq)\ntest_seq = np.array(test_seq)\n\nclass_num = y_train['surface'].unique().shape[0]\ny_group = y_train['group_id'].values\ny_train = pd.get_dummies(y_train['surface'])\nlabel_name = [col for col in y_train.columns]\ny_train = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_features = ['deuler_x', 'deuler_y', 'deuler_z', 'deuler_2', 'dorientation_aW']\nfor v in diff_features:\n    train_seq[:,0,varnames==v] = 0\n    test_seq[:,0,varnames==v] = 0\ntrain_seq[:,0,varnames=='angular_velocity_2'] = train_seq[:,1,varnames=='angular_velocity_2']\ntest_seq[:,0,varnames=='angular_velocity_2']  =  test_seq[:,1,varnames=='angular_velocity_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means = np.mean(train_seq, axis=(0,1))\nstd = np.std(train_seq, axis=(0,1))\ntrain_seq = (train_seq - means[np.newaxis,np.newaxis,:]) / std[np.newaxis,np.newaxis,:]\ntest_seq = (test_seq - means[np.newaxis,np.newaxis,:]) / std[np.newaxis,np.newaxis,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i in range(len(varnames)):\n    plt.subplot(5,5,i+1)\n    plt.title(varnames[i])\n    plt.plot(train_seq[1,:,i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def res_block(nchannels, ksize, x):\n    y = x\n    y = layers.ELU()(y)\n    y = layers.BatchNormalization()(y)\n    y = layers.Conv1D(nchannels, ksize, padding='same')(y)\n    y = layers.ELU()(y)\n    y = layers.BatchNormalization()(y)\n    y = layers.Conv1D(nchannels, ksize, padding='same')(y)\n    x = layers.add([x, y])\n    return x\n    \ndef cnn_model(input_shape, class_num) :\n    inp = Input((input_shape[1], input_shape[2]))\n    x = layers.BatchNormalization(axis=2)(inp)\n    x = layers.Conv1D(32, 3, padding='same')(x)\n    for l in range(4):\n        x = res_block(32, 3, x)\n        x = res_block(32, 3, x)\n        x = res_block(32, 3, x)\n        x = AveragePooling1D(2)(x)\n    x = layers.ELU()(x)\n    x = layers.BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dense(class_num, activation=\"softmax\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(optimizer=\"adadelta\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99271e01d6456d7e2d71864ab228c5c5fe238fd5","scrolled":false},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nrandom_seed = 1\nnp.random.seed(random_seed)\n\nfold = StratifiedKFold(12, shuffle = True, random_state = random_seed)\noof_train = np.zeros((train_seq.shape[0], class_num))\noof_test = np.zeros((test_seq.shape[0], class_num))\nhist = []\nfor i, (trn, val) in enumerate(list(fold.split(y_train, np.argmax(y_train, axis = 1)))):\n    model = cnn_model(train_seq.shape, class_num)\n    chk = ModelCheckpoint(\"best_weight.wt\", monitor='val_acc', mode = 'max', save_best_only = True, verbose = 0)\n    est = EarlyStopping(patience=200, verbose = 0)\n    rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=0.01, verbose = 0)\n    hist.append(model.fit(train_seq[trn], y_train[trn], verbose = 0,\n                          epochs = 500, batch_size = 3072,\n                          validation_data = [train_seq[val], y_train[val]],\n                          callbacks = [chk, est, rlp]))\n    model.load_weights(\"best_weight.wt\")\n    oof_train[val] = model.predict(train_seq[val])\n    oof_test += model.predict(test_seq) / fold.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('OOF metrics\\nAcc: %f\\nLoss: %f' % (np.mean(K.eval(categorical_accuracy(y_train, oof_train))),\n                             np.mean(K.eval(categorical_crossentropy(K.constant(y_train), K.constant(oof_train))))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nnfolds = len(hist)\nfor i in range(nfolds):\n    plt.subplot(nfolds, 2, 2*i+1)\n    plt.plot(hist[i].history['val_acc'])\n    plt.plot(hist[i].history['acc'])\n    if i == 0: plt.title('Acc')\n    plt.legend([\"validation\", \"training\"])\n    plt.subplot(nfolds, 2, 2*i+2)\n    plt.plot(hist[i].history['val_loss'])\n    plt.plot(hist[i].history['loss'])\n    if i == 0: plt.title('Loss')\n    plt.legend([\"validation\", \"training\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abc3acf73a3ebde0dccd4deba290567cdc305eff"},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['surface'] = pd.DataFrame(np.argmax(oof_test, axis = 1))[0].apply(lambda x : label_name[x]).values.reshape(-1)\nsubmission.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"surface\", data=pd.read_csv(\"../input/y_train.csv\"), order=label_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9531f35e0b9d05ee6f93561070fe9dcd50eb86d"},"cell_type":"code","source":"sns.countplot(x=\"surface\", data=submission, order=label_name)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}