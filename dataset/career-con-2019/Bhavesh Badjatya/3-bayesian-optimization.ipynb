{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nfrom seaborn import countplot,lineplot, barplot\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45bf3abc194d6fdb0b8a34cfc5e8b4fdd38c1970"},"cell_type":"code","source":"from IPython.display import HTML\nimport base64\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8efc94a8f1091ea44f114cc3b6fac1d1be4abfc5"},"cell_type":"code","source":"tr = pd.read_csv('../input/X_train.csv')\nte = pd.read_csv('../input/X_test.csv')\ntarget = pd.read_csv('../input/y_train.csv')\nss = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0a0121537e7d91b14cccf9b05b277e16c92b9c8"},"cell_type":"code","source":"def quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z\n\ndef fe(actual):\n    new = pd.DataFrame()\n    actual['total_angular_velocity'] = (actual['angular_velocity_X'] ** 2 + actual['angular_velocity_Y'] ** 2 + actual['angular_velocity_Z'] ** 2) ** 0.5\n    actual['total_linear_acceleration'] = (actual['linear_acceleration_X'] ** 2 + actual['linear_acceleration_Y'] ** 2 + actual['linear_acceleration_Z'] ** 2) ** 0.5\n    \n    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n    \n    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    \n    actual['total_angle'] = (actual['euler_x'] ** 2 + actual['euler_y'] ** 2 + actual['euler_z'] ** 2) ** 5\n    actual['angle_vs_acc'] = actual['total_angle'] / actual['total_linear_acceleration']\n    actual['angle_vs_vel'] = actual['total_angle'] / actual['total_angular_velocity']\n    \n    def f1(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n    \n    def f2(x):\n        return np.mean(np.abs(np.diff(x)))\n    \n    for col in actual.columns:\n        if col in ['row_id', 'series_id', 'measurement_number']:\n            continue\n        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n        \n        # Change. 1st order.\n        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(f2)\n        \n        # Change of Change. 2nd order.\n        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(f1)\n        \n        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n\n    return new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e7d99ffecde84e5f373c8e885c9c92f514526b6"},"cell_type":"code","source":"tr = fe(tr)\nte = fe(te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcd46eeff92e422ead23d0bf5d08d5d31d896868"},"cell_type":"code","source":"train_labels= target['surface']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3f1a4c5b995e7ba6a931abb41a0db5e1f50f518"},"cell_type":"code","source":"tr.fillna(0, inplace = True)\nte.fillna(0, inplace = True)\ntr.replace(-np.inf, 0, inplace = True)\ntr.replace(np.inf, 0, inplace = True)\nte.replace(-np.inf, 0, inplace = True)\nte.replace(np.inf, 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f72e38ece4a078d1a40def7493b0b4838b4e80bf"},"cell_type":"code","source":"le = LabelEncoder()\ntrain_label_encoded = le.fit_transform(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78361af62459f3621639f4944882f2fcd50c519a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_features, test_features, train_labels, test_labels = train_test_split(tr,train_label_encoded,test_size = 0.33 ,random_state = 50)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_set = lgb.Dataset(train_features, label = train_labels)\ntest_set = lgb.Dataset(test_features, label = test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"934b0e14468d01ee6c5d86101a0666d818051f1b"},"cell_type":"code","source":"import csv\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\nfrom hyperopt import hp\nfrom hyperopt.pyll.stochastic import sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7dce77b2e4eaf0d55b28606ed0766353868bca1"},"cell_type":"code","source":"space = {\n    'boosting_type': hp.choice('boosting_type', \n                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b751ebdc8987453a641047d668968480f1f3d64"},"cell_type":"code","source":"x = sample(space)\n\n# Conditional logic to assign top-level keys\nsubsample = x['boosting_type'].get('subsample', 1.0)\nx['boosting_type'] = x['boosting_type']['boosting_type']\nx['subsample'] = subsample\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bc0b688bf7429b591632ee02535d4b29038bcd5"},"cell_type":"code","source":"from hyperopt import tpe\n\n# Create the algorithm\ntpe_algorithm = tpe.suggest\n\n\nfrom hyperopt import Trials\n\n# Record results\ntrials = Trials()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b8c5f97cf1a51d3e4a16fdbbe9c8b2248af2fa7"},"cell_type":"code","source":"\nfrom hyperopt import fmin\n\n\n# Global variable\nglobal  ITERATION\n\nITERATION = 0\n\n# Run optimization\n# best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n#             max_evals = MAX_EVALS)\n\n# best\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a3dfc99771902aa270e47a766f66a126f30ed2f"},"cell_type":"code","source":"def objective(hyperparameters):\n    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n       Writes a new line to `outfile` on every iteration\"\"\"\n    \n    # Keep track of evals\n    global ITERATION\n    \n    ITERATION += 1\n    \n    # Using early stopping to find number of trees trained\n    if 'n_estimators' in hyperparameters:\n        del hyperparameters['n_estimators']\n    \n    # Retrieve the subsample\n    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n    \n    # Extract the boosting type and subsample to top level keys\n    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n    hyperparameters['subsample'] = subsample\n    \n    # Make sure parameters that need to be integers are integers\n    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n\n    start = timer()\n    \n    # Perform n_folds cross validation\n    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n\n    run_time = timer() - start\n    \n    # Extract the best score\n    best_score = cv_results['auc-mean'][-1]\n    \n    # Loss must be minimized\n    loss = 1 - best_score\n    \n    # Boosting rounds that returned the highest cv score\n    n_estimators = len(cv_results['auc-mean'])\n    \n    # Add the number of estimators to the hyperparameters\n    hyperparameters['n_estimators'] = n_estimators\n\n    # Write to the csv file ('a' means append)\n#     of_connection = open(OUT_FILE, 'a')\n#     writer = csv.writer(of_connection)\n#     writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n#     of_connection.close()\n\n    # Dictionary with information for evaluation\n    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n            'train_time': run_time, 'status': STATUS_OK}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e033fbd012d3e3d34d58a13ed38f0477785a8c64"},"cell_type":"code","source":"N_FOLDS = 5\nMAX_EVALS = 5\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a44a792b6c173e2a71d3a0cdcf2d76e98b79dfc0"},"cell_type":"code","source":"# best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n#             max_evals = MAX_EVALS)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}