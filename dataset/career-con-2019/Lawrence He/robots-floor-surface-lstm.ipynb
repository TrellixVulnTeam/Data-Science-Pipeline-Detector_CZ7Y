{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nif device == torch.device('cuda'):\n    print( torch.cuda.get_device_properties( device ) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_train = pd.read_csv('/kaggle/input/career-con-2019/X_train.csv')\ndf_y_train = pd.read_csv('/kaggle/input/career-con-2019/y_train.csv')\n\ndf_X_train_train = df_X_train[df_X_train['series_id'] % 4 != 2]\ndf_X_train_val = df_X_train[df_X_train['series_id'] % 4 == 2]\ndf_y_train_train = df_y_train[df_y_train['series_id'] % 4 != 2]\ndf_y_train_val = df_y_train[df_y_train['series_id'] % 4 == 2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset Class and DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class RoboDataset(Dataset):\n    def __init__(self, X_df, y_df, sequence_length=128):\n        self.X = X_df\n        self.y = y_df\n        self.seq_len = sequence_length\n        self.class_onehot = {\n            'carpet': 0,\n            'concrete': 1,\n            'fine_concrete': 2,\n            'hard_tiles': 3,\n            'hard_tiles_large_space': 4,\n            'soft_pvc': 5,\n            'soft_tiles': 6,\n            'tiled': 7,\n            'wood': 8\n        }\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        data = self.X.iloc[self.seq_len*idx : self.seq_len*(idx+1)].drop(\n            columns=['row_id','series_id','measurement_number']).values.astype('float32')\n        label = self.class_onehot[self.y.iloc[idx]['surface']]\n        \n        return_dict = {'data': data, 'label': label}\n        return return_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = RoboDataset(df_X_train_train, df_y_train_train)\nvalset = RoboDataset(df_X_train_val, df_y_train_val)\n\nbatch_size=64\ntrainloader = DataLoader(trainset, shuffle=True, batch_size=batch_size)\nvalloader = DataLoader(valset, shuffle=False, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LSTM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_dim=10, hidden_dim=256, num_layers=2, output_dim=9, \n                 dropout=0):\n        \"\"\"\n        input_dim = number of features at each time step \n                    (number of features given to each LSTM cell)\n        hidden_dim = number of features produced by each LSTM cell (in each layer)\n        num_layers = number of LSTM layers\n        output_dim = number of classes of the floor texture\n        \"\"\"\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, \n                            num_layers=num_layers, batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        \n        \n    def forward(self, X):\n        hidden_features, (h_n, c_n) = self.lstm(X)  # (h_0, c_0) default to zeros\n        hidden_features = hidden_features[:,-1,:]  # index only the features produced by the last LSTM cell\n        out = self.fc(hidden_features)\n        return out\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training/Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.001\nn_epochs = 1000\niterations_per_epoch = len(trainloader)\nbest_acc = 0\npatience, patience_counter = 50, 0\n\nmodel = LSTMClassifier(dropout=0.75)\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Start model training')\n\nfor epoch in range(1, n_epochs + 1):\n    \n    # initialize losses\n    loss_train_total = 0\n    loss_val_total = 0\n    \n    # Training loop\n    for i, batch_data in enumerate(trainloader):\n        model.train()\n        X_batch = batch_data['data'].to(device)\n        y_batch = batch_data['label'].to(device).long()\n        optimizer.zero_grad()\n        \n        y_pred = model(X_batch) \n        loss = criterion(y_pred, y_batch)\n        loss_train_total += loss.cpu().detach().item() * batch_size\n        \n        loss.backward()\n        optimizer.step()\n    \n    loss_train_total = loss_train_total / len(trainset)\n    \n    \n    # Validation loop\n    with torch.no_grad():\n        for i, batch_data in enumerate(valloader):\n            model.eval()\n            X_batch = batch_data['data'].to(device)\n            y_batch = batch_data['label'].to(device).long()\n\n            y_pred = model(X_batch)\n            loss = criterion(y_pred, y_batch)\n            loss_val_total += loss.cpu().detach().item() * batch_size\n\n    loss_val_total = loss_val_total / len(valset)\n    \n    \n    # Validation Accuracy\n    correct, total = 0, 0\n    with torch.no_grad():\n        model.eval()\n        for i, batch_data in enumerate(valloader):\n            X_batch = batch_data['data'].to(device)\n            y_batch = batch_data['label'].to(device).long()\n\n            y_pred = model(X_batch)\n            class_predictions = F.log_softmax(y_pred, dim=1).argmax(dim=1)\n            total += y_batch.size(0)\n            correct += (class_predictions == y_batch).sum().item()\n\n    acc = correct / total\n\n    \n    # Logging\n    if epoch % 5 == 0:\n        print(f'Epoch: {epoch:3d}. Train Loss: {loss_train_total:.4f}. Val Loss: {loss_val_total:.4f} Acc.: {acc:2.2%}')\n\n    if acc > best_acc:\n        patience_counter = 0\n        best_acc = acc\n        torch.save(model.state_dict(), 'best.pth')\n        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f'Early stopping on epoch {epoch}')\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}