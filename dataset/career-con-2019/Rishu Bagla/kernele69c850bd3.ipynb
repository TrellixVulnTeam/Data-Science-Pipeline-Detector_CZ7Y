{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](http://)![](http://)Importing the required library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom seaborn import countplot,lineplot, barplot\nimport math\nimport lightgbm as lgb\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom mlxtend.classifier import SoftmaxRegression\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom numpy import argmax\nfrom sklearn.metrics import accuracy_score\nfrom keras.regularizers import l1\nfrom scipy import stats\nfrom keras.layers import Dropout\nimport statistics\nimport os\nimport random\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest = pd.read_csv(\"../input/X_test.csv\")\nxtrain = pd.read_csv(\"../input/X_train.csv\")\nytrain = pd.read_csv(\"../input/y_train.csv\")\nssb = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)![](http://)**Check the shape of imported data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest.shape, xtrain.shape, ytrain.shape, ssb.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check the different type of floor present**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of surface: {}'.format(ytrain.surface.nunique()))\ncountplot(y = 'surface', data = ytrain)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the chart we found that hard_tiles has very less number of dataset which might effect out our model prediction on hard_tiles observation. To develop better model it suggested to gather more data for Hard_tile floor. On the other hand cocrete contains the maximum dataset which results better prediction on concrete. As the difference between the dataset of concrete and hard_tile is very high it can lead us under fitting the resul on hard_tile and overfitting the result on concrete "},{"metadata":{},"cell_type":"markdown","source":"**Check our imported dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check the shape of our test set result**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check our imported test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we know robot is free to move in all 3 direction and final movement velocity depends on resultant velocity of robot. \nW = Wx+Wy+Wz\nTo increase the accuracy of our model first we will list down all the required parameter that will affect robot movement"},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant_velocity = (xtrain['angular_velocity_X']**2+\nxtrain['angular_velocity_Y']**2+  \nxtrain['angular_velocity_Z']**2)**.5\nresultant_velocity= pd.DataFrame(resultant_velocity, columns = ['resultant_velocity'])\n#sc_x = StandardScaler()\n#resultant_velocity_n = pd.DataFrame(sc_x.fit_transform(resultant_velocity),columns=resultant_velocity.columns, index=resultant_velocity.index )\n#resultant_velocity_n = np.array(resultant_velocity_n)\nresultant_velocity.shape\nresultant_velocity.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resultant acceleration = sq.root(Ax^2+Ay^2+Az^2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant_acc = (xtrain['linear_acceleration_X']**2+\nxtrain['linear_acceleration_Y']**2+  \nxtrain['linear_acceleration_Z']**2)**.5\n#resultant_acc= np.transpose(np.matrix(np.array(resultant_acc.T)))\nresultant_acc= pd.DataFrame(resultant_acc, columns = ['resultant_acc'])\n#sc_y = StandardScaler()\n#resultant_acc = pd.DataFrame(sc_x.fit_transform(resultant_acc),columns=resultant_acc.columns, index=resultant_acc.index )\nresultant_acc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For robot, Difference between different floor is fiction provided by different floor. All 9 floor mentioned in problem statement has different frictional resistance.\n\n**Friction:**  \n• The resistance between two surfaces when attempting to slide one object across the other.  \n• Friction is due to interactions at molecular level where “rough edges” bond together:\n• Friction is always opposite to the direction of motion\nAs the robot overcome the friction force by its internal power. Power is a fuction of mass, acceleration and velocity of moving object. Hence we consider power as one of factor for our model\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"power=resultant_velocity['resultant_velocity']*resultant_acc['resultant_acc']\n#As floor is fuction of friction, To estimate the friction factor differ force eq is required. Power is one of the factor on which friction force depends\npower= pd.DataFrame(power, columns = ['power'])\npower.head()\n#xtrain_new = np.hstack((xtrain,resultant_velocity,resultant_acc,power))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x, y, z, w = xtrain['orientation_X'].tolist(), xtrain['orientation_Y'].tolist(), xtrain['orientation_Z'].tolist(), xtrain['orientation_W'].tolist()\n#t0 = 2*np.multiply(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x = xtrain.iloc[:,3].values\n#y = xtrain.iloc[:,4].values\n#z = xtrain.iloc[:,5].values\n#w = xtrain.iloc[:,6].values\n\n#a0 = +2.0 * (np.multiply(w,x) + np.multiply(y , z))\n#a1 = +1.0 - 2.0 * (np.multiply(x , x) + np.multiply(y , y))\n#A = np.arctan2(a0,a1)\n\n#a2 = +2.0 * (np.multiply(w , y) - np.multiply(z , x))\n#B = np.arcsin(a2)\n\n#a3 = +2.0 * (np.multiply(w , z) + np.multiply(x , y))\n#a4 = +1.0 - 2.0 * (np.multiply(y , y) + np.multiply(z , z))\n#C = np.arctan2(a3, a4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A.shape, B.shape, C.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xtrain['euler_rotation_x'] = A\n#xtrain['euler_rotation_y'] = B\n#xtrain['euler_rotation_z'] = C\n#xtrain['resultant_angle'] = (xtrain['euler_rotation_x'] ** 2 + xtrain['euler_rotation_y'] ** 2 + xtrain['euler_rotation_z'] ** 2)** .5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Combine calculated parameter in a matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_new= pd.concat([xtrain,resultant_velocity, resultant_acc, power], axis=1)\nxtrain_new.shape\nxtrain_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the data set we found that train sample result is given on the basis of series_id. To increase the training sample we expand our result as per out training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = xtrain_new.merge(ytrain, on='series_id')\nmerged.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extracting type of floor from our created matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"y =merged.iloc[:,16:18].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y = pd.DataFrame(y)\n#y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating labelencoder matrix of our outcomes of training sample**"},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder = LabelEncoder()\ny[:,1] = labelencoder.fit_transform(y[:, 1])\n#y.shape\nonehotencoder = OneHotEncoder(categorical_features = [1])\ny = onehotencoder.fit_transform(y).toarray()\n#y = onehotencoder.fit_transform(ytrain).toarray()\n#Y_Train_f = Y_Train_f[:, 1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y[:,0:9]\ny_train.shape\ny_Train = pd.DataFrame(y_train)\ny_Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = xtrain_new.iloc[:,3:16]\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(x)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalising our generated Training data set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nx = sc.fit_transform(x)\nx=pd.DataFrame(x)\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain_new = xtrain_new.groupby('series_id')['power','resultant_velocity','resultant_acc'].mean()\nytrain_new = pd.DataFrame(ytrain_new).reset_index()\nytrain_new.columns = ['serie_id','avg_power','avg_velocity','avg_acc']\nytrain_new['surface'] = ytrain.surface\nytrain_new['group_id'] = ytrain.group_id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To select our model, we will first start obseving relaion between our different inputs.\nCheck the behaviour of power w.r.t different surface"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(10, 5))\nsns.boxplot(x='surface',y='avg_power',data=ytrain_new, ax=axes)\nplt.title('avg_power vs surface')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot we found that its difficult to distinguish between different surface on the basis of power, similary we will see the relation between different independent variable\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(10, 5))\nsns.boxplot(x='surface',y='avg_acc',data=ytrain_new, ax=axes)\nplt.title('avg_acc vs surface')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot power vs velocity\nf, axes = plt.subplots(figsize=(10, 5))\nsns.lineplot(data=ytrain_new, x='avg_acc', y='avg_power', hue='surface',ax=axes)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(10, 5))\nsns.lineplot(data=ytrain_new, x='avg_velocity', y='avg_power', hue='surface',ax=axes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(10, 5))\nsns.lineplot(data=ytrain_new, x='avg_velocity', y='avg_acc', hue='surface',ax=axes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(10, 5))\nsns.boxplot(x='surface',y='avg_power',data=ytrain_new, ax=axes)\nplt.title('avg_power vs surface')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see its not possible to identify the surface from any single parameter.\nWe will use all the identified parameter and built a ANN model to identify the surface"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(x, y_train, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We spilt our test into training and test in the ratio of 60 to 40. To avoid under fitting problem we divide our data set (60:40). As we need more test set to verify our result"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_Test = pd.DataFrame(Y_test)\nY_Test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_TEST = Y_Test.idxmax(axis=1)\nY_TEST.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We built our model with folowing confrigation-\n\nHidden layer = 4\n\nBy heat and trial method we founnd that maximum for accuracy occured with folowing activation function\n\nFirst Layer - relu\nSecond layer - tanh\nThird Layer - tanh\n\nAs we have multiple outputs (9 surfaces) we used the softmax function in the output layer\n\nWe need an optimize epoch size, if epoch size is less then it create underfitting problem and if epoch size is high it consume high processing power and create overfitting problem.\nreverse is valid as for batch size"},{"metadata":{"trusted":true},"cell_type":"code","source":"    #initializing ANN\nclassifier = Sequential()\n\n    # Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 20, init = 'uniform', activation = 'relu', input_dim = 13 ))\n\n    # Adding the second hidden layer\nclassifier.add(Dense(output_dim = 20, init = 'uniform', activation = 'tanh',))\n\n#classifier.add(Dropout(0.2))\n\n    # Adding the third hidden layer\nclassifier.add(Dense(output_dim = 20, init = 'uniform', activation = 'tanh'))\n\n#classifier.add(Dropout(0.2))\n\n    # Adding the output layer\nclassifier.add(Dense(output_dim = 9, init = 'uniform', activation = 'softmax'))\n\n    # Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \nclassifier.fit(X_train, Y_train, batch_size = 50, nb_epoch = 25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict our result over created test sample**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test, verbose=True)\ny_pred =pd.DataFrame(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_Pred = y_pred.idxmax(axis=1)\ny_Pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy in Test set=\",accuracy_score(Y_TEST, y_Pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating dataset for to predict result on test set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant_velocity1 = (xtest['angular_velocity_X']**2+ xtest['angular_velocity_Y']**2+ xtest['angular_velocity_Z']**2)**.5\nresultant_velocity1= pd.DataFrame(resultant_velocity1, columns = ['resultant_velocity1'])\nresultant_acc1 = (xtest['linear_acceleration_X']**2+\nxtest['linear_acceleration_Y']**2+  \nxtest['linear_acceleration_Z']**2)**.5\n#resultant_acc= np.transpose(np.matrix(np.array(resultant_acc.T)))\nresultant_acc1= pd.DataFrame(resultant_acc1, columns = ['resultant_acc1'])\npower1=resultant_velocity1['resultant_velocity1']*resultant_acc1['resultant_acc1']\n#As floor is fuction of friction, To estimate the friction factor differ force eq is required. Power is one of the factor on which friction force depends\npower1= pd.DataFrame(power1, columns = ['power1'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant_velocity1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant_acc1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"power1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xt = xtest.iloc[:,3].values\n#yt = xtest.iloc[:,4].values\n#zt = xtest.iloc[:,5].values\n#wt = xtest.iloc[:,6].values\n\n#b0 = +2.0 * (np.multiply(wt,xt) + np.multiply(yt , zt))\n#b1 = +1.0 - 2.0 * (np.multiply(xt , xt) + np.multiply(yt , yt))\n#b1.shape\n#Xt = np.arctan2(b0,b1)\n\n#b2 = +2.0 * (np.multiply(wt , yt) - np.multiply(zt , xt))\n\n#Yt = np.arcsin(b2)\n\n#b3 = +2.0 * (np.multiply(wt , zt) + np.multiply(xt , yt))\n#b4 = +1.0 - 2.0 * (np.multiply(yt , yt) + np.multiply(zt , zt))\n#Zt = np.arctan2(b3, b4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Xt.shape, Yt.shape, Zt.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xtest['euler_rotation_x'] = Xt\n#xtest['euler_rotation_y'] = Yt\n#xtest['euler_rotation_z'] = Zt  \n#xtest['resultant_angle'] = (xtest['euler_rotation_x'] ** 2 + xtest['euler_rotation_y'] ** 2 + xtest['euler_rotation_z'] ** 2) ** .5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest_new= pd.concat([xtest,resultant_velocity1, resultant_acc1, power1], axis=1)\nx3 = xtest_new\nxtest_new.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest_new = xtest_new.iloc[:, 3:16]\nxtest_new = pd.DataFrame(xtest_new)\nxtest_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xtest_new = xtest_new.groupby('series_id')['orientation_X','orientation_Y','orientation_Z','orientation_W', 'linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z', 'angular_velocity_X','angular_velocity_Y','angular_velocity_Z','resultant_velocity1','resultant_acc1','power1',].mean()\n#xtest_new.head()\n#xtest_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nxtest_new = sc.fit_transform(xtest_new)\nxtest_new= pd.DataFrame(xtest_new)\nxtest_new.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final = classifier.predict(xtest_new)\nY_test_final=pd.DataFrame(Y_test_final)\nY_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final.columns = ['carpet','concrete','fine_concrete','hard_tiles', 'hard_tiles_large_space', 'soft_pvc', 'soft_tiles','tiled','wood']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final = Y_test_final.idxmax(axis=1)\nY_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final= pd.DataFrame(Y_test_final, columns = ['surface'])\nY_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seriesid_f = x3.iloc[:,1]\nseriesid_f.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seriesid_f= pd.DataFrame(seriesid_f, columns = ['series_id'])\nseriesid_f.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final1 = pd.concat([seriesid_f, Y_test_final], axis=1)\nY_test_final1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final3 = Y_test_final1.pivot_table(values=[\"surface\"], index=[\"series_id\"], aggfunc=pd.mode)\nY_test_final3 = Y_test_final1.pivot_table(values=[\"surface\"],\n                                   index=[\"series_id\"],\n                                   aggfunc=lambda x: x.mode().iat[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final4= Y_test_final3.iloc[:,0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final2 = Y_test_final1.groupby('series_id')['surface'].mode\n#Y_test_final2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final = Y_test_final.iloc[:, [1,17,18,19,20,21,22,23,24,25] ].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final = Y_test_final.groupby('series_id')['surface'].mode()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final.columns = ['carpet','concrete','fine_concrete','hard_tiles', 'hard_tiles_large_space', 'soft_pvc', 'soft_tiles','tiled','wood']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final = Y_test_final.idxmax(axis=1)\n#Y_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Y_test_final = pd.DataFrame(Y_test_final, columns = ['surface'])\n#Y_test_final = Y_test_final.reset_index()\n#Y_test_final.columns[0] = 'series_id'\n#Y_test_final['series_id'] = Y_test_final.index\n#Y_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_final3.to_csv(\"prediction.csv\", index = True, index_label = 'series_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Results** - \n\n***Accuracy on Train dataset = 96%***\n\n***Accuracy on Test dataset = 86%***\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}