{"cells":[{"metadata":{"_uuid":"511f9177cc5e2be0f5aebc307c63dc77c9378c6a"},"cell_type":"markdown","source":"<h1><center><font size=\"7\">CareerCon 2019 - Help Navigate Robots</font></center></h1>\n<img src=\"http://storage.googleapis.com/kaggle-competitions/kaggle/13242/logos/header.png?t=2019-03-12-23-32-42\">\n    \n## Table of contents\n1. [Introduction](#1)\n1. [Prepare for data analysis](#2)\n1. [Data exploration](#3)\n1. [Data preparation](#4)\n1. [Modeling](#5)\n1. [Submission](#6)\n1. [References](#7)"},{"metadata":{"_uuid":"8b45dc7599ac668942a7b9e5a1e1dfb5190d2153"},"cell_type":"markdown","source":"# <a id='1'></a>1. Introduction  \n\nThe task is to predict which one of the floor types (concrete, tiles, pvc, carpet, wood) the robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they wonâ€™t fall down on the job. We need to classify on which surface our robot is standing.\n\nIn this notebook we will explore the data, prepare it for a model, train a model and classify the target value (surface type) for the test set, then prepare a submission.\n\n"},{"metadata":{"_uuid":"df0c1d4ed092063fc0f38bacf76a66ca5b2c3a6f"},"cell_type":"markdown","source":"# <a id='2'></a>2. Prepare for data analysis\n## 2.1 Import libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\n#from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n#from sklearn.neural_network import MLPClassifier\n\nimport matplotlib.pyplot as plt #plotting\nimport seaborn as sns #higher-lever plotting\n\nimport os \nprint(os.listdir(\"../input\")) # let's print available data\nimport warnings\nwarnings.filterwarnings('ignore') # ignore warnings","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a59f9f5655411d2db5de94e4a6988ecbd71f89fd"},"cell_type":"markdown","source":"## 2.2 Read data "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv('../input/X_train.csv')\ntest_df = pd.read_csv('../input/X_test.csv')\ntarget_df = pd.read_csv('../input/y_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af14da7a4827e016fb9d1e512ec5b39b7b76361c"},"cell_type":"markdown","source":"# <a id='3'></a>3. Data exploration"},{"metadata":{"_uuid":"ee87a5a258ecb28b5743868a20696f2e88cbf1f7"},"cell_type":"markdown","source":"## 3.1 Data description\n**1. X_[train/test].csv** - the input data, covering 10 sensor channels and 128 measurements per time series plus three ID columns:\n    - row_id: The ID for this row.\n    - series_id: ID number for the measurement series. Foreign key to y_train/sample_submission.\n    - measurement_number: Measurement number within the series.\n    \nThe orientation channels encode the current angles how the robot is oriented as a quaternion (see [Wikipedia](https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles)). Angular velocity describes the angle and speed of motion, and linear acceleration components describe how the speed is changing at different times. The 10 sensor channels are:\n    - orientation_X\n    - orientation_Y\n    - orientation_Z\n    - orientation_W\n    - angular_velocity_X\n    - angular_velocity_Y\n    - angular_velocity_Z\n    - linear_acceleration_X\n    - linear_acceleration_Y\n    - linear_acceleration_Z\n    \n**2. y_train.csv** - the surfaces for training set.\n    - series_id: ID number for the measurement series.\n    - group_id: ID number for all of the measurements taken in a recording session. Provided for the training set only, to enable more cross validation strategies.\n    - surface: the target for this competition.\n\n**3. sample_submission.csv** - a sample submission file in the correct format."},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Data review"},{"metadata":{"trusted":true,"_uuid":"e7bdcc66de6ac5caaa3c86e10e20f754da10e3f8"},"cell_type":"code","source":"train_df.head(n=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05adff39a93bb12f47214b2779f892fc7971b6de"},"cell_type":"code","source":"len(train_df.measurement_number.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf8b74845c4759cfa115468000cbc49931bdbb4d"},"cell_type":"markdown","source":"We have eight types of surfaces and we should classify it on using data collected from sensors.\nLet's show the numbers of surfaces"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8fb81149e886f9b83e077c80f19ccfb874d8cd21"},"cell_type":"code","source":"target_df['surface'].value_counts().reset_index().rename(columns={'index': 'target'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ca53f993de2f0caf98e231f227b55dd28f4ff67"},"cell_type":"markdown","source":"*and visualize it.*"},{"metadata":{"trusted":true,"_uuid":"b16494b773b79a89353bc0b201b32845e6932448"},"cell_type":"code","source":"sns.set(style='whitegrid')\nsns.countplot(y = 'surface',\n              data = target_df,\n              order = target_df['surface'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (15,6));\ncorr = train_df.corr();\nmask = np.zeros_like(corr);\nmask[np.triu_indices_from(mask)] = True\nhm = sns.heatmap(corr,\n                ax = ax,\n                mask = mask,\n                cmap = 'Blues',\n                annot = True,\n                fmt = '.2f',\n                linewidths = 0.05);\nfig.subplots_adjust(top=0.93);\nfig.suptitle('Features Correlation Heatmap', \n              fontsize=14, \n              fontweight='bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='4'></a>4. Data preparation\n## 4.1 NaN in data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Are there NaNs in {}?: {}\\n'.format('train_df',train_df.isnull().values.any())+\n      'Are there NaNs in {}?: {}\\n'.format('test_df',test_df.isnull().values.any())+\n      'Are there NaNs in {}?: {}\\n'.format('target_df',target_df.isnull().values.any()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bc53558fddf6c335d6d4925e6b04fd133a7bd2d"},"cell_type":"markdown","source":"Ok, our data doesn't have any NaN's. We can continue"},{"metadata":{"_uuid":"8f5a1cb51cea2911d7c84a5b869693728cc1fefa"},"cell_type":"markdown","source":"## 4.2 Encoding categorical data\nWe have strings in target dataframe. It should be converted into numbers"},{"metadata":{"trusted":true,"_uuid":"a6f2ee689213472b94a2016716b0d5c0e79283fd"},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(target_df['surface'])\ntarget_df['surface'] = le.transform(target_df['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8becbb27b3e27e52967a608d810b68c5b977f28"},"cell_type":"code","source":"target_df['surface'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82f52bec2962b59cb1dbeab4f82f148823269949"},"cell_type":"markdown","source":"Now we have numbers instead of letters and we are ready to work with data."},{"metadata":{},"cell_type":"markdown","source":"## 4.3 Data transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df):\n    result_df = pd.DataFrame()\n    for col in df.columns:\n        if col in ['row_id', 'series_id', 'measurement_number']:\n            continue\n        result_df['{}_mean'.format(col)] = df.groupby(['series_id'])[col].mean()\n        result_df['{}_max'.format(col)] = df.groupby(['series_id'])[col].max()\n        result_df['{}_min'.format(col)] = df.groupby(['series_id'])[col].min()\n        result_df['{}_sum'.format(col)] = df.groupby(['series_id'])[col].sum()\n        result_df['{}_mean_abs_change'.format(col)] = df.groupby(['series_id']\\\n        )[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n    return result_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = get_features(train_df)\ntest_df = get_features(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace NAN to 0\ntrain_df.fillna(0, inplace=True)\ntest_df.fillna(0, inplace=True)\n\n# replace infinite value to zero\ntrain_df.replace(-np.inf, 0, inplace=True)\ntrain_df.replace(np.inf, 0, inplace=True)\ntest_df.replace(-np.inf, 0, inplace=True)\ntest_df.replace(np.inf, 0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4 Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature scaling\nsc = StandardScaler()\ntrain_df = sc.fit_transform(train_df)\ntest_df = sc.transform(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6198e0e5d644d12aee0103525cfbfdd0c1e6ff3b"},"cell_type":"markdown","source":"# <a id='5'></a>5. Modeling "},{"metadata":{},"cell_type":"markdown","source":"For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used."},{"metadata":{"trusted":true,"_uuid":"a91f8e6c4c510593e5b91f7e4949e78c31f00779"},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=111222)\nsub_preds_rf = np.zeros((test_df.shape[0],9))\noof_preds_rf = np.zeros((train_df.shape[0]))\nscore = 0\ncounter = 0\n\nprint('start training')\n\nfor train_index, test_index in folds.split(train_df, target_df['surface']):\n    \n    print('Fold {}'.format(counter+1))\n    \n    clf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n    clf.fit(train_df[train_index], target_df['surface'][train_index])\n    oof_preds_rf[test_index] = clf.predict(train_df[test_index])\n    sub_preds_rf += clf.predict_proba(test_df) / folds.n_splits\n    score += clf.score(train_df[test_index], target_df['surface'][test_index])\n    counter += 1\n    \n    print('score : {}'.format(clf.score(train_df[test_index], target_df['surface'][test_index])))\n\nprint('avg accuracy : {}'.format(score / folds.n_splits))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='6'></a>6. Submission  "},{"metadata":{"_uuid":"8819d14ea90e9ceee7968f250b676371b0b28a72"},"cell_type":"markdown","source":"In this competition submissions are evaluated on Multiclass Accuracy, which is simply the average number of observations with the correct label.\nFor each series_id in the test set, we must predict a value for the surface variable. The file should have the following format:\n\n    series_id,surface\n    0,fine_concrete\n    1,concrete\n    2,concrete\n    etc.\n    \nTo submit the correct format, use LabelEncoder().inverse_transform() to transform labels back to original encoding."},{"metadata":{"trusted":true,"_uuid":"ba90d1b7a205454e0a0f38571a0ed46df02b3bb5"},"cell_type":"code","source":"submit = pd.read_csv('../input/sample_submission.csv')\nsubmit['surface'] = le.inverse_transform(sub_preds_rf.argmax(axis=1))\nsubmit.to_csv('submit.csv', index=False)\n\nprint('Ready')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b6aa80727580b75d6de1e2df02cdd6a16d2d482"},"cell_type":"markdown","source":"# <a id='7'></a>7. References  "},{"metadata":{"trusted":true,"_uuid":"98f1558e798014bfc2ddb600ae5bae6c1beabede"},"cell_type":"markdown","source":"1) https://www.kaggle.com/taigokuriyama/random-forest-baseline"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}