{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nfrom time import time\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import rcParams\n%matplotlib inline\nle = preprocessing.LabelEncoder()\nfrom numba import jit\nimport itertools\nfrom seaborn import countplot,lineplot, barplot\nfrom numba import jit\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn import preprocessing\nfrom scipy.stats import randint as sp_randint\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport matplotlib.style as style \nstyle.use('ggplot')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/X_train.csv')\ntr = pd.read_csv('../input/X_train.csv')\nsub = pd.read_csv('../input/sample_submission.csv')\ntest = pd.read_csv('../input/X_test.csv')\ntarget = pd.read_csv('../input/y_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.groupby('group_id').surface.nunique().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target['group_id'].nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='darkgrid')\nsns.countplot(y = 'surface',\n              data = target,\n              order = target['surface'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series_dict = {}\nfor series in (data['series_id'].unique()):\n    series_dict[series] = data[data['series_id'] == series]  \n    \n    \ndef plotSeries(series_id):\n    style.use('ggplot')\n    plt.figure(figsize=(28, 16))\n    print(target[target['series_id'] == series_id]['surface'].values[0].title())\n    for i, col in enumerate(series_dict[series_id].columns[3:]):\n        if col.startswith(\"o\"):\n            color = 'red'\n        elif col.startswith(\"a\"):\n            color = 'green'\n        else:\n            color = 'blue'\n        if i >= 7:\n            i+=1\n        plt.subplot(3, 4, i + 1)\n        plt.plot(series_dict[series_id][col], color=color, linewidth=3)\n        plt.title(col)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_series = 9\nplotSeries(id_series)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_series = 10\nplotSeries(id_series)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_series = 11\nplotSeries(id_series)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_series = 13\nplotSeries(id_series)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del series_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.enable()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(tr.iloc[:,3:].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_distribution(df1, df2, label1, label2, features,a=2,b=5):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(a,b,figsize=(17,9))\n\n    for feature in features:\n        i += 1\n        plt.subplot(a,b,i)\n        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data.columns.values[3:]\nplot_feature_distribution(data, test, 'train', 'test', features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_class_distribution(classes,tt, features,a=5,b=2):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(a,b,figsize=(16,24))\n\n    for feature in features:\n        i += 1\n        plt.subplot(a,b,i)\n        for clas in classes:\n            ttc = tt[tt['surface']==clas]\n            sns.kdeplot(ttc[feature], bw=0.5,label=clas)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = (target['surface'].value_counts()).index\naux = data.merge(target, on='series_id', how='inner')\nplot_feature_class_distribution(classes, aux, features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i, col in enumerate(data.columns[3:]):\n    ax = plt.subplot(3, 4, i + 1)\n    sns.distplot(data[col], bins=100, label='train')\n    sns.distplot(test[col], bins=100, label='test')\n    ax.legend()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z\n\n\ndef fe_step0 (actual):\n    \n    # https://www.mathworks.com/help/aeroblks/quaternionnorm.html\n    # https://www.mathworks.com/help/aeroblks/quaternionmodulus.html\n    # https://www.mathworks.com/help/aeroblks/quaternionnormalize.html\n        \n    actual['norm_quat'] = (actual['orientation_X']**2 + actual['orientation_Y']**2 + actual['orientation_Z']**2 + actual['orientation_W']**2)\n    actual['mod_quat'] = (actual['norm_quat'])**0.5\n    actual['norm_X'] = actual['orientation_X'] / actual['mod_quat']\n    actual['norm_Y'] = actual['orientation_Y'] / actual['mod_quat']\n    actual['norm_Z'] = actual['orientation_Z'] / actual['mod_quat']\n    actual['norm_W'] = actual['orientation_W'] / actual['mod_quat']\n    \n    return actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = fe_step0(data)\ntest = fe_step0(test)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe_step1 (actual):\n    \"\"\"Quaternions to Euler Angles\"\"\"\n    \n    x, y, z, w = actual['norm_X'].tolist(), actual['norm_Y'].tolist(), actual['norm_Z'].tolist(), actual['norm_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    return actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = fe_step1(data)\ntest = fe_step1(test)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feat_eng(data):\n    \n    df = pd.DataFrame()\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 + data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 + data['linear_acceleration_Z']**2)**0.5\n    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 + data['orientation_Z']**2)**0.5\n    data['acc_vs_vel'] = data['totl_linr_acc'] / data['totl_anglr_vel']\n    \n    def mean_change_of_abs_change(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_mean_change_of_abs_change'] = data.groupby('series_id')[col].apply(mean_change_of_abs_change)\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = feat_eng(data)\ntest = feat_eng(test)\nprint (\"New features: \",data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = data.corr().abs()\nraw_corr = data.corr()\n\nsol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n                 .stack()\n                 .sort_values(ascending=False))\ntop_corr = pd.DataFrame(sol).reset_index()\ntop_corr.columns = [\"var1\", \"var2\", \"abs corr\"]\n# with .abs() we lost the sign, and it's very important.\nfor x in range(len(top_corr)):\n    var1 = top_corr.iloc[x][\"var1\"]\n    var2 = top_corr.iloc[x][\"var2\"]\n    corr = raw_corr[var1][var2]\n    top_corr.at[x, \"raw corr\"] = corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna(0,inplace=True)\ntest.fillna(0,inplace=True)\ndata.replace(-np.inf,0,inplace=True)\ndata.replace(np.inf,0,inplace=True)\ntest.replace(-np.inf,0,inplace=True)\ntest.replace(np.inf,0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target['surface'] = le.fit_transform(target['surface'])\ntarget['surface'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\npredicted = np.zeros((test.shape[0],9))\nmeasured= np.zeros((data.shape[0]))\nscore = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for times, (trn_idx, val_idx) in enumerate(folds.split(data.values,target['surface'].values)):\n    model = RandomForestClassifier(n_estimators=500, n_jobs = -1)\n    #model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\n    model.fit(data.iloc[trn_idx],target['surface'][trn_idx])\n    measured[val_idx] = model.predict(data.iloc[val_idx])\n    predicted += model.predict_proba(test)/folds.n_splits\n    score += model.score(data.iloc[val_idx],target['surface'][val_idx])\n    print(\"Fold: {} score: {}\".format(times,model.score(data.iloc[val_idx],target['surface'][val_idx])))\n\n    importances = model.feature_importances_\n    indices = np.argsort(importances)\n    features = data.columns\n    \n    if model.score(data.iloc[val_idx],target['surface'][val_idx]) > 0.92000:\n        hm = 30\n        plt.figure(figsize=(7, 10))\n        plt.title('Feature Importances')\n        plt.barh(range(len(indices[:hm])), importances[indices][:hm], color='b', align='center')\n        plt.yticks(range(len(indices[:hm])), [features[i] for i in indices])\n        plt.xlabel('Relative Importance')\n        plt.show()\n\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(measured,target['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Avg Accuracy', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['surface'] = le.inverse_transform(predicted.argmax(axis=1))\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}