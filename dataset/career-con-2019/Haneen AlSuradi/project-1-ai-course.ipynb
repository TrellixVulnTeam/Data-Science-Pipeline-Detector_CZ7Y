{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# **Project 1: Classification of Time Series Data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Name: Haneen Alsuradi\nNetID: hha243","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this project, I will use 1 dimensional convolotional network to perform classification on time series data. Data is taken from Kaggle competition [Surface Type Classification] found in the link below: https://www.kaggle.com/c/career-con-2019/overview","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Step 1: Data Preparation**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The first step is to import, view and prepare the data. We import the data saved in X_train.csv and y_train.csv. We split the data to train and test as advised. After that, we view the data using the head() command from pandas.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# read Kaggle datasets\nX_train = pd.read_csv('/kaggle/input/career-con-2019/X_train.csv')\ny_train = pd.read_csv('/kaggle/input/career-con-2019/y_train.csv')\n# split X_train\nsamples = 20\ntime_series = 128\nstart_x = X_train.shape[0] - samples*time_series\nX_train_new, X_test_new = X_train.iloc[:start_x], X_train.iloc[start_x:]\n# split y_train\nstart_y = y_train.shape[0] - samples\ny_train_new, y_test_new = y_train.iloc[:start_y], y_train.iloc[start_y:]\nX_train_new.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be noticed, the first 3 columns are not part of the features and must be dropped. We drop these columns for X_train_new and X_test_new.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X_train_new=X_train_new.drop(['row_id', 'series_id','measurement_number'], axis=1)\nX_test_new=X_test_new.drop(['row_id', 'series_id','measurement_number'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have a look at the labels of the training data saved in y_train_new. We are only interested in the surface type which is the last column. We drop the other columns from y_train_new.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_new.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We drop the first two columns from the y_train_new and y_test_new as they will not be needed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_new=y_train_new.drop(['series_id', 'group_id'], axis=1)\ny_test_new=y_test_new.drop(['series_id', 'group_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we convert the dataframes to a numpy array. We extract the values from the data frame using .values. We print the shape of training and testing data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new=X_train_new.values\nX_test_new=X_test_new.values\ny_train_new=y_train_new.values\ny_test_new=y_test_new.values\nprint('The size of X_train_new:', X_train_new.shape )\nprint('The size of X_test_new:', X_test_new.shape )\n\nprint('The size of y_train_new:', y_train_new.shape )\nprint('The size of y_test_new:', y_test_new.shape )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we convert the strings (concrete, tiled, soft_tiels, ..etc.) in y_train_new and y_test_new to integer labels: 0,1,2... etc using the LabelEncorder function. After that we implement one hot coding using the to_categorical function. We have 9 types of surfaces and thus the number of cloumns for y_train_new and y_test_new  will be 9. One hot coding is suitable for 1D conv net models to prevent poor performance or unexpected results (predictions halfway between categories).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\nlabelencoder_y = LabelEncoder()\n\ny=np.concatenate([y_train_new,y_test_new])\ny=labelencoder_y.fit_transform(y)\ny=to_categorical(y)\n\n\ny_train_new = y[:-20]\ny_test_new = y[-20:]\nprint('The shape of y_train_new:', y_train_new.shape)\nprint('The shape of y_test_new:', y_test_new.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We think that the orientation of the robot moving across surfaces is not a relevant information to predict the surface type. Instead, the rate of change of the roll, yaw and pitch can serve as better features for prediction. The rate of change can be affected by the way the robot moves which is directly affected by the tyoe of surface the robot is moving on. We first calculate the roll, yaw and pitch from the orientation information using the transformation formulas as shown below. We add these features to X_train_new and X_test_new (separately) and delete the orientation features (W,X,Y,Z). The rate of change in yaw,pitch and roll will be calculated at a later step.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#FOR TRAIN DATASET\nroll=np.zeros([X_train_new.shape[0],1])\npitch=np.zeros([X_train_new.shape[0],1])\nyaw=np.zeros([X_train_new.shape[0],1])\n\n\nfor i in range(X_train_new.shape[0]):\n  roll[i] = np.arctan2(2*(X_train_new[i,1]*X_train_new[i,2] + X_train_new[i,3]*X_train_new[i,0]),1 - 2*(X_train_new[i,2]*X_train_new[i,2] + X_train_new[i,3]*X_train_new[i,3]))\n  pitch[i] = np.arcsin(2*(X_train_new[i,1]*X_train_new[i,3] - X_train_new[i,0]*X_train_new[i,2]))\n  yaw[i] = np.arctan2(2*(X_train_new[i,1]*X_train_new[i,0] + X_train_new[i,2]*X_train_new[i,3]),1 - 2*(X_train_new[i,3]*X_train_new[i,3] + X_train_new[i,0]*X_train_new[i,0]))\n\nX_train_new=np.delete(X_train_new,[0,1,2,3], 1)\nX_train_new=np.concatenate((roll,pitch,yaw,X_train_new),axis=1)\n\n#FOR TEST DATA SET\nroll=np.zeros([X_test_new.shape[0],1])\npitch=np.zeros([X_test_new.shape[0],1])\nyaw=np.zeros([X_test_new.shape[0],1])\n\n\nfor i in range(X_test_new.shape[0]):\n  roll[i] = np.arctan2(2*(X_test_new[i,1]*X_test_new[i,2] + X_test_new[i,3]*X_test_new[i,0]),1 - 2*(X_test_new[i,2]*X_test_new[i,2] + X_test_new[i,3]*X_test_new[i,3]))\n  pitch[i] = np.arcsin(2*(X_test_new[i,1]*X_test_new[i,3] - X_test_new[i,0]*X_test_new[i,2]))\n  yaw[i] = np.arctan2(2*(X_test_new[i,1]*X_test_new[i,0] + X_test_new[i,2]*X_test_new[i,3]),1 - 2*(X_test_new[i,3]*X_test_new[i,3] + X_test_new[i,0]*X_test_new[i,0]))\n\nX_test_new=np.delete(X_test_new,[0,1,2,3], 1)\nX_test_new=np.concatenate((roll,pitch,yaw,X_test_new),axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Step 2: Building the model**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The data should be reshaped in a 3D matrix to suit the 1D CNN input data shape. The first dimension is for the samples, the second for the timestamp, and the third for the featueres. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nfeatures=X_train_new.shape[1]\nntimestamp=128\nnsamples=3790\nX_3D_train=X_train_new[:,0].reshape(nsamples,ntimestamp)\nfor i in range(nfeatures-1):\n  i=i+1\n  r=X_train_new[:,i].reshape(nsamples,ntimestamp)\n  X_3D_train=np.dstack((X_3D_train,r))\nprint('The shape of X_train: ', X_3D_train.shape)\n\nnfeatures=X_test_new.shape[1]\nntimestamp=128\nnsamples=20\nX_3D_test=X_test_new[:,0].reshape(nsamples,ntimestamp)\nfor i in range(nfeatures-1):\n  i=i+1\n  r=X_test_new[:,i].reshape(nsamples,ntimestamp)\n  X_3D_test=np.dstack((X_3D_test,r))\nprint('The shape of X_test: ', X_3D_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As mentioned earlier, we need to include the rate of change for the yaw, pitch and roll as they are affected by the type of surface the robot is moving on. We calculated the roll, yaw and pitch earlier and added them to X_train_new and X_test_new. We will replace them with their rate of change instead. They are stored in the first three features. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(2):\n    rate = X_3D_train[:,:,i]\n    rate_c = np.copy(rate)\n    rate_c[:,1:] = rate_c[:,:-1]\n    rate = rate - rate_c\n    X_3D_train[:,:,i] = rate\n    \nfor i in range(2):\n    rate = X_3D_test[:,:,i]\n    rate_c = np.copy(rate)\n    rate_c[:,1:] = rate_c[:,:-1]\n    rate = rate - rate_c\n    X_3D_test[:,:,i] = rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another feature we think is important is the fft of the time series data. We believe that each surface will cause the robot to vibrate or oscillate with specific frequencies. Thus, we calculate the fft for all the timeseries features in X_train_new and X_test_new (separately) and add the fft of the features to the corresponding matrix.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import fftpack\nX_3Dfft = np.abs(np.fft.fft(X_3D_train,axis=1))\n#freqs = fftpack.fftfreq(len(x)) * f_s\nX_3D_train=np.dstack((X_3D_train,X_3Dfft))\nprint('The size of X_3D: ', X_3D_train.shape)\n\nfrom scipy import fftpack\nX_3Dfft = np.abs(np.fft.fft(X_3D_test,axis=1))\n#freqs = fftpack.fftfreq(len(x)) * f_s\nX_3D_test=np.dstack((X_3D_test,X_3Dfft))\nprint('The size of X_3D: ', X_3D_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We print the parameters of X_train_new. Number of: (features, timestamps and samples)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nfeatures=X_3D_train.shape[2]\nntimestamp=X_3D_train.shape[1]\nnsamples=X_3D_train.shape[0]\n\nprint('Number of features in Xtrain: ', nfeatures)\nprint('Number of timestamps in Xtrain: ', ntimestamp)\nprint('Number of samples in Xtrain: ', nsamples)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We standarize X_train_new and X_test_new separately by calculating the mean and standard deviation for each of the feautures across all samples, and then subtracting the mean and dividing by the standard deviation. Standarization can help the conv net to acheive better results by removing any effects resulted from different recording sessions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(nfeatures):\n    X_train_m = np.mean(X_3D_train[:,:,k])\n    X_train_sd = np.std(X_3D_train[:,:,k])\n    X_3D_train[:,:,k] = (X_3D_train[:,:,k]-X_train_m)/X_train_sd\n\nfor k in range(nfeatures):\n    X_test_m = np.mean(X_3D_test[:,:,k])\n    X_test_sd = np.std(X_3D_test[:,:,k])\n    X_3D_test[:,:,k] = (X_3D_test[:,:,k]-X_test_m)/X_test_sd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we create the 1D convnet model. I have tried to tune the number of layers, number of filters in each layer, the batch size and the dropout ratio to give the best validation accuracy. Removing the 256 filters layer resulted in a very poor accuracy. Adding more layers resulted in overfitting (high accuracy on training data but low on validation). Lower dropout ratio resulted in over fitting too. I added layers one by one and observed how the training and validation accuracy change over training. 15% of the training data is kept for the validation. The high dropout ration is to avoid overfitting during training. Also, I tried to minimize the complexity of the model by introducing enough layers that can achieve the max possible accuracy with the current features created above.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\npredict=np.zeros([y_test_new.shape[0],y_test_new.shape[1],3])\nfor k in range(1):\n  verbose, epochs, batch_size = 1, 600, 512\n  model = Sequential()\n  model.add(Conv1D(filters=64, kernel_size=8, activation='relu', input_shape=(ntimestamp,nfeatures)))\n  model.add(Dropout(0.5))\n  model.add(Conv1D(filters=128, kernel_size=8, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(Conv1D(filters=256, kernel_size=8, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(MaxPooling1D(pool_size=1))\n  model.add(Flatten())\n  model.add(Dense(128, activation='relu')) \n  model.add(Dropout(0.5))\n  model.add(Dense(y_train_new.shape[1], activation='softmax'))\n  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit network\n  model.fit(X_3D_train, y_train_new, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We calculate the accuracy by comparing the prediction vs ytest:\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model\npredict=np.zeros([y_test_new.shape[0],y_test_new.shape[1],3])\n\nyhat=model.predict(X_3D_test)\npredict[:,:,k]=yhat\n\n#_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n\nyhat=np.mean(predict,axis=2)\nyhat_final = np.array(list(np.argmax(yhat,axis=1)))\ny_testt=np.argmax(y_test_new,axis=1)\n\naccuracy=np.mean(yhat_final==y_testt)\nprint('The accuracy is:', accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}