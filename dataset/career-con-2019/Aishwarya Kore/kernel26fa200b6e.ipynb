{"cells":[{"metadata":{},"cell_type":"markdown","source":"## CareerCon 2019 - Help Navigate Robots\nName-Aishwarya Kore\nNet Id-adk497"},{"metadata":{},"cell_type":"markdown","source":"#### The data has to be loaded in dataframes and filtered out to eliminate null and infinite values."},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"# importing necessary libraries \nimport csv\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split \n  \n# loading the dataset \n#please enter the correct loaction and file name of the input dataset\ndf=pd.read_csv(\"/kaggle/input/career-con-2019/X_train.csv\")\n#please enter the correct loaction and file name of the output dataset\ndf2=pd.read_csv(\"/kaggle/input/career-con-2019/y_train.csv\")\nprint(\"Raw data dimensions:\",df.shape,df2.shape)\n\n#replace poditive and negative infinite values with nan and then drop all nan values present in the data\ndf = df.replace([np.inf, -np.inf], np.nan)\ndf2=df2.replace([np.inf, -np.inf], np.nan)\ndf=df.dropna(how='any',axis=0)\ndf2=df2.dropna(how='any',axis=0)\n\nprint(\"Data after filtering:\",df.shape,df2.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FEATURE CORRELATION VISUALISATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(df.iloc[:,:].corr(), annot=True, linewidths=.5, fmt= '.1f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Note that the orientation X,Y,Z,W are highly correlated with each other and affect the predictions the most"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"##### Group all the entries with same series id as we have one output class per series id\n##### Use various aggregate function for generating new features"},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def modify(df):\n    dfnew=df[[\"series_id\",\"measurement_number\",\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n    temp1= dfnew.groupby(\"series_id\").mean()\n    temp2= dfnew.groupby(\"series_id\").median()\n    temp3= dfnew.groupby(\"series_id\").quantile()\n    temp4=dfnew.groupby(\"series_id\").std()\n    \n    df_train_mean=temp1[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n    df_train_median=temp2[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n    df_train_quantile=temp3[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n    df_train_std=temp4[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n    \n    df_train_mean.rename(columns={\"orientation_X\":\"orientation_X_mean\",\"orientation_Y\":\"orientation_Y_mean\",\"orientation_Z\":\"orientation_Z_mean\",\"orientation_W\":\"orientation_W_mean\",\"angular_velocity_X\":\"angular_velocity_X_mean\",\"angular_velocity_Y\":\"angular_velocity_Y_mean\",\"angular_velocity_Z\":\"angular_velocity_Z_mean\",\"linear_acceleration_X\":\"linear_acceleration_X_mean\",\"linear_acceleration_Y\":\"linear_acceleration_Y_mean\",\"linear_acceleration_Z\":\"linear_acceleration_Z_mean\"})\n    df_train_median.rename(columns={\"orientation_X\":\"orientation_X_median\",\"orientation_Y\":\"orientation_Y_median\",\"orientation_Z\":\"orientation_Z_median\",\"orientation_W\":\"orientation_W_median\",\"angular_velocity_X\":\"angular_velocity_X_median\",\"angular_velocity_Y\":\"angular_velocity_Y_median\",\"angular_velocity_Z\":\"angular_velocity_Z_median\",\"linear_acceleration_X\":\"linear_acceleration_X_median\",\"linear_acceleration_Y\":\"linear_acceleration_Y_median\",\"linear_acceleration_Z\":\"linear_acceleration_Z_median\"})\n    df_train_quantile.rename(columns={\"orientation_X\":\"orientation_X_q\",\"orientation_Y\":\"orientation_Y_q\",\"orientation_Z\":\"orientation_Z_q\",\"orientation_W\":\"orientation_W_q\",\"angular_velocity_X\":\"angular_velocity_X_q\",\"angular_velocity_Y\":\"angular_velocity_Y_q\",\"angular_velocity_Z\":\"angular_velocity_Z_q\",\"linear_acceleration_X\":\"linear_acceleration_X_q\",\"linear_acceleration_Y\":\"linear_acceleration_Y_q\",\"linear_acceleration_Z\":\"linear_acceleration_Z_q\"})\n    df_train_std.rename(columns={\"orientation_X\":\"orientation_X_std\",\"orientation_Y\":\"orientation_Y_std\",\"orientation_Z\":\"orientation_Z_std\",\"orientation_W\":\"orientation_W_std\",\"angular_velocity_X\":\"angular_velocity_X_std\",\"angular_velocity_Y\":\"angular_velocity_Y_std\",\"angular_velocity_Z\":\"angular_velocity_Z_std\",\"linear_acceleration_X\":\"linear_acceleration_X_std\",\"linear_acceleration_Y\":\"linear_acceleration_Y_std\",\"linear_acceleration_Z\":\"linear_acceleration_Z_std\"})\n    \n    X=pd.concat([df_train_mean,df_train_median,df_train_quantile,df_train_std], axis=1)\n    \n    return X\n\nX=modify(df)\n\nprint(\"Shape of data X with new features:\",X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Here I noticed that adding standard deviation as a feature made a huge change in the accuracy from 60% to 90% that is because the s.d measurement represents each of 128 data rows most accurately as a group rather that calculating mean or median because we are considering the difference with each of these 128 values."},{"metadata":{},"cell_type":"markdown","source":"##### Now we eliminiate the columns from the data that we do not need. Also the output values are in string we convert it to interger using a list of all the classes for better calculation putpose"},{"metadata":{"trusted":true},"cell_type":"code","source":"#eliminate group_id and series_id colunms\ny_train=df2[[\"surface\"]].to_numpy()\n#convert string vals in surface to interger index using this list of all classes\nlabels=['carpet','concrete','fine_concrete','hard_tiles','hard_tiles_large_space','soft_pvc','soft_tiles','tiled','wood']\nY= np.zeros(len(y_train))\nfor i in range(0,len(y_train)):\n    Y[i]=labels.index(y_train[i])\nYdf=pd.DataFrame(Y)\nprint(\"New shape of Y:\",Ydf.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## k-fold Cross Validation\n#### We will evaluate metric(s) by cross-validation and also record fit/score times.\n#### here cv parameter is the no.of folds we have used cv=3 for best scoring"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import LinearSVC\nlasso = linear_model.Lasso()\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth=16)\ncv_results = cross_validate(rf, X, Ydf, cv=3)\nsorted(cv_results.keys())\nscores = cross_validate(rf, X, Ydf, cv=3, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\nprint(scores['test_neg_mean_squared_error'])\nprint(scores['train_r2'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split data into training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n# split X_train\nsamples = 20\nstart_x = X.shape[0] - samples\nX_train, X_test = X.iloc[:start_x], X.iloc[start_x:]\n\n# split y_train\nstart_y = Ydf.shape[0] - samples\ny_train, y_test = Ydf.iloc[:start_y], Ydf.iloc[start_y:]\n\nprint(\"Dimensions of the training and testing data:\",X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training different models"},{"metadata":{},"cell_type":"markdown","source":"## 1.Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import r2_score\nimport numpy as np\nfrom sklearn import metrics\n\nlin_regression = LogisticRegression()\nlin_regression.fit(X_train,y_train)\n\ntrain_pred_lr = lin_regression.predict(X_train)\n\nprint(\"Logistic Regression training accuracy=\",metrics.accuracy_score(y_train,train_pred_lr)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_lr=lin_regression.predict(X_test)\nprint(\"Logistic Regression tesing accuracy=\",metrics.accuracy_score(y_test,test_pred_lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndmodel=DecisionTreeClassifier(splitter=\"random\",max_depth=15).fit(X_train,y_train)\ntrain_pred=dmodel.predict(X_train)\nprint(\"Decision tree training accuracy=\",metrics.accuracy_score(y_train,train_pred)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred=dmodel.predict(X_test)\nprint(\"Decision tree testing accuracy=\",metrics.accuracy_score(ypred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth=16)\nrf.fit(X_train,y_train);\nrf_pred=rf.predict(X_train)\nprint(\"Random forest training accuracy=\",metrics.accuracy_score(rf_pred,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pred2=rf.predict(X_test)\nprint(\"Random forest testing accuracy=\",metrics.accuracy_score(rf_pred2,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.Multi Layer Perceptron Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(max_iter=1000)\nclf.fit(X_train, y_train)\nmlpy_pred=clf.predict(X_train)\nprint(\"MLP training accuracy=\",metrics.accuracy_score(mlpy_pred,y_train))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpy_pred2=clf.predict(X_test)\nprint(mlpy_pred2.shape)\nprint(\"MLP testing accuracy=\",metrics.accuracy_score(mlpy_pred2,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **From all the above models we get different accuracies so we choose the one with highest accuracy to predict the surface the robot is on and that would be the random forest classifier with an accuracy of 0.9 on testing data. \n#### **MLP also gives quite good accuracy on the data when its parameters are set right but it takes a lot of time to compute the predictions with that high value of parameters.\n#### **Also our final output should be converted to strings again."},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.DataFrame(columns=['series_id','surface'])\nk=start_y\nfor i in range(0,rf_pred2.shape[0]):\n    j=int(rf_pred2[i])\n    Y.loc[i] = k,labels[j]\n    k=k+1\nprint(\"Final predicted values of surfaces for test data:\")\nprint (Y.to_string(index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":4}