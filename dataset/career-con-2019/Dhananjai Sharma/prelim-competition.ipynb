{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Submission for Data Science internship at Precily\n\nCompetition - [**CareerCon 2019 - Help Navigate Robots**](https://www.kaggle.com/c/career-con-2019)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading all CSV files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample Submission\ndf_sam = pd.read_csv(\"../input/sample_submission.csv\")\nprint(df_sam.shape)\ndf_sam.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_X = pd.read_csv(\"../input/X_train.csv\")\nprint(df_X.shape)\ndf_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_y = pd.read_csv(\"../input/y_train.csv\")\nprint(df_y.shape)\ndf_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/X_test.csv\")\nprint(df_test.shape)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## My understanding of the dataset\n\nThe input data, is covering 10 sensor channels and 128 measurements per time series.\n\nA set of 128 tests were performed on a surface and these 128 tests comprise a series. seriesid is the serial number of the test peformed on the surface in a series. Concluded this from the fact that the ytrain has one row for each Series and each Series number is mapped to only one Surface. For each test they documented the 10 readings. Like this they did 3810 (numbered from 0 to 3809) set of tests and got 3810 x 128 = 487,680 readings. This is the Training set.\n\nThe ytrain data has the mapping between serialid, groupid and surface. One serialid is mapped to only one surface but one surfaces is mapped to multiple serial_id, showing that mutiple series of tests were performed on one surface.\n"},{"metadata":{},"cell_type":"markdown","source":"## Check for null values in train.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# No null values\n_ = sns.heatmap(df_X.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Correlation between features"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n0 - orientation_X\n1 - orientation_Y\n2 - orientation_Z\n3 - orientation_W\n4 - angular_velocity_X\n5 - angular_velocity_Y\n6 - angular_velocity_Z\n7 - linear_acceleration_X\n8 - linear_acceleration_Y\n9 - linear_acceleration_Z\n'''\n\nplt.figure(figsize=(15,10))\nsns.set(font_scale=1.5)\nsns.heatmap(df_X.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encode each surface(wood, concrete etc.) with a number(0-9), to create a new array of target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X = df_X.iloc[:,3:]\nmapper = {'series_id': [],\n         'surface':[]}\ncategories = dict()\nrows = df_y.iterrows()\nx = 0\nfor each in rows:\n    serid = each[0]\n    surface = each[1]['surface']\n    if surface not in categories.keys():\n        categories[surface] = x\n        x = x+1\n    for i in range(0,128):\n        mapper['series_id'].append(serid)\n        mapper['surface'].append(categories[surface])\n    \ndf_y2 = pd.DataFrame(mapper)\ndf_y2 = df_y2['surface']\nprint(df_y2.shape)\ndf_y2.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalize Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import normalize\ndf_X = normalize(df_X)\ndf_X = pd.DataFrame(df_X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Model and finding the best parameter(s)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nclf = KNeighborsClassifier()\ngrid_values = {'n_neighbors': [7]}\nX_train, X_test, y_train, y_test = train_test_split(df_X, df_y2, test_size=0, random_state = 69)\n\n# default metric to optimize over grid parameters: accuracy\ngrid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\ngrid_clf_acc.fit(X_train, y_train)\n\nprint('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\nprint('Grid best score (accuracy): ', grid_clf_acc.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making prediction for all 128 instances of each surface"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_t = df_test.iloc[:,3:]\nX_t = pd.DataFrame(normalize(X_t))\nclf = KNeighborsClassifier(n_neighbors=7)\nclf.fit(X_train, y_train)\nans = clf.predict(X_t)\nans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Change the surface back to their names"},{"metadata":{"trusted":true},"cell_type":"code","source":"serser = df_test['series_id']\nfinal = {'surf':[]}\nk = list(categories.keys())\nv = list(categories.values())\nfor each in ans:\n    final['surf'].append(k[each])\nfinal_ans = pd.DataFrame(final)\ntemp = final_ans['surf']\nfinal_ans['series_id'] = serser\nfinal_ans['surface'] = temp\nfinal_ans = final_ans.drop(['surf'], axis=1)\nprint(final_ans.shape)\nfinal_ans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For each series_id choose the prediction with most number of occurences in the 128 instances"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_g = final_ans.groupby(by='series_id')\nprediction_dict = dict()\ncount_dict = dict()\nfor ser_id, df in df_g:\n    prediction_dict[ser_id] = ''\n    for each in df['surface']:\n        if each not in count_dict.keys():\n            count_dict[each] = 1\n        else:\n            count_dict[each] += 1\n    count_items = list(count_dict.items())\n    count_items.sort(key=lambda x: x[1], reverse=True)\n    prediction_dict[ser_id] = count_items[0][0]\n    count_dict = dict()\nprint(prediction_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert dictionary to dataframe\nmodified_final_ans = pd.DataFrame(list(prediction_dict.items()), columns=['series_id', 'surface'])\nprint(modified_final_ans.shape)\nmodified_final_ans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save as CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"modified_final_ans.to_csv('submission5.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../working\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download CSV file locally"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\nsubmission5 = pd.read_csv('../working/submission5.csv')\n# create a link to download the dataframe\ncreate_download_link(submission5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy on Leaderboard: 0.60"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}