{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 15 Solution (Private: [0.77])\n** *If I would've submitted according to my local CV but I got mesmerized by the Leaderboard Scores and so I fall.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\nimport random\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\nimport time\nfrom tqdm import tqdm\nimport warnings\nwarnings.simplefilter('ignore')\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":182,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_X = pd.read_csv('../input/X_train.csv').iloc[:,3:].values.reshape(-1,128,10)\ntest_X  = pd.read_csv('../input/X_test.csv' ).iloc[:,3:].values.reshape(-1,128,10)\nprint('train_X shape:', train_X.shape, ', test_X shape:', test_X.shape)","execution_count":143,"outputs":[{"output_type":"stream","text":"train_X shape: (3810, 128, 10) , test_X shape: (3816, 128, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_y = pd.read_csv('../input/y_train.csv')\n\n# build a dict to convert surface names into numbers\nsurface_names = df_train_y['surface'].unique()\nnum_surfaces = len(surface_names)\nsurface_to_numeric = dict(zip(surface_names, range(num_surfaces)))\nprint('Convert to numbers: ', surface_to_numeric)\n\n# y and group data as numeric values:\ntrain_y = df_train_y['surface'].replace(surface_to_numeric).values\ntrain_group = df_train_y['group_id'].values","execution_count":144,"outputs":[{"output_type":"stream","text":"Convert to numbers:  {'fine_concrete': 0, 'concrete': 1, 'soft_tiles': 2, 'tiled': 3, 'soft_pvc': 4, 'hard_tiles_large_space': 5, 'carpet': 6, 'hard_tiles': 7, 'wood': 8}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sq_dist(a,b):\n    ''' the squared euclidean distance between two samples '''\n    \n    return np.sum((a-b)**2, axis=1)\n\n\ndef find_run_edges(data, edge):\n    ''' examine links between samples. left/right run edges are those samples which do not have a link on that side. '''\n\n    if edge == 'left':\n        border1 = 0\n        border2 = -1\n    elif edge == 'right':\n        border1 = -1\n        border2 = 0\n    else:\n        return False\n    \n    edge_list = []\n    linked_list = []\n    \n    for i in range(len(data)):\n        dist_list = sq_dist(data[i, border1, :4], data[:, border2, :4]) # distances to rest of samples\n        min_dist = np.min(dist_list)\n        closest_i   = np.argmin(dist_list) # this is i's closest neighbor\n        if closest_i == i: # this might happen and it's definitely wrong\n            print('Sample', i, 'linked with itself. Next closest sample used instead.')\n            closest_i = np.argsort(dist_list)[1]\n        dist_list = sq_dist(data[closest_i, border2, :4], data[:, border1, :4]) # now find closest_i's closest neighbor\n        rev_dist = np.min(dist_list)\n        closest_rev = np.argmin(dist_list) # here it is\n        if closest_rev == closest_i: # again a check\n            print('Sample', i, '(back-)linked with itself. Next closest sample used instead.')\n            closest_rev = np.argsort(dist_list)[1]\n        if (i != closest_rev): # we found an edge\n            edge_list.append(i)\n        else:\n            linked_list.append([i, closest_i, min_dist])\n            \n    return edge_list, linked_list\n\n\ndef find_runs(data, left_edges, right_edges):\n    ''' go through the list of samples & link the closest neighbors into a single run '''\n    \n    data_runs = []\n\n    for start_point in left_edges:\n        i = start_point\n        run_list = [i]\n        while i not in right_edges:\n            tmp = np.argmin(sq_dist(data[i, -1, :4], data[:, 0, :4]))\n            if tmp == i: # self-linked sample\n                tmp = np.argsort(sq_dist(data[i, -1, :4], data[:, 0, :4]))[1]\n            i = tmp\n            run_list.append(i)\n        data_runs.append(np.array(run_list))\n    \n    return data_runs","execution_count":145,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_left_edges, train_left_linked  = find_run_edges(train_X, edge='left')\ntrain_right_edges, train_right_linked = find_run_edges(train_X, edge='right')\nprint('Found', len(train_left_edges), 'left edges and', len(train_right_edges), 'right edges.')","execution_count":146,"outputs":[{"output_type":"stream","text":"Sample 1 (back-)linked with itself. Next closest sample used instead.\nSample 216 linked with itself. Next closest sample used instead.\nSample 335 linked with itself. Next closest sample used instead.\nSample 748 (back-)linked with itself. Next closest sample used instead.\nSample 799 linked with itself. Next closest sample used instead.\nSample 1205 linked with itself. Next closest sample used instead.\nSample 1913 linked with itself. Next closest sample used instead.\nSample 1986 linked with itself. Next closest sample used instead.\nSample 2555 linked with itself. Next closest sample used instead.\nSample 2612 linked with itself. Next closest sample used instead.\nSample 2761 linked with itself. Next closest sample used instead.\nSample 2917 linked with itself. Next closest sample used instead.\nSample 3312 linked with itself. Next closest sample used instead.\nSample 181 linked with itself. Next closest sample used instead.\nSample 272 linked with itself. Next closest sample used instead.\nSample 464 linked with itself. Next closest sample used instead.\nSample 851 linked with itself. Next closest sample used instead.\nSample 990 linked with itself. Next closest sample used instead.\nSample 1179 linked with itself. Next closest sample used instead.\nSample 1334 linked with itself. Next closest sample used instead.\nSample 1584 linked with itself. Next closest sample used instead.\nSample 1679 linked with itself. Next closest sample used instead.\nSample 1730 linked with itself. Next closest sample used instead.\nSample 1860 linked with itself. Next closest sample used instead.\nSample 2567 linked with itself. Next closest sample used instead.\nSample 2720 linked with itself. Next closest sample used instead.\nSample 3005 linked with itself. Next closest sample used instead.\nFound 76 left edges and 76 right edges.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_runs = find_runs(train_X, train_left_edges, train_right_edges)","execution_count":147,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flat_list = [series_id for run in train_runs for series_id in run]\nprint(len(flat_list), len(np.unique(flat_list)))","execution_count":148,"outputs":[{"output_type":"stream","text":"3810 3810\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_y['run_id'] = 0\ndf_train_y['run_pos'] = 0\n\nfor run_id in range(len(train_runs)):\n    for run_pos in range(len(train_runs[run_id])):\n        series_id = train_runs[run_id][run_pos]\n        df_train_y.at[ series_id, 'run_id'  ] = run_id\n        df_train_y.at[ series_id, 'run_pos' ] = run_pos\n\ndf_train_y.to_csv('y_train_with_runs.csv', index=False)\ndf_train_y.tail()","execution_count":149,"outputs":[{"output_type":"execute_result","execution_count":149,"data":{"text/plain":"      series_id  group_id        surface  run_id  run_pos\n3805       3805        55          tiled      46        4\n3806       3806        67           wood      74        2\n3807       3807        48  fine_concrete      65       57\n3808       3808        54          tiled      54       97\n3809       3809        56       soft_pvc      69      123","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>group_id</th>\n      <th>surface</th>\n      <th>run_id</th>\n      <th>run_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3805</th>\n      <td>3805</td>\n      <td>55</td>\n      <td>tiled</td>\n      <td>46</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3806</th>\n      <td>3806</td>\n      <td>67</td>\n      <td>wood</td>\n      <td>74</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3807</th>\n      <td>3807</td>\n      <td>48</td>\n      <td>fine_concrete</td>\n      <td>65</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>3808</th>\n      <td>3808</td>\n      <td>54</td>\n      <td>tiled</td>\n      <td>54</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>3809</th>\n      <td>3809</td>\n      <td>56</td>\n      <td>soft_pvc</td>\n      <td>69</td>\n      <td>123</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_left_edges, test_left_linked  = find_run_edges(test_X, edge='left')\ntest_right_edges, test_right_linked = find_run_edges(test_X, edge='right')\nprint('Found', len(test_left_edges), 'left edges and', len(test_right_edges), 'right edges.')","execution_count":150,"outputs":[{"output_type":"stream","text":"Sample 355 linked with itself. Next closest sample used instead.\nSample 580 linked with itself. Next closest sample used instead.\nSample 1402 linked with itself. Next closest sample used instead.\nSample 1547 linked with itself. Next closest sample used instead.\nSample 1716 linked with itself. Next closest sample used instead.\nSample 2136 (back-)linked with itself. Next closest sample used instead.\nSample 2474 linked with itself. Next closest sample used instead.\nSample 2495 (back-)linked with itself. Next closest sample used instead.\nSample 2600 linked with itself. Next closest sample used instead.\nSample 2922 linked with itself. Next closest sample used instead.\nSample 580 linked with itself. Next closest sample used instead.\nSample 1216 linked with itself. Next closest sample used instead.\nSample 1409 linked with itself. Next closest sample used instead.\nSample 1410 linked with itself. Next closest sample used instead.\nSample 1670 linked with itself. Next closest sample used instead.\nSample 1700 linked with itself. Next closest sample used instead.\nSample 2650 linked with itself. Next closest sample used instead.\nSample 2864 linked with itself. Next closest sample used instead.\nSample 3332 linked with itself. Next closest sample used instead.\nSample 3397 linked with itself. Next closest sample used instead.\nFound 75 left edges and 75 right edges.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_runs = find_runs(test_X, test_left_edges, test_right_edges)","execution_count":151,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lost_samples = np.array([ i for i in range(len(test_X)) if i not in np.concatenate(test_runs) ])\nprint(lost_samples)\nprint(len(lost_samples))","execution_count":152,"outputs":[{"output_type":"stream","text":"[ 264  361  529  620  733  954 1148 1248 1432 1534 1570 1738 1739 2090\n 2205 2714 2847 2978 2991 3115 3173 3183 3195 3359 3517 3655]\n26\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_run_edges(test_X[lost_samples], edge='left')[1][0]","execution_count":153,"outputs":[{"output_type":"execute_result","execution_count":153,"data":{"text/plain":"[0, 5, 2.0548399999999954e-07]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lost_run = np.array(lost_samples[find_runs(test_X[lost_samples], [0], [5])[0]])\ntest_runs.append(lost_run)","execution_count":154,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_y = pd.read_csv(\"../input/sample_submission.csv\")\ndf_test_y['run_id'] = 0\ndf_test_y['run_pos'] = 0\n\nfor run_id in range(len(test_runs)):\n    for run_pos in range(len(test_runs[run_id])):\n        series_id = test_runs[run_id][run_pos]\n        df_test_y.at[ series_id, 'run_id'  ] = run_id\n        df_test_y.at[ series_id, 'run_pos' ] = run_pos\n\ndf_test_y.to_csv('y_test_with_runs.csv', index=False)\n\ndf_test_y.drop(\"surface\", axis=1, inplace=True)\n\ncheat_json = df_train_y.groupby(['run_id'])['surface'].unique().reset_index().to_dict()\ndf_test_y['surface'] = df_test_y['run_id'].apply(lambda x: cheat_json['surface'][x][0])\ndf_test_y.head()","execution_count":155,"outputs":[{"output_type":"execute_result","execution_count":155,"data":{"text/plain":"   series_id  run_id  run_pos        surface\n0          0      14       19     soft_tiles\n1          1      57        8           wood\n2          2      42       13  fine_concrete\n3          3      65       11  fine_concrete\n4          4      68        3           wood","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>run_id</th>\n      <th>run_pos</th>\n      <th>surface</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>14</td>\n      <td>19</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>57</td>\n      <td>8</td>\n      <td>wood</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>42</td>\n      <td>13</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>65</td>\n      <td>11</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>68</td>\n      <td>3</td>\n      <td>wood</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Now adding samples of 256 size\n\nWe can get 256 sized samples by just adding two parts of same run_id i.e groups which have same surface.\nI've done this by taking randomly selecting 50 combinations for every run_id. We could have done for more nbut the kernel space would exceed so I remained for 50."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncounter = 0\nagg_dict = df_train_y.groupby(['run_id'])['series_id'].unique().reset_index()['series_id'].to_dict()\ntwo_sampled_dict = {}\nfor key, value in agg_dict.items():\n    two_sampled_dict[key] = []\n#     for item in list(combinations(agg_dict[key].tolist(), 2)):\n    llist = list(combinations(agg_dict[key].tolist(), 2))\n    if len(llist) > 50:\n        two_sampled_dict[key] = random.sample(llist, 50)\n        counter += 50\n    else:\n        two_sampled_dict[key] = random.sample(llist, len(llist))\n#         two_sampled_dict[key].append(item)\n        counter += len(llist)\nprint(counter)\ndel llist\ndel counter","execution_count":161,"outputs":[{"output_type":"stream","text":"3505\nCPU times: user 72 ms, sys: 12 ms, total: 84 ms\nWall time: 73.1 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/X_train.csv\")\ntest = pd.read_csv(\"../input/X_test.csv\")\nlabel = pd.read_csv(\"../input/y_train.csv\")\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\nlabel = reduce_mem_usage(label)","execution_count":162,"outputs":[{"output_type":"stream","text":"Memory usage of dataframe is 48.37 MB\nMemory usage after optimization is: 36.74 MB\nDecreased by 24.0%\nMemory usage of dataframe is 48.45 MB\nMemory usage after optimization is: 36.77 MB\nDecreased by 24.1%\nMemory usage of dataframe is 0.09 MB\nMemory usage after optimization is: 0.01 MB\nDecreased by 82.8%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nlabel['surface'] = le.fit_transform(label['surface'])\nprint(le.classes_)","execution_count":163,"outputs":[{"output_type":"stream","text":"['carpet' 'concrete' 'fine_concrete' 'hard_tiles' 'hard_tiles_large_space'\n 'soft_pvc' 'soft_tiles' 'tiled' 'wood']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['row_id', 'measurement_number'], axis=1, inplace=True)\ntest.drop(['row_id', 'measurement_number'], axis=1, inplace=True)","execution_count":164,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transforming Train with new series i.e 256 sized series.\nThe newer series having 256 size are given newer series_id starting from 3809."},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\n\nnew_train = train.copy()\nprint(\"Initial Train Size :: \", new_train.shape)\n\nnew_label = {}\nlast_series_id = 3810\n# for item in range(149205):\n\nfor key, value in tqdm(two_sampled_dict.items(), total=len(two_sampled_dict)):\n# for key, value in two_sampled_dict.items():\n    \n    for item in value:\n        \n        idx1 = item[0]\n        idx2 = item[1]\n        \n        df = pd.DataFrame(columns=train.columns)\n\n        # Creating Train\n        for col in df.columns[1: ]:\n            df[col] = new_train[col][(new_train['series_id'] == idx1) | (new_train['series_id'] == idx2)]\n        df['series_id'] = last_series_id\n        \n        df.reset_index(inplace=True)\n        df.drop(['index'], axis=1, inplace=True)\n\n        # Creating in Label\n        new_label[last_series_id] = df_train_y['surface'][(df_train_y['series_id'] == idx1) | (df_train_y['series_id'] == idx2)].value_counts(ascending=False).index[0]\n        last_series_id += 1\n        \n        new_train = pd.concat([new_train, df], ignore_index=True)\n        \nprint(\"Final Train Size :: \", new_train.shape)\nprint(\"Time Taken :: \", time.time() - start_time)","execution_count":165,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/76 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Initial Train Size ::  (487680, 11)\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 76/76 [03:55<00:00,  3.24s/it]","name":"stderr"},{"output_type":"stream","text":"Final Train Size ::  (1384960, 11)\nTime Taken ::  235.0648832321167\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def FE(data):\n    \n    df = pd.DataFrame()\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 +\n                             data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 +\n                             data['linear_acceleration_Z']**2)**0.5\n#     data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 +\n#                              data['orientation_Z'])**0.5\n   \n    data['acc_vs_vel'] = data['totl_linr_acc'] / data['totl_anglr_vel']\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number', 'orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n    return df","execution_count":166,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnew_train = FE(new_train)\ntest = FE(test)\nprint(new_train.shape, test.shape)","execution_count":167,"outputs":[{"output_type":"stream","text":"(7315, 99) (3816, 99)\nCPU times: user 1min 22s, sys: 120 ms, total: 1min 22s\nWall time: 1min 22s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)\nnew_train.replace(-np.inf, 0, inplace = True)\nnew_train.replace(np.inf, 0, inplace = True)\ntest.replace(-np.inf, 0, inplace = True)\ntest.replace(np.inf, 0, inplace = True)","execution_count":168,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def k_folds(clf, X, y, X_test, k):\n    folds = StratifiedKFold(n_splits = k, shuffle=True, random_state=13)\n    y_test = np.zeros((X_test.shape[0], 9))\n    y_oof = np.zeros((X.shape[0]))\n    score = 0\n    for i, (train_idx, val_idx) in  enumerate(folds.split(X, y)):\n#         clf =  RandomForestClassifier(n_estimators = 500, n_jobs = -1)\n        clf.fit(X.iloc[train_idx], y[train_idx])\n        y_oof[val_idx] = clf.predict(X.iloc[val_idx])\n        y_test += clf.predict_proba(X_test) / folds.n_splits\n        score += clf.score(X.iloc[val_idx], y[val_idx])\n        print('Fold: {} score: {}'.format(i,clf.score(X.iloc[val_idx], y[val_idx])))\n    print('Avg Accuracy', score / folds.n_splits) \n        \n    return y_oof, y_test","execution_count":169,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_label = pd.DataFrame.from_dict(new_label, orient='index').reset_index()\nnew_label.columns = ['series_id', 'surface']\nnew_label.head()","execution_count":170,"outputs":[{"output_type":"execute_result","execution_count":170,"data":{"text/plain":"   series_id     surface\n0       3810  soft_tiles\n1       3811  soft_tiles\n2       3812  soft_tiles\n3       3813  soft_tiles\n4       3814  soft_tiles","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>surface</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3810</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3811</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3812</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3813</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3814</td>\n      <td>soft_tiles</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = pd.read_csv(\"../input/y_train.csv\")\nlabel = pd.concat([label, new_label], ignore_index=True)\nlabel.head()","execution_count":171,"outputs":[{"output_type":"execute_result","execution_count":171,"data":{"text/plain":"   group_id  series_id        surface\n0      13.0          0  fine_concrete\n1      31.0          1       concrete\n2      20.0          2       concrete\n3      31.0          3       concrete\n4      22.0          4     soft_tiles","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group_id</th>\n      <th>series_id</th>\n      <th>surface</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.0</td>\n      <td>0</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31.0</td>\n      <td>1</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.0</td>\n      <td>2</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31.0</td>\n      <td>3</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22.0</td>\n      <td>4</td>\n      <td>soft_tiles</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label['surface'] = le.transform(label['surface'])\nlabel.surface.head()","execution_count":172,"outputs":[{"output_type":"execute_result","execution_count":172,"data":{"text/plain":"0    2\n1    1\n2    1\n3    1\n4    6\nName: surface, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand = RandomForestClassifier(n_estimators=500, random_state=13)\ny_oof, y_test_rand = k_folds(rand, new_train, label['surface'], test, k=5)","execution_count":173,"outputs":[{"output_type":"stream","text":"Fold: 0 score: 0.7205180640763463\nFold: 1 score: 0.769808743169399\nFold: 2 score: 0.7551299589603283\nFold: 3 score: 0.7371663244353183\nFold: 4 score: 0.7713894592744696\nAvg Accuracy 0.7508025099831723\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Without Orientations : (50 * 76 samples(256) added)\n\nAvg Accuracy 0.7465495699892621"},{"metadata":{"trusted":true},"cell_type":"code","source":"ext = ExtraTreesClassifier(n_estimators=500, random_state=13)\ny_oof, y_test_ext = k_folds(ext, new_train, label['surface'], test, k=5)","execution_count":174,"outputs":[{"output_type":"stream","text":"Fold: 0 score: 0.7430129516019086\nFold: 1 score: 0.7841530054644809\nFold: 2 score: 0.7886456908344733\nFold: 3 score: 0.7618069815195072\nFold: 4 score: 0.7919233401779603\nAvg Accuracy 0.773908393919666\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# ExtraTrees - 0.7617245030663025 (#50)#without orientations"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_oof,label['surface'])","execution_count":175,"outputs":[{"output_type":"execute_result","execution_count":175,"data":{"text/plain":"array([[ 312,   10,    6,    2,    2,   14,    5,    1,    5],\n       [  52, 1270,   95,    0,   63,   33,    3,  206,   73],\n       [   2,   25,  275,    0,    8,   12,    0,   28,    8],\n       [   0,    0,    0,   47,    0,    1,    0,    0,    0],\n       [   3,   16,    5,    0,  450,    9,    6,   30,   19],\n       [  55,   35,  159,   11,   24,  991,   11,   31,   73],\n       [  15,    8,   13,    1,   21,   20,  511,    6,    9],\n       [   1,   86,   27,    0,   42,    1,    0,  605,   44],\n       [  20,   20,   60,   10,   12,   65,   11,   21, 1200]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submitting averaging\n\ny_test = y_test_ext + y_test_rand\ny_test = np.argmax(y_test, axis=1)\nsubmission = pd.read_csv(os.path.join(\"../input/\", 'sample_submission.csv'))\nsubmission['surface'] = le.inverse_transform(y_test)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.surface.value_counts()","execution_count":176,"outputs":[{"output_type":"execute_result","execution_count":176,"data":{"text/plain":"soft_pvc                  988\nconcrete                  930\nwood                      592\ntiled                     437\nsoft_tiles                409\nhard_tiles_large_space    173\nfine_concrete             168\ncarpet                    113\nhard_tiles                  6\nName: surface, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Trick (Every run has only one surface)\n# So taking the max of every run as the surface for each element"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_y['sub'] = submission['surface']\ndf_test_y.head()","execution_count":177,"outputs":[{"output_type":"execute_result","execution_count":177,"data":{"text/plain":"   series_id  run_id  run_pos        surface            sub\n0          0      14       19     soft_tiles  fine_concrete\n1          1      57        8           wood       soft_pvc\n2          2      42       13  fine_concrete       concrete\n3          3      65       11  fine_concrete     soft_tiles\n4          4      68        3           wood     soft_tiles","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>run_id</th>\n      <th>run_pos</th>\n      <th>surface</th>\n      <th>sub</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>14</td>\n      <td>19</td>\n      <td>soft_tiles</td>\n      <td>fine_concrete</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>57</td>\n      <td>8</td>\n      <td>wood</td>\n      <td>soft_pvc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>42</td>\n      <td>13</td>\n      <td>fine_concrete</td>\n      <td>concrete</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>65</td>\n      <td>11</td>\n      <td>fine_concrete</td>\n      <td>soft_tiles</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>68</td>\n      <td>3</td>\n      <td>wood</td>\n      <td>soft_tiles</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg = df_test_y.groupby(['run_id', 'sub'])['sub'].count()\nagg = pd.DataFrame(agg)\nagg.columns = ['count']\nagg.reset_index(inplace=True)\nagg = df_test_y.groupby(['run_id']).agg(lambda x: x.value_counts().index[0]).reset_index()[['run_id', 'sub']]\nagg_dict = agg.to_dict()\nsubmission['surface'] = df_test_y['run_id'].apply(lambda x: agg_dict['sub'][x])\nsubmission['surface'][df_test_y['run_id'] == 39] = 'hard_tiles'\nsubmission.surface.value_counts()","execution_count":178,"outputs":[{"output_type":"execute_result","execution_count":178,"data":{"text/plain":"concrete                  1211\nsoft_pvc                  1062\nwood                       500\nsoft_tiles                 461\ntiled                      189\nhard_tiles_large_space     151\nhard_tiles                 108\ncarpet                      72\nfine_concrete               62\nName: surface, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.surface.value_counts() / submission.shape[0]","execution_count":179,"outputs":[{"output_type":"execute_result","execution_count":179,"data":{"text/plain":"concrete                  0.317348\nsoft_pvc                  0.278302\nwood                      0.131027\nsoft_tiles                0.120807\ntiled                     0.049528\nhard_tiles_large_space    0.039570\nhard_tiles                0.028302\ncarpet                    0.018868\nfine_concrete             0.016247\nName: surface, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":180,"outputs":[{"output_type":"execute_result","execution_count":180,"data":{"text/plain":"(3816, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"with_model.csv\", index=False)","execution_count":181,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}