{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV,train_test_split\nfrom sklearn.pipeline import Pipeline\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.utils import class_weight\n#performance metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_fe_X = pd.read_feather('../input/surface-prediction-feature-engineering/Train_FE')\ntest_fe_X = pd.read_feather('../input/surface-prediction-feature-engineering/Test_FE')\ntrain_df_Y = pd.read_feather('../input/surface-prediction-feature-engineering/Target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe_X.shape, train_df_Y.shape, test_fe_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(figsize=(12, 10))\n# corr=train.corr()\n\n# sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values,ax=ax)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data = train_fe_X.drop(columns=['series_id','velocity_to_acceleration_norm_entropy'])\n# test_data = test_fe_X.drop(columns=['series_id','velocity_to_acceleration_norm_entropy'])\nle = LabelEncoder()\ntarget =pd.DataFrame()\ntarget['surface'] = le.fit_transform(train_df_Y['surface'])\nclasses = (train_df_Y['surface'].value_counts()).index\n# train_data.shape, target.shape, test_data.shape\ntarget.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\n%time vif['vif_factor'] = [variance_inflation_factor(train_fe_X.values,i) for i in range(train_fe_X.shape[1])]\nvif['features'] = train_fe_X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif.fillna(value=9999,inplace=True)\nvif.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif.sort_values('vif_factor',axis=0,inplace=True, ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_to_remove = vif.loc[vif['vif_factor'] > 5,'features'].values\nfeatures_to_remove = list(features_to_remove)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_to_remove.append('series_id')\nfeatures_to_remove.append('velocity_to_acceleration_norm_entropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop these columns\ntrain_data=train_fe_X.drop(columns=features_to_remove)\ntest_data = test_fe_X.drop(columns=features_to_remove)\ntrain_data.shape,test_data.shape,target.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pipe = Pipeline((\n#     ('xgb', XGBClassifier(n_estimators=500 , random_state=22)),    \n#     ))\n\n# params = {        \n#     'xgb__learning_rate':[1,0.001,0.05]\n#     }\n\n\n# model,name = (params,'XGBoost')\n# print('-'*50)\n# print( \"Starting Randomized Search for %s\" %name)                \n# rs = RandomizedSearchCV(pipe, model, verbose=5, refit=False, n_jobs=3,cv=5,random_state=22,n_iter=20)\n# rs = rs.fit(train_data, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"Finished Randomized Search for %s\"%name)\n# print('Best Score %.5f'%rs.best_score_)\n# print('Best Param %s'%rs.best_params_)\n# # print('-'*50)\n\n\n# class_weights = class_weight.compute_class_weight('balanced', np.unique(target['surface'] ),target['surface'] )\n# class_weights = dict(zip(np.unique(target['surface']),class_weights))\n# class_weights\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfolds = StratifiedKFold(n_splits=50, shuffle=True, random_state=59)\npredicted = np.zeros((test_data.shape[0],9))\nmeasured= np.zeros((train_data.shape[0]))\nscore = 0\nfor times, (trn_idx, val_idx) in enumerate(folds.split(train_data.values,target['surface'].values)):\n    model = RandomForestClassifier(n_estimators=1500,random_state=22, n_jobs = -1,max_features=30,class_weight='balanced_subsample')\n#     model = XGBClassifier(n_estimators=75 , random_state=22,learning_rate=1,subsample=0.9,)\n    model.fit(train_data.iloc[trn_idx],target['surface'][trn_idx])\n    measured[val_idx] = model.predict(train_data.iloc[val_idx])\n    predicted += model.predict_proba(test_data)/folds.n_splits\n    score += model.score(train_data.iloc[val_idx],target['surface'][val_idx])\n    print(\"Fold: {} score: {}\".format(times,model.score(train_data.iloc[val_idx],target['surface'][val_idx])))\n    gc.collect()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Avg Accuracy RF', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list(le.inverse_transform(np.unique(target['surface'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#     importances = model.feature_importances_\n#     indices = np.argsort(importances)\n#     features = train_data.columns\n\n\n#     hm = 30\n#     plt.figure(figsize=(7, 10))\n#     plt.title('Feature Importances')\n#     plt.barh(range(len(indices[:hm])), importances[indices][:hm], color='b', align='center')\n#     plt.yticks(range(len(indices[:hm])), [features[i] for i in indices])\n#     plt.xlabel('Relative Importance')\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(model.feature_importances_)\n# plt.xticks(np.arange(train_data.shape[1]),train_data.columns.tolist(),rotation=90)\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, X_test, y_train, y_test = train_test_split(train_data, target['surface'], test_size=0.3, random_state=22,shuffle=True,stratify=target['surface'])\n# X_train.shape, y_train.shape, X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)    \n# class_weights = dict(zip(np.unique(y_train),class_weights))\n# class_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class_weights={0:0.06,\n# 1:0.16, \n# 2:0.09, \n# 3:0.06, \n# 4:0.10, \n# 5:0.17, \n# 6:0.23, \n# 7:0.3, \n# 8:0.06} \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = RandomForestClassifier(n_estimators=1500,random_state=22, n_jobs = -1,max_features=30,class_weight=class_weights)\n# %time model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('Accuracy: %.4f' %accuracy_score(y_pred=y_pred,y_true=y_test))\n# print('Confusion Matrix: \\n%s'%confusion_matrix(y_pred=y_pred,y_true=y_test))\n# print('Classification report: \\n %s'%classification_report(y_pred=y_pred,y_true=y_test))\n# # print('AUC score: %.5f'%roc_auc_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_confusion_matrix(confusion_matrix(y_pred=y_pred,y_true=y_test), le.classes_,normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted = model.predict_proba(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_rf = pd.DataFrame({\"series_id\": test_fe_X.series_id, \"surface\": le.inverse_transform(predicted.argmax(axis=1))})\n# submission_rf.to_csv(\"submission_rf.csv\", index = False)\n# submission_rf.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_rf.surface.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# folds = StratifiedKFold(n_splits=50, shuffle=True, random_state=59)\n# predicted = np.zeros((test_data.shape[0],9))\n# measured= np.zeros((train_data.shape[0]))\n# score = 0\n\n# for times, (trn_idx, val_idx) in enumerate(folds.split(train_data.values,target['surface'].values)):\n#     model = RandomForestClassifier(n_estimators=750,random_state=22,max_features='sqrt', n_jobs = -1)\n#     #model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\n#     model.fit(train_data.iloc[trn_idx],target['surface'][trn_idx])\n#     measured[val_idx] = model.predict(train_data.iloc[val_idx])\n#     predicted += model.predict_proba(test_data)/folds.n_splits\n#     score += model.score(train_data.iloc[val_idx],target['surface'][val_idx])\n#     print(\"Fold: {} score: {}\".format(times,model.score(train_data.iloc[val_idx],target['surface'][val_idx])))\n    \n#     importances = model.feature_importances_\n#     indices = np.argsort(importances)\n#     features = train_data.columns\n\n# #     if model.score(train_data.iloc[val_idx],target['surface'][val_idx]) > 0.92000:\n# #         hm = 30\n# #         plt.figure(figsize=(7, 10))\n# #         plt.title('Feature Importances')\n# #         plt.barh(range(len(indices[:hm])), importances[indices][:hm], color='b', align='center')\n# #         plt.yticks(range(len(indices[:hm])), [features[i] for i in indices])\n# #         plt.xlabel('Relative Importance')\n# #         plt.show()\n\n# #     gc.collect()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('Avg Accuracy RF', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http://matplotlib.org/examples/color/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(confusion_matrix(measured,target['surface']), le.classes_,normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# soft tiles 0.23\n# soft pvc 0.17\n# concrete 0.16\n# hard tiles large space 0.10\n# fine concrete 0.09\n# carpet 0.06\n# hard tiles 0.06\n# wood 0.06\n# tiled 0.03\n\n\n# concrete                  915\n# wood                      781\n# soft_pvc                  634\n# soft_tiles                463\n# tiled                     322\n# hard_tiles_large_space    295\n# fine_concrete             274\n# carpet                    122\n# hard_tiles                 10\n\n# concrete                  912\n# wood                      778\n# soft_pvc                  644\n# soft_tiles                458\n# tiled                     318\n# hard_tiles_large_space    295\n# fine_concrete             278\n# carpet                    124\n# hard_tiles                  9\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_xgb = pd.DataFrame({\"series_id\": test_fe_X.series_id, \"surface\": le.inverse_transform(predicted.argmax(axis=1))})\nsubmission_xgb.to_csv(\"submission_xgb.csv\", index = False)\nsubmission_xgb.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_xgb.surface.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgb = XGBClassifier(n_estimators=50 , random_state=22)\n# %time xgb.fit(X_train.drop(columns=['surface','velocity_to_acceleration_norm_entropy']),X_train['surface'],eval_metric='map')\n# y_pred_xgb = xgb.predict(X_val.drop(columns=['surface','velocity_to_acceleration_norm_entropy']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('Accuracy: %.4f' %accuracy_score(y_pred=y_pred_xgb,y_true=X_val['surface']))\n# print('Confusion Matrix: \\n%s'%confusion_matrix(y_pred=y_pred_xgb,y_true=X_val['surface']))\n# print('Classification report: \\n %s'%classification_report(y_pred=y_pred_xgb,y_true=X_val['surface']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}