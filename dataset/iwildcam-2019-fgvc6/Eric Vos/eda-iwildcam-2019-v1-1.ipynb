{"cells":[{"metadata":{"_uuid":"891ff33de99b18de3bd0d2b68891e4575e467d41"},"cell_type":"markdown","source":"![](https://tse4.mm.bing.net/th?id=OIP.zN1wmN4DIre-HT2j1tT0dwHaCu&pid=15.1&P=0&w=451&h=167)\n\n# Let's have a quick look at the 'iWildCam 2019 - FGVC6' data...\n\nCamera Traps (or Wild Cams) enable the automatic collection of large quantities of image data. Biologists all over the world use camera traps to monitor biodiversity and population density of animal species. We have recently been making strides towards automating the species classification challenge in camera traps, but as we try to expand the scope of these models from specific regions where we have collected training data to nearby areas we are faced with an interesting probem: how do you classify a species in a new region that you may not have seen in previous training data?\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\nfrom PIL import Image\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3430f531963e4f144d6d682a36315edd7e2fd178"},"cell_type":"markdown","source":"# Let's read data..."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9dd1b712846a5dd6af51da026ab912cfd05b64"},"cell_type":"markdown","source":"# Dataset size:"},{"metadata":{"trusted":true,"_uuid":"45ce66fa9701f83ded5598628581b72d055c5d70"},"cell_type":"code","source":"print('size of train data',train.shape)\nprint('size of test data',test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9870f375503798a1011138ea29aef462630193ce"},"cell_type":"markdown","source":"# Target Distribution in the Train dataset:"},{"metadata":{"trusted":true,"_uuid":"ed910699839faed8a243b1d8eb0e5bb6dbfd5369"},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of image categories(Target Variable)\")\nax = sns.distplot(train[\"category_id\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e71bf412c968f049acfabbc6cfd6f2e91962ab40"},"cell_type":"markdown","source":"# Location Distribution in the Train dataset:"},{"metadata":{"trusted":true,"_uuid":"c0e3f807292ada63259e8e49b8fe0d8cfb1c9113"},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of train image locations(Train location Variable)\")\nax = sns.distplot(train[\"location\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ef145e8b1ffbada1bad1c2eb31a2eca48660c35"},"cell_type":"markdown","source":"# Location Distribution in the Test dataset:"},{"metadata":{"trusted":true,"_uuid":"144e4c7c9a04ec094eae7edbd44768790abab092"},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of test image locations(Test location Variable)\")\nax = sns.distplot(test[\"location\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51a3edceabf4c1542b2b31b76c534d70504f97c7"},"cell_type":"markdown","source":"# Can we do something with Image size?"},{"metadata":{"trusted":true,"_uuid":"f081e2ed199c10951fbccd984676b95c1eccda35"},"cell_type":"code","source":"sns.FacetGrid(train, hue=\"height\", size=10).map(plt.scatter, \"category_id\", \"location\").add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b28d21b190bcdc2598be94c58ca93a14481afb09"},"cell_type":"markdown","source":"# Let's have a look at timestamps..."},{"metadata":{"trusted":true,"_uuid":"23bc71e0f82693b2e6c603e48c72ef2e1a01b3c4"},"cell_type":"code","source":"train['date'] = train['date_captured'].str.split('\\s+').str[0]\ntrain['time'] = train['date_captured'].str.split('\\s+').str[-1]    \ntrain['hour'] = pd.to_numeric(train['time'].str[:2], errors='coerce')\nsns.FacetGrid(train, hue=\"category_id\", size=10).map(plt.scatter, \"hour\", \"location\").add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df8dc324a73241793c9950fe40df45b7e8ac8765"},"cell_type":"markdown","source":"# Day / Night samples ratio:"},{"metadata":{"trusted":true,"_uuid":"9767187c1bc53c70f973a388c5c9de29f32acc8b"},"cell_type":"code","source":"night = train[(train['hour'] > 19) | (train['hour'] < 7)]\nday = len(train) - len(night)\nlabels = 'Day', 'Night'\nsizes = [len(night), day]\ncolors = ['lightcoral', 'lightskyblue']\nexplode = (0.1, 0) \nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=140)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09f5276be8165f0fc4764d1644c6700098ed463f"},"cell_type":"markdown","source":"# Time to display some image samples collected during the night: "},{"metadata":{"trusted":true,"_uuid":"ca93c147ad09530194a515798152521c6516fda7"},"cell_type":"code","source":"# sample night images\nfig = plt.figure(figsize=(25, 60))\nimgs = [np.random.choice(night.loc[night['category_id'] == i, 'file_name'], 4) for i in night.category_id.unique()]\nimgs = [i for j in imgs for i in j]\nlabels = [[i] * 4 for i in train.category_id.unique()]\nlabels = [i for j in labels for i in j]\nfor idx, img in enumerate(imgs):\n    ax = fig.add_subplot(14, 4, idx + 1, xticks=[], yticks=[])\n    im = Image.open(\"../input/train_images/\" + img)\n    plt.imshow(im)\n    ax.set_title(f'Label: {labels[idx]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f291300e81fc93a62063364617a04ed41ca73693"},"cell_type":"markdown","source":"# Time to display some image samples collected during the day: "},{"metadata":{"trusted":true,"_uuid":"5e67e2ac934bc553c5095b046cb2579b1074040a"},"cell_type":"code","source":"day = train[(train['hour'] < 19) & (train['hour'] > 7)]\n# sample night images\nfig = plt.figure(figsize=(25, 60))\nimgs = [np.random.choice(day.loc[day['category_id'] == i, 'file_name'], 4) for i in day.category_id.unique()]\nimgs = [i for j in imgs for i in j]\nlabels = [[i] * 4 for i in train.category_id.unique()]\nlabels = [i for j in labels for i in j]\nfor idx, img in enumerate(imgs):\n    ax = fig.add_subplot(14, 4, idx + 1, xticks=[], yticks=[])\n    im = Image.open(\"../input/train_images/\" + img)\n    plt.imshow(im)\n    ax.set_title(f'Label: {labels[idx]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f1504038a758b953ec10149140b4a8446957b38"},"cell_type":"markdown","source":"# To be continued..."},{"metadata":{"trusted":true,"_uuid":"ff57c54cc597caf3773d7fa59b06a9ffce2655a7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa8f36ac0fef07ca1394573ca125e34055161f3c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}