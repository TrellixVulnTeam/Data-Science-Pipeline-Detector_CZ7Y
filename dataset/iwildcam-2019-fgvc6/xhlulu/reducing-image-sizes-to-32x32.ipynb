{"cells":[{"metadata":{"_uuid":"6ebfc8c5e505e245fc0e38d01ff56402edfe44d0"},"cell_type":"markdown","source":"# Reducing Image Sizes to 32x32\n\nI think that some of you will be interested in trying smaller models to get started (e.g. a CNN with only a few connected layers). However, those datasets seem to be really big (150k test images and 195k training images) as well as high resolution. Just trying to create a GPU kernel and preprocessing the images seem to take a while. \n\nTherefore, I created this kernel in order to reduce the image to the smallest usable size (i.e. 32x32, similar to CIFAR10/100). Please feel free to use this as an output to your exploration models, or to modify this for other image sizes.\n\nLet me know your thoughts!\n\n### References\n* https://www.kaggle.com/xhlulu/exploration-and-preprocessing-for-keras-224x224"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport math\n\nimport numpy as np # linear algebra\nfrom PIL import Image\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcec4faf374aa01d5a92ab3d465daf1c8e396cb8"},"cell_type":"markdown","source":"## Exploration"},{"metadata":{"trusted":true,"_uuid":"42d2ea950ed12f6f896c20c8b23435b36a67f757"},"cell_type":"code","source":"label_df = pd.read_csv('../input/train.csv')\nsubmission_df = pd.read_csv('../input/sample_submission.csv')\nlabel_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34a1e7bd793f0b211127ae37fb9b856e16d25a7d"},"cell_type":"code","source":"label_df['category_id'].value_counts()[1:16].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'file_name']\n        image_id = df.loc[i,'category_id']\n        img = cv2.imread(f'../input/train_images/{image_path}')\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n\ndisplay_samples(label_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19045b8898076cb5ec166ffe70f68fd87e3bb114"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true,"_uuid":"b8ca9a0a8e8ec91f3855cb7d15bc8859a1b70c8e"},"cell_type":"code","source":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef pad_and_resize(image_path, dataset, pad=False, desired_size=32):\n    img = cv2.imread(f'../input/{dataset}_images/{image_path}.jpg')\n    \n    if pad:\n        pad_width = get_pad_width(img, max(img.shape))\n        padded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\n    else:\n        padded = img\n    \n    resized = cv2.resize(padded, (desired_size,)*2).astype('uint8')\n    \n    return resized","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b834e6813a366449183da1ac28bb76079131135e"},"cell_type":"markdown","source":"## Pad and resize all the images"},{"metadata":{"trusted":true,"_uuid":"fb1d093a03ac5af72b9eeaa696bd877e73e89481"},"cell_type":"code","source":"%%time\ntrain_resized_imgs = []\ntest_resized_imgs = []\n\nfor image_id in label_df['id']:\n    train_resized_imgs.append(\n        pad_and_resize(image_id, 'train')\n    )\n\nfor image_id in submission_df['Id']:\n    test_resized_imgs.append(\n        pad_and_resize(image_id, 'test')\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e61354b00dd73b27ea20d04d1e0d039c08cb169b"},"cell_type":"code","source":"X_train = np.stack(train_resized_imgs)\nX_test = np.stack(test_resized_imgs)\n\ntarget_dummies = pd.get_dummies(label_df['category_id'])\ntrain_label = target_dummies.columns.values\ny_train = target_dummies.values\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bc69bfab2ae1440089e93491a06721c77e7db17"},"cell_type":"markdown","source":"## Saving"},{"metadata":{"trusted":true,"_uuid":"ef26b6ee0a6ab8b3ef6c1c64cdef4b31dd657426"},"cell_type":"code","source":"# No need to save the IDs of X_test, since they are in the same order as the \n# ID column in sample_submission.csv\nnp.save('X_train.npy', X_train)\nnp.save('X_test.npy', X_test)\nnp.save('y_train.npy', y_train)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}