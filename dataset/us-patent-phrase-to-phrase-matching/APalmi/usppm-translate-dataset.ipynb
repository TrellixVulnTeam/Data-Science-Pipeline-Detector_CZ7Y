{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T14:54:30.883329Z","iopub.execute_input":"2022-05-25T14:54:30.883726Z","iopub.status.idle":"2022-05-25T14:54:30.913898Z","shell.execute_reply.started":"2022-05-25T14:54:30.883621Z","shell.execute_reply":"2022-05-25T14:54:30.913044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport gc\n\n!pip install --quiet transformers\n!pip install --quiet sentencepiece\nfrom transformers import MarianMTModel, MarianTokenizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T14:54:31.015958Z","iopub.execute_input":"2022-05-25T14:54:31.01628Z","iopub.status.idle":"2022-05-25T14:55:04.896129Z","shell.execute_reply.started":"2022-05-25T14:54:31.016249Z","shell.execute_reply":"2022-05-25T14:55:04.895127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(INPUT_DIR+'train.csv')\n# train = train = train.sample(n=15, replace=False, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T14:55:04.899734Z","iopub.execute_input":"2022-05-25T14:55:04.900322Z","iopub.status.idle":"2022-05-25T14:55:04.987939Z","shell.execute_reply.started":"2022-05-25T14:55:04.900275Z","shell.execute_reply":"2022-05-25T14:55:04.986923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_model_name = 'Helsinki-NLP/opus-mt-en-es'\nfirst_model_tkn = MarianTokenizer.from_pretrained(first_model_name)\nfirst_model = MarianMTModel.from_pretrained(first_model_name)\nfirst_model.to(device)\n\nsecond_model_name = 'Helsinki-NLP/opus-mt-es-en'\nsecond_model_tkn = MarianTokenizer.from_pretrained(second_model_name)\nsecond_model = MarianMTModel.from_pretrained(second_model_name)\nsecond_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T14:55:04.989645Z","iopub.execute_input":"2022-05-25T14:55:04.990018Z","iopub.status.idle":"2022-05-25T14:55:57.750148Z","shell.execute_reply.started":"2022-05-25T14:55:04.989979Z","shell.execute_reply":"2022-05-25T14:55:57.749242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_batch_texts(language_code, batch_texts):\n    formated_batch = [\">>{}<< {}\".format(language_code, text) for text in batch_texts]\n    return formated_batch\n\ndef perform_translation(batch_texts, model, tokenizer, language=\"es\"):\n    formated_batch_texts = format_batch_texts(language, batch_texts)\n    translated = model.generate(**tokenizer(formated_batch_texts, return_tensors=\"pt\", padding=True).to(device))\n    translated_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n    return translated_texts","metadata":{"execution":{"iopub.status.busy":"2022-05-25T14:55:57.753167Z","iopub.execute_input":"2022-05-25T14:55:57.753733Z","iopub.status.idle":"2022-05-25T14:55:57.761427Z","shell.execute_reply.started":"2022-05-25T14:55:57.753691Z","shell.execute_reply":"2022-05-25T14:55:57.76049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(train['target'][:10])\n# translated_targets = perform_translation(train['target'].values.tolist(), first_model, first_model_tkn)\n# print(translated_targets[:10])\n# back_translated_targets = perform_translation(translated_targets, second_model, second_model_tkn)\n# print(back_translated_targets[:10])\n\ntrain_trans = train.copy()\ntrain_trans['id'] = train_trans['id'].map(lambda x: x+'_trans')\n\nn = 50\nfor i in range(len(train)//n):\n    if i % 10 == 0:\n        print(i*n)\n    if (i+1)*n < len(train):\n        target_list = train['target'][i*n:(i+1)*n].values.tolist()\n        anchor_list = train['anchor'][i*n:(i+1)*n].values.tolist()\n    else:\n        target_list = train['target'][i*n:].values.tolist()\n        anchor_list = train['anchor'][i*n:].values.tolist()\n        \n    translated_targets = perform_translation(target_list, first_model, first_model_tkn)\n    back_translated_targets = perform_translation(translated_targets, second_model, second_model_tkn)\n    translated_anchors = perform_translation(anchor_list, first_model, first_model_tkn)\n    back_translated_anchors = perform_translation(translated_anchors, second_model, second_model_tkn)\n       \n    train_trans.loc[i*n:(i+1)*n-1, 'target'] = back_translated_targets\n    train_trans.loc[i*n:(i+1)*n-1, 'anchor'] = back_translated_anchors\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n\n# print(train_trans.head(10))\ntrain_trans.to_csv(OUTPUT_DIR+'train_trans.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T14:55:57.763056Z","iopub.execute_input":"2022-05-25T14:55:57.76347Z","iopub.status.idle":"2022-05-25T15:08:38.828653Z","shell.execute_reply.started":"2022-05-25T14:55:57.763427Z","shell.execute_reply":"2022-05-25T15:08:38.826984Z"},"trusted":true},"execution_count":null,"outputs":[]}]}