{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstract\n\nTrain and prototype your models quickly by using TPUs. This notebook shows easy and quick way to train ðŸ¤—Transformers on TPUs.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Versions\n[Inference Notebook](https://www.kaggle.com/code/bharadwajvedula/pppm-tpu-high-speed-bert-inference)\n* Version 1: Base Uncased Bert on TPUs **CV:- 0.8379 LB:- 0.7201**\n* Version 2: Base Uncased Bert on TPUs trained as classification problem **CV:- 0.728 LB:- 0.**\n* Version 4: Base Uncased Bert on TPUs fixing CV issues **CV:- 0. LB:- 0.**","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nfrom scipy.stats import pearsonr\n\nfrom transformers import TFAutoModel, AutoTokenizer\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy \nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, save_model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau , EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, SGD\n\nimport os\nif not os.path.exists(\"./result\"):\n    os.makedirs(\"./result\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:19.053049Z","iopub.execute_input":"2022-06-01T22:36:19.053453Z","iopub.status.idle":"2022-06-01T22:36:29.062779Z","shell.execute_reply.started":"2022-06-01T22:36:19.053353Z","shell.execute_reply":"2022-06-01T22:36:29.061909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class config:\n    # dataset path\n    train_dataset_path = \"../input/p2pmcleaneddataset/train.csv\"\n    test_dataset_path = \"../input/p2pmcleaneddataset/test.csv\"\n    sample_submission_path = \"../input/p2pmcleaneddataset/sample_submission.csv\"\n    cpc_path = \"../input/cpc-codes/titles.csv\"\n    \n   \n\n    save_dir=\"./result\"\n    \n    AUTOTUNE = tf.data.AUTOTUNE\n    \n    #tokenizer params\n    truncation = True \n    padding = 'max_length'\n    max_length = 150\n    \n    # model params\n    model_name = \"bert-base-uncased\"\n    \n    #training params\n    learning_rate = 1e-5\n    batch_size = 512\n    epochs = 12","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:29.064277Z","iopub.execute_input":"2022-06-01T22:36:29.064548Z","iopub.status.idle":"2022-06-01T22:36:29.070657Z","shell.execute_reply.started":"2022-06-01T22:36:29.064518Z","shell.execute_reply":"2022-06-01T22:36:29.069626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU config","metadata":{}},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:29.071938Z","iopub.execute_input":"2022-06-01T22:36:29.072181Z","iopub.status.idle":"2022-06-01T22:36:34.983189Z","shell.execute_reply.started":"2022-06-01T22:36:29.072155Z","shell.execute_reply":"2022-06-01T22:36:34.98216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(config.train_dataset_path)\ndf_test = pd.read_csv(config.test_dataset_path)\ndf_ss = pd.read_csv(config.sample_submission_path)\ndf_cpc = pd.read_csv(config.cpc_path)\n\ndf_train.drop(['context','anchor_length','target_length'] , axis = \"columns\" , inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:34.985844Z","iopub.execute_input":"2022-06-01T22:36:34.986516Z","iopub.status.idle":"2022-06-01T22:36:36.017528Z","shell.execute_reply.started":"2022-06-01T22:36:34.986466Z","shell.execute_reply":"2022-06-01T22:36:36.016487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {}\n\nfor i,j in zip(df_cpc['code'],df_cpc['title']):\n    context_mapping[i] = j\n    \ndf_test['context_text'] = df_test['context'].map(context_mapping)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:36.01861Z","iopub.execute_input":"2022-06-01T22:36:36.018867Z","iopub.status.idle":"2022-06-01T22:36:36.34666Z","shell.execute_reply.started":"2022-06-01T22:36:36.018836Z","shell.execute_reply":"2022-06-01T22:36:36.345757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['text'] = df_train['anchor'] + \" \" + \"[SEP]\" + \" \" + df_train['target'] + \" \" + \"[SEP]\" + \" \" + df_train['context_text']\ndf_test['text'] = df_test['anchor'] + \" \" + \"[SEP]\" + \" \" + df_test['target'] + \" \" + \"[SEP]\" + \" \" + df_test['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:36.347897Z","iopub.execute_input":"2022-06-01T22:36:36.348159Z","iopub.status.idle":"2022-06-01T22:36:36.40586Z","shell.execute_reply.started":"2022-06-01T22:36:36.348129Z","shell.execute_reply":"2022-06-01T22:36:36.405038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:36.406916Z","iopub.execute_input":"2022-06-01T22:36:36.407124Z","iopub.status.idle":"2022-06-01T22:36:36.435595Z","shell.execute_reply.started":"2022-06-01T22:36:36.407099Z","shell.execute_reply":"2022-06-01T22:36:36.434894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['kfold']","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:36.436607Z","iopub.execute_input":"2022-06-01T22:36:36.437152Z","iopub.status.idle":"2022-06-01T22:36:36.444739Z","shell.execute_reply.started":"2022-06-01T22:36:36.437122Z","shell.execute_reply":"2022-06-01T22:36:36.443873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:36.445793Z","iopub.execute_input":"2022-06-01T22:36:36.446727Z","iopub.status.idle":"2022-06-01T22:36:38.982048Z","shell.execute_reply.started":"2022-06-01T22:36:36.446686Z","shell.execute_reply":"2022-06-01T22:36:38.9811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def create_model():\n    transformers = TFAutoModel.from_pretrained(config.model_name)\n    \n    input_ids_layer = Input(shape = (config.max_length) , dtype = tf.int32, name = 'input_ids')\n    attention_mask_layer = Input(shape = (config.max_length), dtype = tf.int32, name = 'attention_mask')\n    \n    transformer = TFAutoModel.from_pretrained(config.model_name)\n    \n    cls_token = transformer(input_ids = input_ids_layer , attention_mask = attention_mask_layer)[0][:,0,:]\n    \n    x = Dropout(0.3)(cls_token)\n    x = Dense(256 , activation = \"relu\")(x)\n    x = Dense(128 , activation = \"relu\")(x)\n    prediction = Dense(1 , activation = \"relu\")(x)\n    \n    model = Model(inputs = [input_ids_layer, attention_mask_layer] , outputs = prediction)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:49:02.63354Z","iopub.execute_input":"2022-06-01T22:49:02.633872Z","iopub.status.idle":"2022-06-01T22:49:02.643048Z","shell.execute_reply.started":"2022-06-01T22:49:02.633831Z","shell.execute_reply":"2022-06-01T22:49:02.642092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Prep Function","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef map_function(encodings , target):\n    input_ids = encodings['input_ids']\n    attention_mask = encodings['attention_mask']\n    \n    target = tf.cast(target, tf.float32 )\n    \n    return {'input_ids': input_ids , 'attention_mask': attention_mask}, target","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:36:38.994901Z","iopub.execute_input":"2022-06-01T22:36:38.995192Z","iopub.status.idle":"2022-06-01T22:36:39.010288Z","shell.execute_reply.started":"2022-06-01T22:36:38.995159Z","shell.execute_reply":"2022-06-01T22:36:39.009446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competition Metrics\nGrabbed this snippet from [here](https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu#Competition-Metrics)","metadata":{}},{"cell_type":"code","source":"class Pearsonr(tf.keras.callbacks.Callback):\n    def __init__(self, model , val_data, y_val):\n        self.val_data = val_data\n        self.y_val = y_val\n        self.model = model\n        \n    def on_epoch_end(self, epoch, logs):\n        val_preds = self.model.predict(self.val_data, verbose=1)\n        val_pearsonr = pearsonr(self.y_val, val_preds.ravel())[0]\n\n        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n        logs[\"val_pearsonr\"] = val_pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:42:10.367992Z","iopub.execute_input":"2022-06-01T22:42:10.368525Z","iopub.status.idle":"2022-06-01T22:42:10.376116Z","shell.execute_reply.started":"2022-06-01T22:42:10.368484Z","shell.execute_reply":"2022-06-01T22:42:10.375235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KFold Training","metadata":{}},{"cell_type":"code","source":"histories = []\nscores = []\nfor fold in range(1,6):\n    print(f\"====== FOLD RUNNING {fold}======\")\n    \n    X_train = df_train.loc[df_train['kfold'] != fold]['text']\n    y_train = df_train.loc[df_train['kfold'] != fold]['score']\n    \n    X_test = df_train.loc[df_train['kfold'] == fold]['text']\n    y_test = df_train.loc[df_train['kfold'] == fold]['score']\n    \n    print(\"Generating Tokens\")\n    train_embeddings = tokenizer(\n        X_train.tolist(),\n        truncation = config.truncation, \n        padding = config.padding,\n        max_length =config.max_length   \n    )\n    \n    validation_embeddings = tokenizer(\n        X_test.tolist(),\n        truncation = config.truncation, \n        padding = config.padding,\n        max_length =config.max_length   \n    )\n    \n    print(\"Generating Datasets\")\n    \n    train = tf.data.Dataset.from_tensor_slices((train_embeddings , y_train))\n    train = (\n                train\n                .map(map_function, num_parallel_calls= config.AUTOTUNE)\n                .batch(config.batch_size)\n                .prefetch(config.AUTOTUNE)\n            )\n    \n    val = tf.data.Dataset.from_tensor_slices((validation_embeddings , y_test))\n    val = (\n                val\n                .map(map_function, num_parallel_calls= config.AUTOTUNE)\n                .batch(config.batch_size)\n                .prefetch(config.AUTOTUNE)\n            )\n    \n    #Clearing backend session\n    K.clear_session()\n    print(\"Backend Cleared\")\n\n    print(\"Model Creation\")\n    with strategy.scope():\n        model = create_model()\n        model.compile(\n          optimizer = Adam(learning_rate = config.learning_rate), \n          metrics = ['mae'],\n          loss = ['mae']\n      )    \n    early_stopping=EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=4,verbose=0,mode=\"min\",restore_best_weights=True)\n    pearson_corr = Pearsonr(model,val, y_test)\n    \n    hist = model.fit(train , validation_data = val , epochs = config.epochs , callbacks = [early_stopping,pearson_corr])\n    \n    # prediction on val\n    print(\"prediction on validation data\")\n    preds = model.predict(val , verbose = 1)\n    score = pearsonr(preds.reshape(preds.shape[0],), y_test)[0]    \n    scores.append(score)\n    \n    #saving model\n    print(\"saving model\")\n    \n    localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n    model.save(f'{config.save_dir}/{config.model_name}_{fold}', options=localhost_save_option)\n    \n    del model\n\n    histories.append(hist)\n\nprint(\"the final average rmse is \", np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:49:09.696302Z","iopub.execute_input":"2022-06-01T22:49:09.69661Z","iopub.status.idle":"2022-06-01T22:53:20.195767Z","shell.execute_reply.started":"2022-06-01T22:49:09.696582Z","shell.execute_reply":"2022-06-01T22:53:20.194216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThanks for viewing, drop your suggestions down in the comments below. ðŸ™‚","metadata":{}}]}