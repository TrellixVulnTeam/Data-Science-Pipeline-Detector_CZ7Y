{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstract\n\nTrain and prototype your models quickly by using TPUs. This notebook shows easy and quick way to train ðŸ¤—Transformers on TPUs.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Versions\n[Inference Notebook](https://www.kaggle.com/code/bharadwajvedula/pppm-tpu-high-speed-patentsberta-inference)\n* Version 1: PatentSBERTa on TPUs **CV:- 0.7920 LB:- 0.7731**\n* Version 2: PatentSBERTa with attention head on TPUs **CV:- 0.7942 LB:- 0.7744**\n","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import gc\nimport numpy as np \nimport pandas as pd \n\nfrom scipy.stats import pearsonr\n\nfrom transformers import TFAutoModel, AutoTokenizer\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy \nfrom tensorflow.keras.activations import tanh, softmax\nfrom tensorflow.keras.layers import Layer,Input, Dense, Flatten, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, save_model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau , EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, SGD\n\nimport os\nif not os.path.exists(\"./result\"):\n    os.makedirs(\"./result\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:00.209945Z","iopub.execute_input":"2022-06-08T17:56:00.210763Z","iopub.status.idle":"2022-06-08T17:56:08.640095Z","shell.execute_reply.started":"2022-06-08T17:56:00.210661Z","shell.execute_reply":"2022-06-08T17:56:08.639179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class config:\n    # dataset path\n    train_dataset_path = \"../input/p2pmcleaneddataset/train.csv\"\n    test_dataset_path = \"../input/p2pmcleaneddataset/test.csv\"\n    sample_submission_path = \"../input/p2pmcleaneddataset/sample_submission.csv\"\n    cpc_path = \"../input/cpc-codes/titles.csv\"\n    \n   \n\n    save_dir=\"./result\"\n    \n    AUTOTUNE = tf.data.AUTOTUNE\n    \n    #tokenizer params\n    truncation = True \n    padding = 'max_length'\n    max_length = 150\n    \n    # model params\n    model_name = \"AI-Growth-Lab/PatentSBERTa\"\n    \n    #training params\n    learning_rate = 1e-5\n    batch_size = 128\n    epochs = 15","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:21.876868Z","iopub.execute_input":"2022-06-08T17:56:21.877368Z","iopub.status.idle":"2022-06-08T17:56:21.883512Z","shell.execute_reply.started":"2022-06-08T17:56:21.877316Z","shell.execute_reply":"2022-06-08T17:56:21.882612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU config","metadata":{}},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:24.549642Z","iopub.execute_input":"2022-06-08T17:56:24.550412Z","iopub.status.idle":"2022-06-08T17:56:30.872995Z","shell.execute_reply.started":"2022-06-08T17:56:24.550374Z","shell.execute_reply":"2022-06-08T17:56:30.872165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(config.train_dataset_path)\ndf_test = pd.read_csv(config.test_dataset_path)\ndf_ss = pd.read_csv(config.sample_submission_path)\ndf_cpc = pd.read_csv(config.cpc_path)\n\ndf_train.drop(['context','anchor_length','target_length'] , axis = \"columns\" , inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:45.255627Z","iopub.execute_input":"2022-06-08T17:56:45.255931Z","iopub.status.idle":"2022-06-08T17:56:46.325421Z","shell.execute_reply.started":"2022-06-08T17:56:45.2559Z","shell.execute_reply":"2022-06-08T17:56:46.324453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {}\n\nfor i,j in zip(df_cpc['code'],df_cpc['title']):\n    context_mapping[i] = j\n    \ndf_test['context_text'] = df_test['context'].map(context_mapping)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:50.954807Z","iopub.execute_input":"2022-06-08T17:56:50.955111Z","iopub.status.idle":"2022-06-08T17:56:51.27017Z","shell.execute_reply.started":"2022-06-08T17:56:50.955078Z","shell.execute_reply":"2022-06-08T17:56:51.269539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['text'] = df_train['anchor'] + \" \" + \"[SEP]\" + \" \" + df_train['target'] + \" \" + \"[SEP]\" + \" \" + df_train['context_text']\ndf_test['text'] = df_test['anchor'] + \" \" + \"[SEP]\" + \" \" + df_test['target'] + \" \" + \"[SEP]\" + \" \" + df_test['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:54.589681Z","iopub.execute_input":"2022-06-08T17:56:54.589976Z","iopub.status.idle":"2022-06-08T17:56:54.646974Z","shell.execute_reply.started":"2022-06-08T17:56:54.589947Z","shell.execute_reply":"2022-06-08T17:56:54.646223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:54.749597Z","iopub.execute_input":"2022-06-08T17:56:54.750191Z","iopub.status.idle":"2022-06-08T17:56:54.77881Z","shell.execute_reply.started":"2022-06-08T17:56:54.750143Z","shell.execute_reply":"2022-06-08T17:56:54.777849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['kfold']","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:55.27979Z","iopub.execute_input":"2022-06-08T17:56:55.280062Z","iopub.status.idle":"2022-06-08T17:56:55.287858Z","shell.execute_reply.started":"2022-06-08T17:56:55.280033Z","shell.execute_reply":"2022-06-08T17:56:55.287019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:56:57.549706Z","iopub.execute_input":"2022-06-08T17:56:57.550009Z","iopub.status.idle":"2022-06-08T17:57:00.056997Z","shell.execute_reply.started":"2022-06-08T17:56:57.549978Z","shell.execute_reply":"2022-06-08T17:57:00.056099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"./result/tokenizer/\")","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:57:00.058708Z","iopub.execute_input":"2022-06-08T17:57:00.058957Z","iopub.status.idle":"2022-06-08T17:57:00.110235Z","shell.execute_reply.started":"2022-06-08T17:57:00.05892Z","shell.execute_reply":"2022-06-08T17:57:00.109379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"transformers = TFAutoModel.from_pretrained(config.model_name,from_pt = True)\ntransformers.save_pretrained('./result/hf_model/')\ndel transformers\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:57:03.695385Z","iopub.execute_input":"2022-06-08T17:57:03.695729Z","iopub.status.idle":"2022-06-08T17:57:24.378657Z","shell.execute_reply.started":"2022-06-08T17:57:03.695693Z","shell.execute_reply":"2022-06-08T17:57:24.377602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SBERTaBlock(Layer):\n    def __init__(self):\n        super(SBERTaBlock , self).__init__()\n        self.SBERTa_model = TFAutoModel.from_pretrained(config.model_name,from_pt = True)\n        \n    def call(self,input_tensors):\n        input_id = input_tensors[0]\n        attention_mask = input_tensors[1]\n        SBERTa_output = self.SBERTa_model(input_ids = input_id , attention_mask = attention_mask)\n        SBERTa_output = SBERTa_output.last_hidden_state\n        return SBERTa_output\n\nclass RegressionHead(Layer):\n    def __init__(self):\n        super(RegressionHead , self).__init__()\n        self.dense = Dense(1, activation=\"relu\")\n    \n    def call(self , input_tensors):\n        x = self.dense(input_tensors)\n        return x\n\nclass AttentionHead(Layer):\n    def __init__(self):\n        super(AttentionHead , self).__init__()\n        self.dense1 = Dense(512)\n        self.tanh =  tanh\n        self.softmax = softmax\n        self.dense2 = Dense(1,activation=\"softmax\")\n    \n    def call(self , input_tensors):\n        x = self.dense1(input_tensors)\n        x = self.tanh(x)\n        x = self.dense2(x)\n        x = self.softmax(x , axis = 1)\n        return x \n\nclass PPPMModel(Model):\n    def __init__(self):\n        super(PPPMModel, self).__init__()\n        self.SBERTa_model = SBERTaBlock()\n        self.attentionhead = AttentionHead()\n        self.regressionhead = RegressionHead()\n    \n    def call(self,input_tensors):\n        SBERTa_output = self.SBERTa_model(input_tensors)\n        weights = self.attentionhead(SBERTa_output)\n        context_vector = tf.reduce_sum(weights * SBERTa_output, axis=1)\n        x = self.regressionhead(context_vector)\n        return x\n    \n    def model(self):\n        input_id = Input(shape = (config.max_length) , dtype = tf.int32, name = 'input_ids')\n        attention_mask = Input(shape = (config.max_length), dtype = tf.int32, name = 'attention_mask')\n        \n        return Model(inputs = [input_id , attention_mask] , outputs = self.call([input_id , attention_mask]))","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:57:50.674738Z","iopub.execute_input":"2022-06-08T17:57:50.675492Z","iopub.status.idle":"2022-06-08T17:57:50.694574Z","shell.execute_reply.started":"2022-06-08T17:57:50.675421Z","shell.execute_reply":"2022-06-08T17:57:50.693106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Prep Function","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef map_function(encodings , target):\n    input_ids = encodings['input_ids']\n    attention_mask = encodings['attention_mask']\n    \n    target = tf.cast(target, tf.float32 )\n    \n    return {'input_ids': input_ids , 'attention_mask': attention_mask}, target","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:58:04.710127Z","iopub.execute_input":"2022-06-08T17:58:04.710593Z","iopub.status.idle":"2022-06-08T17:58:04.717957Z","shell.execute_reply.started":"2022-06-08T17:58:04.710441Z","shell.execute_reply":"2022-06-08T17:58:04.71693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competition Metrics\nGrabbed this snippet from [here](https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu#Competition-Metrics)","metadata":{}},{"cell_type":"code","source":"class Pearsonr(tf.keras.callbacks.Callback):\n    def __init__(self, model , val_data, y_val):\n        self.val_data = val_data\n        self.y_val = y_val\n        self.model = model\n        \n    def on_epoch_end(self, epoch, logs):\n        val_preds = self.model.predict(self.val_data, verbose=1)\n        val_pearsonr = pearsonr(self.y_val, val_preds.ravel())[0]\n\n        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n        logs[\"val_pearsonr\"] = val_pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:58:07.690099Z","iopub.execute_input":"2022-06-08T17:58:07.690384Z","iopub.status.idle":"2022-06-08T17:58:07.697957Z","shell.execute_reply.started":"2022-06-08T17:58:07.690356Z","shell.execute_reply":"2022-06-08T17:58:07.697062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KFold Training","metadata":{}},{"cell_type":"code","source":"histories = []\nscores = []\nfor fold in range(1,6):\n    print(f\"====== FOLD RUNNING {fold}======\")\n    \n    X_train = df_train.loc[df_train['kfold'] != fold]['text']\n    y_train = df_train.loc[df_train['kfold'] != fold]['score']\n    \n    X_test = df_train.loc[df_train['kfold'] == fold]['text']\n    y_test = df_train.loc[df_train['kfold'] == fold]['score']\n    \n    print(\"Generating Tokens\")\n    train_embeddings = tokenizer(\n        X_train.tolist(),\n        truncation = config.truncation, \n        padding = config.padding,\n        max_length =config.max_length   \n    )\n    \n    validation_embeddings = tokenizer(\n        X_test.tolist(),\n        truncation = config.truncation, \n        padding = config.padding,\n        max_length =config.max_length   \n    )\n    \n    print(\"Generating Datasets\")\n    \n    train = tf.data.Dataset.from_tensor_slices((train_embeddings , y_train))\n    train = (\n                train\n                .map(map_function, num_parallel_calls= config.AUTOTUNE)\n                .batch(config.batch_size)\n                .prefetch(config.AUTOTUNE)\n            )\n    \n    val = tf.data.Dataset.from_tensor_slices((validation_embeddings , y_test))\n    val = (\n                val\n                .map(map_function, num_parallel_calls= config.AUTOTUNE)\n                .batch(config.batch_size)\n                .prefetch(config.AUTOTUNE)\n            )\n    \n    #Clearing backend session\n    K.clear_session()\n    print(\"Backend Cleared\")\n\n    print(\"Model Creation\")\n    with strategy.scope():\n        model = PPPMModel().model()\n        model.compile(\n          optimizer = Adam(learning_rate = config.learning_rate), \n          metrics = ['mae'],\n          loss = ['mae']\n      )    \n    early_stopping=EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=4,verbose=0,mode=\"min\",restore_best_weights=True)\n    pearson_corr = Pearsonr(model,val, y_test)\n    \n    hist = model.fit(train , validation_data = val , epochs = config.epochs, callbacks = [early_stopping,pearson_corr])\n    \n    # prediction on val\n    print(\"prediction on validation data\")\n    preds = model.predict(val , verbose = 1)\n    score = pearsonr(preds.reshape(preds.shape[0],), y_test)[0]    \n    scores.append(score)\n    \n    #saving model\n    print(\"saving model\")\n    \n    localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n    model.save(f'{config.save_dir}/{config.model_name}_{fold}', options=localhost_save_option)\n    \n    del model\n\n    histories.append(hist)\n\nprint(\"the final average rmse is \", np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:59:39.591254Z","iopub.execute_input":"2022-06-08T17:59:39.591574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThanks for viewing, drop your suggestions down in the comments below. ðŸ™‚","metadata":{}}]}