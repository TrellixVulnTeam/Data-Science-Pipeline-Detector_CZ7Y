{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pretrained_Model\nhttps://www.kaggle.com/code/hannes82/pppm-deberta-v3-large-closing-the-cv-lb-gap/notebook?scriptVersionId=91284532.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T07:24:58.835268Z","iopub.execute_input":"2022-04-27T07:24:58.835642Z","iopub.status.idle":"2022-04-27T07:25:29.610646Z","shell.execute_reply.started":"2022-04-27T07:24:58.835559Z","shell.execute_reply":"2022-04-27T07:25:29.60988Z"}}},{"cell_type":"code","source":"import os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\nimport os\nimport gc\nimport re\nimport ast\nimport datetime\nfrom sklearn.model_selection import StratifiedKFold\nfrom datetime import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import BayesianRidge\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-v3-large-closing-the-cv-lb-gap/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n#    seed=42\n    seed=41\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.612187Z","iopub.execute_input":"2022-04-27T07:25:29.612654Z","iopub.status.idle":"2022-04-27T07:25:29.618122Z","shell.execute_reply.started":"2022-04-27T07:25:29.612619Z","shell.execute_reply":"2022-04-27T07:25:29.617185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.61997Z","iopub.execute_input":"2022-04-27T07:25:29.620472Z","iopub.status.idle":"2022-04-27T07:25:29.636234Z","shell.execute_reply.started":"2022-04-27T07:25:29.620432Z","shell.execute_reply":"2022-04-27T07:25:29.63558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\nlabels = oof_df['score'].values\npreds = oof_df['pred'].values\nscore = get_score(labels, preds)\nLOGGER.info(f'CV Score: {score:<.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.638499Z","iopub.execute_input":"2022-04-27T07:25:29.638782Z","iopub.status.idle":"2022-04-27T07:25:29.759903Z","shell.execute_reply.started":"2022-04-27T07:25:29.638746Z","shell.execute_reply":"2022-04-27T07:25:29.759051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\ntrain_df = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.761295Z","iopub.execute_input":"2022-04-27T07:25:29.761564Z","iopub.status.idle":"2022-04-27T07:25:29.903539Z","shell.execute_reply.started":"2022-04-27T07:25:29.761512Z","shell.execute_reply":"2022-04-27T07:25:29.902658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntrain_df['context_text'] = train_df['context'].map(cpc_texts)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.905031Z","iopub.execute_input":"2022-04-27T07:25:29.905292Z","iopub.status.idle":"2022-04-27T07:25:29.934895Z","shell.execute_reply.started":"2022-04-27T07:25:29.905259Z","shell.execute_reply":"2022-04-27T07:25:29.93411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\ntrain_df['text'] = train_df['anchor'] + '[SEP]' + train_df['target'] + '[SEP]'  + train_df['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.93627Z","iopub.execute_input":"2022-04-27T07:25:29.936512Z","iopub.status.idle":"2022-04-27T07:25:29.973249Z","shell.execute_reply.started":"2022-04-27T07:25:29.936477Z","shell.execute_reply":"2022-04-27T07:25:29.972566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:29.974417Z","iopub.execute_input":"2022-04-27T07:25:29.974677Z","iopub.status.idle":"2022-04-27T07:25:30.677763Z","shell.execute_reply.started":"2022-04-27T07:25:29.974644Z","shell.execute_reply":"2022-04-27T07:25:30.677005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:30.679029Z","iopub.execute_input":"2022-04-27T07:25:30.679285Z","iopub.status.idle":"2022-04-27T07:25:30.686467Z","shell.execute_reply.started":"2022-04-27T07:25:30.679253Z","shell.execute_reply":"2022-04-27T07:25:30.68582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return feature,output","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:30.689741Z","iopub.execute_input":"2022-04-27T07:25:30.690253Z","iopub.status.idle":"2022-04-27T07:25:30.706576Z","shell.execute_reply.started":"2022-04-27T07:25:30.690218Z","shell.execute_reply":"2022-04-27T07:25:30.705928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(path,\n                       map_location=torch.device('cuda'))\n    model.load_state_dict(state['model'])\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained('../input/pppm-deberta-v3-large-closing-the-cv-lb-gap/tokenizer/')\n    \n    ds = TestDataset(CFG,df)\n    dl = DataLoader(ds,\n                  batch_size = 64,\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n   \n    tk0 = tqdm(dl, total=len(dl))\n    embeddings = list()\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            \n            feat,outputs = model(inputs)\n            feat = feat.detach().cpu().numpy()\n            embeddings.extend(feat)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:30.707522Z","iopub.execute_input":"2022-04-27T07:25:30.707838Z","iopub.status.idle":"2022-04-27T07:25:30.720806Z","shell.execute_reply.started":"2022-04-27T07:25:30.707801Z","shell.execute_reply":"2022-04-27T07:25:30.720086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  np.load('../input/train-embeddings/Train_embeddings1.npy')\ntest_embeddings1 = get_embeddings(test,'../input/pppm-deberta-v3-large-closing-the-cv-lb-gap/microsoft-deberta-v3-large_fold0_best.pth')\ntrain_embeddings2 =  np.load('../input/train-embeddings/Train_embeddings2.npy')\ntest_embeddings2 = get_embeddings(test,'../input/pppm-deberta-v3-large-closing-the-cv-lb-gap/microsoft-deberta-v3-large_fold1_best.pth')\ntrain_embeddings3 =  np.load('../input/train-embeddings/Train_embeddings3.npy')\ntest_embeddings3 = get_embeddings(test,'../input/pppm-deberta-v3-large-closing-the-cv-lb-gap/microsoft-deberta-v3-large_fold2_best.pth')\ntrain_embeddings4 =  np.load('../input/train-embeddings/Train_embeddings4.npy')\ntest_embeddings4 = get_embeddings(test,'../input/pppm-deberta-v3-large-closing-the-cv-lb-gap/microsoft-deberta-v3-large_fold3_best.pth')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:25:30.722596Z","iopub.execute_input":"2022-04-27T07:25:30.72278Z","iopub.status.idle":"2022-04-27T07:27:40.831505Z","shell.execute_reply.started":"2022-04-27T07:25:30.722759Z","shell.execute_reply":"2022-04-27T07:27:40.829887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy\ndef calculate_metrics(targets, outputs):\n    \n    return dict(pearson=scipy.stats.pearsonr(outputs, targets)[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:27:40.837655Z","iopub.execute_input":"2022-04-27T07:27:40.838395Z","iopub.status.idle":"2022-04-27T07:27:40.848108Z","shell.execute_reply.started":"2022-04-27T07:27:40.838344Z","shell.execute_reply":"2022-04-27T07:27:40.847472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\ntrain_scores = []\n\ndf_oof=train_df.copy()\ndf_oof['oof'] = 0\n\nskf = StratifiedKFold(5, shuffle=True, random_state=42)\ntrain_df[\"score_bin\"] = pd.cut(train_df[\"score\"], bins=5, labels=False)\nsplits = list(skf.split(X=train_embeddings1, y=train_df[\"score_bin\"].values,groups=train_df[\"anchor\"].values))\n\n# predicting out of fold scores for each fold and doing predictions for each training set\n\nfor i, (train_idx, val_idx) in enumerate(splits):\n    print(f'\\n------------- Training Fold {i + 1} / {10}')\n    print(\"Current Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n\n    clf = BayesianRidge(n_iter=300, verbose=True)\n    clf.fit(train_embeddings1[train_idx],train_df.score_bin[train_idx])\n    train_score=calculate_metrics(train_df.score_bin[train_idx], clf.predict(train_embeddings1[train_idx]))\n    train_scores.append(train_score)\n    print(f\"Fold {i} train RMSE: {train_score}\")\n    \n    \n    preds.append(clf.predict(test_embeddings1))\n    x=clf.predict(train_embeddings1[val_idx])\n    df_oof['oof'].iloc[val_idx]+= x\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:27:40.852282Z","iopub.execute_input":"2022-04-27T07:27:40.854976Z","iopub.status.idle":"2022-04-27T07:28:27.923792Z","shell.execute_reply.started":"2022-04-27T07:27:40.854914Z","shell.execute_reply":"2022-04-27T07:28:27.922923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.mean(preds,0)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:27.925214Z","iopub.execute_input":"2022-04-27T07:28:27.925471Z","iopub.status.idle":"2022-04-27T07:28:27.932354Z","shell.execute_reply.started":"2022-04-27T07:28:27.925437Z","shell.execute_reply":"2022-04-27T07:28:27.930547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission(ids, predictions, path=\"submission.csv\"):\n    submission = pd.DataFrame({\n        \"id\": ids,\n        \"score\": predictions,\n    })\n    \n    submission.to_csv(path, index=False)\n    return submission\ndef merge_cpc_codes_with_data_frame(data_frame, cpc_codes, sep=\" \"):\n    data_frame = data_frame.merge(cpc_codes, left_on=\"context\", right_on=\"code\")\n    data_frame[\"text\"] = (data_frame[\"anchor\"] + sep + data_frame[\"title\"]).str.lower()\n    return data_frame\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:27.933947Z","iopub.execute_input":"2022-04-27T07:28:27.934245Z","iopub.status.idle":"2022-04-27T07:28:27.944496Z","shell.execute_reply.started":"2022-04-27T07:28:27.934207Z","shell.execute_reply":"2022-04-27T07:28:27.943538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['predicted'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:27.946003Z","iopub.execute_input":"2022-04-27T07:28:27.94627Z","iopub.status.idle":"2022-04-27T07:28:27.954509Z","shell.execute_reply.started":"2022-04-27T07:28:27.946233Z","shell.execute_reply":"2022-04-27T07:28:27.953492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:27.955888Z","iopub.execute_input":"2022-04-27T07:28:27.957185Z","iopub.status.idle":"2022-04-27T07:28:27.971217Z","shell.execute_reply.started":"2022-04-27T07:28:27.957143Z","shell.execute_reply":"2022-04-27T07:28:27.970365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:27.972617Z","iopub.execute_input":"2022-04-27T07:28:27.972876Z","iopub.status.idle":"2022-04-27T07:28:27.997916Z","shell.execute_reply.started":"2022-04-27T07:28:27.972842Z","shell.execute_reply":"2022-04-27T07:28:27.996724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub['score'] = test['predicted']","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:27.999247Z","iopub.execute_input":"2022-04-27T07:28:27.999685Z","iopub.status.idle":"2022-04-27T07:28:28.006015Z","shell.execute_reply.started":"2022-04-27T07:28:27.999649Z","shell.execute_reply":"2022-04-27T07:28:28.004899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:28:28.007351Z","iopub.execute_input":"2022-04-27T07:28:28.007833Z","iopub.status.idle":"2022-04-27T07:28:28.020277Z","shell.execute_reply.started":"2022-04-27T07:28:28.007791Z","shell.execute_reply":"2022-04-27T07:28:28.019126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}