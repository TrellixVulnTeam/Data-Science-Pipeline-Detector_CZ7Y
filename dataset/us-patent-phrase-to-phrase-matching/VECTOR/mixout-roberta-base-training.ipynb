{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T05:07:48.243766Z","iopub.execute_input":"2022-04-22T05:07:48.244106Z","iopub.status.idle":"2022-04-22T05:07:48.97094Z","shell.execute_reply.started":"2022-04-22T05:07:48.244026Z","shell.execute_reply":"2022-04-22T05:07:48.970142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport math\nimport sys\nsys.path.append(\"../input/torch-components-library/torch-components-main\")\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom torch_components import Configuration, Timer, Averager\nfrom torch_components.callbacks import EarlyStopping, ModelCheckpoint\nfrom torch_components.utils import seed_everything, get_lr, get_optimizer, get_scheduler, get_batch\nfrom torch_components.import_utils import wandb_run_exists\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.optim import Optimizer\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import GradScaler, autocast\nfrom transformers import (\n    get_cosine_schedule_with_warmup, \n    get_cosine_with_hard_restarts_schedule_with_warmup,\n    get_linear_schedule_with_warmup,\n    get_constant_schedule_with_warmup\n)\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig\nfrom transformers import AutoModel\nfrom transformers import PreTrainedModel\n\nfrom tqdm import tqdm\nfrom datetime import timedelta\nimport scipy\nfrom torch.optim import lr_scheduler\nimport warnings\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()\nimport gc\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:48.972788Z","iopub.execute_input":"2022-04-22T05:07:48.973012Z","iopub.status.idle":"2022-04-22T05:07:55.671844Z","shell.execute_reply.started":"2022-04-22T05:07:48.972981Z","shell.execute_reply":"2022-04-22T05:07:55.671057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ndevice = torch.device(\"cuda\")\ncurrent_dir = ''","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:55.674162Z","iopub.execute_input":"2022-04-22T05:07:55.67439Z","iopub.status.idle":"2022-04-22T05:07:55.682161Z","shell.execute_reply.started":"2022-04-22T05:07:55.674354Z","shell.execute_reply":"2022-04-22T05:07:55.681376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_dict = {\n    \"split_num\" : 4,\n    \"seed\" : [2021],\n#     \"seed\" : [0],\n    \"batch_size\" : 64,\n    \"input_path\"  : '../input/us-patent-phrase-to-phrase-matching/',\n    \"model_path\" : '../input/uspppm-debertv3large-5folds-v2/',\n    \"learning_rate\" : 2e-5,\n#     \"learning_rate\" : 1e-4,\n    \"regressor_lr\" : 1.0,\n    \"weight_decay\" : 0.01,\n    \"max_length\" : 256,\n    \"epochs\" : 6,\n#     \"epochs\" : 1,\n    \"hidden_dropout\" : 0,\n    \"attention_dropout\" : 0.1,\n    \"linear_dropout1\" : 0.1,\n    \"linear_dropout2\" : 0.1,\n    \"warmup_ratio\" : 0.06,\n    \"use_llrd\" : True,\n    \"llrd_rate\" : 0.95,\n    \"optimizer\":dict(name=\"AdamW\", \n                                      parameters=dict(lr=2e-5, weight_decay=0.0)),\n                       \n    \"scheduler\":dict(name=\"get_cosine_with_hard_restarts_schedule_with_warmup\", \n                                      parameters=dict(num_cycles=2, last_epoch=-1)),\n#     \"llrd_rate\" : 0.8,\n    \"freeze_embed\" : False,\n    \"use_mixout\" : True,\n    \"mixout_prob\" : 0.3,\n    \"use_prior_wd\" : False,\n    \"gradient_norm\":1.0,\n    \"gradient_scaling\":True,\n    \"use_USPPM_pretrained\" : True,\n    \"use_relu\" : False,\n    \"val_interval\" : 20,\n    \"no_interval_epoch\" : 0,\n    \"reinit_layers\" : 0,\n#     \"reinit_layers\" : 4,\n    \"split_type\" : 0,\n    \"output_directory\": './',\n    \"num_workers\":4,\n    \"pin_memory\" : True,\n    \"delta\" : 1e-4,\n    \"scheduling_after\":\"step\",\n    \"gradient_accumulation_steps\":1,\n    \"validation_steps\":500, \n    \"amp\":True, \n    \"debug\":True,\n    \"verbose\":250,\n    \"device\":'cuda',\n    \"cv_monitor_value\":\"pearson\",\n    \"save_model\":True,\n     \n#     \"model_name\" : \"roberta-base\",\n#     \"model_name\" : 'roberta-large',\n#     \"model_name\" : 'microsoft/deberta-base',\n#     \"model_name\" : 'microsoft/deberta-large',\n#     \"model_name\" : \"google/electra-large-generator\",\n    \"model_name\" : \"../input/roberta-base\",\n#     \"model_name\" : 'studio-ousia/luke-base',\n#     \"model_name\" : 'studio-ousia/luke-large',\n#     \"model_name\" : 'nghuyong/ernie-2.0-en',\n    \n    \"input_linear_num1\" : 768,\n    \"input_linear_num2\" : 384,\n#     \"input_linear_num1\" : 1024,\n#     \"input_linear_num2\" : 512,\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:55.685431Z","iopub.execute_input":"2022-04-22T05:07:55.68593Z","iopub.status.idle":"2022-04-22T05:07:55.696797Z","shell.execute_reply.started":"2022-04-22T05:07:55.685887Z","shell.execute_reply":"2022-04-22T05:07:55.695898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RESULT_TEXT_PATH = f\"{current_dir}result_text.txt\"\n# if os.path.exists(RESULT_TEXT_PATH):\n#     raise\n\nconf_text = \"\"\nfor key,value in conf_dict.items():\n    conf_text += f\"{key}:{value}\\n\"\n        \nwith open(RESULT_TEXT_PATH, mode='w') as f:\n    f.write(conf_text)\n    f.write(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:55.698343Z","iopub.execute_input":"2022-04-22T05:07:55.698825Z","iopub.status.idle":"2022-04-22T05:07:55.707898Z","shell.execute_reply.started":"2022-04-22T05:07:55.698789Z","shell.execute_reply":"2022-04-22T05:07:55.707223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:55.709228Z","iopub.execute_input":"2022-04-22T05:07:55.709485Z","iopub.status.idle":"2022-04-22T05:07:55.720024Z","shell.execute_reply.started":"2022-04-22T05:07:55.709454Z","shell.execute_reply":"2022-04-22T05:07:55.719041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if conf_dict[\"split_type\"] == 0:\n    train_df = pd.read_csv(f\"{conf_dict['input_path']}train.csv\")\n    train_df['fold'] = -1\n    titles = pd.read_csv('../input/cpc-codes/titles.csv')\n    train_df = train_df.merge(titles, left_on='context', right_on='code')\n    train_df['input'] = train_df['title']+'[SEP]'+train_df['anchor']\n    train_df = train_df.sort_values(\"target\").reset_index(drop=True)\n    train_df[\"fold\"] = train_df.index % 4\n\nif conf_dict[\"split_type\"] == 1:\n    import numpy as np\n    import pandas as pd\n\n    from sklearn import datasets\n    from sklearn import model_selection\n\n    def create_folds(data, num_splits):\n        data[\"fold\"] = -1\n        data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n        num_bins = int(np.floor(1 + np.log2(len(data))))\n        data.loc[:, \"bins\"] = pd.cut(\n            data[\"target\"], bins=num_bins, labels=False\n        )\n        kf = model_selection.StratifiedKFold(n_splits=num_splits)\n        for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n            data.loc[v_, 'fold'] = f\n        data = data.drop(\"bins\", axis=1)\n        return data\n\n    train_df = pd.read_csv(f\"{conf_dict['input_path']}train.csv\")\n    titles = pd.read_csv('../input/cpc-codes/titles.csv')\n    train_df = train_df.merge(titles, left_on='context', right_on='code')\n    train_df['input'] = train_df['title']+'[SEP]'+train_df['anchor']\n    train_df = create_folds(train_df, num_splits=conf_dict[\"split_num\"])\n    print(train_df.fold.value_counts())\n    train_df","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:55.721436Z","iopub.execute_input":"2022-04-22T05:07:55.721956Z","iopub.status.idle":"2022-04-22T05:07:56.808443Z","shell.execute_reply.started":"2022-04-22T05:07:55.721921Z","shell.execute_reply":"2022-04-22T05:07:56.807686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"score_bin\"] = pd.cut(train_df[\"score\"], bins=5, labels=False)\ntrain_df[\"text_length\"] = train_df[\"input\"].apply(lambda text: len(text.split()))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:56.810442Z","iopub.execute_input":"2022-04-22T05:07:56.810905Z","iopub.status.idle":"2022-04-22T05:07:56.856223Z","shell.execute_reply.started":"2022-04-22T05:07:56.810868Z","shell.execute_reply":"2022-04-22T05:07:56.855596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"../input/roberta-base\")\ntokenizer_path = os.path.join('./', \"tokenizer/\")\ntokenizer_files = tokenizer.save_pretrained(tokenizer_path)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:56.857643Z","iopub.execute_input":"2022-04-22T05:07:56.857905Z","iopub.status.idle":"2022-04-22T05:07:57.100164Z","shell.execute_reply.started":"2022-04-22T05:07:56.857869Z","shell.execute_reply":"2022-04-22T05:07:57.09938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset:\n    def __init__(self, texts, pair_texts, tokenizer, targets=None, max_length=128):\n        self.texts = texts\n        self.pair_texts = pair_texts\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, index):\n        text = self.texts[index].lower()\n        pair_text = self.pair_texts[index].lower()\n        \n        tokenized = self.tokenizer(text=text, \n                                   text_pair=pair_text, \n                                   add_special_tokens=True,\n                                   #max_length=self.max_length,\n                                   #padding=\"max_length\",\n                                   truncation=True,\n                                   return_attention_mask=True,\n                                   return_token_type_ids=False,\n                                   return_offsets_mapping=False)\n        \n        \n        if self.targets is not None:\n            target = self.targets[index]\n            \n            return tokenized, target\n            \n        return tokenized","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.103674Z","iopub.execute_input":"2022-04-22T05:07:57.104369Z","iopub.status.idle":"2022-04-22T05:07:57.112248Z","shell.execute_reply.started":"2022-04-22T05:07:57.104312Z","shell.execute_reply":"2022-04-22T05:07:57.111549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class USPPM_Model(PreTrainedModel): \n    def __init__(self, conf):\n        super(USPPM_Model, self).__init__(conf) \n\n        if conf_dict[\"use_USPPM_pretrained\"]:\n            self.bert = AutoModel.from_pretrained(f'{current_dir}../input/roberta-base/pytorch_model.bin', config=conf)\n        else:\n            self.bert = AutoModel.from_pretrained(conf_dict[\"model_name\"], config=conf)\n        \n        self.drop_out1 = nn.Dropout(conf_dict[\"linear_dropout1\"])\n        self.drop_out2 = nn.Dropout(conf_dict[\"linear_dropout2\"])\n\n        self.layer_norm1 = nn.LayerNorm(conf_dict[\"input_linear_num1\"])\n        self.l1 = nn.Linear(conf_dict[\"input_linear_num1\"], conf_dict[\"input_linear_num2\"])\n        self.l2 = nn.Linear(conf_dict[\"input_linear_num2\"], 1)\n\n        self._init_weights(self.layer_norm1)\n        self._init_weights(self.l1)\n        self._init_weights(self.l2)\n \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n    \n    def forward(self, ids, mask):\n        out = self.bert(\n            input_ids=ids,\n            attention_mask=mask\n        )\n\n        # out = out['pooler_output']        \n        out = torch.mean(out['last_hidden_state'], 1)\n        out = self.layer_norm1(out)\n        out = self.drop_out1(out)\n        out = self.l1(out)\n        if conf_dict[\"use_relu\"]:\n            out = F.relu(out)\n        out = self.drop_out2(out)\n        out = self.l2(out)\n#         print(\"out:\",out.shape)\n        \n        preds = out.squeeze(-1)\n#         raise\n\n        return preds","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.115365Z","iopub.execute_input":"2022-04-22T05:07:57.1156Z","iopub.status.idle":"2022-04-22T05:07:57.130317Z","shell.execute_reply.started":"2022-04-22T05:07:57.115543Z","shell.execute_reply":"2022-04-22T05:07:57.129355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_optimizer_params(model):\n    param_optimizer = list(model.named_parameters())\n    learning_rate = conf_dict[\"learning_rate\"]\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n\n    model_word = \"bert\"\n\n    # print('model.named_parameters():',[n for n, p in model.named_parameters()])\n    # print('[n for n, p in model.named_parameters() if \"bert\" not in n]', [n for n, p in model.named_parameters() if model_word not in n])\n    optimizer_parameters = [\n        {\n            'params': [p for n, p in model.named_parameters() if model_word not in n],\n            'lr': conf_dict[\"learning_rate\"] * conf_dict[\"regressor_lr\"],\n        }\n    ]\n\n \n    layers = [getattr(model, model_word).embeddings] + list(getattr(model, model_word).encoder.layer)\n    layers.reverse()\n    # print('layers ',layers)\n    for layer in layers:\n        # print('[n for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)] ',[n for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)])\n        # print('[n for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)] ',[n for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)])\n        learning_rate *= conf_dict[\"llrd_rate\"]\n        optimizer_parameters += [\n            {\n                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n                'weight_decay_rate': conf_dict[\"weight_decay\"],\n                \"lr\": learning_rate,\n            },\n            {\n                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n                \"lr\": learning_rate,\n            },\n        ]\n    # raise\n    return optimizer_parameters","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.131831Z","iopub.execute_input":"2022-04-22T05:07:57.132102Z","iopub.status.idle":"2022-04-22T05:07:57.143284Z","shell.execute_reply.started":"2022-04-22T05:07:57.132051Z","shell.execute_reply":"2022-04-22T05:07:57.142384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nfrom torch.autograd.function import InplaceFunction\n\nclass Mixout(InplaceFunction):\n    @staticmethod\n    def _make_noise(input):\n        return input.new().resize_as_(input)\n\n    @classmethod\n    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n        if p < 0 or p > 1:\n            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n        if target is not None and input.size() != target.size():\n            raise ValueError(\n                \"A target tensor size must match with a input tensor size {},\"\n                \" but got {}\".format(input.size(), target.size())\n            )\n        ctx.p = p\n        ctx.training = training\n\n        if ctx.p == 0 or not ctx.training:\n            return input\n\n        if target is None:\n            target = cls._make_noise(input)\n            target.fill_(0)\n        target = target.to(input.device)\n\n        if inplace:\n            ctx.mark_dirty(input)\n            output = input\n        else:\n            output = input.clone()\n\n        ctx.noise = cls._make_noise(input)\n        if len(ctx.noise.size()) == 1:\n            ctx.noise.bernoulli_(1 - ctx.p)\n        else:\n            ctx.noise[0].bernoulli_(1 - ctx.p)\n            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n        ctx.noise.expand_as(input)\n\n        if ctx.p == 1:\n            output = target\n        else:\n            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        if ctx.p > 0 and ctx.training:\n            return grad_output * ctx.noise, None, None, None, None\n        else:\n            return grad_output, None, None, None, None\n\n\ndef mixout(input, target=None, p=0.0, training=False, inplace=False):\n    return Mixout.apply(input, target, p, training, inplace)\n\n\nclass MixLinear(torch.nn.Module):\n    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n        super(MixLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = Parameter(torch.Tensor(out_features, in_features))\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_features))\n        else:\n            self.register_parameter(\"bias\", None)\n        self.reset_parameters()\n        self.target = target\n        self.p = p\n\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input):\n        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n\n    def extra_repr(self):\n        type = \"drop\" if self.target is None else \"mix\"\n        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n        )","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.144784Z","iopub.execute_input":"2022-04-22T05:07:57.145091Z","iopub.status.idle":"2022-04-22T05:07:57.167294Z","shell.execute_reply.started":"2022-04-22T05:07:57.145058Z","shell.execute_reply":"2022-04-22T05:07:57.16659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PriorWD(Optimizer):\n    def __init__(self, optim, use_prior_wd=False, exclude_last_group=True):\n        super(PriorWD, self).__init__(optim.param_groups, optim.defaults)\n        self.param_groups = optim.param_groups\n        self.optim = optim\n        self.use_prior_wd = use_prior_wd\n        self.exclude_last_group = exclude_last_group\n        self.weight_decay_by_group = []\n        for i, group in enumerate(self.param_groups):\n            self.weight_decay_by_group.append(group[\"weight_decay\"])\n            group[\"weight_decay\"] = 0\n\n        self.prior_params = {}\n        for i, group in enumerate(self.param_groups):\n            for p in group[\"params\"]:\n                self.prior_params[id(p)] = p.detach().clone()\n\n    def step(self, closure=None):\n        if self.use_prior_wd:\n            for i, group in enumerate(self.param_groups):\n                for p in group[\"params\"]:\n                    if self.exclude_last_group and i == len(self.param_groups):\n                        p.data.add_(-group[\"lr\"] * self.weight_decay_by_group[i], p.data)\n                    else:\n                        p.data.add_(\n                            -group[\"lr\"] * self.weight_decay_by_group[i], p.data - self.prior_params[id(p)],\n                        )\n        loss = self.optim.step(closure)\n\n        return loss\n\n    def compute_distance_to_prior(self, param):\n        assert id(param) in self.prior_params, \"parameter not in PriorWD optimizer\"\n        return (param.data - self.prior_params[id(param)]).pow(2).sum().sqrt()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.168927Z","iopub.execute_input":"2022-04-22T05:07:57.169098Z","iopub.status.idle":"2022-04-22T05:07:57.183343Z","shell.execute_reply.started":"2022-04-22T05:07:57.169077Z","shell.execute_reply":"2022-04-22T05:07:57.182543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_model(model):\n    model.eval()\n    with torch.no_grad():\n        loss_val = 0\n        preds_val = []\n        targets_val = []\n        for i, (excerpts, targets, standard_error) in enumerate(val_loader):\n            batch = tokenizer(list(excerpts), truncation=True, padding=\"max_length\", return_tensors='pt', max_length=conf_dict[\"max_length\"])\n            input_ids = batch['input_ids']\n            input_ids = input_ids.to(device, dtype=torch.long)\n            attention_mask = batch['attention_mask']\n            attention_mask = attention_mask.to(device, dtype=torch.long)\n            targets=targets.to(device, dtype=torch.float)\n            \n            preds = model(input_ids, attention_mask)\n            \n            loss = loss_fn(preds, targets)\n            loss = loss.item()\n            loss_val = loss_val + loss\n            \n            preds = preds.cpu().detach().numpy().tolist()\n            targets = targets.cpu().detach().numpy().tolist()\n            preds_val += preds\n            targets_val += targets\n                \n        loss_val = loss_val / len(val_loader)\n        \n    return loss_val, targets_val, preds_val","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.184794Z","iopub.execute_input":"2022-04-22T05:07:57.185085Z","iopub.status.idle":"2022-04-22T05:07:57.201689Z","shell.execute_reply.started":"2022-04-22T05:07:57.185051Z","shell.execute_reply":"2022-04-22T05:07:57.200986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_directory(directory, overwriting=False):\n    if not os.path.exists(directory):\n        os.mkdir(directory)\n    else:\n        if overwriting:\n            shutil.rmtree(directory)\n            os.mkdir(directory)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.202971Z","iopub.execute_input":"2022-04-22T05:07:57.203383Z","iopub.status.idle":"2022-04-22T05:07:57.211832Z","shell.execute_reply.started":"2022-04-22T05:07:57.203346Z","shell.execute_reply":"2022-04-22T05:07:57.211134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DynamicPadding:\n    def __init__(self, tokenizer, max_length=None, padding=True, pad_to_multiple_of=None, return_tensors=\"pt\"):\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.padding = padding\n        self.pad_to_multiple_of = pad_to_multiple_of\n        self.return_tensors = return_tensors\n    \n    def __call__(self, tokenized):\n        max_length = max(len(_[\"input_ids\"]) for _ in tokenized)\n        max_length = min(max_length, self.max_length) if self.max_length is not None else max_length\n                \n        padded = self.tokenizer.pad(encoded_inputs=tokenized,\n                                    max_length=max_length,\n                                    padding=self.padding, \n                                    pad_to_multiple_of=self.pad_to_multiple_of, \n                                    return_tensors=self.return_tensors)\n        \n        return padded\nclass Collator:\n    def __init__(self, **kwargs):\n        self.dynamic_padding = DynamicPadding(**kwargs)\n    \n    def __call__(self, batch):\n        all_tokenized, all_targets = [], []\n        for tokenized, target in batch:\n            all_tokenized.append(tokenized)\n            all_targets.append(target)\n        \n        tokenized = self.dynamic_padding(all_tokenized)\n        \n        input_ids = torch.tensor(tokenized.input_ids)\n        attention_mask = torch.tensor(tokenized.attention_mask)\n        all_targets = torch.tensor(all_targets)\n        \n        return input_ids, attention_mask, all_targets","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.213424Z","iopub.execute_input":"2022-04-22T05:07:57.213932Z","iopub.status.idle":"2022-04-22T05:07:57.224158Z","shell.execute_reply.started":"2022-04-22T05:07:57.213899Z","shell.execute_reply":"2022-04-22T05:07:57.223384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_loop(train_loader, \n                  model,\n                  optimizer,\n                  scheduler=None,\n                  scheduling_after=\"step\",\n                  epochs=1,\n                  validation_loader=None, \n                  gradient_accumulation_steps=1, \n                  gradient_scaling=False,\n                  gradient_norm=1,\n                  validation_steps=100, \n                  amp=True,\n                  recalculate_metrics_at_end=True, \n                  return_validation_outputs=True,\n                  debug=True, \n                  verbose=1, \n                  device=\"cpu\", \n                  finish_wandb_run=True, \n                  time_format=\"{hours}:{minutes}:{seconds}\"):\n    \n    training_steps = len(train_loader) * epochs\n    scaler = GradScaler() if gradient_scaling else None\n    \n    if wandb_run_exists():\n        wandb.define_metric(\"train/loss vs epoch\", step_metric=\"epoch\")\n    \n    if debug:\n        print(f\"Auto Mixed Precision: {amp}\")\n        print(f\"Gradient norm: {gradient_norm}\")\n        print(f\"Gradient scaling: {gradient_scaling}\")\n        print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n        print(f\"Validation steps: {validation_steps}\")\n        print(f\"Device: {device}\")\n        print()\n        \n    \n    if wandb_run_exists():\n        print(f\"Weights & Biases Run: {wandb.run.get_url()}\", end=\"\\n\"*2)\n        \n    \n    passed_steps = 1\n    train_loss, train_metrics = Averager(), Averager()\n    best_validation_loss, best_validation_metrics, best_validation_outputs = None, None, None\n    \n    model.to(device)\n    model.zero_grad()\n    total_time = timedelta(seconds=0)\n    for epoch in range(1, epochs+1):\n        print(f\"\\nEpoch {epoch}/{epochs}\", end=\"\\n\"*2)\n\n        timer = Timer(time_format)\n        epoch_train_loss, epoch_train_metrics = Averager(), Averager()\n        steps = len(train_loader)\n        for step, batch in enumerate(train_loader, 1):\n            batch_size = len(batch)\n            batch_loss, batch_metrics = training_step(batch=batch, \n                                                      model=model, \n                                                      gradient_accumulation_steps=gradient_accumulation_steps, \n                                                      amp=amp, \n                                                      scaler=scaler, \n                                                      device=device)\n            \n            train_loss.update(batch_loss, n=batch_size)\n            train_metrics.update(batch_metrics, n=batch_size)\n            epoch_train_loss.update(batch_loss, n=batch_size)\n            epoch_train_metrics.update(batch_metrics, n=batch_size)\n            \n            if (passed_steps % gradient_accumulation_steps) == 0:\n                optimization_step(model=model, optimizer=optimizer, gradient_norm=gradient_norm, scaler=scaler)\n                \n\n            lr = get_lr(optimizer, only_last=True)\n            if scheduling_after == \"step\":\n                scheduling_step(scheduler)\n            \n            logs = {\"train/loss\": train_loss.average, \n                    \"train/loss vs batch\": batch_loss, \"lr\": lr}\n            \n            for metric in batch_metrics:\n                metric = metric.strip().lower()\n                logs.update({f\"train/{metric}\": train_metrics.average[metric], \n                             f\"train/{metric} vs batch\": batch_metrics[metric]})\n                \n            if wandb_run_exists():\n                wandb.log(logs, step=passed_steps) \n            \n            if step % verbose == 0 or step == steps:\n                elapsed, remain = timer(step/steps)\n                print(f\"{step}/{steps} - \"\n                      f\"remain: {remain} - \"\n                      f\"loss: {epoch_train_loss.average:.4}\"\n                      f\"{format_metrics(epoch_train_metrics.average)}\")\n            \n            if validation_loader is not None:\n                if (passed_steps % validation_steps) == 0:\n                    print()\n                    validation_loss, validation_metrics, validation_outputs = validation_loop(loader=validation_loader, \n                                                                                              model=model, \n                                                                                              amp=amp, \n                                                                                              return_outputs=True, \n                                                                                              verbose=verbose, \n                                                                                              recalculate_metrics_at_end=True, \n                                                                                              device=device)\n                    \n                    \n                    logs = {\"validation/loss\": validation_loss, \n                            \"train/loss vs validation steps\": train_loss.average}\n    \n                    for metric, value in validation_metrics.items():\n                        metric = metric.strip().lower()\n                        logs.update({f\"validation/{metric}\": value, \n                                     f\"train/{metric} vs validation steps\": train_metrics.average[metric]})\n                    \n                    if wandb_run_exists():\n                        wandb.log(logs, step=passed_steps)\n                    \n                    is_checkpoint_saved = model_checkpointing(loss=validation_loss, \n                                                              metrics=validation_metrics,\n                                                              model=model, \n                                                              optimizer=optimizer, \n                                                              scheduler=scheduler, \n                                                              step=passed_steps)\n                    \n                    if is_checkpoint_saved:\n                        best_validation_loss = validation_loss\n                        best_validation_metrics = validation_metrics\n                        best_validation_outputs = validation_outputs\n                    \n                    scheduling_step(scheduler, loss=validation_loss)\n                    \n                    print()\n            \n            passed_steps += 1\n        \n        if scheduling_after == \"epoch\":\n            scheduling_step(scheduler)\n        \n        logs = {\"train/loss vs epoch\": epoch_train_loss.average, \n                \"epoch\": epoch}\n        \n        \n        for metric, value in train_metrics.average.items():\n            metric = metric.strip().lower()\n            logs.update({f\"train/{metric} vs epoch\": value})\n            \n            if wandb_run_exists():\n                wandb.define_metric(f\"train/{metric} vs epoch\", step_metric=\"epoch\")\n            \n        epoch_elapsed_seconds = timer.elapsed_time.total_seconds()\n        total_time += timedelta(seconds=epoch_elapsed_seconds)\n        \n        if wandb_run_exists():\n            wandb.log(logs, step=passed_steps)\n\n    \n    print(f\"\\nResults\", end=\"\\n\"*2)\n    \n    print(f\"Training loss: {train_loss.average}{format_metrics(train_metrics.average)}\")\n    print(f\"Validation loss: {best_validation_loss}{format_metrics(best_validation_metrics)}\")\n    print(f\"Total time: {Timer.format_time(total_time, time_format=time_format)}\")\n    \n    if wandb_run_exists() and finish_wandb_run:\n        wandb.finish()\n    \n    \n    if return_validation_outputs:\n        return (train_loss.average, train_metrics.average), (best_validation_loss, best_validation_metrics, best_validation_outputs)\n    \n    return (train_loss.average, train_metrics.average), (best_validation_loss, best_validation_metrics)\n    \n\n    \ndef validation_loop(loader, \n                    model, \n                    amp=False, \n                    return_outputs=True, \n                    recalculate_metrics_at_end=True, \n                    verbose=1, \n                    device=\"cpu\", \n                    time_format=\"{hours}:{minutes}:{seconds}\"):\n    \n    model.eval()\n    loss, metrics = Averager(), Averager()\n    timer = Timer(time_format)\n    outputs, targets = [], []\n    num_steps = len(loader)\n    for step, batch in enumerate(loader, 1):\n        with torch.no_grad():\n            with autocast(enabled=amp):\n                batch_loss, batch_outputs = calculate_loss(batch=batch, model=model, return_outputs=True, device=device)\n                loss.update(batch_loss.item(), n=len(batch))\n                \n                batch_targets = get_targets(batch)\n                batch_metrics = calculate_metrics(outputs=batch_outputs, targets=batch_targets, device=device)\n                metrics.update(batch_metrics, n=len(batch))\n                \n                if isinstance(batch_targets, dict):\n                    targets.append(batch_targets)\n                else:\n                    targets.extend(batch_targets.to(\"cpu\").tolist())\n                \n                outputs.extend(batch_outputs.to(\"cpu\").tolist())\n                \n                if step % verbose == 0 or step == num_steps:\n                    elapsed, remain = timer(step/num_steps)\n                    \n                    if step == num_steps and recalculate_metrics_at_end:\n                        outputs = torch.tensor(outputs)\n                        targets = torch.tensor(targets)\n                        \n                        metrics = Averager(calculate_metrics(outputs=outputs, targets=targets))\n                    \n                    print(f\"[Validation] \"\n                          f\"{step}/{num_steps} - \"\n                          f\"remain: {remain} - \"\n                          f\"loss: {loss.average:.4}\"\n                          f\"{format_metrics(metrics.average)}\")\n                    \n    if not recalculate_metrics_at_end: \n        outputs = torch.tensor(outputs)\n        \n    return (loss.average, metrics.average, outputs) if return_outputs else (loss.average, metrics.average)\n\n\ndef format_metrics(metrics, sep=\" - \", add_sep_to_start=True):\n    if metrics != {}:\n        string = sep.join([f\"{k.strip().lower()}: {v:.4}\" for k, v in metrics.items()])\n        return sep + string if add_sep_to_start else string \n    else:\n        return \"\"\n\n    \ndef training_step(batch, model, amp=False, gradient_accumulation_steps=1, scaler=None, device=\"cpu\"):\n    model.train()\n    with autocast(enabled=amp):\n        loss, outputs = calculate_loss(batch=batch, model=model, return_outputs=True, device=device)\n        targets = get_targets(batch)\n        metrics = calculate_metrics(outputs=outputs, targets=targets, device=device)\n        \n        if gradient_accumulation_steps > 1:\n            loss /= gradient_accumulation_steps\n        \n        if scaler is not None:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        \n    return loss.detach(), metrics\n\n\ndef optimization_step(model, optimizer, gradient_norm=0, scaler=None):\n    if gradient_norm > 0:\n        if scaler is not None:\n            scaler.unscale_(optimizer)\n                            \n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_norm)\n                        \n    if scaler is not None:\n        scaler.step(optimizer)\n        scaler.update()\n    else:\n        optimizer.step()\n        \n    model.zero_grad()\n        \n\ndef scheduling_step(scheduler=None, loss=None):\n    if scheduler is not None:\n        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n            scheduler.step(loss)\n        else:\n            scheduler.step()\ndef calculate_loss(batch, model, return_outputs=True, device=\"cpu\"):\n    input_ids, attention_mask, targets = batch\n    \n    input_ids = input_ids.to(device).long()\n    attention_mask = attention_mask.to(device).long()\n    targets = targets.to(device).float()\n    \n    outputs = model(input_ids, attention_mask)\n    outputs = outputs.squeeze(dim=-1)\n    loss = F.mse_loss(outputs, targets, reduction=\"mean\")\n        \n    return (loss, outputs) if return_outputs else loss\n\n\ndef calculate_metrics(targets, outputs, device=\"cpu\"):\n    outputs = outputs.detach().view(-1).to(\"cpu\").float().numpy()\n    targets = targets.view(-1).to(\"cpu\").float().numpy()\n    \n    return dict(pearson=scipy.stats.pearsonr(outputs, targets)[0])\n\n\ndef get_targets(batch):\n    *_, targets = batch\n    return targets\n\n\ndef model_checkpointing(loss, metrics, model, optimizer=None, scheduler=None, step=None):\n    is_saved_checkpoint = model_checkpoint(value=loss, \n                                           model=model, \n                                           optimizer=optimizer, \n                                           scheduler=scheduler, \n                                           step=step)\n    return is_saved_checkpoint\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.225619Z","iopub.execute_input":"2022-04-22T05:07:57.225954Z","iopub.status.idle":"2022-04-22T05:07:57.275707Z","shell.execute_reply.started":"2022-04-22T05:07:57.22592Z","shell.execute_reply":"2022-04-22T05:07:57.274955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_scores = []\noof_data_frame = pd.DataFrame()\nwith open(RESULT_TEXT_PATH, mode='a') as f:\n\n    for seed in conf_dict[\"seed\"]:\n        print('seed:',seed)\n    \n        for fold in range(conf_dict[\"split_num\"]):\n            print('fold:',fold)\n            \n            #set model init seed\n            set_seed(0)\n            fold_directory = os.path.join(conf_dict['output_directory'], f\"seed_{seed}_fold_{fold}\")    \n            make_directory(fold_directory)\n            model_path = os.path.join(fold_directory, \"model.pth\")\n            model_config_path = os.path.join(fold_directory, \"model_config.json\")\n            checkpoints_directory = os.path.join(fold_directory, \"checkpoints/\")\n            \n            print(conf_dict[\"model_name\"])\n            tokenizer = AutoTokenizer.from_pretrained(conf_dict[\"model_name\"])\n\n            if conf_dict[\"use_USPPM_pretrained\"]:\n                model_config = AutoConfig.from_pretrained(f'../input/roberta-base/config.json')\n            else:\n                model_config = AutoConfig.from_pretrained(conf_dict[\"model_name\"])\n\n            model_config.update({'hidden_dropout_prob':conf_dict[\"hidden_dropout\"]})\n            model_config.update({'attention_probs_dropout_prob':conf_dict[\"attention_dropout\"]})\n    #         model_config.update({'output_hidden_states':True}) \n            split_validation_df = train_df[train_df.fold==fold].reset_index(drop=True)\n            split_train_df = train_df[train_df.fold!=fold].reset_index(drop=True)\n            collator = Collator(tokenizer=tokenizer, max_length=conf_dict['max_length'])\n            train_dataset = Dataset(texts=split_train_df[\"input\"].values, \n                            pair_texts=split_train_df[\"target\"].values, \n                            targets=split_train_df[\"score\"].values, \n                            max_length=conf_dict['max_length'],\n                            tokenizer=tokenizer)\n    \n            train_loader = DataLoader(dataset=train_dataset, \n                              batch_size=conf_dict['batch_size'], \n                              num_workers=conf_dict['num_workers'],\n                              pin_memory=conf_dict['pin_memory'],\n                              collate_fn=collator,\n                              shuffle=True, \n                              drop_last=False)\n    \n            print(f\"Train samples: {len(train_dataset)}\")\n    \n            validation_dataset = Dataset(texts=split_validation_df[\"input\"].values, \n                                 pair_texts=split_validation_df[\"target\"].values, \n                                 targets=split_validation_df[\"score\"].values,\n                                 max_length=conf_dict['max_length'],\n                                 tokenizer=tokenizer)\n    \n            validation_loader = DataLoader(dataset=validation_dataset, \n                                   batch_size=conf_dict['batch_size']*2, \n                                   num_workers=conf_dict['num_workers'],\n                                   pin_memory=conf_dict['pin_memory'],\n                                   collate_fn=collator,\n                                   shuffle=True, \n                                   drop_last=False)\n            print(f\"Validation samples: {len(validation_dataset)}\")\n\n            model = USPPM_Model(model_config)\n            \n            if conf_dict[\"use_mixout\"]:\n                for sup_module in model.modules():\n                    for name, module in sup_module.named_children():\n                        if isinstance(module, nn.Dropout):\n                            module.p = 0.0\n                        if isinstance(module, nn.Linear):\n                            target_state_dict = module.state_dict()\n                            bias = True if module.bias is not None else False\n                            new_module = MixLinear(\n                                module.in_features, module.out_features, bias, target_state_dict[\"weight\"], conf_dict[\"mixout_prob\"]\n                            )\n                            new_module.load_state_dict(target_state_dict)\n                            setattr(sup_module, name, new_module)\n            if not os.path.exists(model_config_path): \n                model.config.to_json_file(model_config_path)\n    \n            model_parameters = model.parameters()\n    \n            training_steps = len(train_loader) * conf_dict['epochs']\n    \n            \n\n\n            if conf_dict[\"freeze_embed\"]:\n                model.bert.embeddings.requires_grad_(False)\n\n            if conf_dict[\"use_llrd\"]:\n                optimizer_grouped_parameters = get_optimizer_params(model)\n                optimizer = AdamW(optimizer_grouped_parameters, lr=conf_dict[\"learning_rate\"], weight_decay=conf_dict[\"weight_decay\"])\n            else:\n                optimizer = AdamW(model.parameters(), lr=conf_dict[\"learning_rate\"], weight_decay=conf_dict[\"weight_decay\"])\n\n            if conf_dict[\"use_prior_wd\"]:\n                print('PRIOR_WD')\n                optimizer = PriorWD(optimizer, use_prior_wd=True)\n                \n            if conf_dict[\"reinit_layers\"] > 0:\n                print(f'Reinitializing Last {conf_dict[\"reinit_layers\"]} Layers ...')\n                encoder_temp = getattr(model, \"bert\")\n#                 print(\"encoder_temp \",encoder_temp)\n                for layer in encoder_temp.encoder.layer[-conf_dict[\"reinit_layers\"]:]:\n                    for module in layer.modules():\n                        if isinstance(module, nn.Linear):\n                            module.weight.data.normal_(mean=0.0, std=model_config.initializer_range)\n                            if module.bias is not None:\n                                module.bias.data.zero_()\n                        elif isinstance(module, nn.Embedding):\n                            module.weight.data.normal_(mean=0.0, std=model_config.initializer_range)\n                            if module.padding_idx is not None:\n                                module.weight.data[module.padding_idx].zero_()\n                        elif isinstance(module, nn.LayerNorm):\n                            module.bias.data.zero_()\n                            module.weight.data.fill_(1.0)\n\n            if \"scheduler\" in list(conf_dict.keys()):\n                conf_dict['scheduler']['parameters']['num_training_steps'] = training_steps\n                conf_dict['scheduler']['parameters']['num_warmup_steps'] = training_steps * 0.6\n                scheduler = get_scheduler(**conf_dict['scheduler'], optimizer=optimizer, from_transformers=True)\n            else:\n                scheduler = None\n        \n            model_checkpoint = ModelCheckpoint(mode=\"min\", \n                                       delta=conf_dict['delta'], \n                                       directory=checkpoints_directory, \n                                       overwriting=True, \n                                       filename_format=\"checkpoint.pth\", \n                                       num_candidates=1)\n            model.to(device)\n            best_rms = 999\n            best_preds = None\n            \n            #set train order seed\n            set_seed(seed)\n            (train_loss, train_metrics), (validation_loss, validation_metrics, validation_outputs) = training_loop(model=model, \n                                                                                                           optimizer=optimizer, \n                                                                                                           scheduler=scheduler,\n                                                                                                           scheduling_after=conf_dict['scheduling_after'],\n                                                                                                           train_loader=train_loader,\n                                                                                                           validation_loader=validation_loader,\n                                                                                                           epochs=conf_dict['epochs'], \n                                                                                                           #epochs=2,          \n                                                                                                           gradient_accumulation_steps=conf_dict['gradient_accumulation_steps'], \n                                                                                                           gradient_scaling=conf_dict['gradient_scaling'], \n                                                                                                           gradient_norm=conf_dict['gradient_norm'], \n                                                                                                           validation_steps=conf_dict['validation_steps'], \n                                                                                                           amp=conf_dict['amp'],\n                                                                                                           debug=conf_dict['debug'], \n                                                                                                           verbose=conf_dict['verbose'], \n                                                                                                           device=conf_dict['device'], \n                                                                                                           recalculate_metrics_at_end=True, \n                                                                                                           return_validation_outputs=True, \n                                                                                                           finish_wandb_run=True)\n    \n            if conf_dict['save_model']:\n                model_state = model.state_dict()\n                torch.save(model_state, model_path)\n                print(f\"Model's path: {model_path}\")\n            validation_fold = train_df[train_df[\"fold\"].isin([fold])]\n            validation_fold[\"predictions\"] = validation_outputs.to(\"cpu\").numpy()\n            oof_data_frame = pd.concat([oof_data_frame, validation_fold])\n    \n            cv_monitor_value = validation_loss if conf_dict['cv_monitor_value'] == \"loss\" else validation_metrics[conf_dict['cv_monitor_value']]\n            cv_scores.append(cv_monitor_value)\n    \n            del model, optimizer, validation_outputs\n            torch.cuda.empty_cache()\n            gc.collect()\n    \n            print(end=\"\\n\"*6)\n        \n    \n            \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:07:57.277147Z","iopub.execute_input":"2022-04-22T05:07:57.27757Z","iopub.status.idle":"2022-04-22T05:09:59.403465Z","shell.execute_reply.started":"2022-04-22T05:07:57.277535Z","shell.execute_reply":"2022-04-22T05:09:59.402263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}