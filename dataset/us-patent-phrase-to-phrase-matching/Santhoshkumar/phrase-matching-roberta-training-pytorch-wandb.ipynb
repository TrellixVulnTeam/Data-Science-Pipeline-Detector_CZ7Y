{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport time\nimport random\nfrom scipy import stats\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-25T02:46:30.674316Z","iopub.execute_input":"2022-03-25T02:46:30.674669Z","iopub.status.idle":"2022-03-25T02:46:37.649463Z","shell.execute_reply.started":"2022-03-25T02:46:30.674581Z","shell.execute_reply":"2022-03-25T02:46:37.648722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:46:39.985262Z","iopub.execute_input":"2022-03-25T02:46:39.986176Z","iopub.status.idle":"2022-03-25T02:46:39.99456Z","shell.execute_reply.started":"2022-03-25T02:46:39.986136Z","shell.execute_reply":"2022-03-25T02:46:39.993828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers: Optional[int] = 4\n    model_name: Optional[str] = 'roberta-large'\n    epochs: Optional[int] = 5\n    T_max: Optional[int] = 10 \n    T_0: Optional[int] = 10 \n    lr: Optional[float]= 2e-5\n    min_lr: Optional[float] = 1e-6\n    batch_size: Optional[int] = 32\n    weight_decay: Optional[float] = 1e-6\n    gradient_accumulation_steps: Optional[int] = 1\n    max_grad_norm: Optional[int] = 1000\n    max_len: Optional[int] = 128\n    seed: Optional[int] = 2019\n    target_size: Optional[int] = 1\n    num_targets: Optional[int] = 1\n    n_folds: Optional[int] = 5\n    fp16: Optional[bool] = True\n    wandb: Optional[bool] = True\n    _wandb_kernel: Optional[str] = 'santos'\n    competition: Optional[str] = 'PPPM'\n    tokenizer = AutoTokenizer.from_pretrained('roberta-large')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:48:32.854104Z","iopub.execute_input":"2022-03-25T02:48:32.854458Z","iopub.status.idle":"2022-03-25T02:48:38.946172Z","shell.execute_reply.started":"2022-03-25T02:48:32.854424Z","shell.execute_reply":"2022-03-25T02:48:38.945411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# wandb\n# ====================================================\nif CFG.wandb:\n    \n    import wandb\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n        wandb.login(key=secret_value_0)\n        anony = None\n    except:\n        anony = \"must\"\n        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n\n\n    def class2dict(f):\n        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\n    run = wandb.init(project='PPPM-Public', \n                     name=CFG.model_name,\n                     config=class2dict(CFG),\n                     group=CFG.model_name,\n                     job_type=\"train\",\n                     anonymous=anony)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:48:42.012517Z","iopub.execute_input":"2022-03-25T02:48:42.0128Z","iopub.status.idle":"2022-03-25T02:48:50.409283Z","shell.execute_reply.started":"2022-03-25T02:48:42.012754Z","shell.execute_reply":"2022-03-25T02:48:50.408522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/us-patent-phrase-to-phrase-matching'\ntrain = pd.read_csv(os.path.join(PATH, 'train.csv'))\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:48:53.7456Z","iopub.execute_input":"2022-03-25T02:48:53.745887Z","iopub.status.idle":"2022-03-25T02:48:53.838009Z","shell.execute_reply.started":"2022-03-25T02:48:53.745855Z","shell.execute_reply":"2022-03-25T02:48:53.837268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T04:48:52.649659Z","iopub.execute_input":"2022-03-24T04:48:52.650192Z","iopub.status.idle":"2022-03-24T04:48:52.660799Z","shell.execute_reply.started":"2022-03-24T04:48:52.650138Z","shell.execute_reply":"2022-03-24T04:48:52.659788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T04:48:55.357693Z","iopub.execute_input":"2022-03-24T04:48:55.358291Z","iopub.status.idle":"2022-03-24T04:48:55.369111Z","shell.execute_reply.started":"2022-03-24T04:48:55.358254Z","shell.execute_reply":"2022-03-24T04:48:55.368241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape, sub.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-24T04:48:58.797066Z","iopub.execute_input":"2022-03-24T04:48:58.797493Z","iopub.status.idle":"2022-03-24T04:48:58.803589Z","shell.execute_reply.started":"2022-03-24T04:48:58.797442Z","shell.execute_reply":"2022-03-24T04:48:58.802825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    data[\"fold\"] = -1\n    data = data.sample(frac=1).reset_index(drop=True)\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n        \n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"score\"], bins=num_bins, labels=False\n    )\n    \n    kf = model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'fold'] = f\n    \n    data = data.drop(\"bins\", axis=1)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:48:57.212774Z","iopub.execute_input":"2022-03-25T02:48:57.213272Z","iopub.status.idle":"2022-03-25T02:48:57.226102Z","shell.execute_reply.started":"2022-03-25T02:48:57.213233Z","shell.execute_reply":"2022-03-25T02:48:57.225339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n   \ncontext_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n    \ntrain.context = train.context.apply(lambda x: context_mapping[x[0]])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:49:21.445038Z","iopub.execute_input":"2022-03-25T02:49:21.445291Z","iopub.status.idle":"2022-03-25T02:49:21.472912Z","shell.execute_reply.started":"2022-03-25T02:49:21.445261Z","shell.execute_reply":"2022-03-25T02:49:21.472191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = create_folds(train, num_splits=CFG.n_folds)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:49:43.79363Z","iopub.execute_input":"2022-03-25T02:49:43.794324Z","iopub.status.idle":"2022-03-25T02:49:43.837549Z","shell.execute_reply.started":"2022-03-25T02:49:43.794286Z","shell.execute_reply":"2022-03-25T02:49:43.836808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:49:46.624231Z","iopub.execute_input":"2022-03-25T02:49:46.624479Z","iopub.status.idle":"2022-03-25T02:49:46.64546Z","shell.execute_reply.started":"2022-03-25T02:49:46.624452Z","shell.execute_reply":"2022-03-25T02:49:46.644798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, score, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.score = score\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n        score = self.score[item]\n\n        encoded_text = CFG.tokenizer.encode_plus(\n            context + \" \" + anchor,\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"score\": torch.tensor(score, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-25T02:50:02.673297Z","iopub.execute_input":"2022-03-25T02:50:02.673558Z","iopub.status.idle":"2022-03-25T02:50:02.686508Z","shell.execute_reply.started":"2022-03-25T02:50:02.673528Z","shell.execute_reply":"2022-03-25T02:50:02.685825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(model, train_dataloader, optimizer, scheduler, loss_fn=None, fp16=False):\n    model.train()\n    \n    scaler =  torch.cuda.amp.GradScaler()\n    \n    train_loss = 0\n    \n    for step, data in enumerate(train_dataloader):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['score'].to(device, dtype = torch.float)\n        \n        with torch.cuda.amp.autocast(enabled=True):\n            output = model(ids, mask)\n            loss = loss_fn(output.squeeze(), targets.squeeze())\n            \n        train_loss +=loss.item()\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n\n        if CFG.fp16:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        \n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            if CFG.fp16:\n                scaler.step(optimizer)\n                scaler.update()\n                scheduler.step()\n            else:\n                optimizer.step()\n                scheduler.step()\n\n            optimizer.zero_grad()\n        \n    return train_loss/len(train_dataloader)\n\n\ndef valid_fn(model, valid_dataloader, loss_fn=None):\n    \n    model.eval()\n    predictions = []\n    valid_loss = 0\n    \n    for data in valid_dataloader:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['score'].to(device, dtype = torch.float)\n        \n        with torch.no_grad():\n            output = model(ids, mask)\n            loss = loss_fn(output.squeeze(), targets.squeeze())\n        valid_loss +=loss.item()\n        predictions.append(output.sigmoid().detach().cpu().numpy().ravel())\n        \n    return valid_loss/len(valid_dataloader), np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:14:07.005764Z","iopub.execute_input":"2022-03-24T10:14:07.006069Z","iopub.status.idle":"2022-03-24T10:14:07.026466Z","shell.execute_reply.started":"2022-03-24T10:14:07.006036Z","shell.execute_reply":"2022-03-24T10:14:07.025516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatentModel(torch.nn.Module):\n    def __init__(self):\n        super(PatentModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.model_name)\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        \n        self.transformer = AutoModel.from_pretrained(CFG.model_name, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, ids, mask):\n        transformer_out = self.transformer(input_ids=ids, attention_mask=mask)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        logits = self.output(last_hidden_states)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:14:14.7274Z","iopub.execute_input":"2022-03-24T10:14:14.727702Z","iopub.status.idle":"2022-03-24T10:14:14.743674Z","shell.execute_reply.started":"2022-03-24T10:14:14.727669Z","shell.execute_reply":"2022-03-24T10:14:14.742482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(df, fold=0, seed=42):    \n\n    best_score = 0\n    \n    seed_everything(seed)\n    \n    df_train=df.loc[df.fold!=fold].reset_index(drop=True)\n    df_valid=df.loc[df.fold==fold].reset_index(drop=True)\n    \n    valid_targets = df_valid['score'].values\n\n    train_dataset = PhraseDataset(\n        df_train.anchor.values,\n        df_train.target.values,\n        df_train.context.values,\n        df_train.score.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    valid_dataset = PhraseDataset(\n        df_valid.anchor.values,\n        df_valid.target.values,\n        df_valid.context.values,\n        df_valid.score.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    \n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    model = PatentModel()\n    model.to(device)\n    \n    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\"]\n    \n    optimizer_parameters = [\n            {\n                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.01,\n            },\n            {\n                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n    \n    optimizer = AdamW(optimizer_parameters, lr=CFG.lr, weight_decay=CFG.weight_decay)\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1\n    )\n        \n    for epoch in range(CFG.epochs): \n        start_time = time.time()\n        \n        train_loss = train_fn(model, train_loader, optimizer, scheduler, loss_fn=criterion, fp16=CFG.fp16)\n        valid_loss, valid_preds = valid_fn(model, valid_loader, loss_fn=criterion)\n        score = stats.pearsonr(valid_targets, valid_preds)[0]\n        elapsed = time.time() - start_time\n        \n        print(f'Epoch {epoch+1} - avg_train_loss: {train_loss:.4f}  avg_val_loss: {valid_loss:.4f}')\n        print(f'Epoch {epoch+1} - pearson score: {score:.4f} time: {elapsed:.0f}s')\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                       f\"[fold{fold}] avg_train_loss\": train_loss, \n                       f\"[fold{fold}] avg_val_loss\": valid_loss,\n                       f\"[fold{fold}] score\": score})\n        if best_score < score:\n            print(f'Validation Score Improved {best_score} ---> :{score} Save Model!!!')\n            best_score = score\n            torch.save(model.state_dict(), f'{CFG.model_name.replace(\"-\", \"_\")}_patent_model_{fold}.pth')\n            \n    oof_preds = np.concatenate((valid_preds.reshape(-1, 1), valid_targets.reshape(-1, 1)), axis=1) \n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return oof_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:14:18.28717Z","iopub.execute_input":"2022-03-24T10:14:18.287619Z","iopub.status.idle":"2022-03-24T10:14:18.568193Z","shell.execute_reply.started":"2022-03-24T10:14:18.287567Z","shell.execute_reply":"2022-03-24T10:14:18.566579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train, seed):\n    \n    predictions = []\n    \n    for f in range(CFG.n_folds):    \n        preds = run_fold(train, f, seed) \n        predictions.append(preds)\n        \n    oof_preds = np.concatenate(predictions)\n        \n    return oof_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:14:23.038681Z","iopub.execute_input":"2022-03-24T10:14:23.038994Z","iopub.status.idle":"2022-03-24T10:14:23.051307Z","shell.execute_reply.started":"2022-03-24T10:14:23.038961Z","shell.execute_reply":"2022-03-24T10:14:23.04989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    oof_preds =  train_model(df, CFG.seed) \n    np.save('patent_oof.npy', oof_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T10:14:29.39612Z","iopub.execute_input":"2022-03-24T10:14:29.396796Z"},"trusted":true},"execution_count":null,"outputs":[]}]}