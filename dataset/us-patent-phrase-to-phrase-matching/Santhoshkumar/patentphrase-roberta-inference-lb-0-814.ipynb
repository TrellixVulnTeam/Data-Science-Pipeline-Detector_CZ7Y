{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport time\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-25T15:54:13.324225Z","iopub.execute_input":"2022-03-25T15:54:13.324795Z","iopub.status.idle":"2022-03-25T15:54:20.374521Z","shell.execute_reply.started":"2022-03-25T15:54:13.324699Z","shell.execute_reply":"2022-03-25T15:54:20.373776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:30.524209Z","iopub.execute_input":"2022-03-25T15:54:30.524716Z","iopub.status.idle":"2022-03-25T15:54:30.533681Z","shell.execute_reply.started":"2022-03-25T15:54:30.524676Z","shell.execute_reply":"2022-03-25T15:54:30.532907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers: Optional[int] = 4\n    config_path: Optional[str] = '../input/robertalarge'\n    model_path: Optional[str] = '../input/phrase-matching-roberta-training-pytorch-wandb'\n    model_name: Optional[str] = 'roberta-large'\n    batch_size: Optional[int] = 32\n    max_len: Optional[int] = 128\n    seed: Optional[int] = 2019\n    num_targets: Optional[int] = 1\n    n_folds: Optional[int] = 5\n    tokenizer = AutoTokenizer.from_pretrained('../input/robertalarge')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:34.36015Z","iopub.execute_input":"2022-03-25T15:54:34.360731Z","iopub.status.idle":"2022-03-25T15:54:34.590199Z","shell.execute_reply.started":"2022-03-25T15:54:34.360679Z","shell.execute_reply":"2022-03-25T15:54:34.58944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/us-patent-phrase-to-phrase-matching'\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:37.363998Z","iopub.execute_input":"2022-03-25T15:54:37.364247Z","iopub.status.idle":"2022-03-25T15:54:37.38343Z","shell.execute_reply.started":"2022-03-25T15:54:37.364218Z","shell.execute_reply":"2022-03-25T15:54:37.38276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n    \ntest.context = test.context.apply(lambda x: context_mapping[x[0]])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:39.816843Z","iopub.execute_input":"2022-03-25T15:54:39.817098Z","iopub.status.idle":"2022-03-25T15:54:39.828863Z","shell.execute_reply.started":"2022-03-25T15:54:39.817068Z","shell.execute_reply":"2022-03-25T15:54:39.827942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n\n        encoded_text = CFG.tokenizer.encode_plus(\n            context + \" \" + anchor,\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:43.480787Z","iopub.execute_input":"2022-03-25T15:54:43.481049Z","iopub.status.idle":"2022-03-25T15:54:43.488694Z","shell.execute_reply.started":"2022-03-25T15:54:43.481019Z","shell.execute_reply":"2022-03-25T15:54:43.487963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_fn(model, test_loader):  \n    model.eval()\n    predictions = []\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for data in tk0:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        with torch.no_grad():\n            output = model(ids, mask)\n        predictions.append(output.sigmoid().detach().cpu().numpy())\n        \n    return np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:45.920114Z","iopub.execute_input":"2022-03-25T15:54:45.920795Z","iopub.status.idle":"2022-03-25T15:54:45.930025Z","shell.execute_reply.started":"2022-03-25T15:54:45.92075Z","shell.execute_reply":"2022-03-25T15:54:45.929265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatentModel(torch.nn.Module):\n    def __init__(self):\n        super(PatentModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.config_path)\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        \n        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, ids, mask):\n        transformer_out = self.transformer(input_ids=ids, attention_mask=mask)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:48.604255Z","iopub.execute_input":"2022-03-25T15:54:48.604964Z","iopub.status.idle":"2022-03-25T15:54:48.615149Z","shell.execute_reply.started":"2022-03-25T15:54:48.604927Z","shell.execute_reply":"2022-03-25T15:54:48.614145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(test, fold, seed=42):    \n    \n    seed_everything(seed)\n    \n    test_dataset = PhraseDataset(\n        test.anchor.values,\n        test.target.values,\n        test.context.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    test_loader = DataLoader(test_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    model = PatentModel()\n    \n    model.load_state_dict(\n        torch.load(f'{CFG.model_path}/{CFG.model_name.replace(\"-\",\"_\")}_patent_model_{fold}.pth',\n        map_location=torch.device('cuda')\n        )\n    )\n    \n    model.to(device)\n\n    preds = inference_fn(model, test_loader)\n    \n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:54:51.921161Z","iopub.execute_input":"2022-03-25T15:54:51.921447Z","iopub.status.idle":"2022-03-25T15:54:51.929459Z","shell.execute_reply.started":"2022-03-25T15:54:51.921415Z","shell.execute_reply":"2022-03-25T15:54:51.928728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_model(test, seed):\n    \n    predictions = []\n    \n    for f in range(CFG.n_folds):    \n        preds = run_fold(test, f, seed) \n        predictions.append(preds)\n        \n    test_preds = np.column_stack(predictions)\n        \n    return test_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-25T16:05:12.037798Z","iopub.execute_input":"2022-03-25T16:05:12.038371Z","iopub.status.idle":"2022-03-25T16:05:12.042991Z","shell.execute_reply.started":"2022-03-25T16:05:12.038334Z","shell.execute_reply":"2022-03-25T16:05:12.042322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    final_predictions =  inference_model(test, CFG.seed) ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T16:05:22.544687Z","iopub.execute_input":"2022-03-25T16:05:22.544939Z","iopub.status.idle":"2022-03-25T16:06:07.984021Z","shell.execute_reply.started":"2022-03-25T16:05:22.544912Z","shell.execute_reply":"2022-03-25T16:06:07.983228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['score'] = np.mean(final_predictions, axis=1)\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T16:06:23.844911Z","iopub.execute_input":"2022-03-25T16:06:23.845173Z","iopub.status.idle":"2022-03-25T16:06:23.851954Z","shell.execute_reply.started":"2022-03-25T16:06:23.845143Z","shell.execute_reply":"2022-03-25T16:06:23.851288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T16:06:26.71611Z","iopub.execute_input":"2022-03-25T16:06:26.716671Z","iopub.status.idle":"2022-03-25T16:06:26.725545Z","shell.execute_reply.started":"2022-03-25T16:06:26.716631Z","shell.execute_reply":"2022-03-25T16:06:26.724849Z"},"trusted":true},"execution_count":null,"outputs":[]}]}