{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Directory settings","metadata":{"papermill":{"duration":0.024515,"end_time":"2022-03-22T09:40:01.460332","exception":false,"start_time":"2022-03-22T09:40:01.435817","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"id":"fa3b873b","papermill":{"duration":0.041313,"end_time":"2022-03-22T09:40:01.526545","exception":false,"start_time":"2022-03-22T09:40:01.485232","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:19.7664Z","iopub.execute_input":"2022-06-19T10:14:19.766934Z","iopub.status.idle":"2022-06-19T10:14:19.793434Z","shell.execute_reply.started":"2022-06-19T10:14:19.766841Z","shell.execute_reply":"2022-06-19T10:14:19.792671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"id":"1d0c4430","papermill":{"duration":0.024609,"end_time":"2022-03-22T09:40:01.576366","exception":false,"start_time":"2022-03-22T09:40:01.551757","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/wkpooling-all-fold/results/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-small\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1,2,3]","metadata":{"id":"48dd82bb","papermill":{"duration":0.033949,"end_time":"2022-03-22T09:40:01.634977","exception":false,"start_time":"2022-03-22T09:40:01.601028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:21.360439Z","iopub.execute_input":"2022-06-19T10:14:21.361048Z","iopub.status.idle":"2022-06-19T10:14:21.374527Z","shell.execute_reply.started":"2022-06-19T10:14:21.361008Z","shell.execute_reply":"2022-06-19T10:14:21.373836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"id":"f2ed8ef2","papermill":{"duration":0.038261,"end_time":"2022-03-22T09:40:10.626926","exception":false,"start_time":"2022-03-22T09:40:10.588665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"executionInfo":{"elapsed":20123,"status":"ok","timestamp":1644920080956,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"35916341","outputId":"06fa0ab8-a380-4f54-a98d-b7015b79d9e2","papermill":{"duration":26.143536,"end_time":"2022-03-22T09:40:36.798853","exception":false,"start_time":"2022-03-22T09:40:10.655317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:22.147671Z","iopub.execute_input":"2022-06-19T10:14:22.147923Z","iopub.status.idle":"2022-06-19T10:14:49.596747Z","shell.execute_reply.started":"2022-06-19T10:14:22.147894Z","shell.execute_reply":"2022-06-19T10:14:49.595928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"fd586614","papermill":{"duration":0.032888,"end_time":"2022-03-22T09:40:36.865209","exception":false,"start_time":"2022-03-22T09:40:36.832321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n#     print(y_true.shape)\n#     print(y_true.dtype)\n#     print(y_pred.shape)\n#     print(y_pred.dtype)\n    score = sp.stats.pearsonr(y_true, np.squeeze(y_pred).astype(y_true.dtype))[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"id":"d5c0ccc6","papermill":{"duration":0.21551,"end_time":"2022-03-22T09:40:37.116848","exception":false,"start_time":"2022-03-22T09:40:36.901338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:49.598569Z","iopub.execute_input":"2022-06-19T10:14:49.598815Z","iopub.status.idle":"2022-06-19T10:14:49.612352Z","shell.execute_reply.started":"2022-06-19T10:14:49.59878Z","shell.execute_reply":"2022-06-19T10:14:49.61163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"code","source":"oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\nlabels = oof_df['score'].values\npreds = oof_df['pred'].values\nscore = get_score(labels, preds)\nLOGGER.info(f'CV Score: {score:<.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:14:49.614029Z","iopub.execute_input":"2022-06-19T10:14:49.614578Z","iopub.status.idle":"2022-06-19T10:14:49.678178Z","shell.execute_reply.started":"2022-06-19T10:14:49.614544Z","shell.execute_reply":"2022-06-19T10:14:49.677427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{"id":"cb3d8e1e","papermill":{"duration":0.032614,"end_time":"2022-03-22T09:40:37.184739","exception":false,"start_time":"2022-03-22T09:40:37.152125","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"executionInfo":{"elapsed":2627,"status":"ok","timestamp":1644920084001,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"bef012d3","outputId":"d4d60dbc-510c-4f34-8d64-dd1d88c4808c","papermill":{"duration":0.154829,"end_time":"2022-03-22T09:40:37.374453","exception":false,"start_time":"2022-03-22T09:40:37.219624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:49.68344Z","iopub.execute_input":"2022-06-19T10:14:49.685669Z","iopub.status.idle":"2022-06-19T10:14:49.732788Z","shell.execute_reply.started":"2022-06-19T10:14:49.685624Z","shell.execute_reply":"2022-06-19T10:14:49.731183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{"papermill":{"duration":0.848818,"end_time":"2022-03-22T09:40:38.260255","exception":false,"start_time":"2022-03-22T09:40:37.411437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:49.733921Z","iopub.execute_input":"2022-06-19T10:14:49.734348Z","iopub.status.idle":"2022-06-19T10:14:49.75853Z","shell.execute_reply.started":"2022-06-19T10:14:49.734314Z","shell.execute_reply":"2022-06-19T10:14:49.757818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{"papermill":{"duration":0.084831,"end_time":"2022-03-22T09:40:38.384239","exception":false,"start_time":"2022-03-22T09:40:38.299408","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:49.762724Z","iopub.execute_input":"2022-06-19T10:14:49.764866Z","iopub.status.idle":"2022-06-19T10:14:49.787396Z","shell.execute_reply.started":"2022-06-19T10:14:49.764824Z","shell.execute_reply":"2022-06-19T10:14:49.786693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tokenizer","metadata":{"id":"918a28aa","papermill":{"duration":0.039494,"end_time":"2022-03-22T09:40:39.374931","exception":false,"start_time":"2022-03-22T09:40:39.335437","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model)","metadata":{"papermill":{"duration":5.198604,"end_time":"2022-03-22T09:40:44.612849","exception":false,"start_time":"2022-03-22T09:40:39.414245","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:49.791426Z","iopub.execute_input":"2022-06-19T10:14:49.793519Z","iopub.status.idle":"2022-06-19T10:14:50.534669Z","shell.execute_reply.started":"2022-06-19T10:14:49.793467Z","shell.execute_reply":"2022-06-19T10:14:50.533946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"14da40cf","papermill":{"duration":0.04897,"end_time":"2022-03-22T09:40:44.706931","exception":false,"start_time":"2022-03-22T09:40:44.657961","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\n# class TestDataset(Dataset):\n#     def __init__(self, cfg, df):\n#         self.cfg = cfg\n#         self.texts = df['text'].values\n\n#     def __len__(self):\n#         return len(self.texts)\n\n#     def __getitem__(self, item):\n#         inputs = prepare_input(self.cfg, self.texts[item])\n#         return inputs\n    \n    \n\n    \n    \nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n        \n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text= self.texts[item]\n        \n        inputs = self.cfg.tokenizer.encode_plus(\n                    text,\n                    add_special_tokens=True,\n                    padding='max_length',\n                    max_length=self.cfg.max_len,\n                    #return_tensors='pt',\n                    return_attention_mask=True)\n                    #return_token_type_ids=True)\n        \n        \n        input_ids = inputs[\"input_ids\"]\n        attention_mask = inputs[\"attention_mask\"]\n#         token_type_ids = inputs[\"token_type_ids\"]\n\n#         label = torch.tensor(self.labels[item], dtype=torch.float)\n#         return inputs, label\n        input_new= {\n            \"token_id\": torch.tensor(input_ids, dtype=torch.long),\n            \"token_mask\": torch.tensor(attention_mask, dtype=torch.long),\n#             \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long)\n        } \n        \n\n        return input_new","metadata":{"id":"9f791a19","papermill":{"duration":0.055528,"end_time":"2022-03-22T09:40:52.072178","exception":false,"start_time":"2022-03-22T09:40:52.01665","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:50.537101Z","iopub.execute_input":"2022-06-19T10:14:50.537507Z","iopub.status.idle":"2022-06-19T10:14:50.549136Z","shell.execute_reply.started":"2022-06-19T10:14:50.537469Z","shell.execute_reply":"2022-06-19T10:14:50.54829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"e04d6363","papermill":{"duration":0.044161,"end_time":"2022-03-22T09:40:52.262022","exception":false,"start_time":"2022-03-22T09:40:52.217861","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class WKPooling(nn.Module):\n    def __init__(self, layer_start: int = 4, context_window_size: int = 2):\n        super(WKPooling, self).__init__()\n        self.layer_start = layer_start\n        self.context_window_size = context_window_size\n\n    def forward(self, all_hidden_states,batch):\n\n        ft_all_layers = all_hidden_states\n        org_device = ft_all_layers.device\n#         print(ft_all_layers.shape)\n        all_layer_embedding = ft_all_layers.transpose(1,0)\n#         print(all_layer_embedding)\n#         print(all_layer_embedding.shape)\n        all_layer_embedding = all_layer_embedding[:, self.layer_start:, :, :]  # Start from 4th layers output\n#         print(all_layer_embedding)\n        # torch.qr is slow on GPU (see https://github.com/pytorch/pytorch/issues/22573). So compute it on CPU until issue is fixed\n        all_layer_embedding = all_layer_embedding.cpu()\n\n        attention_mask = batch[\"token_mask\"].cpu().numpy()\n        unmask_num = np.array([sum(mask) for mask in attention_mask]) - 1  # Not considering the last item\n        embedding = []\n        # One sentence at a time\n        for sent_index in range(len(unmask_num)):\n#             print(all_layer_embedding)\n            sentence_feature = all_layer_embedding[sent_index, :, :unmask_num[sent_index], :]\n#             print(sentence_feature)\n            one_sentence_embedding = []\n            # Process each token\n            for token_index in range(sentence_feature.shape[1]):\n                token_feature = sentence_feature[:, token_index, :]\n#                 print(token_feature)\n                # 'Unified Word Representation'\n                token_embedding = self.unify_token(token_feature)\n                one_sentence_embedding.append(token_embedding)\n\n            ##features.update({'sentence_embedding': features['cls_token_embeddings']})\n\n            one_sentence_embedding = torch.stack(one_sentence_embedding)\n            sentence_embedding = self.unify_sentence(sentence_feature, one_sentence_embedding)\n            embedding.append(sentence_embedding)\n          \n        output_vector = torch.stack(embedding).to(org_device)\n#         print(output_vector)\n        return output_vector\n\n    def unify_token(self, token_feature):\n        ## Unify Token Representation\n        window_size = self.context_window_size\n\n        alpha_alignment = torch.zeros(token_feature.size()[0], device=token_feature.device)\n        alpha_novelty = torch.zeros(token_feature.size()[0], device=token_feature.device)\n\n        for k in range(token_feature.size()[0]):\n            left_window = token_feature[k - window_size:k, :]\n            right_window = token_feature[k + 1:k + window_size + 1, :]\n            window_matrix = torch.cat([left_window, right_window, token_feature[k, :][None, :]])\n            Q, R = torch.qr(window_matrix.T)\n\n            r = R[:, -1]\n            alpha_alignment[k] = torch.mean(self.norm_vector(R[:-1, :-1], dim=0), dim=1).matmul(R[:-1, -1]) / torch.norm(r[:-1])\n            alpha_alignment[k] = 1 / (alpha_alignment[k] * window_matrix.size()[0] * 2)\n            alpha_novelty[k] = torch.abs(r[-1]) / torch.norm(r)\n\n        # Sum Norm\n        alpha_alignment = alpha_alignment / torch.sum(alpha_alignment)  # Normalization Choice\n        alpha_novelty = alpha_novelty / torch.sum(alpha_novelty)\n\n        alpha = alpha_novelty + alpha_alignment\n        alpha = alpha / torch.sum(alpha)  # Normalize\n\n        out_embedding = torch.mv(token_feature.t(), alpha)\n        return out_embedding\n\n    def norm_vector(self, vec, p=2, dim=0):\n        ## Implements the normalize() function from sklearn\n        vec_norm = torch.norm(vec, p=p, dim=dim)\n        return vec.div(vec_norm.expand_as(vec))\n\n    def unify_sentence(self, sentence_feature, one_sentence_embedding):\n        ## Unify Sentence By Token Importance\n        sent_len = one_sentence_embedding.size()[0]\n\n        var_token = torch.zeros(sent_len, device=one_sentence_embedding.device)\n        for token_index in range(sent_len):\n            token_feature = sentence_feature[:, token_index, :]\n            sim_map = self.cosine_similarity_torch(token_feature)\n            var_token[token_index] = torch.var(sim_map.diagonal(-1))\n\n        var_token = var_token / torch.sum(var_token)\n        sentence_embedding = torch.mv(one_sentence_embedding.t(), var_token)\n\n        return sentence_embedding\n    \n    def cosine_similarity_torch(self, x1, x2=None, eps=1e-8):\n        x2 = x1 if x2 is None else x2\n        w1 = x1.norm(p=2, dim=1, keepdim=True)\n        w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n        return torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:14:50.550577Z","iopub.execute_input":"2022-06-19T10:14:50.550872Z","iopub.status.idle":"2022-06-19T10:14:50.573681Z","shell.execute_reply.started":"2022-06-19T10:14:50.550838Z","shell.execute_reply":"2022-06-19T10:14:50.572798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, \n                                                     output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n            \n        \n        \n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.wkpool=WKPooling(layer_start=4)\n        self._init_weights(self.wkpool)\n        \n#         self.attention = AttentionPool(self.config.hidden_size)\n#         self.attention = nn.Sequential(\n#             nn.Linear(self.config.hidden_size, 512),\n#             nn.Tanh(),\n#             nn.Linear(512, 1),\n#             nn.Softmax(dim=1)\n#         )\n#         self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n#     def feature(self, inputs):\n#         outputs = self.model(**inputs)\n#         last_hidden_states = outputs[0]\n#         # feature = torch.mean(last_hidden_states, 1)\n#         weights = self.attention(last_hidden_states)\n#         feature = torch.sum(weights * last_hidden_states, dim=1)\n#         return feature\n    \n    def forward(self, batch):\n#         print(batch['token_id'].shape)\n#         print(batch['token_mask'].shape)\n        outputs = self.model(\n            input_ids      = batch['token_id'],\n            attention_mask = batch['token_mask']\n            )\n#         last = tx.last_hidden_state\n        #x = self.pool(last, batch['token_type_id'])\n        all_hidden_states = torch.stack(outputs[1])\n#         print(all_hidden_states.shape)\n        wkpooling_embeddings = self.wkpool(all_hidden_states,batch)\n#         print(wkpooling_embeddings.shape)\n        logits =self.fc(wkpooling_embeddings) # regression head\n#         print(logits)\n        return logits\n","metadata":{"id":"4c5bab44","papermill":{"duration":0.066203,"end_time":"2022-03-22T09:40:52.37203","exception":false,"start_time":"2022-03-22T09:40:52.305827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-19T10:14:50.576748Z","iopub.execute_input":"2022-06-19T10:14:50.57728Z","iopub.status.idle":"2022-06-19T10:14:50.59111Z","shell.execute_reply.started":"2022-06-19T10:14:50.577224Z","shell.execute_reply":"2022-06-19T10:14:50.590358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"id":"deee9675","papermill":{"duration":0.044158,"end_time":"2022-03-22T09:40:52.460401","exception":false,"start_time":"2022-03-22T09:40:52.416243","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n            #print(y_preds)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:14:50.59257Z","iopub.execute_input":"2022-06-19T10:14:50.592819Z","iopub.status.idle":"2022-06-19T10:14:50.60182Z","shell.execute_reply.started":"2022-06-19T10:14:50.592786Z","shell.execute_reply":"2022-06-19T10:14:50.600897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"microsoft-deberta-v3-small_fold{fold}_best.pth\",\n                   map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-19T10:14:50.603378Z","iopub.execute_input":"2022-06-19T10:14:50.603578Z","iopub.status.idle":"2022-06-19T10:16:26.476517Z","shell.execute_reply.started":"2022-06-19T10:14:50.603556Z","shell.execute_reply":"2022-06-19T10:16:26.473425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission['score'] = predictions\ndisplay(submission.head())\nsubmission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:16:27.149063Z","iopub.execute_input":"2022-06-19T10:16:27.149348Z","iopub.status.idle":"2022-06-19T10:16:27.166082Z","shell.execute_reply.started":"2022-06-19T10:16:27.149314Z","shell.execute_reply":"2022-06-19T10:16:27.165125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[['id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:16:29.169216Z","iopub.execute_input":"2022-06-19T10:16:29.170056Z","iopub.status.idle":"2022-06-19T10:16:29.18206Z","shell.execute_reply.started":"2022-06-19T10:16:29.170009Z","shell.execute_reply":"2022-06-19T10:16:29.181386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}