{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## MSDS 631 - Final Project\n\n### Project description\n\nThe patent review process involves searching for past filed patents in the same domain of a new patent application. The search keywords used by legal analysts depend on context of the patent application. For example, \"strong material\" could mean \"steel\" for construction purposes or \"denim\" for textiles. This Kaggle competition aims to find a relevance score (five levels from 0 to 1) of a target keyword with a given ancho r word in the context of a domain\n\n### Training data description\n\n\n### Preprocessing steps\n\n\n### NLP model selection\n\n### Results\n","metadata":{"papermill":{"duration":0.00541,"end_time":"2022-06-26T02:32:46.571233","exception":false,"start_time":"2022-06-26T02:32:46.565823","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import pearsonr","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.024541,"end_time":"2022-06-26T02:32:46.603039","exception":false,"start_time":"2022-06-26T02:32:46.578498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:52.454081Z","iopub.execute_input":"2022-06-30T12:31:52.455058Z","iopub.status.idle":"2022-06-30T12:31:52.922367Z","shell.execute_reply.started":"2022-06-30T12:31:52.454971Z","shell.execute_reply":"2022-06-30T12:31:52.921561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"papermill":{"duration":1.980943,"end_time":"2022-06-26T02:32:48.588778","exception":false,"start_time":"2022-06-26T02:32:46.607835","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:52.923574Z","iopub.execute_input":"2022-06-30T12:31:52.924054Z","iopub.status.idle":"2022-06-30T12:31:53.313617Z","shell.execute_reply.started":"2022-06-30T12:31:52.924017Z","shell.execute_reply":"2022-06-30T12:31:53.312793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:53.31485Z","iopub.execute_input":"2022-06-30T12:31:53.315617Z","iopub.status.idle":"2022-06-30T12:31:53.351578Z","shell.execute_reply.started":"2022-06-30T12:31:53.315574Z","shell.execute_reply":"2022-06-30T12:31:53.350619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0') ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:53.35468Z","iopub.execute_input":"2022-06-30T12:31:53.35508Z","iopub.status.idle":"2022-06-30T12:31:53.360062Z","shell.execute_reply.started":"2022-06-30T12:31:53.355052Z","shell.execute_reply":"2022-06-30T12:31:53.358565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')\ntrain.head()","metadata":{"papermill":{"duration":0.131799,"end_time":"2022-06-26T02:32:48.7252","exception":false,"start_time":"2022-06-26T02:32:48.593401","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:53.362132Z","iopub.execute_input":"2022-06-30T12:31:53.362597Z","iopub.status.idle":"2022-06-30T12:31:53.430148Z","shell.execute_reply.started":"2022-06-30T12:31:53.362562Z","shell.execute_reply":"2022-06-30T12:31:53.429233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"code = pd.read_csv('/kaggle/input/titles/titles.csv')\ncode.head()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:53.431448Z","iopub.execute_input":"2022-06-30T12:31:53.431903Z","iopub.status.idle":"2022-06-30T12:31:54.083781Z","shell.execute_reply.started":"2022-06-30T12:31:53.431865Z","shell.execute_reply":"2022-06-30T12:31:54.082936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"code[code['code'] == 'A47']['title']","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:54.085327Z","iopub.execute_input":"2022-06-30T12:31:54.085966Z","iopub.status.idle":"2022-06-30T12:31:54.143694Z","shell.execute_reply.started":"2022-06-30T12:31:54.085924Z","shell.execute_reply":"2022-06-30T12:31:54.142871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(code, how='inner', left_on='context', right_on='code')\n\ntrain.head()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:54.145391Z","iopub.execute_input":"2022-06-30T12:31:54.145993Z","iopub.status.idle":"2022-06-30T12:31:54.301129Z","shell.execute_reply.started":"2022-06-30T12:31:54.145956Z","shell.execute_reply":"2022-06-30T12:31:54.300273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\ndef clean_txt(row):\n    row = row.lower()\n    row = row.translate(str.maketrans('', '', string.punctuation))\n    return row\ntrain['title'] = train['title'].apply(clean_txt)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:54.302628Z","iopub.execute_input":"2022-06-30T12:31:54.303215Z","iopub.status.idle":"2022-06-30T12:31:54.445273Z","shell.execute_reply.started":"2022-06-30T12:31:54.303159Z","shell.execute_reply":"2022-06-30T12:31:54.444407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['combined_text'] = train['anchor'] + ' ' + train['target']","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:54.44708Z","iopub.execute_input":"2022-06-30T12:31:54.447721Z","iopub.status.idle":"2022-06-30T12:31:54.464786Z","shell.execute_reply.started":"2022-06-30T12:31:54.447681Z","shell.execute_reply":"2022-06-30T12:31:54.464026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def change_values(row):\n    class_map = {0.00:0,\n                0.25:1,\n                0.50:2,\n                0.75:3,\n                1.00:4}\n    return class_map[row]\ntrain['score'] = train['score'].apply(change_values)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:54.46573Z","iopub.execute_input":"2022-06-30T12:31:54.466014Z","iopub.status.idle":"2022-06-30T12:31:54.512653Z","shell.execute_reply.started":"2022-06-30T12:31:54.465988Z","shell.execute_reply":"2022-06-30T12:31:54.511827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:54.516721Z","iopub.execute_input":"2022-06-30T12:31:54.518898Z","iopub.status.idle":"2022-06-30T12:31:54.53986Z","shell.execute_reply.started":"2022-06-30T12:31:54.518858Z","shell.execute_reply":"2022-06-30T12:31:54.539136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['score'].value_counts()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:54.542903Z","iopub.execute_input":"2022-06-30T12:31:54.543162Z","iopub.status.idle":"2022-06-30T12:31:54.550079Z","shell.execute_reply.started":"2022-06-30T12:31:54.543139Z","shell.execute_reply":"2022-06-30T12:31:54.54918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset and dataloader preparation\n\nWe will use Pytorch's dataset class to construct a bespoke dataset class that will take either of the augmented train or test datasets","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"max_length = 0\nfor idx in range(len(train)):\n    row = train.iloc[idx]\n    length = len(row['combined_text'].split(' '))\n    if length > max_length:\n        max_length = length\nprint(max_length)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:54.551467Z","iopub.execute_input":"2022-06-30T12:31:54.551991Z","iopub.status.idle":"2022-06-30T12:31:59.577502Z","shell.execute_reply.started":"2022-06-30T12:31:54.551954Z","shell.execute_reply":"2022-06-30T12:31:59.576636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_dict = {word:i for i, word in enumerate(train['combined_text'].str.split(' ', expand=True).stack().unique())}","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.578635Z","iopub.execute_input":"2022-06-30T12:31:59.579478Z","iopub.status.idle":"2022-06-30T12:31:59.839939Z","shell.execute_reply.started":"2022-06-30T12:31:59.579428Z","shell.execute_reply":"2022-06-30T12:31:59.838947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatentDataset(Dataset):\n    def __init__(self, df, max_length, word_dict):\n        self.df = df\n        self.max_len = max_length\n        self.word_dict = word_dict\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        combined = row['combined_text'].split(' ')\n        x = torch.zeros(self.max_len).long()\n        \n        # get review as a list of integers\n        for idx in range(len(combined)):\n            \n            # we want to front pad for RNN\n            x[self.max_len - len(combined) + idx] = self.word_dict[combined[idx]]\n            \n        y = torch.tensor(row['score']).float()\n        return x, y","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-06-30T12:31:59.841306Z","iopub.execute_input":"2022-06-30T12:31:59.842301Z","iopub.status.idle":"2022-06-30T12:31:59.84979Z","shell.execute_reply.started":"2022-06-30T12:31:59.842263Z","shell.execute_reply":"2022-06-30T12:31:59.848693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, dict_length, embedding_size, hidden_size):\n        super(RNN, self).__init__()\n        \n        self.word_emb = nn.Embedding(dict_length, embedding_size, padding_idx=0)\n        self.rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True)\n        #self.rnn2 = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n        self.relu = nn.ReLU()\n        self.g = nn.Linear(hidden_size, 1)\n        \n    def forward(self, x):\n        x = self.word_emb(x)\n        hidden = self.rnn(x)[1]\n        out = self.relu(hidden)\n        out = self.g(out)\n\n        return torch.squeeze(out)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.851394Z","iopub.execute_input":"2022-06-30T12:31:59.851913Z","iopub.status.idle":"2022-06-30T12:31:59.86277Z","shell.execute_reply.started":"2022-06-30T12:31:59.851875Z","shell.execute_reply":"2022-06-30T12:31:59.861934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, dict_length, embedding_size, hidden_size):\n        super(LSTM, self).__init__()\n        \n        self.word_emb = nn.Embedding(dict_length, embedding_size, padding_idx=0)\n        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size)\n        self.g = nn.Linear(hidden_size, 1)\n        \n    def forward(self, x):\n        x = self.word_emb(x)\n        hidden = self.lstm(x)[1]\n        out = self.g(out)\n\n        return torch.squeeze(out[:, -1])#torch.squeeze(out)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.863983Z","iopub.execute_input":"2022-06-30T12:31:59.864783Z","iopub.status.idle":"2022-06-30T12:31:59.87307Z","shell.execute_reply.started":"2022-06-30T12:31:59.864745Z","shell.execute_reply":"2022-06-30T12:31:59.872326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_pass(model, dataloader, optimizer, lossFun, backwards=True):\n    \n    total_loss = 0.0\n    if backwards == True:\n        model.train()\n    else:\n        model.eval()\n    \n    for X, y in dataloader:\n        \n        y_pred = model(X.cuda())\n        loss = lossFun(y_pred, y.cuda())\n        total_loss += loss.item()\n        \n        if backwards == True:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n    \n    return total_loss/len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.874048Z","iopub.execute_input":"2022-06-30T12:31:59.87492Z","iopub.status.idle":"2022-06-30T12:31:59.883018Z","shell.execute_reply.started":"2022-06-30T12:31:59.874882Z","shell.execute_reply":"2022-06-30T12:31:59.882323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, optimizer, train_dl, valid_dl, num_epochs):\n    train_losses = []\n    valid_losses = []\n\n    for epoch in tqdm(range(num_epochs)):\n\n        train_loss = one_pass(model, train_dl, optimizer, lossFun)\n        train_losses.append(train_loss)\n\n        valid_loss = one_pass(model, valid_dl, optimizer, lossFun, backwards=False)\n        valid_losses.append(valid_loss)\n        \n        if epoch%5==0:\n            print('Epoch: ', epoch)\n            print('Train loss: ', train_loss)\n            print('Valid loss: ', valid_loss)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.88506Z","iopub.execute_input":"2022-06-30T12:31:59.886487Z","iopub.status.idle":"2022-06-30T12:31:59.894299Z","shell.execute_reply.started":"2022-06-30T12:31:59.886449Z","shell.execute_reply":"2022-06-30T12:31:59.893485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pearsonr_(x, y):\n    \"\"\"\n    Mimics `scipy.stats.pearsonr`\n    Arguments\n    ---------\n    x : 1D torch.Tensor\n    y : 1D torch.Tensor\n    Returns\n    -------\n    r_val : float\n        pearsonr correlation coefficient between x and y\n    \n    Scipy docs ref:\n        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n    \n    Scipy code ref:\n        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\n    Example:\n        >>> x = np.random.randn(100)\n        >>> y = np.random.randn(100)\n        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\n        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\n        >>> np.allclose(sp_corr, th_corr)\n    \"\"\"\n    mean_x = torch.mean(x)\n    mean_y = torch.mean(y)\n    xm = x.sub(mean_x)\n    ym = y.sub(mean_y)\n    r_num = xm.dot(ym)\n    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n    r_val = r_num / r_den\n    return -torch.clamp(r_val, min=-1., max=1.)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.895579Z","iopub.execute_input":"2022-06-30T12:31:59.896428Z","iopub.status.idle":"2022-06-30T12:31:59.909013Z","shell.execute_reply.started":"2022-06-30T12:31:59.89639Z","shell.execute_reply":"2022-06-30T12:31:59.904529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(3)\nmsk = np.random.rand(len(train)) < 0.8\ntrain_ds = PatentDataset(train[msk].reset_index(), max_length, word_dict)\nvalid_ds = PatentDataset(train[~msk].reset_index(), max_length, word_dict)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.910609Z","iopub.execute_input":"2022-06-30T12:31:59.911417Z","iopub.status.idle":"2022-06-30T12:31:59.940903Z","shell.execute_reply.started":"2022-06-30T12:31:59.911375Z","shell.execute_reply":"2022-06-30T12:31:59.940113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN(len(word_dict), 400, 400).to(device)\nlossFun = pearsonr_#nn.CrossEntropyLoss()\n\ntrain_dl = DataLoader(train_ds, batch_size=1000, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=1000, shuffle=False)\n\noptimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=5e-6)\ntrain_model(model, optimizer, train_dl, valid_dl, 31)\noptimizer = optim.Adam(model.parameters(), lr = 0.0002)\ntrain_model(model, optimizer, train_dl, valid_dl, 16)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:31:59.942125Z","iopub.execute_input":"2022-06-30T12:31:59.943007Z","iopub.status.idle":"2022-06-30T12:38:37.281935Z","shell.execute_reply.started":"2022-06-30T12:31:59.942966Z","shell.execute_reply":"2022-06-30T12:38:37.281132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=5)\nrs = []\nfor train_index, test_index in kf.split(train):\n    train_ds = PatentDataset(train.iloc[train_index].reset_index(), max_length, word_dict)\n    valid_ds = PatentDataset(train.iloc[test_index].reset_index(), max_length, word_dict)\n    train_dl = DataLoader(train_ds, batch_size=1000, shuffle=True)\n    valid_dl = DataLoader(valid_ds, batch_size=len(valid_ds), shuffle=False)\n    \n    model = RNN(len(word_dict), 400, 400).to(device)\n    optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=5e-6)\n    train_model(model, optimizer, train_dl, valid_dl, 31)\n    optimizer = optim.Adam(model.parameters(), lr = 0.0002)\n    train_model(model, optimizer, train_dl, valid_dl, 16)\n    \n    #preds = torch.argmax([model(x.cuda()) for x, _ in valid_dl][0], dim=1).cpu().numpy()\n    preds = [model(x.cuda()) for x, _ in valid_dl][0].detach().cpu().numpy()\n    y = train.iloc[test_index]['score'].values\n    r, _ = pearsonr(preds, y)\n    rs.append(r)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T12:38:37.283478Z","iopub.execute_input":"2022-06-30T12:38:37.284077Z","iopub.status.idle":"2022-06-30T13:11:34.315836Z","shell.execute_reply.started":"2022-06-30T12:38:37.284039Z","shell.execute_reply":"2022-06-30T13:11:34.315006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rs)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:11:34.316961Z","iopub.execute_input":"2022-06-30T13:11:34.31742Z","iopub.status.idle":"2022-06-30T13:11:34.324676Z","shell.execute_reply.started":"2022-06-30T13:11:34.317382Z","shell.execute_reply":"2022-06-30T13:11:34.323908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(rs)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:11:34.32706Z","iopub.execute_input":"2022-06-30T13:11:34.327745Z","iopub.status.idle":"2022-06-30T13:11:34.335002Z","shell.execute_reply.started":"2022-06-30T13:11:34.327716Z","shell.execute_reply":"2022-06-30T13:11:34.333836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print([round(r, 4) for r in rs])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:24:48.017253Z","iopub.execute_input":"2022-06-30T13:24:48.018163Z","iopub.status.idle":"2022-06-30T13:24:48.023711Z","shell.execute_reply.started":"2022-06-30T13:24:48.018126Z","shell.execute_reply":"2022-06-30T13:24:48.022717Z"},"trusted":true},"execution_count":null,"outputs":[]}]}