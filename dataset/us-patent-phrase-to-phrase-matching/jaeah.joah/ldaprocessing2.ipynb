{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-18T11:15:29.460204Z","iopub.execute_input":"2022-05-18T11:15:29.460528Z","iopub.status.idle":"2022-05-18T11:15:29.478664Z","shell.execute_reply.started":"2022-05-18T11:15:29.460489Z","shell.execute_reply":"2022-05-18T11:15:29.477638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom gensim.parsing.preprocessing import preprocess_string\nimport pandas as pd\nimport time\nimport pdb\n\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom gensim.models.coherencemodel import CoherenceModel\nimport matplotlib.pyplot as plt\nfrom gensim.models import LdaModel\nimport pyLDAvis.gensim               #pyLDAvis.gensim_models\nfrom scipy.spatial import distance\n\n#nltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:16:20.662847Z","iopub.execute_input":"2022-05-18T11:16:20.663394Z","iopub.status.idle":"2022-05-18T11:17:00.735599Z","shell.execute_reply.started":"2022-05-18T11:16:20.663357Z","shell.execute_reply":"2022-05-18T11:17:00.734635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')\ntest = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv')\ntitle = pd.read_csv('/kaggle/input/cpc-codes/titles.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:01.745184Z","iopub.execute_input":"2022-05-18T11:17:01.74558Z","iopub.status.idle":"2022-05-18T11:17:02.452216Z","shell.execute_reply.started":"2022-05-18T11:17:01.745534Z","shell.execute_reply":"2022-05-18T11:17:02.451275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train),len(test))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:02.461841Z","iopub.execute_input":"2022-05-18T11:17:02.462136Z","iopub.status.idle":"2022-05-18T11:17:02.474131Z","shell.execute_reply.started":"2022-05-18T11:17:02.462097Z","shell.execute_reply":"2022-05-18T11:17:02.473252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"frames = [train, test]\nall = pd.concat(frames, keys=['train', 'test'])\nall","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:16.336932Z","iopub.execute_input":"2022-05-18T11:17:16.33725Z","iopub.status.idle":"2022-05-18T11:17:16.378775Z","shell.execute_reply.started":"2022-05-18T11:17:16.337213Z","shell.execute_reply":"2022-05-18T11:17:16.377958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = all.loc['test']\ndf_test","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:20.72499Z","iopub.execute_input":"2022-05-18T11:17:20.725279Z","iopub.status.idle":"2022-05-18T11:17:20.748604Z","shell.execute_reply.started":"2022-05-18T11:17:20.725247Z","shell.execute_reply":"2022-05-18T11:17:20.747698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_LEFT_JOIN = pd.merge(all, title, left_on='context', right_on='code', how='left')\ndf_LEFT_JOIN","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:24.705814Z","iopub.execute_input":"2022-05-18T11:17:24.706671Z","iopub.status.idle":"2022-05-18T11:17:24.863636Z","shell.execute_reply.started":"2022-05-18T11:17:24.70663Z","shell.execute_reply":"2022-05-18T11:17:24.862781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df_LEFT_JOIN.drop(['code','section','class','subclass','group','main_group'], axis=1)\ndata = data[['id','anchor','target','context','title','score']]\ndata","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:28.711833Z","iopub.execute_input":"2022-05-18T11:17:28.712162Z","iopub.status.idle":"2022-05-18T11:17:28.741231Z","shell.execute_reply.started":"2022-05-18T11:17:28.712123Z","shell.execute_reply":"2022-05-18T11:17:28.74048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(d):\n    d = str(d)\n    pattern = r'[^a-zA-Z\\'\\s]'\n    text = re.sub(pattern, '', d)\n    text = text.lower()\n    #text = [word for word in text if len(word)>2]\n    return ' '.join([w for w in text.split() if len(w) > 3])# 3이하인거 버리기\n\ndef preprocessing(d):\n    return preprocess_string(d)\n\ndef data_load(data):\n    df = pd.DataFrame({'text': data['total']})\n    tokenized_text = df['text'].apply(preprocessing)\n    tokenized_text = tokenized_text.to_list()\n    return tokenized_text \n\ndef make_topictable_per_doc(ldamodel, corpus):\n    topic_table = pd.DataFrame()\n    for i, topic_list in enumerate(ldamodel[corpus]):\n        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n        for j, (topic_num, prop_topic) in enumerate(doc):\n            if j == 0:  \n                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n            else:\n                break\n    return(topic_table)\n\ndef create_output(topictable, topicnum):\n    total_topic_list=list()\n    \n    for topic in range(len(topictable[\"각 토픽의 비중\"])):\n        topic_dict=dict()\n        tmp_list = list()\n        for k in range(len(topictable[\"각 토픽의 비중\"][topic])):\n            topic_dict[f'topic_{int(topictable[\"각 토픽의 비중\"][topic][k][0])}'] = float(topictable[\"각 토픽의 비중\"][topic][k][1])\n            tmp_list.append(int(topictable[\"각 토픽의 비중\"][topic][k][0]))\n\n        num_list = [i for i in range(topicnum)]\n        num_list = [i for i in num_list if i not in tmp_list]   ## 있는 토픽 제거\n\n        for n in num_list:\n            topic_dict[f'topic_{n}'] = 0.0      ## 확률 0인 토픽 넣어줌\n        sorted_dict = sorted(topic_dict.items())\n        total_topic_list.append(dict(sorted_dict))\n\n    with open(f\"./out_t9_total1.json\", 'w') as topic_file:\n        json.dump(total_topic_list, topic_file, indent='\\t')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:28:39.789042Z","iopub.execute_input":"2022-05-18T11:28:39.790158Z","iopub.status.idle":"2022-05-18T11:28:39.808162Z","shell.execute_reply.started":"2022-05-18T11:28:39.790087Z","shell.execute_reply":"2022-05-18T11:28:39.806733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['title'] = data['title'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:44.63905Z","iopub.execute_input":"2022-05-18T11:17:44.639854Z","iopub.status.idle":"2022-05-18T11:17:44.848907Z","shell.execute_reply.started":"2022-05-18T11:17:44.639803Z","shell.execute_reply":"2022-05-18T11:17:44.847963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"origin_data = data\norigin_data","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:17:46.685596Z","iopub.execute_input":"2022-05-18T11:17:46.685918Z","iopub.status.idle":"2022-05-18T11:17:46.702817Z","shell.execute_reply.started":"2022-05-18T11:17:46.685875Z","shell.execute_reply":"2022-05-18T11:17:46.701884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df = pd.DataFrame(columns=['id','total'])\ntotal_df['total'] = data['anchor'] + \" \" + data['target'] + \" \" +  data['title']\ntotal_df['id'] = data['id']\ntotal_df","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:27:27.09304Z","iopub.execute_input":"2022-05-18T11:27:27.093382Z","iopub.status.idle":"2022-05-18T11:27:27.149892Z","shell.execute_reply.started":"2022-05-18T11:27:27.093347Z","shell.execute_reply":"2022-05-18T11:27:27.149022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LDA Modeling","metadata":{}},{"cell_type":"code","source":"doc_token = data_load(total_df)\nLDA_new_list = doc_token\n\n## Modeling\ndictionary = corpora.Dictionary(doc_token)\ncorpus = [dictionary.doc2bow(text) for text in doc_token] #문서를 bag-of-words 형태로 바꾼것\n\nNUM_TOPICS = 9\nNUM_PASSES = 30\nlda_model =LdaModel(corpus, num_topics = NUM_TOPICS, id2word = dictionary, passes = NUM_PASSES)\ntopics = lda_model.print_topics(num_words = 10)\n    \nvis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\npyLDAvis.save_html(vis, 'LDAvis_t9_total1.html')\n\ntopictable = make_topictable_per_doc(lda_model, corpus)\ntopictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\ntopictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\ntopictable[:10]\n\ncreate_output(topictable, NUM_TOPICS)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:29:52.727949Z","iopub.execute_input":"2022-05-18T11:29:52.728608Z","iopub.status.idle":"2022-05-18T11:34:58.901597Z","shell.execute_reply.started":"2022-05-18T11:29:52.728547Z","shell.execute_reply":"2022-05-18T11:34:58.900651Z"},"trusted":true},"execution_count":null,"outputs":[]}]}