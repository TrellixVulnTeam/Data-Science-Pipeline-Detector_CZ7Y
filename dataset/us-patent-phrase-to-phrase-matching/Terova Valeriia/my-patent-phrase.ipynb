{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tez-lib/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T11:29:00.967656Z","iopub.execute_input":"2022-05-19T11:29:00.967911Z","iopub.status.idle":"2022-05-19T11:29:00.971737Z","shell.execute_reply.started":"2022-05-19T11:29:00.967881Z","shell.execute_reply":"2022-05-19T11:29:00.970967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nimport pandas as pd\nimport torch.nn as nn\n\nfrom scipy import stats\nfrom tez import Tez, TezConfig\nfrom transformers import AutoModel, AutoConfig, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:01.840298Z","iopub.execute_input":"2022-05-19T11:29:01.840835Z","iopub.status.idle":"2022-05-19T11:29:01.846226Z","shell.execute_reply.started":"2022-05-19T11:29:01.840798Z","shell.execute_reply":"2022-05-19T11:29:01.844869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Оказалось, что NLP это крутая штука и там есть очень много всяких приколюх!! Вдоль и поперек изучила вот [этот](https://www.kaggle.com/code/venkatkumar001/nlp-starter-almost-all-basic-concept/notebook#5.-Chunking) ноутбук, очень прикольно. Применять тут не стала, потому что использую модель, предобученную на патентных данных и почему-то мне показалось, что вот эта куча NLPишных приемов наоборот сделает предсказания моей модели хуже (я попробовала добавить стемминг и действительно стало не лучше, поэтому приняла это за подверждение моей гипотезы и забила :)  ","metadata":{}},{"cell_type":"code","source":"class args:\n    # https://huggingface.co/anferico/bert-for-patents\n    # https://habr.com/ru/post/436878/\n    model = \"../input/anferico-bert-for-patents/\"\n    max_len = 32\n    accumulation_steps = 2\n    batch_size = 16\n    epochs = 100\n    learning_rate = 2e-9","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:02.30033Z","iopub.execute_input":"2022-05-19T11:29:02.301011Z","iopub.status.idle":"2022-05-19T11:29:02.306011Z","shell.execute_reply.started":"2022-05-19T11:29:02.300955Z","shell.execute_reply":"2022-05-19T11:29:02.305038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n\n        encoded_text = self.tokenizer.encode_plus(\n            context + \" \" + anchor,\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n        token_type_ids = encoded_text[\"token_type_ids\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:02.905981Z","iopub.execute_input":"2022-05-19T11:29:02.906251Z","iopub.status.idle":"2022-05-19T11:29:02.917576Z","shell.execute_reply.started":"2022-05-19T11:29:02.90622Z","shell.execute_reply":"2022-05-19T11:29:02.916804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseModel(nn.Module):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model_name = model_name\n\n        config = AutoConfig.from_pretrained(model_name)\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"add_pooling_layer\": True,\n                \"num_labels\": 1,\n            }\n        )\n        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.output = nn.Linear(config.hidden_size, 1)\n        \n        ## здесь было разное\n        ## но если добавлять немного простых слоев, то score либо не меняется, либо наоборот становится хуже\n        ## сложные модели опробовать не получилось, потому что ноутбук вылетает по памяти :(\n\n    def forward(self, ids, mask, token_type_ids):\n        transformer_out = self.transformer(ids, mask, token_type_ids)\n        output = transformer_out.pooler_output\n        output = self.dropout(output)\n        output = self.output(output)\n        return output, 0, {}","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:03.283936Z","iopub.execute_input":"2022-05-19T11:29:03.284212Z","iopub.status.idle":"2022-05-19T11:29:03.291188Z","shell.execute_reply.started":"2022-05-19T11:29:03.284171Z","shell.execute_reply":"2022-05-19T11:29:03.290516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n\n# data\ncontext_mapping = {\n    \"A\": \"Human Necessities\",\n    \"B\": \"Operations and Transport\",\n    \"C\": \"Chemistry and Metallurgy\",\n    \"D\": \"Textiles\",\n    \"E\": \"Fixed Constructions\",\n    \"F\": \"Mechanical Engineering\",\n    \"G\": \"Physics\",\n    \"H\": \"Electricity\",\n    \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n\ndf.context = df.context.apply(lambda x: context_mapping[x[0]])\n\ntokenizer = AutoTokenizer.from_pretrained(args.model)\ntest_dataset = PhraseDataset(\n    anchor=df.anchor.values,\n    target=df.target.values,\n    context=df.context.values,\n    tokenizer=tokenizer,\n    max_len=args.max_len,\n)\n\nmodel = PhraseModel(model_name=args.model)\n\n# забавная штука, pytorch прекрасно справляется сам, но так нужно чуть-чуть меньше делать ручками\n# https://github.com/abhishekkrthakur/tez/blob/main/tez/model/model.py#L342 -- вот например метод load\nmodel = Tez(model)\nmodel_path = \"../input/uspppm-tez-models/model_f0.bin\"\nconfig = TezConfig(\n    test_batch_size=64,\n    device=\"cuda\",\n    epochs=args.epochs,\n)\nmodel.load(model_path, weights_only=True, config=config)\n\npreds_iter = model.predict(test_dataset)\nfinal_preds = []\nfor preds in preds_iter:\n    preds[preds < 0] = 0\n    preds[preds > 1] = 1\n    final_preds.extend(preds.ravel().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:03.589996Z","iopub.execute_input":"2022-05-19T11:29:03.59045Z","iopub.status.idle":"2022-05-19T11:29:09.595605Z","shell.execute_reply.started":"2022-05-19T11:29:03.590414Z","shell.execute_reply":"2022-05-19T11:29:09.594598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")\n\nsample_submission.score = final_preds\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:09.597642Z","iopub.execute_input":"2022-05-19T11:29:09.597897Z","iopub.status.idle":"2022-05-19T11:29:09.609589Z","shell.execute_reply.started":"2022-05-19T11:29:09.597868Z","shell.execute_reply":"2022-05-19T11:29:09.60876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:29:15.471584Z","iopub.execute_input":"2022-05-19T11:29:15.472293Z","iopub.status.idle":"2022-05-19T11:29:15.481234Z","shell.execute_reply.started":"2022-05-19T11:29:15.472251Z","shell.execute_reply":"2022-05-19T11:29:15.480465Z"},"trusted":true},"execution_count":null,"outputs":[]}]}