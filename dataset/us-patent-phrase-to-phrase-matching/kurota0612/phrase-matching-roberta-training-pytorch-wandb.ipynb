{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport time\nimport random\nfrom scipy import stats\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-30T23:18:58.356019Z","iopub.execute_input":"2022-05-30T23:18:58.356302Z","iopub.status.idle":"2022-05-30T23:18:58.365806Z","shell.execute_reply.started":"2022-05-30T23:18:58.35627Z","shell.execute_reply":"2022-05-30T23:18:58.365013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:18:58.367503Z","iopub.execute_input":"2022-05-30T23:18:58.368011Z","iopub.status.idle":"2022-05-30T23:18:58.382573Z","shell.execute_reply.started":"2022-05-30T23:18:58.367969Z","shell.execute_reply":"2022-05-30T23:18:58.38179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers: Optional[int] = 4\n    model_name: Optional[str] = 'roberta-large'\n    epochs: Optional[int] = 5\n    T_max: Optional[int] = 10 \n    T_0: Optional[int] = 10 \n    lr: Optional[float]= 2e-5\n    min_lr: Optional[float] = 1e-6\n    batch_size: Optional[int] = 32\n    weight_decay: Optional[float] = 1e-6\n    gradient_accumulation_steps: Optional[int] = 1\n    max_grad_norm: Optional[int] = 1000\n    max_len: Optional[int] = 128\n    seed: Optional[int] = 2019\n    target_size: Optional[int] = 1\n    num_targets: Optional[int] = 1\n    n_folds: Optional[int] = 4\n    fp16: Optional[bool] = True\n    wandb: Optional[bool] = True\n    _wandb_kernel: Optional[str] = 'santos'\n    competition: Optional[str] = 'PPPM'\n    tokenizer = AutoTokenizer.from_pretrained('roberta-large')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:18:58.411192Z","iopub.execute_input":"2022-05-30T23:18:58.411419Z","iopub.status.idle":"2022-05-30T23:19:08.718378Z","shell.execute_reply.started":"2022-05-30T23:18:58.411392Z","shell.execute_reply":"2022-05-30T23:19:08.717546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# wandb\n# ====================================================\nif CFG.wandb:\n    \n    import wandb\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n        wandb.login(key=secret_value_0)\n        anony = None\n    except:\n        anony = \"must\"\n        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n\n\n    def class2dict(f):\n        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\n    run = wandb.init(project='PPPM-Public', \n                     name=CFG.model_name,\n                     config=class2dict(CFG),\n                     group=CFG.model_name,\n                     job_type=\"train\",\n                     anonymous=anony)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:08.720261Z","iopub.execute_input":"2022-05-30T23:19:08.720503Z","iopub.status.idle":"2022-05-30T23:19:21.97795Z","shell.execute_reply.started":"2022-05-30T23:19:08.720472Z","shell.execute_reply":"2022-05-30T23:19:21.977079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/us-patent-phrase-to-phrase-matching'\ntrain = pd.read_csv(os.path.join(PATH, 'train.csv'))\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:21.9824Z","iopub.execute_input":"2022-05-30T23:19:21.984976Z","iopub.status.idle":"2022-05-30T23:19:22.089593Z","shell.execute_reply.started":"2022-05-30T23:19:21.984929Z","shell.execute_reply":"2022-05-30T23:19:22.088791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.095413Z","iopub.execute_input":"2022-05-30T23:19:22.097683Z","iopub.status.idle":"2022-05-30T23:19:22.118566Z","shell.execute_reply.started":"2022-05-30T23:19:22.097639Z","shell.execute_reply":"2022-05-30T23:19:22.117848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.122795Z","iopub.execute_input":"2022-05-30T23:19:22.12497Z","iopub.status.idle":"2022-05-30T23:19:22.142567Z","shell.execute_reply.started":"2022-05-30T23:19:22.124928Z","shell.execute_reply":"2022-05-30T23:19:22.141866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape, sub.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.14677Z","iopub.execute_input":"2022-05-30T23:19:22.148992Z","iopub.status.idle":"2022-05-30T23:19:22.173681Z","shell.execute_reply.started":"2022-05-30T23:19:22.14895Z","shell.execute_reply":"2022-05-30T23:19:22.172856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    data[\"fold\"] = -1\n    data = data.sample(frac=1).reset_index(drop=True)\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n        \n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"score\"], bins=num_bins, labels=False\n    )\n    \n    kf = model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'fold'] = f\n    \n    data = data.drop(\"bins\", axis=1)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.177163Z","iopub.execute_input":"2022-05-30T23:19:22.182378Z","iopub.status.idle":"2022-05-30T23:19:22.195771Z","shell.execute_reply.started":"2022-05-30T23:19:22.182327Z","shell.execute_reply":"2022-05-30T23:19:22.194621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n   \ncontext_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n    \ntrain.context = train.context.apply(lambda x: context_mapping[x[0]])","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.201907Z","iopub.execute_input":"2022-05-30T23:19:22.204202Z","iopub.status.idle":"2022-05-30T23:19:22.243622Z","shell.execute_reply.started":"2022-05-30T23:19:22.204159Z","shell.execute_reply":"2022-05-30T23:19:22.242777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = create_folds(train, num_splits=CFG.n_folds)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.25284Z","iopub.execute_input":"2022-05-30T23:19:22.259867Z","iopub.status.idle":"2022-05-30T23:19:22.334152Z","shell.execute_reply.started":"2022-05-30T23:19:22.259824Z","shell.execute_reply":"2022-05-30T23:19:22.333197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.342004Z","iopub.execute_input":"2022-05-30T23:19:22.344373Z","iopub.status.idle":"2022-05-30T23:19:22.366472Z","shell.execute_reply.started":"2022-05-30T23:19:22.344326Z","shell.execute_reply":"2022-05-30T23:19:22.365733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, score, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.score = score\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n        score = self.score[item]\n\n        encoded_text = CFG.tokenizer.encode_plus(\n            context + \" \" + anchor,\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"score\": torch.tensor(score, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.370972Z","iopub.execute_input":"2022-05-30T23:19:22.373247Z","iopub.status.idle":"2022-05-30T23:19:22.388316Z","shell.execute_reply.started":"2022-05-30T23:19:22.373204Z","shell.execute_reply":"2022-05-30T23:19:22.387316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(model, train_dataloader, optimizer, scheduler, loss_fn=None, fp16=False):\n    model.train()\n    \n    scaler =  torch.cuda.amp.GradScaler()\n    \n    train_loss = 0\n    \n    for step, data in enumerate(train_dataloader):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['score'].to(device, dtype = torch.float)\n        \n        with torch.cuda.amp.autocast(enabled=True):\n            output = model(ids, mask)\n            loss = loss_fn(output.squeeze(), targets.squeeze())\n            \n        train_loss +=loss.item()\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n\n        if CFG.fp16:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        \n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            if CFG.fp16:\n                scaler.step(optimizer)\n                scaler.update()\n                scheduler.step()\n            else:\n                optimizer.step()\n                scheduler.step()\n\n            optimizer.zero_grad()\n        \n    return train_loss/len(train_dataloader)\n\n\ndef valid_fn(model, valid_dataloader, loss_fn=None):\n    \n    model.eval()\n    predictions = []\n    valid_loss = 0\n    \n    for data in valid_dataloader:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['score'].to(device, dtype = torch.float)\n        \n        with torch.no_grad():\n            output = model(ids, mask)\n            loss = loss_fn(output.squeeze(), targets.squeeze())\n        valid_loss +=loss.item()\n        predictions.append(output.sigmoid().detach().cpu().numpy().ravel())\n        \n    return valid_loss/len(valid_dataloader), np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.394857Z","iopub.execute_input":"2022-05-30T23:19:22.397254Z","iopub.status.idle":"2022-05-30T23:19:22.420297Z","shell.execute_reply.started":"2022-05-30T23:19:22.39721Z","shell.execute_reply":"2022-05-30T23:19:22.419295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatentModel(torch.nn.Module):\n    def __init__(self):\n        super(PatentModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.model_name)\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        \n        self.transformer = AutoModel.from_pretrained(CFG.model_name, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, ids, mask):\n        transformer_out = self.transformer(input_ids=ids, attention_mask=mask)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        logits = self.output(last_hidden_states)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.426743Z","iopub.execute_input":"2022-05-30T23:19:22.429427Z","iopub.status.idle":"2022-05-30T23:19:22.446948Z","shell.execute_reply.started":"2022-05-30T23:19:22.429384Z","shell.execute_reply":"2022-05-30T23:19:22.445998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(df, fold=0, seed=42):    \n\n    # originalから追加\n    global oof_df\n    \n    best_score = 0\n    \n    seed_everything(seed)\n    \n    df_train=df.loc[df.fold!=fold].reset_index(drop=True)\n    df_valid=df.loc[df.fold==fold].reset_index(drop=True)\n    \n    valid_targets = df_valid['score'].values\n\n    train_dataset = PhraseDataset(\n        df_train.anchor.values,\n        df_train.target.values,\n        df_train.context.values,\n        df_train.score.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    valid_dataset = PhraseDataset(\n        df_valid.anchor.values,\n        df_valid.target.values,\n        df_valid.context.values,\n        df_valid.score.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    \n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    model = PatentModel()\n    model.to(device)\n    \n    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\"]\n    \n    optimizer_parameters = [\n            {\n                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.01,\n            },\n            {\n                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n    \n    optimizer = AdamW(optimizer_parameters, lr=CFG.lr, weight_decay=CFG.weight_decay)\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1\n    )\n        \n    for epoch in range(CFG.epochs): \n        start_time = time.time()\n        \n        train_loss = train_fn(model, train_loader, optimizer, scheduler, loss_fn=criterion, fp16=CFG.fp16)\n        valid_loss, valid_preds = valid_fn(model, valid_loader, loss_fn=criterion)\n        score = stats.pearsonr(valid_targets, valid_preds)[0]\n        elapsed = time.time() - start_time\n        \n        print(f'Epoch {epoch+1} - avg_train_loss: {train_loss:.4f}  avg_val_loss: {valid_loss:.4f}')\n        print(f'Epoch {epoch+1} - pearson score: {score:.4f} time: {elapsed:.0f}s')\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                       f\"[fold{fold}] avg_train_loss\": train_loss, \n                       f\"[fold{fold}] avg_val_loss\": valid_loss,\n                       f\"[fold{fold}] score\": score})\n        print(best_score, score)\n        if best_score < score:\n            print(f'Validation Score Improved {best_score} ---> :{score}: {best_score:.4f} Save Model!!!')\n            best_score = score\n            torch.save(model.state_dict(), f'{CFG.model_name.replace(\"-\", \"_\")}_patent_model_{fold}.pth')\n                \n    preds = valid_preds.reshape(-1)\n    df_valid[\"pred\"] = preds\n    oof_df = pd.concat([oof_df, df_valid])\n    \n    # oof_preds = np.concatenate((valid_preds.reshape(-1, 1), valid_targets.reshape(-1, 1)), axis=1)\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    # return oof_preds\n    return oof_df","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.453504Z","iopub.execute_input":"2022-05-30T23:19:22.45584Z","iopub.status.idle":"2022-05-30T23:19:22.487885Z","shell.execute_reply.started":"2022-05-30T23:19:22.455799Z","shell.execute_reply":"2022-05-30T23:19:22.486802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train, seed):\n    \n    # predictions = []\n    global oof_df  \n    \n    for f in range(CFG.n_folds):   \n        oof_df = run_fold(train, f, seed)\n        # preds = run_fold(train, f, seed)\n        # predictions.append(preds)\n        \n    # oof_preds = np.concatenate(predictions)  \n        \n    # return oof_preds\n    return oof_df","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.494785Z","iopub.execute_input":"2022-05-30T23:19:22.497111Z","iopub.status.idle":"2022-05-30T23:19:22.504483Z","shell.execute_reply.started":"2022-05-30T23:19:22.497067Z","shell.execute_reply":"2022-05-30T23:19:22.503617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# originalから追加\n# CVの計算（相関係数）\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.reshape(len(predictions))\n    file = open(\"CV_pearson.txt\", \"w\")\n    corr = np.corrcoef(predictions, labels)[0][1]\n    file.write(corr.astype(\"str\"))\n    file.close\n    return {\n        'pearson': corr\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.51008Z","iopub.execute_input":"2022-05-30T23:19:22.512319Z","iopub.status.idle":"2022-05-30T23:19:22.520731Z","shell.execute_reply.started":"2022-05-30T23:19:22.512277Z","shell.execute_reply":"2022-05-30T23:19:22.519904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n#     oof_preds =  train_model(df, CFG.seed) \n#     np.save('patent_oof.npy', oof_preds)\n    \n    # originalから追加\n    oof_df = pd.DataFrame()\n    oof_df = train_model(df, CFG.seed)\n    oof_df.reset_index(drop=True).to_csv(\"oof_df.csv\")\n\n    # originalから追加\n    predictions = oof_df['pred'].values\n    label = oof_df['score'].values\n    eval_pred = predictions, label\n    compute_metrics(eval_pred)    ","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:19:22.526872Z","iopub.execute_input":"2022-05-30T23:19:22.529824Z","iopub.status.idle":"2022-05-31T08:24:48.184264Z","shell.execute_reply.started":"2022-05-30T23:19:22.529781Z","shell.execute_reply":"2022-05-31T08:24:48.178585Z"},"trusted":true},"execution_count":null,"outputs":[]}]}