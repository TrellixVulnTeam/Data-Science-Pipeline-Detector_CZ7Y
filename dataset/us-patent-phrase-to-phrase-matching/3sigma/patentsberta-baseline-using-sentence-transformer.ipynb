{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/sentencetransformer/sentence-transformers /tmp/st\n!pip install /tmp/st --quiet","metadata":{"execution":{"iopub.status.busy":"2022-05-14T11:47:38.182577Z","iopub.execute_input":"2022-05-14T11:47:38.183202Z","iopub.status.idle":"2022-05-14T11:47:53.781737Z","shell.execute_reply.started":"2022-05-14T11:47:38.183107Z","shell.execute_reply":"2022-05-14T11:47:53.780878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import some libraries and set seed","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, losses, models, util\nfrom sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\nfrom sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\nfrom sentence_transformers.readers import InputExample\nfrom sentence_transformers.cross_encoder import CrossEncoder\nimport torch\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport os\nimport re\nimport numpy as np\nimport math\nimport random\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T12:14:49.525212Z","iopub.execute_input":"2022-05-14T12:14:49.525504Z","iopub.status.idle":"2022-05-14T12:14:49.557404Z","shell.execute_reply.started":"2022-05-14T12:14:49.525472Z","shell.execute_reply":"2022-05-14T12:14:49.556715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import data and combine the cpc-data as shown in https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/314306","metadata":{}},{"cell_type":"code","source":"DEBUG_mode = True\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = ''\nif DEBUG_mode:\n    train = pd.read_csv(INPUT_DIR+'train.csv', nrows=1000)\nelse:\n    train = pd.read_csv(INPUT_DIR + 'train.csv')\ntest = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"train.shape: {train.shape}\")\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\n\n\n\n# ====================================================\n# CPC Data\n# ====================================================\ndef get_cpc_texts():\n    contexts = []\n    pattern = '[A-Z]\\d+'\n    for file_name in os.listdir('../input/cpc-data/CPCSchemeXML202105'):\n        result = re.findall(pattern, file_name)\n        if result:\n            contexts.append(result)\n    contexts = sorted(set(sum(contexts, [])))\n    results = {}\n    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n        with open(f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt', encoding='utf-8') as f:\n            s = f.read()\n        pattern = f'{cpc}\\t\\t.+'\n        result = re.findall(pattern, s)\n        cpc_result = result[0].lstrip(pattern)\n        for context in [c for c in contexts if c[0] == cpc]:\n            pattern = f'{context}\\t\\t.+'\n            result = re.findall(pattern, s)\n            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n    return results\n\n\ncpc_texts = get_cpc_texts()\ntorch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\ntrain['context_text'] = train['context'].map(cpc_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T12:54:16.052657Z","iopub.execute_input":"2022-05-14T12:54:16.053309Z","iopub.status.idle":"2022-05-14T12:54:16.561301Z","shell.execute_reply.started":"2022-05-14T12:54:16.053275Z","shell.execute_reply":"2022-05-14T12:54:16.560614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"construt the imputs for model\n\ninput1 is anchor + context\n\ninput2 is target + context","metadata":{}},{"cell_type":"code","source":"train['text_a'] = 'anchor:' + train['anchor'] + '[SEP]' + 'context:' + train['context_text']\ntrain['text_b'] = 'target:' + train['target'] + '[SEP]' + 'context:' + train['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-05-14T12:54:18.94479Z","iopub.execute_input":"2022-05-14T12:54:18.945318Z","iopub.status.idle":"2022-05-14T12:54:18.95359Z","shell.execute_reply.started":"2022-05-14T12:54:18.945281Z","shell.execute_reply":"2022-05-14T12:54:18.952825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CV: groupy by anchor","metadata":{}},{"cell_type":"code","source":"anchors = train.anchor.unique()\nnp.random.shuffle(anchors)\nval_prop = 0.20\nval_sz = int(len(anchors)*val_prop)\nval_anchors_0 = anchors[:val_sz]\nval_anchors_1 = anchors[val_sz:2*val_sz]\nval_anchors_2 = anchors[2*val_sz:3*val_sz]\nval_anchors_3 = anchors[3*val_sz:4*val_sz]\nval_anchors_4 = anchors[4*val_sz:]\nval_anchors = [val_anchors_0,val_anchors_1,val_anchors_2,val_anchors_3,val_anchors_4]\n\nk_fold_score = []\n\ntrain_batch_size = 8\nfor fold in range(5):\n    is_val = np.isin(train.anchor, val_anchors[fold])\n    idxs = np.arange(len(train))\n    val_idxs = idxs[is_val]\n    trn_idxs = idxs[~is_val]\n    print(train.iloc[trn_idxs].score.mean(), train.iloc[val_idxs].score.mean())\n    \n    train_samples = []\n    for idx, row in train.iloc[trn_idxs].iterrows():\n        train_samples.append(\n        InputExample(texts=[row['text_a'], row['text_b']], label=row['score'])\n        )\n    dev_samples = []\n    for idx, row in train.iloc[val_idxs].iterrows():\n        dev_samples.append(\n        InputExample(texts=[row['text_a'], row['text_b']], label=row['score'])\n        )\n    \n    model = SentenceTransformer('AI-Growth-Lab/PatentSBERTa')\n    \n    train_dataset = SentencesDataset(train_samples, model)\n    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n    train_loss = losses.CosineSimilarityLoss(model=model)\n    \n    evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n\n    # Train the model\n    model.fit(train_objectives=[(train_dataloader, train_loss)],\n              evaluator=evaluator,\n              epochs=5,\n              evaluation_steps=math.ceil(len(train_dataloader)),\n              output_path=f'fold_{fold}')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T13:06:37.504904Z","iopub.execute_input":"2022-05-14T13:06:37.505169Z","iopub.status.idle":"2022-05-14T13:07:20.590432Z","shell.execute_reply.started":"2022-05-14T13:06:37.505138Z","shell.execute_reply":"2022-05-14T13:07:20.589729Z"},"trusted":true},"execution_count":null,"outputs":[]}]}