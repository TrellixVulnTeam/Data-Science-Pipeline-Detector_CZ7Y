{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Ensemble of the three notebooks.Please upvote the original notebooks:\n\n**1. Deberta v3 large**\n[PPPM / Deberta-v3-large baseline [inference]](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n\n**2. Roberta-large**\n[PatentPhrase RoBERTa Inference](https://www.kaggle.com/code/santhoshkumarv/patentphrase-roberta-inference-lb-0-814)\n\nAnd use ensemble strategy from:\n[Tips for ensambling](https://www.kaggle.com/code/jellyz9/tips-for-ensambling)","metadata":{}},{"cell_type":"markdown","source":"## 1.Deberta v3 large","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:35:18.214571Z","iopub.execute_input":"2022-05-09T14:35:18.21522Z","iopub.status.idle":"2022-05-09T14:35:18.247178Z","shell.execute_reply.started":"2022-05-09T14:35:18.215128Z","shell.execute_reply":"2022-05-09T14:35:18.246166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-v3-large-baseline-w-w-b-train/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:35:18.249238Z","iopub.execute_input":"2022-05-09T14:35:18.249865Z","iopub.status.idle":"2022-05-09T14:35:18.256869Z","shell.execute_reply.started":"2022-05-09T14:35:18.24982Z","shell.execute_reply":"2022-05-09T14:35:18.255857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport time\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\n\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:02.114403Z","iopub.execute_input":"2022-05-09T14:38:02.115054Z","iopub.status.idle":"2022-05-09T14:38:35.995127Z","shell.execute_reply.started":"2022-05-09T14:38:02.115019Z","shell.execute_reply":"2022-05-09T14:38:35.993976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:35.997765Z","iopub.execute_input":"2022-05-09T14:38:35.998402Z","iopub.status.idle":"2022-05-09T14:38:36.012758Z","shell.execute_reply.started":"2022-05-09T14:38:35.998354Z","shell.execute_reply":"2022-05-09T14:38:36.011745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\nlabels = oof_df['score'].values\npreds = oof_df['pred'].values\nscore = get_score(labels, preds)\nLOGGER.info(f'CV Score: {score:<.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:36.013962Z","iopub.execute_input":"2022-05-09T14:38:36.014652Z","iopub.status.idle":"2022-05-09T14:38:36.153217Z","shell.execute_reply.started":"2022-05-09T14:38:36.014601Z","shell.execute_reply":"2022-05-09T14:38:36.151862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:46.763137Z","iopub.execute_input":"2022-05-09T14:38:46.763433Z","iopub.status.idle":"2022-05-09T14:38:46.815841Z","shell.execute_reply.started":"2022-05-09T14:38:46.763401Z","shell.execute_reply":"2022-05-09T14:38:46.814673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:48.454921Z","iopub.execute_input":"2022-05-09T14:38:48.455598Z","iopub.status.idle":"2022-05-09T14:38:48.48344Z","shell.execute_reply.started":"2022-05-09T14:38:48.455558Z","shell.execute_reply":"2022-05-09T14:38:48.482509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:49.534256Z","iopub.execute_input":"2022-05-09T14:38:49.534603Z","iopub.status.idle":"2022-05-09T14:38:49.553463Z","shell.execute_reply.started":"2022-05-09T14:38:49.534573Z","shell.execute_reply":"2022-05-09T14:38:49.55062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:50.366632Z","iopub.execute_input":"2022-05-09T14:38:50.370029Z","iopub.status.idle":"2022-05-09T14:38:51.339409Z","shell.execute_reply.started":"2022-05-09T14:38:50.369984Z","shell.execute_reply":"2022-05-09T14:38:51.338349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:51.741255Z","iopub.execute_input":"2022-05-09T14:38:51.742191Z","iopub.status.idle":"2022-05-09T14:38:51.75207Z","shell.execute_reply.started":"2022-05-09T14:38:51.742139Z","shell.execute_reply":"2022-05-09T14:38:51.75083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:52.772386Z","iopub.execute_input":"2022-05-09T14:38:52.772668Z","iopub.status.idle":"2022-05-09T14:38:52.790914Z","shell.execute_reply.started":"2022-05-09T14:38:52.772638Z","shell.execute_reply":"2022-05-09T14:38:52.789546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:53.554309Z","iopub.execute_input":"2022-05-09T14:38:53.555118Z","iopub.status.idle":"2022-05-09T14:38:53.562636Z","shell.execute_reply.started":"2022-05-09T14:38:53.555067Z","shell.execute_reply":"2022-05-09T14:38:53.561325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npred1 = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:38:54.448202Z","iopub.execute_input":"2022-05-09T14:38:54.449227Z","iopub.status.idle":"2022-05-09T14:41:19.494874Z","shell.execute_reply.started":"2022-05-09T14:38:54.449191Z","shell.execute_reply":"2022-05-09T14:41:19.493907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Roberta-large","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:44:59.535429Z","iopub.execute_input":"2022-05-09T14:44:59.536158Z","iopub.status.idle":"2022-05-09T14:44:59.545808Z","shell.execute_reply.started":"2022-05-09T14:44:59.536112Z","shell.execute_reply":"2022-05-09T14:44:59.544794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers: Optional[int] = 4\n    config_path: Optional[str] = '../input/robertalarge'\n    model_path: Optional[str] = '../input/phrase-matching-roberta-training-pytorch-wandb'\n    model_name: Optional[str] = 'roberta-large'\n    batch_size: Optional[int] = 32\n    max_len: Optional[int] = 128\n    seed: Optional[int] = 2019\n    num_targets: Optional[int] = 1\n    n_folds: Optional[int] = 5\n    tokenizer = AutoTokenizer.from_pretrained('../input/robertalarge')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:00.613082Z","iopub.execute_input":"2022-05-09T14:45:00.613695Z","iopub.status.idle":"2022-05-09T14:45:00.929471Z","shell.execute_reply.started":"2022-05-09T14:45:00.613654Z","shell.execute_reply":"2022-05-09T14:45:00.928259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/us-patent-phrase-to-phrase-matching'\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:15.714052Z","iopub.execute_input":"2022-05-09T14:45:15.714443Z","iopub.status.idle":"2022-05-09T14:45:15.73231Z","shell.execute_reply.started":"2022-05-09T14:45:15.714406Z","shell.execute_reply":"2022-05-09T14:45:15.731312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n    \ntest.context = test.context.apply(lambda x: context_mapping[x[0]])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:16.896445Z","iopub.execute_input":"2022-05-09T14:45:16.896773Z","iopub.status.idle":"2022-05-09T14:45:16.905751Z","shell.execute_reply.started":"2022-05-09T14:45:16.896729Z","shell.execute_reply":"2022-05-09T14:45:16.904392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n\n        encoded_text = CFG.tokenizer.encode_plus(\n            context + \" \" + anchor,\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:17.822416Z","iopub.execute_input":"2022-05-09T14:45:17.823295Z","iopub.status.idle":"2022-05-09T14:45:17.835302Z","shell.execute_reply.started":"2022-05-09T14:45:17.823261Z","shell.execute_reply":"2022-05-09T14:45:17.833451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_fn(model, test_loader):  \n    model.eval()\n    predictions = []\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for data in tk0:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        with torch.no_grad():\n            output = model(ids, mask)\n        predictions.append(output.sigmoid().detach().cpu().numpy())\n        \n    return np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:18.397112Z","iopub.execute_input":"2022-05-09T14:45:18.397428Z","iopub.status.idle":"2022-05-09T14:45:18.407956Z","shell.execute_reply.started":"2022-05-09T14:45:18.397397Z","shell.execute_reply":"2022-05-09T14:45:18.40467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatentModel(torch.nn.Module):\n    def __init__(self):\n        super(PatentModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.config_path)\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        \n        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, ids, mask):\n        transformer_out = self.transformer(input_ids=ids, attention_mask=mask)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:19.340713Z","iopub.execute_input":"2022-05-09T14:45:19.341056Z","iopub.status.idle":"2022-05-09T14:45:19.355228Z","shell.execute_reply.started":"2022-05-09T14:45:19.341016Z","shell.execute_reply":"2022-05-09T14:45:19.353311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(test, fold, seed=42):    \n    \n    seed_everything(seed)\n    \n    test_dataset = PhraseDataset(\n        test.anchor.values,\n        test.target.values,\n        test.context.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    test_loader = DataLoader(test_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    model = PatentModel()\n    \n    model.load_state_dict(\n        torch.load(f'{CFG.model_path}/{CFG.model_name.replace(\"-\",\"_\")}_patent_model_{fold}.pth',\n        map_location=torch.device('cuda')\n        )\n    )\n    \n    model.to(device)\n\n    preds = inference_fn(model, test_loader)\n    \n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:19.816806Z","iopub.execute_input":"2022-05-09T14:45:19.817404Z","iopub.status.idle":"2022-05-09T14:45:19.828716Z","shell.execute_reply.started":"2022-05-09T14:45:19.817368Z","shell.execute_reply":"2022-05-09T14:45:19.827557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_model(test, seed):\n    \n    predictions = []\n    \n    for f in range(CFG.n_folds):    \n        preds = run_fold(test, f, seed) \n        predictions.append(preds)\n        \n    test_preds = np.column_stack(predictions)\n        \n    return test_preds","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:21.261488Z","iopub.execute_input":"2022-05-09T14:45:21.265564Z","iopub.status.idle":"2022-05-09T14:45:21.277443Z","shell.execute_reply.started":"2022-05-09T14:45:21.265481Z","shell.execute_reply":"2022-05-09T14:45:21.275745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    pred2 =  np.mean(inference_model(test, CFG.seed),axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:45:22.589686Z","iopub.execute_input":"2022-05-09T14:45:22.590465Z","iopub.status.idle":"2022-05-09T14:47:31.601847Z","shell.execute_reply.started":"2022-05-09T14:45:22.590425Z","shell.execute_reply":"2022-05-09T14:47:31.600546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"w1 = 0.66\nw2 = 0.33","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:48:18.236714Z","iopub.execute_input":"2022-05-09T14:48:18.237032Z","iopub.status.idle":"2022-05-09T14:48:18.243091Z","shell.execute_reply.started":"2022-05-09T14:48:18.236994Z","shell.execute_reply":"2022-05-09T14:48:18.241788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nMMscaler = MinMaxScaler()\n\npred1_mm = MMscaler.fit_transform(pred1.reshape(-1,1)).reshape(-1)\npred2_mm = MMscaler.fit_transform(pred2.reshape(-1,1)).reshape(-1)\n\nfinal_predictions =  pred1_mm * w1 + pred2_mm * w2","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:48:28.810399Z","iopub.execute_input":"2022-05-09T14:48:28.811194Z","iopub.status.idle":"2022-05-09T14:48:28.822089Z","shell.execute_reply.started":"2022-05-09T14:48:28.81116Z","shell.execute_reply":"2022-05-09T14:48:28.820109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub['score'] = final_predictions\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:48:31.189664Z","iopub.execute_input":"2022-05-09T14:48:31.190168Z","iopub.status.idle":"2022-05-09T14:48:31.20367Z","shell.execute_reply.started":"2022-05-09T14:48:31.190129Z","shell.execute_reply":"2022-05-09T14:48:31.202582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T14:48:31.943161Z","iopub.execute_input":"2022-05-09T14:48:31.943489Z","iopub.status.idle":"2022-05-09T14:48:31.95676Z","shell.execute_reply.started":"2022-05-09T14:48:31.94346Z","shell.execute_reply":"2022-05-09T14:48:31.954952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}