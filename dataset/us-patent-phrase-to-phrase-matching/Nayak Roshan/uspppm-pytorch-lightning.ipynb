{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torchmetrics import MeanSquaredError\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:18.28249Z","iopub.execute_input":"2022-04-28T06:57:18.2829Z","iopub.status.idle":"2022-04-28T06:57:22.862875Z","shell.execute_reply.started":"2022-04-28T06:57:18.282869Z","shell.execute_reply":"2022-04-28T06:57:22.862139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv')\ntest_data = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')\ndata.shape, test_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:22.864575Z","iopub.execute_input":"2022-04-28T06:57:22.864847Z","iopub.status.idle":"2022-04-28T06:57:22.955251Z","shell.execute_reply.started":"2022-04-28T06:57:22.864803Z","shell.execute_reply":"2022-04-28T06:57:22.954467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:22.956676Z","iopub.execute_input":"2022-04-28T06:57:22.956931Z","iopub.status.idle":"2022-04-28T06:57:22.975766Z","shell.execute_reply.started":"2022-04-28T06:57:22.956897Z","shell.execute_reply":"2022-04-28T06:57:22.975111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codes = pd.read_csv('../input/cpc-codes/titles.csv')\ncodes = codes.rename(columns = {\"code\" : \"context\"})\ncodes.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:22.977428Z","iopub.execute_input":"2022-04-28T06:57:22.977608Z","iopub.status.idle":"2022-04-28T06:57:23.826179Z","shell.execute_reply.started":"2022-04-28T06:57:22.977587Z","shell.execute_reply":"2022-04-28T06:57:23.825371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.merge(data,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")\ntest_data=pd.merge(test_data,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:23.827721Z","iopub.execute_input":"2022-04-28T06:57:23.827984Z","iopub.status.idle":"2022-04-28T06:57:24.031116Z","shell.execute_reply.started":"2022-04-28T06:57:23.827948Z","shell.execute_reply":"2022-04-28T06:57:24.030344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:24.032522Z","iopub.execute_input":"2022-04-28T06:57:24.03278Z","iopub.status.idle":"2022-04-28T06:57:24.045205Z","shell.execute_reply.started":"2022-04-28T06:57:24.032745Z","shell.execute_reply":"2022-04-28T06:57:24.044312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration Class","metadata":{}},{"cell_type":"code","source":"class CFG:\n    val_size = 0.20\n    max_len = 192\n    model_name = '../input/bert-for-patent/bert-for-patents'\n    batch_size = 16\n    epochs = 5\n    lr = 2e-5\n    max_lr = 1e-3\n    steps_per_epoch = None\n    pct_start = 0.3\n    div_factor = 1e+2\n    final_div_factor = 1e+4\n    accumulate = 1\n    patience = 3\n    monitor = 'val_loss'\n    seed = 42\n    debug = False\n    dropout = 0.2","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:24.04677Z","iopub.execute_input":"2022-04-28T06:57:24.047323Z","iopub.status.idle":"2022-04-28T06:57:24.054209Z","shell.execute_reply.started":"2022-04-28T06:57:24.047284Z","shell.execute_reply":"2022-04-28T06:57:24.05347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class PhraseSimilarityDataset(Dataset):\n    \n    def __init__(self, df, tokenizer):\n        self.df = df\n        self.tokenizer = tokenizer\n        \n        self.tokenizer_params = {\n            'max_length' : CFG.max_len,\n            'padding' : 'max_length',\n            'truncation' : True\n        }\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        anchor = self.df.anchor.iloc[index].lower()\n        target = self.df.target.iloc[index].lower()\n        title = self.df.title.iloc[index].lower()\n        \n        tokens = self.tokenizer(anchor + '[SEP]' + target + '[SEP]' + title, **self.tokenizer_params)\n        \n        score = torch.tensor(self.df.score.iloc[index], dtype=torch.float32)\n        \n        return (\n            np.array(tokens['input_ids']),\n            np.array(tokens['attention_mask']),\n            score\n        )\n    \nclass PhraseSimilarityTestset(Dataset):\n    \n    def __init__(self, df, tokenizer):\n        self.df = df\n        self.tokenizer = tokenizer\n        \n        self.tokenizer_params = {\n            'max_length' : CFG.max_len,\n            'padding' : 'max_length',\n            'truncation' : True\n        }\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        anchor = self.df.anchor.iloc[index].lower()\n        target = self.df.target.iloc[index].lower()\n        title = self.df.title.iloc[index].lower()\n        \n        tokens = self.tokenizer(anchor + '[SEP]' + target + '[SEP]' + title, **self.tokenizer_params)\n        \n        return (\n            np.array(tokens['input_ids']),\n            np.array(tokens['attention_mask']),\n        )","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:24.055573Z","iopub.execute_input":"2022-04-28T06:57:24.05596Z","iopub.status.idle":"2022-04-28T06:57:24.068945Z","shell.execute_reply.started":"2022-04-28T06:57:24.055853Z","shell.execute_reply":"2022-04-28T06:57:24.068289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Class","metadata":{}},{"cell_type":"markdown","source":"### Model Architecture\n\nhttps://www.kaggle.com/code/tianzijing/pppm-train-deberta-large-baseline-with-pl","metadata":{}},{"cell_type":"code","source":"class PhraseSimilarityModelImpl(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        self.model_config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n        self.model = AutoModel.from_pretrained(model_name, config=self.model_config)\n        self.bert = AutoModel.from_pretrained(model_name)\n        self.head = nn.Linear(1024, 1, bias=True)\n        \n        self.attention = nn.Sequential(\n            nn.Linear(self.model_config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        \n        self.dropout_0 = nn.Dropout(CFG.dropout / 2.)\n        self.dropout_1 = nn.Dropout(CFG.dropout / 1.5)\n        self.dropout_2 = nn.Dropout(CFG.dropout)\n        self.dropout_3 = nn.Dropout(CFG.dropout * 1.5)\n        self.dropout_4 = nn.Dropout(CFG.dropout * 2.)\n    \n    def forward(self, text, mask):\n        feats = self.bert(text, mask)\n        last_hidden_states, pooler_output = feats[0], feats[1]\n        weights = self.attention(last_hidden_states)\n#         feats = torch.sum(feats[0], 1)/feats[0].shape[1]\n        feats = torch.sum(weights * last_hidden_states, dim=1)\n        output_0 = self.head(self.dropout_0(feats))\n        output_1 = self.head(self.dropout_1(feats))\n        output_2 = self.head(self.dropout_2(feats))\n        output_3 = self.head(self.dropout_3(feats))\n        output_4 = self.head(self.dropout_4(feats))\n        return (output_0 + output_1 + output_2 + output_3 + output_4) / 5\n\nclass PhraseSimilarityModel(pl.LightningModule):\n    \n    def __init__(self, model, criterion, metric):\n        super(PhraseSimilarityModel, self).__init__()\n        self.model = model\n        self.criterion = criterion\n        self.metric = metric\n        \n    def forward(self, text, mask):\n        return self.model(text, mask)\n    \n    def configure_optimizers(self):\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=CFG.lr)\n        return self.optimizer\n    \n    def training_step(self, batch, batch_idx):\n        ids, mask = batch[0], batch[1]\n        preds = self.model(ids, mask)\n        loss = self.criterion(preds.squeeze(1), batch[2])\n        rmse = self.metric(preds.squeeze(1), batch[2])\n        logs = {'train_loss': loss, 'train_error': rmse, 'lr': self.optimizer.param_groups[0]['lr']}\n        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        ids, mask = batch[0], batch[1]\n        preds = self.model(ids, mask)\n        loss = self.criterion(preds.squeeze(1), batch[2])\n        rmse = self.metric(preds.squeeze(1), batch[2])\n        logs = {'val_loss': loss, 'val_error': rmse}\n        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def predict_step(self, batch, batch_idx):\n        ids, mask = batch[0], batch[1]\n        preds = self.model(ids, mask)\n        return preds\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:26.711786Z","iopub.execute_input":"2022-04-28T06:57:26.712233Z","iopub.status.idle":"2022-04-28T06:57:26.73204Z","shell.execute_reply.started":"2022-04-28T06:57:26.712195Z","shell.execute_reply":"2022-04-28T06:57:26.731352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.debug == True:\n    train_data = train_data.iloc[:200]\n    \nscores = train_data.score.values\ntrain_data.drop('score', inplace=True, axis=1)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, scores, \n                                                                  stratify=scores, \n                                                                  test_size=CFG.val_size, \n                                                                  random_state=CFG.seed)\ntrain_data['score'] = train_labels\nval_data['score'] = val_labels\n\ntokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\ntrain_dataset = PhraseSimilarityDataset(train_data, tokenizer)\nval_dataset = PhraseSimilarityDataset(val_data, tokenizer)\ntest_dataset = PhraseSimilarityTestset(test_data, tokenizer)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:26.941527Z","iopub.execute_input":"2022-04-28T06:57:26.941986Z","iopub.status.idle":"2022-04-28T06:57:27.139909Z","shell.execute_reply.started":"2022-04-28T06:57:26.941954Z","shell.execute_reply":"2022-04-28T06:57:27.13922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.steps_per_epoch = len(train_dataloader)\nCFG.steps_per_epoch","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:27.251084Z","iopub.execute_input":"2022-04-28T06:57:27.251392Z","iopub.status.idle":"2022-04-28T06:57:27.257126Z","shell.execute_reply.started":"2022-04-28T06:57:27.251361Z","shell.execute_reply":"2022-04-28T06:57:27.256271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = CSVLogger(save_dir='./', name=CFG.model_name.split('/')[-1]+'_log')\nlogger.log_hyperparams(CFG.__dict__)\ncheckpoint_callback = ModelCheckpoint(monitor=CFG.monitor,\n                                      save_top_k=1,\n                                      save_last=True,\n                                      save_weights_only=True,\n                                      filename='{epoch:02d}-{valid_loss:.4f}-{valid_acc:.4f}',\n                                      verbose=False,\n                                      mode='min')\nearly_stop_callback = EarlyStopping(monitor=CFG.monitor, \n                                    patience=CFG.patience, \n                                    verbose=False, \n                                    mode=\"min\")\n\ntrainer = Trainer(\n    max_epochs=CFG.epochs,\n    gpus=[0],\n    accumulate_grad_batches=CFG.accumulate,\n    callbacks=[checkpoint_callback, early_stop_callback], \n    logger=logger,\n    weights_summary='top',\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:28.220985Z","iopub.execute_input":"2022-04-28T06:57:28.221237Z","iopub.status.idle":"2022-04-28T06:57:28.321381Z","shell.execute_reply.started":"2022-04-28T06:57:28.221207Z","shell.execute_reply":"2022-04-28T06:57:28.320726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PhraseSimilarityModelImpl(CFG.model_name)\ncriterion = nn.HuberLoss(reduction='mean', delta=1.0)\nmetric = MeanSquaredError()\ndriver = PhraseSimilarityModel(model, criterion, metric)\n\ntrainer.fit(driver, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T06:57:29.097196Z","iopub.execute_input":"2022-04-28T06:57:29.097452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n\ntrain_acc = metrics['train_error'].dropna().reset_index(drop=True)\nvalid_acc = metrics['val_error'].dropna().reset_index(drop=True)\n    \nfig = plt.figure(figsize=(7, 6))\nplt.grid(True)\nplt.plot(train_acc, color=\"r\", marker=\"o\", label='train/error')\nplt.plot(valid_acc, color=\"b\", marker=\"x\", label='valid/error')\nplt.ylabel('Error', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='lower right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}/acc.png')\n\ntrain_loss = metrics['train_loss'].dropna().reset_index(drop=True)\nvalid_loss = metrics['val_loss'].dropna().reset_index(drop=True)\n\nfig = plt.figure(figsize=(7, 6))\nplt.grid(True)\nplt.plot(train_loss, color=\"r\", marker=\"o\", label='train/loss')\nplt.plot(valid_loss, color=\"b\", marker=\"x\", label='valid/loss')\nplt.ylabel('Loss', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='upper right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}/loss.png')\\\n\nlr = metrics['lr'].dropna().reset_index(drop=True)\n\nfig = plt.figure(figsize=(7, 6))\nplt.grid(True)\nplt.plot(lr, color=\"g\", marker=\"o\", label='learning rate')\nplt.ylabel('LR', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='upper right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}/lr.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:37:48.335153Z","iopub.status.idle":"2022-04-21T18:37:48.336884Z","shell.execute_reply.started":"2022-04-21T18:37:48.336544Z","shell.execute_reply":"2022-04-21T18:37:48.336576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:37:48.338581Z","iopub.status.idle":"2022-04-21T18:37:48.339445Z","shell.execute_reply.started":"2022-04-21T18:37:48.339141Z","shell.execute_reply":"2022-04-21T18:37:48.339172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor batch in predictions:\n    preds += batch.squeeze(1).tolist()\n\nsubmission_csv = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')\nsubmission_csv['score'] = preds\nsubmission_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T08:47:04.814261Z","iopub.execute_input":"2022-04-14T08:47:04.814945Z","iopub.status.idle":"2022-04-14T08:47:04.837226Z","shell.execute_reply.started":"2022-04-14T08:47:04.814911Z","shell.execute_reply":"2022-04-14T08:47:04.836455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_csv.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T08:47:07.530441Z","iopub.execute_input":"2022-04-14T08:47:07.531118Z","iopub.status.idle":"2022-04-14T08:47:07.538327Z","shell.execute_reply.started":"2022-04-14T08:47:07.53108Z","shell.execute_reply":"2022-04-14T08:47:07.53755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}