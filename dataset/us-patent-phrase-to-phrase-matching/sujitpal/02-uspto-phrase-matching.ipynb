{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport shutil\nimport torch\n\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.metrics import (\n    accuracy_score, classification_report, \n    ConfusionMatrixDisplay, confusion_matrix)\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    get_scheduler)\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-17T03:46:53.86474Z","iopub.execute_input":"2022-05-17T03:46:53.864996Z","iopub.status.idle":"2022-05-17T03:47:01.744281Z","shell.execute_reply.started":"2022-05-17T03:46:53.864926Z","shell.execute_reply":"2022-05-17T03:47:01.743566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"../input/us-patent-phrase-to-phrase-matching/\"\n\nTRAIN_FILE = os.path.join(DATA_DIR, \"train.csv\")\nTEST_FILE = os.path.join(DATA_DIR, \"test.csv\")\nSUBMISSION_FILE = \"./submission.csv\"\n\nMODEL_ID = \"microsoft/deberta-v3-xsmall\"\nMODEL_DIR = \"deberta-patent-matching-02\"\n\nBATCH_SIZE = 32\n\nLEARNING_RATE = 5e-5\nWEIGHT_DECAY = 1e-2\nNUM_EPOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:01.746176Z","iopub.execute_input":"2022-05-17T03:47:01.746438Z","iopub.status.idle":"2022-05-17T03:47:01.751579Z","shell.execute_reply.started":"2022-05-17T03:47:01.746403Z","shell.execute_reply":"2022-05-17T03:47:01.750871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset\n\nQuick look at the dataset provided.\n\nWe can't use the test data for validating or evaluation, since there are no scores attached. We will split our training 70/10/20 for this.\n\nWe will use our trained model against `test.csv` to generate `submission.csv` consisting of (ID, score) pairs.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_FILE)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:01.752837Z","iopub.execute_input":"2022-05-17T03:47:01.753317Z","iopub.status.idle":"2022-05-17T03:47:01.849711Z","shell.execute_reply.started":"2022-05-17T03:47:01.753256Z","shell.execute_reply":"2022-05-17T03:47:01.848995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(TEST_FILE)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:01.851139Z","iopub.execute_input":"2022-05-17T03:47:01.851573Z","iopub.status.idle":"2022-05-17T03:47:01.872201Z","shell.execute_reply.started":"2022-05-17T03:47:01.851536Z","shell.execute_reply":"2022-05-17T03:47:01.871319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_df), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:01.874644Z","iopub.execute_input":"2022-05-17T03:47:01.874894Z","iopub.status.idle":"2022-05-17T03:47:01.88002Z","shell.execute_reply.started":"2022-05-17T03:47:01.87486Z","shell.execute_reply":"2022-05-17T03:47:01.87938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Labels\n\nGiven that the scores seem like discrete points in a (0, 1) scale, it might make sense to treat this as a classification problem.","metadata":{}},{"cell_type":"code","source":"scores = sorted(list(set(train_df[\"score\"].values.tolist())))\nscore2label = {s:i for i, s in enumerate(scores)}\nscore2label","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:01.881323Z","iopub.execute_input":"2022-05-17T03:47:01.881788Z","iopub.status.idle":"2022-05-17T03:47:01.896911Z","shell.execute_reply.started":"2022-05-17T03:47:01.881753Z","shell.execute_reply":"2022-05-17T03:47:01.896023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Raw Dataset","metadata":{}},{"cell_type":"code","source":"train_df[\"labels\"] = train_df.apply(lambda x: score2label[x[\"score\"]], axis=1)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:01.898372Z","iopub.execute_input":"2022-05-17T03:47:01.898638Z","iopub.status.idle":"2022-05-17T03:47:02.33789Z","shell.execute_reply.started":"2022-05-17T03:47:01.898602Z","shell.execute_reply":"2022-05-17T03:47:02.337158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, testval_df = train_test_split(train_df, test_size=0.3)\nval_df, test_df = train_test_split(testval_df, test_size=0.3)\nlen(train_df), len(val_df), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:02.339373Z","iopub.execute_input":"2022-05-17T03:47:02.339864Z","iopub.status.idle":"2022-05-17T03:47:02.357185Z","shell.execute_reply.started":"2022-05-17T03:47:02.339822Z","shell.execute_reply":"2022-05-17T03:47:02.356311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)\ntest_ds = Dataset.from_pandas(test_df)\n\nraw_ds = DatasetDict()\nraw_ds[\"train\"] = train_ds\nraw_ds[\"validation\"] = val_ds\nraw_ds[\"test\"] = test_ds\n\nraw_ds","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:02.358716Z","iopub.execute_input":"2022-05-17T03:47:02.35903Z","iopub.status.idle":"2022-05-17T03:47:02.402635Z","shell.execute_reply.started":"2022-05-17T03:47:02.358994Z","shell.execute_reply":"2022-05-17T03:47:02.402023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\nsep = tokenizer.sep_token","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:02.403836Z","iopub.execute_input":"2022-05-17T03:47:02.404049Z","iopub.status.idle":"2022-05-17T03:47:07.60499Z","shell.execute_reply.started":"2022-05-17T03:47:02.404018Z","shell.execute_reply":"2022-05-17T03:47:07.604228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# treat context keys as special tokens\nspecial_tokens = train_df[\"context\"].unique().tolist()\ntokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:07.606242Z","iopub.execute_input":"2022-05-17T03:47:07.606597Z","iopub.status.idle":"2022-05-17T03:47:07.621213Z","shell.execute_reply.started":"2022-05-17T03:47:07.606554Z","shell.execute_reply":"2022-05-17T03:47:07.620317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compose_input(example):\n    text = sep.join([example[\"anchor\"], \n                       example[\"target\"],\n                       example[\"context\"]])\n    example[\"text\"] = text\n    return example\n\n\n\nraw_ds = raw_ds.map(compose_input, \n                    remove_columns=[\"id\", \"anchor\", \n                                    \"target\", \"context\", \n                                    \"score\", \"__index_level_0__\"])\nraw_ds","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:07.622464Z","iopub.execute_input":"2022-05-17T03:47:07.622838Z","iopub.status.idle":"2022-05-17T03:47:12.449964Z","shell.execute_reply.started":"2022-05-17T03:47:07.622801Z","shell.execute_reply":"2022-05-17T03:47:12.449198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_ds[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:12.451187Z","iopub.execute_input":"2022-05-17T03:47:12.451517Z","iopub.status.idle":"2022-05-17T03:47:12.457649Z","shell.execute_reply.started":"2022-05-17T03:47:12.451478Z","shell.execute_reply":"2022-05-17T03:47:12.456984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoded Dataset","metadata":{}},{"cell_type":"code","source":"def tokenize_text(example):\n    return tokenizer(example[\"text\"])\n\n\ntrain_ds = raw_ds[\"train\"].map(tokenize_text, remove_columns=[\"text\"])\nval_ds = raw_ds[\"validation\"].map(tokenize_text, remove_columns=[\"text\"])\ntest_ds = raw_ds[\"test\"].map(tokenize_text, remove_columns=[\"text\"])\n\ntrain_ds","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:12.460851Z","iopub.execute_input":"2022-05-17T03:47:12.461664Z","iopub.status.idle":"2022-05-17T03:47:30.106321Z","shell.execute_reply.started":"2022-05-17T03:47:12.461611Z","shell.execute_reply":"2022-05-17T03:47:30.10562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DataLoader","metadata":{}},{"cell_type":"code","source":"collate_fn = DataCollatorWithPadding(tokenizer, padding=\"longest\", return_tensors=\"pt\")\n\ntrain_dl = DataLoader(train_ds, \n                      shuffle=True, \n#                       sampler=SubsetRandomSampler(np.random.randint(0, train_ds.num_rows, 1000).tolist()),\n                      batch_size=BATCH_SIZE, \n                      collate_fn=collate_fn)\nvalid_dl = DataLoader(val_ds,\n                      shuffle=False, \n#                       sampler=SubsetRandomSampler(np.random.randint(0, val_ds.num_rows, 200).tolist()),                      \n                      batch_size=BATCH_SIZE, \n                      collate_fn=collate_fn)\ntest_dl = DataLoader(test_ds,\n                     shuffle=False,\n#                      sampler=SubsetRandomSampler(np.random.randint(0, test_ds.num_rows, 100).tolist()),                     \n                     batch_size=BATCH_SIZE, \n                     collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:30.107572Z","iopub.execute_input":"2022-05-17T03:47:30.107816Z","iopub.status.idle":"2022-05-17T03:47:30.115042Z","shell.execute_reply.started":"2022-05-17T03:47:30.10778Z","shell.execute_reply":"2022-05-17T03:47:30.114109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:30.116571Z","iopub.execute_input":"2022-05-17T03:47:30.11711Z","iopub.status.idle":"2022-05-17T03:47:30.184746Z","shell.execute_reply.started":"2022-05-17T03:47:30.117076Z","shell.execute_reply":"2022-05-17T03:47:30.183565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, \n                                                           num_labels=len(score2label))\nmodel.resize_token_embeddings(len(tokenizer))\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:30.185903Z","iopub.execute_input":"2022-05-17T03:47:30.186149Z","iopub.status.idle":"2022-05-17T03:47:48.911286Z","shell.execute_reply.started":"2022-05-17T03:47:30.186116Z","shell.execute_reply":"2022-05-17T03:47:48.910507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr=LEARNING_RATE,\n                  weight_decay=WEIGHT_DECAY)\n\nnum_training_steps = NUM_EPOCHS * len(train_dl)\nlr_scheduler = get_scheduler(\"linear\",\n                             optimizer=optimizer,\n                             num_warmup_steps=0,\n                             num_training_steps=num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:48.912478Z","iopub.execute_input":"2022-05-17T03:47:48.912729Z","iopub.status.idle":"2022-05-17T03:47:48.919114Z","shell.execute_reply.started":"2022-05-17T03:47:48.912696Z","shell.execute_reply":"2022-05-17T03:47:48.918475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_train(model, train_dl):\n    model.train()\n    train_loss = 0\n    for bid, batch in enumerate(train_dl):\n        batch = {k:v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        train_loss += loss.detach().cpu().numpy()\n        loss.backward()\n        \n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n    \n    return train_loss\n\n\ndef compute_accuracy(labels, logits):\n    # convert logits to predictions and move to CPU\n    preds_cpu = torch.argmax(logits, dim=-1).cpu().numpy()\n    labels_cpu = labels.cpu().numpy()\n    return accuracy_score(labels_cpu, preds_cpu)\n\n\ndef do_eval(model, eval_dl):\n    model.eval()\n    eval_loss, eval_score, num_batches = 0, 0, 0\n    for bid, batch in enumerate(eval_dl):\n        batch = {k:v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        \n        loss = outputs.loss\n        eval_loss += loss.detach().cpu().numpy()\n        eval_score += compute_accuracy(batch[\"labels\"], outputs.logits)\n        num_batches += 1\n    \n    eval_score /= num_batches\n    return eval_loss, eval_score\n\n\ndef save_checkpoint(model, model_dir, epoch):\n    model.save_pretrained(os.path.join(MODEL_DIR, \"ckpt-{:d}\".format(epoch)))\n    \n\ndef save_training_history(history, model_dir, epoch):\n    fhist = open(os.path.join(MODEL_DIR, \"history.tsv\"), \"w\")\n    for epoch, train_loss, eval_loss, eval_score in history:\n        fhist.write(\"{:d}\\t{:.5f}\\t{:.5f}\\t{:.5f}\\n\".format(\n            epoch, train_loss, eval_loss, eval_score))\n    fhist.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:48.920465Z","iopub.execute_input":"2022-05-17T03:47:48.920904Z","iopub.status.idle":"2022-05-17T03:47:48.935006Z","shell.execute_reply.started":"2022-05-17T03:47:48.920869Z","shell.execute_reply":"2022-05-17T03:47:48.934394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training / Finetuning","metadata":{}},{"cell_type":"code","source":"if os.path.exists(MODEL_DIR):\n    shutil.rmtree(MODEL_DIR)\n    os.makedirs(MODEL_DIR)\n    \nhistory = []\nfor epoch in range(NUM_EPOCHS):\n    train_loss = do_train(model, train_dl)\n    eval_loss, eval_score = do_eval(model, valid_dl)\n    history.append((epoch + 1, train_loss, eval_loss, eval_score))\n    print(\"EPOCH {:3d} | train loss: {:.3f} | val loss: {:.3f} | val acc: {:.5f}\".format(\n        epoch + 1, train_loss, eval_loss, eval_score))\n    save_checkpoint(model, MODEL_DIR, epoch + 1)\n    save_training_history(history, MODEL_DIR, epoch + 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:47:48.937968Z","iopub.execute_input":"2022-05-17T03:47:48.938161Z","iopub.status.idle":"2022-05-17T03:53:18.339819Z","shell.execute_reply.started":"2022-05-17T03:47:48.938137Z","shell.execute_reply":"2022-05-17T03:53:18.339067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(2, 1, 1)\nplt.plot([train_loss for _, train_loss, _, _ in history], label=\"train\")\nplt.plot([eval_loss for _, _, eval_loss, _ in history], label=\"validation\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend(loc=\"best\")\n\nplt.subplot(2, 1, 2)\nplt.plot([eval_score for _, _, _, eval_score in history], label=\"validation\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"f1-score\")\nplt.legend(loc=\"best\")\n\nplt.tight_layout()\n_ = plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:18.341248Z","iopub.execute_input":"2022-05-17T03:53:18.341528Z","iopub.status.idle":"2022-05-17T03:53:18.698814Z","shell.execute_reply.started":"2022-05-17T03:53:18.341492Z","shell.execute_reply":"2022-05-17T03:53:18.698155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation against held out test set","metadata":{}},{"cell_type":"code","source":"_, test_acc = do_eval(model, test_dl)\nprint(\"test accuracy: {:.3f}\".format(test_acc))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:18.700149Z","iopub.execute_input":"2022-05-17T03:53:18.700617Z","iopub.status.idle":"2022-05-17T03:53:21.118823Z","shell.execute_reply.started":"2022-05-17T03:53:18.70058Z","shell.execute_reply":"2022-05-17T03:53:21.11808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, eval_dl):\n    model.eval()\n    labels, preds = [], []\n    eval_loss, eval_score, num_batches = 0, 0, 0\n    for bid, batch in enumerate(eval_dl):\n        batch = {k:v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        preds_b = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n        preds.extend(preds_b)\n        if \"labels\" in batch:\n            labels_b = batch[\"labels\"].cpu().numpy()\n            labels.extend(labels_b)\n    \n    return labels, preds\n\n\nlabels, preds = evaluate(model, test_dl)\n\nlabel2score = {label:str(score) for score, label in score2label.items()}\ntarget_names = [str(label2score[label]) for label in range(len(label2score))]\n\nprint(classification_report(labels, preds, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:21.120137Z","iopub.execute_input":"2022-05-17T03:53:21.120543Z","iopub.status.idle":"2022-05-17T03:53:23.750931Z","shell.execute_reply.started":"2022-05-17T03:53:21.120508Z","shell.execute_reply":"2022-05-17T03:53:23.750164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(ytrue, ypreds, labels):\n    cm = confusion_matrix(ytrue, ypreds, normalize=\"true\")\n    fig, ax = plt.subplots(figsize=(12, 12))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n    disp.plot(cmap=\"Blues\", values_format=\"0.2f\", ax=ax, colorbar=False)\n    plt.title(\"Normalized Confusion Matrix\")\n    _ = plt.show()\n\n\nplot_confusion_matrix(labels, preds, target_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:23.752138Z","iopub.execute_input":"2022-05-17T03:53:23.752882Z","iopub.status.idle":"2022-05-17T03:53:23.996209Z","shell.execute_reply.started":"2022-05-17T03:53:23.752842Z","shell.execute_reply":"2022-05-17T03:53:23.995525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict scores against provided test set","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(TEST_FILE)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:23.997481Z","iopub.execute_input":"2022-05-17T03:53:23.997883Z","iopub.status.idle":"2022-05-17T03:53:24.015449Z","shell.execute_reply.started":"2022-05-17T03:53:23.997845Z","shell.execute_reply":"2022-05-17T03:53:24.014816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = test_df[\"id\"].tolist()\nlen(ids)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:24.016556Z","iopub.execute_input":"2022-05-17T03:53:24.016797Z","iopub.status.idle":"2022-05-17T03:53:24.024813Z","shell.execute_reply.started":"2022-05-17T03:53:24.016765Z","shell.execute_reply":"2022-05-17T03:53:24.024009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(anchor, target, context, model, tokenizer, label2score):\n    text = \" | \".join([anchor, target, context])\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    inputs = {k:v.to(device) for k, v in inputs.items()}\n    outputs = model(**inputs)\n    pred_label = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n    return label2score[pred_label[0]]\n\n\nfout = open(SUBMISSION_FILE, \"w\")\nfout.write(\"id,score\\n\")\n\nfor index, row in test_df.iterrows():\n    pred_score = predict(row.anchor, row.target, row.context, \n                         model, tokenizer, label2score)\n    print(row.id, pred_score)\n    fout.write(\"{:s},{:s}\\n\".format(row.id, pred_score))\n\nfout.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:53:24.026476Z","iopub.execute_input":"2022-05-17T03:53:24.027074Z","iopub.status.idle":"2022-05-17T03:53:24.876081Z","shell.execute_reply.started":"2022-05-17T03:53:24.027039Z","shell.execute_reply":"2022-05-17T03:53:24.875295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}