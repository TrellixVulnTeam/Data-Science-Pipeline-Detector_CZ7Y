{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport pickle\nimport gc\n\nimport torch\nimport torch.nn as nn\n\nfrom scipy.stats import pearsonr\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-19T11:27:29.958947Z","iopub.execute_input":"2022-06-19T11:27:29.959235Z","iopub.status.idle":"2022-06-19T11:27:29.965627Z","shell.execute_reply.started":"2022-06-19T11:27:29.9592Z","shell.execute_reply":"2022-06-19T11:27:29.964762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef read_pickle(filepath):\n    with open(filepath, 'rb') as file:\n        obj = pickle.load(file)\n    return obj\n\n\ncls_map = read_pickle(\"../input/upppmunlabeled-dataset/cls_map.pkl\")\nmain_group_map = read_pickle(\"../input/upppmunlabeled-dataset/main_group_map.pkl\")\nsubcls_map = read_pickle(\"../input/upppmunlabeled-dataset/subcls_map.pkl\")\n\ndel main_group_map['']\n\nunlabel_df = pd.read_csv(\"../input/upppmunlabeled-dataset/unlabled_titles.csv\")\nunlabel_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:29.973539Z","iopub.execute_input":"2022-06-19T11:27:29.974112Z","iopub.status.idle":"2022-06-19T11:27:30.903098Z","shell.execute_reply.started":"2022-06-19T11:27:29.974054Z","shell.execute_reply":"2022-06-19T11:27:30.902334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\ntitle_df = pd.read_csv(\"../input/cpc-codes/titles.csv\")\n\ntest_df = test_df.merge(title_df, how='inner', left_on='context', right_on='code')\ntest_df['text'] = test_df['anchor'] + '[SEP]' + test_df['target'] + '[SEP]' + test_df['title']\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:30.904484Z","iopub.execute_input":"2022-06-19T11:27:30.904691Z","iopub.status.idle":"2022-06-19T11:27:31.723513Z","shell.execute_reply.started":"2022-06-19T11:27:30.904662Z","shell.execute_reply":"2022-06-19T11:27:31.722734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntitle_map = {}\nfor _,row in title_df.iterrows():\n    title_map[row.code] = row.title\nprint(len(title_map))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:31.724765Z","iopub.execute_input":"2022-06-19T11:27:31.725431Z","iopub.status.idle":"2022-06-19T11:27:48.10659Z","shell.execute_reply.started":"2022-06-19T11:27:31.725402Z","shell.execute_reply":"2022-06-19T11:27:48.105687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context2id = {}\nfor i, context in enumerate(cls_map.keys()):\n    context2id[context]=i","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.109717Z","iopub.execute_input":"2022-06-19T11:27:48.109951Z","iopub.status.idle":"2022-06-19T11:27:48.113379Z","shell.execute_reply.started":"2022-06-19T11:27:48.109925Z","shell.execute_reply":"2022-06-19T11:27:48.11294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    batch_size=24\n    n_epochs = 5\n    model_name = \"microsoft/deberta-base\"\n    max_len = 200\n    nfolds = 5\n    min_lr = 1e-6\n    max_lr = 2e-5\n    weight_decay=0.01","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.114121Z","iopub.execute_input":"2022-06-19T11:27:48.114665Z","iopub.status.idle":"2022-06-19T11:27:48.126162Z","shell.execute_reply.started":"2022-06-19T11:27:48.114641Z","shell.execute_reply":"2022-06-19T11:27:48.125602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.128508Z","iopub.execute_input":"2022-06-19T11:27:48.128799Z","iopub.status.idle":"2022-06-19T11:27:48.137334Z","shell.execute_reply.started":"2022-06-19T11:27:48.128767Z","shell.execute_reply":"2022-06-19T11:27:48.136868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class PatentDataset(torch.utils.data.Dataset):\n    def __init__(self, df, model_name='deberta_large_v1', phase='train', tokenizer=None):\n        self.phase = phase\n        self.model_name= model_name\n        self.tokenizer = tokenizer\n        \n        self.ids = df['id'].values\n        self.anchor = df.anchor.values\n        self.target = df.target.values\n        self.context = df.context.values\n        \n        self.text = df.text.values\n    \n    def prepare_inputs(self, text):\n        inputs = self.tokenizer(text, add_special_tokens=True, max_length=CFG.max_len, padding='max_length')\n        for k,v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n        return inputs\n    \n    def __getitem__(self, idx):\n        test_id = self.ids[idx]\n        context = self.context[idx]\n        \n        if self.model_name == 'deberta_large_v1':\n            text = self.anchor[idx]+\"[SEP]\"+self.target[idx]\n        else:\n            text = self.anchor[idx]+\"[SEP]\"+self.target[idx]+\"[SEP]\"+title_map[context]\n        \n        context_id = torch.tensor( context2id[context],  dtype=torch.long)\n        inputs = self.prepare_inputs(text)\n        return (test_id, context_id, inputs)\n    \n    def __len__(self):\n        return len(self.text)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.138464Z","iopub.execute_input":"2022-06-19T11:27:48.138899Z","iopub.status.idle":"2022-06-19T11:27:48.150769Z","shell.execute_reply.started":"2022-06-19T11:27:48.138865Z","shell.execute_reply":"2022-06-19T11:27:48.15026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class BackboneModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = AutoModel.from_pretrained(CFG.model_name)\n        self.attention = nn.Sequential(\n            nn.Linear(model_config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n    \n    def forward(self, inputs, model_name=None):\n        outputs = self.backbone(**inputs)\n        if model_name == 'deberta_large_v1':\n            return outputs.last_hidden_state[:, 0, :]\n        \n        last_hidden_state = outputs[0]\n        weights = self.attention(last_hidden_state)\n        h = torch.sum(weights * last_hidden_state, dim=1)\n        return h","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.152032Z","iopub.execute_input":"2022-06-19T11:27:48.152439Z","iopub.status.idle":"2022-06-19T11:27:48.163679Z","shell.execute_reply.started":"2022-06-19T11:27:48.152406Z","shell.execute_reply":"2022-06-19T11:27:48.162985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = BackboneModel()\n        \n        self.context_embeddings = nn.Embedding(len(context2id), model_config.hidden_size)\n        #task specific layers.\n        self.link_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(2*model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)\n        )\n        \n        self.strength_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(2*model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, 3)\n        )\n        \n        self.strength_prediction5 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(2*model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, 5)\n        )\n        \n        self.context_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, len(context2id))\n        )\n        self.mlp1 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(2*model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)\n        )\n        \n        self.mlp2 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(2*model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)\n        )\n        self.mlp3 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(2*model_config.hidden_size, 256),\n            nn.LeakyReLU(),\n            \n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)\n        )\n        \n    \n    def forward(self, context_id, inputs, model_name):\n        hcontext = self.context_embeddings(context_id)\n        hinputs = self.backbone(inputs, model_name)\n        h = torch.cat([hinputs, hcontext], dim=-1)\n        \n        y1 = self.mlp1(h)\n        y2 = self.mlp2(h)\n        y3 = self.mlp3(h)\n        y = (y1+y2+y3)/3\n        \n        ylink = self.link_prediction(h)\n        ystrength = self.strength_prediction(h)\n        ystrength5 = self.strength_prediction5(h)\n        ycontext = self.context_prediction(hinputs)\n        \n        return (y, ylink, ystrength, ystrength5, ycontext)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.16466Z","iopub.execute_input":"2022-06-19T11:27:48.165366Z","iopub.status.idle":"2022-06-19T11:27:48.182803Z","shell.execute_reply.started":"2022-06-19T11:27:48.165336Z","shell.execute_reply":"2022-06-19T11:27:48.18208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelV2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = BackboneModel()\n        #task specific layers.\n        self.link_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        self.strength_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 3)\n        )\n        \n        self.strength_prediction5 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 5)\n        )\n        \n        self.context_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, len(context2id))\n        )\n        self.mlp = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        \n        self.strength_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.strength_prediction5[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.context_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.mlp[1].weight.data.normal_(mean=0.0, std = 1/np.sqrt(model_config.hidden_size))\n        \n    def forward(self, context_id, inputs, model_name):\n        h = self.backbone(inputs, model_name)\n        y = self.mlp(h)\n        \n        ylink = self.link_prediction(h)\n        ystrength = self.strength_prediction(h)\n        ystrength5 = self.strength_prediction5(h)\n        ycontext = self.context_prediction(h)\n        \n        return (y, ylink, ystrength, ystrength5, ycontext)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.18506Z","iopub.execute_input":"2022-06-19T11:27:48.185627Z","iopub.status.idle":"2022-06-19T11:27:48.199911Z","shell.execute_reply.started":"2022-06-19T11:27:48.185591Z","shell.execute_reply":"2022-06-19T11:27:48.199082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DebertaModelV3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = BackboneModel()\n        #task specific layers.\n        self.link_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        self.strength_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 3)\n        )\n        \n        self.strength_prediction5 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 5)\n        )\n        \n        self.context_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, len(context2id))\n        )\n        self.mlp = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        \n        self.strength_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.strength_prediction5[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.context_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.mlp[1].weight.data.normal_(mean=0.0, std = 1/np.sqrt(model_config.hidden_size))\n        \n    def forward(self, context_id, inputs, model_name):\n        h = self.backbone(inputs, model_name)\n        y = self.mlp(h)\n        \n        ylink = self.link_prediction(h)\n        ystrength = self.strength_prediction(h)\n        ystrength5 = self.strength_prediction5(h)\n        ycontext = self.context_prediction(h)\n        \n        return (y, ylink, ystrength, ystrength5, ycontext)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:32:52.274077Z","iopub.execute_input":"2022-06-19T11:32:52.274697Z","iopub.status.idle":"2022-06-19T11:32:52.291677Z","shell.execute_reply.started":"2022-06-19T11:32:52.274654Z","shell.execute_reply":"2022-06-19T11:32:52.290343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaModelV2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = BackboneModel()\n        #task specific layers.\n        self.link_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        self.strength_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 3)\n        )\n        \n        self.strength_prediction5 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 5)\n        )\n        \n        self.context_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, len(context2id))\n        )\n        self.mlp = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        \n        self.strength_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.strength_prediction5[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.context_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.mlp[1].weight.data.normal_(mean=0.0, std = 1/np.sqrt(model_config.hidden_size))\n        \n    def forward(self, context_id, inputs, model_name=None):\n        h = self.backbone(inputs, model_name)\n        y = self.mlp(h)\n        \n        ylink = self.link_prediction(h)\n        ystrength = self.strength_prediction(h)\n        ystrength5 = self.strength_prediction5(h)\n        \n        return (y, ylink, ystrength, ystrength5, _)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.202498Z","iopub.execute_input":"2022-06-19T11:27:48.202864Z","iopub.status.idle":"2022-06-19T11:27:48.216942Z","shell.execute_reply.started":"2022-06-19T11:27:48.202809Z","shell.execute_reply":"2022-06-19T11:27:48.215882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaModelV3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = BackboneModel()\n        #task specific layers.\n        self.link_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        self.strength_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 3)\n        )\n        \n        self.strength_prediction5 = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 5)\n        )\n        \n        self.context_prediction = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, len(context2id))\n        )\n        self.mlp = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(model_config.hidden_size, 1)\n        )\n        \n        \n        self.strength_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.strength_prediction5[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.context_prediction[1].weight.data.normal_(mean=0.0, std=1/np.sqrt(model_config.hidden_size))\n        self.mlp[1].weight.data.normal_(mean=0.0, std = 1/np.sqrt(model_config.hidden_size))\n        \n    def forward(self, context_id, inputs, model_name=None):\n        h = self.backbone(inputs, model_name)\n        y = self.mlp(h)\n        \n        ylink = self.link_prediction(h)\n        ystrength = self.strength_prediction(h)\n        ystrength5 = self.strength_prediction5(h)\n        \n        return (y, ylink, ystrength, ystrength5, _)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.21811Z","iopub.execute_input":"2022-06-19T11:27:48.218351Z","iopub.status.idle":"2022-06-19T11:27:48.234547Z","shell.execute_reply.started":"2022-06-19T11:27:48.218319Z","shell.execute_reply":"2022-06-19T11:27:48.234016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def infer(models, model_name, tokenizer):\n    \n    val_dataset   = PatentDataset(test_df , model_name=model_name, phase='val', tokenizer=tokenizer)\n    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=CFG.batch_size,\n                                                 shuffle=False, \n                                                 drop_last=False)\n    \n    \n    test_ids = []\n    scores =[]\n    pred_strength=[]\n    pred_strength5=[]\n    \n    \n    print(\"number of batches:\",len(val_dataloader))\n    for (test_id, context_id, inputs) in val_dataloader:\n        context_id = context_id.to(device)\n        batch_max_seqlen = inputs['attention_mask'].sum(dim=-1).max()\n        for k,v in inputs.items():\n            v = v[:, :batch_max_seqlen]\n            inputs[k] = v.to(device)\n        \n        test_ids += test_id\n        enesembled_scores = np.zeros(len(test_id))\n        enesembled_strength = np.zeros((len(test_id), 3))\n        enesembled_strength5 = np.zeros((len(test_id), 5))\n        \n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                (score, yhat_link, yhat_strength, yhat_strength5, _) = model(context_id, inputs, model_name)\n                score = score.view(-1).sigmoid().cpu().numpy()\n                yhat_strength = yhat_strength.softmax(dim=-1).cpu().numpy()\n                yhat_strength5 = yhat_strength5.softmax(dim=-1).cpu().numpy()\n                \n                enesembled_scores+=score\n                enesembled_strength += yhat_strength\n                enesembled_strength5 += yhat_strength5\n        \n        \n        enesembled_scores = enesembled_scores/len(models)\n        enesembled_strength =enesembled_strength/len(models)\n        enesembled_strength5 = enesembled_strength5/len(models)\n        \n        scores += enesembled_scores.tolist()\n        pred_strength += enesembled_strength.tolist()\n        pred_strength5 += enesembled_strength5.tolist()\n        \n    submission_df = pd.DataFrame.from_dict({\n        'id' : test_ids,\n        model_name+'_score' : scores,\n        model_name+'_pred_strength' : pred_strength,\n        model_name+'_pred_strength5' : pred_strength5\n    })\n    return submission_df\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.235605Z","iopub.execute_input":"2022-06-19T11:27:48.235963Z","iopub.status.idle":"2022-06-19T11:27:48.253856Z","shell.execute_reply.started":"2022-06-19T11:27:48.235931Z","shell.execute_reply":"2022-06-19T11:27:48.252595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_large_tokenizer=AutoTokenizer.from_pretrained(\"../input/deberta-huggingface-tokenizers/roberta-large.pt\")\nroberta_large_models = [\n    torch.load(\"../input/usppm-roberta-v1-fold0-model/model_0.pt\", map_location=device),\n    torch.load(\"../input/usppm-roberta-v1-fold1-model/model_1.pt\", map_location=device),\n    torch.load(\"../input/usppm-roberta-v1-fold2-model/model_2.pt\", map_location=device),\n    torch.load(\"../input/usppm-roberta-v1-fold3-model/model_3.pt\", map_location=device),\n    torch.load(\"../input/usppm-roberta-v1-fold4-model/model_4.pt\", map_location=device)\n]\n\nsub_roberta_v1 = infer(roberta_large_models,'roberta_large_v1', roberta_large_tokenizer)\n\ndel roberta_large_models\ngc.collect()\n\nsub_roberta_v1.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:27:48.254758Z","iopub.execute_input":"2022-06-19T11:27:48.255215Z","iopub.status.idle":"2022-06-19T11:28:47.693969Z","shell.execute_reply.started":"2022-06-19T11:27:48.255179Z","shell.execute_reply":"2022-06-19T11:28:47.693246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_large_tokenizer=AutoTokenizer.from_pretrained(\"../input/deberta-huggingface-tokenizers/roberta-large.pt\")\nroberta_large_v3_models = [\n    torch.load(\"../input/usppm-roberta-v3-fold0-model/model_0.pt\", map_location=device),\n    torch.load(\"../input/usppmrobertav3fold1model/model_1.pt\", map_location=device),\n    torch.load(\"../input/usppmrobertav3fold2model/model_2.pt\", map_location=device),\n    torch.load(\"../input/usppmrobertav3fold3model/model_3.pt\", map_location=device),\n    torch.load(\"../input/usppmrobertav3fold4model/model_4.pt\", map_location=device)\n]\n\nsub_roberta_v3 = infer(roberta_large_v3_models,'roberta_large_v3', roberta_large_tokenizer)\n\ndel roberta_large_v3_models\ngc.collect()\n\nsub_roberta_v3.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:28:47.695535Z","iopub.execute_input":"2022-06-19T11:28:47.69573Z","iopub.status.idle":"2022-06-19T11:29:48.944095Z","shell.execute_reply.started":"2022-06-19T11:28:47.695705Z","shell.execute_reply":"2022-06-19T11:29:48.943251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_tokenizer = AutoTokenizer.from_pretrained(\"../input/deberta-huggingface-tokenizers/deberta-v3-large-tokenizer.pt\")\ndeberta_large_models_v1 = [\n    torch.load(\"../input/upmm-deberta-large-run1-fold0-model/model_0.pt\", map_location=device),\n    torch.load(\"../input/usppm-deberta-run1-fold12/model_1.pt\", map_location=device),\n    torch.load(\"../input/usppm-debertalarge-run2-fold2-model/model_2.pt\", map_location=device),\n    torch.load(\"../input/usppm-debertalarge-run1-fold34-models/model_3.pt\", map_location=device),\n    torch.load(\"../input/usppm-debertalarge-run2-fold4-model/model_4.pt\",  map_location=device)\n]\n\nsub_deberta_v1 = infer(deberta_large_models_v1, \"deberta_large_v1\", deberta_tokenizer)\ndel deberta_large_models_v1\ngc.collect()\n\nsub_deberta_v1.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:29:48.945768Z","iopub.execute_input":"2022-06-19T11:29:48.946089Z","iopub.status.idle":"2022-06-19T11:30:15.509163Z","shell.execute_reply.started":"2022-06-19T11:29:48.94605Z","shell.execute_reply":"2022-06-19T11:30:15.508245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_tokenizer = AutoTokenizer.from_pretrained(\"../input/deberta-huggingface-tokenizers/deberta-v3-large-tokenizer.pt\")\ndeberta_v3_large_models_v2 = [\n    torch.load(\"../input/uspppmdebertaattention-v2-fold0/model_0.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattention-v2-fold1/model_1.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattentionv2fold2/model_2.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattention-v2-fold3/model_3.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattention-v2-fold4/model_4.pt\",  map_location=device)\n]\n\nsub_deberta_v2 = infer(deberta_v3_large_models_v2,'deberta_large_v2', deberta_tokenizer)\n\ndel deberta_v3_large_models_v2\ngc.collect()\n\nsub_deberta_v2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:32:13.174035Z","iopub.execute_input":"2022-06-19T11:32:13.174339Z","iopub.status.idle":"2022-06-19T11:32:50.138952Z","shell.execute_reply.started":"2022-06-19T11:32:13.174306Z","shell.execute_reply":"2022-06-19T11:32:50.138183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_tokenizer = AutoTokenizer.from_pretrained(\"../input/deberta-huggingface-tokenizers/deberta-v3-large-tokenizer.pt\")\ndeberta_v3_large_models_v3 = [\n    torch.load(\"../input/uspppm-deberta-attention-v3-fold0-model/model_0.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattentionv3fold1model/model_1.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattentionv2fold2/model_2.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattention-v2-fold3/model_3.pt\", map_location=device),\n    torch.load(\"../input/uspppmdebertaattention-v2-fold4/model_4.pt\",  map_location=device)\n]\n\nsub_deberta_v3 = infer(deberta_v3_large_models_v3,'deberta_large_v3', deberta_tokenizer)\n\ndel deberta_v3_large_models_v3\ngc.collect()\n\nsub_deberta_v3.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:33:05.342366Z","iopub.execute_input":"2022-06-19T11:33:05.342671Z","iopub.status.idle":"2022-06-19T11:33:57.407248Z","shell.execute_reply.started":"2022-06-19T11:33:05.342638Z","shell.execute_reply":"2022-06-19T11:33:57.406161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = sub_roberta_v1.merge(sub_roberta_v3, on='id').merge(sub_deberta_v2, on='id').merge(sub_deberta_v1, on='id').merge(sub_deberta_v3, on='id')\nsubmission_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:33:59.553073Z","iopub.execute_input":"2022-06-19T11:33:59.553341Z","iopub.status.idle":"2022-06-19T11:33:59.608281Z","shell.execute_reply.started":"2022-06-19T11:33:59.553304Z","shell.execute_reply":"2022-06-19T11:33:59.607505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# blend scores","metadata":{}},{"cell_type":"code","source":"[colname for colname in submission_df.columns if '_score' in colname]","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:38:36.241239Z","iopub.execute_input":"2022-06-19T11:38:36.2415Z","iopub.status.idle":"2022-06-19T11:38:36.248136Z","shell.execute_reply.started":"2022-06-19T11:38:36.24147Z","shell.execute_reply":"2022-06-19T11:38:36.246581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#roberta_score = 0.49*submission_df['roberta_large_v1_score'] + 0.51*submission_df['roberta_large_v3_score']\n#deberta_score = 0.44*submission_df['deberta_large_v1_score'] + 0.56*submission_df['deberta_large_v2_score']\n\n#score = 0.275 * roberta_score + 0.725 * deberta_score\npred_scores = 0.2344878  * submission_df['deberta_large_v1_score'] \\\n        + 0.3483222 * submission_df['deberta_large_v2_score'] \\\n        + 0.19213345 * submission_df['deberta_large_v3_score'] \\\n        + 0.12141794 * submission_df['roberta_large_v1_score'] \\\n        + 0.10363861 * submission_df['roberta_large_v3_score']\n\n\nsubmission_df['score'] = pred_scores\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:42:42.180452Z","iopub.execute_input":"2022-06-19T11:42:42.181186Z","iopub.status.idle":"2022-06-19T11:42:42.21697Z","shell.execute_reply.started":"2022-06-19T11:42:42.181155Z","shell.execute_reply":"2022-06-19T11:42:42.2162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess1(row):\n    blend_score = row.score\n    \n    roberta_large_v1_pred_strength5 = np.array(row.roberta_large_v1_pred_strength5)\n    roberta_large_v3_pred_strength5 = np.array(row.roberta_large_v3_pred_strength5)\n    \n    deberta_large_v1_pred_strength5 = np.array(row.deberta_large_v1_pred_strength5)\n    deberta_large_v2_pred_strength5 = np.array(row.deberta_large_v2_pred_strength5)\n    deberta_large_v3_pred_strength5 = np.array(row.deberta_large_v3_pred_strength5)\n    \n    pred_strength5 = (roberta_large_v1_pred_strength5 \\\n                      + roberta_large_v3_pred_strength5 \\\n                      + deberta_large_v1_pred_strength5 \\\n                      + deberta_large_v2_pred_strength5 \\\n                      + deberta_large_v3_pred_strength5\n                     )/5\n    \n    pred_cls = np.argmax(pred_strength5)\n    pred_cls_value = np.max(pred_strength5)\n    \n    if pred_cls_value < 0.9:\n        return blend_score\n    \n    if pred_cls == 0 and blend_score <= 0.02:\n        blend_score=0.0\n    if pred_cls == 1 and blend_score>=0.22 and blend_score <=0.28:\n        blend_score = 0.25\n    elif pred_cls == 2 and blend_score>=0.48 and blend_score <=0.52:\n        blend_score = 0.5\n    elif pred_cls == 3 and blend_score >=0.73 and blend_score <= 0.77:\n        blend_score = 0.75\n    elif pred_cls == 4 and blend_score >=0.97:\n        blend_score=1.0\n    \n    return blend_score","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:42:52.707853Z","iopub.execute_input":"2022-06-19T11:42:52.708132Z","iopub.status.idle":"2022-06-19T11:42:52.718708Z","shell.execute_reply.started":"2022-06-19T11:42:52.708101Z","shell.execute_reply":"2022-06-19T11:42:52.717925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess2(row):\n    blend_score = row.score\n    \n    roberta_large_v1_pred_strength = np.array(row.roberta_large_v1_pred_strength)\n    roberta_large_v3_pred_strength = np.array(row.roberta_large_v3_pred_strength)\n    \n    deberta_large_v1_pred_strength = np.array(row.deberta_large_v1_pred_strength)\n    deberta_large_v2_pred_strength = np.array(row.deberta_large_v2_pred_strength)\n    deberta_large_v3_pred_strength = np.array(row.deberta_large_v3_pred_strength)\n    \n    pred_strength = (roberta_large_v1_pred_strength \\\n                     + roberta_large_v3_pred_strength \\\n                     + deberta_large_v1_pred_strength \\\n                     + deberta_large_v2_pred_strength\\\n                     + deberta_large_v3_pred_strength\n                    )/5\n    \n    pred_cls = np.argmax(pred_strength)\n    pred_cls_value = np.max(pred_strength)\n    \n    if pred_cls_value < 0.9:\n        return blend_score\n    \n    if pred_cls == 0 and blend_score <= 0.02:\n        blend_score=0.0\n    if pred_cls == 1 and blend_score>=0.22 and blend_score <=0.28:\n        blend_score = 0.25\n    elif pred_cls == 1 and blend_score>=0.48 and blend_score <=0.52:\n        blend_score = 0.5\n    elif pred_cls == 2 and blend_score >=0.73 and blend_score <= 0.77:\n        blend_score = 0.75\n    elif pred_cls == 2 and blend_score >=0.97:\n        blend_score=1.0\n    \n    return blend_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['score1'] = submission_df.apply(postprocess1, axis=1)\nsubmission_df['score2'] = submission_df.apply(postprocess2, axis=1)\nsubmission_df['score'] = 0.6 * submission_df['score1'] + 0.4 * submission_df['score2']\n\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:42:57.841255Z","iopub.execute_input":"2022-06-19T11:42:57.841618Z","iopub.status.idle":"2022-06-19T11:42:57.885636Z","shell.execute_reply.started":"2022-06-19T11:42:57.841588Z","shell.execute_reply":"2022-06-19T11:42:57.884778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df[['id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:43:09.003775Z","iopub.execute_input":"2022-06-19T11:43:09.004115Z","iopub.status.idle":"2022-06-19T11:43:09.014277Z","shell.execute_reply.started":"2022-06-19T11:43:09.004084Z","shell.execute_reply":"2022-06-19T11:43:09.013597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}