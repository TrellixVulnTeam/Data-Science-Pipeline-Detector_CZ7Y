{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Iterate like a grandmaster with submission plus miscellaneous","metadata":{}},{"cell_type":"markdown","source":"Based on the original [notebook](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/) by Jermey Howard, we look at adding in code to generate submissions and cleaning up the code a little to make it easier and faster to iterate. We then extending making use of the ideas suggested in the original notebook, and others that might come to mind.\n\nChanges, done and in progress:\n- [x] Add ability to create submission file\n- [x] Update so that pretrained model is loaded from input (first submission scored 0.792)\n- [x] Make notebook more concise by removing explanatory text and grouping code into workflow class\n- [x] Update to model trained on full dataset submission submission (submission scored 0.799)\n- [x] Round labels to closest multiple of 0.25 (dropped to 0.762) \n- [x] Clip values to [0, 1]  (appears to reduce score slightly)\n- [x] Try [BERT for patents](https://huggingface.co/anferico/bert-for-patents) (scored 0.81, 0.82 after tuning LR and epochs)\n- [ ] Implement cross validation in workflow\n- [ ] Change to use one hot encoding for scores\n\n\nIdeas suggested in the original notebook:\n\n- Try a model pretrained on legal vocabulary. E.g. how about [BERT for patents](https://huggingface.co/anferico/bert-for-patents)?\n- You'd likely get better results by using a sentence similarity model. Did you know that there's a [patent similarity model](https://huggingface.co/AI-Growth-Lab/PatentSBERTa) you could try?\n- You could also fine-tune any HuggingFace model using the full patent database (which is provided in BigQuery), before applying it to this dataset\n- Replace the patent context field with the description of that context provided by the patent office\n- ...and try out your own ideas too!","metadata":{}},{"cell_type":"markdown","source":"## Import, set paths and load data\n\nThe first thing we do is import all the packages we are going to need and set the paths to point to the input data and any pretrained model files that will be used.","metadata":{}},{"cell_type":"code","source":"from fastai.imports import *\nfrom torch.utils.data import DataLoader\nimport warnings,transformers,logging,torch\nfrom transformers import TrainingArguments,Trainer\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\nimport datasets\nfrom datasets import load_dataset, Dataset, DatasetDict\n\nwarnings.simplefilter('ignore')\nlogging.disable(logging.WARNING)\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:07:58.22863Z","iopub.execute_input":"2022-04-16T14:07:58.228966Z","iopub.status.idle":"2022-04-16T14:08:05.249602Z","shell.execute_reply.started":"2022-04-16T14:07:58.228885Z","shell.execute_reply":"2022-04-16T14:08:05.248802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set input and model paths\ninput_path = (Path('../input/us-patent-phrase-to-phrase-matching') if iskaggle\n    else Path.home()/'data'/'us-patent-phrase-to-phrase-matching')\nmodel_path = (Path('../input/download-pretrained-models') if iskaggle\n    else Path('models'))","metadata":{"hidden":true,"execution":{"iopub.status.busy":"2022-04-16T14:08:05.25204Z","iopub.execute_input":"2022-04-16T14:08:05.253235Z","iopub.status.idle":"2022-04-16T14:08:05.25803Z","shell.execute_reply.started":"2022-04-16T14:08:05.253197Z","shell.execute_reply":"2022-04-16T14:08:05.257292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a workflow class\n\nCreate a workflow class to tie together different methods, which can be extended upon and modified.","metadata":{}},{"cell_type":"code","source":"class Workflow:\n        \n    def __init__(self, model_nm, val_prop=0.25, seed=42, dev=False):\n        self.model_nm = model_nm\n        self.val_prop = val_prop\n        self.seed = seed\n        self.dev = dev\n        self.sectoks = [] # additional section tokens\n        \n        # setup tokenizer and separator to use\n        self.sep = \" [s] \"\n        self.load_and_preprocess()\n        self.init_tokenizer()\n        \n    def init_tokenizer(self):\n        self.tokz = AutoTokenizer.from_pretrained(model_nm)\n        self.tokz.add_special_tokens({'additional_special_tokens': self.sectoks})\n        \n    def load_and_preprocess(self):\n        # load test and eval data\n        self.train_df = pd.read_csv(input_path/'train.csv')\n        if self.dev: self.train_df = self.train_df.iloc[:500]\n        self.eval_df = pd.read_csv(input_path/'test.csv')\n        \n        self.preprocess_raw_data(self.train_df)\n        self.preprocess_raw_data(self.eval_df)\n        \n    # create separate section column from first letter of the context\n    def preprocess_raw_data(self, df):\n        df['section'] = df['context'].str[0]\n        df['sectok'] = '[' + df.section + ']'\n        df['inputs'] = df.sectok + self.sep + df.context + self.sep + df.anchor + self.sep + df.target\n        self.sectoks = list(set(list(df.sectok.unique()) + self.sectoks))\n        \n    def get_val_split(self):\n        anchors = self.train_df.anchor.unique()\n        np.random.seed(self.seed)\n        np.random.shuffle(anchors)\n        val_sz = int(len(anchors)*self.val_prop)\n        val_anchors = anchors[:val_sz]\n        is_val = np.isin(self.train_df.anchor, val_anchors)\n        idxs = np.arange(len(self.train_df))\n        val_idxs = idxs[ is_val]\n        trn_idxs = idxs[~is_val]\n        return val_idxs, trn_idxs\n        \n    def get_dds(self, df, no_val=False):\n        ds = Dataset.from_pandas(df).rename_column('score', 'label')\n        def tok_func(x): return self.tokz(x[\"inputs\"])\n        tok_ds = ds.map(tok_func, batched=True, remove_columns=('inputs','id','section'))\n        if not no_val:\n            self.val_idxs, self.trn_idxs = self.get_val_split()\n            self.train_ds = tok_ds.select(self.trn_idxs)\n            self.val_ds = tok_ds.select(self.val_idxs)\n        else:\n            self.val_idxs, self.trn_idxs = np.ones(0), np.arange(len(self.train_df))\n            self.train_ds = tok_ds.select(self.trn_idxs)\n            self.val_ds = []\n        \n        return DatasetDict({\"train\": self.train_ds, \"test\": self.val_ds})\n    \n    def train(self, no_val=False, **kwargs):\n        dds = self.get_dds(self.train_df, no_val=no_val)\n        self.trainer = self.get_trainer(dds, **kwargs)\n        self.trainer.train()\n        \n    def get_model(self):        \n        model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n        model.resize_token_embeddings(len(self.tokz))\n        with torch.no_grad():\n            model.get_input_embeddings().weight[-len(self.tokz), :] = torch.zeros([model.config.hidden_size])\n        return model\n\n    def get_trainer(self, dds, epochs=4, lr=8e-5, bs=128, wd=0.01):\n        def corr(eval_pred): return {'pearson': np.corrcoef(eval_pred[0].flatten(), eval_pred[1].flatten())[0][1]}\n        self.model = self.get_model()\n        args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n            evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n            num_train_epochs=epochs, weight_decay=wd, report_to='none', save_steps=5000)\n        return Trainer(self.model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                       tokenizer=self.tokz, compute_metrics=corr)\n    \n    def get_test_predictions(self):\n        test_ds = Dataset.from_pandas(self.eval_df)\n        def tok_func(x): return self.tokz(x[\"inputs\"])\n        test_ds = test_ds.map(tok_func, batched=True, remove_columns=('inputs','id','section'))\n        return self.trainer.predict(test_ds)[0].flatten()\n        \n    \n    def prepare_submission(self, save_fn='submission.csv', clip=False):\n        prediction_results = self.get_test_predictions()\n        if clip: prediction_results = np.clip(prediction_results, 0.0, 1.0)\n        submission_df = pd.DataFrame({'id': self.eval_df['id'], 'score': prediction_results})\n        submission_df.to_csv(save_fn, index=False)        \n        \n    def get_validation_score(self, clip=False):\n        prediction_results = self.trainer.predict(self.val_ds)\n        preds, labels = prediction_results[0].flatten(), prediction_results[1].flatten()\n        if clip: preds = np.clip(preds, 0., 1.)\n        return np.corrcoef(preds, labels)[0][1]\n    \n    def get_train_score(self, clip=False):\n        prediction_results = self.trainer.predict(self.train_ds)\n        preds, labels = prediction_results[0].flatten(), prediction_results[1].flatten()\n        if clip: preds = np.clip(preds, 0., 1.)\n        return np.corrcoef(preds, labels)[0][1]        ","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:11:07.811786Z","iopub.execute_input":"2022-04-16T14:11:07.812123Z","iopub.status.idle":"2022-04-16T14:11:07.841967Z","shell.execute_reply.started":"2022-04-16T14:11:07.812082Z","shell.execute_reply":"2022-04-16T14:11:07.840856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cached_model = True\n# model_nm = model_path/'deberta-v3-small' if cached_model else 'microsoft/deberta-v3-small'\nmodel_nm = model_path/'bert-for-patents' if cached_model else 'anferico/bert-for-patents'","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:11:09.040035Z","iopub.execute_input":"2022-04-16T14:11:09.040555Z","iopub.status.idle":"2022-04-16T14:11:09.04443Z","shell.execute_reply.started":"2022-04-16T14:11:09.040517Z","shell.execute_reply":"2022-04-16T14:11:09.04356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First train with a train validation split to get idea of performance.","metadata":{}},{"cell_type":"code","source":"wf = Workflow(model_nm, dev=False)\nwf.train(no_val=False, epochs=6, bs=64, lr=4e-5)\nprint(wf.get_validation_score(clip=False), wf.get_validation_score(clip=True))\nprint(wf.get_train_score(clip=False), wf.get_train_score(clip=True))\nwf.prepare_submission()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:02:50.278377Z","iopub.execute_input":"2022-04-16T15:02:50.278624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train on the full dataset to make use of the additional data.","metadata":{}},{"cell_type":"code","source":"wf = Workflow(model_nm, dev=False)\nwf.train(no_val=True, epochs=6, bs=64, lr=4e-5)\nwf.prepare_submission()","metadata":{},"execution_count":null,"outputs":[]}]}