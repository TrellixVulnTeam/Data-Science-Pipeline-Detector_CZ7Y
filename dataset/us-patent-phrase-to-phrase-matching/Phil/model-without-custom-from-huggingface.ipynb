{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer\nimport re\nimport json\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset\nfrom sklearn.preprocessing import minmax_scale\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:01:01.393377Z","iopub.execute_input":"2022-05-10T02:01:01.393618Z","iopub.status.idle":"2022-05-10T02:01:07.954031Z","shell.execute_reply.started":"2022-05-10T02:01:01.393542Z","shell.execute_reply":"2022-05-10T02:01:07.953292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_EPOCHS = 5\nBATCH_SIZE = 16\nSEED = 222\nINPUT_PATH = '../input/us-patent-phrase-to-phrase-matching'\n\nCPC_PATH = '../input/cpc-codes/titles.csv'\nMODEL_PATH = {\n    'DB': ''\n}\n\nMODEL_SAVE_PATH = '../input/5-fold-atsc-b4p-atc-db-rb'\n\n\nINPUT_TYPE = [\n    '5_Fold_ATC_B4P', '5_Fold_ATC_DB', '5_Fold_ATC_RB',\n    '5_Fold_ACT_B4P', '5_Fold_ACT_DB', '5_Fold_ACT_RB',\n    '5_Fold_CAT_B4P', '5_Fold_CAT_DB', '5_Fold_CAT_RB',\n    '5_Fold_ATSC_B4P', '5_Fold_ATSC_DB', '5_Fold_ATSC_RB',\n    '5_Fold_SATC_B4P', '5_Fold_SATC_DB', '5_Fold_SATC_RB',\n    '5_Fold_SCAT_B4P', '5_Fold_SCAT_DB', '5_Fold_SCAT_RB',\n    '5_Fold_ATSCC_B4P', '5_Fold_ATSCC_DB', '5_Fold_ATSCC_RB',\n    '5_Fold_SCATC_B4P', '5_Fold_SCATC_DB', '5_Fold_SCATC_RB',\n]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:03:39.398808Z","iopub.execute_input":"2022-05-10T02:03:39.399372Z","iopub.status.idle":"2022-05-10T02:03:39.405795Z","shell.execute_reply.started":"2022-05-10T02:03:39.399328Z","shell.execute_reply":"2022-05-10T02:03:39.404785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_cpc_dict(df_cpc, clean=False):\n    \"\"\"\n    if clean == True: will clean the cpc text, remove {} or () content\n    \"\"\"\n    cpc_dict = {}\n    if clean:\n        for i in range(len(df_cpc)):\n            title = df_cpc.iloc[i, 1]\n            title = re.sub('\\(.*?\\)', '', title)\n            title = re.sub('\\{.{0,3}\\}', '', title)\n            title = re.sub('[\\{\\}]', '', title)\n            cpc_dict[df_cpc.iloc[i, 0]] = title\n    else:\n        for i in range(len(df_cpc)):\n            title = df_cpc.iloc[i, 1]\n            # title = re.sub('\\(.*?\\)', '', title)\n            # title = re.sub('\\{.{0,3}\\}', '', title)\n            # title = re.sub('[\\{\\}]', '', title)\n            cpc_dict[df_cpc.iloc[i, 0]] = title\n    return cpc_dict\n\n\ndef preprocess_data(df, cpc_dict, data_type):\n\n    df['section_text'] = df.context.apply(lambda x: cpc_dict[x[0]])\n    df['context_text'] = df.context.apply(lambda x: cpc_dict[x])\n    \n    d_type = 'ATC'\n    if '_' in data_type:\n        d_type = data_type.split('_')[2]\n    else:\n        d_type = data_type\n    if d_type == 'ATC':\n        df['input'] = df['anchor'] + '[SEP]' + df['target'] + '[SEP]' + df['context_text']\n    if d_type == 'ACT':\n        df['input'] = df['anchor'] + '[SEP]' + df['context_text'] + '[SEP]' + df['target']\n    if d_type == 'CAT':\n        df['input'] = df['context_text'] + '[SEP]' + df['anchor'] + '[SEP]' + df['target']\n    \n    if d_type == 'ATSC':\n        df['input'] = df['anchor'] + '[SEP]' + df['target'] + '[SEP]' + df['section_text'] + '[SEP]' + df['context_text']\n    if d_type == 'SATC':\n        df['input'] = df['section_text'] + '[SEP]' + df['anchor'] + '[SEP]' + df['target'] + '[SEP]' + df['context_text']\n    if d_type == 'SCAT':\n        df['input'] = df['section_text'] + '[SEP]' + df['context_text'] + '[SEP]' + df['anchor'] + '[SEP]' + df['target']\n    \n    \n    if d_type == 'ATSCC':\n        df['input'] = df['anchor'] + '[SEP]' + df['target'] + '[SEP]' + df['section_text'] + ' ' + df['context_text']\n    if d_type == 'SATCC':\n        df['input'] = df['section_text'] + ' ' + df['anchor'] + '[SEP]' + df['target'] + '[SEP]' + df['context_text']\n    if d_type == 'SCATC':\n        df['input'] = df['section_text'] + ' ' + df['context_text'] + '[SEP]' + df['anchor'] + '[SEP]' + df['target']\n\n    return df\n\n\n\ndef split_n_folds(df, n_folds):\n    \"\"\"\n    Use StratifiedKFold to split the data into n_folds\n    \"\"\"\n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n\n    # StratifiedKFold 引入标签信息，使得Fold后的与原来的分布保持一致\n    df['score_map'] = df['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    for n, (train_index, val_index) in enumerate(skf.split(df, df['score_map'])):\n        df.loc[val_index, 'fold'] = int(n)\n    df['fold'] = df['fold'].astype(int)\n    return df\n\nclass TrainDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.inputs = df['input'].values.astype(str)\n        self.label = df['score'].values\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, item):\n        inputs = self.inputs[item]\n#         targets = self.targets[item]\n        label = self.label[item]\n        \n        return {\n        **self.tokenizer( inputs ),\n        'label':label.astype(np.float32)\n    }\n\n\nclass TestDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.inputs = df['input'].values.astype(str)\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, item):\n        inputs = self.inputs[item]\n#         targets = self.targets[item]\n        \n        return {\n        **self.tokenizer( inputs )\n    }\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    \n    predictions = predictions.reshape(len(predictions))\n    return {\n        'pearson': np.corrcoef(predictions, labels)[0][1]\n    }\n\n\ndef log_content(write_file, content):\n    with open(write_file, 'a') as fwa:\n        fwa.write(content)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:03:42.303181Z","iopub.execute_input":"2022-05-10T02:03:42.303497Z","iopub.status.idle":"2022-05-10T02:03:42.329504Z","shell.execute_reply.started":"2022-05-10T02:03:42.303463Z","shell.execute_reply":"2022-05-10T02:03:42.328582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer_single_model(model_save_path, df_test, log_file=None):\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_save_path, num_labels=1)\n    tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n\n    test_dataset = TestDataset(df_test, tokenizer)\n\n    training_args = TrainingArguments(\n        output_dir=model_save_path,\n        evaluation_strategy='epoch',\n        save_strategy='epoch',\n        learning_rate=2e-5,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        weight_decay=0.01,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"pearson\",\n        logging_strategy='epoch'\n    )\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics,\n    )\n    \n    outputs = trainer.predict(test_dataset)\n    for obj in trainer.state.log_history:\n        print(obj)\n        if log_file:\n            log_content(log_file, str(obj) + '\\n')\n    return outputs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:03:43.130873Z","iopub.execute_input":"2022-05-10T02:03:43.131413Z","iopub.status.idle":"2022-05-10T02:03:43.138656Z","shell.execute_reply.started":"2022-05-10T02:03:43.131376Z","shell.execute_reply":"2022-05-10T02:03:43.137816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer_loop_folds(n_folds, df_test, model_saved_path, model_type):\n    \n#     log_file = os.path.join(model_saved_path, 'log_of_each_fold_infer.txt')\n    \n    print('length of test dataset:', len(df_test))\n\n    predictions = []\n    drop_fold = np.random.randint(5)\n    for i in range(n_folds):\n        if '-' in model_type:\n            model_path = model_saved_path + '/fold-' + str(i) + model_type\n        else:\n            model_path = model_saved_path + '/fold_' + str(i) + model_type\n        outputs = infer_single_model(model_path, df_test)    \n        preds = outputs.predictions.reshape(-1).tolist()\n        predictions.append(preds)\n        print('Fold', i, 'predicting finished...')\n    \n#         df_pred_fold = pd.DataFrame({'id': df_test['id'], 'score': preds})\n#         score = np.corrcoef(preds, df_test['score'].values)[0][1]\n#         df_pred_fold.to_csv(model_saved_path + '/pred_single_fold_' + str(i) + '_(' + str(round(score, 4)) + ').csv', index=False)\n    return predictions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:03:43.565457Z","iopub.execute_input":"2022-05-10T02:03:43.566023Z","iopub.status.idle":"2022-05-10T02:03:43.57352Z","shell.execute_reply.started":"2022-05-10T02:03:43.565984Z","shell.execute_reply":"2022-05-10T02:03:43.572542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer_pipeline(input_path, cpc_path, input_type, model_path, model_save_path, model_type):\n    \"\"\"\n    load the and preprocess the data\n    \"\"\"\n    \n    test_file = os.path.join(input_path, 'test.csv')\n    df_test = pd.read_csv(test_file)\n\n    df_cpc = pd.read_csv(cpc_path)\n    cpc_dict = load_cpc_dict(df_cpc)\n\n    data_type = input_type.split('_')[-2]\n    n_folds = int(input_type.split('_')[0])\n    \n    df_test_typed = preprocess_data(df_test, cpc_dict, data_type)\n\n\n    model_saved_path_loop_folds = os.path.join(model_save_path, input_type)\n    predictions = infer_loop_folds(n_folds, df_test_typed, model_saved_path_loop_folds, model_type)\n    return predictions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:03:43.998058Z","iopub.execute_input":"2022-05-10T02:03:43.99832Z","iopub.status.idle":"2022-05-10T02:03:44.005289Z","shell.execute_reply.started":"2022-05-10T02:03:43.998278Z","shell.execute_reply":"2022-05-10T02:03:44.004375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer_other_type(input_path, cpc_path, input_type, model_saved_path):\n    test_file = os.path.join(input_path, 'test.csv')\n    df_test = pd.read_csv(test_file)\n\n    df_cpc = pd.read_csv(cpc_path)\n    cpc_dict = load_cpc_dict(df_cpc)\n\n    data_type = input_type.split('_')[-2]\n    n_folds = int(input_type.split('_')[0])\n    \n    df_test_typed = preprocess_data(df_test, cpc_dict, data_type)\n    predictions = []\n    \n    for i in range(n_folds):\n        \n        model_path = model_saved_path + '/fold_' + str(i) + '/best_model_end'\n\n        outputs = infer_single_model(model_path, df_test)    \n        preds = outputs.predictions.reshape(-1).tolist()\n        predictions.append(preds)\n        print('Fold', i, 'predicting finished...')\n    output_single = infer_single_model('../input/kfold-model-atc-b4p', df_test)\n    pred_single = output_single.predictions.reshape(-1).tolist()\n    predictions.append(pred_single)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-10T02:03:44.410713Z","iopub.execute_input":"2022-05-10T02:03:44.411257Z","iopub.status.idle":"2022-05-10T02:03:44.419402Z","shell.execute_reply.started":"2022-05-10T02:03:44.411216Z","shell.execute_reply":"2022-05-10T02:03:44.418691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score2word = {\n    \n}\ndef preprocess_mask_on_test(sentence, model, tokenizer):\n    \"\"\"\n    anchor and target in context are scoremap[] similar.\n    \"\"\"\n    \n    tokenized_input = tokenizer(sentence, return_tensors='pt')\n    mask_index = torch.where(tokenized_input.input_ids[0] == tokenizer.mask_token_id)\n    output = model(**tokenized_input)\n    logits = output.logits\n    softmax = F.softmax(logits, dim=-1)\n    mask_word = softmax[0, mask_index, :]\n    top_1 = torch.topk(mask_word, 1, dim=1)[1][0]\n    for token in top_1:\n        word = tokenizer.decode([token])\n        new_sentence = sentence.replace(tokenizer.mask_token, word)\n        # print(new_sentence)\n    return new_sentence\n\n\ndef preprocess_train_data(df, cpc_dict, score2word, tokenizer):\n\n    df['word_score'] = df.score.map(score2word)\n    df['context_text'] = df.context.map(cpc_dict)\n    # tokenizer.add_tokens(list(cpc_dict.values()))\n    # to make the \n    # df['input'] = df['section_text'] + ' ' + df['context_text'] + tokenizer.sep_token + df['anchor'] + tokenizer.sep_token + df['target']\n    df['input'] = df['anchor'] + ' and ' + df['target'] + ' in ' + df['context_text'] + ' classifications are ' + tokenizer.mask_token + ' similar.'\n    return df\n\n\ndef preprocess_test_data(df, cpc_dict, model_for_mask, tokenizer):\n    df['context_text'] = df.context.map(cpc_dict)\n\n    df['input'] = df['anchor'] + ' and ' + df['target'] + ' in ' + df['context_text'] + ' classifications are ' + tokenizer.mask_token + ' similar.'\n    # for i in range(len(df)):\n    #     df.loc[i, 'input'] = preprocess_mask_on_test(df.loc[i, 'input'], model_for_mask, tokenizer)\n    # print(df.input.head())\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer_single_model_sent(df_test, model, tokenizer):\n    # process test\n    test_dataset = TestDataset(df_test, tokenizer)\n    trainer = Trainer(\n        model=model,\n        tokenizer=tokenizer,\n    )\n    outputs = trainer.predict(test_dataset)\n    preds = outputs.predictions.reshape(-1).tolist()\n    return preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer_pipeline_sent(input_path, cpc_path, score2word, model_saved_path):\n    \"\"\"\n    infer from all models \n    \"\"\"\n    \n    test_file = os.path.join(input_path, 'test.csv')\n    \n    df_test = pd.read_csv(test_file)\n\n\n    df_cpc = pd.read_csv(cpc_path)\n    cpc_dict = load_cpc_dict(df_cpc)\n\n    model_list = os.listdir(model_saved_path)\n    preds = []\n    for model_name in model_list:\n        model_file = os.path.join(model_saved_path, model_name)\n        if os.path.exists(model_file + '/pytorch_model.bin'):\n            tokenizer = AutoTokenizer.from_pretrained(model_file)\n            model = AutoModelForSequenceClassification.from_pretrained(model_file, num_labels=1)\n            model_for_mask = None\n            df_test_processed = preprocess_test_data(df_test, cpc_dict, model_for_mask, tokenizer)\n            pred = infer_single_model_sent(df_test_processed, model, tokenizer)\n            preds.append(pred)\n        else:\n            print('Model with folds...')\n            for i in range(5):\n                model_path_fold = model_file + '/fold-' + str(i) + '_model'\n                tokenizer = AutoTokenizer.from_pretrained(model_path_fold)\n                model = AutoModelForSequenceClassification.from_pretrained(model_path_fold, num_labels=1)\n                model_for_mask = None\n                df_test_processed = preprocess_test_data(df_test, cpc_dict, model_for_mask, tokenizer)\n                pred = infer_single_model_sent(df_test_processed, model, tokenizer)\n                preds.append(pred)\n                \n    return preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    # df_submission = pd.read_csv(os.path.join(INPUT_PATH, 'sample_submission.csv'))\n    df_test = pd.read_csv(os.path.join(INPUT_PATH, 'test.csv'))\n    df_submission = pd.read_csv(os.path.join(INPUT_PATH, 'sample_submission.csv'))\n    predictions = []\n    model_save_path = MODEL_SAVE_PATH\n    model_save_path = '../input/model-all-with-higher-score'\n    for in_type in INPUT_TYPE:\n        if not os.path.exists(model_save_path + '/' + in_type):\n            continue\n        if 'DB' not in in_type:\n            continue\n        pred_in_type = infer_pipeline(INPUT_PATH, CPC_PATH, in_type, MODEL_PATH, model_save_path, '_model')\n        for pred in pred_in_type:\n            predictions.append(pred)\n    model_save_path = '../input/trained-model-all'\n    for in_type in INPUT_TYPE:\n        if not os.path.exists(model_save_path + '/' + in_type) or in_type == '5_Fold_ATSCC_DB':\n            continue\n        if 'DB' not in in_type:\n            continue\n        pred_in_type = infer_pipeline(INPUT_PATH, CPC_PATH, in_type, MODEL_PATH, model_save_path, '_best_model_end')\n        for pred in pred_in_type:\n            predictions.append(pred)\n#     model_saved_path = '../input/model-trans-to-sent'\n#     preds = infer_pipeline_sent(INPUT_PATH, CPC_PATH, score2word, model_saved_path)\n#     for pred in preds:\n#         predictions.append(pred)\n    model_save_path = '../input/model-gkf'\n    for in_type in INPUT_TYPE:\n        if not os.path.exists(model_save_path + '/' + in_type):\n            continue\n        if 'DB' not in in_type:\n            continue\n        pred_in_type = infer_pipeline(INPUT_PATH, CPC_PATH, in_type, MODEL_PATH, model_save_path, '-model')\n        for pred in pred_in_type:\n            predictions.append(pred)\n    predictions_mean = np.mean(predictions, axis=0)\n    df_submission['score'] = predictions_mean\n    df_submission.to_csv('submission.csv', index=False)\n    print('Infering finished...  Predictions size:', len(predictions))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-02T05:24:53.809467Z","iopub.execute_input":"2022-06-02T05:24:53.809863Z","iopub.status.idle":"2022-06-02T05:24:53.896948Z","shell.execute_reply.started":"2022-06-02T05:24:53.809757Z","shell.execute_reply":"2022-06-02T05:24:53.895848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}