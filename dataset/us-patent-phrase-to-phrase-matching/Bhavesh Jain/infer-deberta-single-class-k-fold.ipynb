{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inferring predictions using an ensemble model of DeBERTa-v3-large and DeBERTa-v3-small model with single class classification\n\nRefer to the training notebook:\n\nhttps://www.kaggle.com/bhavesjain/train-deberta-single-class-k-fold","metadata":{}},{"cell_type":"code","source":"# Import relevant modules\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numpy.linalg import norm\nfrom scipy.stats import pearsonr\nfrom sklearn.model_selection import train_test_split\n\nimport os\n        \nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize, pos_tag\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, SequentialSampler\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nimport datasets\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import DebertaTokenizer, DebertaForSequenceClassification, AdamW, AutoModel, AutoConfig, AutoTokenizer\nfrom transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-14T07:07:43.778689Z","iopub.execute_input":"2022-06-14T07:07:43.779076Z","iopub.status.idle":"2022-06-14T07:07:43.787228Z","shell.execute_reply.started":"2022-06-14T07:07:43.779044Z","shell.execute_reply":"2022-06-14T07:07:43.786362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lemmatizer and prerocessing functions","metadata":{}},{"cell_type":"code","source":"wnl = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:43.807798Z","iopub.execute_input":"2022-06-14T07:07:43.808375Z","iopub.status.idle":"2022-06-14T07:07:43.815784Z","shell.execute_reply.started":"2022-06-14T07:07:43.808347Z","shell.execute_reply":"2022-06-14T07:07:43.815053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(corpus, remove_stop_words = True):\n    '''\n    Function to clean a given corpus - lower the words, strip of the spaces, remove stopwords and lemmatize the corpus\n    Args:\n        corpus: the text to be cleaned\n        remove_stop_words: whether to remove stopwords\n    Returns:\n        filtered_sentence: cleaned corpus\n    '''\n    corpus = corpus.lower().strip()\n    word_tokens = word_tokenize(corpus)\n    if remove_stop_words:\n        filtered_sentence = \" \".join([wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(corpus)) if i not in stop_words])\n    else:\n        filtered_sentence = \" \".join([wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(corpus))])\n    return filtered_sentence\n\ndef cosine(a,b):\n    '''\n    Function to calculate cosine similarity of two vectors\n    Args:\n        a,b: vectors to calculate cosine between\n    Returns:\n        cosine similarity of the given vectors\n    '''\n    return np.dot(a,b)/(norm(a)*norm(b))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:43.825332Z","iopub.execute_input":"2022-06-14T07:07:43.825845Z","iopub.status.idle":"2022-06-14T07:07:43.83556Z","shell.execute_reply.started":"2022-06-14T07:07:43.82582Z","shell.execute_reply":"2022-06-14T07:07:43.834685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading and preprocessing the data","metadata":{}},{"cell_type":"code","source":"code_df = pd.read_csv(\"/kaggle/input/cpc-codes/titles.csv\")[[\"code\",\"title\"]]\ntest_df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\ntest_df = pd.merge(test_df, code_df, left_on=\"context\",right_on=\"code\",how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:43.839176Z","iopub.execute_input":"2022-06-14T07:07:43.839754Z","iopub.status.idle":"2022-06-14T07:07:44.598829Z","shell.execute_reply.started":"2022-06-14T07:07:43.839727Z","shell.execute_reply":"2022-06-14T07:07:44.597994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cleaning the text\ntest_df[\"anchor\"] = test_df[\"anchor\"].apply(lambda x: clean_text(x,False))\ntest_df[\"target\"] = test_df[\"target\"].apply(lambda x: clean_text(x,False))\ntest_df[\"title\"] = test_df[\"title\"].apply(lambda x: clean_text(x,False))\n\n# Concatenating the anchor, target and context\ntest_df[\"text\"] = test_df.apply(lambda x:'[CLS] '+ x[\"anchor\"]+' [SEP] '+x[\"title\"]+' [SEP] '+x[\"target\"],axis=1)\ntest_df = test_df.drop(columns = [\"anchor\", \"target\", \"context\", \"code\", \"title\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:44.600389Z","iopub.execute_input":"2022-06-14T07:07:44.600731Z","iopub.status.idle":"2022-06-14T07:07:44.682357Z","shell.execute_reply.started":"2022-06-14T07:07:44.600698Z","shell.execute_reply":"2022-06-14T07:07:44.681663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the model and tokenzier","metadata":{}},{"cell_type":"code","source":"folds = 5","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:44.683464Z","iopub.execute_input":"2022-06-14T07:07:44.683789Z","iopub.status.idle":"2022-06-14T07:07:44.687663Z","shell.execute_reply.started":"2022-06-14T07:07:44.683755Z","shell.execute_reply":"2022-06-14T07:07:44.686877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:44.689734Z","iopub.execute_input":"2022-06-14T07:07:44.690604Z","iopub.status.idle":"2022-06-14T07:07:44.696748Z","shell.execute_reply.started":"2022-06-14T07:07:44.690566Z","shell.execute_reply":"2022-06-14T07:07:44.69595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/deberta-5-fold/deberta-fold-1/kaggle/working/uspppm_1')\n\ndef process(unit, eval = False):\n    x = unit[\"text\"]    \n    return {**test_tokenizer(x,truncation=True, padding=True)}\n\ndef InferDataset(dataframe):\n    data = datasets.Dataset.from_pandas(dataframe)\n    data = data.map(process,remove_columns=[\"id\",\"text\",\"__index_level_0__\"])\n    return data\n\ntest_data = InferDataset(test_df)\n\nfor fold in range(folds):\n    model_path = f\"/kaggle/input/deberta-5-fold/deberta-fold-{fold}/kaggle/working/uspppm_{fold}\"\n    \n    model = DebertaV2ForSequenceClassification.from_pretrained(model_path,num_labels=1)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    print(\"Model loaded\")\n    \n    trainer = Trainer(\n                model,\n                tokenizer=test_tokenizer,\n            )\n\n    outputs = trainer.predict(test_data)\n    prediction = outputs.predictions.reshape(-1)\n    predictions.append(prediction)\n    \n    del outputs, prediction, trainer, model","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:07:44.697853Z","iopub.execute_input":"2022-06-14T07:07:44.698299Z","iopub.status.idle":"2022-06-14T07:09:17.995812Z","shell.execute_reply.started":"2022-06-14T07:07:44.69824Z","shell.execute_reply":"2022-06-14T07:09:17.995138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/deberta-small-5-fold/deberta-fold-1/kaggle/working/uspppm_1')\n\ndef process(unit, eval = False):\n    x = unit[\"text\"]    \n    return {**test_tokenizer(x,truncation=True, padding=True)}\n\ndef InferDataset(dataframe):\n    data = datasets.Dataset.from_pandas(dataframe)\n    data = data.map(process,remove_columns=[\"id\",\"text\",\"__index_level_0__\"])\n    return data\n\ntest_data = InferDataset(test_df)\n\nfor fold in range(folds):\n    model_path = f\"/kaggle/input/deberta-small-5-fold/deberta-fold-{fold}/kaggle/working/uspppm_{fold}\"\n    \n    model = DebertaV2ForSequenceClassification.from_pretrained(model_path,num_labels=1)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    print(\"Model loaded\")\n    \n    trainer = Trainer(\n                model,\n                tokenizer=test_tokenizer,\n            )\n\n    outputs = trainer.predict(test_data)\n    prediction = outputs.predictions.reshape(-1)\n    predictions.append(prediction)\n    \n    del outputs, prediction, trainer, model","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:17.997255Z","iopub.execute_input":"2022-06-14T07:09:17.997612Z","iopub.status.idle":"2022-06-14T07:09:51.742891Z","shell.execute_reply.started":"2022-06-14T07:09:17.997576Z","shell.execute_reply":"2022-06-14T07:09:51.742206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predictions.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.744212Z","iopub.execute_input":"2022-06-14T07:09:51.744536Z","iopub.status.idle":"2022-06-14T07:09:51.748553Z","shell.execute_reply.started":"2022-06-14T07:09:51.744502Z","shell.execute_reply":"2022-06-14T07:09:51.747404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = preds.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.749952Z","iopub.execute_input":"2022-06-14T07:09:51.750557Z","iopub.status.idle":"2022-06-14T07:09:51.757619Z","shell.execute_reply.started":"2022-06-14T07:09:51.750523Z","shell.execute_reply":"2022-06-14T07:09:51.756966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lim(x):\n    if x<0:\n        return 0\n    elif x>1:\n        return 1\n    return x\n\n# def lim1(x):\n#     if x<0.1:\n#         return 0\n#     elif x>0.9:\n#         return 1\n#     return x\n\n# def lim2(x):\n#     if x<0.1:\n#         return 0\n#     elif x>0.9:\n#         return 1\n#     elif x>0.2 and x<0.3:\n#         return 0.25\n#     elif x>0.45 and x<0.55:\n#         return 0.5\n#     elif x>0.7 and x<0.8:\n#         return 0.75\n#     return x\n# def lim3(x):\n#     if x<0.1:\n#         return 0\n#     elif x>0.9:\n#         return 1\n#     elif x>0.15 and x<0.35:\n#         return 0.25\n#     elif x>0.4 and x<0.6:\n#         return 0.5\n#     elif x>0.65 and x<0.85:\n#         return 0.75\n#     return x\n# def lim4(x):\n#     if x<0.01:\n#         return 0\n#     elif x>0.99:\n#         return 1\n#     elif x>0.24 and x<0.26:\n#         return 0.25\n#     elif x>0.49 and x<0.51:\n#         return 0.5\n#     elif x>0.74 and x<0.76:\n#         return 0.75\n#     return x","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.758854Z","iopub.execute_input":"2022-06-14T07:09:51.759355Z","iopub.status.idle":"2022-06-14T07:09:51.76855Z","shell.execute_reply.started":"2022-06-14T07:09:51.759319Z","shell.execute_reply":"2022-06-14T07:09:51.76778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = preds.copy()\npredictions = np.mean(predictions,axis=0)\npredictions = [lim(x) for x in predictions]\n\n# np.corrcoef(predictions,test_df[\"score\"].tolist())","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.771057Z","iopub.execute_input":"2022-06-14T07:09:51.771473Z","iopub.status.idle":"2022-06-14T07:09:51.782126Z","shell.execute_reply.started":"2022-06-14T07:09:51.77144Z","shell.execute_reply":"2022-06-14T07:09:51.781377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"score\"] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.783294Z","iopub.execute_input":"2022-06-14T07:09:51.783728Z","iopub.status.idle":"2022-06-14T07:09:51.791478Z","shell.execute_reply.started":"2022-06-14T07:09:51.783651Z","shell.execute_reply":"2022-06-14T07:09:51.790772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test_df.drop(columns=[\"text\"])\nsubmission_df.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.794157Z","iopub.execute_input":"2022-06-14T07:09:51.794399Z","iopub.status.idle":"2022-06-14T07:09:51.803388Z","shell.execute_reply.started":"2022-06-14T07:09:51.794377Z","shell.execute_reply":"2022-06-14T07:09:51.802675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T07:09:51.804667Z","iopub.execute_input":"2022-06-14T07:09:51.805588Z","iopub.status.idle":"2022-06-14T07:09:51.81684Z","shell.execute_reply.started":"2022-06-14T07:09:51.805552Z","shell.execute_reply":"2022-06-14T07:09:51.816086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}