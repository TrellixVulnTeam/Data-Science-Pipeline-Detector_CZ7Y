{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nimport warnings\nimport logging\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-29T23:03:28.225154Z","iopub.execute_input":"2022-05-29T23:03:28.22574Z","iopub.status.idle":"2022-05-29T23:03:28.230571Z","shell.execute_reply.started":"2022-05-29T23:03:28.225704Z","shell.execute_reply":"2022-05-29T23:03:28.229739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\nlogging.disable(logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T23:04:01.325866Z","iopub.execute_input":"2022-05-29T23:04:01.32652Z","iopub.status.idle":"2022-05-29T23:04:01.33181Z","shell.execute_reply.started":"2022-05-29T23:04:01.326483Z","shell.execute_reply":"2022-05-29T23:04:01.330677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import load_dataset, Dataset, DatasetDict","metadata":{"execution":{"iopub.status.busy":"2022-05-29T22:57:15.349923Z","iopub.execute_input":"2022-05-29T22:57:15.350709Z","iopub.status.idle":"2022-05-29T22:57:16.061526Z","shell.execute_reply.started":"2022-05-29T22:57:15.350671Z","shell.execute_reply":"2022-05-29T22:57:16.060753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_df(df, tokenizer):\n    df = df.rename(columns={\"score\": \"label\"})\n    sep = \" \" + tokenizer.sep_token + \" \"\n    df[\"section\"] = df[\"context\"].map(lambda val: val.strip()[0])\n    df[\"sec_tok\"] = \"[\" + df[\"section\"] + \"]\"\n    df[\"inputs\"] = (df[\"sec_tok\"] + sep + \n                    df[\"context\"] + sep + \n                    df[\"anchor\"].str.lower() + sep + \n                    df[\"target\"].str.lower()\n                   )\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-29T23:34:54.08771Z","iopub.execute_input":"2022-05-29T23:34:54.087981Z","iopub.status.idle":"2022-05-29T23:34:54.097576Z","shell.execute_reply.started":"2022-05-29T23:34:54.087951Z","shell.execute_reply":"2022-05-29T23:34:54.096902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ds(df, tok_func):\n    ds = Dataset.from_pandas(df)\n    remove_cols = [\"id\", \"anchor\", \"target\", \"context\", \"section\"]\n    ds = ds.map(tok_func, batched=True, remove_columns=remove_cols)\n    return ds\n\ndef get_model(model_name):\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n    return model\n\ndef get_tokenizer(model_name):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    return tokenizer\n\ndef tok_func(x): \n    return tokz(x[\"inputs\"])\n\n\ndef corr(eval_pred): \n    return {'pearson': np.corrcoef(*eval_pred)[0][1]}","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:15:06.468913Z","iopub.execute_input":"2022-05-30T00:15:06.469179Z","iopub.status.idle":"2022-05-30T00:15:06.475642Z","shell.execute_reply.started":"2022-05-30T00:15:06.469148Z","shell.execute_reply":"2022-05-30T00:15:06.474913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"microsoft/deberta-v3-small\"\n\nmodel = get_model(model_name)\ntokenizer = get_tokenizer(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:11:12.815772Z","iopub.execute_input":"2022-05-30T00:11:12.816295Z","iopub.status.idle":"2022-05-30T00:11:19.092333Z","shell.execute_reply.started":"2022-05-30T00:11:12.816258Z","shell.execute_reply":"2022-05-30T00:11:19.091508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = Path(\"../input/us-patent-phrase-to-phrase-matching\")\n\ntrain_df = pd.read_csv(DATA_DIR / \"train.csv\")\ntest_df = pd.read_csv(DATA_DIR / \"train.csv\")\n\ntrain_df = prepare_df(train_df, tokenizer)\ntest_df = prepare_df(test_df, tokenizer)\n\ntokenizer.add_special_tokens({\"additional_special_tokens\": list(train_df.sec_tok.unique())})\nmodel.resize_token_embeddings(len(tokenizer))\nprint(tokenizer.special_tokens_map)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:11:19.095799Z","iopub.execute_input":"2022-05-30T00:11:19.096283Z","iopub.status.idle":"2022-05-30T00:11:21.004689Z","shell.execute_reply.started":"2022-05-30T00:11:19.09625Z","shell.execute_reply":"2022-05-30T00:11:21.003905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:11:21.005826Z","iopub.execute_input":"2022-05-30T00:11:21.006541Z","iopub.status.idle":"2022-05-30T00:11:21.042866Z","shell.execute_reply.started":"2022-05-30T00:11:21.0065Z","shell.execute_reply":"2022-05-30T00:11:21.041945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)\nanchors = np.random.permutation(train_df[\"anchor\"].unique())\nvalid_anchor_count = int(len(anchors) * 0.25)\nvalid_anchors = anchors[:valid_anchor_count]\nvalid_indxs = train_df[train_df[\"anchor\"].isin(valid_anchors)].index\ntrain_indxs = train_df[~train_df[\"anchor\"].isin(valid_anchors)].index\n\ntrain_ds = get_ds(train_df.iloc[train_indxs], tok_func=lambda x: tokenizer(x[\"inputs\"]))\nvalid_ds = get_ds(train_df.iloc[valid_indxs], tok_func=lambda x: tokenizer(x[\"inputs\"]))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:15:09.847572Z","iopub.execute_input":"2022-05-30T00:15:09.848312Z","iopub.status.idle":"2022-05-30T00:15:17.630718Z","shell.execute_reply.started":"2022-05-30T00:15:09.848274Z","shell.execute_reply":"2022-05-30T00:15:17.629904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_trainer(model, train_ds, eval_ds, tokenizer, **training_args):\n    args = TrainingArguments(\"outputs\", **training_args)\n    trainer = Trainer(model, \n                      args, \n                      train_dataset=train_ds, \n                      eval_dataset=eval_ds, \n                      tokenizer=tokenizer, \n                      compute_metrics=corr)\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:15:19.268891Z","iopub.execute_input":"2022-05-30T00:15:19.269456Z","iopub.status.idle":"2022-05-30T00:15:19.276289Z","shell.execute_reply.started":"2022-05-30T00:15:19.269416Z","shell.execute_reply":"2022-05-30T00:15:19.273485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = dict(\n    learning_rate=8e-5,\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    fp16=True,\n    lr_scheduler_type='cosine',\n    evaluation_strategy='epoch',\n    per_device_train_batch_size=128,\n    per_device_eval_batch_size=256,\n    num_train_epochs=4,\n    report_to='none'\n)\ntrainer = get_trainer(model, train_ds, valid_ds, tokenizer, **training_args)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:15:20.32527Z","iopub.execute_input":"2022-05-30T00:15:20.326014Z","iopub.status.idle":"2022-05-30T00:15:20.338207Z","shell.execute_reply.started":"2022-05-30T00:15:20.325964Z","shell.execute_reply":"2022-05-30T00:15:20.33749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:15:21.951478Z","iopub.execute_input":"2022-05-30T00:15:21.953626Z","iopub.status.idle":"2022-05-30T00:15:21.959013Z","shell.execute_reply.started":"2022-05-30T00:15:21.953592Z","shell.execute_reply":"2022-05-30T00:15:21.958303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:15:29.669047Z","iopub.execute_input":"2022-05-30T00:15:29.669307Z","iopub.status.idle":"2022-05-30T00:19:36.078233Z","shell.execute_reply.started":"2022-05-30T00:15:29.669276Z","shell.execute_reply":"2022-05-30T00:19:36.077403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"deberta_small_v1/model\")\ntokenizer.save_pretrained(\"deberta_small_v1/tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:47:08.458904Z","iopub.execute_input":"2022-05-30T00:47:08.459388Z","iopub.status.idle":"2022-05-30T00:47:10.105615Z","shell.execute_reply.started":"2022-05-30T00:47:08.459342Z","shell.execute_reply":"2022-05-30T00:47:10.104801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls \"/kaggle/working/model\"","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:40:53.229463Z","iopub.execute_input":"2022-05-30T00:40:53.229724Z","iopub.status.idle":"2022-05-30T00:40:53.957112Z","shell.execute_reply.started":"2022-05-30T00:40:53.229693Z","shell.execute_reply":"2022-05-30T00:40:53.956241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/model\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/tokenizer\")\ntrainer = Trainer(model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:39:52.023885Z","iopub.execute_input":"2022-05-30T00:39:52.024627Z","iopub.status.idle":"2022-05-30T00:39:55.240431Z","shell.execute_reply.started":"2022-05-30T00:39:52.024589Z","shell.execute_reply":"2022-05-30T00:39:55.239536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation\ntest_df = pd.read_csv(DATA_DIR / \"test.csv\")\ntest_df = prepare_df(test_df, tokenizer)\ntest_ds = get_ds(test_df,  tok_func=lambda x: tokenizer(x[\"inputs\"]))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:39:55.735812Z","iopub.execute_input":"2022-05-30T00:39:55.736552Z","iopub.status.idle":"2022-05-30T00:39:55.802662Z","shell.execute_reply.started":"2022-05-30T00:39:55.736512Z","shell.execute_reply":"2022-05-30T00:39:55.801897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"deberta_small_v1\", 'zip', \"/kaggle/working/deberta_small_v1\")","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:47:33.654745Z","iopub.execute_input":"2022-05-30T00:47:33.655424Z","iopub.status.idle":"2022-05-30T00:48:08.241953Z","shell.execute_reply.started":"2022-05-30T00:47:33.65538Z","shell.execute_reply":"2022-05-30T00:48:08.241213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = trainer.predict(test_ds).predictions.astype(float)\npreds = np.clip(preds, 0, 1).reshape(-1)\n\nsub_df = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"score\": preds\n})\nsub_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T00:40:01.769411Z","iopub.execute_input":"2022-05-30T00:40:01.769669Z","iopub.status.idle":"2022-05-30T00:40:01.856517Z","shell.execute_reply.started":"2022-05-30T00:40:01.769638Z","shell.execute_reply":"2022-05-30T00:40:01.855885Z"},"trusted":true},"execution_count":null,"outputs":[]}]}