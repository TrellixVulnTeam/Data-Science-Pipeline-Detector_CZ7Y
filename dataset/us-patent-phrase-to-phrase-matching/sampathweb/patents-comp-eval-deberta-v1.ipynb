{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-30T01:02:55.822513Z","iopub.execute_input":"2022-05-30T01:02:55.822976Z","iopub.status.idle":"2022-05-30T01:02:55.864498Z","shell.execute_reply.started":"2022-05-30T01:02:55.822888Z","shell.execute_reply":"2022-05-30T01:02:55.863509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer\nfrom datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-30T01:03:57.619881Z","iopub.execute_input":"2022-05-30T01:03:57.620554Z","iopub.status.idle":"2022-05-30T01:03:59.332869Z","shell.execute_reply.started":"2022-05-30T01:03:57.620516Z","shell.execute_reply":"2022-05-30T01:03:59.331856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_df(df, tokenizer):\n    df = df.rename(columns={\"score\": \"label\"})\n    sep = \" \" + tokenizer.sep_token + \" \"\n    df[\"section\"] = df[\"context\"].map(lambda val: val.strip()[0])\n    df[\"sec_tok\"] = \"[\" + df[\"section\"] + \"]\"\n    df[\"inputs\"] = (df[\"sec_tok\"] + sep + \n                    df[\"context\"] + sep + \n                    df[\"anchor\"].str.lower() + sep + \n                    df[\"target\"].str.lower()\n                   )\n    return df\n\ndef get_ds(df, tok_func):\n    ds = Dataset.from_pandas(df)\n    remove_cols = [\"id\", \"anchor\", \"target\", \"context\", \"section\"]\n    ds = ds.map(tok_func, batched=True, remove_columns=remove_cols)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-05-30T01:06:00.101823Z","iopub.execute_input":"2022-05-30T01:06:00.10266Z","iopub.status.idle":"2022-05-30T01:06:00.113423Z","shell.execute_reply.started":"2022-05-30T01:06:00.10262Z","shell.execute_reply":"2022-05-30T01:06:00.112428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"../input/patents-comp/model\")\ntokenizer = AutoTokenizer.from_pretrained(\"../input/patents-comp/tokenizer\")\ntrainer = Trainer(model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T01:06:37.926474Z","iopub.execute_input":"2022-05-30T01:06:37.926884Z","iopub.status.idle":"2022-05-30T01:06:47.072193Z","shell.execute_reply.started":"2022-05-30T01:06:37.926851Z","shell.execute_reply":"2022-05-30T01:06:47.070803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation\ntest_df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\ntest_df = prepare_df(test_df, tokenizer)\ntest_ds = get_ds(test_df,  tok_func=lambda x: tokenizer(x[\"inputs\"]))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T01:06:47.074366Z","iopub.execute_input":"2022-05-30T01:06:47.074731Z","iopub.status.idle":"2022-05-30T01:06:47.232334Z","shell.execute_reply.started":"2022-05-30T01:06:47.074696Z","shell.execute_reply":"2022-05-30T01:06:47.231344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = trainer.predict(test_ds).predictions.astype(float)\npreds = np.clip(preds, 0, 1).reshape(-1)\n\nsub_df = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"score\": preds\n})\nsub_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T01:07:07.778241Z","iopub.execute_input":"2022-05-30T01:07:07.779215Z","iopub.status.idle":"2022-05-30T01:07:09.183714Z","shell.execute_reply.started":"2022-05-30T01:07:07.77916Z","shell.execute_reply":"2022-05-30T01:07:09.182748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}