{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n- Deberta-v3-large starter code\n- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n- Training notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train)\n\nIf this notebook is helpful, feel free to upvote :)","metadata":{"id":"e460cbb5","papermill":{"duration":0.027808,"end_time":"2022-03-22T09:40:01.410751","exception":false,"start_time":"2022-03-22T09:40:01.382943","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 直接copy的noetbook改的，所以模型里有很多冗余内容，懒得删了，模型唯一的改动应该layernorm加meanpooling，至于训练参数纯属碰运气，结果从0.8323到0.8433都有。","metadata":{}},{"cell_type":"markdown","source":"# The training notebook was directly copied and changed from the above noetbook, so there are a lot of redundant codes in the model， I am too lazy to delete it. The only change to the model should be layernorm and meanpooling. As for the training parameters, it is purely luck, and the results range from 0.8323 to 0.8433.  .","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"id":"fa3b873b","papermill":{"duration":0.041313,"end_time":"2022-03-22T09:40:01.526545","exception":false,"start_time":"2022-03-22T09:40:01.485232","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:02:58.404365Z","iopub.execute_input":"2022-06-07T03:02:58.40471Z","iopub.status.idle":"2022-06-07T03:02:58.440315Z","shell.execute_reply.started":"2022-06-07T03:02:58.40463Z","shell.execute_reply":"2022-06-07T03:02:58.439361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"id":"1d0c4430","papermill":{"duration":0.024609,"end_time":"2022-03-22T09:40:01.576366","exception":false,"start_time":"2022-03-22T09:40:01.551757","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-v3-large-baseline-w-w-b-train/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{"id":"48dd82bb","papermill":{"duration":0.033949,"end_time":"2022-03-22T09:40:01.634977","exception":false,"start_time":"2022-03-22T09:40:01.601028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:02:58.442262Z","iopub.execute_input":"2022-06-07T03:02:58.443128Z","iopub.status.idle":"2022-06-07T03:02:58.450189Z","shell.execute_reply.started":"2022-06-07T03:02:58.443085Z","shell.execute_reply":"2022-06-07T03:02:58.449206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"id":"f2ed8ef2","papermill":{"duration":0.038261,"end_time":"2022-03-22T09:40:10.626926","exception":false,"start_time":"2022-03-22T09:40:10.588665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"executionInfo":{"elapsed":20123,"status":"ok","timestamp":1644920080956,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"35916341","outputId":"06fa0ab8-a380-4f54-a98d-b7015b79d9e2","papermill":{"duration":26.143536,"end_time":"2022-03-22T09:40:36.798853","exception":false,"start_time":"2022-03-22T09:40:10.655317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:02:58.451726Z","iopub.execute_input":"2022-06-07T03:02:58.453303Z","iopub.status.idle":"2022-06-07T03:03:33.371461Z","shell.execute_reply.started":"2022-06-07T03:02:58.453256Z","shell.execute_reply":"2022-06-07T03:03:33.370203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"fd586614","papermill":{"duration":0.032888,"end_time":"2022-03-22T09:40:36.865209","exception":false,"start_time":"2022-03-22T09:40:36.832321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"id":"d5c0ccc6","papermill":{"duration":0.21551,"end_time":"2022-03-22T09:40:37.116848","exception":false,"start_time":"2022-03-22T09:40:36.901338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:33.374414Z","iopub.execute_input":"2022-06-07T03:03:33.376326Z","iopub.status.idle":"2022-06-07T03:03:33.389362Z","shell.execute_reply.started":"2022-06-07T03:03:33.376279Z","shell.execute_reply":"2022-06-07T03:03:33.388293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"markdown","source":"# Data Loading","metadata":{"id":"cb3d8e1e","papermill":{"duration":0.032614,"end_time":"2022-03-22T09:40:37.184739","exception":false,"start_time":"2022-03-22T09:40:37.152125","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"executionInfo":{"elapsed":2627,"status":"ok","timestamp":1644920084001,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"bef012d3","outputId":"d4d60dbc-510c-4f34-8d64-dd1d88c4808c","papermill":{"duration":0.154829,"end_time":"2022-03-22T09:40:37.374453","exception":false,"start_time":"2022-03-22T09:40:37.219624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:33.391037Z","iopub.execute_input":"2022-06-07T03:03:33.391486Z","iopub.status.idle":"2022-06-07T03:03:33.441257Z","shell.execute_reply.started":"2022-06-07T03:03:33.391443Z","shell.execute_reply":"2022-06-07T03:03:33.440102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{"papermill":{"duration":0.848818,"end_time":"2022-03-22T09:40:38.260255","exception":false,"start_time":"2022-03-22T09:40:37.411437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:33.442598Z","iopub.execute_input":"2022-06-07T03:03:33.443366Z","iopub.status.idle":"2022-06-07T03:03:33.481727Z","shell.execute_reply.started":"2022-06-07T03:03:33.443328Z","shell.execute_reply":"2022-06-07T03:03:33.480719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{"papermill":{"duration":0.084831,"end_time":"2022-03-22T09:40:38.384239","exception":false,"start_time":"2022-03-22T09:40:38.299408","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:33.483236Z","iopub.execute_input":"2022-06-07T03:03:33.483606Z","iopub.status.idle":"2022-06-07T03:03:33.50274Z","shell.execute_reply.started":"2022-06-07T03:03:33.483558Z","shell.execute_reply":"2022-06-07T03:03:33.501461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tokenizer","metadata":{"id":"918a28aa","papermill":{"duration":0.039494,"end_time":"2022-03-22T09:40:39.374931","exception":false,"start_time":"2022-03-22T09:40:39.335437","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"papermill":{"duration":5.198604,"end_time":"2022-03-22T09:40:44.612849","exception":false,"start_time":"2022-03-22T09:40:39.414245","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:33.504692Z","iopub.execute_input":"2022-06-07T03:03:33.505674Z","iopub.status.idle":"2022-06-07T03:03:34.331802Z","shell.execute_reply.started":"2022-06-07T03:03:33.505613Z","shell.execute_reply":"2022-06-07T03:03:34.330784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"14da40cf","papermill":{"duration":0.04897,"end_time":"2022-03-22T09:40:44.706931","exception":false,"start_time":"2022-03-22T09:40:44.657961","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"id":"9f791a19","papermill":{"duration":0.055528,"end_time":"2022-03-22T09:40:52.072178","exception":false,"start_time":"2022-03-22T09:40:52.01665","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:34.333553Z","iopub.execute_input":"2022-06-07T03:03:34.333837Z","iopub.status.idle":"2022-06-07T03:03:34.343284Z","shell.execute_reply.started":"2022-06-07T03:03:34.333796Z","shell.execute_reply":"2022-06-07T03:03:34.342228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"e04d6363","papermill":{"duration":0.044161,"end_time":"2022-03-22T09:40:52.262022","exception":false,"start_time":"2022-03-22T09:40:52.217861","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n        self._init_weights(self.attention)\n        self.linear = nn.Linear(self.config.hidden_size, 1)\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        out = sum_embeddings / sum_mask\n        \n        out = self.layer_norm1(out)\n        output = self.fc(out)\n        \n        \n        return output","metadata":{"id":"4c5bab44","papermill":{"duration":0.066203,"end_time":"2022-03-22T09:40:52.37203","exception":false,"start_time":"2022-03-22T09:40:52.305827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:03:34.346871Z","iopub.execute_input":"2022-06-07T03:03:34.347465Z","iopub.status.idle":"2022-06-07T03:03:34.370211Z","shell.execute_reply.started":"2022-06-07T03:03:34.347419Z","shell.execute_reply":"2022-06-07T03:03:34.3689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"id":"deee9675","papermill":{"duration":0.044158,"end_time":"2022-03-22T09:40:52.460401","exception":false,"start_time":"2022-03-22T09:40:52.416243","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-07T03:03:34.372019Z","iopub.execute_input":"2022-06-07T03:03:34.372533Z","iopub.status.idle":"2022-06-07T03:03:34.387126Z","shell.execute_reply.started":"2022-06-07T03:03:34.372485Z","shell.execute_reply":"2022-06-07T03:03:34.386012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in range(5):\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(f'../input/debertav3large20220606/microsoft-deberta-v3-large_fold{fold}_best/microsoft-deberta-v3-large_fold{fold}_best.pth',\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-07T03:03:34.390295Z","iopub.execute_input":"2022-06-07T03:03:34.390561Z","iopub.status.idle":"2022-06-07T03:06:37.021273Z","shell.execute_reply.started":"2022-06-07T03:03:34.390497Z","shell.execute_reply":"2022-06-07T03:06:37.020203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission['score'] = predictions\ndisplay(submission.head())\nsubmission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T03:06:37.026773Z","iopub.execute_input":"2022-06-07T03:06:37.030114Z","iopub.status.idle":"2022-06-07T03:06:37.084825Z","shell.execute_reply.started":"2022-06-07T03:06:37.030062Z","shell.execute_reply":"2022-06-07T03:06:37.083834Z"},"trusted":true},"execution_count":null,"outputs":[]}]}