{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_workers = 4\n    path = \"../input/patent-na-rozum-dbl/\"  \n    path1 = \"../input/foreles/mel/\"  \n    path2 = \"../input/mybert/myb/\"\n    path2a = \"../input/myparqs/wups/\"\n    path3 = \"../input/bert768/ab768/\"\n    path4 = \"../input/dblina/\"\n    path4a = \"../input/split10f/xl/xl/\"\n    path0 = \"../input/sgkf8dbl/sgkf/\"\n    config_path1 = path1 +'config.pth'\n    config_path2 = path2 +'config.pth'\n    config_path2a = path2a +'config.pth'\n    config_path3 = path3 +'config.pth'\n    config_path4 = path4 +'config.pth'\n    config_path4a = path4a +'config.pth'\n    config_path0 = path0 +'config.pth'\n    model1 = \"google/electra-large-discriminator\"\n    model2 = \"anferico/bert-for-patents\"\n    model2a = \"microsoft/deberta-v3-large\"\n    model3 = \"anferico/bert-for-patents\"\n    model4 = \"microsoft/deberta-v3-large\"\n    model4a = \"microsoft/deberta-v2-xlarge\"\n    model0 = \"microsoft/deberta-v3-large\"\n    weights1 = \"../input/elektra/\"\n    weights2 = \"../input/berties/\"\n    weights2a = \"../input/myparqs/wups/\"\n    weights3 = \"../input/berties7/\"\n    weights4 = \"../input/dblina/\"\n    weights4a = \"../input/split10f/xl/xl/\"\n    weights0 = \"../input/sgkf8dbl/sgkf/\"\n    weights0a = \"../input/normdbl/\"\n    batch_size = 32\n    fc_dropout = 0.2\n    target_size = 1\n    max_len = 133\n    seed = 56\n    n_fold1 = 9\n    trn_fold1 = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    n_fold2 = 8\n    trn_fold2 = [0, 1, 2, 3, 4, 5, 6, 7]\n    n_fold2a = 5\n    trn_fold2a = [0, 1, 2, 3, 4]\n    n_fold3 = 5\n    trn_fold3 = [0, 1, 2, 3, 4]\n    n_fold4 = 4\n    trn_fold4 = [0, 1, 2, 3,]\n    n_fold4a = 3\n    trn_fold4a = [0, 1, 2]\n    n_fold0 = 8\n    trn_fold0 = [0, 1, 2, 3, 4, 5, 6, 7]  \n    n_fold0a = 5\n    trn_fold0a = [0, 1, 2, 3, 4]  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/mojekola/mk transformers')\nos.system('python -m pip install --no-index --find-links=../input/mojekola/mk tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=56):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=56)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_texts = torch.load(CFG.path0+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path0+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text, add_special_tokens=True, max_length=cfg.max_len,\n                           padding=\"max_length\", return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(nn.Linear(self.config.hidden_size, 512),\n                                       nn.Tanh(),\n                                       nn.Linear(512, 1),\n                                       nn.Softmax(dim=1) )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Normal(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(nn.Linear(self.config.hidden_size, 512),\n                                       nn.Tanh(),\n                                       nn.Linear(512, 1),\n                                       nn.Softmax(dim=1) )\n        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n        self._init_weights(self.attention)\n        self.linear = nn.Linear(self.config.hidden_size, 1)\n           \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        out = sum_embeddings / sum_mask\n        out = self.layer_norm1(out)\n        output = self.fc(out)\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel768(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc1 = nn.Linear(self.config.hidden_size, 768)\n        self.fc2 = nn.Linear(768,1)\n        self._init_weights(self.fc1)\n        self._init_weights(self.fc2)\n        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n        \n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n        \n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        out = sum_embeddings / sum_mask\n        out = self.layer_norm1(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        \n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions0 = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.trn_fold0:\n    model = CustomModel(CFG, config_path=CFG.config_path0, pretrained=False)\n    state = torch.load(CFG.weights0+f\"{CFG.model0.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions0.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\n    \nfor fold in CFG.trn_fold0a:\n    model = Normal(CFG, config_path=CFG.config_path0, pretrained=False)\n    state = torch.load(CFG.weights0a+f\"{CFG.model0.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions0.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()    \n    \npredictions0 = np.mean(predictions0, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nLOGGER = get_logger()\nseed_everything(seed=56)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_texts = torch.load(CFG.path1+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path1+'tokenizer/')\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions1 = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.trn_fold1:\n    model = Normal(CFG, config_path=CFG.config_path1, pretrained=False)\n    state = torch.load(CFG.weights1+f\"gel_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions1.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions1 = np.mean(predictions1, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nLOGGER = get_logger()\nseed_everything(seed=56)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(INPUT_DIR+'test.csv')\n\ncpc_texts = torch.load(CFG.path2+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path2+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions2 = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.trn_fold2:\n    model = Normal(CFG, config_path=CFG.config_path2, pretrained=False)\n    state = torch.load(CFG.weights2+f\"ab-patents_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions2.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions2 = np.mean(predictions2, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(INPUT_DIR+'test.csv')\n\ncpc_texts = torch.load(CFG.path2a+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path2a+'tokenizer/')\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions2a = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.trn_fold2a:\n    model = Normal(CFG, config_path=CFG.config_path2a, pretrained=False)\n    state = torch.load(CFG.weights2a + f\"{CFG.model2a.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions2a.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()    \n    \npredictions2a = np.mean(predictions2a, axis=0)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['score2a'] = predictions2a         \nsubmission['score2b'] = predictions2\nsubmission['score2']= 0.35*submission['score2b']+0.65*submission['score2a']\ndel submission['score2a']\ndel submission['score2b']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nLOGGER = get_logger()\nseed_everything(seed=56)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_texts = torch.load(CFG.path3+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path3+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions3 = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.trn_fold3:\n    model = CustomModel768(CFG, config_path=CFG.config_path3, pretrained=False)\n    state = torch.load(CFG.weights3+f\"ab768-patents_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions3.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions3 = np.mean(predictions3, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nLOGGER = get_logger()\nseed_everything(seed=56)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_texts = torch.load(CFG.path4+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path4+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions4 = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.trn_fold4:\n    model = CustomModel(CFG, config_path=CFG.config_path4, pretrained=False)\n    state = torch.load(CFG.weights4+f\"{CFG.model4.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions4.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions4 = np.mean(predictions4, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(INPUT_DIR+'test.csv')\n\ncpc_texts = torch.load(CFG.path4a+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path4a+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions4a = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\nfor fold in CFG.trn_fold4a:\n    model = CustomModel(CFG, config_path=CFG.config_path4a, pretrained=False)\n    state = torch.load(CFG.weights4a + f\"xlarge_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions4a.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\n    \npredictions4a = np.mean(predictions4a, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['score4b'] = predictions4         \nsubmission['score4a'] = predictions4a\nsubmission['score4']= 0.56*submission['score4b']+0.44*submission['score4a']\ndel submission['score4b']\ndel submission['score4a']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['score0'] = predictions0\nsubmission['score1'] = predictions1\n#submission['score2'] = predictions2\nsubmission['score3'] = predictions3         \n#submission['score4'] = predictions4\nsubmission['scoreB']=0.20*submission['score0']+0.40*submission['score1']+0.12*submission['score3']+0.28*submission['score4']\ndel submission['score0']\ndel submission['score1']\n#del submission['score2']\ndel submission['score3']\ndel submission['score4']\n\nsubmission['score']= 0.56*submission['scoreB'] + 0.44*submission['score2']\ndel submission['score2']\ndel submission['scoreB']\ndisplay(submission.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}