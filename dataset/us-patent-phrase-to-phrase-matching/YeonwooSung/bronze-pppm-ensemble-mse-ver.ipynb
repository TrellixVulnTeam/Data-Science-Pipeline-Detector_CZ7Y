{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"model 1 - pppm-mse-7-out-of-10-folds (0.8392)\n\nmodel 2 - pppm-mse-lr-15e6 (0.8380)\n\nmodel 3 - pppm-10-out-of-20-folds (0.8403)\n\nmodel 4 - pppm-bert-for-patent-5-fold (0.8281)\n\nmodel 5 - pppmdeberta (0.8385)\n\nmodel 6 - deberta v3 large mse exp 2 (0.8362)\n\nmodel 7 - deberta v3 large mse exp 3 (0.8373)\n\nmodel 8 - pppm-bert-for-patent-4-out-of-5-folds (0.8328)\n\nmodel 9 - pppm-mse-5-fold-lr15e6\n\nmodel 10 - pppm-bert-for-patents-5-fold-mse (0,8317)\n\nmodel 11 - pppm-deberta-v3-mse-exp-4 (0.8373)\n\nmodel 12 - pppm-coco-lm-large-mse-exp-1 (0.8302)\n\nmodel 13 - pppm-bert-for-patents-12-out-of-20-folds (0.8342)\n\nmodel 14 - pppm-patentsberta\n\nmodel 15 - pppm-deberta-5-out-of-10-fold (0.8380)\n\nmodel 16 - pppm-patent-sbert-mse-13-out-of-20-folds (0.7996)\n\nmodel 17 - pppm-coco-lm-large-exp-2\n\nmodel 18 - deberta-awp\n\nmodel 19 - pppm-bert-for-patents-10-out-of-25-folds\n\nmodel 20 - pppm-cocolm-large-exp-2","metadata":{"id":"e460cbb5","papermill":{"duration":0.027808,"end_time":"2022-03-22T09:40:01.410751","exception":false,"start_time":"2022-03-22T09:40:01.382943","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ensemble_divide_val = 16\n\nc1 = 1.25\nc2 = 0.25\nc3 = 1.5\nc4 = 0.25\nc5 = 1.25\nc6 = 0\nc7 = 0\nc8 = 1\nc9 = 0\nc10 = 0.75\nc11 = 0\nc12 = 1\nc13 = 1\nc14 = 0.25\nc15 = 1\n\nc16 = 0\nc17 = 0\nc18 = 0\n\nc19 = 1\nc20 = 1\nc21 = 0\nc22 = 1\nc23 = 1\nc24 = 1.5\nc25 = 0\nc26 = 0\nc27 = 0\n\nc28 = 0\nc29 = 1\nc30 = 0","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:02:28.106072Z","iopub.execute_input":"2022-06-04T10:02:28.106713Z","iopub.status.idle":"2022-06-04T10:02:28.113784Z","shell.execute_reply.started":"2022-06-04T10:02:28.106678Z","shell.execute_reply":"2022-06-04T10:02:28.112614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directory settings","metadata":{"papermill":{"duration":0.024515,"end_time":"2022-03-22T09:40:01.460332","exception":false,"start_time":"2022-03-22T09:40:01.435817","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"id":"fa3b873b","papermill":{"duration":0.041313,"end_time":"2022-03-22T09:40:01.526545","exception":false,"start_time":"2022-03-22T09:40:01.485232","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:02:28.121401Z","iopub.execute_input":"2022-06-04T10:02:28.121784Z","iopub.status.idle":"2022-06-04T10:02:28.127416Z","shell.execute_reply.started":"2022-06-04T10:02:28.12174Z","shell.execute_reply":"2022-06-04T10:02:28.126359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"id":"1d0c4430","papermill":{"duration":0.024609,"end_time":"2022-03-22T09:40:01.576366","exception":false,"start_time":"2022-03-22T09:40:01.551757","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-mse-7-out-of-10-folds/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=10\n    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7]","metadata":{"id":"48dd82bb","papermill":{"duration":0.033949,"end_time":"2022-03-22T09:40:01.634977","exception":false,"start_time":"2022-03-22T09:40:01.601028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:02:28.135136Z","iopub.execute_input":"2022-06-04T10:02:28.136128Z","iopub.status.idle":"2022-06-04T10:02:28.144432Z","shell.execute_reply.started":"2022-06-04T10:02:28.136094Z","shell.execute_reply":"2022-06-04T10:02:28.143394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"id":"f2ed8ef2","papermill":{"duration":0.038261,"end_time":"2022-03-22T09:40:10.626926","exception":false,"start_time":"2022-03-22T09:40:10.588665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\nimport tokenizers\nimport datasets, transformers\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n#os.environ[\"WANDB_DISABLED\"] = \"true\"\n\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"executionInfo":{"elapsed":20123,"status":"ok","timestamp":1644920080956,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"35916341","outputId":"06fa0ab8-a380-4f54-a98d-b7015b79d9e2","papermill":{"duration":26.143536,"end_time":"2022-03-22T09:40:36.798853","exception":false,"start_time":"2022-03-22T09:40:10.655317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:02:28.152568Z","iopub.execute_input":"2022-06-04T10:02:28.153396Z","iopub.status.idle":"2022-06-04T10:03:04.366252Z","shell.execute_reply.started":"2022-06-04T10:02:28.153365Z","shell.execute_reply":"2022-06-04T10:03:04.365168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"fd586614","papermill":{"duration":0.032888,"end_time":"2022-03-22T09:40:36.865209","exception":false,"start_time":"2022-03-22T09:40:36.832321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"id":"d5c0ccc6","papermill":{"duration":0.21551,"end_time":"2022-03-22T09:40:37.116848","exception":false,"start_time":"2022-03-22T09:40:36.901338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:04.368588Z","iopub.execute_input":"2022-06-04T10:03:04.368872Z","iopub.status.idle":"2022-06-04T10:03:04.384535Z","shell.execute_reply.started":"2022-06-04T10:03:04.368831Z","shell.execute_reply":"2022-06-04T10:03:04.383062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"code","source":"# oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n# labels = oof_df['score'].values\n# preds = oof_df['pred'].values\n# score = get_score(labels, preds)\n# LOGGER.info(f'CV Score: {score:<.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:03:04.386549Z","iopub.execute_input":"2022-06-04T10:03:04.387759Z","iopub.status.idle":"2022-06-04T10:03:04.39615Z","shell.execute_reply.started":"2022-06-04T10:03:04.387709Z","shell.execute_reply":"2022-06-04T10:03:04.395142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{"id":"cb3d8e1e","papermill":{"duration":0.032614,"end_time":"2022-03-22T09:40:37.184739","exception":false,"start_time":"2022-03-22T09:40:37.152125","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"executionInfo":{"elapsed":2627,"status":"ok","timestamp":1644920084001,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"bef012d3","outputId":"d4d60dbc-510c-4f34-8d64-dd1d88c4808c","papermill":{"duration":0.154829,"end_time":"2022-03-22T09:40:37.374453","exception":false,"start_time":"2022-03-22T09:40:37.219624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:04.399911Z","iopub.execute_input":"2022-06-04T10:03:04.40037Z","iopub.status.idle":"2022-06-04T10:03:04.443702Z","shell.execute_reply.started":"2022-06-04T10:03:04.400325Z","shell.execute_reply":"2022-06-04T10:03:04.442537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{"papermill":{"duration":0.848818,"end_time":"2022-03-22T09:40:38.260255","exception":false,"start_time":"2022-03-22T09:40:37.411437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:04.445712Z","iopub.execute_input":"2022-06-04T10:03:04.446044Z","iopub.status.idle":"2022-06-04T10:03:04.475777Z","shell.execute_reply.started":"2022-06-04T10:03:04.445987Z","shell.execute_reply":"2022-06-04T10:03:04.474868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{"papermill":{"duration":0.084831,"end_time":"2022-03-22T09:40:38.384239","exception":false,"start_time":"2022-03-22T09:40:38.299408","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:04.477559Z","iopub.execute_input":"2022-06-04T10:03:04.477881Z","iopub.status.idle":"2022-06-04T10:03:04.495469Z","shell.execute_reply.started":"2022-06-04T10:03:04.477837Z","shell.execute_reply":"2022-06-04T10:03:04.494383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tokenizer","metadata":{"id":"918a28aa","papermill":{"duration":0.039494,"end_time":"2022-03-22T09:40:39.374931","exception":false,"start_time":"2022-03-22T09:40:39.335437","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained('../input/pppm-deberta-v3-large-baseline-w-w-b-train/tokenizer/')\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"papermill":{"duration":5.198604,"end_time":"2022-03-22T09:40:44.612849","exception":false,"start_time":"2022-03-22T09:40:39.414245","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:04.49754Z","iopub.execute_input":"2022-06-04T10:03:04.498436Z","iopub.status.idle":"2022-06-04T10:03:05.602267Z","shell.execute_reply.started":"2022-06-04T10:03:04.49839Z","shell.execute_reply":"2022-06-04T10:03:05.6013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"14da40cf","papermill":{"duration":0.04897,"end_time":"2022-03-22T09:40:44.706931","exception":false,"start_time":"2022-03-22T09:40:44.657961","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"id":"9f791a19","papermill":{"duration":0.055528,"end_time":"2022-03-22T09:40:52.072178","exception":false,"start_time":"2022-03-22T09:40:52.01665","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:05.606372Z","iopub.execute_input":"2022-06-04T10:03:05.606625Z","iopub.status.idle":"2022-06-04T10:03:05.616682Z","shell.execute_reply.started":"2022-06-04T10:03:05.606597Z","shell.execute_reply":"2022-06-04T10:03:05.615469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"e04d6363","papermill":{"duration":0.044161,"end_time":"2022-03-22T09:40:52.262022","exception":false,"start_time":"2022-03-22T09:40:52.217861","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"id":"4c5bab44","papermill":{"duration":0.066203,"end_time":"2022-03-22T09:40:52.37203","exception":false,"start_time":"2022-03-22T09:40:52.305827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-04T10:03:05.618675Z","iopub.execute_input":"2022-06-04T10:03:05.619588Z","iopub.status.idle":"2022-06-04T10:03:05.638054Z","shell.execute_reply.started":"2022-06-04T10:03:05.61948Z","shell.execute_reply":"2022-06-04T10:03:05.636921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"id":"deee9675","papermill":{"duration":0.044158,"end_time":"2022-03-22T09:40:52.460401","exception":false,"start_time":"2022-03-22T09:40:52.416243","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device, use_sigmoid=False):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        \n        if use_sigmoid:\n            preds.append(y_preds.sigmoid().to('cpu').numpy())\n        else:\n            preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:03:05.6426Z","iopub.execute_input":"2022-06-04T10:03:05.643673Z","iopub.status.idle":"2022-06-04T10:03:05.653518Z","shell.execute_reply.started":"2022-06-04T10:03:05.643626Z","shell.execute_reply":"2022-06-04T10:03:05.65252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions1 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n#     state = torch.load(CFG.path+f\"deberta-v3-large_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions1.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions1 = np.mean(predictions1, axis=0)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-mse-lr-15e6/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions2 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n#     state = torch.load(CFG.path+f\"deberta-v3-large_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions2.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions2 = np.mean(predictions2, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-10-out-of-20-folds/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=20\n    trn_fold=[0, 2, 3, 8, 10, 11, 12, 13, 16, 18]\n    \n\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-deberta-mse-10-out-of-20-folds/\"\n#     config_path=path+'config.pth'\n#     model=\"microsoft/deberta-v3-large\"\n#     batch_size=32\n#     fc_dropout=0.15\n#     target_size=1\n#     max_len=133\n#     seed=42\n#     trn_fold=[0, 1, 2, 3, 10, 11, 12, 13, 14, 18]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# test['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions3 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=True)\n    # prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions3.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions3 = np.mean(predictions3, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 4","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-bert-for-patent-5-fold/\"\n    config_path=path+'config.pth'\n    model=\"anferico/bert-for-patents\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions4 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=True)\n    predictions4.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions4 = np.mean(predictions4, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 5","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppmdeberta/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions5 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=True)\n    predictions5.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions5 = np.mean(predictions5, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 6","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-mse-exp-2/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions6 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions6.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions6 = np.mean(predictions6, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 7","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-v3-mse-exp-3/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions7 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions7.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions7 = np.mean(predictions7, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 8","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-bert-for-patents-mse-4-out-of-5-folds/\"\n    config_path=path+'config.pth'\n    model=\"anferico/bert-for-patents\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions8 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions8.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions8 = np.mean(predictions8, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 9","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-mse-5-fold-lr15e6/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n# predictions9 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device)\n#     predictions9.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions9 = np.mean(predictions9, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 10","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-bert-for-patents-5-fold-mse/\"\n    config_path=path+'config.pth'\n    model=\"anferico/bert-for-patents\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions10 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions10.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions10 = np.mean(predictions10, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 11","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-v3-mse-exp-4/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions11 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions11.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions11 = np.mean(predictions11, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 12","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-coco-lm-large-mse-exp-1/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/cocolm-large\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=190\n    seed=42\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.insert(1, '../input/cocolm/huggingface/')\n \nfrom cocolm.modeling_cocolm import COCOLMModel, COCOLMPreTrainedModel\nfrom cocolm.configuration_cocolm import COCOLMConfig\nfrom cocolm.tokenization_cocolm import COCOLMTokenizer\n\n# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input_CoCoLM(cfg, anchor, target, context_text):\n    # inputs = cfg.tokenizer.encode_plus(text,\n    #                        add_special_tokens=True,\n    #                        max_length=cfg.max_len,\n    #                        padding=\"max_length\",\n    #                        return_offsets_mapping=False)\n\n    tokenizer = cfg.tokenizer\n    _anchor = tokenizer.encode(anchor, add_special_tokens=False)\n    _target = tokenizer.encode(target, add_special_tokens=False)\n    _context_text = tokenizer.encode(context_text, add_special_tokens=False)\n\n    token_ids = [tokenizer.cls_token_id] + _anchor + [tokenizer.sep_token_id] + _target + [tokenizer.sep_token_id] + _context_text + [tokenizer.sep_token_id]\n    inputs = {'input_ids': token_ids}\n\n    for k, v in inputs.items():\n        if len(v) < cfg.max_len:\n            num_of_paddings = cfg.max_len - len(v)\n            paddings = [cfg.tokenizer.pad_token_id for n in range(num_of_paddings)]\n            v = v + paddings\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\n# '[CLS]' + train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text'] + '[SEP]'\nclass CoCoLMTestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.anchor = df['anchor'].values\n        self.target = df['target'].values\n        self.context_text = df['context_text'].values\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        inputs = prepare_input_CoCoLM(self.cfg, self.anchor[item], self.target[item], self.context_text[item])\n        return inputs\n\n\n# ====================================================\n# Model\n# ====================================================\n\n# set model path\nCOCOLMModel.supported_convert_pretrained_model_archive_map['cocolm']['microsoft/cocolm-large'] = '../input/cocolmlargeweight/pytorch_model.bin'\nCOCOLMPreTrainedModel.supported_convert_pretrained_model_archive_map['cocolm']['microsoft/cocolm-large'] = '../input/cocolmlargeweight/pytorch_model.bin'\n\n\nclass CustomCoCoLMModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        \n        self.config = COCOLMConfig.from_pretrained(\"../input/cocolmlargeweight/\")\n        self.model = COCOLMModel.from_pretrained(\"microsoft/cocolm-large\", config=self.config, local_files_only=True)\n        \n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = COCOLMTokenizer.from_pretrained('../input/coco-lm-large/tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\n\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = CoCoLMTestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions12 = []\nfor fold in CFG.trn_fold:\n    model = CustomCoCoLMModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions12.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions12 = np.mean(predictions12, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 13","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-bert-for-patents-12-out-of-20-folds-mse/\"\n    config_path=path+'config.pth'\n    model=\"anferico/bert-for-patents\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.1\n    target_size=1\n    max_len=133\n    seed=42\n    trn_fold=[0, 1, 2, 4, 5, 8, 10, 11, 12, 13, 14, 16]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions13 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions13.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions13 = np.mean(predictions13, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 14","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-patentsberta/\"\n    config_path=path+'config.pth'\n    model=\"AI-Growth-Lab/PatentSBERTa\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions14 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions14.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions14 = np.mean(predictions14, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 15","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-5-out-of-10-fold/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions15 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=True)\n    predictions15.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions15 = np.mean(predictions15, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 16","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-patent-sbert-mse-13-out-of-20-folds/\"\n#     config_path=path+'config.pth'\n#     model=\"AI-Growth-Lab/PatentSBERTa\"\n#     batch_size=32\n#     fc_dropout=0.1\n#     target_size=1\n#     max_len=133\n#     seed=42\n#     n_fold=5\n#     trn_fold=[0, 1, 2, 3, 4, 10, 11, 12, 13, 14, 15, 17, 18]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions16 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions16.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions16 = np.mean(predictions16, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 17","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-coco-lm-large-exp-2/\"\n#     config_path=path+'config.pth'\n#     model=\"microsoft/cocolm-large\"\n#     batch_size=32\n#     fc_dropout=0.1\n#     target_size=1\n#     max_len=190\n#     seed=42\n#     trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = COCOLMTokenizer.from_pretrained('../input/coco-lm-large/tokenizer/')\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = CoCoLMTestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions17 = []\n# for fold in CFG.trn_fold:\n#     model = CustomCoCoLMModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions17.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions17 = np.mean(predictions17, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 18","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-debertav3-awp/\"\n#     config_path=path+'config.pth'\n#     model=\"microsoft/deberta-v3-large\"\n#     batch_size=32\n#     fc_dropout=0.1\n#     target_size=1\n#     max_len=133\n#     seed=42\n#     n_fold=4\n#     trn_fold=[0, 1, 2, 3]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions18 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=True)\n#     predictions18.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions18 = np.mean(predictions18, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 19","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-bert-for-patents-10-out-of-25-folds/\"\n    config_path=path+'config.pth'\n    model=\"anferico/bert-for-patents\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    trn_fold=[0, 3, 6, 7, 8, 10, 14, 16, 22, 23]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions19 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions19.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions19 = np.mean(predictions19, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 20","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-cocolm-large-exp-2/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/cocolm-large\"  # ['microsoft/deberta-v3-large', 'anferico/bert-for-patents']\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=190\n    seed=42\n    trn_fold=[0, 1, 2, 4, 6, 10, 12, 13, 18, 19]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = COCOLMTokenizer.from_pretrained('../input/coco-lm-large/tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\n\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = CoCoLMTestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions20 = []\nfor fold in CFG.trn_fold:\n    model = CustomCoCoLMModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions20.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions20 = np.mean(predictions20, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 21","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-mse-10-out-of-20-folds/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    trn_fold=[0, 1, 2, 3, 10, 11, 12, 13, 14, 18]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:05:36.561342Z","iopub.execute_input":"2022-06-04T10:05:36.561805Z","iopub.status.idle":"2022-06-04T10:05:36.567993Z","shell.execute_reply.started":"2022-06-04T10:05:36.561772Z","shell.execute_reply":"2022-06-04T10:05:36.566912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = '[CLS]' + test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions21 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions21.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions21 = np.mean(predictions21, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 22","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-roberta-large-exp-2/\"\n    config_path=path+'config.pth'\n    model=\"roberta-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=188\n    seed=42\n    trn_fold=[0, 1, 2, 3, 4, 5, 6]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:06:30.839952Z","iopub.execute_input":"2022-06-04T10:06:30.840266Z","iopub.status.idle":"2022-06-04T10:06:30.846729Z","shell.execute_reply.started":"2022-06-04T10:06:30.840219Z","shell.execute_reply":"2022-06-04T10:06:30.845181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:07:50.561014Z","iopub.execute_input":"2022-06-04T10:07:50.561355Z","iopub.status.idle":"2022-06-04T10:07:50.877302Z","shell.execute_reply.started":"2022-06-04T10:07:50.561324Z","shell.execute_reply":"2022-06-04T10:07:50.87552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions22 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions22.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions22 = np.mean(predictions22, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:11:29.452892Z","iopub.execute_input":"2022-06-04T10:11:29.453187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 23","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-roberta-large-exp-1/\"\n    config_path=path+'config.pth'\n    model=\"roberta-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=188\n    seed=42\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions23 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions23.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions23 = np.mean(predictions23, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 24","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-bert-for-patents-5-fold-test/\"\n    config_path=path+'config.pth'\n    model=\"anferico/bert-for-patents\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=130\n    seed=42\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions24 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions24.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions24 = np.mean(predictions24, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 25","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-roberta-large-8-out-of-15-folds/\"\n#     config_path=path+'config.pth'\n#     model=\"roberta-large\"\n#     batch_size=32\n#     fc_dropout=0.15\n#     target_size=1\n#     max_len=188\n#     seed=42\n#     trn_fold=[1, 2, 3, 5, 8, 10, 12, 13]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions25 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions25.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions25 = np.mean(predictions25, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 26","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-bert-for-patents-new-header-10-folds/\"\n#     config_path=path+'config.pth'\n#     model=\"anferico/bert-for-patents\"\n#     batch_size=32\n#     fc_dropout=0.2\n#     target_size=1\n#     max_len=133\n#     seed=42\n#     trn_fold=[0, 1, 2, 3, 8, 10, 11, 12, 16, 18]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions26 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions26.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions26 = np.mean(predictions26, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 27","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppm-deberta-v3-new-head-model-1020-folds/\"\n#     config_path=path+'config.pth'\n#     model=\"microsoft/deberta-v3-large\"\n#     batch_size=32\n#     fc_dropout=0.15\n#     target_size=1\n#     max_len=133\n#     seed=42\n#     trn_fold=[1, 2, 3, 8, 10, 11, 12, 13, 14, 18]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions27 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions27.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions27 = np.mean(predictions27, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 28","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-deberta-20-folds-exp/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    trn_fold=[0, 1, 2, 3, 4, 10, 11, 12, 13, 18]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions28 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n#     predictions28.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions28 = np.mean(predictions28, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 29","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/pppm-albert-xxl-v2/\"\n    config_path=path+'config.pth'\n    model=\"albert-xxlarge-v2\"\n    batch_size=32\n    fc_dropout=0.15\n    target_size=1\n    max_len=133\n    seed=42\n    trn_fold=[0, 1 ,2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())\n\n# ====================================================\n# Dataset\n# ====================================================\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions29 = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device, use_sigmoid=False)\n    predictions29.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions29 = np.mean(predictions29, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 30","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # CFG\n# # ====================================================\n# class CFG:\n#     num_workers=4\n#     path=\"../input/pppmdebertav2xl/\"\n#     config_path=path+'config.pth'\n#     model=\"microsoft/deberta-v2-xlarge\"\n#     batch_size=32\n#     fc_dropout=0.2\n#     target_size=1\n#     max_len=133\n#     seed=42\n#     trn_fold=[0, 1 ,2, 3, 4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ====================================================\n# # tokenizer\n# # ====================================================\n# # CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path)\n\n# # ====================================================\n# # CPC Data\n# # ====================================================\n# cpc_texts = torch.load(CFG.path + \"cpc_texts.pth\")\n# test['context_text'] = test['context'].map(cpc_texts)\n# display(test.head())\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# display(test.head())\n\n# # ====================================================\n# # Dataset\n# # ====================================================\n# test_dataset = TestDataset(CFG, test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG.batch_size,\n#                          shuffle=False,\n#                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions30 = []\n# for fold in CFG.trn_fold:\n#     model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n#     state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n#                        map_location=torch.device('cpu'))\n#     model.load_state_dict(state['model'])\n#     prediction = inference_fn(test_loader, model, device, use_sigmoid=True)\n#     predictions30.append(prediction)\n#     del model, state, prediction; gc.collect()\n#     torch.cuda.empty_cache()\n# predictions30 = np.mean(predictions30, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nMMscaler = MinMaxScaler()\n\npred1_mm = MMscaler.fit_transform(predictions1.reshape(-1,1)).reshape(-1)\npred2_mm = MMscaler.fit_transform(predictions2.reshape(-1,1)).reshape(-1)\npred3_mm = MMscaler.fit_transform(predictions3.reshape(-1,1)).reshape(-1)\npred4_mm = MMscaler.fit_transform(predictions4.reshape(-1,1)).reshape(-1)\npred5_mm = MMscaler.fit_transform(predictions5.reshape(-1,1)).reshape(-1)\n\n# pred6_mm = MMscaler.fit_transform(predictions6.reshape(-1,1)).reshape(-1)\n# pred7_mm = MMscaler.fit_transform(predictions7.reshape(-1,1)).reshape(-1)\npred8_mm = MMscaler.fit_transform(predictions8.reshape(-1,1)).reshape(-1)\n# pred9_mm = MMscaler.fit_transform(predictions9.reshape(-1,1)).reshape(-1)\npred10_mm = MMscaler.fit_transform(predictions10.reshape(-1,1)).reshape(-1)\n\n# pred11_mm = MMscaler.fit_transform(predictions11.reshape(-1,1)).reshape(-1)\npred12_mm = MMscaler.fit_transform(predictions12.reshape(-1,1)).reshape(-1)\npred13_mm = MMscaler.fit_transform(predictions13.reshape(-1,1)).reshape(-1)\npred14_mm = MMscaler.fit_transform(predictions14.reshape(-1,1)).reshape(-1)\npred15_mm = MMscaler.fit_transform(predictions15.reshape(-1,1)).reshape(-1)\n\n# pred16_mm = MMscaler.fit_transform(predictions16.reshape(-1,1)).reshape(-1)\n# pred17_mm = MMscaler.fit_transform(predictions17.reshape(-1,1)).reshape(-1)\n# pred18_mm = MMscaler.fit_transform(predictions18.reshape(-1,1)).reshape(-1)\npred19_mm = MMscaler.fit_transform(predictions19.reshape(-1,1)).reshape(-1)\npred20_mm = MMscaler.fit_transform(predictions20.reshape(-1,1)).reshape(-1)\n\n# pred21_mm = MMscaler.fit_transform(predictions21.reshape(-1,1)).reshape(-1)\npred22_mm = MMscaler.fit_transform(predictions22.reshape(-1,1)).reshape(-1)\npred23_mm = MMscaler.fit_transform(predictions23.reshape(-1,1)).reshape(-1)\npred24_mm = MMscaler.fit_transform(predictions24.reshape(-1,1)).reshape(-1)\n# pred25_mm = MMscaler.fit_transform(predictions25.reshape(-1,1)).reshape(-1)\n\n# pred26_mm = MMscaler.fit_transform(predictions26.reshape(-1,1)).reshape(-1)\n# pred27_mm = MMscaler.fit_transform(predictions27.reshape(-1,1)).reshape(-1)\n# pred28_mm = MMscaler.fit_transform(predictions28.reshape(-1,1)).reshape(-1)\npred29_mm = MMscaler.fit_transform(predictions29.reshape(-1,1)).reshape(-1)\n# pred30_mm = MMscaler.fit_transform(predictions30.reshape(-1,1)).reshape(-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor p1, p2, p3, p4, p5, p8, p10, p12, p13, p14, p15, p19, p20, p22, p23, p24, p29 in zip(\n    pred1_mm, pred2_mm, pred3_mm, pred4_mm, pred5_mm, \n    pred8_mm, pred10_mm, pred11_mm, pred12_mm, pred13_mm,\n    pred14_mm, pred15_mm, pred19_mm, pred20_mm, pred22_mm,\n    pred23_mm, pred24_mm, pred29_mm):\n    \n    # calculate results\n    result1 = p1 * c1 + p2 * c2 + p3 * c3 + p4 * c4 + p5 * c5\n    result2 = p8 * c8 + p10 * c10 + p12 * c12 + p13 * c13 + p14 * c14\n    result3 = p15 * c15 + p19 * c19 + p20 * c20 + p22 * c22 + p23 * c23 + p24 * c24 + p29 * c29\n    predictions.append((result1 + result2 + result3) / ensemble_divide_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nsubmission['score'] = predictions\ndisplay(submission.head())\nsubmission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}