{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Training notebook can be found here:** [US Phrase Matching: TF-Keras Train [TPU]](https://www.kaggle.com/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu)","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\n\nimport transformers\nfrom transformers import BertTokenizer\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:25:55.186522Z","iopub.execute_input":"2022-04-20T06:25:55.186935Z","iopub.status.idle":"2022-04-20T06:25:55.19397Z","shell.execute_reply.started":"2022-04-20T06:25:55.186887Z","shell.execute_reply":"2022-04-20T06:25:55.192792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_PATH = \"../input/us-patent-phrase-to-phrase-matching/\"\n\ntest = pd.read_csv(DATASET_PATH + \"test.csv\")\nsub = pd.read_csv(DATASET_PATH + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:25:59.700433Z","iopub.execute_input":"2022-04-20T06:25:59.700847Z","iopub.status.idle":"2022-04-20T06:25:59.730265Z","shell.execute_reply.started":"2022-04-20T06:25:59.700788Z","shell.execute_reply":"2022-04-20T06:25:59.729339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"class Config():\n    seed = 42\n    epochs = 10\n    num_folds = 5\n    max_length = 128\n    batch_size = 64\n    learning_rate = 2e-5\n    weight_decay = 0.01\n    base_model = \"../input/bert-for-patents/bert-for-patents/\"\n    bb_model = \"../input/bigbirdpegasus/\"\n    #tokenizer = transformers.AutoTokenizer.from_pretrained(base_model)\n    #tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    tokenizer = transformers.AutoTokenizer.from_pretrained(bb_model)\n\n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:27:17.039356Z","iopub.execute_input":"2022-04-20T06:27:17.039627Z","iopub.status.idle":"2022-04-20T06:27:17.243845Z","shell.execute_reply.started":"2022-04-20T06:27:17.039597Z","shell.execute_reply":"2022-04-20T06:27:17.242855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_text(text_pairs, \n                tokenizer,\n                max_length):\n    \n    # With tokenizer's batch_encode_plus batch of both the sentences are\n    # encoded together and separated by [SEP] token.\n    encoded = tokenizer.batch_encode_plus(\n        text_pairs,\n        add_special_tokens=True,\n        max_length=max_length,\n        padding='max_length',\n        return_attention_mask=True,\n        return_token_type_ids=True,\n        return_tensors=\"tf\",\n    )\n\n    # Convert batch of encoded features to numpy array.\n    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_masks\": attention_masks,\n        \"token_type_ids\": token_type_ids\n    }","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:27:23.632898Z","iopub.execute_input":"2022-04-20T06:27:23.633238Z","iopub.status.idle":"2022-04-20T06:27:23.640937Z","shell.execute_reply.started":"2022-04-20T06:27:23.633207Z","shell.execute_reply":"2022-04-20T06:27:23.63988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the model","metadata":{}},{"cell_type":"code","source":"def build_model(config):\n    # Create the model under a distribution strategy scope.\n    strategy = tf.distribute.MirroredStrategy()\n\n    with strategy.scope():\n        # Encoded token ids from BERT tokenizer.\n        input_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n        )\n        # Attention masks indicates to the model which tokens should be attended to.\n        attention_masks = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"attention_masks\"\n        )\n        # Token type ids are binary masks identifying different sequences in the model.\n        token_type_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n        )\n        # Loading pretrained BERT model.\n        base_model = transformers.TFAutoModel.from_pretrained(config.base_model, from_pt=True)\n\n        base_model_output = base_model(\n            input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n        )\n        \n        last_hidden_state = base_model_output.last_hidden_state\n        \n        x = tf.keras.layers.GlobalAveragePooling1D()(last_hidden_state)\n        output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n        \n        model = tf.keras.models.Model(\n            inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n        )\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:27:26.761083Z","iopub.execute_input":"2022-04-20T06:27:26.762146Z","iopub.status.idle":"2022-04-20T06:27:26.773523Z","shell.execute_reply.started":"2022-04-20T06:27:26.762098Z","shell.execute_reply":"2022-04-20T06:27:26.772352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict Folds","metadata":{}},{"cell_type":"code","source":"def predict_folds(test, config):\n    preds = []\n    \n    for fold in range(config.num_folds):\n        print(\"*\" * 25)\n        print(f\"Predicting fold: {fold+1}\")\n\n        # Clear keras session.\n        K.clear_session()\n        \n        test_encoded =  encode_text(test[[\"anchor\", \"target\"]].values.tolist(),\n                                     tokenizer=config.tokenizer,\n                                     max_length=config.max_length)\n        # Dataloader.\n        test_data = tf.data.Dataset.from_tensor_slices((test_encoded))\n        \n        # Disable AutoShard.\n        options = tf.data.Options()\n        options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n        test_data = test_data.with_options(options)\n\n        test_data = (\n                        test_data\n                        .batch(config.batch_size)\n                        .prefetch(tf.data.AUTOTUNE)\n                    )\n\n        # Build and Load the model.\n        model = build_model(config)\n        print('Loading best model weights...')\n        model.load_weights(f'../input/us-patent-matching-models/model-{fold+1}.h5')\n        \n        preds.append(\n                model.predict(test_data,\n                              batch_size=config.batch_size,\n                              verbose=1).reshape(-1)\n                    )\n        print(\"*\" * 25)\n\n    preds = np.mean(preds, axis=0)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:27:29.718292Z","iopub.execute_input":"2022-04-20T06:27:29.718587Z","iopub.status.idle":"2022-04-20T06:27:29.72882Z","shell.execute_reply.started":"2022-04-20T06:27:29.718556Z","shell.execute_reply":"2022-04-20T06:27:29.727888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config()\npreds = predict_folds(test, config)\nsub['score'] = preds\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:27:33.492627Z","iopub.execute_input":"2022-04-20T06:27:33.493566Z","iopub.status.idle":"2022-04-20T06:30:54.364247Z","shell.execute_reply.started":"2022-04-20T06:27:33.493519Z","shell.execute_reply":"2022-04-20T06:30:54.363154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\n\ndef get_score(y_true, y_pred):\n    score = stats.pearsonr(y_true, y_pred)[0]\n    print(score)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:53:20.983435Z","iopub.execute_input":"2022-04-20T06:53:20.983746Z","iopub.status.idle":"2022-04-20T06:53:20.990021Z","shell.execute_reply.started":"2022-04-20T06:53:20.983716Z","shell.execute_reply":"2022-04-20T06:53:20.988315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:33:22.27285Z","iopub.execute_input":"2022-04-20T06:33:22.273129Z","iopub.status.idle":"2022-04-20T06:33:22.282363Z","shell.execute_reply.started":"2022-04-20T06:33:22.273098Z","shell.execute_reply":"2022-04-20T06:33:22.280807Z"},"trusted":true},"execution_count":null,"outputs":[]}]}