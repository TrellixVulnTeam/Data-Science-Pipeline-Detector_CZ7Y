{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nimport transformers\nfrom transformers import RobertaTokenizer, TFRobertaModel\n\ntransformers.logging.set_verbosity_error() # turn off the warnings\npd.set_option(\"display.max_columns\", None) # expand the display of output","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T11:06:14.777032Z","iopub.execute_input":"2022-05-19T11:06:14.777763Z","iopub.status.idle":"2022-05-19T11:06:22.358891Z","shell.execute_reply.started":"2022-05-19T11:06:14.777663Z","shell.execute_reply":"2022-05-19T11:06:22.358113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# constructing dataframes\ntrain_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest_df  = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\")\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:07:10.03513Z","iopub.execute_input":"2022-05-19T11:07:10.035427Z","iopub.status.idle":"2022-05-19T11:07:10.143412Z","shell.execute_reply.started":"2022-05-19T11:07:10.035396Z","shell.execute_reply":"2022-05-19T11:07:10.142597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of unique contexts\ntrain_df[\"context\"].unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:11:16.100854Z","iopub.execute_input":"2022-05-19T11:11:16.101611Z","iopub.status.idle":"2022-05-19T11:11:16.111039Z","shell.execute_reply.started":"2022-05-19T11:11:16.101572Z","shell.execute_reply":"2022-05-19T11:11:16.11Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_codes = pd.read_csv(\"/kaggle/input/cpc-codes/titles.csv\")\ncpc_codes","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:11:26.421966Z","iopub.execute_input":"2022-05-19T11:11:26.422231Z","iopub.status.idle":"2022-05-19T11:11:27.200391Z","shell.execute_reply.started":"2022-05-19T11:11:26.422202Z","shell.execute_reply":"2022-05-19T11:11:27.199699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_codes = cpc_codes.rename(columns = {\"code\" : \"context\"})\ntrain_df = pd.merge(train_df, cpc_codes[[\"context\",\"title\"]], on=\"context\", how=\"left\")\ntest_df = pd.merge(test_df, cpc_codes[[\"context\",\"title\"]], on =\"context\", how=\"left\")\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:11:41.71804Z","iopub.execute_input":"2022-05-19T11:11:41.718302Z","iopub.status.idle":"2022-05-19T11:11:41.973294Z","shell.execute_reply.started":"2022-05-19T11:11:41.718273Z","shell.execute_reply":"2022-05-19T11:11:41.972374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Data","metadata":{}},{"cell_type":"code","source":"max_len = 128\ntrain_df[\"title\"] = train_df[\"title\"].apply(lambda x : re.sub('[;,]', '', x)) # remove punctuation\nprint(train_df.loc[:500, \"title\"].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:12:08.241275Z","iopub.execute_input":"2022-05-19T11:12:08.24154Z","iopub.status.idle":"2022-05-19T11:12:08.365144Z","shell.execute_reply.started":"2022-05-19T11:12:08.24151Z","shell.execute_reply":"2022-05-19T11:12:08.364332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"anchor_title\"] = train_df[\"anchor\"].astype(str) + \" \" + train_df[\"title\"].astype(str)\ntest_df[\"anchor_title\"] = test_df[\"anchor\"].astype(str) + \" \" + test_df[\"title\"].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:12:17.084939Z","iopub.execute_input":"2022-05-19T11:12:17.085484Z","iopub.status.idle":"2022-05-19T11:12:17.10643Z","shell.execute_reply.started":"2022-05-19T11:12:17.085445Z","shell.execute_reply":"2022-05-19T11:12:17.105544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained(\"../input/roberta-base/\") # using roberta tokenizer and pretrained model","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:13:31.619846Z","iopub.execute_input":"2022-05-19T11:13:31.620159Z","iopub.status.idle":"2022-05-19T11:13:31.821001Z","shell.execute_reply.started":"2022-05-19T11:13:31.620127Z","shell.execute_reply":"2022-05-19T11:13:31.820279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_data(id_, anchor_title, target, score, train=True) :\n    input_ids = []\n    attention_mask = []\n    labels = []\n    ids = []\n    # tokenize and prepare for the model a list of sequences or a list of pairs of sequences\n    tok_txt = tokenizer.batch_encode_plus(\n        [(word[0], word[1]) for word in zip(anchor_title, target)],                           \n        max_length = max_len, \n        padding='max_length', # pad to a maximum length specified with the argument max_length\n        truncation=True # can not output batch with sequence lengths greater than the model maximum admissible input size\n    )    \n    \n    for i, _ in enumerate(anchor_title): \n        ids.append(id_[i])\n        input_ids.append(tok_txt['input_ids'][i])\n        attention_mask.append(tok_txt['attention_mask'][i])\n        if train:\n            labels.append(score[i])\n            \n    return {\n        \"input_ids\":input_ids,\n        \"attention_mask\":attention_mask,\n        \"ids\":ids, \n    }, labels","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:17:26.473595Z","iopub.execute_input":"2022-05-19T11:17:26.474395Z","iopub.status.idle":"2022-05-19T11:17:26.484252Z","shell.execute_reply.started":"2022-05-19T11:17:26.474351Z","shell.execute_reply":"2022-05-19T11:17:26.483436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create train data\ntrain_data, train_labels = create_data(train_df['id'], train_df['anchor_title'], \n                                       train_df['target'], train_df['score'], train=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:17:42.941012Z","iopub.execute_input":"2022-05-19T11:17:42.941289Z","iopub.status.idle":"2022-05-19T11:17:54.141732Z","shell.execute_reply.started":"2022-05-19T11:17:42.941258Z","shell.execute_reply":"2022-05-19T11:17:54.140916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create test data\ntest_data, test_labels = create_data(test_df['id'], test_df['anchor_title'], \n                                     test_df['target'], None, train=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:18:57.540369Z","iopub.execute_input":"2022-05-19T11:18:57.540633Z","iopub.status.idle":"2022-05-19T11:18:57.561671Z","shell.execute_reply.started":"2022-05-19T11:18:57.540605Z","shell.execute_reply":"2022-05-19T11:18:57.560927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model_ids = Input(shape=(max_len,), dtype = tf.int32)\n    model_mask = Input(shape=(max_len,), dtype = tf.int32)\n    roberta_model = TFRobertaModel.from_pretrained(\"../input/roberta-base/\") # initializing roberta model\n    \n    x = roberta_model(input_ids = model_ids, \n                      attention_mask = model_mask)     \n    # pooling operation that replaces fully connected layers\n    x = tf.keras.layers.GlobalAveragePooling1D()(x.last_hidden_state) # sequence of hidden-states at the output of the last layer of the model  \n    \n    outputs = Dense(1)(x) # 1, because we want to generate only one value with the Dense layer \n    model = tf.keras.Model(inputs=[model_ids, model_mask], outputs=outputs) # initializing our model\n    model.compile(\n        optimizer = tf.keras.optimizers.Adam(),\n        loss = \"mse\",\n        metrics=[\"mse\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:33:09.158842Z","iopub.execute_input":"2022-05-19T11:33:09.159109Z","iopub.status.idle":"2022-05-19T11:33:09.166297Z","shell.execute_reply.started":"2022-05-19T11:33:09.159082Z","shell.execute_reply":"2022-05-19T11:33:09.165548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining scheduler and dynamic lr\ndef scheduler(epoch):\n    learning_rate = 2e-5\n    if epoch == 0:\n        return learning_rate * 0.05\n    else:\n        return learning_rate * (0.9 ** epoch)\n    \ncallback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:33:09.717588Z","iopub.execute_input":"2022-05-19T11:33:09.718154Z","iopub.status.idle":"2022-05-19T11:33:09.72251Z","shell.execute_reply.started":"2022-05-19T11:33:09.718117Z","shell.execute_reply":"2022-05-19T11:33:09.721793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.fit(\n    (\n        np.array(train_data['input_ids']),\n        np.array(train_data['attention_mask'])\n    ),\n    np.array(train_labels).ravel(), \n    epochs = 5, # number of epochs\n    shuffle = True, # adding some random (shuffling the array)\n    callbacks = [\n        # stop training when a monitored metric has stopped improving\n        EarlyStopping(monitor='val_mse', patience=3, restore_best_weights=True), \n        # callback to save the Keras model or model weights at some frequency\n        ModelCheckpoint('roberta_uspppm.h5', monitor='val_mse', save_best_only=True, save_weights_only=True), \n        # updates learning rate every epoch\n        callback_lr\n    ],                     \n    batch_size = 64, # size of one batch\n    validation_split = 0.25 # proportion of splitting \n)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:33:12.797254Z","iopub.execute_input":"2022-05-19T11:33:12.797944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"test_preds = model.predict((np.array(test_data['input_ids']),\n                            np.array(test_data['attention_mask'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")\nsubmission['score'] = test_preds\nsubmission['score'] = submission.score.apply(lambda x: 0 if x < 0 else x)\nsubmission['score'] = submission.score.apply(lambda x: 1 if x > 1 else x)\nsubmission.to_csv('submission.csv',index=False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}