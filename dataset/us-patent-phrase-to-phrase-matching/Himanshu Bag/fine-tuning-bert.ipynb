{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T05:51:30.806351Z","iopub.execute_input":"2022-06-13T05:51:30.806922Z","iopub.status.idle":"2022-06-13T05:51:30.847513Z","shell.execute_reply.started":"2022-06-13T05:51:30.806828Z","shell.execute_reply":"2022-06-13T05:51:30.846666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:30.849285Z","iopub.execute_input":"2022-06-13T05:51:30.849535Z","iopub.status.idle":"2022-06-13T05:51:30.939398Z","shell.execute_reply.started":"2022-06-13T05:51:30.849501Z","shell.execute_reply":"2022-06-13T05:51:30.938335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')\nprint(train_df.info())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:30.94092Z","iopub.execute_input":"2022-06-13T05:51:30.94172Z","iopub.status.idle":"2022-06-13T05:51:31.070725Z","shell.execute_reply.started":"2022-06-13T05:51:30.941684Z","shell.execute_reply":"2022-06-13T05:51:31.070007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['anchor','target','context','score']:\n    print('\\n====',col,'=====')\n    print(train_df[col].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.072611Z","iopub.execute_input":"2022-06-13T05:51:31.073299Z","iopub.status.idle":"2022-06-13T05:51:31.113092Z","shell.execute_reply.started":"2022-06-13T05:51:31.073261Z","shell.execute_reply":"2022-06-13T05:51:31.112416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\ntrain_df['context_text'] = train_df['context'].str.slice(stop=1).map(context_mapping)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.114305Z","iopub.execute_input":"2022-06-13T05:51:31.114726Z","iopub.status.idle":"2022-06-13T05:51:31.140142Z","shell.execute_reply.started":"2022-06-13T05:51:31.114686Z","shell.execute_reply":"2022-06-13T05:51:31.139464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['context_text'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.1414Z","iopub.execute_input":"2022-06-13T05:51:31.141654Z","iopub.status.idle":"2022-06-13T05:51:31.153606Z","shell.execute_reply.started":"2022-06-13T05:51:31.141622Z","shell.execute_reply":"2022-06-13T05:51:31.151891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cpc = pd.read_csv('../input/cpc-codes/titles.csv')\n# cpc.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.15664Z","iopub.execute_input":"2022-06-13T05:51:31.156905Z","iopub.status.idle":"2022-06-13T05:51:31.1606Z","shell.execute_reply.started":"2022-06-13T05:51:31.156882Z","shell.execute_reply":"2022-06-13T05:51:31.159839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- adding cpc title to add more context","metadata":{}},{"cell_type":"code","source":"# cpc = cpc.rename(columns = {\"code\" : \"context\"})\n# train_df = pd.merge(train_df, cpc[[\"context\",\"title\"]], on =\"context\", how = \"left\")\n# train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.162024Z","iopub.execute_input":"2022-06-13T05:51:31.162729Z","iopub.status.idle":"2022-06-13T05:51:31.168684Z","shell.execute_reply.started":"2022-06-13T05:51:31.162692Z","shell.execute_reply":"2022-06-13T05:51:31.167961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.170775Z","iopub.execute_input":"2022-06-13T05:51:31.171447Z","iopub.status.idle":"2022-06-13T05:51:31.184906Z","shell.execute_reply.started":"2022-06-13T05:51:31.171409Z","shell.execute_reply":"2022-06-13T05:51:31.184117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(x):\n    t = x.lower()\n    t = t.replace(\"[\",'')\n    t = t.replace(\";\",'')\n    t = t.replace(\",\",'')\n    t = t.replace(\"]\",'')\n    t = t.replace(\":\",'')\n    return t\n\ntrain_df['context_text'] = train_df['context_text'].apply(lambda x: clean(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.189Z","iopub.execute_input":"2022-06-13T05:51:31.189253Z","iopub.status.idle":"2022-06-13T05:51:31.238514Z","shell.execute_reply.started":"2022-06-13T05:51:31.189226Z","shell.execute_reply":"2022-06-13T05:51:31.237803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['sen1'] = train_df['anchor'].astype('str')+' '+train_df['context_text'].astype('str')\ntrain_df = train_df.drop(['anchor','context','context_text'],axis=1)\n# train_df['all_sen'] = train_df['sen1']+' [SEP '+train_df['target']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.239676Z","iopub.execute_input":"2022-06-13T05:51:31.240116Z","iopub.status.idle":"2022-06-13T05:51:31.273336Z","shell.execute_reply.started":"2022-06-13T05:51:31.240069Z","shell.execute_reply":"2022-06-13T05:51:31.272603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq1_len = [len(i.split()) for i in train_df['sen1'].values]\npd.Series(seq1_len).hist(bins = 30)\n\ntar_len = [len(i.split()) for i in train_df['target'].values]\npd.Series(tar_len).hist(bins = 30)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.274826Z","iopub.execute_input":"2022-06-13T05:51:31.275258Z","iopub.status.idle":"2022-06-13T05:51:31.750241Z","shell.execute_reply.started":"2022-06-13T05:51:31.275222Z","shell.execute_reply":"2022-06-13T05:51:31.749492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(train_df[['target','sen1']],train_df['score'],random_state=1234,test_size=0.3)\nprint(x_train.shape,x_test.shape)\nprint(y_train.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:31.754252Z","iopub.execute_input":"2022-06-13T05:51:31.756398Z","iopub.status.idle":"2022-06-13T05:51:32.246635Z","shell.execute_reply.started":"2022-06-13T05:51:31.756304Z","shell.execute_reply":"2022-06-13T05:51:32.246001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:32.250137Z","iopub.execute_input":"2022-06-13T05:51:32.252257Z","iopub.status.idle":"2022-06-13T05:51:32.265733Z","shell.execute_reply.started":"2022-06-13T05:51:32.252217Z","shell.execute_reply":"2022-06-13T05:51:32.265022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:32.269783Z","iopub.execute_input":"2022-06-13T05:51:32.269976Z","iopub.status.idle":"2022-06-13T05:51:32.276114Z","shell.execute_reply.started":"2022-06-13T05:51:32.26995Z","shell.execute_reply":"2022-06-13T05:51:32.27552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport transformers\nfrom torch.nn.utils.clip_grad import clip_grad_norm\n\n\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:32.277771Z","iopub.execute_input":"2022-06-13T05:51:32.27835Z","iopub.status.idle":"2022-06-13T05:51:38.069612Z","shell.execute_reply.started":"2022-06-13T05:51:32.278312Z","shell.execute_reply":"2022-06-13T05:51:38.068926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()\nimport gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.071253Z","iopub.execute_input":"2022-06-13T05:51:38.071696Z","iopub.status.idle":"2022-06-13T05:51:38.236216Z","shell.execute_reply.started":"2022-06-13T05:51:38.071656Z","shell.execute_reply":"2022-06-13T05:51:38.235372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### class defination for model , dataset and training functions","metadata":{}},{"cell_type":"code","source":"class my_model(nn.Module):\n    def __init__(self,bert_path):\n        super(my_model,self).__init__()\n        self.bert_path = bert_path\n        self.bert = transformers.AutoModel.from_pretrained(self.bert_path)\n        self.fc_layer = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(1024,1),\n            nn.Sigmoid()\n        )\n    def forward(self,ids,mask,token_type_ids):\n        out = self.bert(input_ids=ids,attention_mask=mask,token_type_ids=token_type_ids,return_dict=True)\n        pooler_output = out.get('pooler_output')\n        bo = self.fc_layer(pooler_output)\n        return bo\n     ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.237888Z","iopub.execute_input":"2022-06-13T05:51:38.239164Z","iopub.status.idle":"2022-06-13T05:51:38.247131Z","shell.execute_reply.started":"2022-06-13T05:51:38.239121Z","shell.execute_reply":"2022-06-13T05:51:38.246352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class my_dataset_train:\n    def __init__(self,text1,text2,label,tokenizer,max_len):\n        self.text1=text1\n        self.text2=text2\n        self.label=label\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.text1)\n    \n    def __getitem__(self,idx):\n        text_1 = str(self.text1[idx])\n        text_2 = str(self.text2[idx])\n        label = self.label[idx]\n        \n        inputs = self.tokenizer(\n            text_1,\n            text_2,\n            add_special_tokens=True,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len,\n            return_attention_mask=True\n        )\n#         print(inputs)\n        ids = inputs['input_ids']\n        token_type_ids = inputs[\"token_type_ids\"]\n        mask = inputs['attention_mask']\n        \n        \n        return {\n            \"ids\": torch.tensor(ids,dtype=torch.long),\n            \"mask\": torch.tensor(mask,dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids,dtype=torch.long),\n            \"targets\": torch.tensor(label,dtype=torch.float),\n        }\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.248649Z","iopub.execute_input":"2022-06-13T05:51:38.249184Z","iopub.status.idle":"2022-06-13T05:51:38.261215Z","shell.execute_reply.started":"2022-06-13T05:51:38.249144Z","shell.execute_reply":"2022-06-13T05:51:38.260376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dataset for train and valid","metadata":{}},{"cell_type":"code","source":"max_len=128\ntrain_batch_size = 8\nepochs=10\nbert_path = '../input/bert-for-patents/bert-for-patents'#'../input/bert-for-patents/bert-for-patents'\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(bert_path)\n\n# Training dataset prep\n\ntrain_text1 = list(x_train['target'].values)\ntrain_text2 = list(x_train['sen1'].values)\ntrain_label = list(y_train.values)\n\ntrain_dataset = my_dataset_train(\n    text1 = train_text1,\n    text2 = train_text2,\n    label = train_label,\n    tokenizer=tokenizer ,\n    max_len=max_len\n)\n\ntrain_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size,shuffle=True)\n\n# validation dataset prep\nval_text1 = list(x_test['target'].values)\nval_text2 = list(x_test['sen1'].values)\nval_label = list(y_test.values)\n\nvalid_dataset = my_dataset_train(\n    text1 = val_text1,\n    text2 = val_text2,\n    label = val_label,\n    tokenizer=tokenizer,\n    max_len=max_len\n)\n\nvalid_data_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=train_batch_size,shuffle=True)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.26272Z","iopub.execute_input":"2022-06-13T05:51:38.263262Z","iopub.status.idle":"2022-06-13T05:51:38.711107Z","shell.execute_reply.started":"2022-06-13T05:51:38.263198Z","shell.execute_reply":"2022-06-13T05:51:38.710385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset[5]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.712585Z","iopub.execute_input":"2022-06-13T05:51:38.712819Z","iopub.status.idle":"2022-06-13T05:51:38.772165Z","shell.execute_reply.started":"2022-06-13T05:51:38.712787Z","shell.execute_reply":"2022-06-13T05:51:38.771521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train","metadata":{}},{"cell_type":"code","source":"def train(model, optimizer, scheduler, loss_function, epochs,train_dataloader, device, clip_value=2):\n    model.train()\n    for epoch in range(epochs):\n#         print(epoch)\n#         print(\"-----\")\n        best_loss = []\n        for step, batch in enumerate(train_dataloader): \n            batch_inputs, batch_masks, batch_labels = batch['ids'].to(device), batch['mask'].to(device), batch['targets'].to(device)\n            batch_token_type_ids = batch['token_type_ids'].to(device)\n            model.zero_grad()\n            outputs = model(batch_inputs, batch_masks, batch_token_type_ids)\n            loss = loss_function(outputs.squeeze(),batch_labels.squeeze())\n            best_loss.append(loss)\n            loss.backward()\n            clip_grad_norm(model.parameters(), clip_value)\n            optimizer.step()\n            scheduler.step()\n#             print(f\"step > {step},loss > {loss}\")\n        loss2 = sum(best_loss)/len(best_loss)\n        print(f'Epoch : {epoch} ,Train loss : {loss2}')\n        gc.collect()\n                \n    return model\n\ndef r2_score(outputs, labels):\n    labels_mean = torch.mean(labels)\n    ss_tot = torch.sum((labels - labels_mean) ** 2)\n    ss_res = torch.sum((labels - outputs) ** 2)\n    r2 = 1 - ss_res / ss_tot\n    return r2\n\ndef evaluate(model,loss_function,test_dataloader,device):\n    model.eval()\n    test_loss, test_r2 = [], []\n    for step,batch in enumerate(test_dataloader):\n        batch_inputs, batch_masks, batch_labels = batch['ids'].to(device), batch['mask'].to(device), batch['targets'].to(device)\n        batch_token_type_ids = batch['token_type_ids'].to(device)\n        with torch.no_grad():\n            outputs = model(batch_inputs, batch_masks, batch_token_type_ids)\n        loss = loss_function(outputs, batch_labels)\n        test_loss.append(loss.item())\n        r2 = r2_score(outputs, batch_labels)\n        test_r2.append(r2.item())\n    return test_loss, test_r2","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.773443Z","iopub.execute_input":"2022-06-13T05:51:38.773953Z","iopub.status.idle":"2022-06-13T05:51:38.789393Z","shell.execute_reply.started":"2022-06-13T05:51:38.773912Z","shell.execute_reply":"2022-06-13T05:51:38.7887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train_steps = len(train_data_loader) * epochs\n\nmodel = my_model(bert_path).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(),lr=1e-5,eps=1e-8)\n\nscheduler = transformers.get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_train_steps\n)\n\nloss_function = nn.MSELoss()\n\nprint('ready to train')\n\nmodel = train(model, optimizer, scheduler, loss_function, epochs,train_data_loader, device)\n\nprint('model trained !')\n\nloss1,r2_ = evaluate(model,loss_function,valid_data_loader,device)\n\nloss = sum(loss1)/len(loss1)\nr2 = sum(r2_)/len(r2_)\nprint(f\"eval mean result : loss {loss}, r2 {r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:51:38.790531Z","iopub.execute_input":"2022-06-13T05:51:38.790893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),f'./my_bert')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n\n- follow evaluate function\n- create dataset class","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncontext_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\ntest_df['context_text'] = test_df['context'].str.slice(stop=1).map(context_mapping)\ndef clean(x):\n    t = x.lower()\n    t = t.replace(\"[\",'')\n    t = t.replace(\";\",'')\n    t = t.replace(\",\",'')\n    t = t.replace(\"]\",'')\n    t = t.replace(\":\",'')\n    return t\n\ntest_df['context_text'] = test_df['context_text'].apply(lambda x: clean(x))\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['sen1'] = test_df['anchor'].astype('str')+' '+test_df['context_text'].astype('str')\ntest_df = test_df.drop(['anchor','context','context_text'],axis=1)\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class my_dataset_test:\n    def __init__(self,text1,text2,idf,tokenizer,max_len):\n        self.text1=text1\n        self.text2=text2\n        self.idf = idf\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.text1)\n    \n    def __getitem__(self,idx):\n        text_1 = str(self.text1[idx])\n        text_2 = str(self.text2[idx])\n        idf = self.idf[idx]\n        \n        inputs = self.tokenizer(\n            text_1,\n            text_2,\n            add_special_tokens=True,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len,\n            return_attention_mask=True\n        )\n        \n        ids = inputs['input_ids']\n        token_type_ids = inputs[\"token_type_ids\"]\n        mask = inputs['attention_mask']\n        \n        padding_len = self.max_len - len(ids)\n        ids = ids + ([0]*padding_len)\n        token_type_ids = token_type_ids + ([0]*padding_len)\n        mask = mask + ([0]*padding_len)\n        \n        return {\n            \"ids\": torch.tensor(ids,dtype=torch.long),\n            \"mask\": torch.tensor(mask,dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids,dtype=torch.long),\n            \"idf\": idf\n        }\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text1 = list(test_df['target'].values)\ntest_text2 = list(test_df['sen1'].values)\n\ntest_dataset = my_dataset_test(\n    text1 = test_text1,\n    text2 = test_text2,\n    idf=list(test_df['id'].values),\n    tokenizer=tokenizer,\n    max_len=max_len\n)\n\ntest_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model,test_dataloader,device):\n    model.eval()\n    result = []\n    for step,batch in enumerate(test_dataloader):\n        batch_inputs, batch_masks = batch['ids'].to(device), batch['mask'].to(device)\n        batch_token_type_ids = batch['token_type_ids'].to(device)\n        with torch.no_grad():\n            outputs = model(batch_inputs, batch_masks, batch_token_type_ids)\n        out = [i[0] for i in outputs.cpu().detach().numpy()]\n        batch_idf = batch['idf']\n        temp = [[i,j] for i,j in zip(batch_idf,out)]\n        result.extend(temp)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = my_model(bert_path).to(device)\nmodel.load_state_dict(torch.load('my_bert'))\n\nfinal_res = predict(model,test_data_loader,device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')\nsample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv = pd.DataFrame(final_res,columns=['id','score'])\nsubmit_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}