{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ensemble deberta v3 + deberta v3 + deberta v1","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T09:43:19.072026Z","iopub.execute_input":"2022-06-02T09:43:19.072818Z","iopub.status.idle":"2022-06-02T09:43:22.070097Z","shell.execute_reply.started":"2022-06-02T09:43:19.072712Z","shell.execute_reply":"2022-06-02T09:43:22.069363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_DEB_SIMPLE:\n    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n    model_path = '../input/deberta-v3-large/deberta-v3-large'\n    batch_size = 24\n    num_workers = 2\n    num_fold = 4\n    max_input_length = 130","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T09:43:22.072911Z","iopub.execute_input":"2022-06-02T09:43:22.07338Z","iopub.status.idle":"2022-06-02T09:43:22.077593Z","shell.execute_reply.started":"2022-06-02T09:43:22.073341Z","shell.execute_reply":"2022-06-02T09:43:22.076967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, tokenizer, max_input_length):\n        self.text = df['text'].values.astype(str)\n        self.tokenizer = tokenizer\n        self.max_input_length = max_input_length\n        \n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        inputs = self.text[item]\n        \n        inputs = self.tokenizer(inputs,\n                    max_length=self.max_input_length,\n                    padding='max_length',\n                    truncation=True)\n        \n        return torch.as_tensor(inputs['input_ids'], dtype=torch.long), \\\n               torch.as_tensor(inputs['token_type_ids'], dtype=torch.long), \\\n               torch.as_tensor(inputs['attention_mask'], dtype=torch.long)\n    \n    \nclass Custom_Bert_Simple(nn.Module):\n    def __init__(self, model_path):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_path)\n        config.num_labels = 1\n        self.base = AutoModelForSequenceClassification.from_config(config=config)\n        dim = config.hidden_size\n        self.dropout = nn.Dropout(p=0)\n        self.cls = nn.Linear(dim,1)\n        \n    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n        base_output = self.base(input_ids=input_ids,\n                                attention_mask=attention_mask,\n                                token_type_ids=token_type_ids\n        )\n\n        return base_output[0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T09:43:22.078787Z","iopub.execute_input":"2022-06-02T09:43:22.079149Z","iopub.status.idle":"2022-06-02T09:43:22.092162Z","shell.execute_reply.started":"2022-06-02T09:43:22.079111Z","shell.execute_reply":"2022-06-02T09:43:22.091401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, device):\n    model.eval()\n    preds = []\n    labels = []\n    \n    for step, batch in enumerate(valid_loader):\n        input_ids, token_type_ids, attention_mask = [i.to(device) for i in batch]\n    \n        with torch.no_grad():\n            y_preds = model(input_ids, attention_mask, token_type_ids)\n        \n        preds.append(y_preds.to('cpu').numpy())\n    \n    predictions = np.concatenate(preds)\n    \n    return predictions\n\n\nmin_max_scaler = MinMaxScaler()\n\ndef upd_outputs(data, is_trim=True, is_minmax=True, is_reshape=True):\n    \"\"\"\\o/\"\"\"\n    if is_trim == True:\n        data = np.where(data <=0, 0, data)\n        data = np.where(data >=1, 1, data)\n\n    if is_minmax ==True:\n        data = min_max_scaler.fit_transform(data)\n    \n    if is_reshape == True:\n        data = data.reshape(-1)\n        \n    return data\n\n\ndef _upd_score_between(data, thresholds, value):\n    \"\"\"\\o/\"\"\"\n    mask_th = data.between(*thresholds, inclusive='both')\n    data[mask_th] = value\n\n\ndef upd_score(data, th_dict=None):\n    \"\"\"\\o/\"\"\"\n    if isinstance(data, pd.Series):\n        result = data.copy()\n    else:\n        return data\n\n    if not th_dict:        \n        th_dict = {\n            '0': 0.02,\n            '.25': (0.24, 0.26),\n            '.50': (0.49, 0.51),\n            '.75': (0.74, 0.76),\n            '1': 0.98\n        }\n\n    if isinstance(th_dict, dict):    \n        th0 = th_dict.get('0')\n        th25 = th_dict.get('.25')\n        th50 = th_dict.get('.50')\n        th75 = th_dict.get('.75')\n        th100 = th_dict.get('1')\n    else:\n        return data\n    \n    if th0:\n        if isinstance(th0, float):\n            th0 = (result.min(), th0)\n        \n        if isinstance(th0, tuple):\n            _upd_score_between(result, th0, 0)\n    \n    if th25 and isinstance(th25, tuple):\n        _upd_score_between(result, th25, 0.25)\n\n    if th50 and isinstance(th50, tuple):\n        _upd_score_between(result, th50, 0.50)\n            \n    if th75 and isinstance(th75, tuple):\n        _upd_score_between(result, th75, 0.75)\n            \n    if th100:\n        if isinstance(th100, float):\n            th100 = (th100, result.max())\n        \n        if isinstance(th100, tuple):\n            _upd_score_between(result, th100, 1)\n\n    return result","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T09:43:22.094394Z","iopub.execute_input":"2022-06-02T09:43:22.094677Z","iopub.status.idle":"2022-06-02T09:43:22.110923Z","shell.execute_reply.started":"2022-06-02T09:43:22.094643Z","shell.execute_reply":"2022-06-02T09:43:22.110032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{CFG_DEB_SIMPLE.input_path}test.csv\")\ntitles = pd.read_csv('../input/cpc-codes/titles.csv')\ntest_df = test_df.merge(titles, left_on='context', right_on='code')\n\ncpc_texts = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")\n\ntest_df['context_text'] = test_df['context'].map(cpc_texts)\ntest_df['text'] = test_df['anchor'] + '[SEP]' + test_df['target'] + '[SEP]'  + test_df['context_text']\ntest_df['text'] = test_df['text'].apply(str.lower)\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:22.112237Z","iopub.execute_input":"2022-06-02T09:43:22.112795Z","iopub.status.idle":"2022-06-02T09:43:22.942856Z","shell.execute_reply.started":"2022-06-02T09:43:22.112745Z","shell.execute_reply":"2022-06-02T09:43:22.942159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Extract & Update Predictions","metadata":{}},{"cell_type":"code","source":"tokenizer_deberta_v3 = AutoTokenizer.from_pretrained(CFG_DEB_SIMPLE.model_path)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-02T09:43:22.9442Z","iopub.execute_input":"2022-06-02T09:43:22.9457Z","iopub.status.idle":"2022-06-02T09:43:23.623194Z","shell.execute_reply.started":"2022-06-02T09:43:22.945672Z","shell.execute_reply":"2022-06-02T09:43:23.622454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\nte_dataset = TestDataset(test_df, tokenizer_deberta_v3, CFG_DEB_SIMPLE.max_input_length)\nte_dataloader = DataLoader(te_dataset,\n                              batch_size=CFG_DEB_SIMPLE.batch_size, shuffle=False,\n                              num_workers=CFG_DEB_SIMPLE.num_workers,\n                              pin_memory=True, drop_last=False)\n\ndeberta_simple_path = \"../input/us-patent-deberta-simple/microsoft_deberta-v3-large\"\n\nfor fold in tqdm(range(CFG_DEB_SIMPLE.num_fold)):\n    fold_path = f\"{deberta_simple_path}_best{fold}.pth\"\n    \n    model = Custom_Bert_Simple(CFG_DEB_SIMPLE.model_path)\n    model.load_state_dict(torch.load(fold_path)['model'])\n    model.to('cuda')\n    \n    prediction = valid_fn(te_dataloader, model, 'cuda')\n    \n    predictions.append(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:23.62457Z","iopub.execute_input":"2022-06-02T09:43:23.624814Z","iopub.status.idle":"2022-06-02T09:45:21.981207Z","shell.execute_reply.started":"2022-06-02T09:43:23.62478Z","shell.execute_reply":"2022-06-02T09:45:21.979858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"folds:\", len(predictions))\nprint(\"rows: \", len(predictions[0]))\nprint(\"score:\", predictions[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:21.983282Z","iopub.execute_input":"2022-06-02T09:45:21.983603Z","iopub.status.idle":"2022-06-02T09:45:21.994395Z","shell.execute_reply.started":"2022-06-02T09:45:21.983549Z","shell.execute_reply":"2022-06-02T09:45:21.993262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_predictions = 14","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:21.996392Z","iopub.execute_input":"2022-06-02T09:45:21.99682Z","iopub.status.idle":"2022-06-02T09:45:22.003611Z","shell.execute_reply.started":"2022-06-02T09:45:21.996751Z","shell.execute_reply":"2022-06-02T09:45:22.002258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first fold\npredictions[0][:n_predictions]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.012109Z","iopub.execute_input":"2022-06-02T09:45:22.012803Z","iopub.status.idle":"2022-06-02T09:45:22.026821Z","shell.execute_reply.started":"2022-06-02T09:45:22.012749Z","shell.execute_reply":"2022-06-02T09:45:22.025403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(*upd_outputs(predictions[0], is_trim=False)[:n_predictions])\n# print(*upd_outputs(predictions[0], is_minmax=False)[:n_predictions])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.028237Z","iopub.execute_input":"2022-06-02T09:45:22.028479Z","iopub.status.idle":"2022-06-02T09:45:22.032169Z","shell.execute_reply.started":"2022-06-02T09:45:22.028446Z","shell.execute_reply":"2022-06-02T09:45:22.031488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.where(x<=0, 0, x) .. >> min_max.fit_transform(x) >> x.reshape(-1)\nupd_predictions = [upd_outputs(x, is_trim=False) for x in predictions]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.034173Z","iopub.execute_input":"2022-06-02T09:45:22.035263Z","iopub.status.idle":"2022-06-02T09:45:22.044748Z","shell.execute_reply.started":"2022-06-02T09:45:22.035227Z","shell.execute_reply":"2022-06-02T09:45:22.044016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(*upd_predictions[0][:n_predictions])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.046197Z","iopub.execute_input":"2022-06-02T09:45:22.047308Z","iopub.status.idle":"2022-06-02T09:45:22.059211Z","shell.execute_reply.started":"2022-06-02T09:45:22.046635Z","shell.execute_reply":"2022-06-02T09:45:22.058375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Additional & Final Predictions","metadata":{}},{"cell_type":"code","source":"origin_predictions = upd_predictions.copy()  # 5. Visualization","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.06088Z","iopub.execute_input":"2022-06-02T09:45:22.06138Z","iopub.status.idle":"2022-06-02T09:45:22.065345Z","shell.execute_reply.started":"2022-06-02T09:45:22.061344Z","shell.execute_reply":"2022-06-02T09:45:22.064437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === add np.median ===\nadd_preds = []\nfor x in zip(*upd_predictions):\n    add_preds.append(np.median(x, axis=0))\n    \nupd_predictions.append(add_preds)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.066871Z","iopub.execute_input":"2022-06-02T09:45:22.067423Z","iopub.status.idle":"2022-06-02T09:45:22.080865Z","shell.execute_reply.started":"2022-06-02T09:45:22.067388Z","shell.execute_reply":"2022-06-02T09:45:22.080039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === add np.mean ===\nadd_preds = []\nfor x in zip(*upd_predictions):\n    add_preds.append(np.mean(x, axis=0))\n    \nupd_predictions.append(add_preds)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.082412Z","iopub.execute_input":"2022-06-02T09:45:22.082879Z","iopub.status.idle":"2022-06-02T09:45:22.088912Z","shell.execute_reply.started":"2022-06-02T09:45:22.082846Z","shell.execute_reply":"2022-06-02T09:45:22.087985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = np.mean(upd_predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.09041Z","iopub.execute_input":"2022-06-02T09:45:22.090995Z","iopub.status.idle":"2022-06-02T09:45:22.099238Z","shell.execute_reply.started":"2022-06-02T09:45:22.090959Z","shell.execute_reply":"2022-06-02T09:45:22.098095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final_predictions)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.100657Z","iopub.execute_input":"2022-06-02T09:45:22.100928Z","iopub.status.idle":"2022-06-02T09:45:22.109081Z","shell.execute_reply.started":"2022-06-02T09:45:22.100895Z","shell.execute_reply":"2022-06-02T09:45:22.108135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(*final_predictions[:n_predictions])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.110522Z","iopub.execute_input":"2022-06-02T09:45:22.110806Z","iopub.status.idle":"2022-06-02T09:45:22.120053Z","shell.execute_reply.started":"2022-06-02T09:45:22.110766Z","shell.execute_reply":"2022-06-02T09:45:22.119083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Create & Calibrate Submissions","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_df['id'],\n    'score': final_predictions,\n})\n\nsubmission.head(14)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.121755Z","iopub.execute_input":"2022-06-02T09:45:22.122057Z","iopub.status.idle":"2022-06-02T09:45:22.141011Z","shell.execute_reply.started":"2022-06-02T09:45:22.122021Z","shell.execute_reply":"2022-06-02T09:45:22.140414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds_dict = {\n    '0': 0.02,\n    '.25': (0.24, 0.26),\n    '.50': (0.49, 0.51),\n    '.75': (0.74, 0.76),\n    '1': 0.98\n}\n\npredictions_1 = upd_score(submission['score'], thresholds_dict)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:45:22.142251Z","iopub.execute_input":"2022-06-02T09:45:22.142715Z","iopub.status.idle":"2022-06-02T09:45:22.164695Z","shell.execute_reply.started":"2022-06-02T09:45:22.142681Z","shell.execute_reply":"2022-06-02T09:45:22.163921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/deberta-v1-baseline/\"\n    data_path=\"../input/us-patent-phrase-to-phrase-matching/\"\n    model_path=\"./\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-large\"\n    batch_size=32\n    fc_dropout=0.3\n    target_size=1\n    max_len=175\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:48:32.902031Z","iopub.execute_input":"2022-06-02T09:48:32.902303Z","iopub.status.idle":"2022-06-02T09:48:32.910049Z","shell.execute_reply.started":"2022-06-02T09:48:32.902253Z","shell.execute_reply":"2022-06-02T09:48:32.909235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForTokenClassification\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:52:17.699417Z","iopub.execute_input":"2022-06-02T09:52:17.699914Z","iopub.status.idle":"2022-06-02T09:52:35.821825Z","shell.execute_reply.started":"2022-06-02T09:52:17.699877Z","shell.execute_reply":"2022-06-02T09:52:35.82107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=CFG.model_path+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:48:54.224577Z","iopub.execute_input":"2022-06-02T09:48:54.224886Z","iopub.status.idle":"2022-06-02T09:48:54.244299Z","shell.execute_reply.started":"2022-06-02T09:48:54.224851Z","shell.execute_reply":"2022-06-02T09:48:54.243646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv(CFG.data_path+'test.csv')\nsubmission = pd.read_csv(CFG.data_path+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:48:54.245256Z","iopub.execute_input":"2022-06-02T09:48:54.245737Z","iopub.status.idle":"2022-06-02T09:48:54.379839Z","shell.execute_reply.started":"2022-06-02T09:48:54.245702Z","shell.execute_reply":"2022-06-02T09:48:54.37897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(\"../input/cpc-text/cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:49:24.814284Z","iopub.execute_input":"2022-06-02T09:49:24.814581Z","iopub.status.idle":"2022-06-02T09:49:24.837238Z","shell.execute_reply.started":"2022-06-02T09:49:24.814532Z","shell.execute_reply":"2022-06-02T09:49:24.836456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:49:24.838732Z","iopub.execute_input":"2022-06-02T09:49:24.839045Z","iopub.status.idle":"2022-06-02T09:49:24.854326Z","shell.execute_reply.started":"2022-06-02T09:49:24.839008Z","shell.execute_reply":"2022-06-02T09:49:24.853728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained('../input/deberta-v1-tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:49:24.855455Z","iopub.execute_input":"2022-06-02T09:49:24.855781Z","iopub.status.idle":"2022-06-02T09:49:24.987425Z","shell.execute_reply.started":"2022-06-02T09:49:24.855745Z","shell.execute_reply":"2022-06-02T09:49:24.986703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:49:24.989525Z","iopub.execute_input":"2022-06-02T09:49:24.989881Z","iopub.status.idle":"2022-06-02T09:49:24.998064Z","shell.execute_reply.started":"2022-06-02T09:49:24.989844Z","shell.execute_reply":"2022-06-02T09:49:24.997109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n        self._init_weights(self.attention)\n        self.linear = nn.Linear(self.config.hidden_size, 1)\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        out = sum_embeddings / sum_mask\n        \n        out = self.layer_norm1(out)\n        output = self.fc(out)\n        \n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:49:36.052311Z","iopub.execute_input":"2022-06-02T09:49:36.052591Z","iopub.status.idle":"2022-06-02T09:49:36.058431Z","shell.execute_reply.started":"2022-06-02T09:49:36.052542Z","shell.execute_reply":"2022-06-02T09:49:36.057782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions_2 = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:49:36.063965Z","iopub.execute_input":"2022-06-02T09:49:36.06434Z","iopub.status.idle":"2022-06-02T09:51:50.324072Z","shell.execute_reply.started":"2022-06-02T09:49:36.064313Z","shell.execute_reply":"2022-06-02T09:51:50.323259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/deberta-v3-10folds/\"\n    data_path=\"../input/us-patent-phrase-to-phrase-matching/\"\n    model_path=\"./\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    seed=42\n    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    tokenizer=None","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:51:50.328517Z","iopub.execute_input":"2022-06-02T09:51:50.33047Z","iopub.status.idle":"2022-06-02T09:51:50.338603Z","shell.execute_reply.started":"2022-06-02T09:51:50.330432Z","shell.execute_reply":"2022-06-02T09:51:50.338003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained('../input/deberta-v3-tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:51:50.339994Z","iopub.execute_input":"2022-06-02T09:51:50.34052Z","iopub.status.idle":"2022-06-02T09:51:51.030235Z","shell.execute_reply.started":"2022-06-02T09:51:50.340487Z","shell.execute_reply":"2022-06-02T09:51:51.029518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerHead(nn.Module):\n    def __init__(self, in_features, max_length, num_layers=1, nhead=8, num_targets=1):\n        super().__init__()\n\n        self.transformer = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=in_features,\n                                                                                          nhead=nhead),\n                                                 num_layers=num_layers)\n        self.row_fc = nn.Linear(in_features, 1)\n        self.out_features = max_length\n\n    def forward(self, x):\n        out = self.transformer(x)\n        out = self.row_fc(out).squeeze(-1)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:51:51.032187Z","iopub.execute_input":"2022-06-02T09:51:51.032452Z","iopub.status.idle":"2022-06-02T09:51:51.040007Z","shell.execute_reply.started":"2022-06-02T09:51:51.032419Z","shell.execute_reply":"2022-06-02T09:51:51.039213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        \n        self.feature_extractor = AutoModelForTokenClassification.from_pretrained(\"../input/deberta-v3-large/deberta-v3-large\")\n        in_features = self.feature_extractor.classifier.in_features\n        self.attention = TransformerHead(in_features=in_features, max_length=133, num_layers=1, nhead=8, num_targets=1)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.attention.out_features, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        feature = self.attention(last_hidden_states)\n        \n        return feature\n\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        #print(feature.shape)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:51:51.041291Z","iopub.execute_input":"2022-06-02T09:51:51.041713Z","iopub.status.idle":"2022-06-02T09:51:51.058875Z","shell.execute_reply.started":"2022-06-02T09:51:51.041675Z","shell.execute_reply":"2022-06-02T09:51:51.058066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions_3 = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:52:35.823521Z","iopub.execute_input":"2022-06-02T09:52:35.82448Z","iopub.status.idle":"2022-06-02T09:56:43.476418Z","shell.execute_reply.started":"2022-06-02T09:52:35.824441Z","shell.execute_reply":"2022-06-02T09:56:43.475626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = (predictions_1.values * 0.35 + predictions_2 * 0.3 + predictions_3 * 0.35)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:56:43.480426Z","iopub.execute_input":"2022-06-02T09:56:43.486708Z","iopub.status.idle":"2022-06-02T09:56:43.492224Z","shell.execute_reply.started":"2022-06-02T09:56:43.48666Z","shell.execute_reply":"2022-06-02T09:56:43.491368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['score'] = predictions\ndisplay(submission.head())\nsubmission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:56:43.494665Z","iopub.execute_input":"2022-06-02T09:56:43.495117Z","iopub.status.idle":"2022-06-02T09:56:43.540731Z","shell.execute_reply.started":"2022-06-02T09:56:43.495083Z","shell.execute_reply":"2022-06-02T09:56:43.54003Z"},"trusted":true},"execution_count":null,"outputs":[]}]}