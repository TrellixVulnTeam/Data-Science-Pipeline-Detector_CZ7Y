{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip show datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T12:57:20.205682Z","iopub.execute_input":"2022-05-20T12:57:20.206419Z","iopub.status.idle":"2022-05-20T12:57:29.808557Z","shell.execute_reply.started":"2022-05-20T12:57:20.20632Z","shell.execute_reply":"2022-05-20T12:57:29.807734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import (AutoModelForMaskedLM,AutoTokenizer,DataCollatorForLanguageModeling,\n                          Trainer, TrainingArguments)\n\nwarnings.filterwarnings('ignore')\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(42)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:57:29.812136Z","iopub.execute_input":"2022-05-20T12:57:29.812769Z","iopub.status.idle":"2022-05-20T12:57:36.422142Z","shell.execute_reply.started":"2022-05-20T12:57:29.812729Z","shell.execute_reply":"2022-05-20T12:57:36.421457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainingArgs:\n    weight_decay = 0.01\n    learning_rate = 2e-5  \n    warmup_ratio = 0.1\n    gradient_accumulation_steps = 4\n    fp16 = True\n    lr_scheduler_type = \"cosine\"\n    # Number of checkpoints to save for each model\n    save_total_limit = 1\n    \nclass Config:    \n    DATA_PATH = \"/kaggle/input/us-patent-phrase-to-phrase-matching/\"\n    # location where trained model weights are saved\n    OUT_DIR = \"/kaggle/working/model/\"\n    RUNTIME = \"KAGGLE\"\n    RANDOM_STATE = 42\n    BATCH_SIZE = 32\n    NUM_LABELS = 1\n    NUM_FOLDS = 5\n    RUN_ALL_FOLDS = True\n    NUM_EPOCHS = 4\n    NUM_WORKERS = 8\n    TRANSFORMER_CHECKPOINT = \"microsoft/deberta-v3-small\"\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    SUBSET_ROWS_FRAC = 0.1\n    TRAIN_ON_SUBSET = False","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:57:36.423429Z","iopub.execute_input":"2022-05-20T12:57:36.423675Z","iopub.status.idle":"2022-05-20T12:57:36.481308Z","shell.execute_reply.started":"2022-05-20T12:57:36.423642Z","shell.execute_reply":"2022-05-20T12:57:36.480626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_abstract = pd.read_csv('../input/pppm-abstract/pppm_abstract.csv')\ndf_abstract = df_abstract.dropna().reset_index(drop=True)\ndf_abstract","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:57:36.483302Z","iopub.execute_input":"2022-05-20T12:57:36.483675Z","iopub.status.idle":"2022-05-20T12:57:38.527068Z","shell.execute_reply.started":"2022-05-20T12:57:36.48364Z","shell.execute_reply":"2022-05-20T12:57:38.526376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_text(data_row):\n    result = tokenizer(data_row[\"abstract\"])\n    if tokenizer.is_fast:\n        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:57:38.528429Z","iopub.execute_input":"2022-05-20T12:57:38.528675Z","iopub.status.idle":"2022-05-20T12:57:38.533401Z","shell.execute_reply.started":"2022-05-20T12:57:38.528642Z","shell.execute_reply":"2022-05-20T12:57:38.532502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\ntokenizer = AutoTokenizer.from_pretrained(Config.TRANSFORMER_CHECKPOINT)\nds_abstract_raw = Dataset.from_pandas(df_abstract)\nraw_ds_col_names = ds_abstract_raw.column_names    \nds_abstract = ds_abstract_raw.map(tokenize_text, batched=True, batch_size=1000, remove_columns=raw_ds_col_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:57:38.534841Z","iopub.execute_input":"2022-05-20T12:57:38.53537Z","iopub.status.idle":"2022-05-20T12:59:38.426961Z","shell.execute_reply.started":"2022-05-20T12:57:38.535333Z","shell.execute_reply":"2022-05-20T12:59:38.42616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    # Compute length of concatenated texts\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the last chunk if it's smaller than chunk_size\n    total_length = (total_length // chunk_size) * chunk_size\n    # Split by chunks of max_len\n    result = {\n        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n        for k, t in concatenated_examples.items()\n    }\n    # Create a new labels column\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:59:38.428527Z","iopub.execute_input":"2022-05-20T12:59:38.428807Z","iopub.status.idle":"2022-05-20T12:59:38.435327Z","shell.execute_reply.started":"2022-05-20T12:59:38.42877Z","shell.execute_reply":"2022-05-20T12:59:38.434287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_size = 128\nds_abstract_mlm = ds_abstract.map(group_texts, batched=True)\nds_abstract_mlm","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:59:38.436451Z","iopub.execute_input":"2022-05-20T12:59:38.43674Z","iopub.status.idle":"2022-05-20T13:01:27.277532Z","shell.execute_reply.started":"2022-05-20T12:59:38.436685Z","shell.execute_reply":"2022-05-20T13:01:27.27675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_abstract_mlm = ds_abstract_mlm.train_test_split(test_size=0.2, train_size=0.8, seed=Config.RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:01:27.278962Z","iopub.execute_input":"2022-05-20T13:01:27.279219Z","iopub.status.idle":"2022-05-20T13:01:27.321225Z","shell.execute_reply.started":"2022-05-20T13:01:27.279185Z","shell.execute_reply":"2022-05-20T13:01:27.320622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(ds_abstract_mlm[\"train\"][1][\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:01:27.324066Z","iopub.execute_input":"2022-05-20T13:01:27.324324Z","iopub.status.idle":"2022-05-20T13:01:28.47436Z","shell.execute_reply.started":"2022-05-20T13:01:27.32429Z","shell.execute_reply":"2022-05-20T13:01:28.47357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:01:28.475729Z","iopub.execute_input":"2022-05-20T13:01:28.476145Z","iopub.status.idle":"2022-05-20T13:01:28.480498Z","shell.execute_reply.started":"2022-05-20T13:01:28.476105Z","shell.execute_reply":"2022-05-20T13:01:28.479616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMaskedLM.from_pretrained(Config.TRANSFORMER_CHECKPOINT)\n\ntraining_args = TrainingArguments(\n        output_dir=Config.OUT_DIR,\n        evaluation_strategy=\"epoch\",\n        save_strategy='epoch',        \n        num_train_epochs=Config.NUM_EPOCHS,\n        per_device_train_batch_size=Config.BATCH_SIZE,\n        per_device_eval_batch_size=Config.BATCH_SIZE,\n        warmup_ratio=TrainingArgs.warmup_ratio,\n        weight_decay=TrainingArgs.weight_decay,\n        learning_rate=TrainingArgs.learning_rate,    \n        gradient_accumulation_steps=TrainingArgs.gradient_accumulation_steps,\n        fp16=TrainingArgs.fp16,\n        lr_scheduler_type=TrainingArgs.lr_scheduler_type,\n        save_total_limit=TrainingArgs.save_total_limit\n    )\n\ntrainer = Trainer(\n    model=model,                                  # the instantiated Transformers model to be trained\n    args=training_args,                           # training arguments, defined above\n    train_dataset=ds_abstract_mlm[\"train\"],       # training dataset\n    eval_dataset=ds_abstract_mlm[\"test\"],         # evaluation dataset    \n    data_collator=data_collator,\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:01:28.481958Z","iopub.execute_input":"2022-05-20T13:01:28.482241Z","iopub.status.idle":"2022-05-20T13:02:05.422417Z","shell.execute_reply.started":"2022-05-20T13:01:28.482207Z","shell.execute_reply":"2022-05-20T13:02:05.421734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before fine tuning the model using MLM\n\nimport math\nimport os\n\neval_results = trainer.evaluate()\nprint(f\">>> Perplexity before fine tuning: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:02:05.423661Z","iopub.execute_input":"2022-05-20T13:02:05.424018Z","iopub.status.idle":"2022-05-20T13:04:35.249853Z","shell.execute_reply.started":"2022-05-20T13:02:05.423979Z","shell.execute_reply":"2022-05-20T13:04:35.249186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:04:35.250834Z","iopub.execute_input":"2022-05-20T13:04:35.255346Z","iopub.status.idle":"2022-05-20T13:05:46.275594Z","shell.execute_reply.started":"2022-05-20T13:04:35.255305Z","shell.execute_reply":"2022-05-20T13:05:46.274547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(f\">>> Perplexity after fine tuning = {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:05:46.276683Z","iopub.status.idle":"2022-05-20T13:05:46.277477Z","shell.execute_reply.started":"2022-05-20T13:05:46.277229Z","shell.execute_reply":"2022-05-20T13:05:46.277255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install GPUtil\n\n# import torch\n# from GPUtil import showUtilization as gpu_usage\n# from numba import cuda\n\n# def free_gpu_cache():\n#     print(\"Initial GPU Usage\")\n#     gpu_usage()                             \n\n#     torch.cuda.empty_cache()\n\n#     cuda.select_device(0)\n#     cuda.close()\n#     cuda.select_device(0)\n\n#     print(\"GPU Usage after emptying the cache\")\n#     gpu_usage()\n\n# free_gpu_cache()    ","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:05:46.278849Z","iopub.status.idle":"2022-05-20T13:05:46.279294Z","shell.execute_reply.started":"2022-05-20T13:05:46.279036Z","shell.execute_reply":"2022-05-20T13:05:46.279059Z"},"trusted":true},"execution_count":null,"outputs":[]}]}