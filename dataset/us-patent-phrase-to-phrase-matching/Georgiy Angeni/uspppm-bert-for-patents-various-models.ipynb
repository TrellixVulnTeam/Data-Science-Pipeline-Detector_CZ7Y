{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT for Patents Baseline\n\n- [kfold strategy](https://www.kaggle.com/code/abhishek/phrase-matching-folds)\n- Utilize [Cooperative Patent Classification Codes Meaning](https://www.kaggle.com/datasets/xhlulu/cpc-codes)\n- reference [phantivia'Notebook](https://www.kaggle.com/code/phantivia/uspppm-huggingface-train-inference-baseline)\n- [BERT for Patents](https://www.kaggle.com/datasets/ksork6s4/bert-for-patents) from [huggingface page](https://huggingface.co/anferico/bert-for-patents)\n\n\n### Please refer to [Inference Notebook](https://www.kaggle.com/code/ksork6s4/uspppm-bert-for-patents-baseline-inference/edit/run/91272728) as well.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport shutil\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport datasets, transformers\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:31.335493Z","iopub.execute_input":"2022-05-14T20:31:31.335725Z","iopub.status.idle":"2022-05-14T20:31:39.047538Z","shell.execute_reply.started":"2022-05-14T20:31:31.33566Z","shell.execute_reply":"2022-05-14T20:31:39.046851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n    models_paths = ['../input/robertalarge', '../input/deberta-v3-large/deberta-v3-large']\n    models_weights = [0.7, 0.3]\n\n    learning_rate = 2e-5\n    weight_decay = 0.01\n    num_fold = 4\n    epochs = 4\n    batch_sizes = [16, 16]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:39.049Z","iopub.execute_input":"2022-05-14T20:31:39.049219Z","iopub.status.idle":"2022-05-14T20:31:39.054129Z","shell.execute_reply.started":"2022-05-14T20:31:39.049188Z","shell.execute_reply":"2022-05-14T20:31:39.053376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preproc","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{CFG.input_path}train.csv\")\ntitles = pd.read_csv('../input/cpc-codes/titles.csv')\ntrain_df = train_df.merge(titles, left_on='context', right_on='code')\n\n# https://www.kaggle.com/code/abhishek/phrase-matching-folds\ndef create_folds(data, num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"fold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    # data = data.sample(frac=1).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    # num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"score\"], bins=5, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'fold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:39.055232Z","iopub.execute_input":"2022-05-14T20:31:39.055626Z","iopub.status.idle":"2022-05-14T20:31:39.89069Z","shell.execute_reply.started":"2022-05-14T20:31:39.055591Z","shell.execute_reply":"2022-05-14T20:31:39.889851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['input'] = train_df['title']+' '+train_df['anchor']\ntrain_df = create_folds(train_df, CFG.num_fold)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:39.892737Z","iopub.execute_input":"2022-05-14T20:31:39.892984Z","iopub.status.idle":"2022-05-14T20:31:39.942425Z","shell.execute_reply.started":"2022-05-14T20:31:39.892957Z","shell.execute_reply":"2022-05-14T20:31:39.941748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizers = [AutoTokenizer.from_pretrained(model_path) for model_path in CFG.models_paths]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:39.943727Z","iopub.execute_input":"2022-05-14T20:31:39.943996Z","iopub.status.idle":"2022-05-14T20:31:40.952999Z","shell.execute_reply.started":"2022-05-14T20:31:39.94396Z","shell.execute_reply":"2022-05-14T20:31:40.952223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.inputs = df['input'].values.astype(str)\n        self.targets = df['target'].values.astype(str)\n        self.label = df['score'].values\n\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, item):\n        inputs = self.inputs[item]\n        targets = self.targets[item]\n        label = self.label[item]\n        \n        return {\n        **self.tokenizer(inputs, targets),\n        'label':label.astype(np.float32)\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:40.954379Z","iopub.execute_input":"2022-05-14T20:31:40.954637Z","iopub.status.idle":"2022-05-14T20:31:40.963275Z","shell.execute_reply.started":"2022-05-14T20:31:40.954603Z","shell.execute_reply":"2022-05-14T20:31:40.962603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.reshape(len(predictions))\n    return {\n        'pearson': np.corrcoef(predictions, labels)[0][1]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:40.964523Z","iopub.execute_input":"2022-05-14T20:31:40.964927Z","iopub.status.idle":"2022-05-14T20:31:40.973491Z","shell.execute_reply.started":"2022-05-14T20:31:40.964893Z","shell.execute_reply":"2022-05-14T20:31:40.972693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:40.975466Z","iopub.execute_input":"2022-05-14T20:31:40.975703Z","iopub.status.idle":"2022-05-14T20:31:40.982999Z","shell.execute_reply.started":"2022-05-14T20:31:40.97568Z","shell.execute_reply":"2022-05-14T20:31:40.982227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(CFG.num_fold):\n    tr_data = train_df[train_df['fold']!=fold].reset_index(drop=True)\n    va_data = train_df[train_df['fold']==fold].reset_index(drop=True)\n\n    predictions = np.zeros(va_data.shape[0])\n    \n    for model_idx in range(len(CFG.models_paths)):\n        tr_dataset = TrainDataset(tr_data, tokenizers[model_idx])\n        va_dataset = TrainDataset(va_data, tokenizers[model_idx])\n        \n        args = TrainingArguments(\n            output_dir=f\"/tmp/models\",\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"no\",\n            learning_rate=CFG.learning_rate,\n            per_device_train_batch_size=CFG.batch_sizes[model_idx],\n            per_device_eval_batch_size=CFG.batch_sizes[model_idx],\n            num_train_epochs=CFG.epochs,\n            weight_decay=CFG.weight_decay,\n        )\n        \n        model = AutoModelForSequenceClassification.from_pretrained(CFG.models_paths[model_idx], num_labels=1)\n        trainer = Trainer(\n            model,\n            args,\n            train_dataset=tr_dataset,\n            eval_dataset=va_dataset,\n            tokenizer=tokenizers[model_idx],\n            compute_metrics=compute_metrics\n        )\n        \n        trainer.train()\n        shutil.rmtree(f\"/tmp/models\")\n        # trainer.save_model(f\"models_{fold}\")\n        \n        outputs = trainer.predict(va_dataset)\n        predictions += outputs.predictions.reshape(-1) * CFG.models_weights[model_idx]\n\n    va_data['preds'] = predictions\n    output_df = pd.concat([output_df, va_data])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T20:31:40.984439Z","iopub.execute_input":"2022-05-14T20:31:40.984723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = output_df['preds'].values\nlabel = output_df['score'].values\neval_pred = predictions, label\ncompute_metrics(eval_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"almost_ready_df = output_df.drop(output_df.columns.difference(['id','preds']), 1, inplace=False).rename(columns={'preds': 'score'})\n\nalmost_ready_truncated_df = almost_ready_df\nalmost_ready_truncated_df['score'] = np.where(almost_ready_truncated_df['score'] > 0, almost_ready_truncated_df['score'], 0)\nalmost_ready_truncated_df['score'] = np.where(almost_ready_truncated_df['score'] < 1, almost_ready_truncated_df['score'], 1)\n\nalmost_ready_truncated_df['score'] = [min([0.0, 0.25, 0.5, 0.75, 1.0], key=lambda x: abs(x - pred_val)) for pred_val in almost_ready_truncated_df['score']]\n\nalmost_ready_truncated_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# almost_ready_df.to_csv('submission.csv', index=False)\nalmost_ready_truncated_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}