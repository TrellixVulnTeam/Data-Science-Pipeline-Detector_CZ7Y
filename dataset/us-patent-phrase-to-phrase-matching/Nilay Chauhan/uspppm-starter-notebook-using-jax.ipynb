{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Introduction\nThis is a starter notebook for [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview) using JAX and Flax. In this competition, you will train your models on a novel semantic similarity dataset to extract relevant information by matching key phrases in patent documents.\n\n### About Dataset\nThe dataset contains pairs of phrases (an anchor and a target phrase) and asked to rate how similar they are on a scale from 0 (not at all similar) to 1 (identical in meaning).\n\n**Files**\n\n- `train.csv` - the training set, containing phrases, contexts, and their similarity scores\n- `test.csv` - the test set set, identical in structure to the training set but without the score\n- `sample_submission.csv` - a sample submission file in the correct format\n\n**Columns** \n\n- `id` - a unique identifier for a pair of phrases\n- `anchor` - the first phrase\n- `target` - the second phrase\n- `context` - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n- `score` - the similarity. This is sourced from a combination of one or more manual expert ratings.\n\n### Intro to JAX\n[JAX](https://github.com/google/jax) is a framework which is used for high-performance numerical computing and machine learning research developed at [Google Research](https://research.google/) teams. It allows you to build Python applications with a NumPy-consistent API that specializes in differentiating, vectorizing, parallelizing, and compiling to GPU/TPU Just-In-Time. JAX was designed with performance and speed as a first priority, and is natively compatible with common machine learning accelerators such as [GPUs](https://www.kaggle.com/docs/efficient-gpu-usage) and [TPUs](https://www.kaggle.com/docs/tpu). Large ML models can take ages to train -- you might be interested in using JAX for applications where speed and performance are particularly important!\n### When to use JAX vs TensorFlow?\n[TensorFlow](https://www.tensorflow.org/guide) is a fantastic product, with a rich and fully-featured ecosystem, capable of supporting most every use case a machine learning practitioner might have (e.g. [TFLite](https://www.tensorflow.org/lite) for on-device inference computing, [TFHub](https://tfhub.dev/) for sharing pre-trained models, and many additional specialized applications as well). This type of broad mandate both contrasts and compliments JAX's philosophy, which is more narrowly focused on speed and performance.  We recommend using JAX in situations where you do want to maximize speed and performance but you do not require any of the long tail of features and additional functionalities that only the [TensorFlow ecosystem](https://www.tensorflow.org/learn) can provide.\n### Intro to the FLAX\nJust like [JAX](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) focuses on speed, other members of the JAX ecosystem are encouraged to specialize as well.  For example, [Flax](https://flax.readthedocs.io/en/latest/) focuses on neural networks and [jgraph](https://github.com/deepmind/jraph) focuses on graph networks.  \n\n[Flax](https://flax.readthedocs.io/en/latest/) is a JAX-based neural network library that was initially developed by  Google Research's Brain Team (in close collaboration with the JAX team) but is now open source.  If you want to train machine learning models on GPUs and TPUs at an accelerated speed, or if you have an ML project that might benefit from bringing together both [Autograd](https://github.com/hips/autograd) and [XLA](https://www.tensorflow.org/xla), consider using [Flax](https://flax.readthedocs.io/en/latest/) for your next project! [Flax](https://flax.readthedocs.io/en/latest/) is especially well-suited for projects that use large language models, and is a popular choice for cutting-edge [machine learning research](https://arxiv.org/search/?query=JAX&searchtype=all&abstracts=show&order=-announced_date_first&size=50).\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T14:18:36.643686Z","iopub.execute_input":"2022-04-21T14:18:36.6442Z","iopub.status.idle":"2022-04-21T14:18:36.65843Z","shell.execute_reply.started":"2022-04-21T14:18:36.644133Z","shell.execute_reply":"2022-04-21T14:18:36.657051Z"}}},{"cell_type":"markdown","source":"### **Imports**\nImporting the required libraries for this notebook","metadata":{}},{"cell_type":"code","source":"import os, re\nimport time\nimport jax\nimport flax\nimport optax\nimport datasets\nimport pandas as pd \nimport numpy as np\nfrom jax import jit\nimport jax.numpy as jnp\nimport tensorflow as tf\nfrom flax.training import train_state\nfrom itertools import chain\nfrom tqdm.notebook import tqdm\nfrom typing import Callable\nfrom flax import traverse_util\nfrom datasets import load_dataset, load_metric ,Dataset,list_metrics,load_from_disk, concatenate_datasets\nfrom flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\nfrom transformers import FlaxAutoModelForSequenceClassification, AutoConfig, AutoTokenizer, BertTokenizer,AutoModelForSequenceClassification,RobertaTokenizer\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pyarrow as pa\nfrom scipy import stats\nfrom scipy.stats import pearsonr\n# to suppress warnings caused by cuda version\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Loading the model checkpoint and tokenizer**\nWe'll be using Huggingface's pre-trained [bert model](https://huggingface.co/bert-base-uncased) in this notebook.","metadata":{}},{"cell_type":"code","source":"seed=0\nmodel_checkpoint = '../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased' \ntokenizer = BertTokenizer.from_pretrained(model_checkpoint,use_fast=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Loading and preprocess the data**\nWe'll start with reading train data and looking at the first five rows.","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:18:37.311023Z","iopub.execute_input":"2022-04-21T14:18:37.312077Z","iopub.status.idle":"2022-04-21T14:18:37.389936Z","shell.execute_reply.started":"2022-04-21T14:18:37.312037Z","shell.execute_reply":"2022-04-21T14:18:37.388715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[`sep_token`](https://huggingface.co/docs/transformers/main_classes/tokenizer) is a special token separating two different sentences in the same input used by BERT","metadata":{}},{"cell_type":"code","source":"sep = tokenizer.sep_token\nsep","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:06.176822Z","iopub.execute_input":"2022-04-21T14:20:06.177115Z","iopub.status.idle":"2022-04-21T14:20:06.18534Z","shell.execute_reply.started":"2022-04-21T14:20:06.177083Z","shell.execute_reply":"2022-04-21T14:20:06.184234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine context, anchor and target columns\ntrain['inputs'] = train.context + sep + train.anchor + sep + train.target","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:08.83869Z","iopub.execute_input":"2022-04-21T14:20:08.839008Z","iopub.status.idle":"2022-04-21T14:20:08.870846Z","shell.execute_reply.started":"2022-04-21T14:20:08.838975Z","shell.execute_reply":"2022-04-21T14:20:08.869752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:11.511375Z","iopub.execute_input":"2022-04-21T14:20:11.51166Z","iopub.status.idle":"2022-04-21T14:20:11.526416Z","shell.execute_reply.started":"2022-04-21T14:20:11.51163Z","shell.execute_reply":"2022-04-21T14:20:11.525445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding\nWe're using JAX to train a classifier model to predict score labels in this notebook. The training data score is separated into five intervals, each of which can be classified into one of five classes [0,1,2,3,4].","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/vbookshelf/hugging-face-trainer-a-classification-workflow\ndef create_label(x):\n    \n    if x == 0:\n        return 0\n\n    if x == 0.25:\n        return 1\n    \n    if x == 0.5:\n        return 2\n\n    if x == 0.75:\n        return 3\n\n    if x == 1.0:\n        return 4\n\ntrain['labels'] = train['score'].apply(create_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:15.691862Z","iopub.execute_input":"2022-04-21T14:20:15.692233Z","iopub.status.idle":"2022-04-21T14:20:15.730131Z","shell.execute_reply.started":"2022-04-21T14:20:15.692195Z","shell.execute_reply":"2022-04-21T14:20:15.729006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:17.204698Z","iopub.execute_input":"2022-04-21T14:20:17.204986Z","iopub.status.idle":"2022-04-21T14:20:17.220549Z","shell.execute_reply.started":"2022-04-21T14:20:17.204954Z","shell.execute_reply":"2022-04-21T14:20:17.21953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting train dataframe to HuggingFace Dataset using Huggingface's [`from_pandas`](https://huggingface.co/docs/datasets/loading) function from Dataset class ","metadata":{}},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:21.943694Z","iopub.execute_input":"2022-04-21T14:20:21.944366Z","iopub.status.idle":"2022-04-21T14:20:21.987342Z","shell.execute_reply.started":"2022-04-21T14:20:21.944314Z","shell.execute_reply":"2022-04-21T14:20:21.986344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:23.555438Z","iopub.execute_input":"2022-04-21T14:20:23.555737Z","iopub.status.idle":"2022-04-21T14:20:23.563366Z","shell.execute_reply.started":"2022-04-21T14:20:23.555707Z","shell.execute_reply":"2022-04-21T14:20:23.562233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, this function will preprocess the dataset by taking batch of data and returns the tokenized processed data","metadata":{}},{"cell_type":"code","source":"def preprocess_function(input_batch):\n    '''\n    INPUT - input batch from from original dataset\n    RETURNS preprocessed data\n    '''\n    texts = (input_batch[\"inputs\"],)\n    processed = tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n    processed[\"labels\"] = input_batch[\"labels\"]\n    return processed","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:30.026639Z","iopub.execute_input":"2022-04-21T14:20:30.026939Z","iopub.status.idle":"2022-04-21T14:20:30.033649Z","shell.execute_reply.started":"2022-04-21T14:20:30.026907Z","shell.execute_reply":"2022-04-21T14:20:30.032221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_ds = train_ds.map(preprocess_function,batched=True, remove_columns= ['id', 'anchor', 'target', 'context', 'labels','score', 'inputs'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:30.658033Z","iopub.execute_input":"2022-04-21T14:20:30.658399Z","iopub.status.idle":"2022-04-21T14:20:44.093773Z","shell.execute_reply.started":"2022-04-21T14:20:30.658366Z","shell.execute_reply":"2022-04-21T14:20:44.092839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Spliting the dataset into train and eval sets","metadata":{}},{"cell_type":"code","source":"encoded_ds = encoded_ds.train_test_split(test_size=0.2)\nencoded_ds","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:45.376318Z","iopub.execute_input":"2022-04-21T14:20:45.377416Z","iopub.status.idle":"2022-04-21T14:20:45.406087Z","shell.execute_reply.started":"2022-04-21T14:20:45.377353Z","shell.execute_reply":"2022-04-21T14:20:45.405207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = encoded_ds[\"train\"]\nvalidation_dataset = encoded_ds[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:48.718738Z","iopub.execute_input":"2022-04-21T14:20:48.719027Z","iopub.status.idle":"2022-04-21T14:20:48.725719Z","shell.execute_reply.started":"2022-04-21T14:20:48.718995Z","shell.execute_reply":"2022-04-21T14:20:48.724361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model Config**\nDefining all the model config parameters below","metadata":{}},{"cell_type":"code","source":"num_labels = 5\nseed = 0\nnum_train_epochs = 5\nlearning_rate = 2e-5\nper_device_batch_size = 128\nweight_decay=1e-2","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:52.182885Z","iopub.execute_input":"2022-04-21T14:20:52.184004Z","iopub.status.idle":"2022-04-21T14:20:52.190302Z","shell.execute_reply.started":"2022-04-21T14:20:52.183934Z","shell.execute_reply":"2022-04-21T14:20:52.189205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_batch_size = per_device_batch_size * jax.local_device_count()\nprint(\"The overall batch size (both for training and eval) is\", total_batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:54.949726Z","iopub.execute_input":"2022-04-21T14:20:54.95005Z","iopub.status.idle":"2022-04-21T14:20:55.326612Z","shell.execute_reply.started":"2022-04-21T14:20:54.950009Z","shell.execute_reply":"2022-04-21T14:20:55.325549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluating num of train steps and defining learning_rate_function using optax for jax.\n\nHere I am using [cosine onecycle learning rate scheduler](https://optax.readthedocs.io/en/latest/api.html#optax.cosine_onecycle_schedule) from optax library","metadata":{}},{"cell_type":"code","source":"num_train_steps = len(train_dataset) // total_batch_size * num_train_epochs\nlearning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, peak_value=learning_rate, pct_start=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:20:56.269662Z","iopub.execute_input":"2022-04-21T14:20:56.270695Z","iopub.status.idle":"2022-04-21T14:20:57.503222Z","shell.execute_reply.started":"2022-04-21T14:20:56.270654Z","shell.execute_reply":"2022-04-21T14:20:57.50226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Evaluation Metrics**\nFor this notebook, we'll be using [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) to evaluate similarity between the predicted and actual scores.","metadata":{}},{"cell_type":"code","source":"def simple_corr(preds, labels):\n    preds = preds.reshape(len(preds))\n    corr,_ = pearsonr(preds,labels)\n    return corr\n\nclass CORR(datasets.Metric):\n    def _info(self):\n        return datasets.MetricInfo(\n            description=\"Calculates PearsonR metric.\",\n            citation=\"TODO: _CITATION\",\n            inputs_description=\"_KWARGS_DESCRIPTION\",\n            features=datasets.Features({\n                'predictions': datasets.Value('float32'),\n                'references': datasets.Value('float32'),\n            }),\n            codebase_urls=[],\n            reference_urls=[],\n            format='numpy'\n        )\n\n    def _compute(self, predictions, references):\n        return {\"PEARSONR\": simple_corr(predictions, references)}\n    \nmetric = CORR()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:21:03.336116Z","iopub.execute_input":"2022-04-21T14:21:03.336498Z","iopub.status.idle":"2022-04-21T14:21:03.344829Z","shell.execute_reply.started":"2022-04-21T14:21:03.336457Z","shell.execute_reply":"2022-04-21T14:21:03.343854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below step is downloading the pretrained model,as we are doing sentence classification we can use FlaxAutoModelForSequenceClassification class. from_pretrained method will download and cache the model.\n\n","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(model_checkpoint, num_labels=num_labels)\nmodel = FlaxAutoModelForSequenceClassification.from_pretrained(model_checkpoint, config=config, seed=seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:21:08.918389Z","iopub.execute_input":"2022-04-21T14:21:08.918985Z","iopub.status.idle":"2022-04-21T14:21:44.204091Z","shell.execute_reply.started":"2022-04-21T14:21:08.918949Z","shell.execute_reply":"2022-04-21T14:21:44.203135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Train state**","metadata":{}},{"cell_type":"markdown","source":"Flax provides a class [flax.training.train_state.TrainState](https://flax.readthedocs.io/en/latest/flax.training.html#train-state), which stores the model parameters, the loss function, the optimizer, and exposes an apply_gradients function to update the model's weight parameters.","metadata":{}},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    '''\n    Derived TrainState class that saves the forward pass of the model as an eval function and a loss function\n    '''\n    logits_function: Callable = flax.struct.field(pytree_node=False)\n    loss_function: Callable = flax.struct.field(pytree_node=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:21:50.561262Z","iopub.execute_input":"2022-04-21T14:21:50.561577Z","iopub.status.idle":"2022-04-21T14:21:50.568641Z","shell.execute_reply.started":"2022-04-21T14:21:50.561529Z","shell.execute_reply":"2022-04-21T14:21:50.567547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are using Adam optimizer with weight decay, and again we are using [optax](https://optax.readthedocs.io/en/latest/) library.\n\nHere is the interesting article on adam optimizer - https://www.fast.ai/2018/07/02/adam-weight-decay/","metadata":{}},{"cell_type":"code","source":"def decay_mask_fn(params):\n    '''\n    This function's task is to make sure that weight decay is not applies to any bias or Layernorm weights\n    '''\n    flat_params = traverse_util.flatten_dict(params)\n    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:21:52.399223Z","iopub.execute_input":"2022-04-21T14:21:52.399821Z","iopub.status.idle":"2022-04-21T14:21:52.407247Z","shell.execute_reply.started":"2022-04-21T14:21:52.399784Z","shell.execute_reply":"2022-04-21T14:21:52.404758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adamw(weight_decay):\n    return optax.adamw(learning_rate=learning_rate_function, b1=0.9, b2=0.999, eps=1e-6, weight_decay=weight_decay,mask=decay_mask_fn)\nadamw = adamw(weight_decay)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:21:52.701628Z","iopub.execute_input":"2022-04-21T14:21:52.702562Z","iopub.status.idle":"2022-04-21T14:21:52.711529Z","shell.execute_reply.started":"2022-04-21T14:21:52.702527Z","shell.execute_reply":"2022-04-21T14:21:52.710223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now , computing the softmax cross entropy between sets of logits and labels using the [optax](https://optax.readthedocs.io/en/latest/) library.","metadata":{}},{"cell_type":"code","source":"## Defining the loss and the evaluation function\n@jit\ndef loss_function(logits, labels):\n    xentropy = optax.softmax_cross_entropy(logits, onehot(labels, num_classes=num_labels))\n    return jnp.mean(xentropy)\n\n@jit\ndef eval_function(logits):\n    return logits.argmax(-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:13.640088Z","iopub.execute_input":"2022-04-21T14:22:13.640501Z","iopub.status.idle":"2022-04-21T14:22:13.648309Z","shell.execute_reply.started":"2022-04-21T14:22:13.640455Z","shell.execute_reply":"2022-04-21T14:22:13.647259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate a TrainState.\nstate = TrainState.create(\n    apply_fn=model.__call__,\n    params=model.params,\n    tx=adamw,\n    logits_function=eval_function,\n    loss_function=loss_function,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:15.243986Z","iopub.execute_input":"2022-04-21T14:22:15.244573Z","iopub.status.idle":"2022-04-21T14:22:16.12164Z","shell.execute_reply.started":"2022-04-21T14:22:15.244537Z","shell.execute_reply":"2022-04-21T14:22:16.120566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Training and evaluate functions**\nWe'd pass state, batch, and dropout rng to the train function, which would return new state, metrics, and new dropout rng. We'll define a loss function that runs the forward pass in the train function. Then we'll use [`jax.value_and_grad`](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html) to differentiate this loss function. The mean gradient will then be computed across all devices. The gradients will then be applied to the weights. Finally, the train step function will be parallelized over all accessible machines.","metadata":{}},{"cell_type":"code","source":"def train_step(state, batch, dropout_rng):\n    # take targets\n    targets = batch.pop(\"labels\")\n    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n    \n    #define loss function which runs the forward pass \n    def loss_function(params):\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        loss = state.loss_function(logits, targets)\n        return loss\n    \n    grad_fn = jax.value_and_grad(loss_function) #differentiate the loss function\n    loss, grad = grad_fn(state.params) \n    grad = jax.lax.pmean(grad, \"batch\") #compute the mean gradient over all devices\n    new_state = state.apply_gradients(grads=grad) #applies the gradients to the weights.\n    metrics = jax.lax.pmean({'loss': loss, 'learning_rate': learning_rate_function(state.step)}, axis_name='batch')\n    \n    return new_state, metrics, new_dropout_rng\nparallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,)) # parallelized training over all TPU devices","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:17.587522Z","iopub.execute_input":"2022-04-21T14:22:17.587822Z","iopub.status.idle":"2022-04-21T14:22:17.597925Z","shell.execute_reply.started":"2022-04-21T14:22:17.58779Z","shell.execute_reply":"2022-04-21T14:22:17.596459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define evaluation step\ndef eval_step(state, batch):\n    logits = state.apply_fn(**batch, params=state.params, train=False)[0] #stack the model's forward pass with the logits function\n    return state.logits_function(logits)\nparallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:20.518337Z","iopub.execute_input":"2022-04-21T14:22:20.51867Z","iopub.status.idle":"2022-04-21T14:22:20.526873Z","shell.execute_reply.started":"2022-04-21T14:22:20.518639Z","shell.execute_reply":"2022-04-21T14:22:20.525856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data loader**\n","metadata":{}},{"cell_type":"code","source":"# Returns batch model input\n# 1. define random permutation \n# 2. randomized dataset is extracted and then it converted to a JAX array and sharded over all local TPU devices.\ndef train_data_loader(rng, dataset, batch_size):\n    steps_per_epoch = len(dataset) // batch_size\n    perms = jax.random.permutation(rng, len(dataset))\n    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n    perms = perms.reshape((steps_per_epoch, batch_size))\n\n    for perm in perms:\n        batch = dataset[perm]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n        yield batch\n        \n# similar to train data loader \ndef eval_data_loader(dataset, batch_size): \n    for i in range(len(dataset) // batch_size):\n        batch = dataset[i * batch_size : (i + 1) * batch_size]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n        yield batch","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:22.555938Z","iopub.execute_input":"2022-04-21T14:22:22.556289Z","iopub.status.idle":"2022-04-21T14:22:22.565394Z","shell.execute_reply.started":"2022-04-21T14:22:22.556255Z","shell.execute_reply":"2022-04-21T14:22:22.564367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replicate/copy the weight parameters on each device, to passthem to our pmapped functions.\nstate = flax.jax_utils.replicate(state)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:23.323256Z","iopub.execute_input":"2022-04-21T14:22:23.324139Z","iopub.status.idle":"2022-04-21T14:22:23.445453Z","shell.execute_reply.started":"2022-04-21T14:22:23.324094Z","shell.execute_reply":"2022-04-21T14:22:23.444505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generating a seeded PRNGKey for the dropout layers and dataset shuffling.\nrng = jax.random.PRNGKey(seed)\ndropout_rngs = jax.random.split(rng, jax.local_device_count())","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:24.317211Z","iopub.execute_input":"2022-04-21T14:22:24.317845Z","iopub.status.idle":"2022-04-21T14:22:24.453219Z","shell.execute_reply.started":"2022-04-21T14:22:24.317793Z","shell.execute_reply":"2022-04-21T14:22:24.452219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Training**\nNow, we'll define the training loop and train the pre-trained model. Each epoch includes a training phase for each batch. After an epoch has been finished, we can provide training metrics and conduct an evaluation. To begin, we'll perform the train step, which entails loading data batches using the `train_data_loader` defined above, then applying the `parallel_train_step` defined above, then taking data batches from the `eval_data_loader`, and then implementing the `parallel_eval_step` function defined above to obtain predictions, and evaluating metrics to check the model's performance.","metadata":{}},{"cell_type":"code","source":"start = time.time()\n# Full training loop\nfor i, epoch in enumerate(tqdm(range(1, num_train_epochs + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n    rng, input_rng = jax.random.split(rng)\n\n    # train\n    with tqdm(total=len(train_dataset) // total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n        for batch in train_data_loader(input_rng, train_dataset, total_batch_size):\n            state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n            progress_bar_train.update(1)\n\n    # evaluate\n    with tqdm(total=len(validation_dataset) // total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n          for batch in eval_data_loader(validation_dataset, total_batch_size):\n                labels = batch.pop(\"labels\")\n                predictions = parallel_eval_step(state, batch)\n                metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n                progress_bar_eval.update(1)\n    eval_metric = metric.compute()\n    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n    eval_score = round(list(eval_metric.values())[0],5)\n    metric_name = list(eval_metric.keys())[0]\n\n    print(f\"{i+1}/{num_train_epochs} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")\n    \nprint(\"Total time: \", time.time() - start, \"seconds\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:22:54.569516Z","iopub.execute_input":"2022-04-21T14:22:54.569863Z","iopub.status.idle":"2022-04-21T14:41:07.984412Z","shell.execute_reply.started":"2022-04-21T14:22:54.56983Z","shell.execute_reply":"2022-04-21T14:41:07.983233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Test Generation**\nNow we'll load and preprocess the test data in preparation for competition submission.","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv')\nsubmission=pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's have a look at the test data\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:41:12.600627Z","iopub.execute_input":"2022-04-21T14:41:12.60091Z","iopub.status.idle":"2022-04-21T14:41:12.615184Z","shell.execute_reply.started":"2022-04-21T14:41:12.600881Z","shell.execute_reply":"2022-04-21T14:41:12.613904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine context, anchor and target columns\ntest['inputs'] = test.context + sep + test.anchor + sep + test.target","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:41:43.25813Z","iopub.execute_input":"2022-04-21T14:41:43.258931Z","iopub.status.idle":"2022-04-21T14:41:43.266065Z","shell.execute_reply.started":"2022-04-21T14:41:43.258896Z","shell.execute_reply":"2022-04-21T14:41:43.264723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:41:47.45428Z","iopub.execute_input":"2022-04-21T14:41:47.454862Z","iopub.status.idle":"2022-04-21T14:41:47.468702Z","shell.execute_reply.started":"2022-04-21T14:41:47.454826Z","shell.execute_reply":"2022-04-21T14:41:47.467441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting test dataframe to HuggingFace Dataset using Huggingface's [`from_pandas`](https://huggingface.co/docs/datasets/loading) function from Dataset class ","metadata":{}},{"cell_type":"code","source":"test_ds = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:42:48.713272Z","iopub.execute_input":"2022-04-21T14:42:48.713582Z","iopub.status.idle":"2022-04-21T14:42:48.725655Z","shell.execute_reply.started":"2022-04-21T14:42:48.713542Z","shell.execute_reply":"2022-04-21T14:42:48.724433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:42:52.938295Z","iopub.execute_input":"2022-04-21T14:42:52.939234Z","iopub.status.idle":"2022-04-21T14:42:52.947445Z","shell.execute_reply.started":"2022-04-21T14:42:52.939182Z","shell.execute_reply":"2022-04-21T14:42:52.946365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess test dataset\ndef preprocess_test(input_batch):\n    '''\n    INPUT - input batch from from original dataset\n    RETURNS preprocessed data\n    '''\n    texts = (input_batch[\"inputs\"],)\n    processed = tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n    return processed","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:44:08.023323Z","iopub.execute_input":"2022-04-21T14:44:08.02361Z","iopub.status.idle":"2022-04-21T14:44:08.032305Z","shell.execute_reply.started":"2022-04-21T14:44:08.023577Z","shell.execute_reply":"2022-04-21T14:44:08.030898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_test = test_ds.map(preprocess_test,batched=True, remove_columns= ['id', 'anchor', 'target', 'context', 'inputs'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:44:15.579358Z","iopub.execute_input":"2022-04-21T14:44:15.579724Z","iopub.status.idle":"2022-04-21T14:44:17.358918Z","shell.execute_reply.started":"2022-04-21T14:44:15.579692Z","shell.execute_reply":"2022-04-21T14:44:17.357658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# similar to train dataloader, it takes dataset and batch_size\ndef test_data_loader(dataset,batch_size):\n    if len(dataset)<batch_size:\n        batch = dataset[:]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n        yield batch\n    else:\n        for i in range(len(dataset) // batch_size):\n            batch = dataset[i * batch_size : (i + 1) * batch_size]\n            batch = {k: jnp.array(v) for k, v in batch.items()}\n            batch = shard(batch)\n            yield batch\n        batch = dataset[(i+1) * batch_size:]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n        yield batch","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:44:28.968748Z","iopub.execute_input":"2022-04-21T14:44:28.969038Z","iopub.status.idle":"2022-04-21T14:44:28.97796Z","shell.execute_reply.started":"2022-04-21T14:44:28.969005Z","shell.execute_reply":"2022-04-21T14:44:28.976596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Running on test dataset , storing predictions \npreds=[]\nfor batch in test_data_loader(encoded_test, total_batch_size):\n    predictions = parallel_eval_step(state, batch)\n    preds.append(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:45:04.364891Z","iopub.execute_input":"2022-04-21T14:45:04.365203Z","iopub.status.idle":"2022-04-21T14:45:12.424882Z","shell.execute_reply.started":"2022-04-21T14:45:04.365147Z","shell.execute_reply":"2022-04-21T14:45:12.422867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert it into numpy array\npredictions=[]\nfor pred in preds:\n    predictions.extend(np.array(pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:45:24.863659Z","iopub.execute_input":"2022-04-21T14:45:24.864008Z","iopub.status.idle":"2022-04-21T14:45:24.870312Z","shell.execute_reply.started":"2022-04-21T14:45:24.863966Z","shell.execute_reply":"2022-04-21T14:45:24.868973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds'] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:46:29.063111Z","iopub.execute_input":"2022-04-21T14:46:29.063766Z","iopub.status.idle":"2022-04-21T14:46:29.070972Z","shell.execute_reply.started":"2022-04-21T14:46:29.063727Z","shell.execute_reply":"2022-04-21T14:46:29.069863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:46:41.020413Z","iopub.execute_input":"2022-04-21T14:46:41.020786Z","iopub.status.idle":"2022-04-21T14:46:41.040218Z","shell.execute_reply.started":"2022-04-21T14:46:41.020752Z","shell.execute_reply":"2022-04-21T14:46:41.038987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change the preds back to the corresponding float values\ndef change_preds(x):\n    \n    if x == 0:\n        return 0\n\n    if x == 1:\n        return 0.25\n    \n    if x == 2:\n        return 0.5\n\n    if x == 3:\n        return 0.75\n\n    if x == 4:\n        return 1.0\n    \ntest['modified_preds'] = test['preds'].apply(change_preds)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:46:59.316872Z","iopub.execute_input":"2022-04-21T14:46:59.317207Z","iopub.status.idle":"2022-04-21T14:46:59.325405Z","shell.execute_reply.started":"2022-04-21T14:46:59.317145Z","shell.execute_reply":"2022-04-21T14:46:59.324138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:47:13.761579Z","iopub.execute_input":"2022-04-21T14:47:13.761872Z","iopub.status.idle":"2022-04-21T14:47:13.778562Z","shell.execute_reply.started":"2022-04-21T14:47:13.76184Z","shell.execute_reply":"2022-04-21T14:47:13.777422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['id', 'modified_preds']\ndf = test[cols]\nmodified_preds = df['modified_preds']\nsubmission['score'] = modified_preds\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:47:55.540356Z","iopub.execute_input":"2022-04-21T14:47:55.540696Z","iopub.status.idle":"2022-04-21T14:47:55.555629Z","shell.execute_reply.started":"2022-04-21T14:47:55.540665Z","shell.execute_reply":"2022-04-21T14:47:55.554229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Conclusion**\nIn this notebook, we've used a novel semantic similarity dataset to train a model to extract meaningful information from patent documents by matching key terms. We used [JAX](https://github.com/google/jax) and [FLAX](https://flax.readthedocs.io/en/latest/) to train the pre-trained BERT neural network from huggingface for this dataset. In this notebook, we utilised the classifier BERT model to predict score labels. Each of the five intervals in the training data score can be categorised into one of five classes [0,1,2,3,4]. The anticipated classes will be changed back to float increments after inference. Using this approach, we were able to achieve a public score of 0.6937.\n\nSave the version of your notebook that you want to submit before proceeding. When it's finished, go to the data section and look for the output there. Select the option for Output. When you click the submit button in output, you'll be able to see how your model performed. Click the Edit button to reopen the notebook and return to your model to improve it.\n\n\nTo see more examples of how to use [JAX](https://github.com/google/jax) and [FLAX](https://flax.readthedocs.io/en/latest/) with different data formats, please see this [discussion post](https://www.kaggle.com/discussions/getting-started/315696).  \n\nNow, it's your turn to  create some amazing notebooks using [JAX](https://github.com/google/jax) and [FLAX](https://flax.readthedocs.io/en/latest/) for [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/c/us-patent-phrase-to-phrase-matching) competition. \n\n### **Works Cited**\n- https://flax.readthedocs.io/en/latest/index.html\n- https://github.com/google/flax/tree/main/examples\n- https://www.kaggle.com/heyytanay/sentiment-clf-jax-flax-on-tpus-w-b/notebook\n- https://www.kaggle.com/asvskartheek/bert-tpus-jax-huggingface/notebook\n- https://huggingface.co/docs/datasets/package_reference/main_classes.html#dataset\n-  https://colab.sandbox.google.com/github/huggingface/notebooks/blob/master/examples/text_classification_flax.ipynb#scrollTo=Mn1GdGpipfWK\n- https://www.kaggle.com/code/vbookshelf/hugging-face-trainer-a-classification-workflow\n- https://www.kaggle.com/code/yashvi/predict-book-review-rating-using-jax-flax/notebook#Test-Generation","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:51:24.893356Z","iopub.execute_input":"2022-04-21T14:51:24.89433Z","iopub.status.idle":"2022-04-21T14:51:24.917661Z","shell.execute_reply.started":"2022-04-21T14:51:24.89427Z","shell.execute_reply":"2022-04-21T14:51:24.910388Z"}}}]}