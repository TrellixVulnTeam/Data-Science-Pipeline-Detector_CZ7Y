{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q sentence_transformers --no-index --find-links /kaggle/input/all-distilroberta-v1-train/site_packages","metadata":{"execution":{"iopub.status.busy":"2022-06-01T23:04:26.439174Z","iopub.execute_input":"2022-06-01T23:04:26.439716Z","iopub.status.idle":"2022-06-01T23:04:38.133895Z","shell.execute_reply.started":"2022-06-01T23:04:26.439653Z","shell.execute_reply":"2022-06-01T23:04:38.132973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\ntest = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv') \ntest['target_context'] = test[['target','context']].agg(' '.join, axis=1) \ntest = test.drop(['id','target','context'],axis=1) \ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:11:20.367951Z","iopub.execute_input":"2022-06-02T00:11:20.36833Z","iopub.status.idle":"2022-06-02T00:11:20.390491Z","shell.execute_reply.started":"2022-06-02T00:11:20.368299Z","shell.execute_reply":"2022-06-02T00:11:20.389605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys \nmodel_path = '../input/all-distilroberta-v1-train/all-distilroberta-v1'\n#tokenizer_path = sys.path.append(\"../input/all-distilroberta-v1-train/all-distilroberta-v1/tokenizer.json\") ","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:11:15.549711Z","iopub.execute_input":"2022-06-02T00:11:15.55017Z","iopub.status.idle":"2022-06-02T00:11:15.555161Z","shell.execute_reply.started":"2022-06-02T00:11:15.550135Z","shell.execute_reply":"2022-06-02T00:11:15.554293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.anchor.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T23:10:33.937176Z","iopub.execute_input":"2022-06-01T23:10:33.938334Z","iopub.status.idle":"2022-06-01T23:10:33.948283Z","shell.execute_reply.started":"2022-06-01T23:10:33.93828Z","shell.execute_reply":"2022-06-01T23:10:33.947505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport torch.nn.functional as F\n\n#Mean Pooling - Take attention mask into account for correct averaging\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\n\n# Sentences we want sentence embeddings for\nsentences = test.anchor.tolist()\n\n# Load model from HuggingFace Hub\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModel.from_pretrained(model_path)\n\n# Tokenize sentences\nencoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n\n# Compute token embeddings\nwith torch.no_grad():\n    model_output = model(**encoded_input)\n\n# Perform pooling\nsentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n\n# Normalize embeddings\nsentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n\nprint(\"Sentence embeddings:\")\nprint(sentence_embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:11:29.457492Z","iopub.execute_input":"2022-06-02T00:11:29.458271Z","iopub.status.idle":"2022-06-02T00:11:34.539075Z","shell.execute_reply.started":"2022-06-02T00:11:29.458231Z","shell.execute_reply":"2022-06-02T00:11:34.538212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer(model_path)\nanchor_vec = model.encode(test.anchor.tolist())\ntarget_vec = model.encode(test.target_context.tolist())\ncos_sim = []\nfor i in range(len(anchor_vec)):\n    sim = util.cos_sim(anchor_vec[i], target_vec[i])\n    cos_sim.append(sim[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:11:55.071858Z","iopub.execute_input":"2022-06-02T00:11:55.072265Z","iopub.status.idle":"2022-06-02T00:11:57.102359Z","shell.execute_reply.started":"2022-06-02T00:11:55.072229Z","shell.execute_reply":"2022-06-02T00:11:57.101713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cos_sim_score = []\nfor i in range(len(cos_sim)):\n    cs = cos_sim[i].item()\n    cos_sim_score.append(cs)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:12:33.36548Z","iopub.execute_input":"2022-06-02T00:12:33.366312Z","iopub.status.idle":"2022-06-02T00:12:33.370607Z","shell.execute_reply.started":"2022-06-02T00:12:33.366274Z","shell.execute_reply":"2022-06-02T00:12:33.369975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cos_sim_score","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:12:49.885253Z","iopub.execute_input":"2022-06-02T00:12:49.885997Z","iopub.status.idle":"2022-06-02T00:12:49.893046Z","shell.execute_reply.started":"2022-06-02T00:12:49.885955Z","shell.execute_reply":"2022-06-02T00:12:49.892074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:14:11.016054Z","iopub.execute_input":"2022-06-02T00:14:11.016481Z","iopub.status.idle":"2022-06-02T00:14:11.032163Z","shell.execute_reply.started":"2022-06-02T00:14:11.016445Z","shell.execute_reply":"2022-06-02T00:14:11.031228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {'id': sample.id, 'score': cos_sim_score}\n    \n    \nsubmission = pd.DataFrame(data)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:14:14.227914Z","iopub.execute_input":"2022-06-02T00:14:14.228377Z","iopub.status.idle":"2022-06-02T00:14:14.262118Z","shell.execute_reply.started":"2022-06-02T00:14:14.228339Z","shell.execute_reply":"2022-06-02T00:14:14.261422Z"},"trusted":true},"execution_count":null,"outputs":[]}]}