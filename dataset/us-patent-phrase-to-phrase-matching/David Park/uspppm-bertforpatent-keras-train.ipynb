{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow import keras\n# import bert\nimport math\nimport os\n\nfrom tensorflow.keras.layers import Dense, LSTM, Bidirectional, Reshape, Layer, Multiply, GRU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import callbacks\nimport tensorflow.keras.backend as K\n\nimport codecs\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport pickle\n\nfrom transformers import BertTokenizer, TFBertModel, AutoTokenizer\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:02.339357Z","iopub.execute_input":"2022-05-04T03:54:02.340021Z","iopub.status.idle":"2022-05-04T03:54:09.564807Z","shell.execute_reply.started":"2022-05-04T03:54:02.339914Z","shell.execute_reply":"2022-05-04T03:54:09.564041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# environmental variables","metadata":{}},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/us-patent-phrase-to-phrase-matching/\"\npt_model_dir = \"/kaggle/input/bert-for-patents/bert-for-patents/\"\ncpc_mc_cls_weight = \"/kaggle/input/cpc-mc-cls-wgt/cpc_title_mc_cls_v2.h5\"\nmax_seq_len = 80\nbatch_size = 32\nepochs = 30\nlearning_rate = 2e-5","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.56659Z","iopub.execute_input":"2022-05-04T03:54:09.566824Z","iopub.status.idle":"2022-05-04T03:54:09.573837Z","shell.execute_reply.started":"2022-05-04T03:54:09.56679Z","shell.execute_reply":"2022-05-04T03:54:09.573125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(pt_model_dir)\n# tokenizer = AutoTokenizer.from_pretrained(pt_model_dir)\npad_idx = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\nprint(tokenizer)\nprint(\"Padding token index : \", pad_idx)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.577136Z","iopub.execute_input":"2022-05-04T03:54:09.577339Z","iopub.status.idle":"2022-05-04T03:54:09.719062Z","shell.execute_reply.started":"2022-05-04T03:54:09.577315Z","shell.execute_reply":"2022-05-04T03:54:09.718339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# User define functions","metadata":{}},{"cell_type":"code","source":"def dataset_split(dataset, split_val):\n    lengths = int(len(dataset) * split_val)\n    train_data = dataset[:lengths]\n    valid_data = dataset[lengths:]\n    return train_data, valid_data\n\ndef dataset_load(train_url, test_url):\n    train_data = pd.read_csv(train_url, sep=',')\n    train_data['sep_token'] = '[SEP]'\n    train_data['cls_token'] = '[CLS]'\n    train_data['context_token'] = '[' + train_data.context + ']'\n    context_tokens = list(train_data.context_token.unique())\n    train_data = train_data.sample(frac=1).reset_index(drop=True)\n    train_data, valid_data = dataset_split(dataset=train_data, split_val=0.9)\n    test_data = pd.read_csv(test_url, sep=',')\n    test_data['sep_token'] = '[SEP]'\n    test_data['cls_token'] = '[CLS]'\n    test_data['context_token'] = '[' + test_data.context + ']'\n    \n    return train_data, valid_data, test_data, context_tokens\n\ndef create_learning_rate_scheduler(max_learn_rate=5e-5,\n                                   end_learn_rate=1e-7,\n                                   warmup_epoch_count=10,\n                                   total_epoch_count=90):\n\n    def lr_scheduler(epoch):\n        \n        if epoch < warmup_epoch_count:\n            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n        else:\n            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n        return float(res)\n    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n\n    return learning_rate_scheduler\n\ndef encode_text(text, \n                tokenizer,\n                max_length):\n    \n    # With tokenizer's batch_encode_plus batch of both the sentences are\n    # encoded together and separated by [SEP] token.\n    encoded = tokenizer.batch_encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_token_type_ids=True,\n        return_tensors=\"tf\",\n    )\n\n    # Convert batch of encoded features to numpy array.\n    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_masks\": attention_masks,\n        \"token_type_ids\": token_type_ids\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.72112Z","iopub.execute_input":"2022-05-04T03:54:09.722459Z","iopub.status.idle":"2022-05-04T03:54:09.736607Z","shell.execute_reply.started":"2022-05-04T03:54:09.722419Z","shell.execute_reply":"2022-05-04T03:54:09.735807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataset load","metadata":{}},{"cell_type":"code","source":"train_data, valid_data, test_data, context_tokens = dataset_load(dataset_path + \"train.csv\", dataset_path + \"test.csv\")\nlabels = list(set(train_data[\"score\"].values))\nlabels.sort()\n\nprint(len(train_data), len(valid_data), len(test_data))\nprint(labels)\nprint(context_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.737798Z","iopub.execute_input":"2022-05-04T03:54:09.73813Z","iopub.status.idle":"2022-05-04T03:54:09.876824Z","shell.execute_reply.started":"2022-05-04T03:54:09.738092Z","shell.execute_reply":"2022-05-04T03:54:09.87511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.878045Z","iopub.execute_input":"2022-05-04T03:54:09.878283Z","iopub.status.idle":"2022-05-04T03:54:09.897651Z","shell.execute_reply.started":"2022-05-04T03:54:09.878248Z","shell.execute_reply":"2022-05-04T03:54:09.896959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the data\nprint(f\"Total train samples : {train_data.shape[0]}\")\nprint(f\"Total valid samples: {valid_data.shape[0]}\")\nprint(f\"Total test samples: {test_data.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.898957Z","iopub.execute_input":"2022-05-04T03:54:09.89921Z","iopub.status.idle":"2022-05-04T03:54:09.904243Z","shell.execute_reply.started":"2022-05-04T03:54:09.899175Z","shell.execute_reply":"2022-05-04T03:54:09.903596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train Score Distribution\")\ntrain_data['score'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.905521Z","iopub.execute_input":"2022-05-04T03:54:09.905904Z","iopub.status.idle":"2022-05-04T03:54:09.922932Z","shell.execute_reply.started":"2022-05-04T03:54:09.905869Z","shell.execute_reply":"2022-05-04T03:54:09.922154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load cpc title data","metadata":{}},{"cell_type":"code","source":"cpc_codes = pd.read_csv(\"/kaggle/input/cpc-codes/titles.csv\")\ncpc_codes = cpc_codes[[\"code\", \"title\"]]\n\ncondition = cpc_codes['code'].map(len) == 3\ncpc_codes = cpc_codes[condition].reset_index(drop=True)\ncpc_codes","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:09.924408Z","iopub.execute_input":"2022-05-04T03:54:09.924785Z","iopub.status.idle":"2022-05-04T03:54:10.755744Z","shell.execute_reply.started":"2022-05-04T03:54:09.924747Z","shell.execute_reply":"2022-05-04T03:54:10.755078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cpc_codes.loc[cpc_codes.code == \"B29\"][\"title\"].values )","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.758712Z","iopub.execute_input":"2022-05-04T03:54:10.758915Z","iopub.status.idle":"2022-05-04T03:54:10.763826Z","shell.execute_reply.started":"2022-05-04T03:54:10.758891Z","shell.execute_reply":"2022-05-04T03:54:10.763002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# merge cpc title and anchor","metadata":{}},{"cell_type":"code","source":"train_data = train_data.merge(cpc_codes, left_on='context', right_on='code', how='left')\nvalid_data = valid_data.merge(cpc_codes, left_on='context', right_on='code', how='left')\ntest_data = test_data.merge(cpc_codes, left_on='context', right_on='code', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.765147Z","iopub.execute_input":"2022-05-04T03:54:10.765606Z","iopub.status.idle":"2022-05-04T03:54:10.804554Z","shell.execute_reply.started":"2022-05-04T03:54:10.765572Z","shell.execute_reply":"2022-05-04T03:54:10.803825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.805924Z","iopub.execute_input":"2022-05-04T03:54:10.806179Z","iopub.status.idle":"2022-05-04T03:54:10.810049Z","shell.execute_reply.started":"2022-05-04T03:54:10.806143Z","shell.execute_reply":"2022-05-04T03:54:10.809162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.812193Z","iopub.execute_input":"2022-05-04T03:54:10.81304Z","iopub.status.idle":"2022-05-04T03:54:10.820653Z","shell.execute_reply.started":"2022-05-04T03:54:10.813004Z","shell.execute_reply":"2022-05-04T03:54:10.819745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['title'] = train_data['title'].str.lower().str.replace(\";\",\"\")\ntrain_data['anchor'] = train_data['anchor'].str.lower()\ntrain_data['target'] = train_data['target'].str.lower()\n\nvalid_data['title'] = valid_data['title'].str.lower().str.replace(\";\",\"\")\nvalid_data['anchor'] = valid_data['anchor'].str.lower()\nvalid_data['target'] = valid_data['target'].str.lower()\n\ntest_data['title'] = test_data['title'].str.lower().str.replace(\";\",\"\")\ntest_data['anchor'] = test_data['anchor'].str.lower()\ntest_data['target'] = test_data['target'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.821916Z","iopub.execute_input":"2022-05-04T03:54:10.822496Z","iopub.status.idle":"2022-05-04T03:54:10.908801Z","shell.execute_reply.started":"2022-05-04T03:54:10.822459Z","shell.execute_reply":"2022-05-04T03:54:10.90807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['text'] = train_data['title'] + \" \" + train_data['anchor']\nvalid_data['text'] = valid_data['title'] + \" \" + valid_data['anchor']\ntest_data['text'] = test_data['title'] + \" \" + test_data['anchor']\n\n# train_data['text'] = train_data['cls_token'] + \\\n#                 train_data['context_token'] + train_data['title'] + \\\n#                 train_data['sep_token'] + train_data['anchor'] + \\\n#                 train_data['sep_token'] + train_data['target'] + \\\n#                 train_data['sep_token']\n# valid_data['text'] = valid_data['cls_token'] + \\\n#                 valid_data['context_token'] + valid_data['title'] + \\\n#                 valid_data['sep_token'] + valid_data['anchor'] + \\\n#                 valid_data['sep_token'] + valid_data['target'] + \\\n#                 valid_data['sep_token']\n\n# test_data['text'] = test_data['cls_token'] + \\\n#                 test_data['context_token'] + test_data['title'] + \\\n#                 test_data['sep_token'] + test_data['anchor'] + \\\n#                 test_data['sep_token'] + test_data['target'] + \\\n#                 test_data['sep_token']","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.909931Z","iopub.execute_input":"2022-05-04T03:54:10.910248Z","iopub.status.idle":"2022-05-04T03:54:10.929571Z","shell.execute_reply.started":"2022-05-04T03:54:10.910211Z","shell.execute_reply":"2022-05-04T03:54:10.928871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.932282Z","iopub.execute_input":"2022-05-04T03:54:10.93251Z","iopub.status.idle":"2022-05-04T03:54:10.952883Z","shell.execute_reply.started":"2022-05-04T03:54:10.932485Z","shell.execute_reply":"2022-05-04T03:54:10.951926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[\"title\"][0])\nprint(train_data['anchor'][0])\nprint(train_data['target'][0])\nprint(train_data['text'][0])\nprint(\"\\n\")\nprint(test_data[\"title\"][0])\nprint(test_data['anchor'][0])\nprint(test_data['target'][0])\nprint(test_data['text'][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.954565Z","iopub.execute_input":"2022-05-04T03:54:10.955104Z","iopub.status.idle":"2022-05-04T03:54:10.967829Z","shell.execute_reply.started":"2022-05-04T03:54:10.954979Z","shell.execute_reply":"2022-05-04T03:54:10.966848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# encode the dataset","metadata":{}},{"cell_type":"code","source":"encoded_train_data = encode_text(train_data[[\"text\", \"target\"]].values.tolist(), tokenizer, max_seq_len)\nencoded_valid_data = encode_text(valid_data[[\"text\", \"target\"]].values.tolist(), tokenizer, max_seq_len)\nencoded_test_data = encode_text(test_data[[\"text\", \"target\"]].values.tolist(), tokenizer, max_seq_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:10.969251Z","iopub.execute_input":"2022-05-04T03:54:10.969583Z","iopub.status.idle":"2022-05-04T03:54:38.534014Z","shell.execute_reply.started":"2022-05-04T03:54:10.969549Z","shell.execute_reply":"2022-05-04T03:54:38.533266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(encoded_train_data[\"input_ids\"][0])\nprint(encoded_train_data[\"attention_masks\"][0])\nprint(encoded_train_data[\"token_type_ids\"][0])\n\nprint(encoded_valid_data[\"input_ids\"][0])\nprint(encoded_valid_data[\"attention_masks\"][0])\nprint(encoded_valid_data[\"token_type_ids\"][0])\n\nprint(encoded_test_data[\"input_ids\"][0])\nprint(encoded_test_data[\"attention_masks\"][0])\nprint(encoded_test_data[\"token_type_ids\"][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:38.536149Z","iopub.execute_input":"2022-05-04T03:54:38.536555Z","iopub.status.idle":"2022-05-04T03:54:38.550106Z","shell.execute_reply.started":"2022-05-04T03:54:38.536517Z","shell.execute_reply":"2022-05-04T03:54:38.549345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# construct x y input data","metadata":{}},{"cell_type":"code","source":"train_x = [encoded_train_data[\"input_ids\"], encoded_train_data[\"attention_masks\"], encoded_train_data[\"token_type_ids\"]]\ntrain_y = np.array(train_data['score'].values.tolist())\nvalid_x = [encoded_valid_data[\"input_ids\"], encoded_valid_data[\"attention_masks\"], encoded_valid_data[\"token_type_ids\"]]\nvalid_y = np.array(valid_data['score'].values.tolist())\ntest_x = [encoded_test_data[\"input_ids\"], encoded_test_data[\"attention_masks\"], encoded_test_data[\"token_type_ids\"]]\n\nprint(\"train x shape : \", train_x[0].shape, train_x[1].shape, train_x[2].shape)\nprint(\"train y shape : \", train_y.shape)\nprint(\"valid x shape : \", valid_x[0].shape, valid_x[1].shape, valid_x[2].shape)\nprint(\"valid y shape : \", valid_y.shape)\nprint(\"test x shape : \", test_x[0].shape, test_x[1].shape, test_x[2].shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:38.551476Z","iopub.execute_input":"2022-05-04T03:54:38.551824Z","iopub.status.idle":"2022-05-04T03:54:38.572729Z","shell.execute_reply.started":"2022-05-04T03:54:38.551784Z","shell.execute_reply":"2022-05-04T03:54:38.571878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# build the model","metadata":{}},{"cell_type":"code","source":"mirrored_strategy = tf.distribute.MirroredStrategy()\nwith mirrored_strategy.scope():\n    # Encoded token ids from BERT tokenizer.\n    input_ids = tf.keras.layers.Input(\n        shape=(max_seq_len,), dtype=tf.int32, name=\"input_ids\"\n    )\n    # Attention masks indicates to the model which tokens should be attended to.\n    attention_masks = tf.keras.layers.Input(\n        shape=(max_seq_len,), dtype=tf.int32, name=\"attention_masks\"\n    )\n    # Token type ids are binary masks identifying different sequences in the model.\n    token_type_ids = tf.keras.layers.Input(\n        shape=(max_seq_len,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n    # Loading pretrained BERT model.\n    base_model = TFBertModel.from_pretrained(pt_model_dir, from_pt=True)\n\n    base_model_output = base_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n\n    last_hidden_state = base_model_output.last_hidden_state\n    print(last_hidden_state.shape)\n    \n#     cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(last_hidden_state)\n#     output = tf.keras.layers.Dense(1, activation=\"linear\")(cls_out)\n\n#     gru = GRU(units=max_seq_len, return_sequences=False)(last_hidden_state)\n    lstm = Bidirectional(LSTM(units=max_seq_len, return_sequences=False))(last_hidden_state)\n    output = tf.keras.layers.Dense(1, activation=\"linear\", name=\"uspppm_output\")(lstm)\n    \n#     avg_pool = tf.keras.layers.GlobalAveragePooling1D()(last_hidden_state)\n#     dropout = tf.keras.layers.Dropout(0.1, name=\"uspppm_dropout\")(avg_pool)\n#     output = tf.keras.layers.Dense(1, activation=\"linear\", name=\"uspppm_output\")(dropout)\n\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n    )\n\n    model.compile(\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n#         optimizer = tf.keras.optimizers.Adam(),\n        loss='mse'\n#         loss=tf.keras.losses.BinaryCrossentropy()\n    )\n\n# 전체 신경망 모델 요약 출력\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:54:38.574506Z","iopub.execute_input":"2022-05-04T03:54:38.574959Z","iopub.status.idle":"2022-05-04T03:55:02.168425Z","shell.execute_reply.started":"2022-05-04T03:54:38.574921Z","shell.execute_reply":"2022-05-04T03:55:02.16771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(cpc_mc_cls_weight, by_name=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:55:02.169812Z","iopub.execute_input":"2022-05-04T03:55:02.170071Z","iopub.status.idle":"2022-05-04T03:55:12.446519Z","shell.execute_reply.started":"2022-05-04T03:55:02.170037Z","shell.execute_reply":"2022-05-04T03:55:12.445777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train start","metadata":{}},{"cell_type":"code","source":"es = callbacks\ncb_earlystop = es.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:55:12.448024Z","iopub.execute_input":"2022-05-04T03:55:12.44831Z","iopub.status.idle":"2022-05-04T03:55:12.452908Z","shell.execute_reply.started":"2022-05-04T03:55:12.448261Z","shell.execute_reply":"2022-05-04T03:55:12.452214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 학습 시작\nhistory = model.fit(\n    train_x,\n    train_y,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_data=(valid_x, valid_y),\n    callbacks=[cb_earlystop]\n#     callbacks=[cb_earlystop, create_learning_rate_scheduler(max_learn_rate=3e-4,\n#                                                     end_learn_rate=3e-6,\n#                                                     warmup_epoch_count=2,\n#                                                     total_epoch_count=epochs)]\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:55:12.454099Z","iopub.execute_input":"2022-05-04T03:55:12.454654Z","iopub.status.idle":"2022-05-04T03:55:51.794328Z","shell.execute_reply.started":"2022-05-04T03:55:12.454616Z","shell.execute_reply":"2022-05-04T03:55:51.793139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model save","metadata":{}},{"cell_type":"code","source":"model.save(\"/kaggle/working/usppm_bfp_v5_lstm.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:55:51.795435Z","iopub.status.idle":"2022-05-04T03:55:51.796339Z","shell.execute_reply.started":"2022-05-04T03:55:51.796085Z","shell.execute_reply":"2022-05-04T03:55:51.796109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prediction","metadata":{}},{"cell_type":"code","source":"# pred = model.predict(test_x)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:55:51.797439Z","iopub.status.idle":"2022-05-04T03:55:51.798289Z","shell.execute_reply.started":"2022-05-04T03:55:51.798057Z","shell.execute_reply":"2022-05-04T03:55:51.798081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")\n# submission['score'] = pred\n# submission['score'] = submission.score.apply(lambda x: 0 if x < 0 else x)\n# submission['score'] = submission.score.apply(lambda x: 1 if x > 1 else x)\n# submission.to_csv(\"submission.csv\",index=False)\n# submission","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:55:51.799543Z","iopub.status.idle":"2022-05-04T03:55:51.799952Z","shell.execute_reply.started":"2022-05-04T03:55:51.799722Z","shell.execute_reply":"2022-05-04T03:55:51.799745Z"},"trusted":true},"execution_count":null,"outputs":[]}]}