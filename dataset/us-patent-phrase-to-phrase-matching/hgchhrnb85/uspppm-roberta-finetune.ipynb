{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport scipy\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import get_cosine_schedule_with_warmup,get_linear_schedule_with_warmup,AdamW\nfrom transformers import AutoModel,AutoModelForSequenceClassification,AutoTokenizer\n\nscaler = torch.cuda.amp.GradScaler() # GPUでの高速化。\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cpuがgpuかを自動判断\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:21.32373Z","iopub.execute_input":"2022-05-20T08:26:21.32408Z","iopub.status.idle":"2022-05-20T08:26:21.3355Z","shell.execute_reply.started":"2022-05-20T08:26:21.324047Z","shell.execute_reply":"2022-05-20T08:26:21.334527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"#各種パラメータ設定\nconfig = {\n    'lr': 2e-5,\n    'wd':0.01,\n    'batch_size':32,\n    'valid_step':10,\n    'max_len':128,\n    'epochs':5,\n    'nfolds':5,\n    'seed':42,\n    'dropout_rate':0.2,\n    'model_dir':\"../input/roberta-transformers-pytorch/roberta-base\",\n}\n\nfor i in range(config['nfolds']):\n    os.makedirs(f'./model{i}',exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:21.346782Z","iopub.execute_input":"2022-05-20T08:26:21.347126Z","iopub.status.idle":"2022-05-20T08:26:21.353648Z","shell.execute_reply.started":"2022-05-20T08:26:21.347085Z","shell.execute_reply":"2022-05-20T08:26:21.352636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seed","metadata":{}},{"cell_type":"code","source":"def random_seed(SEED):\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nrandom_seed(config[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:21.371501Z","iopub.execute_input":"2022-05-20T08:26:21.371801Z","iopub.status.idle":"2022-05-20T08:26:21.377231Z","shell.execute_reply.started":"2022-05-20T08:26:21.371775Z","shell.execute_reply":"2022-05-20T08:26:21.376182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Import","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = './'\ntrain = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\nsubmit = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")\ntitles = pd.read_csv(\"../input/cpc-codes/titles.csv\")\n\ntrain = train.merge(titles, left_on='context', right_on='code')\ntest = test.merge(titles, left_on='context', right_on='code')\ntrain['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['title']\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['title']\ntrain = train[[\"id\",\"anchor\",\"target\",\"context\",\"score\",\"text\"]]\ntest = test[[\"id\",\"anchor\",\"target\",\"context\",\"text\"]]","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:21.39671Z","iopub.execute_input":"2022-05-20T08:26:21.39697Z","iopub.status.idle":"2022-05-20T08:26:22.295063Z","shell.execute_reply.started":"2022-05-20T08:26:21.396946Z","shell.execute_reply":"2022-05-20T08:26:22.294123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.296836Z","iopub.execute_input":"2022-05-20T08:26:22.29726Z","iopub.status.idle":"2022-05-20T08:26:22.323846Z","shell.execute_reply.started":"2022-05-20T08:26:22.297223Z","shell.execute_reply":"2022-05-20T08:26:22.322859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.325875Z","iopub.execute_input":"2022-05-20T08:26:22.326317Z","iopub.status.idle":"2022-05-20T08:26:22.356274Z","shell.execute_reply.started":"2022-05-20T08:26:22.326274Z","shell.execute_reply":"2022-05-20T08:26:22.355358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.359706Z","iopub.execute_input":"2022-05-20T08:26:22.360035Z","iopub.status.idle":"2022-05-20T08:26:22.370237Z","shell.execute_reply.started":"2022-05-20T08:26:22.360003Z","shell.execute_reply":"2022-05-20T08:26:22.369108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titles","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.37216Z","iopub.execute_input":"2022-05-20T08:26:22.372805Z","iopub.status.idle":"2022-05-20T08:26:22.399852Z","shell.execute_reply.started":"2022-05-20T08:26:22.37259Z","shell.execute_reply":"2022-05-20T08:26:22.398598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kfold","metadata":{}},{"cell_type":"code","source":"def make_folds(data, num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"fold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    data = data.sample(frac=1).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    # num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"score\"], bins=5, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=config['seed'])\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'fold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data\n\ntrain = make_folds(train,config['nfolds'])","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.401453Z","iopub.execute_input":"2022-05-20T08:26:22.401903Z","iopub.status.idle":"2022-05-20T08:26:22.445435Z","shell.execute_reply.started":"2022-05-20T08:26:22.401844Z","shell.execute_reply":"2022-05-20T08:26:22.4445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataSet","metadata":{}},{"cell_type":"code","source":"class USPPPMDataset(Dataset):\n    def __init__(self, df, model_name, include_labels=True):\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n        self.df = df\n\n        self.include_labels = include_labels\n\n        self.text = df[\"text\"].tolist()\n\n        self.encoded = tokenizer.batch_encode_plus(\n            self.text,\n            padding = 'max_length',            \n            max_length = config[\"max_len\"],\n            truncation = True,\n            return_attention_mask=True\n        )\n        \n        if self.include_labels:\n            self.labels = df[\"score\"].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n\n        if self.include_labels:\n            label = torch.tensor(self.labels[idx]).float()\n            return input_ids, attention_mask, label\n\n        return input_ids, attention_mask","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.446984Z","iopub.execute_input":"2022-05-20T08:26:22.447385Z","iopub.status.idle":"2022-05-20T08:26:22.456277Z","shell.execute_reply.started":"2022-05-20T08:26:22.447344Z","shell.execute_reply":"2022-05-20T08:26:22.455219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class USPPPMModel(nn.Module):\n    def __init__(self,model_name):\n        super().__init__()\n\n        self.model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=1)\n        \n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_ids, attention_mask):\n        model_output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        \n        output = self.sigmoid(model_output.logits).squeeze()\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.459445Z","iopub.execute_input":"2022-05-20T08:26:22.46024Z","iopub.status.idle":"2022-05-20T08:26:22.470303Z","shell.execute_reply.started":"2022-05-20T08:26:22.460196Z","shell.execute_reply":"2022-05-20T08:26:22.469346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class USPPPMModel(nn.Module):\n#     def __init__(self,model_name):\n#         super().__init__()\n\n#         self.model = AutoModel.from_pretrained(model_name)\n        \n#         self.linear = nn.Linear(768, 1)\n\n#     def forward(self,  input_ids, attention_mask):\n#         outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n#         output = torch.sum(self.linear(outputs[0]),dim=1).squeeze()\n#         return output","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.472054Z","iopub.execute_input":"2022-05-20T08:26:22.472451Z","iopub.status.idle":"2022-05-20T08:26:22.479428Z","shell.execute_reply.started":"2022-05-20T08:26:22.472411Z","shell.execute_reply":"2022-05-20T08:26:22.478506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return \"%dm %ds\" % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.482487Z","iopub.execute_input":"2022-05-20T08:26:22.483004Z","iopub.status.idle":"2022-05-20T08:26:22.490827Z","shell.execute_reply.started":"2022-05-20T08:26:22.482974Z","shell.execute_reply":"2022-05-20T08:26:22.489949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Function","metadata":{}},{"cell_type":"code","source":"def train_fn(train_loader, model, loss_fn, optimizer, epoch, device):\n    start = end = time.time()\n    losses = 0\n\n    # switch to train mode\n    model.train()\n\n    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        y_preds = model(input_ids, attention_mask)\n\n        loss = loss_fn(y_preds, labels)\n\n        # record loss\n        losses += loss.item()\n        loss.backward()\n\n        optimizer.step()\n\n        if step % 100 == 0 or step == (len(train_loader) - 1):\n            print(\n                f\"Epoch: [{epoch}][{step}/{len(train_loader)}] \"\n                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n                f\"Loss: {losses/(step+1):.4f} \"\n            )\n\n    return losses/(step+1)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.492874Z","iopub.execute_input":"2022-05-20T08:26:22.493555Z","iopub.status.idle":"2022-05-20T08:26:22.504424Z","shell.execute_reply.started":"2022-05-20T08:26:22.493481Z","shell.execute_reply":"2022-05-20T08:26:22.503588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, loss_fn, device):\n    start = end = time.time()\n    losses = 0\n\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n\n    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(input_ids, attention_mask)\n\n        loss = loss_fn(y_preds, labels)\n        losses += loss.item()\n\n        # record score\n        preds.append(y_preds.sigmoid().to(\"cpu\").numpy())\n\n        if step % 100 == 0 or step == (len(valid_loader) - 1):\n            print(\n                f\"EVAL: [{step}/{len(valid_loader)}] \"\n                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n                f\"Loss: {losses/(step+1):.4f} \"\n            )\n\n    predictions = np.concatenate(preds)\n    return losses/(step+1), predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.507514Z","iopub.execute_input":"2022-05-20T08:26:22.507825Z","iopub.status.idle":"2022-05-20T08:26:22.518061Z","shell.execute_reply.started":"2022-05-20T08:26:22.507788Z","shell.execute_reply":"2022-05-20T08:26:22.51723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = scipy.stats.pearsonr(y_true, y_pred)[0]\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.519382Z","iopub.execute_input":"2022-05-20T08:26:22.519845Z","iopub.status.idle":"2022-05-20T08:26:22.529575Z","shell.execute_reply.started":"2022-05-20T08:26:22.519795Z","shell.execute_reply":"2022-05-20T08:26:22.528658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(train, fold):\n\n    print(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # Data Loader\n    # ====================================================\n    trn_idx = train[train[\"fold\"] != fold].index\n    val_idx = train[train[\"fold\"] == fold].index\n\n    train_folds = train.loc[trn_idx].reset_index(drop=True)\n    valid_folds = train.loc[val_idx].reset_index(drop=True)\n\n    train_dataset = USPPPMDataset(train_folds, config[\"model_dir\"])\n    valid_dataset = USPPPMDataset(valid_folds, config[\"model_dir\"])\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config[\"batch_size\"],\n        shuffle=True,\n        num_workers=4,\n        pin_memory=True,\n        drop_last=True,\n    )\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=config[\"batch_size\"],\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n    # ====================================================\n    # Model\n    # ====================================================\n    model = USPPPMModel(config[\"model_dir\"])\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=config[\"lr\"])\n    \n    train_steps = int(len(train_folds)/config[\"batch_size\"]*config[\"epochs\"])\n    num_steps = int(train_steps*0.1)\n\n    loss_fn = nn.MSELoss()\n\n    # ====================================================\n    # Loop\n    # ====================================================\n    best_score = -1\n    best_loss = np.inf\n    \n    for epoch in range(config[\"epochs\"]):\n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(train_loader, model, loss_fn, optimizer, epoch, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, loss_fn, device)\n        valid_labels = valid_folds[\"score\"].values\n\n        # scoring\n        score =  get_score(valid_labels, preds)\n        \n        elapsed = time.time() - start_time\n        print(f\"Epoch {epoch} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n        print(f\"Epoch {epoch} - Score: {score}\")\n\n        if score > best_score:\n            best_score = score\n            print(f\"Epoch {epoch} - Save Best Score: {best_score:.4f} \")\n            torch.save(\n                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"model{fold}/model{fold}.pth\"\n            )\n\n    check_point = torch.load(OUTPUT_DIR + f\"model{fold}/model{fold}.pth\")\n\n    valid_folds[\"preds\"] = check_point[\"preds\"]\n\n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.531099Z","iopub.execute_input":"2022-05-20T08:26:22.531579Z","iopub.status.idle":"2022-05-20T08:26:22.547826Z","shell.execute_reply.started":"2022-05-20T08:26:22.531541Z","shell.execute_reply":"2022-05-20T08:26:22.546948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_result(result_df):\n    preds = result_df[\"preds\"].values\n    labels = result_df[\"score\"].values\n    score = get_score(labels, preds)\n    print(f\"Score: {score:<.5f}\")\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.549354Z","iopub.execute_input":"2022-05-20T08:26:22.549867Z","iopub.status.idle":"2022-05-20T08:26:22.558513Z","shell.execute_reply.started":"2022-05-20T08:26:22.549828Z","shell.execute_reply":"2022-05-20T08:26:22.55766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Training\noof_df = pd.DataFrame()\nscores = []\nfor fold in range(config[\"nfolds\"]):\n    _oof_df = train_loop(train, fold)\n    print(f\"========== fold: {fold} result ==========\")\n    score = get_result(_oof_df)\n    scores.append(score)\n    \n# CV result\nprint(f\"CV: {np.mean(scores)}\")\n\n# # Save OOF result\n# oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:26:22.560355Z","iopub.execute_input":"2022-05-20T08:26:22.560637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}