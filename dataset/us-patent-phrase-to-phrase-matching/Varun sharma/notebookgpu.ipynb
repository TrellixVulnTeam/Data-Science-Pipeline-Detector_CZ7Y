{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstract\n\nTrain and prototype your models quickly by using GPUs. This notebook shows easy and quick way to train ðŸ¤—Transformers on GPUs.\n\n**This notebook is trained on folds 4 and 5**\n\n","metadata":{}},{"cell_type":"markdown","source":"# Versions\n[Inference Notebook]()\n\n* Version 3: DeBertaV3 Base on GPUs **CV:- 0. LB:- 0.**\n","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip uninstall transformers -y\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:45:39.223471Z","iopub.execute_input":"2022-06-13T13:45:39.224093Z","iopub.status.idle":"2022-06-13T13:45:57.590062Z","shell.execute_reply.started":"2022-06-13T13:45:39.224003Z","shell.execute_reply":"2022-06-13T13:45:57.589064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport numpy as np \nimport pandas as pd \n\nfrom scipy.stats import pearsonr\n\nfrom transformers import TFAutoModel, AutoTokenizer,AutoModel\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy \nfrom tensorflow.keras.activations import tanh, softmax\nfrom tensorflow.keras.layers import Layer,Input, Dense, Flatten, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, save_model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau , EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, SGD\n\nimport os\nif not os.path.exists(\"./result\"):\n    os.makedirs(\"./result\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:45:57.592144Z","iopub.execute_input":"2022-06-13T13:45:57.59253Z","iopub.status.idle":"2022-06-13T13:46:04.91475Z","shell.execute_reply.started":"2022-06-13T13:45:57.592473Z","shell.execute_reply":"2022-06-13T13:46:04.913929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\ntransformers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:05.58747Z","iopub.execute_input":"2022-06-13T13:46:05.588451Z","iopub.status.idle":"2022-06-13T13:46:05.594849Z","shell.execute_reply.started":"2022-06-13T13:46:05.588402Z","shell.execute_reply":"2022-06-13T13:46:05.594165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class config:\n    # dataset path\n    train_dataset_path = \"../input/ppmpcleaned/train.csv\"\n    test_dataset_path = \"../input/ppmpcleaned/test.csv\"\n    sample_submission_path = \"../input/ppmpcleaned/sample_submission.csv\"\n    cpc_path = \"../input/ppmpcleaned/titles.csv\"\n    \n   \n\n    save_dir=\"./result\"\n    \n    AUTOTUNE = tf.data.AUTOTUNE\n    \n    #tokenizer params\n    truncation = True \n    padding = 'max_length'\n    max_length = 75\n    \n    # model params\n    model_name = \"microsoft/deberta-v3-base\"\n    \n    #training params\n    learning_rate = 1e-5\n    batch_size = 16\n    epochs = 15","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:08.547209Z","iopub.execute_input":"2022-06-13T13:46:08.547599Z","iopub.status.idle":"2022-06-13T13:46:08.553276Z","shell.execute_reply.started":"2022-06-13T13:46:08.547566Z","shell.execute_reply":"2022-06-13T13:46:08.552356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(config.train_dataset_path)\ndf_test = pd.read_csv(config.test_dataset_path)\ndf_ss = pd.read_csv(config.sample_submission_path)\ndf_cpc = pd.read_csv(config.cpc_path)\n\ndf_train.drop(['context','anchor_length','target_length'] , axis = \"columns\" , inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:10.395264Z","iopub.execute_input":"2022-06-13T13:46:10.396155Z","iopub.status.idle":"2022-06-13T13:46:11.244942Z","shell.execute_reply.started":"2022-06-13T13:46:10.396108Z","shell.execute_reply":"2022-06-13T13:46:11.244106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {}\n\nfor i,j in zip(df_cpc['code'],df_cpc['title']):\n    context_mapping[i] = j\n    \ndf_test['context_text'] = df_test['context'].map(context_mapping)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:11.246559Z","iopub.execute_input":"2022-06-13T13:46:11.246911Z","iopub.status.idle":"2022-06-13T13:46:11.473877Z","shell.execute_reply.started":"2022-06-13T13:46:11.246876Z","shell.execute_reply":"2022-06-13T13:46:11.47302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['text'] = df_train['anchor'] + \" \" + \"[SEP]\" + \" \" + df_train['target'] + \" \" + \"[SEP]\" + \" \" + df_train['context_text']\ndf_test['text'] = df_test['anchor'] + \" \" + \"[SEP]\" + \" \" + df_test['target'] + \" \" + \"[SEP]\" + \" \" + df_test['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:11.487573Z","iopub.execute_input":"2022-06-13T13:46:11.488183Z","iopub.status.idle":"2022-06-13T13:46:11.533263Z","shell.execute_reply.started":"2022-06-13T13:46:11.488151Z","shell.execute_reply":"2022-06-13T13:46:11.532532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:12.726922Z","iopub.execute_input":"2022-06-13T13:46:12.727743Z","iopub.status.idle":"2022-06-13T13:46:12.752263Z","shell.execute_reply.started":"2022-06-13T13:46:12.727706Z","shell.execute_reply":"2022-06-13T13:46:12.751146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['kfold']","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:13.293777Z","iopub.execute_input":"2022-06-13T13:46:13.294129Z","iopub.status.idle":"2022-06-13T13:46:13.302053Z","shell.execute_reply.started":"2022-06-13T13:46:13.2941Z","shell.execute_reply":"2022-06-13T13:46:13.301112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name)\ntokenizer.save_pretrained(\"./result/tokenizer/\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:17.118989Z","iopub.execute_input":"2022-06-13T13:46:17.119621Z","iopub.status.idle":"2022-06-13T13:46:24.271486Z","shell.execute_reply.started":"2022-06-13T13:46:17.119583Z","shell.execute_reply":"2022-06-13T13:46:24.270572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"transformer = TFAutoModel.from_pretrained(config.model_name)\ntransformer.save_pretrained('./result/hf_model/')\ndel transformer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:24.273498Z","iopub.execute_input":"2022-06-13T13:46:24.273879Z","iopub.status.idle":"2022-06-13T13:46:54.814165Z","shell.execute_reply.started":"2022-06-13T13:46:24.273844Z","shell.execute_reply":"2022-06-13T13:46:54.813351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(Layer):\n    def __init__(self):\n        super(TransformerBlock , self).__init__()\n        self.transformer_model = TFAutoModel.from_pretrained(config.model_name)\n        self.dense = Dense(1, activation='relu')\n        \n    def call(self,input_tensors):\n        input_id = input_tensors[0]\n        attention_mask = input_tensors[1]\n        transformer_output = self.transformer_model(input_ids = input_id , attention_mask = attention_mask)\n        transformer_output = transformer_output.last_hidden_state\n        return transformer_output\n\nclass RegressionHead(Layer):\n    def __init__(self):\n        super(RegressionHead , self).__init__()\n        self.dense = Dense(1, activation=\"relu\")\n    \n    def call(self , input_tensors):\n        x = self.dense(input_tensors)\n        return x\n\nclass AttentionHead(Layer):\n    def __init__(self):\n        super(AttentionHead , self).__init__()\n        self.dense1 = Dense(512)\n        self.tanh =  tanh\n        self.softmax = softmax\n        self.dense2 = Dense(1,activation=\"softmax\")\n    \n    def call(self , input_tensors):\n        x = self.dense1(input_tensors)\n        x = self.tanh(x)\n        x = self.dense2(x)\n        x = self.softmax(x , axis = 1)\n        return x  \n    \nclass PPPMModel(Model):\n    def __init__(self):\n        super(PPPMModel, self).__init__()\n        self.transformer_model = TransformerBlock()\n        self.attentionhead = AttentionHead()\n        self.regressionhead = RegressionHead()\n    \n    def call(self,input_tensors):\n        transformer_output = self.transformer_model(input_tensors)\n        weights = self.attentionhead(transformer_output)\n        context_vector = tf.reduce_sum(weights * transformer_output, axis=1)\n        x = self.regressionhead(context_vector)\n        return x\n    \n    def model(self):\n        input_id = Input(shape = (config.max_length) , dtype = tf.int32, name = 'input_ids')\n        attention_mask = Input(shape = (config.max_length), dtype = tf.int32, name = 'attention_mask')\n        \n        return Model(inputs = [input_id , attention_mask] , outputs = self.call([input_id , attention_mask]))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:54.815489Z","iopub.execute_input":"2022-06-13T13:46:54.81588Z","iopub.status.idle":"2022-06-13T13:46:54.832572Z","shell.execute_reply.started":"2022-06-13T13:46:54.815844Z","shell.execute_reply":"2022-06-13T13:46:54.831321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Prep Function","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef map_function(encodings , target):\n    input_ids = encodings['input_ids']\n    attention_mask = encodings['attention_mask']\n    \n    target = tf.cast(target, tf.float32 )\n    \n    return {'input_ids': input_ids , 'attention_mask': attention_mask}, target","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:54.834799Z","iopub.execute_input":"2022-06-13T13:46:54.835225Z","iopub.status.idle":"2022-06-13T13:46:54.8481Z","shell.execute_reply.started":"2022-06-13T13:46:54.835185Z","shell.execute_reply":"2022-06-13T13:46:54.846827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competition Metrics\nGrabbed this snippet from [here](https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu#Competition-Metrics)","metadata":{}},{"cell_type":"code","source":"class Pearsonr(tf.keras.callbacks.Callback):\n    def __init__(self, model , val_data, y_val):\n        self.val_data = val_data\n        self.y_val = y_val\n        self.model = model\n        \n    def on_epoch_end(self, epoch, logs):\n        val_preds = self.model.predict(self.val_data, verbose=1)\n        val_pearsonr = pearsonr(self.y_val, val_preds.ravel())[0]\n\n        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n        logs[\"val_pearsonr\"] = val_pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:54.850209Z","iopub.execute_input":"2022-06-13T13:46:54.850669Z","iopub.status.idle":"2022-06-13T13:46:54.858546Z","shell.execute_reply.started":"2022-06-13T13:46:54.850625Z","shell.execute_reply":"2022-06-13T13:46:54.85744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KFold Training","metadata":{}},{"cell_type":"code","source":"histories = []\nscores = []\nfor fold in range(4,6):\n    print(f\"====== FOLD RUNNING {fold}======\")\n    \n    X_train = df_train.loc[df_train['kfold'] != fold]['text']\n    y_train = df_train.loc[df_train['kfold'] != fold]['score']\n    \n    X_test = df_train.loc[df_train['kfold'] == fold]['text']\n    y_test = df_train.loc[df_train['kfold'] == fold]['score']\n    \n    print(\"Generating Tokens\")\n    train_embeddings = tokenizer(\n        X_train.tolist(),\n        truncation = config.truncation, \n        padding = config.padding,\n        max_length =config.max_length   \n    )\n    \n    validation_embeddings = tokenizer(\n        X_test.tolist(),\n        truncation = config.truncation, \n        padding = config.padding,\n        max_length =config.max_length   \n    )\n    \n    print(\"Generating Datasets\")\n    \n    train = tf.data.Dataset.from_tensor_slices((train_embeddings , y_train))\n    train = (\n                train\n                .map(map_function, num_parallel_calls= config.AUTOTUNE)\n                .batch(config.batch_size)\n                .prefetch(config.AUTOTUNE)\n            )\n    \n    val = tf.data.Dataset.from_tensor_slices((validation_embeddings , y_test))\n    val = (\n                val\n                .map(map_function, num_parallel_calls= config.AUTOTUNE)\n                .batch(config.batch_size)\n                .prefetch(config.AUTOTUNE)\n            )\n    \n    #Clearing backend session\n    K.clear_session()\n    print(\"Backend Cleared\")\n\n    print(\"Model Creation\")\n    model = PPPMModel().model()\n    model.compile(\n          optimizer = Adam(learning_rate = config.learning_rate), \n          metrics = ['mae'],\n          loss = ['mae']\n      )    \n    early_stopping=EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=3, verbose=1,mode=\"min\",restore_best_weights=True)\n    pearson_corr = Pearsonr(model,val, y_test)\n    \n    hist = model.fit(train , validation_data = val,steps_per_epoch = 1, validation_steps = 1 , epochs = config.epochs,callbacks = [early_stopping,pearson_corr])\n    \n    # prediction on val\n    print(\"prediction on validation data\")\n    preds = model.predict(val , verbose = 1)\n    score = pearsonr(preds.reshape(preds.shape[0],), y_test)[0]    \n    scores.append(score)\n    \n    print(\"saving model\")\n    save_model(model,f'{config.save_dir}/{config.model_name}_{fold}.h5')\n        \n    del model,X_train, y_train, X_test,y_test,train, val\n    gc.collect()\n\n    histories.append(hist)\n\nprint(\"the final average rmse is \", np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:46:54.860218Z","iopub.execute_input":"2022-06-13T13:46:54.860797Z","iopub.status.idle":"2022-06-13T14:00:07.281106Z","shell.execute_reply.started":"2022-06-13T13:46:54.860755Z","shell.execute_reply":"2022-06-13T14:00:07.280256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThanks for viewing, drop your suggestions down in the comments below. ðŸ™‚","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}