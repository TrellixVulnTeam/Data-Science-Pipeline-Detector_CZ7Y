{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Analysis and using models from three notebooks\n\n**1.** Deberta v3 large (0.8392)\n> [Inference BERT for usPatents](https://www.kaggle.com/code/leehann/inference-bert-for-uspatents)\n\n**2.** Deberta v3 large (0.8338)\n> [PPPM / Deberta-v3-large baseline [inference]](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n\n**3.** Roberta-large (0.8143)\n> [PatentPhrase RoBERTa Inference](https://www.kaggle.com/code/santhoshkumarv/patentphrase-roberta-inference-lb-0-814)\n\n#### Please upvote the original notebooks!\n\n## UPD: I have an error in my code (Version 1)!\n\nMethod merge in model 1 shuffled the dataframe.\n\n```\ntest = test.merge(titles, left_on='context', right_on='code')\n```\n\nSo I reseted index, merged, sorted and drop index.\n\n```\ntest.reset_index(inplace=True)\ntest = test.merge(titles, left_on='context', right_on='code')\ntest.sort_values(by='index', inplace=True)\ntest.drop(columns='index', inplace=True)\n```","metadata":{}},{"cell_type":"markdown","source":"# 1. Import & Def & Set & Load","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom dataclasses import dataclass\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-20T18:53:33.817085Z","iopub.execute_input":"2022-06-20T18:53:33.817532Z","iopub.status.idle":"2022-06-20T18:53:40.642181Z","shell.execute_reply.started":"2022-06-20T18:53:33.817415Z","shell.execute_reply":"2022-06-20T18:53:40.641387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True    \n    torch.backends.cudnn.benchmark = False\n\n    \ndef inference_fn(test_loader, model, device, is_sigmoid=True):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    \n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n            \n        with torch.no_grad():\n            output = model(inputs)\n        \n        if is_sigmoid == True:\n            preds.append(output.sigmoid().to('cpu').numpy())\n        else:\n            preds.append(output.to('cpu').numpy())\n\n    return np.concatenate(preds)    \n    \n\ndef upd_outputs(data, is_trim=False, is_minmax=False, is_reshape=False):\n    min_max_scaler = MinMaxScaler()\n    \n    if is_trim == True:\n        data = np.where(data <=0, 0, data)\n        data = np.where(data >=1, 1, data)\n\n    if is_minmax ==True:\n        data = min_max_scaler.fit_transform(data)\n    \n    if is_reshape == True:\n        data = data.reshape(-1)\n        \n    return data\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-20T18:53:40.644256Z","iopub.execute_input":"2022-06-20T18:53:40.644537Z","iopub.status.idle":"2022-06-20T18:53:40.657933Z","shell.execute_reply.started":"2022-06-20T18:53:40.644501Z","shell.execute_reply":"2022-06-20T18:53:40.65712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.precision', 4)\ncm = sns.light_palette('green', as_cmap=True)\nprops_param = \"color:white; font-weight:bold; background-color:green;\"\n\nCUSTOM_SEED = 42\nCUSTOM_BATCH = 24\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:53:40.661528Z","iopub.execute_input":"2022-06-20T18:53:40.6618Z","iopub.status.idle":"2022-06-20T18:53:40.742451Z","shell.execute_reply.started":"2022-06-20T18:53:40.661771Z","shell.execute_reply":"2022-06-20T18:53:40.7415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"competition_dir = \"../input/us-patent-phrase-to-phrase-matching/\"\n\nsubmission = pd.read_csv(competition_dir+'sample_submission.csv')\ntest_origin = pd.read_csv(competition_dir+'test.csv')\ntest_origin.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:13:28.105644Z","iopub.execute_input":"2022-06-20T19:13:28.105944Z","iopub.status.idle":"2022-06-20T19:13:28.130777Z","shell.execute_reply.started":"2022-06-20T19:13:28.105911Z","shell.execute_reply":"2022-06-20T19:13:28.130087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Extract predictions\n\n## 2.1 Deberta v3 large - 1","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           truncation=True)\n    \n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg        \n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.text[item])\n        \n        return inputs\n   \n    \nclass CustomModel(nn.Module):\n    def __init__(self, model_path):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_path)\n        config.num_labels = 1\n        self.base = AutoModelForSequenceClassification.from_config(config=config)\n        dim = config.hidden_size\n        self.dropout = nn.Dropout(p=0)\n        self.cls = nn.Linear(dim,1)\n        \n    def forward(self, inputs):\n        output = self.base(**inputs)\n\n        return output[0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-20T19:16:38.183751Z","iopub.execute_input":"2022-06-20T19:16:38.184804Z","iopub.status.idle":"2022-06-20T19:16:38.197628Z","shell.execute_reply.started":"2022-06-20T19:16:38.184752Z","shell.execute_reply":"2022-06-20T19:16:38.19667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CUSTOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:53:40.800137Z","iopub.execute_input":"2022-06-20T18:53:40.800336Z","iopub.status.idle":"2022-06-20T18:53:40.814599Z","shell.execute_reply.started":"2022-06-20T18:53:40.800311Z","shell.execute_reply":"2022-06-20T18:53:40.813757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_path='../input/deberta-v3-large/deberta-v3-large'\n    batch_size=CUSTOM_BATCH\n    num_workers=2\n    max_len=130\n    trn_fold=[0, 1, 2, 3]\n\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\n\ncontext_mapping = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:53:40.816322Z","iopub.execute_input":"2022-06-20T18:53:40.816695Z","iopub.status.idle":"2022-06-20T18:53:41.579493Z","shell.execute_reply.started":"2022-06-20T18:53:40.816644Z","shell.execute_reply":"2022-06-20T18:53:41.578722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_origin.copy()\ntitles = pd.read_csv('../input/cpc-codes/titles.csv')\n\ntest.reset_index(inplace=True)\ntest = test.merge(titles, left_on='context', right_on='code')\ntest.sort_values(by='index', inplace=True)\ntest.drop(columns='index', inplace=True)\n\ntest['context_text'] = test['context'].map(context_mapping)\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ntest['text'] = test['text'].apply(str.lower)\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:53:41.580915Z","iopub.execute_input":"2022-06-20T18:53:41.581649Z","iopub.status.idle":"2022-06-20T18:53:42.430719Z","shell.execute_reply.started":"2022-06-20T18:53:41.581605Z","shell.execute_reply":"2022-06-20T18:53:42.429934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_predicts_1 = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_dataloader = DataLoader(test_dataset,\n                             batch_size=CFG.batch_size, shuffle=False,\n                             num_workers=CFG.num_workers,\n                             pin_memory=True, drop_last=False)\n\ndeberta_simple_path = \"../input/us-patent-deberta-simple/microsoft_deberta-v3-large\"\n\nfor fold in CFG.trn_fold:\n    fold_path = f\"{deberta_simple_path}_best{fold}.pth\"\n    \n    model = CustomModel(CFG.model_path)    \n    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n    model.load_state_dict(state['model'])\n    \n    prediction = inference_fn(test_dataloader, model, DEVICE, is_sigmoid=False)\n    \n    deberta_predicts_1.append(prediction)\n    \n    del model, state, prediction\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:53:42.432243Z","iopub.execute_input":"2022-06-20T18:53:42.432554Z","iopub.status.idle":"2022-06-20T18:55:43.519096Z","shell.execute_reply.started":"2022-06-20T18:53:42.432506Z","shell.execute_reply":"2022-06-20T18:55:43.518088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -------------- inference_fn([...], is_sigmoid=False)\ndeberta_predicts_1 = [upd_outputs(x, is_minmax=True, is_reshape=True) for x in deberta_predicts_1]\ndeberta_predicts_1 = pd.DataFrame(deberta_predicts_1).T\n\ndeberta_predicts_1.head(10).style.background_gradient(cmap=cm, axis=1)\ndel test, test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:55:43.521036Z","iopub.execute_input":"2022-06-20T18:55:43.521371Z","iopub.status.idle":"2022-06-20T18:55:43.778822Z","shell.execute_reply.started":"2022-06-20T18:55:43.521325Z","shell.execute_reply":"2022-06-20T18:55:43.77805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Deberta v3 large - 2","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    \n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n\n    \nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n            \n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        \n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        \n        return output","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-20T18:55:43.780282Z","iopub.execute_input":"2022-06-20T18:55:43.780697Z","iopub.status.idle":"2022-06-20T18:55:43.797913Z","shell.execute_reply.started":"2022-06-20T18:55:43.780657Z","shell.execute_reply":"2022-06-20T18:55:43.797116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CUSTOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:55:43.799226Z","iopub.execute_input":"2022-06-20T18:55:43.799604Z","iopub.status.idle":"2022-06-20T18:55:43.810745Z","shell.execute_reply.started":"2022-06-20T18:55:43.799565Z","shell.execute_reply":"2022-06-20T18:55:43.809948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_workers=2\n    path=\"../input/pppm-deberta-v3-large-baseline-w-w-b-train/\"\n    files = [\n        '../input/fgmmodel/fgm_12epoch_5fold_microsoft-deberta-v3-large_fold0_best.pth',\n        '../input/fgmmodel/fgm_12epoch_5fold_microsoft-deberta-v3-large_fold1_best.pth',\n        '../input/fgmmodel/fgm_12epoch_5fold_microsoft-deberta-v3-large_fold2_best.pth',\n        '../input/fgmmodel/fgm_12epoch_5fold_microsoft-deberta-v3-large_fold3_best.pth',\n        '../input/fgmmodel/fgm_12epoch_5fold_microsoft-deberta-v3-large_fold4_best.pth',\n        '../input/fgm1995/fgm_1995_microsoft-deberta-v3-large_fold0_best.pth',\n        '../input/fgm1995/fgm_1995_microsoft-deberta-v3-large_fold1_best.pth',\n        '../input/fgm1995/fgm_1995_microsoft-deberta-v3-large_fold2_best.pth',\n        '../input/fgm1995/fgm_1995_microsoft-deberta-v3-large_fold3_best.pth',\n        '../input/fgm1995/fgm_1995_microsoft-deberta-v3-large_fold4_best.pth',\n    ]\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=CUSTOM_BATCH\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    trn_fold=[0, 1, 2, 3]\n    \nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\ncontext_mapping = torch.load(CFG.path+\"cpc_texts.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:55:43.812189Z","iopub.execute_input":"2022-06-20T18:55:43.812494Z","iopub.status.idle":"2022-06-20T18:55:44.55087Z","shell.execute_reply.started":"2022-06-20T18:55:43.812455Z","shell.execute_reply":"2022-06-20T18:55:44.550073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_origin.copy()\n\ntest['context_text'] = test['context'].map(context_mapping)\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:55:44.554848Z","iopub.execute_input":"2022-06-20T18:55:44.55512Z","iopub.status.idle":"2022-06-20T18:55:44.57774Z","shell.execute_reply.started":"2022-06-20T18:55:44.555084Z","shell.execute_reply":"2022-06-20T18:55:44.57704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_predicts_2 = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers,\n                         pin_memory=True, drop_last=False)\n\nfolds_path = CFG.path + f\"{CFG.model.replace('/', '-')}\"\n\nfor file in CFG.files:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(file, map_location=torch.device('cpu'))  # DEVICE\n    model.load_state_dict(state['model'])\n    \n    prediction = inference_fn(test_loader, model, DEVICE)\n    deberta_predicts_2.append(prediction)\n    \n    del model, state, prediction\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:55:44.579384Z","iopub.execute_input":"2022-06-20T18:55:44.579639Z","iopub.status.idle":"2022-06-20T18:59:49.808938Z","shell.execute_reply.started":"2022-06-20T18:55:44.579604Z","shell.execute_reply":"2022-06-20T18:59:49.807997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_predicts_2 = [upd_outputs(x, is_reshape=True) for x in deberta_predicts_2]\ndeberta_predicts_2 = pd.DataFrame(deberta_predicts_2).T\n\ndeberta_predicts_2.head(10).style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:59:49.81067Z","iopub.execute_input":"2022-06-20T18:59:49.810967Z","iopub.status.idle":"2022-06-20T18:59:49.851419Z","shell.execute_reply.started":"2022-06-20T18:59:49.810925Z","shell.execute_reply":"2022-06-20T18:59:49.850476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test, test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:59:49.853015Z","iopub.execute_input":"2022-06-20T18:59:49.853411Z","iopub.status.idle":"2022-06-20T18:59:50.050019Z","shell.execute_reply.started":"2022-06-20T18:59:49.853366Z","shell.execute_reply":"2022-06-20T18:59:50.049006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3. Roberta-large","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text, target):\n    inputs = cfg.tokenizer(text, target,\n                           padding=\"max_length\",\n                           max_length=cfg.max_len,\n                           truncation=True)\n\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n        self.target = df['target'].values\n        \n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = self.texts[item]\n        target = self.target[item]\n        \n        inputs = prepare_input(self.cfg, text, target)\n        \n        return inputs\n\n    \nclass CustomModel(nn.Module):\n    def __init__(self):\n        super(CustomModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.config_path)\n\n        config.update({\"output_hidden_states\": True,\n                       \"hidden_dropout_prob\": hidden_dropout_prob,\n                       \"layer_norm_eps\": layer_norm_eps,\n                       \"add_pooling_layer\": False})\n        \n        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, inputs):\n        transformer_out = self.transformer(**inputs)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        \n        return logits","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-20T18:59:50.05176Z","iopub.execute_input":"2022-06-20T18:59:50.052537Z","iopub.status.idle":"2022-06-20T18:59:50.069023Z","shell.execute_reply.started":"2022-06-20T18:59:50.052494Z","shell.execute_reply":"2022-06-20T18:59:50.068241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CUSTOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:59:50.070417Z","iopub.execute_input":"2022-06-20T18:59:50.070798Z","iopub.status.idle":"2022-06-20T18:59:50.082403Z","shell.execute_reply.started":"2022-06-20T18:59:50.070749Z","shell.execute_reply":"2022-06-20T18:59:50.08153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers=2\n    config_path='../input/robertalarge'\n    model_path='../input/phrase-matching-roberta-training-pytorch-wandb'\n    model_name='roberta-large'\n    batch_size=CUSTOM_BATCH\n    max_len=128\n    num_targets=1\n    trn_fold=[0, 1, 2, 3, 4]\n    tokenizer=AutoTokenizer.from_pretrained('../input/robertalarge')\n\ncontext_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:59:50.084016Z","iopub.execute_input":"2022-06-20T18:59:50.084342Z","iopub.status.idle":"2022-06-20T18:59:50.349256Z","shell.execute_reply.started":"2022-06-20T18:59:50.084298Z","shell.execute_reply":"2022-06-20T18:59:50.348386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_origin.copy()\n\ntest['context_text'] = test['context'].str.slice(stop=1).map(context_mapping)\ntest['text'] = test['context_text'] + ' ' + test['anchor']","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:59:50.35057Z","iopub.execute_input":"2022-06-20T18:59:50.350856Z","iopub.status.idle":"2022-06-20T18:59:50.36269Z","shell.execute_reply.started":"2022-06-20T18:59:50.350807Z","shell.execute_reply":"2022-06-20T18:59:50.361938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T18:59:50.364192Z","iopub.execute_input":"2022-06-20T18:59:50.364892Z","iopub.status.idle":"2022-06-20T18:59:50.382999Z","shell.execute_reply.started":"2022-06-20T18:59:50.364845Z","shell.execute_reply":"2022-06-20T18:59:50.382221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_predicts = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers,\n                         pin_memory=True, drop_last=False)\n\nfolds_path = CFG.model_path + f\"/{CFG.model_name.replace('-','_')}\"\n\nfor fold in CFG.trn_fold:\n    fold_path = f\"{folds_path}_patent_model_{fold}.pth\"\n    \n    model = CustomModel()\n    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n    model.load_state_dict(state)\n\n    prediction = inference_fn(test_loader, model, DEVICE)\n    roberta_predicts.append(prediction)\n    \n    del model, state, prediction\n    torch.cuda.empty_cache()    \n    gc.collect()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-20T18:59:50.386658Z","iopub.execute_input":"2022-06-20T18:59:50.386886Z","iopub.status.idle":"2022-06-20T19:01:36.475468Z","shell.execute_reply.started":"2022-06-20T18:59:50.38686Z","shell.execute_reply":"2022-06-20T19:01:36.474457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_predicts = [upd_outputs(x, is_reshape=True) for x in roberta_predicts]\nroberta_predicts = pd.DataFrame(roberta_predicts).T\n\nroberta_predicts.head(10).style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:36.476982Z","iopub.execute_input":"2022-06-20T19:01:36.477498Z","iopub.status.idle":"2022-06-20T19:01:36.510451Z","shell.execute_reply.started":"2022-06-20T19:01:36.477446Z","shell.execute_reply":"2022-06-20T19:01:36.50949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test, test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:36.51193Z","iopub.execute_input":"2022-06-20T19:01:36.512307Z","iopub.status.idle":"2022-06-20T19:01:36.70832Z","shell.execute_reply.started":"2022-06-20T19:01:36.512263Z","shell.execute_reply":"2022-06-20T19:01:36.70725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Comparison / Ensemble","metadata":{}},{"cell_type":"code","source":"all_predictions = pd.concat(\n    [deberta_predicts_1, deberta_predicts_2, roberta_predicts],\n    keys=['deberta 1', 'deberta 2', 'roberta'],\n    axis=1\n)\n\nall_predictions.head(10) \\\n    .assign(mean=lambda x: x.mean(axis=1)) \\\n        .style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:36.710262Z","iopub.execute_input":"2022-06-20T19:01:36.710556Z","iopub.status.idle":"2022-06-20T19:01:36.843136Z","shell.execute_reply.started":"2022-06-20T19:01:36.710518Z","shell.execute_reply":"2022-06-20T19:01:36.842332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_mean = pd.DataFrame({\n    'deberta 1': deberta_predicts_1.mean(axis=1),\n    'deberta 2': deberta_predicts_2.mean(axis=1),\n    'roberta': roberta_predicts.mean(axis=1)\n})\n\nall_mean.head(10) \\\n    .assign(mean=lambda x: x.mean(axis=1)) \\\n        .style.highlight_max(axis=1, props=props_param)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:36.84446Z","iopub.execute_input":"2022-06-20T19:01:36.846261Z","iopub.status.idle":"2022-06-20T19:01:36.870581Z","shell.execute_reply.started":"2022-06-20T19:01:36.846213Z","shell.execute_reply":"2022-06-20T19:01:36.869616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === N1 ===\nweights_ = [0.4, 0.4, 0.2]\nfinal_predictions = all_mean.mul(weights_).sum(axis=1)\n\nfinal_predictions.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:36.87185Z","iopub.execute_input":"2022-06-20T19:01:36.872434Z","iopub.status.idle":"2022-06-20T19:01:36.884792Z","shell.execute_reply.started":"2022-06-20T19:01:36.872387Z","shell.execute_reply":"2022-06-20T19:01:36.883684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Submission","metadata":{}},{"cell_type":"code","source":"\nsubmission = pd.DataFrame({\n    'id': test_origin['id'],\n    'score': final_predictions,\n})\n\nsubmission.head(14)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:57.041929Z","iopub.status.idle":"2022-06-20T19:01:57.042509Z","shell.execute_reply.started":"2022-06-20T19:01:57.042155Z","shell.execute_reply":"2022-06-20T19:01:57.04218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ===================  Baseline\n# 0  4112d61851461f60  0.56127\n# 1  09e418c93a776564  0.72176\n# 2  36baf228038e314b  0.47086\n# 3  1f37ead645e7f0c8  0.25826\n# 4  71a5b6ad068d531f  0.00908\n# 5  474c874d0c07bd21  0.48173","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:57.044537Z","iopub.status.idle":"2022-06-20T19:01:57.04528Z","shell.execute_reply.started":"2022-06-20T19:01:57.044955Z","shell.execute_reply":"2022-06-20T19:01:57.044982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:01:57.046904Z","iopub.status.idle":"2022-06-20T19:01:57.047446Z","shell.execute_reply.started":"2022-06-20T19:01:57.047174Z","shell.execute_reply":"2022-06-20T19:01:57.047199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}