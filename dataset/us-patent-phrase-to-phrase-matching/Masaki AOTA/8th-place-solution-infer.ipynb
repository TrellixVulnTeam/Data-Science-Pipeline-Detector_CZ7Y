{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Directory settings","metadata":{"papermill":{"duration":0.004874,"end_time":"2022-06-19T03:53:19.928168","exception":false,"start_time":"2022-06-19T03:53:19.923294","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"6つのexp ごった煮版\n\nハイパラチューン済み","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"id":"fa3b873b","papermill":{"duration":0.020211,"end_time":"2022-06-19T03:53:19.952206","exception":false,"start_time":"2022-06-19T03:53:19.931995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T14:41:33.560702Z","iopub.execute_input":"2022-06-20T14:41:33.561496Z","iopub.status.idle":"2022-06-20T14:41:33.566354Z","shell.execute_reply.started":"2022-06-20T14:41:33.561454Z","shell.execute_reply":"2022-06-20T14:41:33.565509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 tokenizers')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T14:41:33.567875Z","iopub.execute_input":"2022-06-20T14:41:33.568616Z","iopub.status.idle":"2022-06-20T14:41:59.063276Z","shell.execute_reply.started":"2022-06-20T14:41:33.568572Z","shell.execute_reply":"2022-06-20T14:41:59.062195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# exp100\n\ndef exp100():\n\n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        num_workers=0\n        path=\"../input/uspppm-exp100/\"\n        config_path=path+'config.pth'\n        model=\"google/electra-large-discriminator\"\n        ckpt_name=\"electra-large-discriminator\"\n        batch_size=16\n        target_size=1\n        max_len=404\n        seed=42\n        n_fold=4\n        tar_token_id = 30522\n        tar_token = '[TAR]'\n        trn_fold=[0, 1, 2, 3]\n        n_augs = 2\n    # Library\n    # ====================================================\n    # Library\n    # ====================================================\n    import os\n    import gc\n    import re\n    import ast\n    import sys\n    import copy\n    import json\n    import time\n    import math\n    import shutil\n    import string\n    import pickle\n    import random\n    import joblib\n    import itertools\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    from tqdm.auto import tqdm\n    from sklearn.metrics import f1_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    import torch\n    print(f\"torch.__version__: {torch.__version__}\")\n    import torch.nn as nn\n    from torch.nn import Parameter\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD, AdamW\n    from torch.utils.data import DataLoader, Dataset\n    from torch import inference_mode\n\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\n    from transformers import AutoTokenizer, AutoModel, AutoConfig\n    from transformers import DataCollatorWithPadding\n    from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n    %env TOKENIZERS_PARALLELISM=false #true\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Utils\n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        score = sp.stats.pearsonr(y_true, y_pred)[0]\n        return score\n\n\n    def get_logger(filename=OUTPUT_DIR+'train'):\n        from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = get_logger()\n\n    def seed_everything(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_everything(seed=42)\n    # OOF\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df['score'].values\n    preds = oof_df['pred'].values\n    score = get_score(labels, preds)\n    LOGGER.info(f'CV Score: {score:<.4f}')\n    # Data Loading\n    # ====================================================\n    # Data Loading\n    # ====================================================\n    # test = pd.read_csv(INPUT_DIR+'train.csv').sample(n=100)\n    test = pd.read_csv(INPUT_DIR+'test.csv')\n    submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n    print(f\"test.shape: {test.shape}\")\n    print(f\"submission.shape: {submission.shape}\")\n    display(test.head())\n    display(submission.head())\n    # ====================================================\n    # CPC Data\n    # ====================================================\n    cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n    test['context_text'] = test['context'].map(cpc_texts)\n    display(test.head())\n    anchor_context_grouped_target = test.groupby(['anchor', 'context'])['target'].apply(list)\n    anchor_context_grouped_id = test.groupby(['anchor', 'context'])['id'].apply(list)\n    i = pd.DataFrame(anchor_context_grouped_id).reset_index()\n    t = pd.DataFrame(anchor_context_grouped_target).reset_index()\n    test = t.merge(i, on=['anchor', 'context'])\n    test['context_text'] = test['context'].map(cpc_texts)\n    test = test.rename(columns={'target': 'targets', 'id': 'ids'})\n    test['n_ids'] = test['ids'].map(len)\n    test.head()\n    from functools import reduce\n\n    def cat_ids(x) -> str:\n        return reduce(lambda a,b: a+b, x)\n    import random \n\n    cat_ids_sets = set(test['ids'].map(cat_ids))\n    auged_test = test.copy()\n    auged_rows = []\n    for a in range(CFG.n_augs):\n        for _,r in test.iterrows():\n            if r.n_ids == 1:\n                continue\n            indices = list(range(r.n_ids))\n            random.shuffle(indices)\n            if cat_ids(list(np.array(r.ids)[indices])) in cat_ids_sets:\n                continue\n            auged_r = r.copy()\n            auged_r.targets = list(np.array(auged_r.targets)[indices])\n            auged_r.ids = list(np.array(auged_r.ids)[indices])\n            cat_ids_sets.add(cat_ids(auged_r.ids))\n            auged_rows.append(auged_r)\n    auged_test = test.append(\n        pd.DataFrame(auged_rows, columns=test.columns).reset_index(drop=True))\n    exploded_test = auged_test.explode(['targets', 'ids']).rename(columns={\n            'targets': 'target',\n            'ids': 'id',\n        }).reset_index(drop=True)\n    # tokenizer\n    # ====================================================\n    # tokenizer\n    # ====================================================\n    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n    assert CFG.tokenizer.encode(CFG.tar_token, add_special_tokens=False)[0] == CFG.tar_token_id\n    assert CFG.tokenizer.decode(CFG.tar_token_id) == CFG.tar_token\n\n    setattr(CFG.tokenizer, 'tar_token', CFG.tar_token)\n    setattr(CFG.tokenizer, 'tar_token_id', CFG.tar_token_id)\n    # Dataset\n    # ====================================================\n    # Dataset\n    # ====================================================\n\n    class TestDataset(Dataset):\n        def __init__(self, cfg, df):\n            self.cfg = cfg\n            self.anchors = df['anchor'].values\n            self.target_lists = df['targets'].values\n            self.id_lists = df['ids'].values\n            self.context_texts = df['context_text'].values\n            self.max_len = cfg.max_len\n            self.tokenizer = cfg.tokenizer\n\n        def __len__(self):\n            return len(self.id_lists)\n\n        def __getitem__(self, item):\n            target_mask = np.zeros(self.max_len)\n            targets = np.array(self.target_lists[item])\n\n            text = ''\n            text += self.tokenizer.cls_token\n            text += self.anchors[item]\n            text += self.tokenizer.sep_token\n            for target in targets:\n                text += target + self.tokenizer.tar_token\n            text += self.context_texts[item] + self.tokenizer.sep_token\n\n            encoded = self.tokenizer(\n                text,\n                max_length = self.max_len,\n                padding='max_length',\n                add_special_tokens=False,\n                truncation=True\n            )\n\n            cnt_tar = 0\n            cnt_sep = 0\n            nth_target = -1\n            prev_i = -1\n\n            for i, input_id in enumerate(encoded['input_ids']):\n                if input_id == self.tokenizer.tar_token_id:\n                    cnt_tar += 1\n                    if cnt_tar == len(targets):\n                        break\n                if input_id == self.tokenizer.sep_token_id:\n                    cnt_sep += 1\n\n                if cnt_sep == 1 and input_id not in [self.tokenizer.pad_token_id, self.tokenizer.sep_token_id, self.tokenizer.tar_token_id]:\n                    if (i-prev_i) > 1:\n                        nth_target += 1\n                    target_mask[i] = 1\n                    prev_i = i\n\n            for k,v in encoded.items():\n                encoded[k] = torch.tensor(v, dtype=torch.long)\n\n            return encoded, target_mask\n    # Model\n    # ====================================================\n    # Model\n    # ====================================================\n    class CustomModel(nn.Module):\n        def __init__(self, cfg, config_path=None, pretrained=False, n_vocabs=0):\n            super().__init__()\n            self.cfg = cfg\n            if config_path is None:\n                self.config = AutoConfig.from_pretrained(\n                    cfg.model, output_hidden_states=True)\n            else:\n                self.config = torch.load(config_path)\n            if pretrained:\n                self.model = AutoModel.from_pretrained(\n                    cfg.model, config=self.config)\n            else:\n                self.model = AutoModel.from_config(self.config)\n            self.model.resize_token_embeddings(n_vocabs)\n            self.fc = nn.Linear(self.config.hidden_size, 1)\n\n        def feature(self, inputs):\n            outputs = self.model(**inputs)\n            last_hidden_states = outputs[0]\n            return last_hidden_states\n\n        def forward(self, inputs):\n            feature = self.feature(inputs)\n            output = self.fc(feature).squeeze(-1)\n            return output\n    # inference\n    # ====================================================\n    # inference\n    # ====================================================\n    @inference_mode()\n    def inference_fn(test_loader, model, device):\n        preds = []\n        model.eval()\n        model.to(device)\n        for inputs, target_masks in test_loader:\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            y_preds = model(inputs)\n            y_preds = y_preds.sigmoid().to('cpu').numpy()\n\n            anchorwise_preds = []\n            for pred, target_mask, in zip(y_preds, target_masks):\n                prev_i = -1\n                targetwise_pred_scores = []\n                for i, (p, tm) in enumerate(zip(pred, target_mask)):\n                    if tm != 0:\n                        if i-1 == prev_i:\n                            targetwise_pred_scores[-1].append(p)\n                        else:\n                            targetwise_pred_scores.append([p])\n                        prev_i = i\n                for targetwise_pred_score in targetwise_pred_scores:\n                    anchorwise_preds.append(np.mean(targetwise_pred_score))\n            preds.append(anchorwise_preds)\n        return preds\n    # postprocess\n    import numpy as np\n    import pandas as pd\n\n    import re\n    import nltk\n    from nltk.stem import PorterStemmer\n    from nltk.stem import WordNetLemmatizer\n\n    class PostProcess:\n        def __init__(self, df, options={}):\n            self.options = {\n                'fit_near_score_th': 0.005,\n                'normalizer': ('lemmatizer') # 'stemmer'\n            }\n            self.options.update(options)\n            self.df = df.copy()\n            self.predictions = []\n\n        def add_predection(self, pred):\n            # shape => (36, 1)\n            self.predictions.append(pred.reshape(-1, 1))\n\n        def nanmean(self, preds):\n            return np.nanmean(preds, axis=0).reshape(-1)\n\n        def equal_score_1(self, preds):\n            \"\"\"\n            単純に anchor == target は score 1.0 にする\n            \"\"\"\n            df = self.df.copy()\n            df['preds'] = preds\n            df.loc[df.anchor == df.target, ['preds']] = 1.0\n            return df['preds'].values\n\n        def normalize_score_1(self, preds):\n            \"\"\"\n            normalizeした結果 == なら score を 1.0にする\n            \"\"\"\n            df = self.df.copy()\n            normalizer_options = self.options['normalizer']\n            lemmatizer = WordNetLemmatizer()\n            ps = PorterStemmer()\n            use_lemmatizer = 'lemmatizer' in normalizer_options\n            use_stemmer = 'stemmer' in normalizer_options\n            def normalize(word):\n                w = word.lower()\n                if use_lemmatizer:\n                    w = lemmatizer.lemmatize(w)\n                if use_stemmer:\n                    w = ps.stem(w)\n                return w\n            def normalize_words(word):\n                words = re.split(r'\\s+', word)\n                words = [normalize(t) for t in words]\n                return ' '.join(words)\n            an = df.anchor.map(normalize_words)\n            tn = df.target.map(normalize_words)\n            df['preds'] = preds\n            df.loc[an == tn, ['preds']] = 1.0\n            return df['preds'].values\n\n        def fit_near_score(self, preds):\n            fit_n = self.options['fit_near_score_th']\n            def fit_score(pred):\n                if pred <= fit_n:\n                    return 0.0\n                elif pred >= (0.25 - fit_n) and pred <= (0.25 + fit_n):\n                    return 0.25\n                elif pred >= (0.5 - fit_n) and pred <= (0.5 + fit_n):\n                    return 0.5\n                elif pred >= (0.75 - fit_n) and pred <= (0.75 + fit_n):\n                    return 0.75\n                elif pred >= (1 - fit_n):\n                    return 1.0\n                return pred\n            vect = np.vectorize(fit_score)\n            return vect(preds)\n\n        def get_score(self, apply_funcs=['nanmean', 'equal_score_1', 'normalize_score_1', 'fit_near_score']):\n            preds = self.predictions\n            for funcname in apply_funcs:\n                fn = getattr(self, funcname)\n                preds = fn(preds)\n            return preds.reshape(-1, 1) # 提出形式に合わせる\n\n\n    post_process = PostProcess(df=exploded_test)\n    # predictions\n    from functools import reduce\n\n    test_dataset = TestDataset(CFG, auged_test)\n    test_loader = DataLoader(test_dataset,\n                             batch_size=CFG.batch_size,\n                             shuffle=False,\n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    for fold in CFG.trn_fold:\n        model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False, n_vocabs=len(CFG.tokenizer))\n        state = torch.load(CFG.path+f\"{CFG.ckpt_name}_fold{fold}_best.pth\",\n                           map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        prediction = np.array(reduce(lambda a,b: a+b, prediction))\n        post_process.add_predection(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    predictions = post_process.get_score()\n    # Submission\n    exploded_test['score']=predictions\n    exploded_test = exploded_test.groupby('id').mean().reset_index() # aggregate auged samples\n    submission_100 = exploded_test[['id','score']].sort_index()\n    display(submission_100.head())\n    return submission_100","metadata":{"papermill":{"duration":0.118822,"end_time":"2022-06-19T03:53:20.074713","exception":false,"start_time":"2022-06-19T03:53:19.955891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T14:41:59.06547Z","iopub.execute_input":"2022-06-20T14:41:59.065959Z","iopub.status.idle":"2022-06-20T14:41:59.204841Z","shell.execute_reply.started":"2022-06-20T14:41:59.065918Z","shell.execute_reply":"2022-06-20T14:41:59.203654Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 099\ndef exp099():\n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        num_workers=0\n        path=\"../input/uspppm-exp099/\"\n        config_path=path+'config.pth'\n        model=\"microsoft/deberta-v3-large\"\n        ckpt_name=\"deberta-v3-large\"\n        batch_size=16\n        target_size=1\n        max_len=512\n        seed=42\n        n_fold=4\n    #     trn_fold=[0]\n        tar_token_id = 128001\n        tar_token = '[TAR]'\n        trn_fold=[0, 1, 2, 3]\n        n_augs = 2\n\n    # Library\n    # ====================================================\n    # Library\n    # ====================================================\n    import os\n    import gc\n    import re\n    import ast\n    import sys\n    import copy\n    import json\n    import time\n    import math\n    import shutil\n    import string\n    import pickle\n    import random\n    import joblib\n    import itertools\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    from tqdm.auto import tqdm\n    from sklearn.metrics import f1_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    import torch\n    print(f\"torch.__version__: {torch.__version__}\")\n    import torch.nn as nn\n    from torch.nn import Parameter\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD, AdamW\n    from torch.utils.data import DataLoader, Dataset\n    from torch import inference_mode\n\n    # os.system('pip uninstall -y transformers')\n    # os.system('pip uninstall -y tokenizers')\n    # os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 transformers')\n    # os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 tokenizers')\n\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\n    from transformers import AutoTokenizer, AutoModel, AutoConfig\n    from transformers import DataCollatorWithPadding\n    from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n    %env TOKENIZERS_PARALLELISM=false #true\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Utils\n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        score = sp.stats.pearsonr(y_true, y_pred)[0]\n        return score\n\n\n    def get_logger(filename=OUTPUT_DIR+'train'):\n        from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = get_logger()\n\n    def seed_everything(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_everything(seed=42)\n    # OOF\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df['score'].values\n    preds = oof_df['pred'].values\n    score = get_score(labels, preds)\n    LOGGER.info(f'CV Score: {score:<.4f}')\n    # Data Loading\n    # ====================================================\n    # Data Loading\n    # ====================================================\n    # test = pd.read_csv(INPUT_DIR+'train.csv').sample(n=100)\n    test = pd.read_csv(INPUT_DIR+'test.csv')\n    submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n    print(f\"test.shape: {test.shape}\")\n    print(f\"submission.shape: {submission.shape}\")\n    display(test.head())\n    display(submission.head())\n    # ====================================================\n    # CPC Data\n    # ====================================================\n    cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n    test['context_text'] = test['context'].map(cpc_texts)\n    display(test.head())\n    anchor_context_grouped_target = test.groupby(['anchor', 'context'])['target'].apply(list)\n    anchor_context_grouped_id = test.groupby(['anchor', 'context'])['id'].apply(list)\n    i = pd.DataFrame(anchor_context_grouped_id).reset_index()\n    t = pd.DataFrame(anchor_context_grouped_target).reset_index()\n    test = t.merge(i, on=['anchor', 'context'])\n    test['context_text'] = test['context'].map(cpc_texts)\n    test = test.rename(columns={'target': 'targets', 'id': 'ids'})\n    test['n_ids'] = test['ids'].map(len)\n    test.head()\n    from functools import reduce\n\n    def cat_ids(x) -> str:\n        return reduce(lambda a,b: a+b, x)\n    import random \n\n    cat_ids_sets = set(test['ids'].map(cat_ids))\n    auged_test = test.copy()\n    auged_rows = []\n    \n    for a in range(CFG.n_augs):\n        for _,r in test.iterrows():\n            if r.n_ids == 1:\n                continue\n            indices = list(range(r.n_ids))\n            random.shuffle(indices)\n            if cat_ids(list(np.array(r.ids)[indices])) in cat_ids_sets:\n                continue\n            auged_r = r.copy()\n            auged_r.targets = list(np.array(auged_r.targets)[indices])\n            auged_r.ids = list(np.array(auged_r.ids)[indices])\n            cat_ids_sets.add(cat_ids(auged_r.ids))\n            auged_rows.append(auged_r)\n    auged_test = test.append(\n        pd.DataFrame(auged_rows, columns=test.columns).reset_index(drop=True))\n    exploded_test = auged_test.explode(['targets', 'ids']).rename(columns={\n            'targets': 'target',\n            'ids': 'id',\n        }).reset_index(drop=True)\n    # tokenizer\n    # ====================================================\n    # tokenizer\n    # ====================================================\n    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n    assert CFG.tokenizer.encode(CFG.tar_token, add_special_tokens=False)[0] == CFG.tar_token_id\n    assert CFG.tokenizer.decode(CFG.tar_token_id) == CFG.tar_token\n\n    setattr(CFG.tokenizer, 'tar_token', CFG.tar_token)\n    setattr(CFG.tokenizer, 'tar_token_id', CFG.tar_token_id)\n    # Dataset\n    # ====================================================\n    # Dataset\n    # ====================================================\n\n    class TestDataset(Dataset):\n        def __init__(self, cfg, df):\n            self.cfg = cfg\n            self.anchors = df['anchor'].values\n            self.target_lists = df['targets'].values\n            self.id_lists = df['ids'].values\n            self.context_texts = df['context_text'].values\n            self.max_len = cfg.max_len\n            self.tokenizer = cfg.tokenizer\n\n        def __len__(self):\n            return len(self.id_lists)\n\n        def __getitem__(self, item):\n            target_mask = np.zeros(self.max_len)\n            targets = np.array(self.target_lists[item])\n\n            text = ''\n            text += self.tokenizer.cls_token\n            text += self.anchors[item]\n            text += self.tokenizer.sep_token\n            for target in targets:\n                text += target + self.tokenizer.tar_token\n            text += self.context_texts[item] + self.tokenizer.sep_token\n\n            encoded = self.tokenizer(\n                text,\n                max_length = self.max_len,\n                padding='max_length',\n                add_special_tokens=False,\n                truncation=True\n            )\n\n            cnt_tar = 0\n            cnt_sep = 0\n            nth_target = -1\n            prev_i = -1\n\n            for i, input_id in enumerate(encoded['input_ids']):\n                if input_id == self.tokenizer.tar_token_id:\n                    cnt_tar += 1\n                    if cnt_tar == len(targets):\n                        break\n                if input_id == self.tokenizer.sep_token_id:\n                    cnt_sep += 1\n\n                if cnt_sep == 1 and input_id not in [self.tokenizer.pad_token_id, self.tokenizer.sep_token_id, self.tokenizer.tar_token_id]:\n                    if (i-prev_i) > 1:\n                        nth_target += 1\n                    target_mask[i] = 1\n                    prev_i = i\n\n            for k,v in encoded.items():\n                encoded[k] = torch.tensor(v, dtype=torch.long)\n\n            return encoded, target_mask\n    # Model\n    # ====================================================\n    # Model\n    # ====================================================\n    class CustomModel(nn.Module):\n        def __init__(self, cfg, config_path=None, pretrained=False, n_vocabs=0):\n            super().__init__()\n            self.cfg = cfg\n            if config_path is None:\n                self.config = AutoConfig.from_pretrained(\n                    cfg.model, output_hidden_states=True)\n            else:\n                self.config = torch.load(config_path)\n            if pretrained:\n                self.model = AutoModel.from_pretrained(\n                    cfg.model, config=self.config)\n            else:\n                self.model = AutoModel.from_config(self.config)\n            self.model.resize_token_embeddings(n_vocabs)\n            self.fc = nn.Linear(self.config.hidden_size, 1)\n\n        def feature(self, inputs):\n            outputs = self.model(**inputs)\n            last_hidden_states = outputs[0]\n            return last_hidden_states\n\n        def forward(self, inputs):\n            feature = self.feature(inputs)\n            output = self.fc(feature).squeeze(-1)\n            return output\n    # inference\n    # ====================================================\n    # inference\n    # ====================================================\n    @inference_mode()\n    def inference_fn(test_loader, model, device):\n        preds = []\n        model.eval()\n        model.to(device)\n        for inputs, target_masks in test_loader:\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            y_preds = model(inputs)\n            y_preds = y_preds.sigmoid().to('cpu').numpy()\n\n            anchorwise_preds = []\n            for pred, target_mask, in zip(y_preds, target_masks):\n                prev_i = -1\n                targetwise_pred_scores = []\n                for i, (p, tm) in enumerate(zip(pred, target_mask)):\n                    if tm != 0:\n                        if i-1 == prev_i:\n                            targetwise_pred_scores[-1].append(p)\n                        else:\n                            targetwise_pred_scores.append([p])\n                        prev_i = i\n                for targetwise_pred_score in targetwise_pred_scores:\n                    anchorwise_preds.append(np.mean(targetwise_pred_score))\n            preds.append(anchorwise_preds)\n        return preds\n    # postprocess\n    import numpy as np\n    import pandas as pd\n\n    import re\n    import nltk\n    from nltk.stem import PorterStemmer\n    from nltk.stem import WordNetLemmatizer\n\n    class PostProcess:\n        def __init__(self, df, options={}):\n            self.options = {\n                'fit_near_score_th': 0.005,\n                'normalizer': ('lemmatizer') # 'stemmer'\n            }\n            self.options.update(options)\n            self.df = df.copy()\n            self.predictions = []\n\n        def add_predection(self, pred):\n            # shape => (36, 1)\n            self.predictions.append(pred.reshape(-1, 1))\n\n        def nanmean(self, preds):\n            return np.nanmean(preds, axis=0).reshape(-1)\n\n        def equal_score_1(self, preds):\n            \"\"\"\n            単純に anchor == target は score 1.0 にする\n            \"\"\"\n            df = self.df.copy()\n            df['preds'] = preds\n            df.loc[df.anchor == df.target, ['preds']] = 1.0\n            return df['preds'].values\n\n        def normalize_score_1(self, preds):\n            \"\"\"\n            normalizeした結果 == なら score を 1.0にする\n            \"\"\"\n            df = self.df.copy()\n            normalizer_options = self.options['normalizer']\n            lemmatizer = WordNetLemmatizer()\n            ps = PorterStemmer()\n            use_lemmatizer = 'lemmatizer' in normalizer_options\n            use_stemmer = 'stemmer' in normalizer_options\n            def normalize(word):\n                w = word.lower()\n                if use_lemmatizer:\n                    w = lemmatizer.lemmatize(w)\n                if use_stemmer:\n                    w = ps.stem(w)\n                return w\n            def normalize_words(word):\n                words = re.split(r'\\s+', word)\n                words = [normalize(t) for t in words]\n                return ' '.join(words)\n            an = df.anchor.map(normalize_words)\n            tn = df.target.map(normalize_words)\n            df['preds'] = preds\n            df.loc[an == tn, ['preds']] = 1.0\n            return df['preds'].values\n\n        def fit_near_score(self, preds):\n            fit_n = self.options['fit_near_score_th']\n            def fit_score(pred):\n                if pred <= fit_n:\n                    return 0.0\n                elif pred >= (0.25 - fit_n) and pred <= (0.25 + fit_n):\n                    return 0.25\n                elif pred >= (0.5 - fit_n) and pred <= (0.5 + fit_n):\n                    return 0.5\n                elif pred >= (0.75 - fit_n) and pred <= (0.75 + fit_n):\n                    return 0.75\n                elif pred >= (1 - fit_n):\n                    return 1.0\n                return pred\n            vect = np.vectorize(fit_score)\n            return vect(preds)\n\n        def get_score(self, apply_funcs=['nanmean', 'equal_score_1', 'normalize_score_1', 'fit_near_score']):\n            preds = self.predictions\n            for funcname in apply_funcs:\n                fn = getattr(self, funcname)\n                preds = fn(preds)\n            return preds.reshape(-1, 1) # 提出形式に合わせる\n\n\n    post_process = PostProcess(df=exploded_test)\n    # predictions\n    from functools import reduce\n\n    test_dataset = TestDataset(CFG, auged_test)\n    test_loader = DataLoader(test_dataset,\n                             batch_size=CFG.batch_size,\n                             shuffle=False,\n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    for fold in CFG.trn_fold:\n        model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False, n_vocabs=len(CFG.tokenizer))\n        state = torch.load(CFG.path+f\"{CFG.ckpt_name}_fold{fold}_best.pth\",\n                           map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        prediction = np.array(reduce(lambda a,b: a+b, prediction))\n        post_process.add_predection(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    predictions = post_process.get_score()\n    # Submission\n    exploded_test['score']=predictions\n    exploded_test = exploded_test.groupby('id').mean().reset_index() # aggregate auged samples\n    submission_099=exploded_test[['id','score']].sort_index()\n    display(submission_099.head())\n    submission_099[['id','score']].to_csv('submission.csv',index=False)\n    return submission_099","metadata":{"papermill":{"duration":0.149649,"end_time":"2022-06-19T03:53:20.228518","exception":false,"start_time":"2022-06-19T03:53:20.078869","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T14:49:42.395247Z","iopub.execute_input":"2022-06-20T14:49:42.395742Z","iopub.status.idle":"2022-06-20T14:49:42.632777Z","shell.execute_reply.started":"2022-06-20T14:49:42.395703Z","shell.execute_reply":"2022-06-20T14:49:42.631904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 108\ndef exp108():\n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        num_workers=0\n        path=\"../input/pppm-exp108/\"\n        config_path=path+'config.pth'\n        model=\"anferico/bert-for-patents\"\n        ckpt_name=\"bert_for_patents\"\n        batch_size=16\n        target_size=1\n        max_len=480\n        seed=42\n        n_fold=4\n    #     trn_fold=[0]\n        tar_token_id = 39859\n        tar_token = '[TAR]'\n        trn_fold=[0, 1, 2, 3]\n        n_augs = 2\n\n    # Library\n    # ====================================================\n    # Library\n    # ====================================================\n    import os\n    import gc\n    import re\n    import ast\n    import sys\n    import copy\n    import json\n    import time\n    import math\n    import shutil\n    import string\n    import pickle\n    import random\n    import joblib\n    import itertools\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    from tqdm.auto import tqdm\n    from sklearn.metrics import f1_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    import torch\n    print(f\"torch.__version__: {torch.__version__}\")\n    import torch.nn as nn\n    from torch.nn import Parameter\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD, AdamW\n    from torch.utils.data import DataLoader, Dataset\n    from torch import inference_mode\n\n    # os.system('pip uninstall -y transformers')\n    # os.system('pip uninstall -y tokenizers')\n    # os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 transformers')\n    # os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 tokenizers')\n\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\n    from transformers import AutoTokenizer, AutoModel, AutoConfig\n    from transformers import DataCollatorWithPadding\n    from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n    %env TOKENIZERS_PARALLELISM=false #true\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Utils\n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        score = sp.stats.pearsonr(y_true, y_pred)[0]\n        return score\n\n\n    def get_logger(filename=OUTPUT_DIR+'train'):\n        from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = get_logger()\n\n    def seed_everything(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_everything(seed=42)\n    # OOF\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df['score'].values\n    preds = oof_df['pred'].values\n    score = get_score(labels, preds)\n    LOGGER.info(f'CV Score: {score:<.4f}')\n    # Data Loading\n    # ====================================================\n    # Data Loading\n    # ====================================================\n    # test = pd.read_csv(INPUT_DIR+'train.csv').sample(n=100)\n    test = pd.read_csv(INPUT_DIR+'test.csv')\n    submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n    print(f\"test.shape: {test.shape}\")\n    print(f\"submission.shape: {submission.shape}\")\n    display(test.head())\n    display(submission.head())\n    # ====================================================\n    # CPC Data\n    # ====================================================\n    cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n    test['context_text'] = test['context'].map(cpc_texts)\n    display(test.head())\n    anchor_context_grouped_target = test.groupby(['anchor', 'context'])['target'].apply(list)\n    anchor_context_grouped_id = test.groupby(['anchor', 'context'])['id'].apply(list)\n    i = pd.DataFrame(anchor_context_grouped_id).reset_index()\n    t = pd.DataFrame(anchor_context_grouped_target).reset_index()\n    test = t.merge(i, on=['anchor', 'context'])\n    test['context_text'] = test['context'].map(cpc_texts)\n    test = test.rename(columns={'target': 'targets', 'id': 'ids'})\n    test['n_ids'] = test['ids'].map(len)\n    test.head()\n    from functools import reduce\n\n    def cat_ids(x) -> str:\n        return reduce(lambda a,b: a+b, x)\n    import random \n\n    cat_ids_sets = set(test['ids'].map(cat_ids))\n    auged_test = test.copy()\n    auged_rows = []\n    for a in range(CFG.n_augs):\n        for _,r in test.iterrows():\n            if r.n_ids == 1:\n                continue\n            indices = list(range(r.n_ids))\n            random.shuffle(indices)\n            if cat_ids(list(np.array(r.ids)[indices])) in cat_ids_sets:\n                continue\n            auged_r = r.copy()\n            auged_r.targets = list(np.array(auged_r.targets)[indices])\n            auged_r.ids = list(np.array(auged_r.ids)[indices])\n            cat_ids_sets.add(cat_ids(auged_r.ids))\n            auged_rows.append(auged_r)\n    auged_test = test.append(\n        pd.DataFrame(auged_rows, columns=test.columns).reset_index(drop=True))\n    exploded_test = auged_test.explode(['targets', 'ids']).rename(columns={\n            'targets': 'target',\n            'ids': 'id',\n        }).reset_index(drop=True)\n    # tokenizer\n    # ====================================================\n    # tokenizer\n    # ====================================================\n    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n    assert CFG.tokenizer.encode(CFG.tar_token, add_special_tokens=False)[0] == CFG.tar_token_id\n    assert CFG.tokenizer.decode(CFG.tar_token_id) == CFG.tar_token\n\n    setattr(CFG.tokenizer, 'tar_token', CFG.tar_token)\n    setattr(CFG.tokenizer, 'tar_token_id', CFG.tar_token_id)\n    # Dataset\n    # ====================================================\n    # Dataset\n    # ====================================================\n\n    class TestDataset(Dataset):\n        def __init__(self, cfg, df):\n            self.cfg = cfg\n            self.anchors = df['anchor'].values\n            self.target_lists = df['targets'].values\n            self.id_lists = df['ids'].values\n            self.context_texts = df['context_text'].values\n            self.max_len = cfg.max_len\n            self.tokenizer = cfg.tokenizer\n\n        def __len__(self):\n            return len(self.id_lists)\n\n        def __getitem__(self, item):\n            target_mask = np.zeros(self.max_len)\n            targets = np.array(self.target_lists[item])\n\n            text = ''\n            text += self.tokenizer.cls_token\n            text += self.anchors[item]\n            text += self.tokenizer.sep_token\n            for target in targets:\n                text += target + self.tokenizer.tar_token\n            text += self.context_texts[item] + self.tokenizer.sep_token\n\n            encoded = self.tokenizer(\n                text,\n                max_length = self.max_len,\n                padding='max_length',\n                add_special_tokens=False,\n                truncation=True\n            )\n\n            cnt_tar = 0\n            cnt_sep = 0\n            nth_target = -1\n            prev_i = -1\n\n            for i, input_id in enumerate(encoded['input_ids']):\n                if input_id == self.tokenizer.tar_token_id:\n                    cnt_tar += 1\n                    if cnt_tar == len(targets):\n                        break\n                if input_id == self.tokenizer.sep_token_id:\n                    cnt_sep += 1\n\n                if cnt_sep == 1 and input_id not in [self.tokenizer.pad_token_id, self.tokenizer.sep_token_id, self.tokenizer.tar_token_id]:\n                    if (i-prev_i) > 1:\n                        nth_target += 1\n                    target_mask[i] = 1\n                    prev_i = i\n\n            for k,v in encoded.items():\n                encoded[k] = torch.tensor(v, dtype=torch.long)\n\n            return encoded, target_mask\n    # Model\n    # ====================================================\n    # Model\n    # ====================================================\n    class CustomModel(nn.Module):\n        def __init__(self, cfg, config_path=None, pretrained=False, n_vocabs=0):\n            super().__init__()\n            self.cfg = cfg\n            if config_path is None:\n                self.config = AutoConfig.from_pretrained(\n                    cfg.model, output_hidden_states=True)\n            else:\n                self.config = torch.load(config_path)\n            if pretrained:\n                self.model = AutoModel.from_pretrained(\n                    cfg.model, config=self.config)\n            else:\n                self.model = AutoModel.from_config(self.config)\n            self.model.resize_token_embeddings(n_vocabs)\n            self.fc = nn.Linear(self.config.hidden_size, 1)\n\n        def feature(self, inputs):\n            outputs = self.model(**inputs)\n            last_hidden_states = outputs[0]\n            return last_hidden_states\n\n        def forward(self, inputs):\n            feature = self.feature(inputs)\n            output = self.fc(feature).squeeze(-1)\n            return output\n    # inference\n    # ====================================================\n    # inference\n    # ====================================================\n    @inference_mode()\n    def inference_fn(test_loader, model, device):\n        preds = []\n        model.eval()\n        model.to(device)\n        for inputs, target_masks in test_loader:\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            y_preds = model(inputs)\n            y_preds = y_preds.sigmoid().to('cpu').numpy()\n\n            anchorwise_preds = []\n            for pred, target_mask, in zip(y_preds, target_masks):\n                prev_i = -1\n                targetwise_pred_scores = []\n                for i, (p, tm) in enumerate(zip(pred, target_mask)):\n                    if tm != 0:\n                        if i-1 == prev_i:\n                            targetwise_pred_scores[-1].append(p)\n                        else:\n                            targetwise_pred_scores.append([p])\n                        prev_i = i\n                for targetwise_pred_score in targetwise_pred_scores:\n                    anchorwise_preds.append(np.mean(targetwise_pred_score))\n            preds.append(anchorwise_preds)\n        return preds\n    # postprocess\n    import numpy as np\n    import pandas as pd\n\n    import re\n    import nltk\n    from nltk.stem import PorterStemmer\n    from nltk.stem import WordNetLemmatizer\n\n    class PostProcess:\n        def __init__(self, df, options={}):\n            self.options = {\n                'fit_near_score_th': 0.005,\n                'normalizer': ('lemmatizer') # 'stemmer'\n            }\n            self.options.update(options)\n            self.df = df.copy()\n            self.predictions = []\n\n        def add_predection(self, pred):\n            # shape => (36, 1)\n            self.predictions.append(pred.reshape(-1, 1))\n\n        def nanmean(self, preds):\n            return np.nanmean(preds, axis=0).reshape(-1)\n\n        def equal_score_1(self, preds):\n            \"\"\"\n            単純に anchor == target は score 1.0 にする\n            \"\"\"\n            df = self.df.copy()\n            df['preds'] = preds\n            df.loc[df.anchor == df.target, ['preds']] = 1.0\n            return df['preds'].values\n\n        def normalize_score_1(self, preds):\n            \"\"\"\n            normalizeした結果 == なら score を 1.0にする\n            \"\"\"\n            df = self.df.copy()\n            normalizer_options = self.options['normalizer']\n            lemmatizer = WordNetLemmatizer()\n            ps = PorterStemmer()\n            use_lemmatizer = 'lemmatizer' in normalizer_options\n            use_stemmer = 'stemmer' in normalizer_options\n            def normalize(word):\n                w = word.lower()\n                if use_lemmatizer:\n                    w = lemmatizer.lemmatize(w)\n                if use_stemmer:\n                    w = ps.stem(w)\n                return w\n            def normalize_words(word):\n                words = re.split(r'\\s+', word)\n                words = [normalize(t) for t in words]\n                return ' '.join(words)\n            an = df.anchor.map(normalize_words)\n            tn = df.target.map(normalize_words)\n            df['preds'] = preds\n            df.loc[an == tn, ['preds']] = 1.0\n            return df['preds'].values\n\n        def fit_near_score(self, preds):\n            fit_n = self.options['fit_near_score_th']\n            def fit_score(pred):\n                if pred <= fit_n:\n                    return 0.0\n                elif pred >= (0.25 - fit_n) and pred <= (0.25 + fit_n):\n                    return 0.25\n                elif pred >= (0.5 - fit_n) and pred <= (0.5 + fit_n):\n                    return 0.5\n                elif pred >= (0.75 - fit_n) and pred <= (0.75 + fit_n):\n                    return 0.75\n                elif pred >= (1 - fit_n):\n                    return 1.0\n                return pred\n            vect = np.vectorize(fit_score)\n            return vect(preds)\n\n        def get_score(self, apply_funcs=['nanmean', 'equal_score_1', 'normalize_score_1', 'fit_near_score']):\n            preds = self.predictions\n            for funcname in apply_funcs:\n                fn = getattr(self, funcname)\n                preds = fn(preds)\n            return preds.reshape(-1, 1) # 提出形式に合わせる\n\n\n    post_process = PostProcess(df=exploded_test)\n    # predictions\n    from functools import reduce\n\n    test_dataset = TestDataset(CFG, auged_test)\n    test_loader = DataLoader(test_dataset,\n                             batch_size=CFG.batch_size,\n                             shuffle=False,\n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    for fold in CFG.trn_fold:\n        model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False, n_vocabs=len(CFG.tokenizer))\n        state = torch.load(CFG.path+f\"{CFG.ckpt_name}_fold{fold}_best.pth\",\n                           map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        prediction = np.array(reduce(lambda a,b: a+b, prediction))\n        post_process.add_predection(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    predictions = post_process.get_score()\n    # Submission\n    exploded_test['score']=predictions\n    exploded_test = exploded_test.groupby('id').mean().reset_index() # aggregate auged samples\n    submission_108=exploded_test[['id','score']].sort_index()\n    display(submission_108.head())\n    submission_108[['id','score']].to_csv('submission.csv',index=False)\n    return submission_108","metadata":{"papermill":{"duration":0.198069,"end_time":"2022-06-19T03:53:20.430571","exception":false,"start_time":"2022-06-19T03:53:20.232502","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T14:57:58.09571Z","iopub.execute_input":"2022-06-20T14:57:58.096121Z","iopub.status.idle":"2022-06-20T14:57:58.317136Z","shell.execute_reply.started":"2022-06-20T14:57:58.096091Z","shell.execute_reply":"2022-06-20T14:57:58.316209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 124\ndef exp124():\n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        num_workers=0\n        path=\"../input/pppm-exp124/\"\n        config_path=path+'config.pth'\n        model=\"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n        ckpt_name=\"DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n        batch_size=16\n        target_size=1\n        max_len=512\n        seed=42\n        n_fold=4\n        tar_token_id = 128001\n        tar_token = '[TAR]'\n        trn_fold=[0, 1, 2, 3]\n        n_augs = 2\n\n    # Library\n    # ====================================================\n    # Library\n    # ====================================================\n    import os\n    import gc\n    import re\n    import ast\n    import sys\n    import copy\n    import json\n    import time\n    import math\n    import shutil\n    import string\n    import pickle\n    import random\n    import joblib\n    import itertools\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    from tqdm.auto import tqdm\n    from sklearn.metrics import f1_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    import torch\n    print(f\"torch.__version__: {torch.__version__}\")\n    import torch.nn as nn\n    from torch.nn import Parameter\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD, AdamW\n    from torch.utils.data import DataLoader, Dataset\n    from torch import inference_mode\n\n    # os.system('pip uninstall -y transformers')\n    # os.system('pip uninstall -y tokenizers')\n    # os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 transformers')\n    # os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheel-20220531 tokenizers')\n\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\n    from transformers import AutoTokenizer, AutoModel, AutoConfig\n    from transformers import DataCollatorWithPadding\n    from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n    %env TOKENIZERS_PARALLELISM=false #true\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Utils\n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        score = sp.stats.pearsonr(y_true, y_pred)[0]\n        return score\n\n\n    def get_logger(filename=OUTPUT_DIR+'train'):\n        from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = get_logger()\n\n    def seed_everything(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_everything(seed=42)\n    # OOF\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df['score'].values\n    preds = oof_df['pred'].values\n    score = get_score(labels, preds)\n    LOGGER.info(f'CV Score: {score:<.4f}')\n    # Data Loading\n    # ====================================================\n    # Data Loading\n    # ====================================================\n    # test = pd.read_csv(INPUT_DIR+'train.csv').sample(n=100)\n    test = pd.read_csv(INPUT_DIR+'test.csv')\n    submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n    print(f\"test.shape: {test.shape}\")\n    print(f\"submission.shape: {submission.shape}\")\n    display(test.head())\n    display(submission.head())\n    # ====================================================\n    # CPC Data\n    # ====================================================\n    cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n    test['context_text'] = test['context'].map(cpc_texts)\n    display(test.head())\n    anchor_context_grouped_target = test.groupby(['anchor', 'context'])['target'].apply(list)\n    anchor_context_grouped_id = test.groupby(['anchor', 'context'])['id'].apply(list)\n    i = pd.DataFrame(anchor_context_grouped_id).reset_index()\n    t = pd.DataFrame(anchor_context_grouped_target).reset_index()\n    test = t.merge(i, on=['anchor', 'context'])\n    test['context_text'] = test['context'].map(cpc_texts)\n    test = test.rename(columns={'target': 'targets', 'id': 'ids'})\n    test['n_ids'] = test['ids'].map(len)\n    test.head()\n    from functools import reduce\n\n    def cat_ids(x) -> str:\n        return reduce(lambda a,b: a+b, x)\n    import random \n\n    cat_ids_sets = set(test['ids'].map(cat_ids))\n    auged_test = test.copy()\n    auged_rows = []\n    for a in range(CFG.n_augs):\n        for _,r in test.iterrows():\n            if r.n_ids == 1:\n                continue\n            indices = list(range(r.n_ids))\n            random.shuffle(indices)\n            if cat_ids(list(np.array(r.ids)[indices])) in cat_ids_sets:\n                continue\n            auged_r = r.copy()\n            auged_r.targets = list(np.array(auged_r.targets)[indices])\n            auged_r.ids = list(np.array(auged_r.ids)[indices])\n            cat_ids_sets.add(cat_ids(auged_r.ids))\n            auged_rows.append(auged_r)\n    auged_test = test.append(\n        pd.DataFrame(auged_rows, columns=test.columns).reset_index(drop=True))\n    exploded_test = auged_test.explode(['targets', 'ids']).rename(columns={\n            'targets': 'target',\n            'ids': 'id',\n        }).reset_index(drop=True)\n    # tokenizer\n    # ====================================================\n    # tokenizer\n    # ====================================================\n    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n    assert CFG.tokenizer.encode(CFG.tar_token, add_special_tokens=False)[0] == CFG.tar_token_id\n    assert CFG.tokenizer.decode(CFG.tar_token_id) == CFG.tar_token\n\n    setattr(CFG.tokenizer, 'tar_token', CFG.tar_token)\n    setattr(CFG.tokenizer, 'tar_token_id', CFG.tar_token_id)\n    # Dataset\n    # ====================================================\n    # Dataset\n    # ====================================================\n\n    class TestDataset(Dataset):\n        def __init__(self, cfg, df):\n            self.cfg = cfg\n            self.anchors = df['anchor'].values\n            self.target_lists = df['targets'].values\n            self.id_lists = df['ids'].values\n            self.context_texts = df['context_text'].values\n            self.max_len = cfg.max_len\n            self.tokenizer = cfg.tokenizer\n\n        def __len__(self):\n            return len(self.id_lists)\n\n        def __getitem__(self, item):\n            target_mask = np.zeros(self.max_len)\n            targets = np.array(self.target_lists[item])\n\n            text = ''\n            text += self.tokenizer.cls_token\n            text += self.anchors[item]\n            text += self.tokenizer.sep_token\n            for target in targets:\n                text += target + self.tokenizer.tar_token\n            text += self.context_texts[item] + self.tokenizer.sep_token\n\n            encoded = self.tokenizer(\n                text,\n                max_length = self.max_len,\n                padding='max_length',\n                add_special_tokens=False,\n                truncation=True\n            )\n\n            cnt_tar = 0\n            cnt_sep = 0\n            nth_target = -1\n            prev_i = -1\n\n            for i, input_id in enumerate(encoded['input_ids']):\n                if input_id == self.tokenizer.tar_token_id:\n                    cnt_tar += 1\n                    if cnt_tar == len(targets):\n                        break\n                if input_id == self.tokenizer.sep_token_id:\n                    cnt_sep += 1\n\n                if cnt_sep == 1 and input_id not in [self.tokenizer.pad_token_id, self.tokenizer.sep_token_id, self.tokenizer.tar_token_id]:\n                    if (i-prev_i) > 1:\n                        nth_target += 1\n                    target_mask[i] = 1\n                    prev_i = i\n\n            for k,v in encoded.items():\n                encoded[k] = torch.tensor(v, dtype=torch.long)\n\n            return encoded, target_mask\n    # Model\n    # ====================================================\n    # Model\n    # ====================================================\n    class CustomModel(nn.Module):\n        def __init__(self, cfg, config_path=None, pretrained=False, n_vocabs=0):\n            super().__init__()\n            self.cfg = cfg\n            if config_path is None:\n                self.config = AutoConfig.from_pretrained(\n                    cfg.model, output_hidden_states=True)\n            else:\n                self.config = torch.load(config_path)\n            if pretrained:\n                self.model = AutoModel.from_pretrained(\n                    cfg.model, config=self.config)\n            else:\n                self.model = AutoModel.from_config(self.config)\n            self.model.resize_token_embeddings(n_vocabs)\n            self.fc = nn.Linear(self.config.hidden_size, 1)\n\n        def feature(self, inputs):\n            outputs = self.model(**inputs)\n            last_hidden_states = outputs[0]\n            return last_hidden_states\n\n        def forward(self, inputs):\n            feature = self.feature(inputs)\n            output = self.fc(feature).squeeze(-1)\n            return output\n    # inference\n    # ====================================================\n    # inference\n    # ====================================================\n    @inference_mode()\n    def inference_fn(test_loader, model, device):\n        preds = []\n        model.eval()\n        model.to(device)\n        for inputs, target_masks in test_loader:\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            y_preds = model(inputs)\n            y_preds = y_preds.sigmoid().to('cpu').numpy()\n\n            anchorwise_preds = []\n            for pred, target_mask, in zip(y_preds, target_masks):\n                prev_i = -1\n                targetwise_pred_scores = []\n                for i, (p, tm) in enumerate(zip(pred, target_mask)):\n                    if tm != 0:\n                        if i-1 == prev_i:\n                            targetwise_pred_scores[-1].append(p)\n                        else:\n                            targetwise_pred_scores.append([p])\n                        prev_i = i\n                for targetwise_pred_score in targetwise_pred_scores:\n                    anchorwise_preds.append(np.mean(targetwise_pred_score))\n            preds.append(anchorwise_preds)\n        return preds\n    # postprocess\n    import numpy as np\n    import pandas as pd\n\n    import re\n    import nltk\n    from nltk.stem import PorterStemmer\n    from nltk.stem import WordNetLemmatizer\n\n    class PostProcess:\n        def __init__(self, df, options={}):\n            self.options = {\n                'fit_near_score_th': 0.005,\n                'normalizer': ('lemmatizer') # 'stemmer'\n            }\n            self.options.update(options)\n            self.df = df.copy()\n            self.predictions = []\n\n        def add_predection(self, pred):\n            # shape => (36, 1)\n            self.predictions.append(pred.reshape(-1, 1))\n\n        def nanmean(self, preds):\n            return np.nanmean(preds, axis=0).reshape(-1)\n\n        def equal_score_1(self, preds):\n            \"\"\"\n            単純に anchor == target は score 1.0 にする\n            \"\"\"\n            df = self.df.copy()\n            df['preds'] = preds\n            df.loc[df.anchor == df.target, ['preds']] = 1.0\n            return df['preds'].values\n\n        def normalize_score_1(self, preds):\n            \"\"\"\n            normalizeした結果 == なら score を 1.0にする\n            \"\"\"\n            df = self.df.copy()\n            normalizer_options = self.options['normalizer']\n            lemmatizer = WordNetLemmatizer()\n            ps = PorterStemmer()\n            use_lemmatizer = 'lemmatizer' in normalizer_options\n            use_stemmer = 'stemmer' in normalizer_options\n            def normalize(word):\n                w = word.lower()\n                if use_lemmatizer:\n                    w = lemmatizer.lemmatize(w)\n                if use_stemmer:\n                    w = ps.stem(w)\n                return w\n            def normalize_words(word):\n                words = re.split(r'\\s+', word)\n                words = [normalize(t) for t in words]\n                return ' '.join(words)\n            an = df.anchor.map(normalize_words)\n            tn = df.target.map(normalize_words)\n            df['preds'] = preds\n            df.loc[an == tn, ['preds']] = 1.0\n            return df['preds'].values\n\n        def fit_near_score(self, preds):\n            fit_n = self.options['fit_near_score_th']\n            def fit_score(pred):\n                if pred <= fit_n:\n                    return 0.0\n                elif pred >= (0.25 - fit_n) and pred <= (0.25 + fit_n):\n                    return 0.25\n                elif pred >= (0.5 - fit_n) and pred <= (0.5 + fit_n):\n                    return 0.5\n                elif pred >= (0.75 - fit_n) and pred <= (0.75 + fit_n):\n                    return 0.75\n                elif pred >= (1 - fit_n):\n                    return 1.0\n                return pred\n            vect = np.vectorize(fit_score)\n            return vect(preds)\n\n        def get_score(self, apply_funcs=['nanmean', 'equal_score_1', 'normalize_score_1', 'fit_near_score']):\n            preds = self.predictions\n            for funcname in apply_funcs:\n                fn = getattr(self, funcname)\n                preds = fn(preds)\n            return preds.reshape(-1, 1) # 提出形式に合わせる\n\n\n    post_process = PostProcess(df=exploded_test)\n    # predictions\n    from functools import reduce\n\n    test_dataset = TestDataset(CFG, auged_test)\n    test_loader = DataLoader(test_dataset,\n                             batch_size=CFG.batch_size,\n                             shuffle=False,\n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    for fold in CFG.trn_fold:\n        model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False, n_vocabs=len(CFG.tokenizer))\n        state = torch.load(CFG.path+f\"{CFG.ckpt_name}_fold{fold}_best.pth\",\n                           map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        prediction = np.array(reduce(lambda a,b: a+b, prediction))\n        post_process.add_predection(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    predictions = post_process.get_score()\n    # Submission\n    exploded_test['score']=predictions\n    exploded_test = exploded_test.groupby('id').mean().reset_index() # aggregate auged samples\n    submission=exploded_test[['id','score']].sort_index()\n    display(submission.head())\n    submission[['id','score']].to_csv('submission.csv',index=False)\n    return submission","metadata":{"execution":{"iopub.status.busy":"2022-06-20T14:59:44.196335Z","iopub.execute_input":"2022-06-20T14:59:44.1967Z","iopub.status.idle":"2022-06-20T14:59:44.315471Z","shell.execute_reply.started":"2022-06-20T14:59:44.196671Z","shell.execute_reply":"2022-06-20T14:59:44.314588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def exp115():\n    class CFG:\n        num_workers=0\n        path=\"../input/pppm-exp115/\"\n        config_path=path+'config.pth'\n        model=\"microsoft/deberta-v3-large\"\n        ckpt_name=\"deberta-v3-large\"\n        batch_size=32\n        target_size=1\n        max_len=160\n        seed=42\n        n_fold=4\n        trn_fold=[0, 1, 2, 3]\n\n        \n    import os\n    import gc\n    import re\n    import ast\n    import sys\n    import copy\n    import json\n    import time\n    import math\n    import shutil\n    import string\n    import pickle\n    import random\n    import joblib\n    import itertools\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    from tqdm.auto import tqdm\n    from sklearn.metrics import f1_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    import torch\n    print(f\"torch.__version__: {torch.__version__}\")\n    import torch.nn as nn\n    from torch.nn import Parameter\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD, AdamW\n    from torch.utils.data import DataLoader, Dataset\n    from torch import inference_mode\n\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\n    from transformers import AutoTokenizer, AutoModel, AutoConfig\n    from transformers import DataCollatorWithPadding\n    from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n    %env TOKENIZERS_PARALLELISM=false #true\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        score = sp.stats.pearsonr(y_true, y_pred)[0]\n        return score\n\n\n    def get_logger(filename=OUTPUT_DIR+'train'):\n        from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = get_logger()\n\n    def seed_everything(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_everything(seed=42)\n\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df['score'].values\n    preds = oof_df['pred'].values\n    score = get_score(labels, preds)\n    LOGGER.info(f'CV Score: {score:<.4f}')\n\n    # ====================================================\n    # Data Loading\n    # ====================================================\n    test = pd.read_csv(INPUT_DIR+'test.csv')\n    submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n    print(f\"test.shape: {test.shape}\")\n    print(f\"submission.shape: {submission.shape}\")\n    display(test.head())\n    display(submission.head())\n\n    # ====================================================\n    # CPC Data\n    # ====================================================\n    cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n    test['context_text'] = test['context'].map(cpc_texts)\n    display(test.head())\n\n    test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n    display(test.head())\n\n    # ====================================================\n    # tokenizer\n    # ====================================================\n    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n    # token_length付与\n    test['token_length']=CFG.tokenizer(test['text'].to_list(), max_length=CFG.max_len, truncation=True, return_length=True)['length']\n    test=test.sort_values('token_length')\n    test.head()\n\n    # ====================================================\n    # Dataset\n    # ====================================================\n\n    class TestDataset(Dataset):\n        def __init__(self, cfg, df):\n            self.cfg = cfg\n            self.texts = df['text'].values\n\n        def __len__(self):\n            return len(self.texts)\n\n        def __getitem__(self, item):\n            inputs = self.texts[item]\n            return inputs\n\n    def collate_fn(data: \"list[str]\"\n                ) -> \"dict[str,torch.Tensor]\":\n        '''DataLoaderで使用するcollate_fn. Datasetの出力を受け取り、tensorの形に加工する関数。\n        ここでは、動的にpaddingを行うために使用している'''\n        texts = data\n        inputs = CFG.tokenizer(texts,\n                            add_special_tokens=True,\n                            max_length=CFG.max_len,\n                            truncation=True,\n                            return_offsets_mapping=False)\n        data_collator = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n        inputs = data_collator(inputs)\n        return inputs\n\n    # ====================================================\n    # Model\n    # ====================================================\n    class CustomModel(nn.Module):\n        def __init__(self, cfg, config_path=None, pretrained=False):\n            super().__init__()\n            self.cfg = cfg\n            if config_path is None:\n                self.config = AutoConfig.from_pretrained(\n                    cfg.model, output_hidden_states=True)\n            else:\n                self.config = torch.load(config_path)\n            if pretrained:\n                self.model = AutoModel.from_pretrained(\n                    cfg.model, config=self.config)\n            else:\n                self.model = AutoModel.from_config(self.config)\n            self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n            self._init_weights(self.fc)\n\n        def _init_weights(self, module):\n            if isinstance(module, nn.Linear):\n                module.weight.data.normal_(\n                    mean=0.0, std=self.config.initializer_range)\n                if module.bias is not None:\n                    module.bias.data.zero_()\n            elif isinstance(module, nn.Embedding):\n                module.weight.data.normal_(\n                    mean=0.0, std=self.config.initializer_range)\n                if module.padding_idx is not None:\n                    module.weight.data[module.padding_idx].zero_()\n            elif isinstance(module, nn.LayerNorm):\n                module.bias.data.zero_()\n                module.weight.data.fill_(1.0)\n\n        def feature(self, inputs):\n            outputs = self.model(**inputs)\n            # 最終層の出力 #(, max_len, hidden_size)\n            last_hidden_states = outputs['last_hidden_state']\n            # feature = torch.mean(last_hidden_states, 1)\n            # ただ単に平均するんじゃなくて、どのhidden_sizeがどのくらい重要なのかで合計する\n            feature = last_hidden_states[:, 0, :]  # (, hidden_size)\n            return feature\n\n        def forward(self, inputs):\n            feature = self.feature(inputs)  # (, hidden_size)\n            output = self.fc(feature)  # (,target_size)\n            return output\n\n    # ====================================================\n    # inference\n    # ====================================================\n    @inference_mode()\n    def inference_fn(test_loader, model, device):\n        preds = []\n        model.eval()\n        model.to(device)\n        tk0 = tqdm(test_loader, total=len(test_loader))\n        for inputs in tk0:\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            y_preds = model(inputs)\n            preds.append(y_preds.sigmoid().to('cpu').numpy())\n        predictions = np.concatenate(preds)\n        return predictions\n\n    # postprocess\n\n    import numpy as np\n    import pandas as pd\n\n    import re\n    import nltk\n    # nltk.download('stopwords')\n    # nltk.download('wordnet')\n    # nltk.download('omw-1.4')\n    from nltk.stem import PorterStemmer\n    from nltk.stem import WordNetLemmatizer\n\n    class PostProcess:\n        def __init__(self, df, options={}):\n            self.options = {\n                'fit_near_score_th': 0.005,\n                'normalizer': ('lemmatizer') # 'stemmer'\n            }\n            self.options.update(options)\n            self.df = df.copy()\n            self.predictions = []\n        \n        def add_predection(self, pred):\n            # shape => (36, 1)\n            self.predictions.append(pred.reshape(-1, 1))\n\n        def nanmean(self, preds):\n            return np.nanmean(preds, axis=0).reshape(-1)\n        \n        def equal_score_1(self, preds):\n            \"\"\"\n            単純に anchor == target は score 1.0 にする\n            \"\"\"\n            df = self.df.copy()\n            df['preds'] = preds\n            df.loc[df.anchor == df.target, ['preds']] = 1.0\n            return df['preds'].values\n        \n        def normalize_score_1(self, preds):\n            \"\"\"\n            normalizeした結果 == なら score を 1.0にする\n            \"\"\"\n            df = self.df.copy()\n            normalizer_options = self.options['normalizer']\n            lemmatizer = WordNetLemmatizer()\n            ps = PorterStemmer()\n            use_lemmatizer = 'lemmatizer' in normalizer_options\n            use_stemmer = 'stemmer' in normalizer_options\n            def normalize(word):\n                w = word.lower()\n                if use_lemmatizer:\n                    w = lemmatizer.lemmatize(w)\n                if use_stemmer:\n                    w = ps.stem(w)\n                return w\n            def normalize_words(word):\n                words = re.split(r'\\s+', word)\n                words = [normalize(t) for t in words]\n                return ' '.join(words)\n            an = df.anchor.map(normalize_words)\n            tn = df.target.map(normalize_words)\n            df['preds'] = preds\n            df.loc[an == tn, ['preds']] = 1.0\n            return df['preds'].values\n        \n        def fit_near_score(self, preds):\n            fit_n = self.options['fit_near_score_th']\n            def fit_score(pred):\n                if pred <= fit_n:\n                    return 0.0\n                elif pred >= (0.25 - fit_n) and pred <= (0.25 + fit_n):\n                    return 0.25\n                elif pred >= (0.5 - fit_n) and pred <= (0.5 + fit_n):\n                    return 0.5\n                elif pred >= (0.75 - fit_n) and pred <= (0.75 + fit_n):\n                    return 0.75\n                elif pred >= (1 - fit_n):\n                    return 1.0\n                return pred\n            vect = np.vectorize(fit_score)\n            return vect(preds)\n\n        def get_score(self, apply_funcs=['nanmean', 'equal_score_1', 'normalize_score_1', 'fit_near_score']):\n            preds = self.predictions\n            for funcname in apply_funcs:\n                fn = getattr(self, funcname)\n                preds = fn(preds)\n            return preds.reshape(-1, 1) # 提出形式に合わせる\n    post_process = PostProcess(df=test)\n\n    # exp-070 prediction\n    test_dataset = TestDataset(CFG, test)\n    test_loader = DataLoader(test_dataset,\n                            batch_size=CFG.batch_size,\n                            shuffle=False,\n                            num_workers=CFG.num_workers, pin_memory=True, drop_last=False,\n                            collate_fn=collate_fn)\n    # predictions = []\n    for fold in CFG.trn_fold:\n        model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n        state = torch.load(CFG.path+f\"{CFG.ckpt_name}_fold{fold}_best.pth\",\n                        map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        post_process.add_predection(prediction)\n        # predictions.append(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    # predictions = np.nanmean(predictions, axis=0)\n    preds = post_process.get_score()\n    test['score'] = preds\n    return test[['id','score']]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T14:59:50.278593Z","iopub.execute_input":"2022-06-20T14:59:50.278968Z","iopub.status.idle":"2022-06-20T14:59:50.375796Z","shell.execute_reply.started":"2022-06-20T14:59:50.278937Z","shell.execute_reply":"2022-06-20T14:59:50.374947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def exp114():\n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        num_workers=2\n        path=\"../input/pppm-exp114/\"\n        config_path=path+'config.pth'\n        model=\"microsoft/deberta-v3-large\"\n        ckpt_name=\"deberta-v3-large\"\n        batch_size=32\n        fc_dropout=0.2\n        target_size=1\n        max_len=133\n        seed=42\n        n_fold=4\n        trn_fold=[0, 1, 2, 3]\n    # Utils\n    import os\n    import gc\n    import re\n    import ast\n    import sys\n    import copy\n    import json\n    import time\n    import math\n    import shutil\n    import string\n    import pickle\n    import random\n    import joblib\n    import itertools\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    from tqdm.auto import tqdm\n    from sklearn.metrics import f1_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    import torch\n    print(f\"torch.__version__: {torch.__version__}\")\n    import torch.nn as nn\n    from torch.nn import Parameter\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD, AdamW\n    from torch.utils.data import DataLoader, Dataset\n    from torch import inference_mode\n\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\n    from transformers import AutoTokenizer, AutoModel, AutoConfig\n    from transformers import DataCollatorWithPadding\n    from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n    %env TOKENIZERS_PARALLELISM=false #true\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    \n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        score = sp.stats.pearsonr(y_true, y_pred)[0]\n        return score\n\n\n    def get_logger(filename=OUTPUT_DIR+'train'):\n        from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = get_logger()\n\n    def seed_everything(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        \n    seed_everything(seed=42)\n    # OOF\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df['score'].values\n    preds = oof_df['pred'].values\n    score = get_score(labels, preds)\n    LOGGER.info(f'CV Score: {score:<.4f}')\n    # Data Loading\n    # ====================================================\n    # Data Loading\n    # ====================================================\n    test = pd.read_csv(INPUT_DIR+'test.csv')\n    submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n    print(f\"test.shape: {test.shape}\")\n    print(f\"submission.shape: {submission.shape}\")\n    display(test.head())\n    display(submission.head())\n    # ====================================================\n    # CPC Data\n    # ====================================================\n    cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n    test['context_text'] = test['context'].map(cpc_texts)\n    display(test.head())\n    test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n    display(test.head())\n    # tokenizer\n    # ====================================================\n    # tokenizer\n    # ====================================================\n    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\n    # token_length付与\n    test['token_length']=CFG.tokenizer(test['text'].to_list(), max_length=CFG.max_len, truncation=True, return_length=True)['length']\n    test=test.sort_values('token_length')\n    test.head()\n    # Dataset\n    # ====================================================\n    # Dataset\n    # ====================================================\n    # def prepare_input(cfg, text):\n    #     inputs = cfg.tokenizer(text,\n    #                            add_special_tokens=True,\n    #                            max_length=cfg.max_len,\n    #                            padding=\"max_length\",\n    #                            return_offsets_mapping=False)\n    #     for k, v in inputs.items():\n    #         inputs[k] = torch.tensor(v, dtype=torch.long)\n    #     return inputs\n\n\n    class TestDataset(Dataset):\n        def __init__(self, cfg, df):\n            self.cfg = cfg\n            self.texts = df['text'].values\n\n        def __len__(self):\n            return len(self.texts)\n\n        def __getitem__(self, item):\n    #         inputs = prepare_input(self.cfg, self.texts[item])\n            inputs = self.texts[item]\n            return inputs\n\n    def collate_fn(data: \"list[str]\"\n                ) -> \"dict[str,torch.Tensor]\":\n        '''DataLoaderで使用するcollate_fn. Datasetの出力を受け取り、tensorの形に加工する関数。\n        ここでは、動的にpaddingを行うために使用している'''\n        texts = data\n        inputs = CFG.tokenizer(texts,\n                            add_special_tokens=True,\n                            max_length=CFG.max_len,\n                            truncation=True,\n                            return_offsets_mapping=False)\n        data_collator = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n        inputs = data_collator(inputs)\n        return inputs\n    # Model\n    # ====================================================\n    # Model\n    # ====================================================\n    class CustomModel(nn.Module):\n        def __init__(self, cfg, config_path=None, pretrained=False):\n            super().__init__()\n            self.cfg = cfg\n            if config_path is None:\n                self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            else:\n                self.config = torch.load(config_path)\n            if pretrained:\n                self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n            else:\n                self.model = AutoModel.from_config(self.config)\n            self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n            self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n            self._init_weights(self.fc)\n            self.attention = nn.Sequential(\n                nn.Linear(self.config.hidden_size, 512),\n                nn.Tanh(),\n                nn.Linear(512, 1),\n                nn.Softmax(dim=1)\n            )\n            self._init_weights(self.attention)\n            \n        def _init_weights(self, module):\n            if isinstance(module, nn.Linear):\n                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n                if module.bias is not None:\n                    module.bias.data.zero_()\n            elif isinstance(module, nn.Embedding):\n                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n                if module.padding_idx is not None:\n                    module.weight.data[module.padding_idx].zero_()\n            elif isinstance(module, nn.LayerNorm):\n                module.bias.data.zero_()\n                module.weight.data.fill_(1.0)\n            \n        def feature(self, inputs):\n            outputs = self.model(**inputs)\n            last_hidden_states = outputs[0]\n            # feature = torch.mean(last_hidden_states, 1)\n            weights = self.attention(last_hidden_states)\n            feature = torch.sum(weights * last_hidden_states, dim=1)\n            return feature\n\n        def forward(self, inputs):\n            feature = self.feature(inputs)\n            output = self.fc(self.fc_dropout(feature))\n            return output\n    # inference\n    # ====================================================\n    # inference\n    # ====================================================\n    @inference_mode()\n    def inference_fn(test_loader, model, device):\n        preds = []\n        model.eval()\n        model.to(device)\n        tk0 = tqdm(test_loader, total=len(test_loader))\n        for inputs in tk0:\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            y_preds = model(inputs)\n            preds.append(y_preds.sigmoid().to('cpu').numpy())\n        predictions = np.concatenate(preds)\n        return predictions\n    test_dataset = TestDataset(CFG, test)\n    test_loader = DataLoader(test_dataset,\n                            batch_size=CFG.batch_size,\n                            shuffle=False,\n                            num_workers=CFG.num_workers, pin_memory=True, drop_last=False,\n                            collate_fn=collate_fn)\n\n    import numpy as np\n    import pandas as pd\n\n    import re\n    import nltk\n    # nltk.download('stopwords')\n    # nltk.download('wordnet')\n    # nltk.download('omw-1.4')\n    from nltk.stem import PorterStemmer\n    from nltk.stem import WordNetLemmatizer\n\n    class PostProcess:\n        def __init__(self, df, options={}):\n            self.options = {\n                'fit_near_score_th': 0.005,\n                'normalizer': ('lemmatizer') # 'stemmer'\n            }\n            self.options.update(options)\n            self.df = df.copy()\n            self.predictions = []\n        \n        def add_predection(self, pred):\n            # shape => (36, 1)\n            self.predictions.append(pred.reshape(-1, 1))\n\n        def nanmean(self, preds):\n            return np.nanmean(preds, axis=0).reshape(-1)\n        \n        def equal_score_1(self, preds):\n            \"\"\"\n            単純に anchor == target は score 1.0 にする\n            \"\"\"\n            df = self.df.copy()\n            df['preds'] = preds\n            df.loc[df.anchor == df.target, ['preds']] = 1.0\n            return df['preds'].values\n        \n        def normalize_score_1(self, preds):\n            \"\"\"\n            normalizeした結果 == なら score を 1.0にする\n            \"\"\"\n            df = self.df.copy()\n            normalizer_options = self.options['normalizer']\n            lemmatizer = WordNetLemmatizer()\n            ps = PorterStemmer()\n            use_lemmatizer = 'lemmatizer' in normalizer_options\n            use_stemmer = 'stemmer' in normalizer_options\n            def normalize(word):\n                w = word.lower()\n                if use_lemmatizer:\n                    w = lemmatizer.lemmatize(w)\n                if use_stemmer:\n                    w = ps.stem(w)\n                return w\n            def normalize_words(word):\n                words = re.split(r'\\s+', word)\n                words = [normalize(t) for t in words]\n                return ' '.join(words)\n            an = df.anchor.map(normalize_words)\n            tn = df.target.map(normalize_words)\n            df['preds'] = preds\n            df.loc[an == tn, ['preds']] = 1.0\n            return df['preds'].values\n        \n        def fit_near_score(self, preds):\n            fit_n = self.options['fit_near_score_th']\n            def fit_score(pred):\n                if pred <= fit_n:\n                    return 0.0\n                elif pred >= (0.25 - fit_n) and pred <= (0.25 + fit_n):\n                    return 0.25\n                elif pred >= (0.5 - fit_n) and pred <= (0.5 + fit_n):\n                    return 0.5\n                elif pred >= (0.75 - fit_n) and pred <= (0.75 + fit_n):\n                    return 0.75\n                elif pred >= (1 - fit_n):\n                    return 1.0\n                return pred\n            vect = np.vectorize(fit_score)\n            return vect(preds)\n\n        def get_score(self, apply_funcs=['nanmean', 'equal_score_1', 'normalize_score_1', 'fit_near_score']):\n            preds = self.predictions\n            for funcname in apply_funcs:\n                fn = getattr(self, funcname)\n                preds = fn(preds)\n            return preds.reshape(-1, 1) # 提出形式に合わせる\n\n    post_process = PostProcess(df=test)\n\n\n    # predictions = []\n    for fold in CFG.trn_fold:\n        model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n        state = torch.load(CFG.path+f\"{CFG.ckpt_name}_fold{fold}_best.pth\",\n                        map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        post_process.add_predection(prediction)\n        # predictions.append(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    preds = post_process.get_score()\n    test['score'] = preds\n    return test[['id','score']]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T14:59:51.956611Z","iopub.execute_input":"2022-06-20T14:59:51.956976Z","iopub.status.idle":"2022-06-20T14:59:52.053509Z","shell.execute_reply.started":"2022-06-20T14:59:51.956946Z","shell.execute_reply":"2022-06-20T14:59:52.052657Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# submissions を結合する\nsubmission_114 = exp114().sort_values('id').reset_index(drop=True)\nsubmission_115 = exp115().sort_values('id').reset_index(drop=True)\n\nsubmission_124 = exp124().sort_values('id').reset_index(drop=True)\nsubmission_100 = exp100().sort_values('id').reset_index(drop=True)\nsubmission_099 = exp099().sort_values('id').reset_index(drop=True)\nsubmission_108 = exp108().sort_values('id').reset_index(drop=True)\n\n","metadata":{"papermill":{"duration":303.141171,"end_time":"2022-06-19T03:58:23.575868","exception":false,"start_time":"2022-06-19T03:53:20.434697","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T15:05:52.557141Z","iopub.execute_input":"2022-06-20T15:05:52.557955Z","iopub.status.idle":"2022-06-20T15:15:45.575581Z","shell.execute_reply.started":"2022-06-20T15:05:52.557923Z","shell.execute_reply":"2022-06-20T15:15:45.574639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 確認用\nprint('exp114')\ndisplay(submission_114[['id', 'score']].head())\nprint('exp115')\ndisplay(submission_115[['id', 'score']].head())\n\nprint('exp124')\ndisplay(submission_124[['id', 'score']].head())\nprint('exp100')\ndisplay(submission_100[['id', 'score']].head())\nprint('exp099')\ndisplay(submission_099[['id', 'score']].head())\nprint('exp108')\ndisplay(submission_108[['id', 'score']].head())\n\n\n","metadata":{"papermill":{"duration":0.031313,"end_time":"2022-06-19T03:58:23.61524","exception":false,"start_time":"2022-06-19T03:58:23.583927","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T15:15:45.577451Z","iopub.execute_input":"2022-06-20T15:15:45.577974Z","iopub.status.idle":"2022-06-20T15:15:45.62981Z","shell.execute_reply.started":"2022-06-20T15:15:45.577931Z","shell.execute_reply":"2022-06-20T15:15:45.628742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# sunのid,scoreを結合前と比較すること\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv').sort_values('id').reset_index(drop=True)\nsubmission['score'] = submission_099.score * 0.1147 \\\n                    + submission_100.score * 0.1383 \\\n                    + submission_108.score * 0.2260 \\\n                    + submission_124.score * 0.2202 \\\n                    + submission_115.score * 0.1738 \\\n                    + submission_114.score * 0.1270\ndisplay(submission.head())\nsubmission[['id','score']].to_csv('submission.csv',index=False)","metadata":{"papermill":{"duration":0.036026,"end_time":"2022-06-19T03:58:23.65996","exception":false,"start_time":"2022-06-19T03:58:23.623934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T16:08:38.06891Z","iopub.execute_input":"2022-06-20T16:08:38.069336Z","iopub.status.idle":"2022-06-20T16:08:38.093139Z","shell.execute_reply.started":"2022-06-20T16:08:38.069302Z","shell.execute_reply":"2022-06-20T16:08:38.092328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}