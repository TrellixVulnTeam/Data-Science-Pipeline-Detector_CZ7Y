{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# US Patent Phrase to Phrase Matching","metadata":{}},{"cell_type":"markdown","source":"* Updated June 5 5pm by Nabil Arnaoot\n* Submission to Kaggle Competition\n* By Mark Sosa, Norelle Liang, and Nabil Arnaoot\n* for Machine Learning class, MSBA Saint Mary's College April 22, 2022","metadata":{}},{"cell_type":"markdown","source":"### Summary and Dependencies\n\nThis notebook is set up to test and score many models very quickly, then choose a single one for submission to the competition.\n* When trying out many models, run it with the internet turned on.\n* After selecting the best model, use the companion notebook Model_Import_Notebook to create the datasets it needs to run without internet.\n\nWhen you've chosen the model you want to submit, add it to to Model_Import_Notebook and run it to download the datasets it needs.  Then in this notebook you need to + Add Data, look in your datasets, your notebook outputs, and grab the output from the Model_Import_Notebook.  At that point the code below should work.","metadata":{}},{"cell_type":"markdown","source":"### Gotchas\n\n* make sure you've imported the right datasets the right datasets-- sentencetransformers220 and whatever model you're using\n* the model you're using comes from the Model_Import_Notebook-- make sure you've run and saved that notebook, then loaded it as a dataset into this notebook\n* the other tricky bit is which dataset you're using-- if you're using the test dataset from the competition, you won't be able to calculate the model score.  turn that off in the function or you'll get an error message\n* if you're submitting the notebook, turn off internet and save it first\n","metadata":{}},{"cell_type":"markdown","source":"# Setup: import libraries, load & preprocess data.","metadata":{}},{"cell_type":"code","source":"# Import datasets and libraries\n\nimport numpy as np\nimport pandas as pd\n\nimport scipy\nfrom scipy import stats\n\ndf = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv')\ndf.head()\n\nimport sys\nsys.path.append('../input/sentencetransformers220/sentence-transformers-2.2.0')\nimport sentence_transformers\nfrom sentence_transformers import SentenceTransformer\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nfrom nltk import word_tokenize\n\nfrom unidecode import unidecode\n\nfrom sentence_transformers import SentenceTransformer, util","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:41:55.959516Z","iopub.execute_input":"2022-06-08T00:41:55.960461Z","iopub.status.idle":"2022-06-08T00:42:03.279795Z","shell.execute_reply.started":"2022-06-08T00:41:55.960367Z","shell.execute_reply":"2022-06-08T00:42:03.27885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pre-process data\n\ndef pre_process(corpus):\n    # convert input corpus to lower case.\n    corpus = corpus.lower()\n    # collecting a list of stop words from nltk and punctuation form\n    # string class and create single array.\n    stopset = stopwords.words('english') + list(string.punctuation)\n    # remove stop words and punctuations from string.\n    # word_tokenize is used to tokenize the input corpus in word tokens.\n    corpus = \" \".join([i for i in word_tokenize(corpus) if i not in stopset])\n    # remove non-ascii characters\n    corpus = unidecode(corpus)\n    return corpus\n\ndf['target'] = df['target'].apply(pre_process)\ndf['anchor'] = df['anchor'].apply(pre_process)\n\n# Grab the two columns we care about\n\ninput_anchor = df.anchor.to_list()\ninput_target = df.target.to_list()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:42:03.28367Z","iopub.execute_input":"2022-06-08T00:42:03.284633Z","iopub.status.idle":"2022-06-08T00:42:28.390024Z","shell.execute_reply.started":"2022-06-08T00:42:03.284599Z","shell.execute_reply":"2022-06-08T00:42:28.389076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare a function that will allow us to quickly test models.","metadata":{}},{"cell_type":"code","source":"# This function takes in a model name (must be available as input to run without internet)\n# and anchor and target and returns a list of all the new scores we have created\n# and the pearson score for the entire model (which is very close to the score \n# the leaderboard assigns)\n\ndef use_model(model_name, input_anchor, input_target):\n    model = SentenceTransformer(model_name)\n    anchor_vec = model.encode(input_anchor)\n    target_vec = model.encode(input_target)\n    cos_sim = []\n    for i in range(len(anchor_vec)):\n        sim = util.cos_sim(anchor_vec[i], target_vec[i])\n        cos_sim.append(sim[0][0].item())\n    cos_sim_model_score, p = scipy.stats.pearsonr(df.score, cos_sim)  \n    dot_sim = []\n    for i in range(len(anchor_vec)):\n        dsim = util.dot_score(anchor_vec[i], target_vec[i])\n        dot_sim.append(dsim[0][0].item())\n    dot_sim_model_score, p = scipy.stats.pearsonr(df.score, dot_sim)\n    return(cos_sim, cos_sim_model_score, dot_sim, dot_sim_model_score) \n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:42:28.395048Z","iopub.execute_input":"2022-06-08T00:42:28.397536Z","iopub.status.idle":"2022-06-08T00:42:28.411466Z","shell.execute_reply.started":"2022-06-08T00:42:28.397494Z","shell.execute_reply":"2022-06-08T00:42:28.409973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run a bunch of models and see which one has the best results.\n\nTurn on internet to run many models quickly, then find the best one for submission to the competition.\n* For this chosen model, we have to make it available without internet.\n* Add the chosen model to the copanion notebook Model_Import_Notebook, run that notebook to load the model, then load the resulting dataset into this model.\n* Use the chosen model for submission with interent turned off.\n* Before turning off the internet, change the cell below from code to markdown.\n\nModels selected from here:  https://www.sbert.net/docs/pretrained_models.html\n\nNote: the next cell is the longest one to run in this notebook.\n\n","metadata":{}},{"cell_type":"code","source":"# Try many models quickly (with internet turned on) and find the scores for each one.\n# Based on these scores, we'll choose which model to use for submission to the competition.\n\n# For each model we're testing: assign model name, then run function, grab generated scores for each row \n# and the overall model score\n\n# create an empty dataframe to hold model names and scores\nmodel_comparisons = pd.DataFrame(columns = ['Model', 'Cos_Sim_Model_Score', 'Dot_Model_Score'])\n\n# First model we're testing:\nmodel_name = 'all-mpnet-base-v2'\ncos_sim_function_results1, cos_sim_function_score, dot_sim_results1, dot_sim_model_score = use_model('sentence-transformers/' + model_name, input_anchor, input_target)\nmodel_comparisons = model_comparisons.append({'Model': model_name, 'Cos_Sim_Model_Score': cos_sim_function_score, \"Dot_Model_Score\": dot_sim_model_score}, ignore_index=True)\n\n# Next model we're testing:\nmodel_name = 'multi-qa-mpnet-base-dot-v1' \ncos_sim_function_results2, cos_sim_function_score, dot_sim_results2, dot_sim_model_score = use_model('sentence-transformers/' + model_name, input_anchor, input_target)\nmodel_comparisons = model_comparisons.append({'Model': model_name, 'Cos_Sim_Model_Score': cos_sim_function_score, \"Dot_Model_Score\": dot_sim_model_score}, ignore_index=True)\n\n\n# Next model we're testing:\nmodel_name = 'all-distilroberta-v1' \ncos_sim_function_results3, cos_sim_function_score, dot_sim_results3, dot_sim_model_score = use_model('sentence-transformers/' + model_name, input_anchor, input_target)\nmodel_comparisons = model_comparisons.append({'Model': model_name, 'Cos_Sim_Model_Score': cos_sim_function_score, \"Dot_Model_Score\": dot_sim_model_score}, ignore_index=True)\n\n# Next model we're testing:\nmodel_name = 'all-MiniLM-L12-v2' \ncos_sim_function_results4, cos_sim_function_score, dot_sim_results4, dot_sim_model_score = use_model('sentence-transformers/' + model_name, input_anchor, input_target)\nmodel_comparisons = model_comparisons.append({'Model': model_name, 'Cos_Sim_Model_Score': cos_sim_function_score, \"Dot_Model_Score\": dot_sim_model_score}, ignore_index=True)\n\n# Next model we're testing:\nmodel_name = 'all-MiniLM-L6-v2' \ncos_sim_function_results5, cos_sim_function_score, dot_sim_results5, dot_sim_model_score = use_model('sentence-transformers/' + model_name, input_anchor, input_target)\nmodel_comparisons = model_comparisons.append({'Model': model_name, 'Cos_Sim_Model_Score': cos_sim_function_score, \"Dot_Model_Score\": dot_sim_model_score}, ignore_index=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:42:28.413486Z","iopub.execute_input":"2022-06-08T00:42:28.414063Z","iopub.status.idle":"2022-06-08T00:50:07.627202Z","shell.execute_reply.started":"2022-06-08T00:42:28.414021Z","shell.execute_reply":"2022-06-08T00:50:07.625951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print results\nprint(\"\\n\\nYour results are:\")\nmodel_comparisons","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:50:07.628929Z","iopub.execute_input":"2022-06-08T00:50:07.629403Z","iopub.status.idle":"2022-06-08T00:50:07.661037Z","shell.execute_reply.started":"2022-06-08T00:50:07.629359Z","shell.execute_reply":"2022-06-08T00:50:07.658623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try an ensemble model by averaging the cos_sim results of the other 5\n\nr5 = np.array(cos_sim_function_results5)\nr4 = np.array(cos_sim_function_results4)\nr3 = np.array(cos_sim_function_results3)\nr2 = np.array(cos_sim_function_results2)\nr1 = np.array(cos_sim_function_results1)\navg = (r5 + r4 + r3 + r2 + r1)/5\n\navg_model_score, p = scipy.stats.pearsonr(df.score, avg)\nprint(\"Combining the cos sim scores of your five (cos_sim score) models gives you an accuracy of\", avg_model_score)\n\n\n# Try an ensemble model by averaging the dot results of the other 5\n\nd5 = np.array(dot_sim_results5)\nd4 = np.array(dot_sim_results4)\nd3 = np.array(dot_sim_results3)\nd2 = np.array(dot_sim_results2)\nd1 = np.array(dot_sim_results1)\navg_dot = (d5 + d4 + d3 + d2 + d1)/5\n\navg_model_score, p = scipy.stats.pearsonr(df.score, avg_dot)\nprint(\"Combining the cos sim scores of your five (dot_sim score) models gives you an accuracy of\", avg_model_score)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:50:07.662731Z","iopub.execute_input":"2022-06-08T00:50:07.663315Z","iopub.status.idle":"2022-06-08T00:50:07.762353Z","shell.execute_reply.started":"2022-06-08T00:50:07.66327Z","shell.execute_reply":"2022-06-08T00:50:07.759268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the chosen model without internet, then write the datafile for your submission.","metadata":{}},{"cell_type":"code","source":"model = SentenceTransformer(\"../input/model-import-notebook/all-mpnet-base-v2\")\nanchor_vec = model.encode(input_anchor)\ntarget_vec = model.encode(input_target)\ncos_sim = []\nfor i in range(len(anchor_vec)):\n    sim = util.cos_sim(anchor_vec[i], target_vec[i])\n    cos_sim.append(sim[0][0].item())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:50:07.763894Z","iopub.execute_input":"2022-06-08T00:50:07.764451Z","iopub.status.idle":"2022-06-08T00:50:47.506733Z","shell.execute_reply.started":"2022-06-08T00:50:07.764405Z","shell.execute_reply":"2022-06-08T00:50:47.505725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write the datafile for your submission\n\ndata = {'id': df.id, 'score': cos_sim}\nsubmission = pd.DataFrame(data)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:50:47.508055Z","iopub.execute_input":"2022-06-08T00:50:47.508704Z","iopub.status.idle":"2022-06-08T00:50:47.664387Z","shell.execute_reply.started":"2022-06-08T00:50:47.508659Z","shell.execute_reply":"2022-06-08T00:50:47.663495Z"},"trusted":true},"execution_count":null,"outputs":[]}]}