{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## U.S. Patent Phrase to Phrase Matching\n### Help Identify Similar Phrases in U.S. Patents\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/33657/logos/header.png?t=2022-02-23-06-26-59)","metadata":{}},{"cell_type":"markdown","source":"## Data Description\nIn this dataset, you are presented pairs of phrases (an anchor and a target phrase) and asked to rate how similar they are on a scale from 0 (not at all similar) to 1 (identical in meaning). This challenge differs from a standard semantic similarity task in that similarity has been scored here within a patent's context, specifically its CPC classification (version 2021.05), which indicates the subject to which the patent relates. For example, while the phrases \"bird\" and \"Cape Cod\" may have low semantic similarity in normal language, the likeness of their meaning is much closer if considered in the context of \"house\".\n\nThis is a code competition, in which you will submit code that will be run against an unseen test set. The unseen test set contains approximately 12k pairs of phrases. A small public test set has been provided for testing purposes, but is not used in scoring.\n\nInformation on the meaning of CPC codes may be found on the USPTO website. The CPC version 2021.05 can be found on the CPC archive website.\n\n## Score meanings\nThe scores are in the 0-1 range with increments of 0.25 with the following meanings:\n\n>- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n>- 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n>- 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n>- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n>- 0.0 - Unrelated.\n\n## Files\n>- train.csv - the training set, containing phrases, contexts, and their similarity scores\n>- test.csv - the test set set, identical in structure to the training set but without the score\n>- sample_submission.csv - a sample submission file in the correct format\n\n## Columns\n>- id - a unique identifier for a pair of phrases\n>- anchor - the first phrase\n>- target - the second phrase\n>- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n>- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n\n## CPC\nThe Cooperative Patent Classification (CPC) is a patent classification system, which has been jointly developed by the European Patent Office (EPO) and the United States Patent and Trademark Office (USPTO). The CPC is substantially based on the previous European classification system (ECLA), which itself was a more specific and detailed version of the International Patent Classification (IPC) system.\n\nEach classification term consists of a symbol such as \"A01B33/00\" (which represents \"tilling implements with rotary driven tools\"). The first letter is the \"section symbol\" consisting of a letter from \"A\" (\"Human Necessities\") to \"H\" (\"Electricity\") or \"Y\" for emerging cross-sectional technologies. This is followed by a two-digit number to give a \"class symbol\" (\"A01\" represents \"Agriculture; forestry; animal husbandry; trapping; fishing\"). The final letter makes up the \"subclass\" (A01B represents \"Soil working in agriculture or forestry, parts, details, or accessories of agricultural machines or implements, in general\"). The subclass is then followed by a 1- to 3-digit \"group\" number, an oblique stroke and a number of at least two digits representing a \"main group\" (\"00\") or \"subgroup\". A patent examiner assigns a classification to the patent application or other document at the most detailed level which is applicable to its contents.\n\n### Nomenclature:\n>- A: Human Necessities\n>- B: Operations and Transport\n>- C: Chemistry and Metallurgy\n>- D: Textiles\n>- E: Fixed Constructions\n>- F: Mechanical Engineering\n>- G: Physics\n>- H: Electricity\n>- Y: Emerging Cross-Sectional Technologies\n\n## Evaluation:\nSubmissions are evaluated on the Pearson correlation coefficient between the predicted and actual similarity scores","metadata":{}},{"cell_type":"markdown","source":"### If this notebook is helpful, feel free to upvote! :)\n\nReference notebooks used: \n>- https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train/notebook","metadata":{}},{"cell_type":"markdown","source":"## Import packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport os\nimport re\nimport time\nimport random\nimport scipy as sp\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tqdm import tqdm\ntqdm.pandas()\nimport plotly.express as px\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\nfrom sklearn import model_selection as sk_model_selection\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\nSEED=42\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:07:42.437163Z","iopub.execute_input":"2022-04-03T14:07:42.437435Z","iopub.status.idle":"2022-04-03T14:07:42.45363Z","shell.execute_reply.started":"2022-04-03T14:07:42.437402Z","shell.execute_reply":"2022-04-03T14:07:42.452845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest_data = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\nsample_submission_data = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.230891Z","iopub.execute_input":"2022-04-03T13:28:14.231159Z","iopub.status.idle":"2022-04-03T13:28:14.296204Z","shell.execute_reply.started":"2022-04-03T13:28:14.231121Z","shell.execute_reply":"2022-04-03T13:28:14.295473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DIR = './'","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.297408Z","iopub.execute_input":"2022-04-03T13:28:14.297754Z","iopub.status.idle":"2022-04-03T13:28:14.302087Z","shell.execute_reply.started":"2022-04-03T13:28:14.297694Z","shell.execute_reply":"2022-04-03T13:28:14.301152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"print(train_data.shape, train_data['id'].nunique(), train_data[['anchor','target','context']].drop_duplicates().shape[0])\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.304775Z","iopub.execute_input":"2022-04-03T13:28:14.305522Z","iopub.status.idle":"2022-04-03T13:28:14.346121Z","shell.execute_reply.started":"2022-04-03T13:28:14.305484Z","shell.execute_reply":"2022-04-03T13:28:14.345306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.347511Z","iopub.execute_input":"2022-04-03T13:28:14.34779Z","iopub.status.idle":"2022-04-03T13:28:14.370686Z","shell.execute_reply.started":"2022-04-03T13:28:14.347756Z","shell.execute_reply":"2022-04-03T13:28:14.369901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[(train_data['anchor'].str.strip()=='') | (train_data['context'].str.strip()=='') | (train_data['target'].str.strip()=='')]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.372032Z","iopub.execute_input":"2022-04-03T13:28:14.372341Z","iopub.status.idle":"2022-04-03T13:28:14.439343Z","shell.execute_reply.started":"2022-04-03T13:28:14.372305Z","shell.execute_reply":"2022-04-03T13:28:14.438596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['anchor'].nunique(), train_data['target'].nunique(), train_data['context'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.440395Z","iopub.execute_input":"2022-04-03T13:28:14.440632Z","iopub.status.idle":"2022-04-03T13:28:14.461242Z","shell.execute_reply.started":"2022-04-03T13:28:14.440597Z","shell.execute_reply":"2022-04-03T13:28:14.460631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.groupby(['anchor']).agg({'target':'nunique','context':'nunique'}).reset_index().sort_values(by = ['target'], ascending = False).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.462426Z","iopub.execute_input":"2022-04-03T13:28:14.462694Z","iopub.status.idle":"2022-04-03T13:28:14.492286Z","shell.execute_reply.started":"2022-04-03T13:28:14.462659Z","shell.execute_reply":"2022-04-03T13:28:14.491605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1 context can be associated with more than 1 anchor\ntrain_data.groupby(['context']).agg({'anchor':'nunique'}).reset_index().sort_values(by = ['anchor'], ascending = False).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.493373Z","iopub.execute_input":"2022-04-03T13:28:14.49359Z","iopub.status.idle":"2022-04-03T13:28:14.515362Z","shell.execute_reply.started":"2022-04-03T13:28:14.493558Z","shell.execute_reply":"2022-04-03T13:28:14.514684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[train_data['context']=='H01']","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.516506Z","iopub.execute_input":"2022-04-03T13:28:14.516752Z","iopub.status.idle":"2022-04-03T13:28:14.537029Z","shell.execute_reply.started":"2022-04-03T13:28:14.516702Z","shell.execute_reply":"2022-04-03T13:28:14.536372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_data.shape)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.538159Z","iopub.execute_input":"2022-04-03T13:28:14.538523Z","iopub.status.idle":"2022-04-03T13:28:14.549431Z","shell.execute_reply.started":"2022-04-03T13:28:14.538486Z","shell.execute_reply":"2022-04-03T13:28:14.548382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[~(test_data['anchor'].isin(train_data['anchor'].unique().tolist()))], test_data[~(test_data['target'].isin(train_data['target'].unique().tolist()))], test_data[~(test_data['context'].isin(train_data['context'].unique().tolist()))]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.550924Z","iopub.execute_input":"2022-04-03T13:28:14.551409Z","iopub.status.idle":"2022-04-03T13:28:14.580016Z","shell.execute_reply.started":"2022-04-03T13:28:14.551373Z","shell.execute_reply":"2022-04-03T13:28:14.579218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_target = 'inorganic photoconductor drum'\nprint('\\nTest data record:\\n')\ndisplay(test_data[test_data['target']==sample_target])\nprint('\\nTrain data record:\\n')\ndisplay(train_data[train_data['target']==sample_target])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.583524Z","iopub.execute_input":"2022-04-03T13:28:14.583714Z","iopub.status.idle":"2022-04-03T13:28:14.607329Z","shell.execute_reply.started":"2022-04-03T13:28:14.58369Z","shell.execute_reply":"2022-04-03T13:28:14.606609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if public test data is a sample drawn from train data\ntest_data[~(test_data['id'].isin(train_data['id'].unique().tolist()))]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.608512Z","iopub.execute_input":"2022-04-03T13:28:14.608772Z","iopub.status.idle":"2022-04-03T13:28:14.629831Z","shell.execute_reply.started":"2022-04-03T13:28:14.608738Z","shell.execute_reply":"2022-04-03T13:28:14.62918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_submission_data.shape)\nsample_submission_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.631509Z","iopub.execute_input":"2022-04-03T13:28:14.632104Z","iopub.status.idle":"2022-04-03T13:28:14.641954Z","shell.execute_reply.started":"2022-04-03T13:28:14.632068Z","shell.execute_reply":"2022-04-03T13:28:14.64126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train\n# ====================================================\n# CPC Data\n# ====================================================\ndef get_cpc_texts():\n    contexts = []\n    pattern = '[A-Z]\\d+'\n    for file_name in os.listdir('../input/cpc-data/CPCSchemeXML202105'):\n        result = re.findall(pattern, file_name)\n        if result:\n            contexts.append(result)\n    contexts = sorted(set(sum(contexts, [])))\n    results = {}\n    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n        with open(f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n            s = f.read()\n        pattern = f'{cpc}\\t\\t.+'\n        result = re.findall(pattern, s)\n        cpc_result = result[0].lstrip(pattern)\n        for context in [c for c in contexts if c[0] == cpc]:\n            pattern = f'{context}\\t\\t.+'\n            result = re.findall(pattern, s)\n            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n    return results\n\n\ncpc_texts = get_cpc_texts()\ntorch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\ntrain_data['context_text'] = train_data['context'].map(cpc_texts)\ntest_data['context_text'] = test_data['context'].map(cpc_texts)\ndisplay(train_data.head())\ndisplay(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:14.643186Z","iopub.execute_input":"2022-04-03T13:28:14.643616Z","iopub.status.idle":"2022-04-03T13:28:15.065339Z","shell.execute_reply.started":"2022-04-03T13:28:14.643582Z","shell.execute_reply":"2022-04-03T13:28:15.064618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[train_data['context_text'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:15.066596Z","iopub.execute_input":"2022-04-03T13:28:15.066853Z","iopub.status.idle":"2022-04-03T13:28:15.082367Z","shell.execute_reply.started":"2022-04-03T13:28:15.066817Z","shell.execute_reply":"2022-04-03T13:28:15.081482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['text'] = train_data['anchor'] + '[SEP]' + train_data['target'] + '[SEP]'  + train_data['context_text']\ntest_data['text'] = test_data['anchor'] + '[SEP]' + test_data['target'] + '[SEP]'  + test_data['context_text']\ndisplay(train_data.head())\ndisplay(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:15.083691Z","iopub.execute_input":"2022-04-03T13:28:15.084515Z","iopub.status.idle":"2022-04-03T13:28:15.128826Z","shell.execute_reply.started":"2022-04-03T13:28:15.084475Z","shell.execute_reply":"2022-04-03T13:28:15.12818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of # records","metadata":{}},{"cell_type":"code","source":"train_data['# Words in text'] = train_data['text'].apply(lambda x: len(x.split(' ')))\nfig = px.histogram(train_data, x='# Words in text', title = 'Distribution of text length')\npy.offline.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:15.129977Z","iopub.execute_input":"2022-04-03T13:28:15.130291Z","iopub.status.idle":"2022-04-03T13:28:15.52819Z","shell.execute_reply.started":"2022-04-03T13:28:15.130252Z","shell.execute_reply":"2022-04-03T13:28:15.527473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(train_data, x='score', title = 'Distribution of correlation score')\npy.offline.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:15.529185Z","iopub.execute_input":"2022-04-03T13:28:15.529407Z","iopub.status.idle":"2022-04-03T13:28:15.955222Z","shell.execute_reply.started":"2022-04-03T13:28:15.529378Z","shell.execute_reply":"2022-04-03T13:28:15.954574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_records_by_patent_category = train_data['context'].apply(lambda x: x[0]).value_counts().reset_index()\nnum_records_by_patent_category.columns = ['Category','# Records']\nfig = px.bar(num_records_by_patent_category.sort_values(by = ['# Records'], ascending = False), x='Category', y='# Records', title = 'Top patent categories by record count')\nfig.update_traces(marker_color='green')\npy.offline.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:15.956632Z","iopub.execute_input":"2022-04-03T13:28:15.957081Z","iopub.status.idle":"2022-04-03T13:28:16.068567Z","shell.execute_reply.started":"2022-04-03T13:28:15.957043Z","shell.execute_reply":"2022-04-03T13:28:16.067706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{"execution":{"iopub.status.busy":"2022-04-03T09:46:49.072819Z","iopub.execute_input":"2022-04-03T09:46:49.073552Z","iopub.status.idle":"2022-04-03T09:46:49.076466Z","shell.execute_reply.started":"2022-04-03T09:46:49.073508Z","shell.execute_reply":"2022-04-03T09:46:49.075845Z"}}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:16.070099Z","iopub.execute_input":"2022-04-03T13:28:16.070375Z","iopub.status.idle":"2022-04-03T13:28:16.078489Z","shell.execute_reply.started":"2022-04-03T13:28:16.070337Z","shell.execute_reply":"2022-04-03T13:28:16.077563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    apex=True\n    print_freq=100\n    num_workers=4\n    model=\"microsoft/deberta-v3-large\"\n    scheduler='cosine' # ['linear', 'cosine']\n    batch_scheduler=True\n    num_cycles=0.5\n    num_warmup_steps=0\n    epochs=4\n    encoder_lr=2e-5\n    decoder_lr=2e-5\n    min_lr=1e-6\n    eps=1e-6\n    betas=(0.9, 0.999)\n    batch_size=16\n    fc_dropout=0.2\n    target_size=1\n    max_len=512\n    weight_decay=0.01\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=SEED\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]\n    train=True","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:16.080336Z","iopub.execute_input":"2022-04-03T13:28:16.080639Z","iopub.status.idle":"2022-04-03T13:28:16.089153Z","shell.execute_reply.started":"2022-04-03T13:28:16.080587Z","shell.execute_reply":"2022-04-03T13:28:16.088182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.model)\ntokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\nCFG.tokenizer = tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:16.090638Z","iopub.execute_input":"2022-04-03T13:28:16.091142Z","iopub.status.idle":"2022-04-03T13:28:19.809652Z","shell.execute_reply.started":"2022-04-03T13:28:16.091104Z","shell.execute_reply":"2022-04-03T13:28:19.808866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Define max_len\n# ====================================================\nlengths_dict = {}\n\nlengths = []\ntk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\nfor text in tk0:\n    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n    lengths.append(length)\nlengths_dict['context_text'] = lengths\n\nfor text_col in ['anchor', 'target']:\n    lengths = []\n    tk0 = tqdm(train_data[text_col].fillna(\"\").values, total=len(train_data))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n        lengths.append(length)\n    lengths_dict[text_col] = lengths\n    \nCFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\nCFG.max_len","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:19.812687Z","iopub.execute_input":"2022-04-03T13:28:19.812915Z","iopub.status.idle":"2022-04-03T13:28:26.233231Z","shell.execute_reply.started":"2022-04-03T13:28:19.812888Z","shell.execute_reply":"2022-04-03T13:28:26.232514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Text:', train_data['text'].iloc[0])\nprint('\\nTokenizer output\\n')\ntokenizer(train_data['text'].iloc[0], add_special_tokens=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.234593Z","iopub.execute_input":"2022-04-03T13:28:26.235012Z","iopub.status.idle":"2022-04-03T13:28:26.245445Z","shell.execute_reply.started":"2022-04-03T13:28:26.234972Z","shell.execute_reply":"2022-04-03T13:28:26.24446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n        self.labels = df['score'].values\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        label = torch.tensor(self.labels[item], dtype=torch.float)\n        return inputs, label","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.246594Z","iopub.execute_input":"2022-04-03T13:28:26.247403Z","iopub.status.idle":"2022-04-03T13:28:26.256164Z","shell.execute_reply.started":"2022-04-03T13:28:26.247365Z","shell.execute_reply":"2022-04-03T13:28:26.255319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train/notebook\n# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 256),\n            nn.Tanh(),\n            nn.Linear(256, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.259052Z","iopub.execute_input":"2022-04-03T13:28:26.259274Z","iopub.status.idle":"2022-04-03T13:28:26.274862Z","shell.execute_reply.started":"2022-04-03T13:28:26.259244Z","shell.execute_reply":"2022-04-03T13:28:26.274084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train()\n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    for step, (inputs, labels) in enumerate(train_loader):\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            y_preds = model(inputs)\n        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            global_step += 1\n            if CFG.batch_scheduler:\n                scheduler.step()\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.8f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (inputs, labels) in enumerate(valid_loader):\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        losses.update(loss.item(), batch_size)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    predictions = np.concatenate(predictions)\n    return losses.avg, predictions\n\n\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.277825Z","iopub.execute_input":"2022-04-03T13:28:26.278419Z","iopub.status.idle":"2022-04-03T13:28:26.303606Z","shell.execute_reply.started":"2022-04-03T13:28:26.278381Z","shell.execute_reply":"2022-04-03T13:28:26.302878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['score'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.304831Z","iopub.execute_input":"2022-04-03T13:28:26.305485Z","iopub.status.idle":"2022-04-03T13:28:26.31686Z","shell.execute_reply.started":"2022-04-03T13:28:26.305447Z","shell.execute_reply":"2022-04-03T13:28:26.31597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_data['score'].describe())\ntrain_data['score bin'] = pd.cut(train_data['score'], 5)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_data, \n    test_size=0.1, \n    random_state=SEED,\n    stratify = train_data['score'])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.318134Z","iopub.execute_input":"2022-04-03T13:28:26.318447Z","iopub.status.idle":"2022-04-03T13:28:26.357214Z","shell.execute_reply.started":"2022-04-03T13:28:26.31841Z","shell.execute_reply":"2022-04-03T13:28:26.356574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['score bin'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.358515Z","iopub.execute_input":"2022-04-03T13:28:26.359004Z","iopub.status.idle":"2022-04-03T13:28:26.367298Z","shell.execute_reply.started":"2022-04-03T13:28:26.358968Z","shell.execute_reply":"2022-04-03T13:28:26.36639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_train['score'].describe())\ndisplay(df_valid['score'].describe())","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.368911Z","iopub.execute_input":"2022-04-03T13:28:26.369534Z","iopub.status.idle":"2022-04-03T13:28:26.384092Z","shell.execute_reply.started":"2022-04-03T13:28:26.369492Z","shell.execute_reply":"2022-04-03T13:28:26.38335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(CFG, df_train)\nvalid_dataset = TrainDataset(CFG, df_valid)\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=CFG.batch_size,\n                          shuffle=True,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\nvalid_loader = DataLoader(valid_dataset,\n                          batch_size=CFG.batch_size,\n                          shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n# ====================================================\n# model & optimizer\n# ====================================================\nmodel = CustomModel(CFG, config_path=None, pretrained=True)\ntorch.save(model.config, OUTPUT_DIR+'config.pth')\nmodel.to(device)\n\ndef get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': weight_decay},\n        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': 0.0},\n        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n         'lr': decoder_lr, 'weight_decay': 0.0}\n    ]\n    return optimizer_parameters\n\noptimizer_parameters = get_optimizer_params(model,\n                                            encoder_lr=CFG.encoder_lr, \n                                            decoder_lr=CFG.decoder_lr,\n                                            weight_decay=CFG.weight_decay)\noptimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n\n# ====================================================\n# scheduler\n# ====================================================\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    if cfg.scheduler == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n        )\n    elif cfg.scheduler == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n        )\n    return scheduler\n\nnum_train_steps = int(len(df_train) / CFG.batch_size * CFG.epochs)\nscheduler = get_scheduler(CFG, optimizer, num_train_steps)\n\ncriterion = nn.BCEWithLogitsLoss(reduction=\"mean\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:28:26.385382Z","iopub.execute_input":"2022-04-03T13:28:26.385838Z","iopub.status.idle":"2022-04-03T13:28:34.276239Z","shell.execute_reply.started":"2022-04-03T13:28:26.385804Z","shell.execute_reply":"2022-04-03T13:28:34.275491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training & validation","metadata":{}},{"cell_type":"code","source":"valid_labels = df_valid['score'].values","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:04:38.387456Z","iopub.execute_input":"2022-04-03T14:04:38.387743Z","iopub.status.idle":"2022-04-03T14:04:38.393528Z","shell.execute_reply.started":"2022-04-03T14:04:38.387695Z","shell.execute_reply":"2022-04-03T14:04:38.392103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_score = np.inf\n\nfor epoch in range(CFG.epochs):\n\n    start_time = time.time()\n\n    # train\n    avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n    # eval\n    avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n\n    # scoring\n    score = get_score(valid_labels, predictions)\n\n    elapsed = time.time() - start_time\n\n    print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n    print(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n    if best_score > score:\n        best_score = score\n        print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n        torch.save({'model': model.state_dict(),\n                    'predictions': predictions},\n                    OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\")\n        \n    # Save model for every epoch\n    torch.save({'model': model.state_dict(),\n                'predictions': predictions},\n                OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_epoch_{epoch}.pth\")\n\npredictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\", \n                         map_location=torch.device('cpu'))['predictions']\n\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:07:48.934132Z","iopub.execute_input":"2022-04-03T14:07:48.934393Z","iopub.status.idle":"2022-04-03T14:07:54.704521Z","shell.execute_reply.started":"2022-04-03T14:07:48.934365Z","shell.execute_reply":"2022-04-03T14:07:54.703682Z"},"trusted":true},"execution_count":null,"outputs":[]}]}