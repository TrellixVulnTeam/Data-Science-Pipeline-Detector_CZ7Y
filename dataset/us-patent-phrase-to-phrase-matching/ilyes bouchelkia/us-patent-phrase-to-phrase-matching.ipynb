{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-20T20:02:55.268594Z","iopub.execute_input":"2022-06-20T20:02:55.268854Z","iopub.status.idle":"2022-06-20T20:02:55.292529Z","shell.execute_reply.started":"2022-06-20T20:02:55.268827Z","shell.execute_reply":"2022-06-20T20:02:55.291705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom PIL import Image\nfrom tqdm import tqdm\nfrom scipy import stats\nfrom collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel, get_linear_schedule_with_warmup\nfrom wordcloud import WordCloud\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:02:55.464659Z","iopub.execute_input":"2022-06-20T20:02:55.464905Z","iopub.status.idle":"2022-06-20T20:03:01.81156Z","shell.execute_reply.started":"2022-06-20T20:02:55.464878Z","shell.execute_reply":"2022-06-20T20:03:01.81082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1- reading data**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:01.813157Z","iopub.execute_input":"2022-06-20T20:03:01.813412Z","iopub.status.idle":"2022-06-20T20:03:01.817638Z","shell.execute_reply.started":"2022-06-20T20:03:01.813363Z","shell.execute_reply":"2022-06-20T20:03:01.816856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\")\ndf_test=pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\")\ndf_submission=pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:01.819447Z","iopub.execute_input":"2022-06-20T20:03:01.82001Z","iopub.status.idle":"2022-06-20T20:03:01.926093Z","shell.execute_reply.started":"2022-06-20T20:03:01.819962Z","shell.execute_reply":"2022-06-20T20:03:01.925244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### df_ train","metadata":{}},{"cell_type":"code","source":"df_train.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:01.928303Z","iopub.execute_input":"2022-06-20T20:03:01.928581Z","iopub.status.idle":"2022-06-20T20:03:01.951043Z","shell.execute_reply.started":"2022-06-20T20:03:01.928547Z","shell.execute_reply":"2022-06-20T20:03:01.95029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**data shape**","metadata":{}},{"cell_type":"code","source":"print(f\"train shape :{df_train.shape}\")\nprint(f\"test shape:{df_test.shape}\")\nprint(f\"df_submission shape:{df_submission.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:01.952271Z","iopub.execute_input":"2022-06-20T20:03:01.952606Z","iopub.status.idle":"2022-06-20T20:03:01.958515Z","shell.execute_reply.started":"2022-06-20T20:03:01.95257Z","shell.execute_reply":"2022-06-20T20:03:01.957675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"number of row in target :{df_train.target.shape}\")\nprint(f\"unique values in target :{df_train.target.nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:01.96035Z","iopub.execute_input":"2022-06-20T20:03:01.960608Z","iopub.status.idle":"2022-06-20T20:03:01.980236Z","shell.execute_reply.started":"2022-06-20T20:03:01.960575Z","shell.execute_reply":"2022-06-20T20:03:01.979437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"missing values :{df_train.isnull().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:01.98165Z","iopub.execute_input":"2022-06-20T20:03:01.981897Z","iopub.status.idle":"2022-06-20T20:03:02.001963Z","shell.execute_reply.started":"2022-06-20T20:03:01.981864Z","shell.execute_reply":"2022-06-20T20:03:02.001137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### df_test","metadata":{}},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.003286Z","iopub.execute_input":"2022-06-20T20:03:02.004056Z","iopub.status.idle":"2022-06-20T20:03:02.016826Z","shell.execute_reply.started":"2022-06-20T20:03:02.004017Z","shell.execute_reply":"2022-06-20T20:03:02.016066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.01794Z","iopub.execute_input":"2022-06-20T20:03:02.018604Z","iopub.status.idle":"2022-06-20T20:03:02.033235Z","shell.execute_reply.started":"2022-06-20T20:03:02.018567Z","shell.execute_reply":"2022-06-20T20:03:02.032558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Missing values**","metadata":{}},{"cell_type":"markdown","source":"# **2-EXPLORATORY DATA ANALYSIS (EDA)**","metadata":{}},{"cell_type":"markdown","source":"### Score ","metadata":{}},{"cell_type":"code","source":"df_train[\"score\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.036161Z","iopub.execute_input":"2022-06-20T20:03:02.036556Z","iopub.status.idle":"2022-06-20T20:03:02.042812Z","shell.execute_reply.started":"2022-06-20T20:03:02.036527Z","shell.execute_reply":"2022-06-20T20:03:02.042138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.score.unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.043985Z","iopub.execute_input":"2022-06-20T20:03:02.044754Z","iopub.status.idle":"2022-06-20T20:03:02.054308Z","shell.execute_reply.started":"2022-06-20T20:03:02.044706Z","shell.execute_reply":"2022-06-20T20:03:02.053436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the count of each value in score\nsns.countplot(x='score', data=df_train, palette='Set3')\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.055589Z","iopub.execute_input":"2022-06-20T20:03:02.055955Z","iopub.status.idle":"2022-06-20T20:03:02.347512Z","shell.execute_reply.started":"2022-06-20T20:03:02.055918Z","shell.execute_reply":"2022-06-20T20:03:02.346288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the\nnumber_one=len(df_train[df_train[\"score\"]==1])\nnumber_0=len(df_train[df_train[\"score\"]==0])\nnumber_between=len(df_train[df_train[\"score\"]!=0]) and len(df_train[df_train[\"score\"]!=1])\n#define data\ndata = [number_one,number_0,number_between]\nlabels = ['Number of Rows having a score of 1 ', 'Number of Rows having a score of 0 ', 'Number of Rows having a score between 0 and 1  ']\n\n#define Seaborn color palette to use\ncolors = sns.color_palette('pastel')[0:5]\nprint(f\"Number of Rows having a score between 0 and 1: {number_between}\")\nprint(f\"Number of Rows having a score of 0: {number_0}\")\nprint(f\"Number of Rows having a score of 1: {number_one}\")\n\n#create pie chart\nplt.pie(data, labels = labels, colors = colors, autopct='%.0f%%',textprops={'color':\"w\"})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.351985Z","iopub.execute_input":"2022-06-20T20:03:02.35238Z","iopub.status.idle":"2022-06-20T20:03:02.555948Z","shell.execute_reply.started":"2022-06-20T20:03:02.35233Z","shell.execute_reply":"2022-06-20T20:03:02.555153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### anchor","metadata":{}},{"cell_type":"code","source":"print(f\"number of row in anchor :{df_train.anchor.shape}\")\nprint(f\"unique values in anchor:{df_train.anchor.nunique()}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.559673Z","iopub.execute_input":"2022-06-20T20:03:02.559925Z","iopub.status.idle":"2022-06-20T20:03:02.584506Z","shell.execute_reply.started":"2022-06-20T20:03:02.559888Z","shell.execute_reply":"2022-06-20T20:03:02.583817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.585671Z","iopub.execute_input":"2022-06-20T20:03:02.586319Z","iopub.status.idle":"2022-06-20T20:03:02.614343Z","shell.execute_reply.started":"2022-06-20T20:03:02.586281Z","shell.execute_reply":"2022-06-20T20:03:02.613439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most commun phrases (anchor) ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 6))\n\nax=df_train.groupby('anchor')['id'].count().sort_values(ascending=False).head(50).plot(kind='bar',color = list('rgbkymc'))\nfor container in ax.containers:\n    ax.bar_label(container)\nplt.title(\"top 50 anchor in data\")\n#plt.xticks(rotation=60)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:02.61797Z","iopub.execute_input":"2022-06-20T20:03:02.618223Z","iopub.status.idle":"2022-06-20T20:03:03.650855Z","shell.execute_reply.started":"2022-06-20T20:03:02.618188Z","shell.execute_reply":"2022-06-20T20:03:03.650158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud= WordCloud(stopwords=STOPWORDS, max_font_size=80, max_words=5000,\n                      width = 600, height = 400,\n                      background_color='black').generate(' '.join(txt for txt in df_train[\"anchor\"]))\nfig, ax = plt.subplots(figsize=(14,10))\nax.imshow(wordcloud, interpolation='bilinear')\nax.set_axis_off()\nplt.imshow(wordcloud);","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:03.651893Z","iopub.execute_input":"2022-06-20T20:03:03.652207Z","iopub.status.idle":"2022-06-20T20:03:05.258337Z","shell.execute_reply.started":"2022-06-20T20:03:03.652179Z","shell.execute_reply":"2022-06-20T20:03:05.257676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### target","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\ntar=df_train.groupby('target')['id'].count().sort_values(ascending= False).head(50).plot(kind='bar',color=list('rgbkymc'))\n\nfor countainr in tar.containers:\n    tar.bar_label(countainr)\n    \nplt.title(\"top 50 target in data\")\n\nplt.show()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:05.259563Z","iopub.execute_input":"2022-06-20T20:03:05.259924Z","iopub.status.idle":"2022-06-20T20:03:06.245678Z","shell.execute_reply.started":"2022-06-20T20:03:05.259888Z","shell.execute_reply":"2022-06-20T20:03:06.243583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"\"\"\"\"\nwordcloud = wordcloud.WordCloud(stopwords=wordcloud.STOPWORDS, max_font_size=80, max_words=5000,\n                      width = 600, height = 400,\n                      background_color='black').generate(' '.join(txt for txt in df_train[\"target\"]))\nfig, ax = plt.subplots(figsize=(14,10))\nax.imshow(wordcloud, interpolation='bilinear')\nax.set_axis_off()\nplt.imshow(wordcloud);\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:38:43.583609Z","iopub.execute_input":"2022-05-15T04:38:43.584384Z","iopub.status.idle":"2022-05-15T04:38:43.604473Z","shell.execute_reply.started":"2022-05-15T04:38:43.584326Z","shell.execute_reply":"2022-05-15T04:38:43.6035Z"}}},{"cell_type":"markdown","source":"### contex","metadata":{}},{"cell_type":"code","source":"df_train['context'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:06.247219Z","iopub.execute_input":"2022-06-20T20:03:06.247508Z","iopub.status.idle":"2022-06-20T20:03:06.257295Z","shell.execute_reply.started":"2022-06-20T20:03:06.247471Z","shell.execute_reply":"2022-06-20T20:03:06.256074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\ncon=df_train.groupby('context')['id'].count().sort_values(ascending=False).head(50).plot(kind='bar',color=list('rgbkymc'))\n\nfor container in con.containers:\n    con.bar_label(container)\n    \nplt.title(\"top 50 context in data\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:06.258798Z","iopub.execute_input":"2022-06-20T20:03:06.259394Z","iopub.status.idle":"2022-06-20T20:03:07.034861Z","shell.execute_reply.started":"2022-06-20T20:03:06.259274Z","shell.execute_reply":"2022-06-20T20:03:07.03419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"like we see in this graph the first letter in the context ih assigned to the \"section\" this is followed with two number who represent the \" class symbol\"","metadata":{}},{"cell_type":"code","source":"df_train[\"section\"]=df_train['context'].astype(str).str[0]\ndf_train['class']=df_train['context'].astype(str).str[1:]\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:07.036061Z","iopub.execute_input":"2022-06-20T20:03:07.036744Z","iopub.status.idle":"2022-06-20T20:03:07.097508Z","shell.execute_reply.started":"2022-06-20T20:03:07.036705Z","shell.execute_reply":"2022-06-20T20:03:07.096804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### score","metadata":{}},{"cell_type":"code","source":"df_train.score.value_counts().sort_index().plot(kind='bar',title=\"Score\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:07.098764Z","iopub.execute_input":"2022-06-20T20:03:07.099162Z","iopub.status.idle":"2022-06-20T20:03:07.281092Z","shell.execute_reply.started":"2022-06-20T20:03:07.099124Z","shell.execute_reply":"2022-06-20T20:03:07.280409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# new notebook","metadata":{}},{"cell_type":"code","source":"cpc = pd.read_csv('../input/cpc-codes/titles.csv')\ncpc.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:07.282424Z","iopub.execute_input":"2022-06-20T20:03:07.282681Z","iopub.status.idle":"2022-06-20T20:03:08.427964Z","shell.execute_reply.started":"2022-06-20T20:03:07.282646Z","shell.execute_reply":"2022-06-20T20:03:08.427228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc = cpc.rename(columns = {\"code\" : \"context\"})\ntrain_df = pd.merge(df_train, cpc[[\"context\",\"title\"]], on =\"context\", how = \"left\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.429351Z","iopub.execute_input":"2022-06-20T20:03:08.429607Z","iopub.status.idle":"2022-06-20T20:03:08.587345Z","shell.execute_reply.started":"2022-06-20T20:03:08.429573Z","shell.execute_reply":"2022-06-20T20:03:08.586541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(x):\n    t = x.lower()\n    t = t.replace(\"[\",'')\n    t = t.replace(\";\",'')\n    t = t.replace(\",\",'')\n    t = t.replace(\"]\",'')\n    t = t.replace(\":\",'')\n    return t\n\ntrain_df['title'] = train_df['title'].apply(lambda x: clean(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.588806Z","iopub.execute_input":"2022-06-20T20:03:08.589073Z","iopub.status.idle":"2022-06-20T20:03:08.651166Z","shell.execute_reply.started":"2022-06-20T20:03:08.589037Z","shell.execute_reply":"2022-06-20T20:03:08.650385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['sen1'] = train_df['anchor'].astype('str')+' '+train_df['title'].astype('str')\ntrain_df = train_df.drop(['anchor','context','title'],axis=1)\n# train_df['all_sen'] = train_df['sen1']+' [SEP '+train_df['target']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.652472Z","iopub.execute_input":"2022-06-20T20:03:08.652792Z","iopub.status.idle":"2022-06-20T20:03:08.68719Z","shell.execute_reply.started":"2022-06-20T20:03:08.652755Z","shell.execute_reply":"2022-06-20T20:03:08.68639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(train_df[['target','sen1']],train_df['score'],random_state=1234,test_size=0.3)\nprint(x_train.shape,x_test.shape)\nprint(y_train.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.688537Z","iopub.execute_input":"2022-06-20T20:03:08.688856Z","iopub.status.idle":"2022-06-20T20:03:08.704714Z","shell.execute_reply.started":"2022-06-20T20:03:08.688818Z","shell.execute_reply":"2022-06-20T20:03:08.704036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.709187Z","iopub.execute_input":"2022-06-20T20:03:08.7097Z","iopub.status.idle":"2022-06-20T20:03:08.720255Z","shell.execute_reply.started":"2022-06-20T20:03:08.709668Z","shell.execute_reply":"2022-06-20T20:03:08.719424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.721795Z","iopub.execute_input":"2022-06-20T20:03:08.722202Z","iopub.status.idle":"2022-06-20T20:03:08.733775Z","shell.execute_reply.started":"2022-06-20T20:03:08.72214Z","shell.execute_reply":"2022-06-20T20:03:08.733135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.735087Z","iopub.execute_input":"2022-06-20T20:03:08.735334Z","iopub.status.idle":"2022-06-20T20:03:08.743198Z","shell.execute_reply.started":"2022-06-20T20:03:08.735301Z","shell.execute_reply":"2022-06-20T20:03:08.742472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport transformers\nfrom torch.nn.utils.clip_grad import clip_grad_norm\n\n\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.74488Z","iopub.execute_input":"2022-06-20T20:03:08.745309Z","iopub.status.idle":"2022-06-20T20:03:08.804893Z","shell.execute_reply.started":"2022-06-20T20:03:08.745248Z","shell.execute_reply":"2022-06-20T20:03:08.804116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.806515Z","iopub.execute_input":"2022-06-20T20:03:08.806764Z","iopub.status.idle":"2022-06-20T20:03:08.813051Z","shell.execute_reply.started":"2022-06-20T20:03:08.806729Z","shell.execute_reply":"2022-06-20T20:03:08.812279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class my_model(nn.Module):\n    def __init__(self,bert_path):\n        super(my_model,self).__init__()\n        self.bert_path = bert_path\n        self.bert = transformers.AutoModel.from_pretrained(self.bert_path)\n        self.fc_layer = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(1024,1),\n            nn.Sigmoid()\n        )\n    def forward(self,ids,mask,token_type_ids):\n        out = self.bert(input_ids=ids,attention_mask=mask,token_type_ids=token_type_ids,return_dict=True)\n        pooler_output = out.get('pooler_output')\n        bo = self.fc_layer(pooler_output)\n        return bo","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.814516Z","iopub.execute_input":"2022-06-20T20:03:08.814827Z","iopub.status.idle":"2022-06-20T20:03:08.82435Z","shell.execute_reply.started":"2022-06-20T20:03:08.814791Z","shell.execute_reply":"2022-06-20T20:03:08.823603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class my_dataset_train:\n    def __init__(self,text1,text2,label,tokenizer,max_len):\n        self.text1=text1\n        self.text2=text2\n        self.label=label\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.text1)\n    \n    def __getitem__(self,idx):\n        text_1 = str(self.text1[idx])\n        text_2 = str(self.text2[idx])\n        label = self.label[idx]\n        \n        inputs = self.tokenizer(\n            text_1,\n            text_2,\n            add_special_tokens=True,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len,\n            return_attention_mask=True\n        )\n        \n        ids = inputs['input_ids']\n        token_type_ids = inputs[\"token_type_ids\"]\n        mask = inputs['attention_mask']\n        \n        padding_len = self.max_len - len(ids)\n        ids = ids + ([0]*padding_len)\n        token_type_ids = token_type_ids + ([0]*padding_len)\n        mask = mask + ([0]*padding_len)\n        \n        return {\n            \"ids\": torch.tensor(ids,dtype=torch.long),\n            \"mask\": torch.tensor(mask,dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids,dtype=torch.long),\n            \"targets\": torch.tensor(label,dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.826307Z","iopub.execute_input":"2022-06-20T20:03:08.826663Z","iopub.status.idle":"2022-06-20T20:03:08.837562Z","shell.execute_reply.started":"2022-06-20T20:03:08.826621Z","shell.execute_reply":"2022-06-20T20:03:08.836636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len=128\ntrain_batch_size = 16\nepochs=4\nbert_path = '../input/bert-for-patents/bert-for-patents'\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(bert_path)\n\n# Training dataset prep\n\ntrain_text1 = list(x_train['target'].values)\ntrain_text2 = list(x_train['sen1'].values)\ntrain_label = list(y_train.values)\n\ntrain_dataset = my_dataset_train(\n    text1 = train_text1,\n    text2 = train_text2,\n    label = train_label,\n    tokenizer=tokenizer ,\n    max_len=max_len\n)\n\ntrain_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size,shuffle=True)\n\n# validation dataset prep\nval_text1 = list(x_test['target'].values)\nval_text2 = list(x_test['sen1'].values)\nval_label = list(y_test.values)\n\nvalid_dataset = my_dataset_train(\n    text1 = val_text1,\n    text2 = val_text2,\n    label = val_label,\n    tokenizer=tokenizer,\n    max_len=max_len\n    )\n\nvalid_data_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=train_batch_size,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:08.838631Z","iopub.execute_input":"2022-06-20T20:03:08.838929Z","iopub.status.idle":"2022-06-20T20:03:09.040058Z","shell.execute_reply.started":"2022-06-20T20:03:08.838892Z","shell.execute_reply":"2022-06-20T20:03:09.039348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, scheduler, loss_function, epochs,train_dataloader, device, clip_value=2):\n    model.train()\n    for epoch in range(epochs):\n#         print(epoch)\n#         print(\"-----\")\n        best_loss = []\n        for step, batch in enumerate(train_dataloader): \n            batch_inputs, batch_masks, batch_labels = batch['ids'].to(device), batch['mask'].to(device), batch['targets'].to(device)\n            batch_token_type_ids = batch['token_type_ids'].to(device)\n            model.zero_grad()\n            outputs = model(batch_inputs, batch_masks, batch_token_type_ids)\n            loss = loss_function(outputs.squeeze(),batch_labels.squeeze())\n            best_loss.append(loss)\n            loss.backward()\n            clip_grad_norm(model.parameters(), clip_value)\n            optimizer.step()\n            scheduler.step()\n#             print(f\"step > {step},loss > {loss}\")\n        loss2 = sum(best_loss)/len(best_loss)\n        print(f'Epoch : {epoch} ,Train loss : {loss2}')\n                \n    return model\n\ndef r2_score(outputs, labels):\n    labels_mean = torch.mean(labels)\n    ss_tot = torch.sum((labels - labels_mean) ** 2)\n    ss_res = torch.sum((labels - outputs) ** 2)\n    r2 = 1 - ss_res / ss_tot\n    return r2\ndef evaluate(model,loss_function,test_dataloader,device):\n    model.eval()\n    test_loss, test_r2 = [], []\n    for step,batch in enumerate(test_dataloader):\n        batch_inputs, batch_masks, batch_labels = batch['ids'].to(device), batch['mask'].to(device), batch['targets'].to(device)\n        batch_token_type_ids = batch['token_type_ids'].to(device)\n        with torch.no_grad():\n            outputs = model(batch_inputs, batch_masks, batch_token_type_ids)\n        loss = loss_function(outputs, batch_labels)\n        test_loss.append(loss.item())\n        r2 = r2_score(outputs, batch_labels)\n        test_r2.append(r2.item())\n    return test_loss, test_r2","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:09.04122Z","iopub.execute_input":"2022-06-20T20:03:09.041491Z","iopub.status.idle":"2022-06-20T20:03:09.056114Z","shell.execute_reply.started":"2022-06-20T20:03:09.041457Z","shell.execute_reply":"2022-06-20T20:03:09.055433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:09.059428Z","iopub.execute_input":"2022-06-20T20:03:09.059641Z","iopub.status.idle":"2022-06-20T20:03:09.066032Z","shell.execute_reply.started":"2022-06-20T20:03:09.059611Z","shell.execute_reply":"2022-06-20T20:03:09.065341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train_steps = len(train_data_loader) * epochs\n\nmodel = my_model(bert_path).to(device)\n\noptimizer = transformers.AdamW(model.parameters(),lr=3e-5,eps=1e-8)\n\nscheduler = transformers.get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_train_steps\n)\n\nloss_function = nn.MSELoss()\n\n\nmodel = train(model, optimizer, scheduler, loss_function, epochs,train_data_loader, device)\n\n\nloss1,r2_ = evaluate(model,loss_function,valid_data_loader,device)\n\nloss = sum(loss1)/len(loss1)\nr2 = sum(r2_)/len(r2_)\nprint(f\"eval mean result : loss {loss}, r2 {r2}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:03:09.067496Z","iopub.execute_input":"2022-06-20T20:03:09.068855Z","iopub.status.idle":"2022-06-20T21:17:04.58655Z","shell.execute_reply.started":"2022-06-20T20:03:09.068826Z","shell.execute_reply":"2022-06-20T21:17:04.585332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),f'./my_bert')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T21:17:04.587851Z","iopub.status.idle":"2022-06-20T21:17:04.588241Z","shell.execute_reply.started":"2022-06-20T21:17:04.588028Z","shell.execute_reply":"2022-06-20T21:17:04.588051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')\ntest_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc = pd.read_csv('../input/cpc-codes/titles.csv')\ncpc = cpc.rename(columns = {\"code\" : \"context\"})\ntest_df = pd.merge(test_df, cpc[[\"context\",\"title\"]], on =\"context\", how = \"left\")\n\ndef clean(x):\n    t = x.lower()\n    t = t.replace(\"[\",'')\n    t = t.replace(\";\",'')\n    t = t.replace(\",\",'')\n    t = t.replace(\"]\",'')\n    t = t.replace(\":\",'')\n    return t\ntest_df['title'] = test_df['title'].apply(lambda x: clean(x))\ntest_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['sen1'] = test_df['anchor'].astype('str')+' '+test_df['title'].astype('str')\ntest_df = test_df.drop(['anchor','context','title'],axis=1)\ntest_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class my_dataset_test:\n    def __init__(self,text1,text2,idf,tokenizer,max_len):\n        self.text1=text1\n        self.text2=text2\n        self.idf = idf\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.text1)\n    \n    def __getitem__(self,idx):\n        text_1 = str(self.text1[idx])\n        text_2 = str(self.text2[idx])\n        idf = self.idf[idx]\n        \n        inputs = self.tokenizer(\n            text_1,\n            text_2,\n            add_special_tokens=True,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len,\n            return_attention_mask=True\n        )\n        \n        ids = inputs['input_ids']\n        token_type_ids = inputs[\"token_type_ids\"]\n        mask = inputs['attention_mask']\n        padding_len = self.max_len - len(ids)\n        ids = ids + ([0]*padding_len)\n        token_type_ids = token_type_ids + ([0]*padding_len)\n        mask = mask + ([0]*padding_len)\n        \n        return {\n            \"ids\": torch.tensor(ids,dtype=torch.long),\n            \"mask\": torch.tensor(mask,dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids,dtype=torch.long),\n            \"idf\": idf\n        }\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text1 = list(test_df['target'].values)\ntest_text2 = list(test_df['sen1'].values)\n\ntest_dataset = my_dataset_test(\n    text1 = test_text1,\n    text2 = test_text2,\n    idf=list(test_df['id'].values),\n    tokenizer=tokenizer,\n    max_len=max_len\n)\n\ntest_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model,test_dataloader,device):\n    model.eval()\n    result = []\n    for step,batch in enumerate(test_dataloader):\n        batch_inputs, batch_masks = batch['ids'].to(device), batch['mask'].to(device)\n        batch_token_type_ids = batch['token_type_ids'].to(device)\n        with torch.no_grad():\n            outputs = model(batch_inputs, batch_masks, batch_token_type_ids)\n        out = [i[0] for i in outputs.cpu().detach().numpy()]\n        batch_idf = batch['idf']\n        temp = [[i,j] for i,j in zip(batch_idf,out)]\n        result.extend(temp)\n    return result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = my_model(bert_path).to(device)\nmodel.load_state_dict(torch.load('my_bert'))\n\nfinal_res = predict(model,test_data_loader,device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_res\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv = pd.DataFrame(final_res,columns=['id','score'])\nsubmit_csv.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv.to_csv('submission.csv',index=False)\n","metadata":{},"execution_count":null,"outputs":[]}]}