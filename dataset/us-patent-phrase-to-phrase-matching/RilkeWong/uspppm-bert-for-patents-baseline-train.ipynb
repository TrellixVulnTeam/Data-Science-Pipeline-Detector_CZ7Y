{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT for Patents Baseline\n\n- [kfold strategy](https://www.kaggle.com/code/abhishek/phrase-matching-folds)\n- Utilize [Cooperative Patent Classification Codes Meaning](https://www.kaggle.com/datasets/xhlulu/cpc-codes)\n- reference [phantivia'Notebook](https://www.kaggle.com/code/phantivia/uspppm-huggingface-train-inference-baseline)\n- [BERT for Patents](https://www.kaggle.com/datasets/ksork6s4/bert-for-patents) from [huggingface page](https://huggingface.co/anferico/bert-for-patents)\n\n\n### Please refer to [Inference Notebook](https://www.kaggle.com/code/ksork6s4/uspppm-bert-for-patents-baseline-inference/edit/run/91272728) as well.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport shutil\n\nfrom torch.utils.data import DataLoader, Dataset\nimport datasets, transformers\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:48:33.416492Z","iopub.execute_input":"2022-05-30T08:48:33.41674Z","iopub.status.idle":"2022-05-30T08:48:41.26779Z","shell.execute_reply.started":"2022-05-30T08:48:33.416667Z","shell.execute_reply":"2022-05-30T08:48:41.267098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n    #model_path = '../input/deberta-v3-large/deberta-v3-large/'\n    model_path = '../input/deberta-v3-large-us-patent-cpc'\n    \n    learning_rate = 2e-5\n    weight_decay = 0.01\n    num_fold = 5\n    epochs = 5\n    batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:48:44.772027Z","iopub.execute_input":"2022-05-30T08:48:44.772556Z","iopub.status.idle":"2022-05-30T08:48:44.776927Z","shell.execute_reply.started":"2022-05-30T08:48:44.772515Z","shell.execute_reply":"2022-05-30T08:48:44.776147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preproc","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{CFG.input_path}train.csv\")\ntitles = pd.read_csv('../input/cpc-codes/titles.csv')\ntrain_df = train_df.merge(titles, left_on='context', right_on='code')\n\n# https://www.kaggle.com/code/abhishek/phrase-matching-folds\ndef create_folds(data, num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"fold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    # data = data.sample(frac=1).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    # num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"score\"], bins=5, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'fold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:48:52.554086Z","iopub.execute_input":"2022-05-30T08:48:52.55435Z","iopub.status.idle":"2022-05-30T08:48:53.427567Z","shell.execute_reply.started":"2022-05-30T08:48:52.55432Z","shell.execute_reply":"2022-05-30T08:48:53.426816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['input'] = train_df['title']+' '+train_df['anchor']\ntrain_df = create_folds(train_df, CFG.num_fold)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:48:59.162697Z","iopub.execute_input":"2022-05-30T08:48:59.163013Z","iopub.status.idle":"2022-05-30T08:48:59.224842Z","shell.execute_reply.started":"2022-05-30T08:48:59.162977Z","shell.execute_reply":"2022-05-30T08:48:59.224133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:49:02.833627Z","iopub.execute_input":"2022-05-30T08:49:02.834157Z","iopub.status.idle":"2022-05-30T08:49:02.840845Z","shell.execute_reply.started":"2022-05-30T08:49:02.834118Z","shell.execute_reply":"2022-05-30T08:49:02.839982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:49:04.529359Z","iopub.execute_input":"2022-05-30T08:49:04.529898Z","iopub.status.idle":"2022-05-30T08:49:04.551765Z","shell.execute_reply.started":"2022-05-30T08:49:04.529859Z","shell.execute_reply":"2022-05-30T08:49:04.551134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:49:16.024939Z","iopub.execute_input":"2022-05-30T08:49:16.025192Z","iopub.status.idle":"2022-05-30T08:49:16.723114Z","shell.execute_reply.started":"2022-05-30T08:49:16.025162Z","shell.execute_reply":"2022-05-30T08:49:16.722366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        self.inputs = df['input'].values.astype(str)\n        self.targets = df['target'].values.astype(str)\n        self.label = df['score'].values\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, item):\n        inputs = self.inputs[item]\n        targets = self.targets[item]\n        label = self.label[item]\n        \n        return {\n        **tokenizer( inputs, targets ),\n        'label':label.astype(np.float32)\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:49:19.912904Z","iopub.execute_input":"2022-05-30T08:49:19.913161Z","iopub.status.idle":"2022-05-30T08:49:19.923293Z","shell.execute_reply.started":"2022-05-30T08:49:19.913132Z","shell.execute_reply":"2022-05-30T08:49:19.922108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.reshape(len(predictions))\n    return {\n        'pearson': np.corrcoef(predictions, labels)[0][1]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:49:23.514803Z","iopub.execute_input":"2022-05-30T08:49:23.515053Z","iopub.status.idle":"2022-05-30T08:49:23.519609Z","shell.execute_reply.started":"2022-05-30T08:49:23.515025Z","shell.execute_reply":"2022-05-30T08:49:23.518673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env JOBLIB_TEMP_FOLDER=/tmp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df = pd.DataFrame()\nfor fold in range(CFG.num_fold):\n    \n    tr_data = train_df[train_df['fold']!=fold].reset_index(drop=True)\n    va_data = train_df[train_df['fold']==fold].reset_index(drop=True)\n    tr_dataset = TrainDataset(tr_data)\n    va_dataset = TrainDataset(va_data)\n    \n    args = TrainingArguments(\n        output_dir=f\"/tmp/uspppm\",\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=CFG.learning_rate,\n        per_device_train_batch_size=CFG.batch_size,\n        per_device_eval_batch_size=CFG.batch_size,\n        num_train_epochs=CFG.epochs,\n        weight_decay=CFG.weight_decay,\n        metric_for_best_model=\"pearson\",\n        load_best_model_at_end=True,\n        save_total_limit = 6,\n        save_steps=4000\n    )\n    \n    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=tr_dataset,\n        eval_dataset=va_dataset,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics\n    )\n    \n    trainer.train()\n    shutil.rmtree(f\"/tmp/uspppm\")\n    trainer.save_model(f\"uspppm_{fold}\")\n    \n    outputs = trainer.predict(va_dataset)\n    predictions = outputs.predictions.reshape(-1)\n    va_data['preds'] = predictions\n    oof_df = pd.concat([oof_df, va_data])","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:50:40.814699Z","iopub.execute_input":"2022-05-30T08:50:40.814961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = oof_df['preds'].values\nlabel = oof_df['score'].values\neval_pred = predictions, label\ncompute_metrics(eval_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df.to_csv('oof_df.csv')\nprint('the end of training bert for patents...')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}