{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### If this notebook is helpful, please upvote [the original version](https://www.kaggle.com/code/leehann/inference-bert-for-uspatents)! (score: 0.8392)\n\n### Version 2-8: \n\n```\n# === add np.median ===\n\nadd_preds = []\nfor x in zip(*upd_predictions):\n    add_preds.append(np.median(x, axis=0))\n    \nupd_predictions.append(add_preds)\n\n# === add np.mean ===\n\n[...]\n```\n\n### I am trying to improve my score: 0.8393\n\n### Version 9: \n\n```\ndef _upd_score_between(data, thresholds, value):\n    mask_th = data.between(*thresholds, inclusive='both')\n    data[mask_th] = value\n\n\ndef upd_score(data, th_dict=None):\n    [...]\n    if th0:\n        if isinstance(th0, float):\n            th0 = (result.min(), th0)\n        \n        if isinstance(th0, tuple):\n            _upd_score_between(result, th0, 0)\n    \n    if th25 and isinstance(th25, tuple):\n        _upd_score_between(result, th25, 0.25)\n\n    [...]\n```\n\n#### Calibrate scores (use thresholds)\n\n```\nthresholds_dict = {       # between(min_x, max_x, inclusive='both')\n    '0': 0.02,            # (min_x, max_x) or X -> (data.min(), X)\n    '.25': (0.24, 0.26),  # (min_x, max_x)\n    '.50': (0.49, 0.51),  # (min_x, max_x)\n    '.75': (0.74, 0.76),  # (min_x, max_x)\n    '1': 0.98             # (min_x, max_x) or X -> (x, data.max())\n}\n\nsubmission['score'] = upd_score(submission['score'], thresholds_dict)\n\n```","metadata":{}},{"cell_type":"markdown","source":"# 1. Import & Set & Def & Load","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-27T12:18:31.174438Z","iopub.execute_input":"2022-05-27T12:18:31.174868Z","iopub.status.idle":"2022-05-27T12:18:33.863502Z","shell.execute_reply.started":"2022-05-27T12:18:31.174772Z","shell.execute_reply":"2022-05-27T12:18:33.86278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_DEB_SIMPLE:\n    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n    model_path = '../input/deberta-v3-large/deberta-v3-large'\n    batch_size = 24\n    num_workers = 2\n    num_fold = 4\n    max_input_length = 130","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-27T12:18:33.865285Z","iopub.execute_input":"2022-05-27T12:18:33.865669Z","iopub.status.idle":"2022-05-27T12:18:33.870148Z","shell.execute_reply.started":"2022-05-27T12:18:33.865632Z","shell.execute_reply":"2022-05-27T12:18:33.869479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, tokenizer, max_input_length):\n        self.text = df['text'].values.astype(str)\n        self.tokenizer = tokenizer\n        self.max_input_length = max_input_length\n        \n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        inputs = self.text[item]\n        \n        inputs = self.tokenizer(inputs,\n                    max_length=self.max_input_length,\n                    padding='max_length',\n                    truncation=True)\n        \n        return torch.as_tensor(inputs['input_ids'], dtype=torch.long), \\\n               torch.as_tensor(inputs['token_type_ids'], dtype=torch.long), \\\n               torch.as_tensor(inputs['attention_mask'], dtype=torch.long)\n    \n    \nclass Custom_Bert_Simple(nn.Module):\n    def __init__(self, model_path):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_path)\n        config.num_labels = 1\n        self.base = AutoModelForSequenceClassification.from_config(config=config)\n        dim = config.hidden_size\n        self.dropout = nn.Dropout(p=0)\n        self.cls = nn.Linear(dim,1)\n        \n    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n        base_output = self.base(input_ids=input_ids,\n                                attention_mask=attention_mask,\n                                token_type_ids=token_type_ids\n        )\n\n        return base_output[0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-27T12:18:33.8715Z","iopub.execute_input":"2022-05-27T12:18:33.871785Z","iopub.status.idle":"2022-05-27T12:18:33.883294Z","shell.execute_reply.started":"2022-05-27T12:18:33.871725Z","shell.execute_reply":"2022-05-27T12:18:33.882498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, device):\n    model.eval()\n    preds = []\n    labels = []\n    \n    for step, batch in enumerate(valid_loader):\n        input_ids, token_type_ids, attention_mask = [i.to(device) for i in batch]\n    \n        with torch.no_grad():\n            y_preds = model(input_ids, attention_mask, token_type_ids)\n        \n        preds.append(y_preds.to('cpu').numpy())\n    \n    predictions = np.concatenate(preds)\n    \n    return predictions\n\n\nmin_max_scaler = MinMaxScaler()\n\ndef upd_outputs(data, is_trim=True, is_minmax=True, is_reshape=True):\n    \"\"\"\\o/\"\"\"\n    if is_trim == True:\n        data = np.where(data <=0, 0, data)\n        data = np.where(data >=1, 1, data)\n\n    if is_minmax ==True:\n        data = min_max_scaler.fit_transform(data)\n    \n    if is_reshape == True:\n        data = data.reshape(-1)\n        \n    return data\n\n\ndef _upd_score_between(data, thresholds, value):\n    \"\"\"\\o/\"\"\"\n    mask_th = data.between(*thresholds, inclusive='both')\n    data[mask_th] = value\n\n\ndef upd_score(data, th_dict=None):\n    \"\"\"\\o/\"\"\"\n    if isinstance(data, pd.Series):\n        result = data.copy()\n    else:\n        return data\n\n    if not th_dict:        \n        th_dict = {\n            '0': 0.02,\n            '.25': (0.24, 0.26),\n            '.50': (0.49, 0.51),\n            '.75': (0.74, 0.76),\n            '1': 0.98\n        }\n\n    if isinstance(th_dict, dict):    \n        th0 = th_dict.get('0')\n        th25 = th_dict.get('.25')\n        th50 = th_dict.get('.50')\n        th75 = th_dict.get('.75')\n        th100 = th_dict.get('1')\n    else:\n        return data\n    \n    if th0:\n        if isinstance(th0, float):\n            th0 = (result.min(), th0)\n        \n        if isinstance(th0, tuple):\n            _upd_score_between(result, th0, 0)\n    \n    if th25 and isinstance(th25, tuple):\n        _upd_score_between(result, th25, 0.25)\n\n    if th50 and isinstance(th50, tuple):\n        _upd_score_between(result, th50, 0.50)\n            \n    if th75 and isinstance(th75, tuple):\n        _upd_score_between(result, th75, 0.75)\n            \n    if th100:\n        if isinstance(th100, float):\n            th100 = (th100, result.max())\n        \n        if isinstance(th100, tuple):\n            _upd_score_between(result, th100, 1)\n\n    return result","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-27T12:18:33.885385Z","iopub.execute_input":"2022-05-27T12:18:33.885848Z","iopub.status.idle":"2022-05-27T12:18:33.902517Z","shell.execute_reply.started":"2022-05-27T12:18:33.885801Z","shell.execute_reply":"2022-05-27T12:18:33.901802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{CFG_DEB_SIMPLE.input_path}test.csv\")\ntitles = pd.read_csv('../input/cpc-codes/titles.csv')\ntest_df = test_df.merge(titles, left_on='context', right_on='code')\n\ncpc_texts = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")\n\ntest_df['context_text'] = test_df['context'].map(cpc_texts)\ntest_df['text'] = test_df['anchor'] + '[SEP]' + test_df['target'] + '[SEP]'  + test_df['context_text']\ntest_df['text'] = test_df['text'].apply(str.lower)\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:18:33.903755Z","iopub.execute_input":"2022-05-27T12:18:33.904201Z","iopub.status.idle":"2022-05-27T12:18:34.73259Z","shell.execute_reply.started":"2022-05-27T12:18:33.904166Z","shell.execute_reply":"2022-05-27T12:18:34.731868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Extract & Update Predictions","metadata":{}},{"cell_type":"code","source":"tokenizer_deberta_v3 = AutoTokenizer.from_pretrained(CFG_DEB_SIMPLE.model_path)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-27T12:18:34.733891Z","iopub.execute_input":"2022-05-27T12:18:34.734137Z","iopub.status.idle":"2022-05-27T12:18:35.48363Z","shell.execute_reply.started":"2022-05-27T12:18:34.734103Z","shell.execute_reply":"2022-05-27T12:18:35.482834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\nte_dataset = TestDataset(test_df, tokenizer_deberta_v3, CFG_DEB_SIMPLE.max_input_length)\nte_dataloader = DataLoader(te_dataset,\n                              batch_size=CFG_DEB_SIMPLE.batch_size, shuffle=False,\n                              num_workers=CFG_DEB_SIMPLE.num_workers,\n                              pin_memory=True, drop_last=False)\n\ndeberta_simple_path = \"../input/us-patent-deberta-simple/microsoft_deberta-v3-large\"\n\nfor fold in tqdm(range(CFG_DEB_SIMPLE.num_fold)):\n    fold_path = f\"{deberta_simple_path}_best{fold}.pth\"\n    \n    model = Custom_Bert_Simple(CFG_DEB_SIMPLE.model_path)\n    model.load_state_dict(torch.load(fold_path)['model'])\n    model.to('cuda')\n    \n    prediction = valid_fn(te_dataloader, model, 'cuda')\n    \n    predictions.append(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:18:35.484967Z","iopub.execute_input":"2022-05-27T12:18:35.485239Z","iopub.status.idle":"2022-05-27T12:20:26.388079Z","shell.execute_reply.started":"2022-05-27T12:18:35.485209Z","shell.execute_reply":"2022-05-27T12:20:26.387258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"folds:\", len(predictions))\nprint(\"rows: \", len(predictions[0]))\nprint(\"score:\", predictions[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.389803Z","iopub.execute_input":"2022-05-27T12:20:26.390121Z","iopub.status.idle":"2022-05-27T12:20:26.397435Z","shell.execute_reply.started":"2022-05-27T12:20:26.390075Z","shell.execute_reply":"2022-05-27T12:20:26.396636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_predictions = 14","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.398905Z","iopub.execute_input":"2022-05-27T12:20:26.399838Z","iopub.status.idle":"2022-05-27T12:20:26.406636Z","shell.execute_reply.started":"2022-05-27T12:20:26.399786Z","shell.execute_reply":"2022-05-27T12:20:26.405876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first fold\npredictions[0][:n_predictions]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.410927Z","iopub.execute_input":"2022-05-27T12:20:26.411143Z","iopub.status.idle":"2022-05-27T12:20:26.419151Z","shell.execute_reply.started":"2022-05-27T12:20:26.411117Z","shell.execute_reply":"2022-05-27T12:20:26.418249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(*upd_outputs(predictions[0], is_trim=False)[:n_predictions])\n# print(*upd_outputs(predictions[0], is_minmax=False)[:n_predictions])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.420577Z","iopub.execute_input":"2022-05-27T12:20:26.420861Z","iopub.status.idle":"2022-05-27T12:20:26.427625Z","shell.execute_reply.started":"2022-05-27T12:20:26.420825Z","shell.execute_reply":"2022-05-27T12:20:26.426835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.where(x<=0, 0, x) .. >> min_max.fit_transform(x) >> x.reshape(-1)\nupd_predictions = [upd_outputs(x, is_trim=False) for x in predictions]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.430463Z","iopub.execute_input":"2022-05-27T12:20:26.430743Z","iopub.status.idle":"2022-05-27T12:20:26.437996Z","shell.execute_reply.started":"2022-05-27T12:20:26.430634Z","shell.execute_reply":"2022-05-27T12:20:26.437219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(*upd_predictions[0][:n_predictions])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.439189Z","iopub.execute_input":"2022-05-27T12:20:26.43951Z","iopub.status.idle":"2022-05-27T12:20:26.452597Z","shell.execute_reply.started":"2022-05-27T12:20:26.439474Z","shell.execute_reply":"2022-05-27T12:20:26.451739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Additional & Final Predictions","metadata":{}},{"cell_type":"code","source":"origin_predictions = upd_predictions.copy()  # 5. Visualization","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.454001Z","iopub.execute_input":"2022-05-27T12:20:26.454247Z","iopub.status.idle":"2022-05-27T12:20:26.458687Z","shell.execute_reply.started":"2022-05-27T12:20:26.454213Z","shell.execute_reply":"2022-05-27T12:20:26.457764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === add np.median ===\nadd_preds = []\nfor x in zip(*upd_predictions):\n    add_preds.append(np.median(x, axis=0))\n    \nupd_predictions.append(add_preds)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.460401Z","iopub.execute_input":"2022-05-27T12:20:26.460713Z","iopub.status.idle":"2022-05-27T12:20:26.471625Z","shell.execute_reply.started":"2022-05-27T12:20:26.460675Z","shell.execute_reply":"2022-05-27T12:20:26.470746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === add np.mean ===\nadd_preds = []\nfor x in zip(*upd_predictions):\n    add_preds.append(np.mean(x, axis=0))\n    \nupd_predictions.append(add_preds)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.47339Z","iopub.execute_input":"2022-05-27T12:20:26.474146Z","iopub.status.idle":"2022-05-27T12:20:26.479779Z","shell.execute_reply.started":"2022-05-27T12:20:26.47411Z","shell.execute_reply":"2022-05-27T12:20:26.47899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = np.mean(upd_predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.482146Z","iopub.execute_input":"2022-05-27T12:20:26.482381Z","iopub.status.idle":"2022-05-27T12:20:26.488778Z","shell.execute_reply.started":"2022-05-27T12:20:26.482351Z","shell.execute_reply":"2022-05-27T12:20:26.48813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(*final_predictions[:n_predictions])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.490092Z","iopub.execute_input":"2022-05-27T12:20:26.490396Z","iopub.status.idle":"2022-05-27T12:20:26.499792Z","shell.execute_reply.started":"2022-05-27T12:20:26.490358Z","shell.execute_reply":"2022-05-27T12:20:26.498892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Create & Calibrate Submissions","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_df['id'],\n    'score': final_predictions,\n})\n\nsubmission.head(14)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.501592Z","iopub.execute_input":"2022-05-27T12:20:26.502026Z","iopub.status.idle":"2022-05-27T12:20:26.51499Z","shell.execute_reply.started":"2022-05-27T12:20:26.501829Z","shell.execute_reply":"2022-05-27T12:20:26.514083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds_dict = {\n    '0': 0.02,\n    '.25': (0.24, 0.26),\n    '.50': (0.49, 0.51),\n    '.75': (0.74, 0.76),\n    '1': 0.98\n}\n\nsubmission['score'] = upd_score(submission['score'], thresholds_dict)\n\nsubmission.head(14)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.516384Z","iopub.execute_input":"2022-05-27T12:20:26.516966Z","iopub.status.idle":"2022-05-27T12:20:26.539367Z","shell.execute_reply.started":"2022-05-27T12:20:26.516909Z","shell.execute_reply":"2022-05-27T12:20:26.53858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.540695Z","iopub.execute_input":"2022-05-27T12:20:26.540995Z","iopub.status.idle":"2022-05-27T12:20:26.549164Z","shell.execute_reply.started":"2022-05-27T12:20:26.540936Z","shell.execute_reply":"2022-05-27T12:20:26.548448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Visualization origin_predictions","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\ncm = sns.light_palette('green', as_cmap=True)\nprops_param = \"color:white; font-weight:bold; background-color:green;\"\npd.set_option('display.precision', 10)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-27T12:20:26.550669Z","iopub.execute_input":"2022-05-27T12:20:26.551074Z","iopub.status.idle":"2022-05-27T12:20:26.626809Z","shell.execute_reply.started":"2022-05-27T12:20:26.551039Z","shell.execute_reply":"2022-05-27T12:20:26.626065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(origin_predictions).T.head(15)\ndf = df.rename_axis(columns='folds', index='rows')\n\ndf.style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.630349Z","iopub.execute_input":"2022-05-27T12:20:26.632772Z","iopub.status.idle":"2022-05-27T12:20:26.769429Z","shell.execute_reply.started":"2022-05-27T12:20:26.632728Z","shell.execute_reply":"2022-05-27T12:20:26.768767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.style.highlight_quantile(q_left=0.75, axis=1, color='green')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.770613Z","iopub.execute_input":"2022-05-27T12:20:26.770976Z","iopub.status.idle":"2022-05-27T12:20:26.804146Z","shell.execute_reply.started":"2022-05-27T12:20:26.770929Z","shell.execute_reply":"2022-05-27T12:20:26.803403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.assign(mean=lambda x: x.mean(axis=1)) \\\n    .style.highlight_max(axis=1, props=props_param)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.807883Z","iopub.execute_input":"2022-05-27T12:20:26.809571Z","iopub.status.idle":"2022-05-27T12:20:26.845623Z","shell.execute_reply.started":"2022-05-27T12:20:26.809528Z","shell.execute_reply":"2022-05-27T12:20:26.845004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sub(df.mean(axis=1), axis=0) \\\n    .style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:20:26.848886Z","iopub.execute_input":"2022-05-27T12:20:26.849296Z","iopub.status.idle":"2022-05-27T12:20:26.884812Z","shell.execute_reply.started":"2022-05-27T12:20:26.849259Z","shell.execute_reply":"2022-05-27T12:20:26.884197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}