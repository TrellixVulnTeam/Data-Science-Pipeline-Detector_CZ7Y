{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Analysis and using models from three notebooks\n\n**1.** Deberta v3 large (0.8392)\n> [Inference BERT for usPatents](https://www.kaggle.com/code/leehann/inference-bert-for-uspatents)\n\n**2.** Deberta v3 large (0.8338)\n> [PPPM / Deberta-v3-large baseline [inference]](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n\n**3.** Roberta-large (0.8143)\n> [PatentPhrase RoBERTa Inference](https://www.kaggle.com/code/santhoshkumarv/patentphrase-roberta-inference-lb-0-814)\n\n#### Please upvote the original notebooks!\n\n## UPD: I have an error in my code (Version 1)!\n\nMethod merge in model 1 shuffled the dataframe.\n\n```\ntest = test.merge(titles, left_on='context', right_on='code')\n```\n\nSo I reseted index, merged, sorted and drop index.\n\n```\ntest.reset_index(inplace=True)\ntest = test.merge(titles, left_on='context', right_on='code')\ntest.sort_values(by='index', inplace=True)\ntest.drop(columns='index', inplace=True)\n```","metadata":{}},{"cell_type":"markdown","source":"# 1. Import & Def & Set & Load","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom dataclasses import dataclass\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T00:00:43.750934Z","iopub.execute_input":"2022-06-02T00:00:43.751262Z","iopub.status.idle":"2022-06-02T00:00:51.299718Z","shell.execute_reply.started":"2022-06-02T00:00:43.751185Z","shell.execute_reply":"2022-06-02T00:00:51.298992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True    \n    torch.backends.cudnn.benchmark = False\n\n    \ndef inference_fn(test_loader, model, device, is_sigmoid=True):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    \n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n            \n        with torch.no_grad():\n            output = model(inputs)\n        \n        if is_sigmoid == True:\n            preds.append(output.sigmoid().to('cpu').numpy())\n        else:\n            preds.append(output.to('cpu').numpy())\n\n    return np.concatenate(preds)    \n    \n\ndef upd_outputs(data, is_trim=False, is_minmax=False, is_reshape=False):\n    min_max_scaler = MinMaxScaler()\n    \n    if is_trim == True:\n        data = np.where(data <=0, 0, data)\n        data = np.where(data >=1, 1, data)\n\n    if is_minmax ==True:\n        data = min_max_scaler.fit_transform(data)\n    \n    if is_reshape == True:\n        data = data.reshape(-1)\n        \n    return data\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T00:00:51.301333Z","iopub.execute_input":"2022-06-02T00:00:51.30155Z","iopub.status.idle":"2022-06-02T00:00:51.31251Z","shell.execute_reply.started":"2022-06-02T00:00:51.301518Z","shell.execute_reply":"2022-06-02T00:00:51.311775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.precision', 4)\ncm = sns.light_palette('green', as_cmap=True)\nprops_param = \"color:white; font-weight:bold; background-color:green;\"\n\nCUSTOM_SEED = 42\nCUSTOM_BATCH = 24\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:00:51.318157Z","iopub.execute_input":"2022-06-02T00:00:51.318677Z","iopub.status.idle":"2022-06-02T00:00:51.389633Z","shell.execute_reply.started":"2022-06-02T00:00:51.318642Z","shell.execute_reply":"2022-06-02T00:00:51.389015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"competition_dir = \"../input/us-patent-phrase-to-phrase-matching/\"\n\nsubmission = pd.read_csv(competition_dir+'sample_submission.csv')\ntest_origin = pd.read_csv(competition_dir+'test.csv')\ntest_origin.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:00:51.390802Z","iopub.execute_input":"2022-06-02T00:00:51.391196Z","iopub.status.idle":"2022-06-02T00:00:51.420848Z","shell.execute_reply.started":"2022-06-02T00:00:51.391163Z","shell.execute_reply":"2022-06-02T00:00:51.42023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Extract predictions\n\n## 2.1 Deberta v3 large - 1","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           truncation=True)\n    \n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg        \n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.text[item])\n        \n        return inputs\n   \n    \nclass CustomModel(nn.Module):\n    def __init__(self, model_path):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_path)\n        config.num_labels = 1\n        self.base = AutoModelForSequenceClassification.from_config(config=config)\n        dim = config.hidden_size\n        self.dropout = nn.Dropout(p=0)\n        self.cls = nn.Linear(dim,1)\n        \n    def forward(self, inputs):\n        output = self.base(**inputs)\n\n        return output[0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T00:00:51.422161Z","iopub.execute_input":"2022-06-02T00:00:51.422553Z","iopub.status.idle":"2022-06-02T00:00:51.433457Z","shell.execute_reply.started":"2022-06-02T00:00:51.422518Z","shell.execute_reply":"2022-06-02T00:00:51.432699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CUSTOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:00:51.434809Z","iopub.execute_input":"2022-06-02T00:00:51.435247Z","iopub.status.idle":"2022-06-02T00:00:51.444079Z","shell.execute_reply.started":"2022-06-02T00:00:51.435211Z","shell.execute_reply":"2022-06-02T00:00:51.443459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_path='../input/deberta-v3-large/deberta-v3-large'\n    batch_size=CUSTOM_BATCH\n    num_workers=2\n    max_len=130\n    trn_fold=[0, 1, 2, 3]\n\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\n\ncontext_mapping = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:00:51.445224Z","iopub.execute_input":"2022-06-02T00:00:51.445628Z","iopub.status.idle":"2022-06-02T00:00:52.134321Z","shell.execute_reply.started":"2022-06-02T00:00:51.445594Z","shell.execute_reply":"2022-06-02T00:00:52.133547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_origin.copy()\ntitles = pd.read_csv('../input/cpc-codes/titles.csv')\n\ntest.reset_index(inplace=True)\ntest = test.merge(titles, left_on='context', right_on='code')\ntest.sort_values(by='index', inplace=True)\ntest.drop(columns='index', inplace=True)\n\ntest['context_text'] = test['context'].map(context_mapping)\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\ntest['text'] = test['text'].apply(str.lower)\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:00:52.135661Z","iopub.execute_input":"2022-06-02T00:00:52.135928Z","iopub.status.idle":"2022-06-02T00:00:52.911547Z","shell.execute_reply.started":"2022-06-02T00:00:52.135876Z","shell.execute_reply":"2022-06-02T00:00:52.910864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_predicts_1 = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_dataloader = DataLoader(test_dataset,\n                             batch_size=CFG.batch_size, shuffle=False,\n                             num_workers=CFG.num_workers,\n                             pin_memory=True, drop_last=False)\n\ndeberta_simple_path = \"../input/us-patent-deberta-simple/microsoft_deberta-v3-large\"\n\nfor fold in CFG.trn_fold:\n    fold_path = f\"{deberta_simple_path}_best{fold}.pth\"\n    \n    model = CustomModel(CFG.model_path)    \n    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n    model.load_state_dict(state['model'])\n    \n    prediction = inference_fn(test_dataloader, model, DEVICE, is_sigmoid=False)\n    \n    deberta_predicts_1.append(prediction)\n    \n    del model, state, prediction\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:00:52.914819Z","iopub.execute_input":"2022-06-02T00:00:52.916032Z","iopub.status.idle":"2022-06-02T00:02:49.666752Z","shell.execute_reply.started":"2022-06-02T00:00:52.915991Z","shell.execute_reply":"2022-06-02T00:02:49.665959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -------------- inference_fn([...], is_sigmoid=False)\ndeberta_predicts_1 = [upd_outputs(x, is_minmax=True, is_reshape=True) for x in deberta_predicts_1]\ndeberta_predicts_1 = pd.DataFrame(deberta_predicts_1).T\n\ndeberta_predicts_1.head(10).style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:02:49.668408Z","iopub.execute_input":"2022-06-02T00:02:49.668825Z","iopub.status.idle":"2022-06-02T00:02:49.754353Z","shell.execute_reply.started":"2022-06-02T00:02:49.668788Z","shell.execute_reply":"2022-06-02T00:02:49.753704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test, test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:02:49.755678Z","iopub.execute_input":"2022-06-02T00:02:49.756157Z","iopub.status.idle":"2022-06-02T00:02:49.912384Z","shell.execute_reply.started":"2022-06-02T00:02:49.756119Z","shell.execute_reply":"2022-06-02T00:02:49.911713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Deberta v3 large - 2","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    \n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n\n    \nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n            \n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        \n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        \n        return output","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T00:02:49.913903Z","iopub.execute_input":"2022-06-02T00:02:49.914392Z","iopub.status.idle":"2022-06-02T00:02:49.933339Z","shell.execute_reply.started":"2022-06-02T00:02:49.914354Z","shell.execute_reply":"2022-06-02T00:02:49.932537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CUSTOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:02:49.93443Z","iopub.execute_input":"2022-06-02T00:02:49.935257Z","iopub.status.idle":"2022-06-02T00:02:49.945714Z","shell.execute_reply.started":"2022-06-02T00:02:49.93522Z","shell.execute_reply":"2022-06-02T00:02:49.94494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_workers=2\n    path=\"../input/pppm-deberta-v3-large-baseline-w-w-b-train/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n    batch_size=CUSTOM_BATCH\n    fc_dropout=0.2\n    target_size=1\n    max_len=133\n    trn_fold=[0, 1, 2, 3]\n    \nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n\ncontext_mapping = torch.load(CFG.path+\"cpc_texts.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:02:49.947183Z","iopub.execute_input":"2022-06-02T00:02:49.947707Z","iopub.status.idle":"2022-06-02T00:02:50.617649Z","shell.execute_reply.started":"2022-06-02T00:02:49.94767Z","shell.execute_reply":"2022-06-02T00:02:50.616921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_origin.copy()\n\ntest['context_text'] = test['context'].map(context_mapping)\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:02:50.620038Z","iopub.execute_input":"2022-06-02T00:02:50.620584Z","iopub.status.idle":"2022-06-02T00:02:50.637193Z","shell.execute_reply.started":"2022-06-02T00:02:50.620544Z","shell.execute_reply":"2022-06-02T00:02:50.636545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_predicts_2 = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers,\n                         pin_memory=True, drop_last=False)\n\nfolds_path = CFG.path + f\"{CFG.model.replace('/', '-')}\"\n\nfor fold in CFG.trn_fold:\n    fold_path = f\"{folds_path}_fold{fold}_best.pth\"\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n    model.load_state_dict(state['model'])\n    \n    prediction = inference_fn(test_loader, model, DEVICE)\n    deberta_predicts_2.append(prediction)\n    \n    del model, state, prediction\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:02:50.638407Z","iopub.execute_input":"2022-06-02T00:02:50.638778Z","iopub.status.idle":"2022-06-02T00:04:28.308575Z","shell.execute_reply.started":"2022-06-02T00:02:50.638743Z","shell.execute_reply":"2022-06-02T00:04:28.307801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_predicts_2 = [upd_outputs(x, is_reshape=True) for x in deberta_predicts_2]\ndeberta_predicts_2 = pd.DataFrame(deberta_predicts_2).T\n\ndeberta_predicts_2.head(10).style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:04:28.310005Z","iopub.execute_input":"2022-06-02T00:04:28.310433Z","iopub.status.idle":"2022-06-02T00:04:28.337933Z","shell.execute_reply.started":"2022-06-02T00:04:28.310393Z","shell.execute_reply":"2022-06-02T00:04:28.337322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test, test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:04:28.33902Z","iopub.execute_input":"2022-06-02T00:04:28.33932Z","iopub.status.idle":"2022-06-02T00:04:28.497249Z","shell.execute_reply.started":"2022-06-02T00:04:28.339283Z","shell.execute_reply":"2022-06-02T00:04:28.496546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3. Roberta-large","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text, target):\n    inputs = cfg.tokenizer(text, target,\n                           padding=\"max_length\",\n                           max_length=cfg.max_len,\n                           truncation=True)\n\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n        self.target = df['target'].values\n        \n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = self.texts[item]\n        target = self.target[item]\n        \n        inputs = prepare_input(self.cfg, text, target)\n        \n        return inputs\n\n    \nclass CustomModel(nn.Module):\n    def __init__(self):\n        super(CustomModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.config_path)\n\n        config.update({\"output_hidden_states\": True,\n                       \"hidden_dropout_prob\": hidden_dropout_prob,\n                       \"layer_norm_eps\": layer_norm_eps,\n                       \"add_pooling_layer\": False})\n        \n        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, inputs):\n        transformer_out = self.transformer(**inputs)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        \n        return logits","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-02T00:04:28.49863Z","iopub.execute_input":"2022-06-02T00:04:28.499092Z","iopub.status.idle":"2022-06-02T00:04:28.518017Z","shell.execute_reply.started":"2022-06-02T00:04:28.499053Z","shell.execute_reply":"2022-06-02T00:04:28.517341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CUSTOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:04:28.521444Z","iopub.execute_input":"2022-06-02T00:04:28.521961Z","iopub.status.idle":"2022-06-02T00:04:28.531373Z","shell.execute_reply.started":"2022-06-02T00:04:28.52192Z","shell.execute_reply":"2022-06-02T00:04:28.530586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers=2\n    config_path='../input/robertalarge'\n    model_path='../input/phrase-matching-roberta-training-pytorch-wandb'\n    model_name='roberta-large'\n    batch_size=CUSTOM_BATCH\n    max_len=128\n    num_targets=1\n    trn_fold=[0, 1, 2, 3, 4]\n    tokenizer=AutoTokenizer.from_pretrained('../input/robertalarge')\n\ncontext_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:04:28.533087Z","iopub.execute_input":"2022-06-02T00:04:28.533517Z","iopub.status.idle":"2022-06-02T00:04:28.791851Z","shell.execute_reply.started":"2022-06-02T00:04:28.533473Z","shell.execute_reply":"2022-06-02T00:04:28.791119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_origin.copy()\n\ntest['context_text'] = test['context'].str.slice(stop=1).map(context_mapping)\ntest['text'] = test['context_text'] + ' ' + test['anchor']","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:04:28.793317Z","iopub.execute_input":"2022-06-02T00:04:28.793829Z","iopub.status.idle":"2022-06-02T00:04:28.803171Z","shell.execute_reply.started":"2022-06-02T00:04:28.793788Z","shell.execute_reply":"2022-06-02T00:04:28.802365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:04:28.804951Z","iopub.execute_input":"2022-06-02T00:04:28.80533Z","iopub.status.idle":"2022-06-02T00:04:28.818715Z","shell.execute_reply.started":"2022-06-02T00:04:28.805293Z","shell.execute_reply":"2022-06-02T00:04:28.817899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_predicts = []\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers,\n                         pin_memory=True, drop_last=False)\n\nfolds_path = CFG.model_path + f\"/{CFG.model_name.replace('-','_')}\"\n\nfor fold in CFG.trn_fold:\n    fold_path = f\"{folds_path}_patent_model_{fold}.pth\"\n    \n    model = CustomModel()\n    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n    model.load_state_dict(state)\n\n    prediction = inference_fn(test_loader, model, DEVICE)\n    roberta_predicts.append(prediction)\n    \n    del model, state, prediction\n    torch.cuda.empty_cache()    \n    gc.collect()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-02T00:04:28.820059Z","iopub.execute_input":"2022-06-02T00:04:28.820461Z","iopub.status.idle":"2022-06-02T00:06:14.029635Z","shell.execute_reply.started":"2022-06-02T00:04:28.820424Z","shell.execute_reply":"2022-06-02T00:06:14.028908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_predicts = [upd_outputs(x, is_reshape=True) for x in roberta_predicts]\nroberta_predicts = pd.DataFrame(roberta_predicts).T\n\nroberta_predicts.head(10).style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.031365Z","iopub.execute_input":"2022-06-02T00:06:14.031624Z","iopub.status.idle":"2022-06-02T00:06:14.059628Z","shell.execute_reply.started":"2022-06-02T00:06:14.031589Z","shell.execute_reply":"2022-06-02T00:06:14.05866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test, test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.061029Z","iopub.execute_input":"2022-06-02T00:06:14.061425Z","iopub.status.idle":"2022-06-02T00:06:14.233149Z","shell.execute_reply.started":"2022-06-02T00:06:14.061388Z","shell.execute_reply":"2022-06-02T00:06:14.23236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Comparison / Ensemble","metadata":{}},{"cell_type":"code","source":"all_predictions = pd.concat(\n    [deberta_predicts_1, deberta_predicts_2, roberta_predicts],\n    keys=['deberta 1', 'deberta 2', 'roberta'],\n    axis=1\n)\n\nall_predictions.head(10) \\\n    .assign(mean=lambda x: x.mean(axis=1)) \\\n        .style.background_gradient(cmap=cm, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.237293Z","iopub.execute_input":"2022-06-02T00:06:14.240206Z","iopub.status.idle":"2022-06-02T00:06:14.414642Z","shell.execute_reply.started":"2022-06-02T00:06:14.240167Z","shell.execute_reply":"2022-06-02T00:06:14.413799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_mean = pd.DataFrame({\n    'deberta 1': deberta_predicts_1.mean(axis=1),\n    'deberta 2': deberta_predicts_2.mean(axis=1),\n    'roberta': roberta_predicts.mean(axis=1)\n})\n\nall_mean.head(10) \\\n    .assign(mean=lambda x: x.mean(axis=1)) \\\n        .style.highlight_max(axis=1, props=props_param)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.416448Z","iopub.execute_input":"2022-06-02T00:06:14.417051Z","iopub.status.idle":"2022-06-02T00:06:14.442397Z","shell.execute_reply.started":"2022-06-02T00:06:14.417006Z","shell.execute_reply":"2022-06-02T00:06:14.441616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === N1 ===\n# weights_ = [0.33, 0.33, 0.33]\n# final_predictions = all_mean.mul(weights_).sum(axis=1)\n\n# === N2 ===\n# final_predictions = all_mean.median(axis=1)\nfinal_predictions = all_mean.mean(axis=1)\n\n# === N3 ===\n# final_predictions = all_predictions.mean(axis=1)\n\n# === N4 ===\n# combs = pd.DataFrame({\n#     'deberta_1': deberta_predicts_1.mean(axis=1),\n#     'deb_2+rob': (deberta_predicts_2.mean(axis=1) * 0.666) \\\n#                     + (roberta_predicts.mean(axis=1) * 0.333)\n# })\n# display(combs.head())\n# final_predictions = combs.median(axis=1)\n# final_predictions = combs.mean(axis=1)\n\nfinal_predictions.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.443875Z","iopub.execute_input":"2022-06-02T00:06:14.444144Z","iopub.status.idle":"2022-06-02T00:06:14.4518Z","shell.execute_reply.started":"2022-06-02T00:06:14.444109Z","shell.execute_reply":"2022-06-02T00:06:14.451116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_origin['id'],\n    'score': final_predictions,\n})\n\nsubmission.head(14)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.453607Z","iopub.execute_input":"2022-06-02T00:06:14.454297Z","iopub.status.idle":"2022-06-02T00:06:14.468236Z","shell.execute_reply.started":"2022-06-02T00:06:14.45426Z","shell.execute_reply":"2022-06-02T00:06:14.467393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ===================  Baseline\n# 0  4112d61851461f60  0.56127\n# 1  09e418c93a776564  0.72176\n# 2  36baf228038e314b  0.47086\n# 3  1f37ead645e7f0c8  0.25826\n# 4  71a5b6ad068d531f  0.00908\n# 5  474c874d0c07bd21  0.48173","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.470122Z","iopub.execute_input":"2022-06-02T00:06:14.470374Z","iopub.status.idle":"2022-06-02T00:06:14.4766Z","shell.execute_reply.started":"2022-06-02T00:06:14.470341Z","shell.execute_reply":"2022-06-02T00:06:14.475793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T00:06:14.478173Z","iopub.execute_input":"2022-06-02T00:06:14.478367Z","iopub.status.idle":"2022-06-02T00:06:14.491852Z","shell.execute_reply.started":"2022-06-02T00:06:14.478345Z","shell.execute_reply":"2022-06-02T00:06:14.491103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}