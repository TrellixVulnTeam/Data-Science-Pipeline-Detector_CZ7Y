{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-24T07:43:46.94744Z","iopub.execute_input":"2022-04-24T07:43:46.948543Z","iopub.status.idle":"2022-04-24T07:43:46.983564Z","shell.execute_reply.started":"2022-04-24T07:43:46.948416Z","shell.execute_reply":"2022-04-24T07:43:46.982636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:46.985065Z","iopub.execute_input":"2022-04-24T07:43:46.985355Z","iopub.status.idle":"2022-04-24T07:43:47.096434Z","shell.execute_reply.started":"2022-04-24T07:43:46.98532Z","shell.execute_reply":"2022-04-24T07:43:47.095373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:47.098075Z","iopub.execute_input":"2022-04-24T07:43:47.098458Z","iopub.status.idle":"2022-04-24T07:43:47.123296Z","shell.execute_reply.started":"2022-04-24T07:43:47.098416Z","shell.execute_reply":"2022-04-24T07:43:47.122397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"target\"][0]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:47.125314Z","iopub.execute_input":"2022-04-24T07:43:47.126052Z","iopub.status.idle":"2022-04-24T07:43:47.134355Z","shell.execute_reply.started":"2022-04-24T07:43:47.126013Z","shell.execute_reply":"2022-04-24T07:43:47.133554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:47.135651Z","iopub.execute_input":"2022-04-24T07:43:47.135895Z","iopub.status.idle":"2022-04-24T07:43:47.147768Z","shell.execute_reply.started":"2022-04-24T07:43:47.135864Z","shell.execute_reply":"2022-04-24T07:43:47.146857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:47.149456Z","iopub.execute_input":"2022-04-24T07:43:47.149739Z","iopub.status.idle":"2022-04-24T07:43:47.156609Z","shell.execute_reply.started":"2022-04-24T07:43:47.149683Z","shell.execute_reply":"2022-04-24T07:43:47.155939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add another helpful dataset\ncpc_add = pd.read_csv(\"../input/cpc-codes/titles.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:47.157987Z","iopub.execute_input":"2022-04-24T07:43:47.158383Z","iopub.status.idle":"2022-04-24T07:43:48.141231Z","shell.execute_reply.started":"2022-04-24T07:43:47.158354Z","shell.execute_reply":"2022-04-24T07:43:48.140204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_add.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.145132Z","iopub.execute_input":"2022-04-24T07:43:48.145417Z","iopub.status.idle":"2022-04-24T07:43:48.161874Z","shell.execute_reply.started":"2022-04-24T07:43:48.145387Z","shell.execute_reply":"2022-04-24T07:43:48.160607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpc_add.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.164298Z","iopub.execute_input":"2022-04-24T07:43:48.165119Z","iopub.status.idle":"2022-04-24T07:43:48.173069Z","shell.execute_reply.started":"2022-04-24T07:43:48.165045Z","shell.execute_reply":"2022-04-24T07:43:48.172221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"score\"].describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.175674Z","iopub.execute_input":"2022-04-24T07:43:48.176286Z","iopub.status.idle":"2022-04-24T07:43:48.190475Z","shell.execute_reply.started":"2022-04-24T07:43:48.176224Z","shell.execute_reply":"2022-04-24T07:43:48.18969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"score\"].value_counts(normalize = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.191844Z","iopub.execute_input":"2022-04-24T07:43:48.192538Z","iopub.status.idle":"2022-04-24T07:43:48.205625Z","shell.execute_reply.started":"2022-04-24T07:43:48.192491Z","shell.execute_reply":"2022-04-24T07:43:48.204754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns, cpc_add.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.206764Z","iopub.execute_input":"2022-04-24T07:43:48.207032Z","iopub.status.idle":"2022-04-24T07:43:48.220863Z","shell.execute_reply.started":"2022-04-24T07:43:48.207002Z","shell.execute_reply":"2022-04-24T07:43:48.220239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's merge both the data\ntrain = train.merge(cpc_add, left_on = \"context\", right_on = \"code\", how = \"left\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.22225Z","iopub.execute_input":"2022-04-24T07:43:48.22323Z","iopub.status.idle":"2022-04-24T07:43:48.392933Z","shell.execute_reply.started":"2022-04-24T07:43:48.223176Z","shell.execute_reply":"2022-04-24T07:43:48.392081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.394267Z","iopub.execute_input":"2022-04-24T07:43:48.394602Z","iopub.status.idle":"2022-04-24T07:43:48.413438Z","shell.execute_reply.started":"2022-04-24T07:43:48.39457Z","shell.execute_reply":"2022-04-24T07:43:48.412492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config():\n    seed = 42\n    epochs = 10\n    num_folds = 5\n    max_length = 192\n    batch_size = 64\n    learning_rate = 2e-5\n    weight_decay = 0.01\n    base_model = \"AI-Growth-Lab/PatentSBERTa\"","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.414655Z","iopub.execute_input":"2022-04-24T07:43:48.415259Z","iopub.status.idle":"2022-04-24T07:43:48.420186Z","shell.execute_reply.started":"2022-04-24T07:43:48.4152Z","shell.execute_reply":"2022-04-24T07:43:48.419547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"import transformers","metadata":{}},{"cell_type":"code","source":"from scipy import stats\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\n\nimport transformers\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") ","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:48.421458Z","iopub.execute_input":"2022-04-24T07:43:48.421715Z","iopub.status.idle":"2022-04-24T07:43:55.000956Z","shell.execute_reply.started":"2022-04-24T07:43:48.421688Z","shell.execute_reply":"2022-04-24T07:43:55.000038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizer.\ntokenizer = transformers.AutoTokenizer.from_pretrained(Config.base_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:55.004034Z","iopub.execute_input":"2022-04-24T07:43:55.00433Z","iopub.status.idle":"2022-04-24T07:43:59.019796Z","shell.execute_reply.started":"2022-04-24T07:43:55.004301Z","shell.execute_reply":"2022-04-24T07:43:59.019043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Context tokens. \ntrain['context_token'] = '[' + train.context + ']'\n#train['sep_token'] = '[SEP]'\n#train['cls_token'] = '[CLS]'\ncontext_tokens = list(train.context_token.unique())\ntokenizer.add_special_tokens({'additional_special_tokens': context_tokens})\n\n# Preparing input text for the model.\n# We are adding context_token before the context title\n# to let model learn the context of anchor and target.\ntrain['text'] = '[CLS]' + \\\n                    train['context_token'] + train['title'] + \\\n                    '[SEP]' + train['anchor'] + \\\n                    '[SEP]' + train['target'] + \\\n                '[SEP]'\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:59.021374Z","iopub.execute_input":"2022-04-24T07:43:59.02189Z","iopub.status.idle":"2022-04-24T07:43:59.110545Z","shell.execute_reply.started":"2022-04-24T07:43:59.021848Z","shell.execute_reply":"2022-04-24T07:43:59.109475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:59.11216Z","iopub.execute_input":"2022-04-24T07:43:59.112875Z","iopub.status.idle":"2022-04-24T07:43:59.132407Z","shell.execute_reply.started":"2022-04-24T07:43:59.112829Z","shell.execute_reply":"2022-04-24T07:43:59.131643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_text(text, \n                tokenizer,\n                max_length):\n    \n \n    encoded = tokenizer.batch_encode_plus(\n        text,\n        add_special_tokens=False,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_token_type_ids=True,\n        return_tensors=\"tf\",\n    )\n\n    # Convert batch of encoded features to numpy array.\n    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_masks\": attention_masks,\n        \"token_type_ids\": token_type_ids\n    }","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:59.133502Z","iopub.execute_input":"2022-04-24T07:43:59.13422Z","iopub.status.idle":"2022-04-24T07:43:59.142035Z","shell.execute_reply.started":"2022-04-24T07:43:59.134183Z","shell.execute_reply":"2022-04-24T07:43:59.141149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU config\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n    print(f'TPU: {tpu.master()}')\nexcept:\n    strategy = tf.distribute.get_strategy()\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n\n# XLA acceleartion\ntf.config.optimizer.set_jit(True)\nprint(f'Replicas: {replicas}')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:43:59.143609Z","iopub.execute_input":"2022-04-24T07:43:59.143858Z","iopub.status.idle":"2022-04-24T07:44:05.105683Z","shell.execute_reply.started":"2022-04-24T07:43:59.143832Z","shell.execute_reply":"2022-04-24T07:44:05.104708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(config, num_train_steps):\n    # Create the model under a distribution strategy scope.\n    with strategy.scope():\n        # Encoded token ids from BERT tokenizer.\n        input_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n        )\n        # Attention masks indicates to the model which tokens should be attended to.\n        attention_masks = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"attention_masks\"\n        )\n        # Token type ids are binary masks identifying different sequences in the model.\n        token_type_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n        )\n        # Loading pretrained BERT model.\n        base_model = transformers.TFAutoModel.from_pretrained(config.base_model, from_pt=True)\n\n        base_model_output = base_model(\n            input_ids, attention_mask=attention_masks)\n        \n        last_hidden_state = base_model_output.last_hidden_state\n        avg_pool = tf.keras.layers.GlobalAveragePooling1D()(last_hidden_state)\n        dropout = tf.keras.layers.Dropout(0.3)(avg_pool)\n\n        output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dropout)\n        \n        model = tf.keras.models.Model(\n            inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n        )\n\n        model.compile(\n            optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n            loss=tf.keras.losses.BinaryCrossentropy()\n        )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:44:05.107266Z","iopub.execute_input":"2022-04-24T07:44:05.107589Z","iopub.status.idle":"2022-04-24T07:44:05.119246Z","shell.execute_reply.started":"2022-04-24T07:44:05.107557Z","shell.execute_reply":"2022-04-24T07:44:05.118168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_folds(train, config):\n    oof = np.zeros(len(train))\n    \n    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    \n    skf = StratifiedKFold(n_splits=config.num_folds, \n                      shuffle=True,\n                      random_state=config.seed)\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['score_map'])):\n        print(\"*\" * 25)\n        print(f\"Training fold: {fold+1}\")\n\n        train_df = train.loc[train_idx].reset_index(drop=True)\n        val_df = train.loc[val_idx].reset_index(drop=True)\n        \n        # Clear keras session.\n        K.clear_session()\n        \n        train_encoded =  encode_text(train_df[\"text\"].tolist(),\n                                     tokenizer=tokenizer,\n                                     max_length=config.max_length)\n        \n        val_encoded =  encode_text(val_df[\"text\"].tolist(),\n                                     tokenizer=tokenizer,\n                                     max_length=config.max_length)\n        # Dataloader.\n        train_data = tf.data.Dataset.from_tensor_slices((train_encoded, train_df['score'].tolist()))\n        val_data = tf.data.Dataset.from_tensor_slices((val_encoded, val_df['score'].tolist()))\n\n        train_data = (\n                        train_data\n                        .shuffle(1024)\n                        .batch(config.batch_size)\n                        .prefetch(tf.data.AUTOTUNE)\n                     )\n        \n        val_data = (\n                        val_data\n                        .batch(config.batch_size)\n                        .prefetch(tf.data.AUTOTUNE)\n                    )\n\n        # Callbacks.\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n                                                        monitor='val_loss',\n                                                        mode='min',\n                                                        save_best_only=True,\n                                                        save_weights_only=True,\n                                                        save_freq='epoch',\n                                                        verbose=1)\n        \n        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                          mode='min',\n                                                          patience=3,\n                                                          verbose=1)\n        \n        pearsonr_callback = Pearsonr(val_data, val_df['score'].values)\n        num_train_steps = int(len(train_df) / config.batch_size * config.epochs)\n        \n        # Build and Train model.\n        model = build_model(config, num_train_steps)\n        history = model.fit(\n                        train_data,\n                        validation_data=val_data,\n                        epochs=config.epochs,\n                        callbacks=[checkpoint, \n                                   early_stopping, \n                                   pearsonr_callback],\n                        verbose=1\n                    )\n        \n        print('\\nLoading best model weights...')\n        model.load_weights(f'model-{fold+1}.h5')\n        \n        print('Predicting OOF...')\n        oof[val_idx] = model.predict(val_data,\n                                     batch_size=config.batch_size,\n                                     verbose=0).reshape(-1)\n        \n        \n        score = stats.pearsonr(val_df['score'].values, oof[val_idx])[0]\n        print(f'\\nFold {fold + 1}: OOF pearson_r: {score:.4f}')        \n        print(\"*\" * 25)\n        \n    score = stats.pearsonr(train['score'].values, oof)[0]\n    print(f'\\nOverall OOF pearson_r: {score:.4f}')\n    return oof\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:44:05.120663Z","iopub.execute_input":"2022-04-24T07:44:05.120894Z","iopub.status.idle":"2022-04-24T07:44:05.140531Z","shell.execute_reply.started":"2022-04-24T07:44:05.120865Z","shell.execute_reply":"2022-04-24T07:44:05.139218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Pearsonr(tf.keras.callbacks.Callback):\n    def __init__(self, val_data, y_val):\n        self.val_data = val_data\n        self.y_val = y_val\n    def on_epoch_end(self, epoch, logs):\n        val_preds = self.model.predict(self.val_data, verbose=0)\n        \n        val_pearsonr = stats.pearsonr(self.y_val, val_preds.ravel())[0]\n\n        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n        logs[\"val_pearsonr\"] = val_pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:44:05.142564Z","iopub.execute_input":"2022-04-24T07:44:05.143308Z","iopub.status.idle":"2022-04-24T07:44:05.154933Z","shell.execute_reply.started":"2022-04-24T07:44:05.143241Z","shell.execute_reply":"2022-04-24T07:44:05.154044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config()\noof_preds = train_folds(train, config)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T07:44:05.156463Z","iopub.execute_input":"2022-04-24T07:44:05.156846Z","iopub.status.idle":"2022-04-24T08:21:28.273013Z","shell.execute_reply.started":"2022-04-24T07:44:05.156802Z","shell.execute_reply":"2022-04-24T08:21:28.271894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('oof.npy', oof_preds)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:21:28.275535Z","iopub.execute_input":"2022-04-24T08:21:28.276762Z","iopub.status.idle":"2022-04-24T08:21:28.28681Z","shell.execute_reply.started":"2022-04-24T08:21:28.276709Z","shell.execute_reply":"2022-04-24T08:21:28.285378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}