{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport time\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T14:30:13.112426Z","iopub.execute_input":"2022-04-04T14:30:13.112674Z","iopub.status.idle":"2022-04-04T14:30:13.119549Z","shell.execute_reply.started":"2022-04-04T14:30:13.112645Z","shell.execute_reply":"2022-04-04T14:30:13.118692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(seed=2019)\n#print (torch.cuda.manual_seed(2019))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:30:13.605478Z","iopub.execute_input":"2022-04-04T14:30:13.606035Z","iopub.status.idle":"2022-04-04T14:30:13.61284Z","shell.execute_reply.started":"2022-04-04T14:30:13.605994Z","shell.execute_reply":"2022-04-04T14:30:13.612033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass CFG:\n    num_workers: Optional[int] = 4\n    config_path: Optional[str] = '../input/robertalarge'\n    model_path: Optional[str] = '../input/phrase-matching-roberta-training-pytorch-wandb'\n    model_name: Optional[str] = 'roberta-large'\n    batch_size: Optional[int] = 32\n    max_len: Optional[int] = 128\n    seed: Optional[int] = 2019\n    num_targets: Optional[int] = 1\n    n_folds: Optional[int] = 5\n    tokenizer = AutoTokenizer.from_pretrained('../input/robertalarge')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:30:14.132102Z","iopub.execute_input":"2022-04-04T14:30:14.13272Z","iopub.status.idle":"2022-04-04T14:30:14.379319Z","shell.execute_reply.started":"2022-04-04T14:30:14.132676Z","shell.execute_reply":"2022-04-04T14:30:14.378605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('../input/robertalarge')\nconfig_path: Optional[str] = '../input/robertalarge'\nprint((tokenizer))\nprint(type(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:40:33.055829Z","iopub.execute_input":"2022-04-04T14:40:33.056376Z","iopub.status.idle":"2022-04-04T14:40:33.213191Z","shell.execute_reply.started":"2022-04-04T14:40:33.056334Z","shell.execute_reply":"2022-04-04T14:40:33.212432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/us-patent-phrase-to-phrase-matching'\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))\nprint(test)\n#sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:40:54.823319Z","iopub.execute_input":"2022-04-04T14:40:54.823586Z","iopub.status.idle":"2022-04-04T14:40:54.843234Z","shell.execute_reply.started":"2022-04-04T14:40:54.823556Z","shell.execute_reply":"2022-04-04T14:40:54.842586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping = {\n        \"A\": \"Human Necessities\",\n        \"B\": \"Operations and Transport\",\n        \"C\": \"Chemistry and Metallurgy\",\n        \"D\": \"Textiles\",\n        \"E\": \"Fixed Constructions\",\n        \"F\": \"Mechanical Engineering\",\n        \"G\": \"Physics\",\n        \"H\": \"Electricity\",\n        \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n    \ntest.context = test.context.apply(lambda x: context_mapping[x[0]])\nprint(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:40:55.708308Z","iopub.execute_input":"2022-04-04T14:40:55.708862Z","iopub.status.idle":"2022-04-04T14:40:55.71854Z","shell.execute_reply.started":"2022-04-04T14:40:55.708824Z","shell.execute_reply":"2022-04-04T14:40:55.717866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n\n        encoded_text = CFG.tokenizer.encode_plus(\n            context + \" \" + anchor,\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:40:57.188734Z","iopub.execute_input":"2022-04-04T14:40:57.18937Z","iopub.status.idle":"2022-04-04T14:40:57.196386Z","shell.execute_reply.started":"2022-04-04T14:40:57.189335Z","shell.execute_reply":"2022-04-04T14:40:57.195707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_fn(model, test_loader):  \n    model.eval()\n    predictions = []\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for data in tk0:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        with torch.no_grad():\n            output = model(ids, mask)\n        predictions.append(output.sigmoid().detach().cpu().numpy())\n        \n    return np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:39:37.447727Z","iopub.execute_input":"2022-04-04T10:39:37.451831Z","iopub.status.idle":"2022-04-04T10:39:37.459516Z","shell.execute_reply.started":"2022-04-04T10:39:37.451789Z","shell.execute_reply":"2022-04-04T10:39:37.458687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatentModel(torch.nn.Module):\n    def __init__(self):\n        super(PatentModel, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(CFG.config_path)\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        \n        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n        \n    def forward(self, ids, mask):\n        transformer_out = self.transformer(input_ids=ids, attention_mask=mask)\n        last_hidden_states = transformer_out[0]\n        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n        logits1 = self.output(self.dropout1(last_hidden_states))\n        logits2 = self.output(self.dropout2(last_hidden_states))\n        logits3 = self.output(self.dropout3(last_hidden_states))\n        logits4 = self.output(self.dropout4(last_hidden_states))\n        logits5 = self.output(self.dropout5(last_hidden_states))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:39:37.461545Z","iopub.execute_input":"2022-04-04T10:39:37.462179Z","iopub.status.idle":"2022-04-04T10:39:37.474325Z","shell.execute_reply.started":"2022-04-04T10:39:37.462134Z","shell.execute_reply":"2022-04-04T10:39:37.473373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(test, fold, seed=42):    \n    \n    seed_everything(seed)\n    \n    test_dataset = PhraseDataset(\n        test.anchor.values,\n        test.target.values,\n        test.context.values,\n        CFG.tokenizer, \n        CFG.max_len\n    ) \n    \n    test_loader = DataLoader(test_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    model = PatentModel()\n    \n    model.load_state_dict(\n        torch.load(f'{CFG.model_path}/{CFG.model_name.replace(\"-\",\"_\")}_patent_model_{fold}.pth',\n        map_location=torch.device('cuda')\n        )\n    )\n    \n    model.to(device)\n\n    preds = inference_fn(model, test_loader)\n    \n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:39:37.476932Z","iopub.execute_input":"2022-04-04T10:39:37.477545Z","iopub.status.idle":"2022-04-04T10:39:37.486914Z","shell.execute_reply.started":"2022-04-04T10:39:37.477503Z","shell.execute_reply":"2022-04-04T10:39:37.486161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_model(test, seed):\n    \n    predictions = []\n    \n    for f in range(CFG.n_folds):    \n        preds = run_fold(test, f, seed) \n        predictions.append(preds)\n        \n    test_preds = np.column_stack(predictions)\n        \n    return test_preds","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:39:37.490814Z","iopub.execute_input":"2022-04-04T10:39:37.491337Z","iopub.status.idle":"2022-04-04T10:39:37.497908Z","shell.execute_reply.started":"2022-04-04T10:39:37.491296Z","shell.execute_reply":"2022-04-04T10:39:37.497195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    final_predictions =  inference_model(test, CFG.seed) ","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:39:37.498933Z","iopub.execute_input":"2022-04-04T10:39:37.499434Z","iopub.status.idle":"2022-04-04T10:41:45.805866Z","shell.execute_reply.started":"2022-04-04T10:39:37.499396Z","shell.execute_reply":"2022-04-04T10:41:45.805015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['score'] = np.mean(final_predictions, axis=1)\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:41:45.807383Z","iopub.execute_input":"2022-04-04T10:41:45.807922Z","iopub.status.idle":"2022-04-04T10:41:45.819463Z","shell.execute_reply.started":"2022-04-04T10:41:45.807867Z","shell.execute_reply":"2022-04-04T10:41:45.818397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T10:41:45.821223Z","iopub.execute_input":"2022-04-04T10:41:45.82151Z","iopub.status.idle":"2022-04-04T10:41:45.839329Z","shell.execute_reply.started":"2022-04-04T10:41:45.82147Z","shell.execute_reply":"2022-04-04T10:41:45.838637Z"},"trusted":true},"execution_count":null,"outputs":[]}]}