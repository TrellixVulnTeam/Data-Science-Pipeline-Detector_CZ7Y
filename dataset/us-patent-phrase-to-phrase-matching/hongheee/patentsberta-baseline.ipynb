{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/sentencetransformer/sentence-transformers /tmp/st\n!pip install /tmp/st --quiet","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:00:27.784869Z","iopub.execute_input":"2022-05-17T12:00:27.785137Z","iopub.status.idle":"2022-05-17T12:00:41.065705Z","shell.execute_reply.started":"2022-05-17T12:00:27.785109Z","shell.execute_reply":"2022-05-17T12:00:41.064835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import some libraries and set seed","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport re\nimport string\n\nfrom tqdm import tqdm\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple, Optional\n\nimport torch\nfrom transformers import BertTokenizer\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset, SequentialSampler, RandomSampler\n\ndef normalize_text(s):\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch for ch in text if ch not in exclude)\n    \n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_punc(lower(s)))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:01:08.899705Z","iopub.execute_input":"2022-05-17T12:01:08.899996Z","iopub.status.idle":"2022-05-17T12:01:08.908432Z","shell.execute_reply.started":"2022-05-17T12:01:08.899964Z","shell.execute_reply":"2022-05-17T12:01:08.907731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, losses, models, util\nfrom sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\nfrom sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\nfrom sentence_transformers.readers import InputExample\nfrom sentence_transformers.cross_encoder import CrossEncoder\nimport torch\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport os\nimport re\nimport numpy as np\nimport math\nimport random\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:01:09.309704Z","iopub.execute_input":"2022-05-17T12:01:09.310248Z","iopub.status.idle":"2022-05-17T12:01:09.31902Z","shell.execute_reply.started":"2022-05-17T12:01:09.31021Z","shell.execute_reply":"2022-05-17T12:01:09.318243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import data and combine the cpc-data as shown in https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/314306","metadata":{}},{"cell_type":"code","source":"DEBUG_mode = True\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = ''\nif DEBUG_mode:\n    train_df = pd.read_csv(INPUT_DIR+'train.csv', nrows=1000)\nelse:\n    train_df = pd.read_csv(INPUT_DIR + 'train.csv')\ntest_df = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"train.shape: {train_df.shape}\")\nprint(f\"test.shape: {test_df.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\n\n\n\n# ====================================================\n# CPC Data\n# ====================================================\ndef get_cpc_texts():\n    cpc = pd.read_csv('../input/cpccodes/titles.csv')\n    cpc = cpc.rename(columns = {\"code\" : \"context\"})\n    return cpc\n\n\ncpc_texts = get_cpc_texts()\ntrain_df = pd.merge(train_df, cpc_texts[[\"context\",\"title\"]], on =\"context\", how = \"left\")\ntrain_df['title'] = train_df['title'].apply(lambda x: normalize_text(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:01:15.122646Z","iopub.execute_input":"2022-05-17T12:01:15.122911Z","iopub.status.idle":"2022-05-17T12:01:15.769937Z","shell.execute_reply.started":"2022-05-17T12:01:15.122883Z","shell.execute_reply":"2022-05-17T12:01:15.769207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"construt the imputs for model\n\ninput1 is anchor + context\n\ninput2 is target + context","metadata":{}},{"cell_type":"code","source":"train_df['text_a'] = 'anchor:' + train_df['anchor'] + '[SEP]' + 'context:' + train_df['title']\ntrain_df['text_b'] = 'target:' + train_df['target'] + '[SEP]' + 'context:' + train_df['title']","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:01:18.270506Z","iopub.execute_input":"2022-05-17T12:01:18.270757Z","iopub.status.idle":"2022-05-17T12:01:18.279492Z","shell.execute_reply.started":"2022-05-17T12:01:18.270729Z","shell.execute_reply":"2022-05-17T12:01:18.278679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CV: groupy by anchor","metadata":{}},{"cell_type":"code","source":"anchors = train_df.anchor.unique()\nnp.random.shuffle(anchors)\nval_prop = 0.20\nval_sz = int(len(anchors)*val_prop)\nval_anchors_0 = anchors[:val_sz]\nval_anchors_1 = anchors[val_sz:2*val_sz]\nval_anchors_2 = anchors[2*val_sz:3*val_sz]\nval_anchors_3 = anchors[3*val_sz:4*val_sz]\nval_anchors_4 = anchors[4*val_sz:]\nval_anchors = [val_anchors_0,val_anchors_1,val_anchors_2,val_anchors_3,val_anchors_4]\n\nk_fold_score = []\n\ntrain_batch_size = 8\nfor fold in range(5):\n    is_val = np.isin(train_df.anchor, val_anchors[fold])\n    idxs = np.arange(len(train_df))\n    val_idxs = idxs[is_val]\n    trn_idxs = idxs[~is_val]\n    print(train_df.iloc[trn_idxs].score.mean(), train_df.iloc[val_idxs].score.mean())\n    \n    train_samples = []\n    for idx, row in train_df.iloc[trn_idxs].iterrows():\n        train_samples.append(\n        InputExample(texts=[row['text_a'], row['text_b']], label=row['score'])\n        )\n    dev_samples = []\n    for idx, row in train_df.iloc[val_idxs].iterrows():\n        dev_samples.append(\n        InputExample(texts=[row['text_a'], row['text_b']], label=row['score'])\n        )\n    \n    model = SentenceTransformer('../input/patentsberta/PatentSBERTa')\n    \n    train_dataset = SentencesDataset(train_samples, model)\n    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n    train_loss = losses.CosineSimilarityLoss(model=model)\n    \n    evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n\n    # Train the model\n    model.fit(train_objectives=[(train_dataloader, train_loss)],\n              evaluator=evaluator,\n              epochs=20,\n              evaluation_steps=math.ceil(len(train_dataloader)),\n              output_path=f'fold_{fold}')","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:03:25.242251Z","iopub.execute_input":"2022-05-17T12:03:25.242842Z","iopub.status.idle":"2022-05-17T12:08:26.495191Z","shell.execute_reply.started":"2022-05-17T12:03:25.242798Z","shell.execute_reply":"2022-05-17T12:08:26.494457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"test_df = pd.merge(test_df, cpc_texts[[\"context\",\"title\"]], on =\"context\", how = \"left\")\ntest_df['title'] = test_df['title'].apply(lambda x: normalize_text(x))\ntest_df['text_a'] = 'anchor:' + test_df['anchor'] + '[SEP]' + 'context:' + test_df['title']\ntest_df['text_b'] = 'target:' + test_df['target'] + '[SEP]' + 'context:' + test_df['title']\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:56:50.207733Z","iopub.execute_input":"2022-05-17T10:56:50.207972Z","iopub.status.idle":"2022-05-17T10:56:50.308407Z","shell.execute_reply.started":"2022-05-17T10:56:50.207946Z","shell.execute_reply":"2022-05-17T10:56:50.307595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_samples = []\nfor idx, row in test_df.iterrows():\n    test_samples.append(\n    {\"id\":row['id'],\n     'texts': [row['text_a'], row['text_b']]\n    }\n    )","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:08:42.123504Z","iopub.execute_input":"2022-05-17T11:08:42.123759Z","iopub.status.idle":"2022-05-17T11:08:42.132087Z","shell.execute_reply.started":"2022-05-17T11:08:42.12373Z","shell.execute_reply":"2022-05-17T11:08:42.131409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compute embeddings\nsims = []\nfor idx, sample in enumerate(test_samples):\n    id = sample['id']\n    embeddings = model.encode(sample['texts'], convert_to_tensor=True)\n    cosine_scores = util.cos_sim(embeddings, embeddings)\n    sims.append( [\n        id, cosine_scores[0][1].cpu().clone().numpy()\n    ]\n       )","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:32:04.753511Z","iopub.execute_input":"2022-05-17T11:32:04.753767Z","iopub.status.idle":"2022-05-17T11:32:06.845514Z","shell.execute_reply.started":"2022-05-17T11:32:04.75374Z","shell.execute_reply":"2022-05-17T11:32:06.84462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')\nsubmit_csv = pd.DataFrame(sims,columns=['id','score'])\nsubmit_csv.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:32:08.861936Z","iopub.execute_input":"2022-05-17T11:32:08.862625Z","iopub.status.idle":"2022-05-17T11:32:08.872251Z","shell.execute_reply.started":"2022-05-17T11:32:08.862588Z","shell.execute_reply":"2022-05-17T11:32:08.871554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:32:08.984742Z","iopub.execute_input":"2022-05-17T11:32:08.985437Z","iopub.status.idle":"2022-05-17T11:32:08.995899Z","shell.execute_reply.started":"2022-05-17T11:32:08.985402Z","shell.execute_reply":"2022-05-17T11:32:08.995152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}