{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U -q --no-index --find-links=../input/download-packages \\\npython-box \\\npytorch-lightning \\\ndatasets \\\ntorchmetrics \\\npytorch-pfn-extras \\\nkaleido \\\nmlflow \\\niterative-stratification \\\nadabelief-pytorch \\\nomegaconf \\\nhydra-core","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-21T09:51:55.048273Z","iopub.execute_input":"2022-06-21T09:51:55.048621Z","iopub.status.idle":"2022-06-21T09:52:38.072485Z","shell.execute_reply.started":"2022-06-21T09:51:55.048537Z","shell.execute_reply":"2022-06-21T09:52:38.071595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/uspppm-public -lh","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:52:38.074741Z","iopub.execute_input":"2022-06-21T09:52:38.07533Z","iopub.status.idle":"2022-06-21T09:52:38.751298Z","shell.execute_reply.started":"2022-06-21T09:52:38.07529Z","shell.execute_reply":"2022-06-21T09:52:38.750458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/uspppm-results -lh","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:52:38.754541Z","iopub.execute_input":"2022-06-21T09:52:38.754761Z","iopub.status.idle":"2022-06-21T09:52:39.409648Z","shell.execute_reply.started":"2022-06-21T09:52:38.754735Z","shell.execute_reply":"2022-06-21T09:52:39.408268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference of each run","metadata":{}},{"cell_type":"code","source":"%%writefile process.py\n\nimport argparse\n\nimport os\nimport sys\nimport gc\nimport glob\nimport time\nimport warnings\nimport joblib\nimport shutil\nimport psutil\nimport importlib\nimport yaml\nfrom pathlib import Path\n\nfrom tqdm.auto import tqdm\n\nwarnings.simplefilter(\"ignore\")\n\nfrom scipy.special import expit as sigmoid\nfrom sklearn.decomposition import PCA\nimport numpy as np\nimport pandas as pd\n\nimport torch\n\nimport pytorch_pfn_extras as ppe\nfrom pytorch_pfn_extras.config import Config\n\ndef parse_arguments():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--dataset-name\", default=\"uspppm-results\", type=str)\n    parser.add_argument('--idx', default=0, type=int)\n    parser.add_argument('--run-id', default=None)\n    \n    return parser.parse_args()\n\ndef memory_used_to_str():\n    pid = os.getpid()\n    processs = psutil.Process(pid)\n    memory_use = processs.memory_info()[0] / 2.0**30\n    return \"ram memory gb :\" + str(np.round(memory_use, 2))\n\n\ndef get_feature(CFG, model_path, df):\n    CFG[\"/dataset/test\"].lazy_init(df=df)\n    dataloader = CFG[f\"/dataloader/test\"]\n\n    model = CFG[\"/model\"]\n    device = CFG[\"/training/device\"]\n    model.load_state_dict(torch.load(model_path))\n    model.to(device)\n    model.eval()\n    pred_list = []\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"extracting...\"):\n            for k in batch.keys():\n                batch[k] = batch[k].to(device)\n\n            last_hidden_state = model.encoder(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n            )[\"last_hidden_state\"]\n            pred_list.append(last_hidden_state[:, 0, :].detach().cpu().numpy())\n\n    del model, device\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    output = np.concatenate(pred_list)\n    \n    return output\n\n\ndef get_prediction(CFG, model_path, df, use_sigmoid=False):\n    CFG[\"/dataset/test\"].lazy_init(df=df)\n    dataloader = CFG[f\"/dataloader/test\"]\n\n    model = CFG[\"/model\"]\n    device = CFG[\"/training/device\"]\n    model.load_state_dict(torch.load(model_path))\n    model.to(device)\n    model.eval()\n    pred_list = []\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"predicting...\"):\n            for k in batch.keys():\n                batch[k] = batch[k].to(device)\n\n            yhat = model(batch)\n            pred_list.append(yhat.detach().cpu().numpy())\n\n    del model, device\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    output = np.concatenate(pred_list)\n\n    if use_sigmoid:\n        return sigmoid(output)\n    \n    return output\n\n\ndef run_inference(dataset_name=\"uspppm-results\", idx=0, RUN_ID=None):\n    print()\n    print(\"#\" * 30, f\"idx={idx}\", f\"RUN_ID={RUN_ID}\", \"#\" * 30)\n    \n    if RUN_ID is None:\n        input_dir = f\"../input/{dataset_name}\"\n    else:\n        input_dir = f\"../input/{dataset_name}/{RUN_ID}\"\n    \n    result = joblib.load(os.path.join(input_dir, \"results.pkl\"))\n    result.model_paths = [os.path.join(input_dir, path) for path in result.model_paths]\n    os.makedirs(f\"RUN{idx}\", exist_ok=True)\n    shutil.copy(os.path.join(input_dir, \"work.py\"), f\"RUN{idx}\")\n    \n    exec(f\"from RUN{idx} import work as work{idx}\")\n    \n    # run inference code\n    config_path = Path(input_dir, \"config.yaml\")\n    if os.path.exists(config_path):\n        with open(Path(input_dir, \"config.yaml\")) as f:\n            PRE_EVAL_CFG = yaml.safe_load(f.read())\n    else:\n        PRE_EVAL_CFG = yaml.safe_load(eval(f\"work{idx}.CONFIG_STRING\"))\n    \n    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n        train_df = pd.read_csv(Path(PRE_EVAL_CFG[\"globals\"][\"input_dir\"], \"train.csv\"))\n    else:\n        train_df = pd.read_csv(Path(PRE_EVAL_CFG[\"globals\"][\"input_dir\"], \"train.csv\"), nrows=500)\n    test_df = pd.read_csv(Path(PRE_EVAL_CFG[\"globals\"][\"input_dir\"], \"test.csv\"))\n    test_df[\"score\"] = 0.0\n    \n    CFG = Config(PRE_EVAL_CFG, types=eval(f\"work{idx}.CONFIG_TYPES\"))\n    \n    pred_sigmoid = isinstance(CFG[\"/metric/metric\"], eval(f\"work{idx}.PearsonCorrCoefWithLogitsMetric\"))\n    \n    for fold, model_path in enumerate(result.model_paths):\n        print(\"#\" * 30, f\"fold: {fold}\", \"#\" * 30)\n        print(\"#\" * 30, f\"model path: {model_path}\", \"#\" * 30)\n\n        \n        # train_predictions\n#         train_prediction = get_prediction(CFG, model_path, train_df, use_sigmoid=pred_sigmoid)\n#         np.save(f\"train_prediction_{idx}_fold{fold}\", train_prediction)\n\n        \n        # test_predictions\n        test_prediction = get_prediction(CFG, model_path, test_df, use_sigmoid=pred_sigmoid)\n        np.save(f\"test_prediction_{idx}_fold{fold}\", test_prediction)\n        test_df[\"score\"] += test_prediction / len(result.model_paths)\n\n\n\n        # train_features\n#         train_feature = get_feature(CFG, model_path, train_df)\n#         np.save(f\"train_feature_{idx}_fold{fold}\", train_feature)\n\n\n        # test_features\n#         test_feature = get_feature(CFG, model_path, test_df)\n#         np.save(f\"test_feature_{idx}_fold{fold}\", test_feature)\n\n        gc.collect()\n        print(memory_used_to_str())\n    \n    del PRE_EVAL_CFG, CFG\n    gc.collect()\n    \n    shutil.copy(os.path.join(input_dir, \"oof.csv\"), f\"oof_{idx}.csv\")\n    test_df[[\"id\", \"score\"]].to_csv(f\"submission_{idx}.csv\", index=False)\n\nargs = parse_arguments()\nrun_inference(dataset_name=args.dataset_name, idx=args.idx, RUN_ID=args.run_id)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:52:39.412594Z","iopub.execute_input":"2022-06-21T09:52:39.4129Z","iopub.status.idle":"2022-06-21T09:52:39.422691Z","shell.execute_reply.started":"2022-06-21T09:52:39.412859Z","shell.execute_reply":"2022-06-21T09:52:39.421747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -u process.py\n\n!python -u process.py --dataset-name=\"uspppm-public\" --run-id=018420c68d63460f9ad625d51bb3903f --idx=0\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=187e25eeeed943f08f6b450e47455542 --idx=1\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=56a4472423e54bd39ff7b02c0daa08ac --idx=2\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=7923146adde64b6a9643eb163d8d223f --idx=3\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=b02bfabced5345b689e6ac36e25a478c --idx=4\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=b977b33e7f8547bcb1e62e42e021e627 --idx=5\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=bc8145deac9d4376b708e8b1499da970 --idx=6\n# !python -u process.py --dataset-name=\"uspppm-public\" --run-id=e38625b57d3e4f00992c4f191a786c5d --idx=7\n\n# !python -u process.py --dataset-name=\"uspppm-results\" --run-id=9aa398aea22c4048b4e904c36bb3605b --idx=8\n# !python -u process.py --dataset-name=\"uspppm-results\" --run-id=c05c9ec899474ff58fb3552fe4a084ed --idx=9\n# !python -u process.py --dataset-name=\"uspppm-results\" --run-id=c54349cdef094923b1003ba22b394ce9 --idx=10\n# !python -u process.py --dataset-name=\"uspppm-results\" --run-id=dc95c61f15bf4ac0b9e1de3ac1299f45 --idx=11\n# !python -u process.py --dataset-name=\"uspppm-results\" --run-id=f87754b75cb54060b19527b551b3e6fe --idx=12","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:52:39.424255Z","iopub.execute_input":"2022-06-21T09:52:39.425092Z","iopub.status.idle":"2022-06-21T09:54:33.198775Z","shell.execute_reply.started":"2022-06-21T09:52:39.425052Z","shell.execute_reply":"2022-06-21T09:54:33.197858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make submission","metadata":{}},{"cell_type":"markdown","source":"## mean blending","metadata":{}},{"cell_type":"code","source":"import glob\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.stats import pearsonr\n\nimport numpy as np\nimport pandas as pd\n\n\ntrain = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n\noof_paths = sorted(glob.glob(\"oof_*.csv\"))\nsub_paths = sorted(glob.glob(\"submission_*.csv\"))\n\nprint(list(zip(oof_paths, sub_paths)))\n\nN = len(sub_paths)\n\nfor idx, (oof_path, sub_path) in enumerate(zip(oof_paths, sub_paths)):\n    print(f\"oof_path: {oof_path}, sub_path: {sub_path}\")\n    oof = pd.read_csv(oof_path)\n    sub = pd.read_csv(sub_path)\n\n    \n    scaler = MinMaxScaler((0, 1))\n    scaler.fit(np.concatenate([oof[[\"score\"]].to_numpy(), sub[[\"score\"]].to_numpy()]))\n\n    train[f\"score_{idx}\"] = scaler.transform(train[[\"id\"]].merge(oof, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n    value = pearsonr(train['score'], train[f'score_{idx}'])[0]\n    print(f\"pearsonr: {value}\")\n    \n    test[f\"score_{idx}\"] = scaler.transform(test[[\"id\"]].merge(sub, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n\nprint(\"#\" * 100)\ncols = [f\"score_{idx}\" for idx in range(N)]\ntrain[\"oof_score\"] = train[cols].mean(axis=1)\ntest[\"score\"] = test[cols].mean(axis=1)\nvalue = pearsonr(train['score'], train[\"oof_score\"])[0]\nprint(f\"pearsonr: {value}\")\nprint(\"#\" * 100)\n\ntest[[\"id\", \"score\"]].to_csv(\"submission.csv\", index=False)\npd.read_csv(\"submission.csv\", nrows=30)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:54:33.200379Z","iopub.execute_input":"2022-06-21T09:54:33.200654Z","iopub.status.idle":"2022-06-21T09:54:33.877773Z","shell.execute_reply.started":"2022-06-21T09:54:33.200615Z","shell.execute_reply":"2022-06-21T09:54:33.873996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Nelder-Mead","metadata":{}},{"cell_type":"code","source":"# import glob\n# from sklearn.preprocessing import MinMaxScaler\n# from scipy.optimize import minimize\n# from scipy.stats import pearsonr\n\n# import numpy as np\n# import pandas as pd\n\n\n# train = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\n# test = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n\n# oof_paths = sorted(glob.glob(\"oof_*.csv\"))\n# sub_paths = sorted(glob.glob(\"submission_*.csv\"))\n\n# N = len(sub_paths)\n# cols = [f\"score_{idx}\" for idx in range(N)]\n\n# for idx, (oof_path, sub_path) in enumerate(zip(oof_paths, sub_paths)):\n#     print(f\"oof_path: {oof_path}, sub_path: {sub_path}\")\n#     oof = pd.read_csv(oof_path)\n#     sub = pd.read_csv(sub_path)\n\n    \n#     scaler = MinMaxScaler((0, 1))\n#     scaler.fit(np.concatenate([oof[[\"score\"]].to_numpy(), sub[[\"score\"]].to_numpy()]))\n\n#     train[f\"score_{idx}\"] = scaler.transform(train[[\"id\"]].merge(oof, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n#     value = pearsonr(train['score'], train[f'score_{idx}'])[0]\n#     print(f\"pearsonr: {value}\")\n    \n#     test[f\"score_{idx}\"] = scaler.transform(test[[\"id\"]].merge(sub, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n\n\n\n# def func(x):\n#     pred = np.average(train[cols], weights=x, axis=1)\n#     return -pearsonr(train[\"score\"], pred)[0]\n\n# x0 = [1] * N\n# result = minimize(func, x0, method='Nelder-Mead')\n\n# result_weights = result.x\n# result_value = result.fun\n\n# print(\"#\" * 100)\n# print(f\"result_weights: {result_weights}\")\n# print(f\"result_value: {-result_value}\")\n# print(\"#\" * 100)\n\n\n# test[\"score\"] = np.average(test[cols], weights=result_weights, axis=1)\n\n# test[[\"id\", \"score\"]].to_csv(\"submission.csv\", index=False)\n# pd.read_csv(\"submission.csv\", nrows=30)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:54:33.879341Z","iopub.execute_input":"2022-06-21T09:54:33.879625Z","iopub.status.idle":"2022-06-21T09:54:33.889945Z","shell.execute_reply.started":"2022-06-21T09:54:33.879588Z","shell.execute_reply":"2022-06-21T09:54:33.888821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Nelder-Mead(gmean)","metadata":{}},{"cell_type":"code","source":"# import glob\n# from sklearn.preprocessing import MinMaxScaler\n# from scipy.optimize import minimize\n# from scipy.stats import pearsonr, gmean\n\n# import numpy as np\n# import pandas as pd\n\n\n# train = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\n# test = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n\n# oof_paths = sorted(glob.glob(\"oof_*.csv\"))\n# sub_paths = sorted(glob.glob(\"submission_*.csv\"))\n\n# N = len(sub_paths)\n# cols = [f\"score_{idx}\" for idx in range(N)]\n\n# for idx, (oof_path, sub_path) in enumerate(zip(oof_paths, sub_paths)):\n#     print(f\"oof_path: {oof_path}, sub_path: {sub_path}\")\n#     oof = pd.read_csv(oof_path)\n#     sub = pd.read_csv(sub_path)\n\n    \n#     scaler = MinMaxScaler((0.0001, 1))\n#     scaler.fit(np.concatenate([oof[[\"score\"]].to_numpy(), sub[[\"score\"]].to_numpy()]))\n\n#     train[f\"score_{idx}\"] = scaler.transform(train[[\"id\"]].merge(oof, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n#     value = pearsonr(train['score'], train[f'score_{idx}'])[0]\n#     print(f\"pearsonr: {value}\")\n    \n#     test[f\"score_{idx}\"] = scaler.transform(test[[\"id\"]].merge(sub, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n\n\n\n# def func(x):\n#     pred = gmean(train[cols], weights=x, axis=1)\n#     return -pearsonr(train[\"score\"], pred)[0]\n\n# x0 = [1] * N\n# result = minimize(func, x0, method='Nelder-Mead')\n\n# result_weights = result.x\n# result_value = result.fun\n\n# print(\"#\" * 100)\n# print(f\"result_weights: {result_weights}\")\n# print(f\"result_value: {-result_value}\")\n# print(\"#\" * 100)\n\n# predictions = gmean(test[cols], weights=result_weights, axis=1)\n\n# test[\"score\"] = predictions\n\n# test[[\"id\", \"score\"]].to_csv(\"submission.csv\", index=False)\n# pd.read_csv(\"submission.csv\", nrows=30)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:54:33.891596Z","iopub.execute_input":"2022-06-21T09:54:33.892122Z","iopub.status.idle":"2022-06-21T09:54:33.904059Z","shell.execute_reply.started":"2022-06-21T09:54:33.892084Z","shell.execute_reply":"2022-06-21T09:54:33.902774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking(skearn)","metadata":{}},{"cell_type":"code","source":"# import glob\n# import copy\n# from sklearn.preprocessing import MinMaxScaler\n# from scipy.optimize import minimize\n# from scipy.stats import pearsonr\n\n# import numpy as np\n# import pandas as pd\n\n# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n# from sklearn.linear_model import LinearRegression, BayesianRidge, Lasso\n# from sklearn.svm import SVR\n# from sklearn.gaussian_process import GaussianProcessRegressor\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.decomposition import PCA\n\n# def prepare_fold(df: pd.DataFrame, n_fold: int, seed: int):\n#     dfx = (\n#         pd.get_dummies(df, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n#     )\n#     cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n#     dfx = dfx[cols]\n\n#     mskf = MultilabelStratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n#     labels = [c for c in dfx.columns if c != \"anchor\"]\n#     dfx_labels = dfx[labels]\n#     dfx[\"fold\"] = -1\n\n#     for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n#         dfx.loc[val_, \"fold\"] = fold\n\n#     fold_array = df.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")[\n#         \"fold\"\n#     ].to_numpy()\n#     df[\"fold\"] = fold_array\n\n#     print(\"#\" * 30, \"folds\", \"#\" * 30)\n#     print(df[\"fold\"].value_counts())\n\n\n# train = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\n# test = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n# test[\"score\"] = 0.0\n\n# oof_paths = sorted(glob.glob(\"oof_*.csv\"))\n# sub_paths = sorted(glob.glob(\"submission_*.csv\"))\n\n# N = len(sub_paths)\n# cols = [f\"score_{idx}\" for idx in range(N)]\n\n# for idx, (oof_path, sub_path) in enumerate(zip(oof_paths, sub_paths)):\n#     print(f\"oof_path: {oof_path}, sub_path: {sub_path}\")\n#     oof = pd.read_csv(oof_path)\n#     sub = pd.read_csv(sub_path)\n\n    \n#     scaler = MinMaxScaler((0, 1))\n#     scaler.fit(np.concatenate([oof[[\"score\"]].to_numpy(), sub[[\"score\"]].to_numpy()]))\n\n#     train[f\"score_{idx}\"] = scaler.transform(train[[\"id\"]].merge(oof, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n#     value = pearsonr(train['score'], train[f'score_{idx}'])[0]\n#     print(f\"pearsonr: {value}\")\n    \n#     test[f\"score_{idx}\"] = scaler.transform(test[[\"id\"]].merge(sub, on=\"id\")[\"score\"].to_numpy().reshape(-1, 1)).reshape(-1)\n\n    \n# #     train[f\"score_{idx}\"] = train[[\"id\"]].merge(oof, on=\"id\")[\"score\"].to_numpy()\n# #     value = pearsonr(train['score'], train[f'score_{idx}'])[0]\n# #     print(f\"pearsonr: {value}\")\n    \n# #     test[f\"score_{idx}\"] = test[[\"id\"]].merge(sub, on=\"id\")[\"score\"].to_numpy()\n\n\n# def stacking(model, df, n_fold, seed):\n#     np.random.seed(seed)\n#     prepare_fold(df, n_fold=n_fold, seed=seed)\n#     oof = np.zeros(len(train))\n#     models = []\n#     for fold in range(n_fold):\n#         tr, val = df.loc[df[\"fold\"] != fold], df.loc[df[\"fold\"] == fold]\n#         model.fit(tr[cols], tr[\"score\"])\n        \n#         oof[df[\"fold\"] == fold] = model.predict(val[cols])\n#         models.append(copy.deepcopy(model))\n\n#     score = pearsonr(train[\"score\"], oof)[0]\n#     print(\"#\" * 30)\n#     print(\"OOF:\", score)\n#     print(\"#\" * 30)\n    \n#     return models, oof\n\n# oof = np.zeros(len(train))\n\n# seeds = [42, 1221, 128, 256, 512, 1024]\n# models = []\n\n# for seed in seeds:\n#     print(f\"seed: {seed}\")\n#     model = BayesianRidge()\n#     _models, _oof = stacking(model, train.copy(), n_fold=10, seed=seed)\n#     oof += _oof\n#     models.extend(_models)\n\n\n# score = pearsonr(train[\"score\"], oof)[0]\n# print(f\"ALL OOF: {score}\")\n\n# for idx, model in enumerate(models):\n#     print(f\"idx: {idx}, model: {model}\")\n#     predictions = model.predict(test[cols])\n    \n#     test[\"score\"] += predictions\n\n# test[[\"id\", \"score\"]].to_csv(\"submission.csv\", index=False)\n# pd.read_csv(\"submission.csv\", nrows=30)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:54:33.905716Z","iopub.execute_input":"2022-06-21T09:54:33.906103Z","iopub.status.idle":"2022-06-21T09:54:33.923199Z","shell.execute_reply.started":"2022-06-21T09:54:33.906068Z","shell.execute_reply":"2022-06-21T09:54:33.922268Z"},"trusted":true},"execution_count":null,"outputs":[]}]}