{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# In this notebook we attempt a solution as a baseline \n\n### We will be using BERT as the model and computing the cosine similarity\n### between the anchor and text without considering the context","metadata":{"editable":false}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numpy.linalg import norm\nfrom scipy.stats import pearsonr\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize, pos_tag","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wnl = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\").drop(columns=[\"id\"])\ntest_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\").drop(columns=[\"id\"])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"anchor\"].nunique(), train_df[\"context\"].nunique(), train_df[\"target\"].nunique()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions:","metadata":{"editable":false}},{"cell_type":"code","source":"def clean_text(corpus, remove_stop_words = True):\n    '''\n    Function to clean a given corpus - lower the words, strip of the spaces, remove stopwords and lemmatize the corpus\n    Args:\n        corpus: the text to be cleaned\n        remove_stop_words: whether to remove stopwords\n    Returns:\n        filtered_sentence: cleaned corpus\n    '''\n    corpus = corpus.lower().strip()\n    word_tokens = word_tokenize(corpus)\n    if remove_stop_words:\n        filtered_sentence = \" \".join([wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(corpus)) if i not in stop_words])\n    else:\n        filtered_sentence = \" \".join([wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(corpus))])\n    return filtered_sentence\n\ndef cosine(a,b):\n    '''\n    Function to calculate cosine similarity of two vectors\n    Args:\n        a,b: vectors to calculate cosine between a and b\n    Returns:\n        cosine similarity of the given vectors\n    '''\n    return np.dot(a,b)/(norm(a)*norm(b))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"anchor\"] = train_df[\"anchor\"].apply(lambda x: clean_text(x,False))\ntrain_df[\"target\"] = train_df[\"target\"].apply(lambda x: clean_text(x,False))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')\n\nmodelPath = \"/kaggle/working/bert-base\"\n\nmodel.save(modelPath)\n# model = SentenceTransformer(modelPath)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anchors = train_df[\"anchor\"].to_list()\nanchor_embed = model.encode(anchors,show_progress_bar=True, batch_size=128)##explore normalize embeddings param","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train_df[\"target\"].to_list()\ntarget_embed = model.encode(targets,show_progress_bar=True, batch_size=128)##explore normalize embeddings param","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sims = [cosine(i[0],i[1]) for i in zip(anchor_embed,target_embed)]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_val = max(sims)\nmin_val = min(sims)\nsim_norm = (sims-min_val)/(max_val-min_val)\nsim_norm = np.floor(sim_norm*4)/4","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np.array(train_df[\"score\"].to_list())","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr,_ = pearsonr(y,sim_norm)\nprint(corr)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Although the obtained correlation isn't that good, but its good enough for a baseline solution \n## without context and build up from this point","metadata":{"editable":false}},{"cell_type":"markdown","source":"### Following lines are to get the sentence-transfromer package as a github repo","metadata":{"editable":false}},{"cell_type":"code","source":"!git clone https://github.com/UKPLab/sentence-transformers.git","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"/kaggle/working/\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}