{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Gaussian Mixture Model\n\nHere I fit gaussian mixture model to a data of a few places. "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn import mixture\nimport matplotlib.pyplot as plt\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.read_csv('../input/train.csv',\n                        usecols=['x','y','time','place_id','accuracy'], \n                        index_col = 'place_id')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"place_id = pd.DataFrame(train.index.value_counts())\nplace_id.columns = ['count']\nplace_id.index.name = 'place_id'\nplace_id = place_id.iloc[:40]\ntrain = train[train.index.isin(place_id.index)]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\ndef fit_gmm(X):\n    score = np.zeros(X.shape[0])\n    for i in range(10,0,-1):\n        gmm = mixture.GMM(n_components=i, covariance_type='tied', min_covar=0.0001)\n        gmm.fit(X[score>-7].values)\n        if (gmm.weights_<0.003).sum() == 0:\n            #print(i)\n            break\n        score = gmm.score(X)\n    return gmm\n\ng = train[['x','y']].groupby(level=0)\nplace_id['gmm'] = g.apply(fit_gmm)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# adapted from http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm.html\nfrom scipy import linalg\nimport matplotlib as mpl\nimport itertools\n\nplt.rcParams['figure.figsize'] = (16,32)\n\ncolor_iter = itertools.cycle(['r', 'g', 'b', 'c', 'm', 'y','gray','brown'])\n\n#splot = plt.subplot(4, 1, 1)\n\np = [1,6, 10, 16, 21, 26, 31, 33, 35]\n\nfor j in range(len(p)):\n    clf = place_id.gmm.iloc[p[j]]\n    X = train.loc[place_id.index[p[j]], ['x','y']].values\n    Y_ = clf.predict(X)\n    splot = plt.subplot(9, 1, 1 +j)\n        \n    for i, (mean, covar, color) in enumerate(zip(\n            clf.means_, clf._get_covars(), color_iter)):\n        v, w = linalg.eigh(covar)\n        u = w[0] / linalg.norm(w[0])\n        # as the DP will not use every component it has access to\n        # unless it needs it, we shouldn't plot the redundant\n        # components.\n        #if not np.any(Y_ == i):\n        #    continue\n        splot.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .5, color=color, alpha=0.5)\n        \n        # Plot an ellipse to show the Gaussian component\n        angle = np.arctan(u[1] / u[0])\n        angle = 180 * angle / np.pi  # convert to degrees\n        #print(j, color)\n        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180 + angle, color=color)\n        ell.set_clip_box(splot.bbox)\n        ell.set_alpha(0.5)\n        splot.add_artist(ell)\n\n    plt.xlim(0,10)\n    plt.title(str(p[j])+', '+str(clf.n_components))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}