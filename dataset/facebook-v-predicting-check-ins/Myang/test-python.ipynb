{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# # Start to look at the data folder\n# This code is learned from AnujChopra\n\n#This code helps to find out feature multipliers for KNN.\n#This is shown using some features derived by me but this method can be extended for other features as well.\n#One needs to derive his own features and then apply similar approach to get the correct weights.\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\n\nprint(os.listdir(\"../input/\")) \n# # Start to look at the data\nmy_train=pd.read_csv('../input/train.csv')\nprint(my_train.sample(10))\nprint(len(my_train.index))\n#print()\n\nsample_train=my_train.sample(1000)[['x','y','place_id']]\ngroups = sample_train.groupby('place_id')\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Plot\nplt.rcParams.update(pd.tools.plotting.mpl_stylesheet)\n#colors = pd.tools.plotting._get_standard_colors(len(groups), color_type='random')\n#import matplotlib.pyplot as plt\n#fig, ax = plt.subplots()\n#ax.set_color_cycle(colors)\n#ax.margins(0.05)\n#for name, group in groups:\n#    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n#ax.legend(numpoints=1, loc='upper left')\n#plt.show()\n# Plot\nfig, ax = plt.subplots()\nax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\nfor name, group in groups:\n    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\nax.legend()\n\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#select a single x_y_grid at random\n#recent_train = recent_train[(recent_train[\"x\"]>4.5) &(recent_train[\"x\"]<5) &(recent_train[\"y\"]>2) &(recent_train[\"y\"]<2.3)]\n#derive some features\nrecent_train[\"x\"],recent_train[\"y\"] = recent_train[\"x\"]*1000,recent_train[\"y\"]*1000\nrecent_train[\"hour\"] = recent_train[\"time\"]//60\nrecent_train[\"hour_of_day\"] = recent_train[\"hour\"]%24 + 1\n\nrecent_train[\"day\"] = recent_train[\"hour\"]//24\nrecent_train[\"day_of_week\"] = recent_train[\"day\"]%7 + 1\n\nrecent_train[\"month\"] = recent_train[\"day\"]//30 + 1\nrecent_train[\"month_of_year\"] = (recent_train[\"month\"]-1)%12 + 1 \n\nrecent_train[\"sine\"] = np.sin(2*np.pi*recent_train[\"hour_of_day\"]/24)\nrecent_train[\"cos\"] = np.cos(2*np.pi*recent_train[\"hour_of_day\"]/24)\n\nrecent_train[\"year\"] = recent_train[\"day\"]//365 + 1\n\nprint(\"recent_train created\")\n\n#creating arbitrary test\ntest = recent_train.sample(axis = 0,frac = 0.05)\nprint (\"selected_part and test created\")\nfeatures = [\"x\",\"y\",\"hour_of_day\",\"day_of_week\",\"month_of_year\",\"year\",\"sine\",\"cos\",\"accuracy\"]\nconstant = [0,0,0,0,0,0,0,0,0]\n\nprint (len(test))\n\ncolname = str(features)\ntest[colname] = list\nindex = test.index\ntest[\"done\"] = 0\nfor i in index:\n    #manhattan distance between train and test[i]\n    new_ld = abs(recent_train[features] - test.loc[i][features])\n    new_ld = new_ld.drop(i)\n    new_ld[\"target\"] = (recent_train[\"place_id\"] != test.loc[i][\"place_id\"]) + 0\n    #select 100 nearest points based on x+2y distance \n    new_ld[\"x+y\"] = (new_ld[\"x\"])+(2*new_ld[\"y\"])\n    new_ld = new_ld.sort(\"x+y\")[0:100]\n    true = new_ld[new_ld[\"target\"] == 0]\n    false = new_ld[new_ld[\"target\"] != 0]\n    #check for skewness\n    if (len(true)< 20) | (len(false)< 20):\n        print (\"skipped test sample -\",i)\n        continue\n    #get the multipliers which can distinguish between 0 and 1\n    lr.fit(new_ld[features],new_ld[\"target\"])\n    test.set_value(i,colname,np.maximum(constant,lr.coef_.ravel()))\n#    actual_test.set_value(i,colname,lr.coef_.ravel())\n    test.set_value(i,\"done\",1)\n    print (\"done test sample\",i)\n\n\n#average or sum all the multipliers to get overall multiplier\nactual_test2 = test[test[\"done\"]==1]\nfinal_weights = np.array([0,0,0,0,0,0,0,0,0])\nfor lists in actual_test2[colname]:\n    final_weights = final_weights + lists\n\n\nprint (features) \nprint (\"corresponding weights\")\nprint (final_weights)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}