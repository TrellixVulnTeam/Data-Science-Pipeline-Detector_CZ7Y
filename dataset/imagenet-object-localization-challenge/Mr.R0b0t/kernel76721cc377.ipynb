{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/imagenet-subset/subset_dataset/ILSVRC/ImageSets/CLS-LOC/train'):\n#    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n    print(dirname)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nimport subprocess\nfrom xml.dom import minidom\nfrom os.path import basename\nimport cv2 \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xml_folder=r'/kaggle/input/imagenet-subset/subset_dataset/ILSVRC/Annotations/CLS-LOC/train/'\ntrain_folder=r'/kaggle/input/imagenet-subset/subset_dataset/ILSVRC/Data/CS-LOC/train/'\ntest_folder=r'/kaggle/input/imagenet-subset/subset_dataset/ILSVRC/Data/CS-LOC/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample image\nPIL.Image.open('/kaggle/input/imagenet-subset/subset_dataset/ILSVRC/Data/CS-LOC/train/n01580077/n01580077_28541.JPEG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch size\nbatch_size=16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(train_folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the train image classes\nsubdir= [name for name in os.listdir(\".\") if os.path.isdir(name)]\nsubdir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to convert the labels from PASCAL VOC to required strings \ndef xmlToTxt(xml_path,f_name,f_w,f_h,f_x,f_y):\n    mydoc=minidom.parse(xml_path)\n#     folder=mydoc.getElementsByTagName('folder')[0].firstChild.data\n#     filername=mydoc.getElementsByTagName('filename')[0].firstChild.data\n    folder=os.path.basename(os.path.dirname(xml_path))\n    filername=os.path.splitext(basename(xml_path))[0]\n    width=float(mydoc.getElementsByTagName('width')[0].firstChild.data)\n    height=float(mydoc.getElementsByTagName('height')[0].firstChild.data)\n    objects=mydoc.getElementsByTagName('object')\n    #to_save=target_forder\n    #if(isCreatePfolder):\n    #    to_save = os.path.join(target_forder, folder)\n    #pathlib.Path(to_save).mkdir(parents=True, exist_ok=True)\n\n    for obj in objects:\n        name=obj.getElementsByTagName('name')[0].firstChild.data\n        #name_index=str(df.loc[df[0]==name].index[0])\n        xmin=float(obj.getElementsByTagName('xmin')[0].firstChild.data)\n        ymin=float(obj.getElementsByTagName('ymin')[0].firstChild.data)\n        xmax=float(obj.getElementsByTagName('xmax')[0].firstChild.data)\n        ymax=float(obj.getElementsByTagName('ymax')[0].firstChild.data)\n        w=xmax-xmin\n        h=ymax-ymin\n        x=xmax-w/2\n        y=ymin+h/2\n        \n        f_name.append(filername)\n        f_w.append(w)\n        f_h.append(h)\n        f_x.append(x)\n        f_y.append(y)\n    return folder,f_name,f_w,f_h,f_x,f_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to create a dataframe for each image class and its localization cordinates \n\n#map_file=\n#df=pd.read_csv(map_file, sep='\\t', header=None)\nlabels={}\nfor s in subdir:\n    labels[s]=pd.DataFrame()\nfor target, dirs, files in os.walk(xml_folder):\n    filename=None\n    f_name=[]\n    f_w=[]\n    f_h=[]\n    f_x=[]\n    f_y=[]\n    for file in files:\n        if file.endswith(\".xml\"):\n            filename,f_name,f_w,f_h,f_x,f_y=xmlToTxt(os.path.join(target, file),f_name,f_w,f_h,f_x,f_y)\n    #print(filename)\n    if filename != None :\n        (labels[filename])['Name']=f_name\n        (labels[filename])['width']=f_w\n        (labels[filename])['height']=f_h\n        (labels[filename])['X']=f_x\n        (labels[filename])['Y']=f_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels['n01532829'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"REPO_LOCATION = 'https://github.com/pjreddie/darknet'\nREPO_NAME = 'darknet'\nREPO_BRANCH = 'master'\n\n# Clone the repository\nprint('cloning the repository')\nsubprocess.call(['git', 'clone', '-b', REPO_BRANCH, REPO_LOCATION])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.applications import imagenet_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wget\n\nprint('Beginning download of yolo weights')\n\nurl = 'https://pjreddie.com/media/files/yolov3.weights'\nwget.download(url,'/kaggle/working/yolov3.weights')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import struct\nimport numpy as np\nfrom keras.layers import Conv2D\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import UpSampling2D\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model\nfrom numpy import expand_dims\nfrom keras.models import load_model\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _conv_block(inp, convs, skip=True):\n\tx = inp\n\tcount = 0\n\tfor conv in convs:\n\t\tif count == (len(convs) - 2) and skip:\n\t\t\tskip_connection = x\n\t\tcount += 1\n\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n\t\tx = Conv2D(conv['filter'],\n\t\t\t\t   conv['kernel'],\n\t\t\t\t   strides=conv['stride'],\n\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n\treturn add([skip_connection, x]) if skip else x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_yolov3_model():\n\tinput_image = Input(shape=(None, None, 3))\n\t# Layer  0 => 4\n\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n\t# Layer  5 => 8\n\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n\t# Layer  9 => 11\n\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n\t# Layer 12 => 15\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n\t# Layer 16 => 36\n\tfor i in range(7):\n\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n\tskip_36 = x\n\t# Layer 37 => 40\n\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n\t# Layer 41 => 61\n\tfor i in range(7):\n\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n\tskip_61 = x\n\t# Layer 62 => 65\n\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n\t# Layer 66 => 74\n\tfor i in range(3):\n\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n\t# Layer 75 => 79\n\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n\t# Layer 80 => 82\n\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n\t# Layer 83 => 86\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n\tx = UpSampling2D(2)(x)\n\tx = concatenate([x, skip_61])\n\t# Layer 87 => 91\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n\t# Layer 92 => 94\n\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n\t# Layer 95 => 98\n\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n\tx = UpSampling2D(2)(x)\n\tx = concatenate([x, skip_36])\n\t# Layer 99 => 106\n\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WeightReader:\n\tdef __init__(self, weight_file):\n\t\twith open(weight_file, 'rb') as w_f:\n\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n\t\t\trevision, = struct.unpack('i', w_f.read(4))\n\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n\t\t\t\tw_f.read(8)\n\t\t\telse:\n\t\t\t\tw_f.read(4)\n\t\t\ttranspose = (major > 1000) or (minor > 1000)\n\t\t\tbinary = w_f.read()\n\t\tself.offset = 0\n\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n \n\tdef read_bytes(self, size):\n\t\tself.offset = self.offset + size\n\t\treturn self.all_weights[self.offset-size:self.offset]\n \n\tdef load_weights(self, model):\n\t\tfor i in range(106):\n\t\t\ttry:\n\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n\t\t\t\tif i not in [81, 93, 105]:\n\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n\t\t\t\t\tgamma = self.read_bytes(size) # scale\n\t\t\t\t\tmean  = self.read_bytes(size) # mean\n\t\t\t\t\tvar   = self.read_bytes(size) # variance\n\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n\t\t\t\tif len(conv_layer.get_weights()) > 1:\n\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n\t\t\t\telse:\n\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n\t\t\t\t\tconv_layer.set_weights([kernel])\n\t\t\texcept ValueError:\n\t\t\t\tprint(\"no convolution #\" + str(i))\n \n\tdef reset(self):\n\t\tself.offset = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the model\nyolo_model = make_yolov3_model()\n# load the model weights\nweight_reader = WeightReader('/kaggle/working/yolov3.weights')\n# set the model weights into the model\nweight_reader.load_weights(yolo_model)\n# save the model to file\n#yolo_model.save('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yolo_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image_pixels(filename, shape):\n    # load the image to get its shape\n    image = load_img(filename)\n    width, height = image.size\n    # load the image with the required size\n    image = load_img(filename, target_size=shape)\n    # convert to numpy array\n    image = img_to_array(image)\n    # normalize the image\n    image = image.astype('float32')\n    image /= 255.0\n    # add a dimension for predict\n    image = expand_dims(image, 0)\n    return image, width, height","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the anchors boxes\nanchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n# define the probability threshold for detected objects\nclass_threshold = 0.6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _interval_overlap(interval_a, interval_b):\n    x1, x2 = interval_a\n    x3, x4 = interval_b\n\n    if x3 < x1:\n        if x4 < x1:\n            return 0\n        else:\n            return min(x2,x4) - x1\n    else:\n        if x2 < x3:\n             return 0\n        else:\n            return min(x2,x4) - x3          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bbox_iou(box1, box2):\n    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n    \n    intersect = intersect_w * intersect_h\n\n    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n    \n    union = w1*h1 + w2*h2 - intersect\n    \n    return float(intersect) / union","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BoundBox:\n    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n        self.xmin = xmin\n        self.ymin = ymin\n        self.xmax = xmax\n        self.ymax = ymax\n        \n        self.objness = objness\n        self.classes = classes\n\n        self.label = -1\n        self.score = -1\n\n    def get_label(self):\n        if self.label == -1:\n            self.label = np.argmax(self.classes)\n        \n        return self.label\n    \n    def get_score(self):\n        if self.score == -1:\n            self.score = self.classes[self.get_label()]\n            \n        return self.score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n    grid_h, grid_w = netout.shape[:2]\n    nb_box = 3\n    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n    nb_class = netout.shape[-1] - 5\n\n    boxes = []\n\n    netout[..., :2]  = _sigmoid(netout[..., :2])\n    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n\n    for i in range(grid_h*grid_w):\n        row = i / grid_w\n        col = i % grid_w\n        \n        for b in range(nb_box):\n            # 4th element is objectness score\n            objectness = netout[int(row)][int(col)][b][4]\n            #objectness = netout[..., :4]\n            \n            if(objectness.all() <= obj_thresh): continue\n            \n            # first 4 elements are x, y, w, and h\n            x, y, w, h = netout[int(row)][int(col)][b][:4]\n\n            x = (col + x) / grid_w # center position, unit: image width\n            y = (row + y) / grid_h # center position, unit: image height\n            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n            \n            # last elements are class probabilities\n            classes = netout[int(row)][col][b][5:]\n            \n            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n\n            boxes.append(box)\n\n    return boxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_nms(boxes, nms_thresh):\n    if len(boxes) > 0:\n        nb_class = len(boxes[0].classes)\n    else:\n        return\n        \n    for c in range(nb_class):\n        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n\n        for i in range(len(sorted_indices)):\n            index_i = sorted_indices[i]\n\n            if boxes[index_i].classes[c] == 0: continue\n\n            for j in range(i+1, len(sorted_indices)):\n                index_j = sorted_indices[j]\n\n                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n                    boxes[index_j].classes[c] = 0\n                    \n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxes(image, boxes, labels, obj_thresh):\n    for box in boxes:\n        label_str = ''\n        label = -1\n        \n        for i in range(len(labels)):\n            if box.classes[i] > obj_thresh:\n                label_str += labels[i]\n                label = i\n                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\n                \n        if label >= 0:\n            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\n            cv2.putText(image, \n                        label_str + ' ' + str(box.get_score()), \n                        (box.xmin, box.ymin - 13), \n                        cv2.FONT_HERSHEY_SIMPLEX, \n                        1e-3 * image.shape[0], \n                        (0,255,0), 2)\n        \n    return image ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n    if (float(net_w)/image_w) < (float(net_h)/image_h):\n        new_w = net_w\n        new_h = (image_h*net_w)/image_w\n    else:\n        new_h = net_w\n        new_w = (image_w*net_h)/image_h\n        \n    for i in range(len(boxes)):\n        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n        \n        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path='/kaggle/input/imagenet-subset/subset_dataset/ILSVRC/Data/CS-LOC/train/n01580077/n01580077_28541.JPEG'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_thresh, nms_thresh = 0.7, 0.60\nnet_h, net_w = 416, 416","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_box(image_path,yolo_model):\n    \n    image,w,h=load_image_pixels(image_path,(416, 416))\n    yolos=yolo_model.predict(image)\n    \n    boxes = []\n    labels=[]\n    image = cv2.imread(image_path)\n    image_h, image_w, _ = image.shape\n    for i in range(len(yolos)):\n            # decode the output of the network\n        boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n\n    # correct the sizes of the bounding boxes\n    correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n\n    # suppress non-maximal boxes\n    do_nms(boxes, nms_thresh)     \n\n        # draw bounding boxes on the image using labels\n        #draw_boxes(image, boxes, labels, obj_thresh) \n        #plt.imshow(image)\n        # write the image with bounding boxes to file\n        \n        #cv2.imshow('sample',image) \n    box = (boxes[0].xmin,boxes[0].xmax,boxes[0].ymin,boxes[0].ymax)\n    return box","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=[]\n\nfor target, dirs, files in os.walk(test_folder):\n    for file in files :\n        if file.endswith('.JPEG')or file.endswith('.JPG') or file.endswith('.PNG') :\n            predictions.append((file.split('.')[0],return_box(os.path.join(target, file),yolo_model)))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}