{"cells":[{"metadata":{"_uuid":"140ab0533aa6ce88d9e126ba2fc60758b282cddc"},"cell_type":"markdown","source":"## AAM / Machine Learning - Atividade Final\n\n**Identificação**:\n\n*Renan Renger* - RA: 183148\n\n**Projeto**\n\n*Essa avaliação consiste em avaliar se um determinado jogador pontuou ou não em determinados lances, cujas informações foram coletadas de uma série de jogos de basquete. A coluna de rótulo é \"shot_made_flag\", e trata-se de um problema de classificação.*\n\n**Observação**\n\n*Vide Regras*\n\n**Regras**\n\n*Atividade individual;*\n\n*Na primeira célula do notebook, deve conter o nome completo do aluno;*\n\n*O aluno será avaliado em todos os tópicos expostos em sala de aula;*\n\n*O aluno deve justificar suas escolhas e criar células de comentário anterior a todo código e resultado, evidenciando o que fez e por que fez;*\n\n*As linhas onde o rótulo estiver vazio deverão ser descartadas;*\n\n*A coluna de rótulo é \"shot_made_flag\";*\n\n*Separação dos dados: 30% para teste e 70% para treino.*\n"},{"metadata":{"_uuid":"1a7654aaf347e25084cbe7356064efadc9fcc25a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d35574e8e2a6db2bc80d28529fbafc1b103a7e4"},"cell_type":"markdown","source":"## Os gráficos abaixo foram copiados do Kernel fornecido como exemplo ao fazer o upload do dataset e são usados somente para contextualizar alguns dos pontos expostos a diante"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"25476717ffd56b86d04a9e306e7501236295381e"},"cell_type":"code","source":"# Distribution graphs (histogram/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"acecb6435312200fed68af84fb05d9bc2a8962a4"},"cell_type":"code","source":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"fae45221f7ba4a2da8cbb0bcc50ed73d8db1bb75"},"cell_type":"code","source":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7418c7b14b9e66afe65c1acbf34c8603edb80a4f","trusted":true},"cell_type":"code","source":"dfBase = pd.read_csv('../input/kobe-bryant-shot-selection/data.csv')\ndfBase.dataframeName = 'kobe-bryant-shot-selection.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1be6e280a99d03758fbc4994e7f7bb6844c50e42"},"cell_type":"code","source":"print('Dataset Base - Sumário das Features')\nprint(dfBase.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9055a39e3e27162b69a28e8356c6cf8b6c4a4da"},"cell_type":"markdown","source":"# Observações sobre as Features\n## lat, loc_X, loc_Y e lon\nComo dito [aqui](https://sports.stackexchange.com/questions/13838/definition-of-positional-terms-latitude-longitude-of-basketball-shots), os valores de **loc_X** e **loc_Y** fazem referencia a distância da cesta em cada um dos eixos, da seguinte forma:\n\n### **loc_X** -> Eixo X, com 0 na cesta, correndo pela linha de fundo da quadra e com valores positivos e negativos sendo possíveis; Positivos representam pontos a esqueda (ou acima, quando visto de cima) da cesta, enquanto valores negativos representam pontos a direita da cesta (ou abaixo dela, quando visto de cima);\n\n### **loc_Y** -> Eixo Y, com 0 na cesta, máximo no centro da quadra e valores tanto positivos quando levemente negativos; O valor atinge um máximo (o centro da quadra) e reduz até 0 novamente quando nos dirigimos a cesta oposta; Valores negativos representam o pequeno espaço entre a cesta e a linha de fundo da quadra;\n\n### **lat e lon** -> Ao que tudo indica, são valores \"inuteis\" e feitos com base em algum referencial não conhecido; Serão descartados durante a analise;\n\n---\n"},{"metadata":{"_uuid":"17c7b96681c5b098d4bc1ecd862b9f54ec39f843","trusted":true},"cell_type":"code","source":"headNumber = 5\nprint(f'Dataset Base - Primeiras {headNumber} linhas')\ndisplay(dfBase.head(headNumber))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3c620fc418e9e13abea019149eaf2a3d612711b","trusted":true},"cell_type":"code","source":"print('Dataset Base - Estatistica descritiva')\ndisplay(dfBase.describe())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62630365986dbf806707c1805f9fe5ab752555e","trusted":true},"cell_type":"code","source":"print(f'Dataset de treino tem {dfBase.shape[0]} linhas por {dfBase.shape[1]} colunas ({dfBase.shape[0] * dfBase.shape[1]} celulas)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c56e7d35db35ec6076f38a9aa7d2c8892ee2f1c7","trusted":true},"cell_type":"code","source":"nonUsed, used = dfBase.groupby('shot_made_flag').size()\nprint(f'Das {dfBase.shape[0]} entradas no dataset, {nonUsed} foram de lances não convertidos e {used} foram de lances convertidos.')\nprint(f'Temos assim {round((used/dfBase.shape[0]) * 100,6)}% de lances que foram convertidos em pontos.')\nprint('---')\n\ndata = [go.Bar(\n            x=['Lances Convertidos', 'Lances Ñ Convertidos'],\n            y=[used, nonUsed],\n            marker=dict(\n                color=['rgba(38,222,47,0.8)','rgba(222,45,38,0.8)'])\n    )]\n\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c38111bf75fb979318cabf418c4fe6f40bd8d18"},"cell_type":"code","source":"plotPerColumnDistribution(dfBase, len(dfBase), 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f125c2d386a3035d8c412e5b77ede94c818ff0a"},"cell_type":"code","source":"plotCorrelationMatrix(dfBase, 15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83d135946935602b4cb5934147e09758caeb92c4"},"cell_type":"code","source":"plotScatterMatrix(dfBase, 25, 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49c68a8b72a43fcc854ddafeeacf7d94c6ff10ac"},"cell_type":"markdown","source":"## Analise e Tratamento de Features\n\n### **loc_x, loc_Y, lat, lon** -> _Serão convertidas em coordenadas polares centradas na cesta;_\n\n### **shot_zone_area, shot_zone_basic, shot_zone_range, shot_type** -> Refletida para as coordenadas polares de forma mais precisa; _Suplantada por um features novas_\n\n### **shot_id** -> _Promovida a index do dataframe;_ Não causa impacto na analise e garante que os resultados da classificação final estaram associados as entradas corretas;\n\n### **season, game_date** -> _Não trabalharemos com a massa de dados como série temporal;_\n\n### **team_id, game_event_id, game_id** -> Identificadores provenientes da fonte de dados originais; _Não representam valor significativos e por isso serão removidos_\n\n### **team_name ** -> Não apresenta variação ao longo do dataset e por isso _será descartada_;\n\n### **matchup** -> Duplicata desnormalizada do dado existente em **opponent**; _Descartado_;\n\n### **action_type, combined_shot_type** -> Ambos representam o tipo de lançamento efetuado, com diferentes níveis de granularidade; _Eventualmente removeremos um deles_\n"},{"metadata":{"trusted":true,"_uuid":"56adfe3884d98ad3ed67617eb834d1b190a166d0"},"cell_type":"code","source":"## Ao trabalharmos com coordenadas polares, podemos definir com mais facilidade um ponto \"zero\", além de facilitar a visualização dos dados e remover features redundantes\n\ndfPreprocess = dfBase.copy()\n\ndfPreprocess['dist'] = np.sqrt(dfPreprocess['loc_x']**2 + dfPreprocess['loc_y']**2)\n\nloc_x_zero = dfPreprocess['loc_x'] == 0\ndfPreprocess['angle'] = np.array([0]*len(dfPreprocess))\ndfPreprocess['angle'][~loc_x_zero] = np.arctan(dfPreprocess['loc_y'][~loc_x_zero] / dfPreprocess['loc_x'][~loc_x_zero])\ndfPreprocess['angle'][loc_x_zero] = np.pi / 2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c525a76c876e1a3d55614a145dfc50d25775627d"},"cell_type":"code","source":"## Tempo restante até o termino do período, em segundos.\ndfPreprocess['remaining_time'] = dfPreprocess['minutes_remaining'] * 60 + dfPreprocess['seconds_remaining']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9234f42acf745c23136ebfcb43999d105372cc6d"},"cell_type":"code","source":"## Tempo decorrido de partida, gerado a partir do \"period\" e do \"remaining_time\"\ndfPreprocess['match_elapsed_time'] = (dfPreprocess['period'] * 720) + (720 -  dfPreprocess['remaining_time'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e3337658326f973cc9f1ac6b8831d327500abfd"},"cell_type":"code","source":"dfPreprocess.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f15d45757b2fc7564415d22840b1e09a0062dfb"},"cell_type":"code","source":"dfPreprocess = dfPreprocess.drop(axis=1, columns=[\n    ## Removido em detrimento a conversão para coordenadas polares\n    'shot_zone_range', \n    'shot_zone_area', \n    'shot_distance',\n    'lat', \n    'lon',\n    'loc_x',\n    'loc_y',\n    'shot_zone_basic', \n    'shot_type', \n    \n    # Não apresentam variação no arquivo - Ambos tem o mesmo valor como constante\n    'team_name',  \n    'team_id', \n    \n    'matchup', ## Duplicidade desnormalizada de \"Opponent\"\n    \n    ## Identificador incremental sem valor para analise\n    'game_event_id',\n    'game_id',\n    \n    ## Não trataremos o dataset como série temporal\n    'season', \n    'game_date',\n    \n    ## Eliminação por conversão - Deram origem a duas novas features\n    'seconds_remaining',\n    'minutes_remaining',\n    'period',\n    \n])\n\n## Promovido a Index por simples facilidade durante geração do arquivo de saída\ndfPreprocess.set_index('shot_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"312d82de1b1cdef4bcf5be9cfe2216741e42b1e7"},"cell_type":"code","source":"## Reordenando as colunas por um simples fator de comodidade\ndfPreprocess = dfPreprocess[['dist','angle', 'action_type', 'combined_shot_type', 'playoffs', 'match_elapsed_time', 'remaining_time', 'opponent', 'shot_made_flag']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8086d789a7db700083fdf4db5484a9664d02320"},"cell_type":"code","source":"dfPreprocess","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6d462012bd1442a349f654d3da06d14365af1e6"},"cell_type":"markdown","source":"## Alteração de nomes das Feature\n\nPor uma questão de facilitar na geração dos metadados mais a frente na analise, algumas features vão receber o sufixo ** _cat** para indicar que são categoricas\n\nAlém disso, a variável de alvo será renomeada para **target** por comodidade"},{"metadata":{"trusted":true,"_uuid":"b215026818ba21cda9bf09ea41d44042538c097e"},"cell_type":"code","source":"dfPreprocess.columns = [\n    'dist',\n    'angle',\n    'action_type_cat', \n    'combined_shot_type_cat', \n    'playoffs_cat', \n    'match_elapsed_time', \n    'remaining_time', \n    'opponent_cat', \n    'target'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a582d8af2d2771dc5853fe33de625a99aa17cbee"},"cell_type":"code","source":"dfPreprocess","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f55ba8dea6d0f9c706be2c2f6f3ddc1c1cc7d190"},"cell_type":"markdown","source":"## Observação\nPodemos perceber que temos uma quantidade não-zero de registros onde nosso alvo (\"converteu_lancamento\") é nulo.\n\nUsaremos esse dados para gerar nossa submissão final e divideremos o restante em 70% para treino e 30% para validação"},{"metadata":{"_uuid":"1a759114a85164dffd7e8bc22634aaede327e174","trusted":true},"cell_type":"code","source":"print(f'Antes - Preprocess tem {dfPreprocess.shape[0]} linhas por {dfPreprocess.shape[1]} colunas ({dfPreprocess.shape[0] * dfPreprocess.shape[1]} celulas)')\ndfPreprocess.drop_duplicates()\nprint(f'Depois - Preprocess tem {dfPreprocess.shape[0]} linhas por {dfPreprocess.shape[1]} colunas ({dfPreprocess.shape[0] * dfPreprocess.shape[1]} celulas)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50f2facc45a1b3d17f43b4b93dda2d1a5f44453d"},"cell_type":"markdown","source":"Vou utilizar o código disponibilizado em https://www.kaggle.com/bertcarremans/data-preparation-exploration para gerar os metadados do dataset e facilitar nas tratativas futuras."},{"metadata":{"_uuid":"bdc7d1048a6ea454e4432a125353e0f2279fdd83","trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"def generateMetadata(dfInput):\n    data = []\n    for f in dfInput.columns:\n        # definindo o uso (entre rótulo, id e atributos)\n        if f == 'target':\n            role = 'target' # rótulo\n        elif f == 'id':\n            role = 'id'\n        else:\n            role = 'input' # atributos\n\n        # definindo o tipo do dado\n        if f == 'target':\n            level = 'binary'\n        elif 'cat' in f or f == 'id':\n            level = 'nominal'\n        elif dfInput[f].dtype == float or dfInput[f].dtype == np.float64:\n            level = 'interval'\n        elif dfInput[f].dtype == int or dfInput[f].dtype == np.int64:\n            level = 'ordinal'\n            \n        # mantem keep como verdadeiro pra tudo, exceto id\n        keep = True\n        if f == 'id':\n            keep = False\n\n        # cria o tipo de dado\n        dtype = dfInput[f].dtype\n\n        # cria dicionário de metadados\n        f_dict = {\n            'varname': f,\n            'role': role,\n            'level': level,\n            'keep': keep,\n            'dtype': dtype\n        }\n        data.append(f_dict)\n\n    meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n    meta.set_index('varname', inplace=True)\n    \n    return meta","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab6e9dfb59b12eedad5391391f49ca49951a7b9b","trusted":true},"cell_type":"code","source":"meta_preprocess = generateMetadata(dfPreprocess)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5293d760cb438834c71c46d8dbcfe14ec8e1b4b9","trusted":true},"cell_type":"code","source":"display(meta_preprocess)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e606fff15cbdd9e93a1b26fa8c81dc5c7a474b84","trusted":true},"cell_type":"code","source":"## Simples demonstração para conferencia eventual\nprint('Metadados categoricos da base pré processada')\nprint(meta_preprocess[(meta_preprocess.level == 'nominal') & (meta_preprocess.keep)].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10e8d89f5e57830447940a9f318bf57c627523a2","trusted":true},"cell_type":"code","source":"## Simples demonstração para conferencia eventual\nprint('Tipos e quantidade de features do dataset')\ndisplay(pd.DataFrame({'count' : meta_preprocess.groupby(['role', 'level'])['role'].size()}).reset_index())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05f8c63263099b83736eaccdd28fdf03b80dd264"},"cell_type":"markdown","source":"## Tratativa de valores faltantes\n\nO código abaixo é uma cópia/reuso de notebooks antigos e uma adaptação de um código passado em aula, funcionando de forma mais \"automatizada\" do que foi passado em aula"},{"metadata":{"_uuid":"00213ba7f718ceb850a063964abc5aca64ec1dda","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def getMissingAttributes(dfInput):\n    atributos_missing = []\n    return_missing = []\n\n    for f in dfInput.columns:\n        missings = dfInput[f].isna().sum()\n        if missings > 0:\n            atributos_missing.append(f)\n            missings_perc = missings/dfInput.shape[0]\n            \n            return_missing.append([f, missings, missings_perc])\n\n            print('Atributo {} tem {} amostras ({:.2%}) com valores faltantes'.format(f, missings, missings_perc))\n            \n\n    print('No total, há {} atributos com valores faltantes'.format(len(atributos_missing)))\n    \n    return pd.DataFrame(return_missing).rename(index=str, columns={0: \"column_name\", 1: \"column_nulls\", 2: \"column_percentage\"})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c70e52f178ddcc54242b5249184bba079aafc54","trusted":true},"cell_type":"code","source":"## Ao gerar nossa matriz de atributos faltantes, claramente vamos ignorar a coluna de alvo, que sabemos conter 5000 registros NaN (que desejamos prever ao termino da atividade)\nmissing = getMissingAttributes(dfPreprocess[meta_preprocess[(meta_preprocess.role != 'target')].index])\ndisplay(missing)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcd12a496b8fba471f22f6684e273df4bea5643d"},"cell_type":"markdown","source":"Duas estratégias foram utilizadas aqui: simplesmente remover o atributo ou tentar preenchê-lo de forma sintética. Preencher de forma sintética pode gerar uma falsa distribuição quando o número de atributos faltantes é muito alto. Quando este for o caso, é sempre seguro optar por remover o atributo inteiro. Também é importante lembrar que a estratégia de preenchimento deve ser coerente com o tipo de dado, por exemplo: **dados ordinais não devem ser preenchidos com média, nem dados contínuos com moda.**"},{"metadata":{"_uuid":"e9ea753249d796c495bcff97739b511d87233eeb","trusted":true},"cell_type":"code","source":"## limiar de remoção - 42.5% de nulos (Assumido como \"horizonte de evento\" em alguma aula passada e mantido desde então)\nremove_threshold = 0.425","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69559f3ede8d31cb5959c5b58575716dba2c74cd","trusted":true},"cell_type":"code","source":"if (len(missing) > 0):\n    columns_to_remove = np.array(missing.column_name[(missing.column_percentage >= remove_threshold)])\nelse:\n    columns_to_remove = None","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06ed2b6f78fa9e39444358f17b9547afdb847b80","trusted":true},"cell_type":"code","source":"if (columns_to_remove != None):\n    # removendo as colunas que tem muitos valores faltantes\n    dfTreino = dfPreprocess.drop(columns_to_remove, axis=1)\n\n    # atualiza os metadados para ter como referência\n    meta_preprocess.loc[(columns_to_remove),'keep'] = False  \n\n    # remove do frame de colunas com falta de dados as colunas que foram dropadas\n    missing.drop(missing[(np.isin(missing.column_name, columns_to_remove))].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"805b5d3bb4a13fe039bc29de0630e46701623ed6","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Usa ou moda ou média para preencher os valores \"vazios\" que nosso dataset contem, baseado nos metadados do mesmo\ndef fillNullNumbers(dfInput, dfMetadata, dfMissing, missing_default, label):\n\n    from sklearn.impute import SimpleImputer\n\n    media_imp = SimpleImputer(missing_values=missing_default, strategy='mean')\n    moda_imp = SimpleImputer(missing_values=missing_default, strategy='most_frequent')\n\n    for index,row in dfMissing.iterrows():\n        columnName = row['column_name']\n        columnType = dfMetadata.level[(dfMetadata.index == columnName)][0]\n\n        if (columnType == 'interval'):\n            imputerToUse = media_imp\n            imputerString = 'media_imp'\n        elif (columnType == 'ordinal'):\n            imputerToUse = moda_imp\n            imputerString = 'moda_imp'\n        else:\n            imputerToUse = None\n            imputerString = None\n\n        if (imputerToUse != None):\n            dfInput[columnName] = imputerToUse.fit_transform(dfInput[[columnName]]).ravel()\n            print(f\"{label} - Preenchida coluna {columnName}, cujo tipo é {columnType}, usando o Imputer {imputerString}\")\n\n    return dfInput","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d77312312941f0919691fb1c8647870e5b24ed2","trusted":true},"cell_type":"code","source":"dfPreprocess = fillNullNumbers(dfPreprocess, meta_preprocess, missing, -1, 'Pré Processado')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d33f93e1d121e292dda2040ea2b9b183bf09942","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def performOneHotEncoding(dfInput, meta_generic, dist_limit):\n    v = meta_generic[(meta_generic.level == 'nominal') & (meta_generic.keep)].index\n    display(v)\n    for f in v:\n        dist_values = dfInput[f].value_counts().shape[0]\n        print('Atributo {} tem {} valores distintos'.format(f, dist_values))\n        if (dist_values > dist_limit):\n            print('Atributo {} tem mais de {} valores distintos e por isso será ignorado'.format(f, dist_limit))\n            dfInput.drop([f], axis=1)\n            v = v.drop([f])\n        \n    print('Antes do one-hot encoding tinha-se {} atributos'.format(dfInput.shape[1]))\n    dfInput = pd.get_dummies(dfInput, columns=v, drop_first=True)\n    print('Depois do one-hot encoding tem-se {} atributos'.format(dfInput.shape[1]))\n    \n    return dfInput","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d6b5fafda4ec24b89a66a46d7ecdca49afbfe5b"},"cell_type":"markdown","source":"## One-Hot Encoding\n\nComo nosso dataset contem variáveis categoricas, temos que converter elas em algo que os algoritmos possam usar.\n\nNesse caso, faremos o One-Hot Encoding para binário de colunas com, no máximo, 200 valores distintos"},{"metadata":{"_uuid":"acf4c6866c9c00d07b0855349f194a3cbd36076c","trusted":true},"cell_type":"code","source":"dfPreprocess = performOneHotEncoding(dfPreprocess, meta_preprocess, 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3b6a53ada050f73f9c2c624298b482c7d171c5f"},"cell_type":"code","source":"dfPreprocess.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87bd842b1150a0846b66c904c287a882983f349a"},"cell_type":"markdown","source":"## Normalização\n\nPor se tratarem de dados em escalas muito diferentes, aplicaremos normalização (baseada no Teorema de Tales, usada por conta dos valores negativos que podemos ter em **dist** e **angle**)"},{"metadata":{"_uuid":"2a925c09396f626bfab0ddca2b42022244ac9bbc","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nmin_max_scaler = MinMaxScaler()\n\ndfPreprocess[dfPreprocess.columns] = min_max_scaler.fit_transform(dfPreprocess[dfPreprocess.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0341f851c7c28a37038db9e4026035a1d9371bc"},"cell_type":"code","source":"dfPreprocess.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e0804251395cef399517f8b29c87a73e5704105"},"cell_type":"code","source":"# Models\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\n# Feature Selection\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, ShuffleSplit, KFold, train_test_split, StratifiedKFold\n\n# Auxiliary Scores\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edc481aab1df0be1076a243f15ad38bbd9ba01ce","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def showDistribution(val_classes, targetName):\n    nonUsed, used = pd.DataFrame(val_classes).groupby(targetName).size()\n    print('---')\n    print(f'Das {pd.DataFrame(val_classes).shape[0]} entradas no dataset, {nonUsed} foram de lances não convertidos e {used} foram de lances convertidos.')\n    print(f'Temos assim {round((used/len(val_classes)) * 100,6)}% de lances que foram convertidos em pontos.')\n    print('---')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2874f507980a038d60bcdbeb2c8e3acfbc03894a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def logisticRegression(X_Train, y_Train, X_Val, y_Val):\n\n    model = LogisticRegression(solver='lbfgs')\n\n    model.fit(X_Train, y_Train)\n\n    y_pred_class = model.predict(X_Val)\n    y_pred_proba = model.predict_proba(X_Val)\n\n    recall = recall_score(y_Val, y_pred_class)\n    accuracy = accuracy_score(y_Val, y_pred_class)\n    logloss = log_loss(y_Val, y_pred_proba)\n    precision =  precision_score(y_Val, y_pred_class)\n    f1 = f1_score(y_Val, y_pred_class)\n\n    print(f'Baseline - Regressão Logistica')\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n    print('---')\n    \n    return model, 'Baseline - Regressão Logistica'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"add33086c01d42b3543fa1fa44913cebe33f9a08","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def xGBClassifier(X_Train, y_Train, X_Val, y_Val, modelName, modelParams):\n\n    if (modelParams == None):\n        clf = XGBClassifier()\n    else:\n        clf = XGBClassifier(**modelParams)  \n        modelName = modelName + ' - Parameters: ' + str(modelParams)\n    \n    clf.fit(X_Train, y_Train)\n\n    y_pred_class = clf.predict(X_Val)\n    y_pred_proba = clf.predict_proba(X_Val)\n\n    recall = recall_score(y_Val, y_pred_class)\n    accuracy = accuracy_score(y_Val, y_pred_class)\n    logloss = log_loss(y_Val, y_pred_proba)\n    precision =  precision_score(y_Val, y_pred_class)\n    f1 = f1_score(y_Val, y_pred_class)\n\n    print(modelName)\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n    print('---')\n    \n    return clf, modelName","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b01174ab51a24474d98363ed64b0ac87a7602d39","_kg_hide-input":true},"cell_type":"code","source":"def xGB_KFold(X, y, kfoldAmount, modelName, modelParams):\n\n    if (modelParams == None):\n        clf = XGBClassifier()\n    else:\n        clf = XGBClassifier(**modelParams)  \n        modelName = modelName + ' - Parameters: ' + str(modelParams)\n        \n    clf_score = []\n    iterator = 1\n    \n    for train_index, test_index in KFold(shuffle=True, n_splits=kfoldAmount, random_state=42).split(X):\n        \n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n        print(f'Processando Fold {iterator}/{kfoldAmount}')\n        \n        clf.fit(X_train, y_train)\n        y_pred_class = clf.predict(X_test)\n        y_pred_proba = clf.predict_proba(X_test)\n        \n        \n        recall = recall_score(y_test, y_pred_class)\n        accuracy = accuracy_score(y_test, y_pred_class)\n        logloss = log_loss(y_test, y_pred_proba)\n        precision =  precision_score(y_test, y_pred_class)\n        f1 = f1_score(y_test, y_pred_class)\n        \n        print(f'Fold {iterator}/{kfoldAmount} - Resultados')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'Log Loss: {round(logloss, 6)}')\n        print(f'F1 Score: {round(f1, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_test, y_pred_class)))\n        print('---')\n        \n        clf_score.append(logloss)\n        \n        iterator += 1\n        \n    print('Score Médio = ', round(np.array(clf_score).mean(), 6))\n    return clf, modelName","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8bea94e697d9ac6708a0502db46dcd8e0bf15f4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def decisionTreeClassifier(X_Train, y_Train, X_Val, y_Val):\n\n    clf = DecisionTreeClassifier()\n\n    clf.fit(X_Train, y_Train)\n\n    y_pred_class = clf.predict(X_Val)\n    y_pred_proba = clf.predict_proba(X_Val)\n\n    recall = recall_score(y_Val, y_pred_class)\n    accuracy = accuracy_score(y_Val, y_pred_class)\n    logloss = log_loss(y_Val, y_pred_proba)\n    precision =  precision_score(y_Val, y_pred_class)\n    f1 = f1_score(y_Val, y_pred_class)\n\n    print(f'Decision Tree - Default Parameters')\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n    print('---')\n    \n    return clf, f'Decision Tree - Default Parameters'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78fd822ef4b6e374245c98ed637ed0ac248ddef3","_kg_hide-input":true},"cell_type":"code","source":"def gridSearchKNN(X_Train, y_Train, X_Val, y_Val, k_range):\n    clf=KNeighborsClassifier()\n    param_grid=dict(n_neighbors=k_range)\n    scores = ['neg_log_loss']\n    for sc in scores:\n        grid=GridSearchCV(clf,param_grid,cv=2,scoring=sc,n_jobs=-1)\n        print(\"K-Nearest Neighbors - Tuning hyper-parameters for %s\" % sc)\n        \n        grid.fit(X_Train,y_Train)\n        \n        print(grid.best_params_)\n        print(np.round(grid.best_score_,3))\n        \n        y_pred_class = grid.predict(X_Val)\n        y_pred_proba = grid.predict_proba(X_Val)\n\n        recall = recall_score(y_Val, y_pred_class)\n        accuracy = accuracy_score(y_Val, y_pred_class)\n        logloss = log_loss(y_Val, y_pred_proba)\n        precision =  precision_score(y_Val, y_pred_class)\n        f1 = f1_score(y_Val, y_pred_class)\n\n        print(f'KNN with recall-maxing hyperparameters - {grid.best_params_}')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'Log Loss: {round(logloss, 6)}')\n        print(f'F1 Score: {round(f1, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n        print('---')\n        \n        return grid, f'KNN with recall-maxing hyperparameters - {grid.best_params_}'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e4c46819eefe201b29e56f47996f9bdef69c9ff","_kg_hide-input":true},"cell_type":"code","source":"def gridSearchSVC(X_Train, y_Train, X_Val, y_Val):\n    svc=SVC()\n    param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],'C': [1, 10, 100, 1000]},\n                  {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n    scores = ['neg_log_loss']\n    for sc in scores:\n        grid=GridSearchCV(svc,param_grid,cv=4,scoring=sc,n_jobs=-1)\n        \n        print(\"Support Vector Classifier - Tuning hyper-parameters for %s\" % sc)\n        \n        grid.fit(X_Train,y_Train)\n        print(grid.best_params_)\n        print(np.round(grid.best_score_,3))\n        \n        y_pred_class = grid.predict(X_Val)\n\n        recall = recall_score(y_Val, y_pred_class)\n        accuracy = accuracy_score(y_Val, y_pred_class)\n        precision =  precision_score(y_Val, y_pred_class)\n        f1 = f1_score(y_Val, y_pred_class)\n\n        print(f'SVC with recall-maxing hyperparameters - {grid.best_params_}')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'F1 Score: {round(f1, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n        print('---')\n        \n        return grid, f'SVC with recall-maxing hyperparameters - {grid.best_params_}'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85d7d66d12116da708643f8f912e02c99ff01dc0","_kg_hide-input":true},"cell_type":"code","source":"def gridSearchXGB(X_Train, y_Train, X_Val, y_Val, score):\n    xgb=XGBClassifier(random_state = 0)\n    ## Parametros para hiperparametrização tirados de um artigo do Medium, sugeridos como mais significativos e rápidos para classificação via XGB\n    param_grid = [{'subsample': [0.3, 0.6, 0.9], 'colsample_bytree': [0.3, 0.6, 0.9], 'n_estimators': [100, 200, 300, 400, 500], 'learning_rate': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75],'max_depth': [3, 7, 11, 15], 'gamma': [3, 6, 9]}]\n    scores = [score]\n    for sc in scores:\n        grid=GridSearchCV(xgb,param_grid,cv=2,scoring=sc,n_jobs=-1)\n        \n        print(\"XGBoost - Tuning hyper-parameters for %s\" % sc)\n        \n        grid.fit(X_Train,y_Train)\n        print(grid.best_params_)\n        print(np.round(grid.best_score_,3))\n        \n        y_pred_class = grid.predict(X_Val)\n        y_pred_proba = grid.predict_proba(X_Val)\n\n        recall = recall_score(y_Val, y_pred_class)\n        accuracy = accuracy_score(y_Val, y_pred_class)\n        logloss = log_loss(y_Val, y_pred_proba)\n        precision =  precision_score(y_Val, y_pred_class)\n        f1 = f1_score(y_Val, y_pred_class)\n\n        print(f'XGBoost with {sc}-maxing hyperparameters - {grid.best_params_}')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'Log Loss: {round(logloss, 6)}')\n        print(f'F1 Score: {round(f1, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n        print('---')\n        \n        return grid, f'XGBoost with {sc}-maxing hyperparameters - {grid.best_params_}'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"664dad7a496fecae1568255ed928fb8ff290d502","_kg_hide-input":true},"cell_type":"code","source":"def predictTestDataset(X_Test, y_Test, clfModel, clfName):\n    y_pred_class = clfModel.predict(X_Test)\n    y_pred_proba = clfModel.predict_proba(X_Test)\n\n    recall = recall_score(y_Test, y_pred_class)\n    accuracy = accuracy_score(y_Test, y_pred_class)\n    logloss = log_loss(y_Test, y_pred_proba)\n    precision =  precision_score(y_Test, y_pred_class)\n    f1 = f1_score(y_Test, y_pred_class)\n\n    print(clfName)\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Test, y_pred_class)))\n    print('---')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4bfd15b88db9edb1fc7a2efa4f0205c2f1c9cc0","_kg_hide-input":true},"cell_type":"code","source":"def predictContestDataset(X_Test, clfModel, clfName): \n    \n    print(clfName) \n    \n    print('---') \n    \n    y_pred_class = clfModel.predict(X_Test) \n    y_pred_proba = clfModel.predict_proba(X_Test) \n    \n    pd_prediction = pd.DataFrame(y_pred_class) \n    pd_prediction.columns = ['target']\n    \n    showDistribution(pd_prediction, 'target') \n    \n    return y_pred_class, y_pred_proba","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f22786e9d4edbeed8bbb9ac998306f68ee1ef32","trusted":true},"cell_type":"code","source":"print(dfPreprocess.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54b468a436e21ad2a6f03eeb43dcc676f8c7285f","_kg_hide-input":true},"cell_type":"code","source":"def performSubSampling(sample_size_target, sample_size_non_target, dfInput, targetValue):\n    target_indices = dfInput[dfInput.target == targetValue].index\n    target_values = dfInput.loc[np.random.choice(activated_indices, sample_size, replace=False)]\n\n    non_target_indices = dfInput[dfInput.target != targetValue].index\n    non_target_values = dfInput.loc[np.random.choice(inactive_indices, sample_size_non_target, replace=False)]\n\n    subsampled = pd.concat([target_values, non_target_values])\n\n    subsampled.sort_index(inplace=True)\n    \n    return subsampled","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d788af862800c4a4e520d7232f151d0f37b8f79"},"cell_type":"markdown","source":"## Sobre os algoritmos usados\n\nTodas as funções acima foram elaboradas para as atividades passas, focando em atender as diversas situações pedidas em aula\n\nAchei melhor, dessa forma, utilizá-los novamente para a atividade final em virtude da facilidade e de já estarem \"modularizados\" o suficiente para reuso em outros notebooks de forma simples e indolor"},{"metadata":{"trusted":true,"_uuid":"e01f59b9b63b3248454655973bd50bf91c710920"},"cell_type":"code","source":"## Como nosso objetivo final é submeter uma previsão dos valores nulos para a competição, vamos remover eles do dataset de onde tiraremos nossos dados de treino e validação\ndfPredict = dfPreprocess[dfPreprocess['target'].isnull()]\ndfPreprocess = dfPreprocess.dropna()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0318036e906b1314a1ab0761fdaf21398d3ab9c8","trusted":true},"cell_type":"code","source":"## Separamos os dados restantes em X (features) e y (alvo), para que possamos separar em treino e validação no futuro\nX = dfPreprocess.drop(['target'], axis=1)\ny = dfPreprocess['target']\ny.columns = ['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef6596c99d40806a8c722a8f56f2400cf147a58c"},"cell_type":"code","source":"## Nossa coluna \"target\" do dataset da competição é composta inteiramente de nulos e, sendo assim, pode ser descartada sem problemas\nX_predict = dfPredict.drop(['target'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2013e5e222489b8edf880ce3c6a997715a2aed"},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"447cd91e0658400ace4cd2881588a9a6a1a86e5a"},"cell_type":"code","source":"print(X_predict.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6407c00eb0a43aacbfcff7e2a78b9d5fc83090d8","scrolled":true},"cell_type":"code","source":"## Como era de se esperar (e foi mostrado antes), nosso dataset é razoavelmente balanceado no que tange a distribuição das classes\nshowDistribution(y, 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51cb7dc4b61444386180bbcd263feec1360e6a13"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"787b49155166775f5a55306183a83fb3c88e82f6"},"cell_type":"code","source":"## Graças a estratificação, mantemos a mesma proporção entre classes na massa de treino, com 70% dos dados originais para treino, 30% para validação do modelo e 5k fixo para submissão\nshowDistribution(y_train, 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f06bcaf62d01d294d791680bced0ecf5be6aac1a"},"cell_type":"code","source":"# Baseline - Regressão Logistica\n## Como sempre, Regressão Logistica é nossa metrica mais básica a ser batida\nlogRegModel, logRegName = logisticRegression(X_train, y_train, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a667acaadc97f55de4fb498278366450c618028f"},"cell_type":"code","source":"# Modelos baseados em arvore\n## Na minha limitada experiencia, algoritmos baseados em arvore que usam gradiente (como o XGBoost) apresentam resultados bom para classificação\n## No que tange aos hiperparametros, o \"Preset\" é o resultado da hiperparametrização do exercicio anterior enquanto que o \"Grid Search Outputted\" veio do algoritmo de grid search implementado nesse notebook, mas que foi comentado após a execução em virtude da demora\nxgbPureModel, xgbPureName = xGBClassifier(X_train, y_train, X_val, y_val, 'XGBoost - Base', None)\nxgbPresetModel, xgbPresetName = xGBClassifier(X_train, y_train, X_val, y_val, 'XGBoost - Preset', {'n_estimator':400, 'learning_rate' : 0.5,'random_state' : 0,'max_depth':70,'objective':\"binary:logistic\",'subsample':.8,'min_child_weig':6,'colsample_bytr':.8,'scale_pos_weight':1.6, 'gamma':10, 'reg_alph':8, 'reg_lambda':1})\nxgbHyperParametrizedModel, xgbHyperParametrizedName = xGBClassifier(X_train, y_train, X_val, y_val, 'XGBoost - Grid Search Outputted',{'colsample_bytree': 0.6, 'gamma': 9, 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.6, 'random_state': 42})\n\n## Usamos também Decision Tree para comparar os resultados\ndecTreeModel, decTreeName = decisionTreeClassifier(X_train, y_train, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cb9b0fe37c61daecac4101c7083384ef6a89f21"},"cell_type":"code","source":"# Otimizações via GridSearch - DEMORAM PARA EXECUTAR\n## Como dito acima, os casos onde usamos hiperparametrização vieram desses algoritmos; Infelizmente executar eles toda vez é inviavel devido a demora\n# xgbGSModel, xgbGSName = gridSearchXGB(X_train, y_train, X_val, y_val,'neg_log_loss')\n# knnModel, knnName = gridSearchKNN(X_train, y_train, X_val, y_val, list(range(1,20)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c5bb69b1455a499366359945f2c9ed39adb7aad","scrolled":false,"_kg_hide-output":false},"cell_type":"code","source":"# KFolding - Usando separação em treino e validação internamente\n## No caso do K-Fold, usamos a massa de dados toda para podermos quebrar nos K segmentos utilizados pelo algoritmo e testar uns contra os outros\nshowDistribution(y, 'target')\nxgbGSModel, xgbGSName = xGB_KFold(X, y, 10, 'XGBoost - KFolded',\n                                  {'colsample_bytree': 0.6, \n                                   'gamma': 9, \n                                   'learning_rate': 0.01, \n                                   'max_depth': 7, \n                                   'n_estimators': 500, \n                                   'subsample': 0.6, \n                                   'random_state': 42\n                                  })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f2bce379e596670b3472ee8660f4202874373d7"},"cell_type":"code","source":"## Considerando o resultado dos modelos acima, acabei por escolher o modelo saido do K-Fold, visto que ele entrega uma acurácia satisfatória e o melhor Logloss entre os testados\ncontest_prediction, contest_prediction_probability = predictContestDataset(X_predict, xgbGSModel, xgbGSName)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6cc9262f13a48a6d629f8deffef7bf891cbc293a"},"cell_type":"code","source":"## Finalmente, vamos gerar o arquivo de submissão da competição e torcer por resultados bons!\nsample    = pd.read_csv('../input/kobe-bryant-shot-selection/sample_submission.csv', low_memory=False)\nsample.shot_made_flag = contest_prediction_probability\nsample.shot_made_flag = 1 - sample.shot_made_flag\nsample.to_csv(\"submission.csv\", float_format='%.6f', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f40869d830cc5b6fefae8e383001457288366c70"},"cell_type":"markdown","source":"# Conclusão\n\nDurante uma versão anterior do notebook, acabei por cometer o engano de remover feature demais durante o processo de entrada e, com isso, prejudicar a eficiência do algoritmo.\n\nEssa ultima passagem para documentar me fez perceber que talvez remover coisas como o tipo de jogada estivesse tornando meu modelo menos assertivo e me fizeram alterar a lógica de seleção de features, removendo apenas aquelas ou podia substituir por outras a partir dos dados existentes ou que eram totalmente sem valor (como os identificadores). Felizmente, isso provou-se correto e acabei com um modelo bem mais assertivo do que antes."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}