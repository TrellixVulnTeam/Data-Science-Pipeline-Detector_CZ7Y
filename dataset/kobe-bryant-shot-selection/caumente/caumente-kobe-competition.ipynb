{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# Table of Contents\n\n\n$\\;\\;\\;$ 1. [Data Selection](#data_selection)<br>\n$\\;\\;\\;\\;\\;\\;$ 1.1. [Import libraries](#libraries)<br>\n$\\;\\;\\;\\;\\;\\;$ 1.2. [Load data](#load_data)<br>\n$\\;\\;\\;$ 2. [Data Processing](#data_processing)<br>\n$\\;\\;\\;\\;\\;\\;$ 2.1. [Casting types of variables](#casting)<br>\n$\\;\\;\\;\\;\\;\\;$ 2.2. [Check missing values](#missing)<br>\n$\\;\\;\\;\\;\\;\\;$ 2.3. [Exploratory analysis](#exploratory)<br>\n$\\;\\;\\;\\;\\;\\;$ 2.4. [Processing and selecting features](#select_features)<br>\n$\\;\\;\\;\\;\\;\\;\\;\\;\\;$ 2.4.1. [Quantitative features](#select_quantitatives)<br>\n$\\;\\;\\;\\;\\;\\;\\;\\;\\;$ 1.4.2. [Qualitarive features](#select_qualitatives)<br>\n$\\;\\;\\;$ 3. [Data transformation](#data_transformation)<br>\n$\\;\\;\\;\\;\\;\\;$ 3.1. [Opponents](#opponent)<br>\n$\\;\\;\\;\\;\\;\\;$ 3.2. [Time](#time)<br>\n$\\;\\;\\;\\;\\;\\;$ 3.3. [Date](#date)<br>\n$\\;\\;\\;\\;\\;\\;$ 3.4. [One hot encoding](#hot_encoding)<br>\n$\\;\\;\\;$ 4. [Data Mining](#modelling)<br>\n$\\;\\;\\;\\;\\;\\;$ 4.1. [Splitting data](#splitting)<br>\n$\\;\\;\\;\\;\\;\\;$ 4.2. [Scaler](#scaler)<br>\n$\\;\\;\\;\\;\\;\\;$ 4.3. [Feature selecion](#feat_sel)<br>\n$\\;\\;\\;\\;\\;\\;$ 4.4. [First modelling](#first)<br>\n$\\;\\;\\;\\;\\;\\;$ 4.5. [Second modelling](#second)<br>\n$\\;\\;\\;$ 5. [Predictions](#prediction)<br>\n$\\;\\;\\;$ 6. [Anexo](#anexo)<br>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Selection\n\n<a id='data_selection'></a>"},{"metadata":{},"cell_type":"markdown","source":"# 1.1. Import libraries\n\n<a id='libraries'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport pandas as pd\nimport warnings\nfrom datetime import datetime\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import pearsonr\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\n%matplotlib inline\n\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.feature_selection import SelectPercentile, RFE, RFECV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2. Load data\n\n<a id='load_data'></a>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/kobe-bryant-shot-selection/data.csv', header=0, index_col=\"shot_id\", parse_dates=['game_date'])\nprint(\"Size of data loaded:\", len(df))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Processing\n\n<a id='data_processing'></a>"},{"metadata":{},"cell_type":"markdown","source":"## 2.1. Casting types of variables\n\n<a id='casting'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"period\"] = df[\"period\"].astype('category')\ndf[\"season\"] = df[\"season\"].astype('category')\ndf[\"team_id\"] = df[\"team_id\"].astype('category')\ndf[\"game_id\"] = df[\"game_id\"].astype('category')\ndf[\"opponent\"] = df[\"opponent\"].astype('category')\ndf[\"playoffs\"] = df[\"playoffs\"].astype('category')\ndf[\"shot_type\"] = df[\"shot_type\"].astype('category')\ndf[\"action_type\"] = df[\"action_type\"].astype('category')\ndf[\"game_event_id\"] = df[\"game_event_id\"].astype('category')\ndf[\"shot_zone_area\"] = df[\"shot_zone_area\"].astype('category')\ndf[\"shot_zone_basic\"] = df[\"shot_zone_basic\"].astype('category')\ndf[\"shot_zone_range\"] = df[\"shot_zone_range\"].astype('category')\ndf[\"combined_shot_type\"] = df[\"combined_shot_type\"].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Check missing values\n\n<a id='missing'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3. Exploratory analysis\n\n<a id='exploratory'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot('shot_zone_range',hue='shot_made_flag',data=df[df.shot_made_flag.notnull()])\nplt.title('misses and baskets from each zone_range')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot('shot_zone_basic',hue='shot_made_flag',data=df[df.shot_made_flag.notnull()])\nplt.title('misses and baskets from each zone_basic')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cols = [\"combined_shot_type\", \"period\", \"playoffs\", \"season\", \"shot_type\", \"shot_zone_area\", \"shot_zone_basic\", \"shot_zone_range\", \"team_id\", \"team_name\", \"opponent\"]\n\nfor c in cols:\n    plt.figure(figsize=(20, 8), dpi=80, facecolor='w', edgecolor='k')\n    ax = plt.axes()\n    sns.countplot(x=c, data=df, ax=ax);\n    ax.set_title(c)\n    plt.xticks(rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.4. Processing and selecting features\n\n<a id='select_features'> </a>"},{"metadata":{},"cell_type":"markdown","source":"# 2.4.1. Quantitative features\n\n<a id='select_quantitatives'> </a>"},{"metadata":{},"cell_type":"markdown","source":"Comenzaremos el análisis de nuestras características por las variables cuantitativas. En este sentido, vamos a analizar la correlación que existe entre cada una de esas variables con el fin de poder descartar alguna de ellas si es que poseen alta correlación. Esto es importante para posteriormente no introducir información redundante a la hora de entrenar nuestro modelo."},{"metadata":{},"cell_type":"markdown","source":"### Matrix correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr = df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(10, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nos encontramos que tenemos dos pares de variables que están completamente correlacionadas entre sí, lon-loc_x y lat-loc_y. Con el fin de no introducir información redundante en nuestro modelo, procederemos a eliminar de nuestro conjunto de datos dichas variables."},{"metadata":{},"cell_type":"markdown","source":"### Drop continuous variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Pearson correlation between lat and loc_y variables: %.2f\" % pearsonr(df.lat, df.loc_y)[0])\ndf.drop('lat', axis=1, inplace=True)\n\nprint(\"Pearson correlation between lon and loc_x variables: %.2f\" % pearsonr(df.lon, df.loc_x)[0])\ndf.drop('lon', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.4.2. Qualitative features\n\n<a id='select_qualitatives'> </a>"},{"metadata":{},"cell_type":"markdown","source":"En cuanto a las variables cualitativas, como no podemos estudiar la correlacion de Pearson, vamos a indagar en como están distribuidos los valores en cada variables con el fin de encontrar la forma de disminuir el número de variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include=['object', 'category'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos, existen algunas variables que solo cuentan con un único valor. A fines prácticos, poco podrá aprender nuestro modelo de este tipo de caracteristicas."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Different values for team_name variable\", set(df.team_name))\ndf.drop('team_name', axis=1, inplace=True)\n\nprint(\"Different values for team_id variable\", set(df.team_id))\ndf.drop('team_id', axis=1, inplace=True)\n\ndf.drop('game_event_id', axis=1, inplace=True)\ndf.drop('game_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Las variables con las que contamos hasta el momento son tanto binarias como multietiqueta. No parecen presentar demasiado problema a priori, salvo que quizá tengamos que discretizarlas numéricamente más adelante. La única variable categórica que no esta incluida en las gráficas anteriores es 'action_type'. Tendremos que examinarla con mas detalle, ya que cuenta con 57 etiquetas diferentes."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[\"action_type\", \"combined_shot_type\"]].head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Uniques values for action_type:\",format(str(len(set(df.action_type)))))\nprint(\"Uniques values for combined_shot_type:\",format(str(len(set(df.combined_shot_type)))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver en esta tabla que tenemos encima, parece que la variable 'action_type' aporta mas granularidad aun sobre la variable 'combined_shot_type', es decir, va más aun al detalle. Al introducir tantas casúisticas diferentes, según el modelo que se utilice sería recomendable no usarla o tratar de preprocesarla."},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop('action_type', axis=1, inplace=True)\ndf.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Transformation\n\n<a id='data_transformation'></a>"},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Opponents\n\n<a id='opponent'></a>"},{"metadata":{},"cell_type":"markdown","source":"Se supone que los datos contenidos en la columna 'matchup' hacen referencia a los partidos que se disputaron entre Los Angeles Lakers y sus contrincantes. Esta columna nos denotaria únicamente cual es los dos equipos era local, ya que el oponente viene especificado nuevamente en la columna 'opponent'. De tal forma que los equipos contrarios deben ser los mismos en una columna y en otra. Veamos que pasa:"},{"metadata":{"trusted":true},"cell_type":"code","source":"matchups = list(set(df.matchup.str[-3:]))\nprint(\"Number of teams by matches column:\", len(matchups))\nopponent = list(set(df.opponent))\nprint(\"Number of teams by opponent column:\", len(opponent))\n\nmain_list = list(set(matchups).difference(opponent))\nprint(\"\\nThere are\", len(main_list), \"teams incongruous:\")\nprint(main_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos, existe una inconsistencia entre el número de equipos encontrados en una columna y en otra. Para avergiguar cual es la mejor solución, recurriremos a la web oficial de la NBA y comprobaremos cuales son las siglas reales para los equipos que participan en dicha competición."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"matchup\"].str.endswith(main_list[0])].head(2) # PHO == PHX --> Phoenix Suns\ndf[df[\"matchup\"].str.endswith(main_list[1])].head(2) # SAN == SAS --> San Antonio Spurs\ndf[df[\"matchup\"].str.endswith(main_list[2])].head(2) # CHH == CHA --> Charlotte Horets\ndf[df[\"matchup\"].str.endswith(main_list[3])].head(2) # UTH == UTA --> Utah Jazz\ndf[df[\"matchup\"].str.endswith(main_list[4])].head(2) # NOK == NOP --> New Orleans Pelicans https://stats.nba.com/game/0020500903/scoring/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se ha comprobado manualmente que la columna 'matchup' posee errores en las siglas usadas par denotar a los equipos, por lo que para saber con que equipo se enfrentaban los LAL, usaremos la columna 'opponent' y descartaremos 'matchup'. Sin embargo, antes de eliminarla vamos a crear una nueva columna a partir de ella en la que indiquemos con 1 LAL jugaba como local y con 0 si jugaba como visitante. Si vamos a esa columna, vemos que existen dos formatos para expresar el enfrentamiento, el simbolo '@' y el 'vs.'. Tras una serie de comprobaciones tales como: buscar en google 2006-03-26 Lakers vs. new orleans pelicans y ver que LAL jugaron en casa a la vez que en los datos se denoto con vs. Asimismo se ha comprobado con el encuentro 2000-10-31 lakers vs partland, donde LAL jugó como visitante y en nuestros datos aparece con un @. Finalmente la logica será, si aparece '@' en dicha columna, asigno un 0, si aparece un 'vs.', asigno un 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"home\"] = pd.np.where(df.matchup.str.contains(\"@\"), 0, 1)\ndf[\"home\"] = df[\"home\"].astype('category')\ndf.drop('matchup', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Time\n\n<a id='time'></a>"},{"metadata":{},"cell_type":"markdown","source":"Otra de las variables que parecen estar muy relacionadas entre si son 'minutes_remaining' y 'seconds_remaining'. en lugar de tener ambas por separado, al deberse cada una de ellas a espacios temporales relacionados, podemos tratar de aunarlas en una sola. Por ejemplo de la siguiente forma: "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['remain_time'] = 60*df['seconds_remaining'] + df['minutes_remaining']\ndf.drop('minutes_remaining', axis=1, inplace=True)\ndf.drop('seconds_remaining', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3. Date\n\n<a id='date'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year'] = df.game_date.dt.year\ndf['month'] = df.game_date.dt.month\ndf['day'] = df.game_date.dt.day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('game_date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4. One hot encoding\n\n<a id='hot_encoding'></a>"},{"metadata":{},"cell_type":"markdown","source":"Un paso fundamental que debemos realizar es el realizar un 'encoding' sobre las variables categoricas. La mayoria de algoritmos trabajan mejor con variables numéricas. La idea de esta técnica se basa en, dada una variable predictora que puede tomar n valores distintos, generaremos a partir de ella un vector de n dimensiones, cada una de ellas correspondiente a los posibles valores. De forma que si para una instancia, esta variable predictora tomaba un valor \"X\", entonces el vector estará completamente relleno de ceros, excepto en la posicion de la columna \"X\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorial_cols = df.select_dtypes(include='category').columns\n\nfor cc in categorial_cols:\n    dummies = pd.get_dummies(df[cc])\n    dummies = dummies.add_prefix(\"{}#\".format(cc))\n    df.drop(cc, axis=1, inplace=True)\n    df = df.join(dummies)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El resultado obtenido, debe ser un dataframe que solo contenga variables predictoras numéricas."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Mining\n\n<a id='modelling'></a>"},{"metadata":{},"cell_type":"markdown","source":"En primer lugar vamos a dividir todo el conjunto de datos en dos. Por un lado, los datos que nos servirán para realizar el aprendizaje supervisado, es decir, aquellos registros para los cuales tenemos el valor de la variable objetivo. Por otro, los registros a los que aplicaremos nuestro modelo predictivo y enviaremos a Kaggle."},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Splitting data\n\n<a id='splitting'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into train-test\ndata = df[~df.shot_made_flag.isna()]\nsubmit = df[df.shot_made_flag.isna()]\n\nprint(\"Split dataframe into data-submit: Data:\", len(data), \"; Submit:\", len(submit))\nprint(\"\\nPercentage for every class:\\n\", data.shot_made_flag.value_counts()/len(data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos como de balanceada esta la clase a predecir:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\nax = plt.axes()\nsns.countplot(x='shot_made_flag', data=data, ax=ax);\nax.set_title('Target class distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hemos querido realizar un print tanto del número de registros que han sido repartidos a cada conjunto, como del porcentaje de elementos de cada clase. A pesar de que hemos obtenido que un 55% de las instancias pertenecen a la clase 0 y un 45% a la clase 0, es decir, los porcentajes son bastante similares, cuando dividamos nuestro conjunto de datos en train-test, intentaremos mantener las mismas proporciones."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    data.loc[:, data.columns != 'shot_made_flag'], data.shot_made_flag, \n    test_size=0.2, random_state=0, stratify=data.shot_made_flag)\n\nprint(\"Split data into train-test:\\nTrain:\", len(X_train), \"\\nTest:\", len(X_test),\"\\n\\n\")\n\nprint(\"Percentage for train set:\\n\",y_train.value_counts()/len(y_train),\"\\n\")\nprint(\"Percentage for train set:\\n\",y_test.value_counts()/len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos, hemos dividido nuestros datos en conjunto de entrenamiento y de validacion manteniendo las proporciones de clase originales."},{"metadata":{},"cell_type":"markdown","source":"## 4.2. Scaler data\n\n<a id='scaler'></a>"},{"metadata":{},"cell_type":"markdown","source":"Implementaremos un método que escale los datos aplicando la diferencia el mínimo y cada punto del dataset, dividiendo eso por el rango."},{"metadata":{"trusted":true},"cell_type":"code","source":"#sc = StandardScaler()\nsc = MinMaxScaler()\n\nX_train_sc = pd.DataFrame(sc.fit_transform(X_train.values), \n                          index=X_train.index, \n                          columns=X_train.columns)\nX_test_sc = pd.DataFrame(sc.transform(X_test.values), \n                          index=X_test.index, \n                          columns=X_test.columns)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3. Features selection\n\n<a id='feat_sel'></a>"},{"metadata":{},"cell_type":"markdown","source":"A la hora de entrenar nuestros modelos, puede ser computacionalmente muy complejo contar con mas de 150 variables. Es cierto que nuestro dataset no contiene demasiadas instancias, pero aun así es conveniente seleccionar las variables mas importantes."},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the RFE object and compute a cross-validated score.\nranker = GradientBoostingClassifier()\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nrfecv = RFECV(estimator=ranker, step=1, cv=StratifiedKFold(2), n_jobs = 1, scoring='neg_log_loss')\nrfecv.fit(X_train_sc, y_train)\n\nprint(\"Optimal number of features based on Gradient Boosting : %d\" % rfecv.n_features_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(13, 6.5))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation -Log_Loss\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = X_train_sc.columns\nselected_features_gb = feature_names[rfecv.support_].tolist()\nselected_features_gb\n\nprint(\"\\nNumber of main features by Linear Discriminant Analysis: {}\\n\".format(len(selected_features_gb)))\n#selected_features_gb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"ranker = LinearDiscriminantAnalysis()\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nrfecv = RFECV(estimator=ranker, step=1, cv=StratifiedKFold(2), scoring='neg_log_loss')\nrfecv.fit(X_train_sc, y_train)\n\nprint(\"Optimal number of features based on LDA : %d\" % rfecv.n_features_)\n\n# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(13, 6.5))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = X_train_sc.columns\nselected_features_lda = feature_names[rfecv.support_].tolist()\nselected_features_lda\n\nprint(\"\\nNumber of main features by Linear Discriminant Analysis: {}\\n\".format(len(selected_features_lda)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hemos almacenado cuales han sido las variables mas relevantes aplicando este algoritmo. Probemos ahora cambiando el modelo, en este caso aplicando una regresión logística, y comparemos resultados."},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the RFE object and compute a cross-validated score.\nranker = LogisticRegression()\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nrfecv = RFECV(estimator=ranker, step=1, cv=StratifiedKFold(2),\n              scoring='accuracy')\nrfecv.fit(X_train_sc, y_train)\n\nprint(\"Optimal number of features based on Logistic Regression : %d\" % rfecv.n_features_)\n\n# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(13, 6.5))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"feature_names = X_train_sc.columns\nselected_features_lr = feature_names[rfecv.support_].tolist()\n\nprint(\"\\nNumber of main features by Logistic regression: {}\\n\".format(len(selected_features_lr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4. First modelling\n\n<a id='first'></a>"},{"metadata":{},"cell_type":"markdown","source":"En este momento, toca implementar diferentes modelos y técnicas. Para ello, aplicaremos un cross validation con 5 folds para diferendes modelos y las principales variables."},{"metadata":{},"cell_type":"markdown","source":"Omitimos la seleccion de variables y mantenemos la variable ActionType"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"num_folds = 5\nkfold = KFold(n_splits=num_folds, shuffle = True)\n\nmodels = []\nmodels.append((\"LDA\", LinearDiscriminantAnalysis()))\nmodels.append(('Logistic regression', LogisticRegression()))\nmodels.append(('Random Forest', RandomForestClassifier()))\nmodels.append(('Ada Boost', AdaBoostClassifier()))\nmodels.append(('Gradient Boosting', GradientBoostingClassifier()))\nmodels.append(('XGBoost', XGBClassifier()))\nmodels.append((\"Bagging\", BaggingClassifier()))\nmodels.append((\"KNN\", KNeighborsClassifier()))\nmodels.append((\"MLP\", MLPClassifier()))\nmodels.append((\"Gauss\", GaussianNB()))\nmodels.append((\"Voting\", VotingClassifier(estimators=[\n                                                    ('lr', GradientBoostingClassifier()), \n                                                    ('rf', AdaBoostClassifier()), \n                                                    ('xgb', XGBClassifier())], voting='soft')))\n\n\n\nstart_time = time.time()\n# Evaluate each model in turn\nresults = []\nnames = []\nstds = []\nmeans =[]\nfor name, model in models:\n    cv_results = cross_val_score(model, X_train_sc[selected_features_gb], y_train, cv=kfold, scoring='neg_log_loss', n_jobs=2)\n    print(\"Cross validation results for {0}: {1}\".format(name, cv_results))\n    print(\"{0}: ({1:.4f}) +/- ({2:.4f})\".format(name, cv_results.mean(), cv_results.std()),\"\\n\")\n    results.append(cv_results)\n    names.append(name)\n    stds.append(cv_results.std())\n    means.append(abs(cv_results.mean()))\n    \n    \nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({\"Name\":names, \"Log Loss\":means, \"Standar Deviation\": stds}).sort_values(by=\"Log Loss\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Los resultados mostrados son propios de mas de 10 modelos en los que hemos dejado por defecto los hiperparametros. Tiene sentido que habiendo seleccionado las mejores variables segun LDA y Linear Regression , sean dos de los modelos que mejores resultados obtienen. Pero no solo tenemos esos dos, si no también han obtenido muy buenos resultados Gradient Boosting y XGboots, ya que es una versión modificada del anterior. Lo que haremos ahora será, seleccionar esos 3 o 4 modelos mas importantes, y tratar de optimizar los hiperparametros."},{"metadata":{},"cell_type":"markdown","source":"## 4.5 Second modelling\n\n<a id='second'></a>"},{"metadata":{},"cell_type":"markdown","source":"Con el fin de no extendernos demasiado en el tiempo de computo, vamos a tratar de averiguar cuales son los mejores hiperparametros para este conjunto de datos y el algoritmo Gradient Boosting"},{"metadata":{},"cell_type":"markdown","source":"### Learning rates"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rates = [0.0001, 0.001,0.005, 0.01, 0.05, 0.1, 0.15, 0.5, 1]\ntrain_results = []\ntest_results = []\nfor eta in learning_rates:\n    model = GradientBoostingClassifier(learning_rate=eta)\n    model.fit(X_train_sc[selected_features_gb], y_train)\n    train_pred = model.predict(X_train_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, train_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = model.predict(X_test_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nplt.figure(figsize=(15,8))\nline1, = plt.plot(learning_rates, train_results, 'b', label='Train AUC')\nline2, = plt.plot(learning_rates, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.xscale(\"log\")\nplt.ylabel('AUC score')\nplt.xlabel('learning rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El mejor learing rate rondará el valor 0.05, ya que a partir de 0.1 el algoritmo empieza a cometer overfitting."},{"metadata":{},"cell_type":"markdown","source":"### Number estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200, 500, 1000]\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n    model = GradientBoostingClassifier(n_estimators=estimator)\n    model.fit(X_train_sc[selected_features_gb], y_train)\n    train_pred = model.predict(X_train_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, train_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = model.predict(X_test_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nplt.figure(figsize=(15,8))\nline1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\nline2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esto demuestra que no por generar miles de árboles obtendremos mejores resultados. Con unos 50 estimadores nos servirá para que el algoritmo no cometa overfitting."},{"metadata":{},"cell_type":"markdown","source":"### Min. samples splits"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_samples_splits = np.linspace(0.0001, 1.0, 10, endpoint=True)\ntrain_results = []\ntest_results = []\nfor min_samples in min_samples_splits:\n    model = GradientBoostingClassifier(min_samples_split = min_samples)\n    model.fit(X_train_sc[selected_features_gb], y_train)\n    train_pred = model.predict(X_train_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, train_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = model.predict(X_test_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nplt.figure(figsize=(15,8))\nline1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\nline2, = plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.xscale(\"log\")\nplt.ylabel('AUC score')\nplt.xlabel('Min. samples split')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuevamente el modelo produce overfitting para valores superiores a 0.5"},{"metadata":{},"cell_type":"markdown","source":"### Min. samples leaf"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_samples_leafs = [0.00001, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 4, 8, 15]\ntrain_results = []\ntest_results = []\nfor min_samples in min_samples_leafs:\n    model = GradientBoostingClassifier(min_samples_leaf = min_samples)\n    model.fit(X_train_sc[selected_features_gb], y_train)\n    train_pred = model.predict(X_train_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, train_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = model.predict(X_test_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nplt.figure(figsize=(15,8))\nline1, = plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')\nline2, = plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.xscale(\"log\")\nplt.ylabel('AUC score')\nplt.xlabel('Min. samples leaf')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elegiremos valores que ronden 0.01"},{"metadata":{},"cell_type":"markdown","source":"### Max. features"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = list(range(1,X_train_sc[selected_features_gb].shape[1]))\ntrain_results = []\ntest_results = []\nfor max_feature in max_features:\n    model = GradientBoostingClassifier(max_features = max_feature)\n    model.fit(X_train_sc[selected_features_gb], y_train)\n    train_pred = model.predict(X_train_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, train_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = model.predict(X_test_sc[selected_features_gb])\n    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nplt.figure(figsize=(15,8))\nline1, = plt.plot(max_features, train_results, 'b', label='Train AUC')\nline2, = plt.plot(max_features, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('Max. features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient boosting permite elegir como numero maximo de caracteristicas para optimizar la division del nodo la raíz cuadrada del numero de caracteristicas. Como contamos con unas 35 carateristicas, la raiz será casi 6, y por tanto parece un valor bastante razonable para elegir."},{"metadata":{},"cell_type":"markdown","source":"Finalmente elegiremos el algoritmo Gradient Boosting que a priori mejor resultados nos habian dado. En este caso, aplicaremos un grid de hiperparametros para cada parametros y los iremos seleccionando de forma aleatoria."},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = {}\nclassifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {}\nparameters.update({\"Gradient Boosting\": { \n                                        \"classifier__learning_rate\":[0.1,0.05,0.01,0.005], \n                                        \"classifier__n_estimators\": [500],\n                                        \"classifier__max_depth\": [2,3,4,5,6],\n                                        \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n                                        \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n                                        \"classifier__subsample\": [0.8, 0.9, 1]\n                                         }})\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"results = {}\nstart_time = time.time()\n# Tune and evaluate classifiers\nfor classifier_label, classifier in classifiers.items():\n    \n    # Print message to user\n    print(f\"Now tuning {classifier_label}.\")\n\n    # Initialize Pipeline object\n    pipeline = Pipeline([(\"classifier\", classifier)])\n\n    # Define parameter grid\n    param_grid = parameters[classifier_label]\n    \n    # Initialize GridSearch object\n    rscv = RandomizedSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = 'neg_log_loss')\n\n    # Fit gscv\n    rscv.fit(X_train_sc[selected_features_gb], np.ravel(y_train))  \n\n    # Get best parameters and score\n    best_params = rscv.best_params_\n    best_score = rscv.best_score_\n\n    # Update classifier parameters and define new pipeline with tuned classifier\n    tuned_params = {item[12:]: best_params[item] for item in best_params}\n    classifier.set_params(**tuned_params)\n\n    # Make predictions\n    y_pred = rscv.predict_proba(X_test_sc[selected_features_gb])\n\n    # Evaluate model\n    log_loss = metrics.log_loss(y_test, y_pred)\n\n    # Save results\n    result = {\"Classifier\": rscv,\n              \"Best Parameters\": best_params,\n              \"Training Log Loss\": (-1) * best_score,\n              \"Test Log Loss\": log_loss\n             }\n\n    results.update({classifier_label: result})\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veamos gráficamente los resultados obtenidos"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"log_scores = {\n              \"Classifier\": [],\n              \"Log Loss\": [],\n              \"Log Loss Type\": []\n              }\n\n# Get AUC scores into dictionary\nfor classifier_label in results:\n    log_scores.update({\"Classifier\": [classifier_label] + log_scores[\"Classifier\"],\n                       \"Log Loss\": [results[classifier_label][\"Training Log Loss\"]] + log_scores[\"Log Loss\"],\n                       \"Log Loss Type\": [\"Training\"] + log_scores[\"Log Loss Type\"]})\n    \n    log_scores.update({\"Classifier\": [classifier_label] + log_scores[\"Classifier\"],\n                       \"Log Loss\": [results[classifier_label][\"Test Log Loss\"]] + log_scores[\"Log Loss\"],\n                       \"Log Loss Type\": [\"Test\"] + log_scores[\"Log Loss Type\"]})\n    \n\n\n# Dictionary to PandasDataFrame\nlog_scores = pd.DataFrame(log_scores)\n\n# Set graph style\nsns.set(font_scale = 1.75)\nsns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n               'ytick.color': '0.4'})\n\n    \n# Colors\ntraining_color = sns.color_palette(\"RdYlBu\", 10)[1]\ntest_color = sns.color_palette(\"RdYlBu\", 10)[-2]\ncolors = [training_color, test_color]\n\n# Set figure size and create barplot\nf, ax = plt.subplots(figsize=(10, 5))\n\nsns.barplot(x=\"Log Loss\", y=\"Classifier\", hue=\"Log Loss Type\", palette = colors, data=log_scores)\n\n# Generate a bolded horizontal line at y = 0\nax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n\n# Turn frame off\nax.set_frame_on(False)\n\n# Tight layout\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"log_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A pesar de que los resultados son muy parejos, Gradient Boost se ejecuto 4 veces mas rápido que XGBoost. Finalmente, vamos a ejecutar un grid search para este modelo en busca de los mejores hiperparametros."},{"metadata":{},"cell_type":"markdown","source":"# 5. Predictions\n\n<a id='prediction'></a>"},{"metadata":{},"cell_type":"markdown","source":"Una vez hemos entrenado y validado el modelo, se le ha asignado los mejores hiperparametros posible. En este momento vamos a realizar las predicciones sobre el conjunto de datos 'submit'"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.DataFrame(sc.fit_transform(data.loc[:, data.columns != 'shot_made_flag'].values), \n                          index=data.loc[:, data.columns != 'shot_made_flag'].index, \n                          columns=data.loc[:, data.columns != 'shot_made_flag'].columns)\n\nobject_variable = data.shot_made_flag\n\nsubmit_ = pd.DataFrame(sc.transform(submit.loc[:, submit.columns != 'shot_made_flag'].values), \n                          index=submit.loc[:, submit.columns != 'shot_made_flag'].index, \n                          columns=submit.loc[:, submit.columns != 'shot_made_flag'].columns)\n\nmodel = classifiers[\"Gradient Boosting\"]\nmodel.fit(train[selected_features_gb], object_variable)\ny_pred = model.predict_proba(submit_[selected_features_gb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exportamos los resultados en el formato que Kaggle necesita para poder evaluarlo."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pd.DataFrame({'shot_made_flag' : y_pred[:,1]},\n                           index = df[df.shot_made_flag.isnull()].index)\npredictions.index.name = 'shot_id'\npredictions.to_csv('/kaggle/working/submission_{}.csv'.format(datetime.now().strftime('%Y_%m_%d')))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}