{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Spotting great features\n\nThe following notebook presentes a template that can be used to discover which features are providing informative value. It makes also easier to spot *overfitting* and *underfitting* symtopms.\n\n\n## Load libs\nAll required libraries are import beforehand."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"%matplotlib inline \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cross_validation import KFold\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.learning_curve import learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.mixture import GMM"},{"cell_type":"markdown","metadata":{},"source":"## Helper functions\nFunctions that might be helpful when processing raw features - *\"one-hot encoding\"* or *continuous variable bininng*."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def encode_categorical(df, col):\n    dummies = pd.get_dummies(df[col], prefix=col)\n    df.drop(col, axis=1, inplace=True)\n    df = df.join(dummies)\n    return df\n\ndef binning(df, col, bins):\n    df[col] = pd.cut(df[col], bins)\n    return df\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=2, \n                        train_sizes=np.linspace(.1, 1.0, 5), scoring='log_loss'):\n    plt.figure()\n    plt.title(title)\n    \n    if ylim is not None:\n        plt.ylim(*ylim)\n        \n    plt.xlabel('Training size')\n    plt.ylabel('Score')\n    \n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, \n                                                            train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n        \n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    \n    print(\"Last cross-val score: {}\".format(test_scores.flatten()[-1]))\n    \n    plt.grid()\n    plt.show()\n    \ndef init_learning_data(df):\n    unknown_mask = df['shot_made_flag'].isnull()\n\n    features = df[~unknown_mask]\n    labels = df.loc[~unknown_mask, 'shot_made_flag']\n\n    X = features.drop('shot_made_flag', axis=1).copy()\n    Y = labels\n    \n    return X,Y"},{"cell_type":"markdown","metadata":{},"source":"Read the original data."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"raw_df = pd.read_csv('../input/data.csv')"},{"cell_type":"markdown","metadata":{},"source":"## Evaluate different features\nFirst declare some widely used variables."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nseed = 7\nnum_folds=5\nscoring='log_loss'\nnum_instances=len(X)\n\nkfold = KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n\nrf = RandomForestClassifier(n_estimators=50)\ngbc = GradientBoostingClassifier()\nlr = LogisticRegression()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Calculate a vector of previous shots (probably could be done more efficient ...)\ndef get_prev_made_shot(row, df):\n    game_id = row['game_id']\n    game_event_id = row['game_event_id']\n    \n    game_df = df.loc[df['game_id'] == game_id].sort_values('game_event_id')\n    prev_events_df = game_df.loc[game_df['game_event_id'] < game_event_id]\n    \n    # Was previous shot in game made?\n    last = prev_events_df.tail(1)\n    last_shot = last['shot_made_flag']\n    \n    # if game starts, or previous shot was unknown\n    if (last_shot.empty | pd.isnull(last_shot).any()):\n        return 0.5\n    \n    return int(last_shot.values[0])\n\nprev_shot_made_s = X.apply(lambda x: get_prev_made_shot(x, X.join(Y)), axis=1)\nprev_shot_made_s.name = \"prev_shot_made\""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Calculate a vector of shot location cluster based on Gaussian Mixture Model\ndef get_shot_location_clusters(df, num_clusters):\n    gmm = GMM(\n        n_components=num_clusters,\n        covariance_type='full',\n        params='wmc',\n        init_params='wmc',\n        random_state=1,\n        n_init=3,\n        verbose=0)\n\n    gmm.fit(df.loc[:, ['loc_x', 'loc_y']])\n    \n    return gmm.predict(df.loc[:, ['loc_x', 'loc_y']]) \n\nlocation_clusters_s = get_shot_location_clusters(X, 13)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 1: `loc_x` and `loc_y`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\nfeatures = ['loc_y', 'loc_x']\n\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 2: `loc_x`, `loc_y` and `last_5_sec_in_period`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\nX = (X\n     .assign(seconds_from_period_end = lambda x: 60 * x['minutes_remaining'] + x['seconds_remaining'])\n     .assign(last_5_sec_in_period = lambda x: x['seconds_from_period_end'] < 5))\n\nfeatures = ['loc_x', 'loc_y', 'last_5_sec_in_period']\n    \nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 3: `loc_x`, `loc_y` and `shot_distance`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nfeatures = ['loc_x', 'loc_y', 'shot_distance']\n\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 4: `loc_x`, `loc_y` and `combined_shot_type`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\ncst_dummies = pd.get_dummies(X['combined_shot_type'], prefix='combined_shot_type', prefix_sep=\":\")\nX = X.join(cst_dummies)\n\nfeatures = np.concatenate([['loc_x', 'loc_y'], cst_dummies.columns])\n\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 5: Enhanced `shot_distance`, and `action_type`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nX['shot_distance']= np.sqrt((X['loc_x']/10)**2 + (X['loc_y']/10)**2)\n\nat_dummies = pd.get_dummies(X['action_type'], prefix='action_type', prefix_sep=\":\")\nX = X.join(at_dummies)\n\nfeatures = np.concatenate([['shot_distance'] ,at_dummies.columns])\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 6: `loc_x`, `loc_y` and `prev_shot_made`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nX = X.join(prev_shot_made_s)\n\nfeatures = np.concatenate([['loc_x', 'loc_y', 'prev_shot_made']])\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 7: `shot_distance`, `prev_shot_made` and `action_type`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nX = X.join(prev_shot_made_s)\nX = X.join(at_dummies)\n\nfeatures = np.concatenate([['prev_shot_made', 'shot_distance'], at_dummies.columns])\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 8: `location_cluster`, `action_type` and `combined_shot_type`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nlc_dummies = pd.get_dummies(location_clusters_s, prefix='location_cluster', prefix_sep=\":\")\nlc_dummies = lc_dummies.set_index(X.index)\n\nX = X.join(lc_dummies)\nX = X.join(at_dummies)\nX = X.join(cst_dummies)\n\nfeatures = np.concatenate([lc_dummies.columns, at_dummies.columns])\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 9: binned `loc_x`,  binned `loc_y`"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, Y = init_learning_data(raw_df)\n\nloc_x_20_bins = binning(X, 'loc_x', 20)\nloc_y_20_bins = binning(X, 'loc_y', 20)\n\nloc_x_20_dummies = pd.get_dummies(X['loc_x'], prefix='loc_x')\nloc_y_20_dummies = pd.get_dummies(X['loc_y'], prefix='loc_y')\n\nX = X.join(loc_x_20_dummies)\nX = X.join(loc_y_20_dummies)\n\nfeatures = np.concatenate([loc_x_20_dummies.columns, loc_y_20_dummies.columns])\nplot_learning_curve(gbc, 'GBC', X.loc[:,features], Y, cv=kfold)"},{"cell_type":"markdown","metadata":{},"source":"### Feature set 10: ..."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}