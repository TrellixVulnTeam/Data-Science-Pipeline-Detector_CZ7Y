{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"## import packages and modules\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport math\nimport h5py\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport time\n# show plots inline\n%matplotlib inline\n## dataset path\nfilename = \"../input/data.csv\"\n## set default figure size\nfigure_size = (15,10)\n# set max display row number\npd.set_option('max_rows',5)\n","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"38768d0b52c7f0efdb3895c84090b447daaf9a15","collapsed":true},"cell_type":"code","source":"## load dataset\n# set column 'shot_id' as index because it is subjective and unique\ndf = pd.read_csv(filename, parse_dates=['game_date'], index_col='shot_id')\n# view first 3 lines\nprint(df.head(3))\n# list all features\nprint(df.columns.values)\n# response variable\nresponse_variable = 'shot_made_flag'","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a169d5e4d360742c1a9592180a561c1410c3bb4","collapsed":true},"cell_type":"code","source":"## columns not needed\nnotNeeded = []\n## dummy variables\ndummy_var = []","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d56635c3f699beb345122e06a1f63824997f3a1f"},"cell_type":"code","source":"## craete new features and delete unnecessary ones\n# action_type\nfor elem in df['action_type'].unique():\n    df[str(elem)] = (df['action_type'] == elem).astype(int)\n    dummy_var.append(str(elem))\nnotNeeded.append('action_type')\n# combined shot type \nfor elem in df['combined_shot_type'].unique():\n    df[str(elem)] = (df['combined_shot_type'] == elem).astype(int)\n    dummy_var.append(str(elem))\nnotNeeded.append('combined_shot_type')","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6974ff1682a75c66abe5993716f311c8e66790fd"},"cell_type":"code","source":"# game event and game IDs not needed, subjective index\nnotNeeded.extend(['game_event_id','game_id'])","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b05a3dee89f98147ab28cea2f91df4bb6b494ac","collapsed":true},"cell_type":"code","source":"# lat, lon, loc_x, loc_y\nsns.set_style('whitegrid')\nsns.pairplot(df, vars=['loc_x', 'lon'], hue='shot_made_flag',size = 3)\nsns.pairplot(df, vars=[ 'loc_y', 'lat'], hue='shot_made_flag',size = 3)\nsns.set_style('whitegrid')\nsns.pairplot(df, vars=['loc_x', 'loc_y'], hue='shot_made_flag')\n#loc_x and lon are correlated, also loc_y and lat, so we'll drop lon and lat.\nnotNeeded.extend(['lon','lat'])\n","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"23908d605578eba58ec7af479fcc2a167a5c5dc5"},"cell_type":"code","source":"# minutes_remaining and seconds_remaining can be put in one column named time_remaining.\ndf['timeRemaining'] = 60 * df.loc[:,'minutes_remaining'] + df.loc[:,'seconds_remaining']\nnotNeeded.extend(['minutes_remaining','seconds_remaining'])","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8c8cf6c714397c381c0e4630d93d1791ff509b39"},"cell_type":"code","source":"# season, just keep the year when season started\ndf['season'] = df['season'].apply(lambda x: x[:4])\n# convert column to integer\ndf['season'] = pd.to_numeric(df['season'])","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b30f7650ef4c818d3977d57456bb673d690c1167","collapsed":true},"cell_type":"code","source":"# shot distance, seems like shot_distance is just floored distance calculated from x- and y- location of a shot,\n# so we'll use more precise measure and drop floored one.\ndistance = pd.DataFrame({'trueDistance': np.sqrt((df['loc_x']/10)** 2 + (df['loc_y']/10) ** 2),\n                       'shotDistance': df['shot_distance']})\nprint(distance.head(5))\ndf['shotDistance'] = distance['trueDistance']\nnotNeeded.append('shot_distance')","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6bbf73fb0c4880b7cdf2f2bf1231568e8d5ed455"},"cell_type":"code","source":"# shot type\ndf['3ptGoal'] = df['shot_type'].str.contains('3PT').astype('int')\ndummy_var.append('3ptGoal')\nnotNeeded.append('shot_type')","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"68a79c77e2f8757bce9c0c0b88c3ba6a40df6080"},"cell_type":"code","source":"#shot_zone_range is just putting shot_distance in 5 bins, not needed\nnotNeeded.append('shot_zone_range')\n# shot zone area and basic\nfor elem in df['shot_zone_area'].unique():\n    df[str(elem)] = (df['shot_zone_area'] == elem).astype(int)\n    dummy_var.append(str(elem))\nnotNeeded.append('shot_zone_area')\nfor elem in df['shot_zone_basic'].unique():\n    df[str(elem)] = (df['shot_zone_basic'] == elem).astype(int)\n    dummy_var.append(str(elem))\nnotNeeded.append('shot_zone_basic')","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6085c5d992be494db6b7ed4f8e2d5500aebb57d9"},"cell_type":"code","source":"# team id and team name, consistent within the dataset\nnotNeeded.extend(['team_id','team_name'])","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbefea71c704192025250eb24758936b3edce5be","collapsed":true},"cell_type":"code","source":"# game date\n# convert game_date to datetime format, and then split it to year, month and weekday (0 = Monday, 6 = Sunday)\ndf['game_date'] = pd.to_datetime(df['game_date'])\ndf['game_year'] = df['game_date'].dt.year\ndf['game_month'] = df['game_date'].dt.month\ndf['game_day'] = df['game_date'].dt.dayofweek\n# create indicate variables for month and weekday\nfor elem in df['game_month'].unique():\n    pass\nnotNeeded.append('game_date')","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ef27c58708f8f5bf842741046cc0c78aca5c9ff1"},"cell_type":"code","source":"# matchup and opponent\n# matchup and opponent columns give as almost the same data - matchup tells us if the game was home or away (depending if it is '@' or 'vs'), \n# so we'll make a new column with that info and then we can drop matchup column.\ndf['homeGame'] = df['matchup'].str.contains('vs').astype(int)\nnotNeeded.append('matchup')\nfor elem in df['opponent'].unique():\n    df[str(elem)] = (df['opponent'] == elem).astype(int)\n    dummy_var.append(str(elem))\nnotNeeded.append('opponent')","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8a02011187928d3faaabcc317a837d603ab7a7db"},"cell_type":"code","source":"# finally drop all not needed columns:\ndf = df.drop(notNeeded,axis=1)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d37b54f5f19396c5f0328ddd48eefa45183557c3","collapsed":true},"cell_type":"code","source":"## split into training set and predict set\ntrain_df = df.loc[df['shot_made_flag'].notnull()]\npredict_df = df.loc[df['shot_made_flag'].isnull()]\n# variables in dummy_var is a sparse matrix\nprint(train_df.head(3))\nprint(predict_df.head(3))\n# normalizing for not dummy variables\nY = df['shot_made_flag'].as_matrix()\nY = Y.reshape(Y.shape[0],1)   \nX = df.drop(['shot_made_flag'], axis=1)\nmax_x = []\nfor c in X.columns.values:\n    if c not in dummy_var:\n        max_x.append(df[str(c)].max())\n    else:\n        max_x.append(1)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f792a4443edaffece68777d20b3fb44d5fa41ff","collapsed":true},"cell_type":"code","source":"## labels Y and X\n# training set\ntrain_Y = train_df['shot_made_flag'].as_matrix()\ntrain_Y = train_Y.reshape(train_Y.shape[0],1)      \ntrain_X = train_df.drop(['shot_made_flag'], axis=1)\ntrain_X = train_X/max_x\n# test set\npredict_Y = predict_df['shot_made_flag'].as_matrix()\npredict_Y = predict_Y.reshape(predict_Y.shape[0],1)\npredict_X = predict_df.drop(['shot_made_flag'], axis=1)\npredict_X = predict_X/max_x\n## display training and test dataframe\nprint(train_X.head(3))\nprint(predict_X.head(3))\ntrain_X = train_X.as_matrix()\npredict_X = predict_X.as_matrix()\n## transpose matrix\ntrain_X = train_X.T\ntrain_Y = train_Y.T\npredict_X = predict_X.T\npredict_Y = predict_Y.T\n## print info\nprint (\"number of training examples = \" + str(train_X.shape[1]))\nprint (\"number of test examples = \" + str(predict_X.shape[1]))\nprint (\"train_X shape: \" + str(train_X.shape))\nprint (\"train_Y shape: \" + str(train_Y.shape))\nprint (\"predict_X shape: \" + str(predict_X.shape))\nprint (\"predict_Y shape: \" + str(predict_Y.shape))","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"372da1e14ee50f99cb3c5a3817e6d52d3a240eac","collapsed":true},"cell_type":"code","source":"## store processed and normalized dataframe\ndf = X/max_x\ndf['shot_made_flag'] = Y\ndf['shot_id'] = df.index.values\nprint(df.head(3))\noutput_file = 'processed.csv'\ndf.to_csv(output_file, index = False)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"91b96aeb4ed03494e5c9d8cb2724b7f6bfd5c3cb"},"cell_type":"code","source":"## define neural network function\ndef create_placeholders(n_x, n_y):\n    \"\"\"\n    Creates the placeholders for the tensorflow session.    \n    Arguments:\n    n_x -- scalar, size of an image vector\n    n_y -- scalar, number of classes   \n    Returns:\n    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"    \n    Tips:\n    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n      In fact, the number of examples during test/train is different.\n    \"\"\"\n    X = tf.placeholder(tf.float32, shape = [n_x,None])\n    Y = tf.placeholder(tf.float32, shape = [n_y,None])    \n    return X, Y","execution_count":126,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"06050deae027c7361735ad541606a2afc2c5f836"},"cell_type":"code","source":"## define neural network function\ndef initialize_parameters(nn):\n    \"\"\"\n    layer = len(nn)-1\n    Initializes parameters to build a neural network with tensorflow. The shapes are:\n                        W1 : [n1, n0]\n                        b1 : [n1, 1]\n                        W2 : [n2, n1]\n                        b2 : [n2, 1]\n                        ...\n                        W_layer : [n(layer), n(layer-1)]\n                        b_layer : [n(layer), 1]    \n    Returns:\n    parameters -- a dictionary of tensors containing W1, b1, W2, b2, ...\n    \"\"\"\n    parameters = {}\n    for i in range(len(nn)-1):\n        parameters['W' + str(i+1)] = tf.get_variable('W'+str(i+1), [nn[i+1], nn[i]], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n        parameters['b' + str(i+1)] = tf.get_variable('b' + str(i+1), [nn[i+1],1], initializer = tf.zeros_initializer())\n    return parameters","execution_count":127,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"06821b5d5ee053167d9c458940a30398225f3b7b"},"cell_type":"code","source":"## define neural network function\ndef forward_propagation(X, parameters):\n    \"\"\"\n    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n    Arguments:\n    X -- input dataset placeholder, of shape (input size, number of examples)\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", ...\n                  the shapes are given in initialize_parameters\n    Returns: \n    Z(len(parameters)/2) -- the output of the last LINEAR unit\n    \"\"\"\n    length = int(len(parameters)/2)\n    Z = tf.add(tf.matmul(parameters['W1'], X),parameters['b1'])\n    A = tf.nn.relu(Z)  \n    for i in range(2, length):\n        Z = tf.add(tf.matmul(parameters['W'+str(i)], A),parameters['b'+str(i)])\n        A = tf.nn.relu(Z)  \n    Z = tf.add(tf.matmul(parameters['W'+str(length)], A),parameters['b'+str(length)])\n    return Z","execution_count":128,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a8adb0b7de9c6708fae500d6d6674659f2fd2852"},"cell_type":"code","source":"## deifne neural network function\ndef compute_cost(Z_end, Y):\n    \"\"\"\n    Computes the cost  \n    Arguments:\n    Z_end -- output of forward propagation (output of the last LINEAR unit), of shape (1, number of examples)\n    Y -- \"true\" labels vector placeholder, same shape as Z_end\n    Returns:\n    cost - Tensor of the cost function\n    \"\"\"\n    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n    logits = tf.transpose(Z_end)\n    labels = tf.transpose(Y)   \n    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))   \n    return cost","execution_count":129,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a92accf34b54561b36f1fa0ebcac20e329eb855","collapsed":true},"cell_type":"code","source":"## define neural network function\ndef model(X_train, Y_train, X_test, nn, learning_rate = 0.001,\n          num_epochs = 1500, print_cost = True):\n    \"\"\"\n    Implements a len(nn)-1 layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->...->LINEAR->SIGMOID. \n    Arguments:\n    X_train -- training set\n    Y_train -- test set\n    nn -- input layer + number of neurals in each layer\n    learning_rate -- learning rate of the optimization\n    num_epochs -- number of epochs of the optimization loop\n    print_cost -- True to print the cost every 100 epochs\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep consistent results\n    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n    n_y = Y_train.shape[0]                            # n_y : output size\n    costs = []                                        # To keep track of the cost\n    # Create Placeholders of shape (n_x, n_y)\n    X, Y = create_placeholders(n_x,n_y)\n    # Initialize parameters\n    parameters = initialize_parameters(nn)\n    # Forward propagation: Build the forward propagation in the tensorflow graph\n    Z_end = forward_propagation(X, parameters)\n    # Cost function: Add cost function to tensorflow graph\n    cost = compute_cost(Z_end, Y)\n    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n    # Initialize all the variables\n    init = tf.global_variables_initializer()\n    # Start the session to compute the tensorflow graph\n    with tf.Session() as sess:  \n        # Run the initialization\n        sess.run(init)\n        # Do the training loop\n        for epoch in range(num_epochs):\n            # decrease learning rate every 1000 iterations to avoid oscillation\n            if epoch%1000 == 1:\n                learning_rate_now = learning_rate * np.exp(-epoch/num_epochs)\n                optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate_now).minimize(cost)\n            _ , tmp_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n            epoch_cost = tmp_cost\n            # Print the cost every 100 epoch\n            if print_cost == True and epoch % 100 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            if print_cost == True and epoch % 10 == 0:\n                costs.append(epoch_cost)     \n        # plot the cost\n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.show()\n        # lets save the parameters in a variable\n        parameters = sess.run(parameters)\n        print (\"Parameters have been trained!\")\n        return parameters","execution_count":137,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad625f2c1ea20bf0a86efd6281912ecd5632fa8b","scrolled":false,"collapsed":true},"cell_type":"code","source":"## training\n# train\nstart_time = time.time()\nneural_num = [train_X.shape[0], 25, 12, 1]\nparameters = model(train_X, train_Y, predict_X, neural_num, num_epochs = 10000, learning_rate = 0.1)\nend_time = time.time()\nprint(\"Neural network training time consumed: %lf secs\" % (end_time - start_time))","execution_count":139,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c040c7f9d1a4133c8721b026586fe6f3a67d83c1","collapsed":true},"cell_type":"code","source":"## accuracy and prediction\nz_end = forward_propagation(tf.cast(predict_X, tf.float32), parameters)\npredict_y = tf.sigmoid(z_end)\nwith tf.Session() as sess:\n    predict_y = sess.run(predict_y)\n    print(predict_y)\n","execution_count":145,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6b511df481793ca38c851d54d672bddae82aba3e"},"cell_type":"code","source":"## submit\nmask = df['shot_made_flag'].isnull()\nsubmission = pd.DataFrame({\"shot_id\":df[mask].index, \"shot_made_flag\":predict_y[0]})\nsubmission.sort_values('shot_id',  inplace=True)\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":149,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d30b671af84f675cc1ee35d16db4c27c9c882149","collapsed":true},"cell_type":"code","source":"## nect step:\n# further feature engineering \n# implement neural network with keras\n# cross-validation\n# ensemble\n# xgboost\n","execution_count":148,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"028975088bfe908fa3bb6cfc49f4c9bf7af22fc0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}