{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport numpy as np\nimport datetime\nimport csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\nfrom io import TextIOWrapper\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PREFIX = '/kaggle/input/predict-west-nile-virus/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(PREFIX + \"train.csv.zip\", compression='zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather = pd.read_csv(PREFIX + 'weather.csv.zip', compression='zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with ZipFile(PREFIX + 'weather.csv.zip') as zf:\n    for line in csv.DictReader(TextIOWrapper(zf.open('weather.csv'))):\n        print(line)\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_map = {'CULEX RESTUANS' : \"100000\",\n              'CULEX TERRITANS' : \"010000\", \n              'CULEX PIPIENS'   : \"001000\", \n              'CULEX PIPIENS/RESTUANS' : \"101000\", \n              'CULEX ERRATICUS' : \"000100\", \n              'CULEX SALINARIUS': \"000010\", \n              'CULEX TARSALIS' :  \"000001\",\n              'UNSPECIFIED CULEX': \"001000\"} # Treating unspecified as PIPIENS (http://www.ajtmh.org/content/80/2/268.full)\n\ndef date(text):\n    return datetime.datetime.strptime(text, \"%Y-%m-%d\").date()\n    \ndef precip(text):\n    TRACE = 1e-3\n    text = text.strip()\n    if text == \"M\":\n        return None\n    if text == \"T\":\n        return TRACE\n    return float(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill nans with values from the station with valid parameters\n# for example, if temperature is not available for station1, it would be taken from station 2.\ndef impute_missing_weather_station_values(weather):\n    # Stupid simple\n    for k, v in weather.items():\n        if v[0] is None:\n            v[0] = v[1]\n        elif v[1] is None:\n            v[1] = v[0]\n        for k1 in v[0]:\n            if v[0][k1] is None:\n                v[0][k1] = v[1][k1]\n        for k1 in v[1]:\n            if v[1][k1] is None:\n                v[1][k1] = v[0][k1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_weather():\n    weather = {}\n    with ZipFile(PREFIX + 'weather.csv.zip') as zf:\n        for line in csv.DictReader(TextIOWrapper(zf.open('weather.csv'))):\n        # for line in csv.DictReader(open(PREFIX + \"weather.csv.zip\")):\n            for name, converter in {\"Date\" : date,\n                                    \"Tmax\" : float,\"Tmin\" : float,\"Tavg\" : float,\n                                    \"DewPoint\" : float, \"WetBulb\" : float,\n                                    \"PrecipTotal\" : precip,\n                                    \"Depart\" : float, \n                                    \"ResultSpeed\" : float,\"ResultDir\" : float,\"AvgSpeed\" : float,\n                                    \"StnPressure\" : float, \"SeaLevel\" : float}.items():\n                x = line[name].strip()\n                line[name] = converter(x) if (x != \"M\") else None\n            station = int(line[\"Station\"]) - 1\n            assert station in [0,1]\n            dt = line[\"Date\"]\n            if dt not in weather:\n                weather[dt] = [None, None]\n            assert weather[dt][station] is None, \"duplicate weather reading {0}:{1}\".format(dt, station)\n            weather[dt][station] = line\n    impute_missing_weather_station_values(weather)        \n    return weather","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_training():\n    training = []\n    with ZipFile(PREFIX + 'train.csv.zip') as zf:\n        for line in csv.DictReader(TextIOWrapper(zf.open('train.csv'))):\n            # for line in csv.DictReader(open(PREFIX + \"train.csv\")):\n            for name, converter in {\"Date\" : date, \n                                    \"Latitude\" : float, \"Longitude\" : float,\n                                    \"NumMosquitos\" : int, \"WnvPresent\" : int}.items():\n                line[name] = converter(line[name])\n            training.append(line)\n    return training\n    \ndef load_testing():\n    training = []\n    with ZipFile(PREFIX + 'test.csv.zip') as zf:\n        for line in csv.DictReader(TextIOWrapper(zf.open('test.csv'))):\n            # for line in csv.DictReader(open(PREFIX + \"test.csv\")):\n            for name, converter in {\"Date\" : date, \n                                    \"Latitude\" : float, \"Longitude\" : float}.items():\n                line[name] = converter(line[name])\n            training.append(line)\n    return training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def closest_station(lat, longi):\n    # Chicago is small enough that we can treat coordinates as rectangular.\n    stations = np.array([[41.995, -87.933],\n                         [41.786, -87.752]])\n    loc = np.array([lat, longi])\n    deltas = stations - loc[None, :]\n    dist2 = (deltas**2).sum(1)\n    return np.argmin(dist2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(X, mean=None, std=None):\n    count = X.shape[1]\n    if mean is None:\n        mean = np.nanmean(X, axis=0)\n    for i in range(count):\n        X[np.isnan(X[:,i]), i] = mean[i]\n    if std is None:\n        std = np.std(X, axis=0)\n    for i in range(count):\n        X[:,i] = (X[:,i] - mean[i]) / std[i]\n    return mean, std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaled_count(record):\n    SCALE = 10.0\n    if \"NumMosquitos\" not in record:\n        # This is test data\n        return 1\n    return int(np.ceil(record[\"NumMosquitos\"] / SCALE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def assemble_X(base, weather):\n    X = []\n    for b in base:\n        date = b[\"Date\"]\n        lat, longi = b[\"Latitude\"], b[\"Longitude\"]\n        case = [date.year, date.month, date.day, lat, longi]\n        # Look at a selection of past weather values\n        for days_ago in [1,2,3,5,8,13]:\n            day = date - datetime.timedelta(days=days_ago)\n            for obs in [\"Tmax\",\"Tmin\",\"Tavg\",\"DewPoint\",\"WetBulb\",\"PrecipTotal\",\"Depart\"]:\n                station = closest_station(lat, longi)\n                case.append(weather[day][station][obs])\n        # Specify which mosquitos are present\n        species_vector = [float(x) for x in species_map[b[\"Species\"]]]\n        case.extend(species_vector)\n        # Weight each observation by the number of mosquitos seen. Test data\n        # Doesn't have this column, so in that case use 1. This accidentally\n        # Takes into account multiple entries that result from >50 mosquitos\n        # on one day. \n        for repeat in range(scaled_count(b)):\n            X.append(case)    \n    X = np.asarray(X, dtype=np.float32)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def assemble_y(base):\n    y = []\n    for b in base:\n        present = b[\"WnvPresent\"]\n        for repeat in range(scaled_count(b)):\n            y.append(present)    \n    return np.asarray(y, dtype=np.int32).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this was for another NN library.\n\nclass AdjustVariable(object):\n    def __init__(self, variable, target, half_life=20):\n        self.variable = variable\n        self.target = target\n        self.half_life = half_life\n    def __call__(self, nn, train_history):\n        delta = self.variable.get_value() - self.target\n        delta /= 2**(1.0/self.half_life)\n        self.variable.set_value(np.float32(self.target + delta))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather = load_weather()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather.items()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training = load_training()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = assemble_X(training, weather)\nmean, std = normalize(X)\ny = assemble_y(training)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(200, activation='relu', input_shape=X[0].shape),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(200, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nopt = tf.keras.optimizers.SGD(\n    learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\",\n)\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=X_train, y=y_train, epochs=60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict_proba(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train:\", metrics.roc_auc_score(y_train, model.predict_proba(X_train)))\n\nprint(\"valid:\", metrics.roc_auc_score(y_valid, model.predict_proba(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list(zip(testing, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing = load_testing()\nX_testing = assemble_X(testing, weather) \nnormalize(X_testing, mean, std)\npredictions = model.predict_proba(X_testing)[:,0]  \n\ndf_out = pd.DataFrame(np.array([[row['Id'], p] for row, p in zip(testing, predictions)]), columns=[\"Id\",\"WnvPresent\"])\n\ndf_out.to_csv('west_nile_v5_pd.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = pd.DataFrame(np.array([[row['Id'], p] for row, p in zip(testing, predictions)]), columns=[\"Id\",\"WnvPresent\"])\n\ndf_out.to_csv('west_nile_v5_pd.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}