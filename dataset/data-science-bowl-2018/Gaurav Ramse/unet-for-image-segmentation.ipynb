{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing liabraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport glob\nimport pathlib\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\nfrom tqdm import tqdm\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-31T17:42:57.333792Z","iopub.execute_input":"2021-12-31T17:42:57.334594Z","iopub.status.idle":"2021-12-31T17:43:01.303027Z","shell.execute_reply.started":"2021-12-31T17:42:57.33448Z","shell.execute_reply":"2021-12-31T17:43:01.30229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the input zip path and output unzip path","metadata":{}},{"cell_type":"code","source":"base_dir = '/kaggle/input/data-science-bowl-2018/'\nunzip_base_dir = '/kaggle/working/'\nstage_train_zip = base_dir + 'stage1_train.zip'\nstage_train_labels_zip= base_dir + 'stage1_train_labels.csv.zip'\n\nstage_train_unzip = unzip_base_dir + 'stage1_train/'\nstage_train_labels_unzip= unzip_base_dir + 'stage1_train_labels/'","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:01.304598Z","iopub.execute_input":"2021-12-31T17:43:01.30483Z","iopub.status.idle":"2021-12-31T17:43:01.309625Z","shell.execute_reply.started":"2021-12-31T17:43:01.304797Z","shell.execute_reply":"2021-12-31T17:43:01.308668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1) Unzip the data","metadata":{}},{"cell_type":"code","source":"import zipfile\nfor path, unzip_path in zip([stage_train_zip,stage_train_labels_zip ], [stage_train_unzip, stage_train_labels_unzip]):\n    print(path)\n    print(unzip_path)\n    print('---')\n    with zipfile.ZipFile(path, 'r') as zip_ref:\n        zip_ref.extractall(unzip_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:01.311193Z","iopub.execute_input":"2021-12-31T17:43:01.311574Z","iopub.status.idle":"2021-12-31T17:43:07.224045Z","shell.execute_reply.started":"2021-12-31T17:43:01.311538Z","shell.execute_reply":"2021-12-31T17:43:07.223249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = r\"/kaggle/input/data-science-bowl-2018/stage1_test.zip\"\ntest_data_unzip = unzip_base_dir + 'stage1_test/'\nwith zipfile.ZipFile(test_data, 'r') as zip_ref:\n    zip_ref.extractall(test_data_unzip)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:07.226128Z","iopub.execute_input":"2021-12-31T17:43:07.226871Z","iopub.status.idle":"2021-12-31T17:43:07.475257Z","shell.execute_reply.started":"2021-12-31T17:43:07.226833Z","shell.execute_reply":"2021-12-31T17:43:07.47455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pathlib.Path(test_data_unzip)\nlsttest_files = glob.glob(str(test/'*/'))\nlsttest_files[:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:07.478219Z","iopub.execute_input":"2021-12-31T17:43:07.478422Z","iopub.status.idle":"2021-12-31T17:43:07.486841Z","shell.execute_reply.started":"2021-12-31T17:43:07.478392Z","shell.execute_reply":"2021-12-31T17:43:07.486067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function is just to get an image given path, So for test purpose we will use this function to get test image","metadata":{}},{"cell_type":"code","source":"def get_image(image_path):\n    temp_path = glob.glob(image_path+'/images/*')\n    img = tf.io.read_file(temp_path[0])\n    img = tf.io.decode_image(img)\n    img = tf.image.resize(img, (128,128))\n\n    arr = img[:, :, :3].numpy()\n    new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min())))\n    return new_arr\n\ntest_images = []\nfor i in lsttest_files:\n    test_images.append(get_image(i))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:07.488288Z","iopub.execute_input":"2021-12-31T17:43:07.48886Z","iopub.status.idle":"2021-12-31T17:43:10.186453Z","shell.execute_reply.started":"2021-12-31T17:43:07.488785Z","shell.execute_reply":"2021-12-31T17:43:10.185746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will convert test images to the tensor\ntest_dataset = tf.convert_to_tensor(np.array(test_images))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:10.187865Z","iopub.execute_input":"2021-12-31T17:43:10.18811Z","iopub.status.idle":"2021-12-31T17:43:10.209152Z","shell.execute_reply.started":"2021-12-31T17:43:10.188076Z","shell.execute_reply":"2021-12-31T17:43:10.20849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's have all filepath of images in list","metadata":{}},{"cell_type":"code","source":"path = pathlib.Path(stage_train_unzip)\nlst_files = glob.glob(str(path/'*/'))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:10.210211Z","iopub.execute_input":"2021-12-31T17:43:10.210469Z","iopub.status.idle":"2021-12-31T17:43:10.219097Z","shell.execute_reply.started":"2021-12-31T17:43:10.210435Z","shell.execute_reply":"2021-12-31T17:43:10.218306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:10.220407Z","iopub.execute_input":"2021-12-31T17:43:10.220977Z","iopub.status.idle":"2021-12-31T17:43:10.225224Z","shell.execute_reply.started":"2021-12-31T17:43:10.220942Z","shell.execute_reply":"2021-12-31T17:43:10.224447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This class will create dataset for training,As we know by using this type of class, It is computationally expensive. So for just demostration purpose i am using this class to pass data to the model","metadata":{}},{"cell_type":"code","source":"class create_ds(keras.utils.Sequence):\n    def __init__(self, lst_files, batch_size):\n        self.lst_files = lst_files\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return len(self.lst_files)//self.batch_size\n\n    \n    def get_image(self, image_path):\n        temp_path = glob.glob(image_path+'/images/*')\n        img = tf.io.read_file(temp_path[0])\n        img = tf.io.decode_image(img)\n        img = tf.image.resize(img, (128,128))\n\n        arr = img[:, :, :3].numpy()\n        new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min())))\n        \n        ma = glob.glob(image_path+'/masks/*')\n        mask_ = tf.zeros(shape = (128, 128, 1))\n        \n        # Get all mask in particular folder and append to mask with all pixel value equal to zero\n        for mask_path in ma:\n            mask = tf.io.read_file(mask_path)\n            mask = tf.io.decode_image(mask)\n            mask = tf.image.resize(mask, (128,128))\n           \n            mask_ = tf.maximum(mask_, mask)\n        \n        return new_arr, mask_.numpy()\n        \n    # Create batches of given batch and return to the dataset object    \n    def __getitem__(self, idx):\n        batch = self.lst_files[idx * self.batch_size : (idx+1)*self.batch_size]\n        \n        temp_image = []\n        temp_label = []\n        for path in batch:\n            new_arr, mask = self.get_image(path)\n            temp_image.append(new_arr)\n            temp_label.append(mask/255.0)\n        \n        return tf.convert_to_tensor(np.array(temp_image), dtype='float32'), tf.convert_to_tensor(np.array(temp_label),dtype ='float32')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:10.22771Z","iopub.execute_input":"2021-12-31T17:43:10.228457Z","iopub.status.idle":"2021-12-31T17:43:11.186274Z","shell.execute_reply.started":"2021-12-31T17:43:10.228419Z","shell.execute_reply":"2021-12-31T17:43:11.185548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to plot the ","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\n\n# We will pass the df which we created using model.history, So we wo=ill plot train, test loss. Train test accuracy\ndef plot_train_valid_curcve(df):\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['loss'],\n                            mode='lines',\n                            name='Train_loss'))\n\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['val_loss'],\n                            mode='lines',\n                            name='val_loss'))\n\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['accuracy'],\n                            mode='lines',\n                            name='Train_accuracy'))\n\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['val_accuracy'],\n                            mode='lines',\n                            name='val_accuracy'))\n        fig.show()\n        \n# Let's see what we got as a prediction\ndef plot_predicted_image(x_test, valid, pred):\n    ''' Function to plot Actual image, actual mask, Predicted Mask\n    \n    Param X-test : Actual image\n    Param valid  : Validation mask\n    Param pred   : Predicted image\n    '''\n    \n    fig = plt.figure(figsize = (15,7))\n    plt.subplot(1, 3,1)\n    plt.title('Actual Image')\n    plt.imshow(x_test)\n    \n#     fig = plt.figure(figsize = (20,7))\n    plt.subplot(1, 3,2)\n    plt.title('Actual Mask')\n    plt.imshow(valid)\n    \n    plt.subplot(1, 3,3)\n    plt.title('Predicted mask')\n    plt.imshow(pred)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:14.229732Z","iopub.execute_input":"2021-12-31T17:43:14.23065Z","iopub.status.idle":"2021-12-31T17:43:14.25049Z","shell.execute_reply.started":"2021-12-31T17:43:14.230602Z","shell.execute_reply":"2021-12-31T17:43:14.249849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's split the data into train test split\nfrom sklearn.model_selection import train_test_split\ntrain, valid = train_test_split(lst_files)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:15.253231Z","iopub.execute_input":"2021-12-31T17:43:15.253656Z","iopub.status.idle":"2021-12-31T17:43:15.867293Z","shell.execute_reply.started":"2021-12-31T17:43:15.253611Z","shell.execute_reply":"2021-12-31T17:43:15.866556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the data using the class we created where we leverage the functionality of keras.sequence\ntrain_ds = create_ds(lst_files=train, batch_size = BATCH_SIZE) \nvalid_ds= create_ds(lst_files=valid, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:16.619Z","iopub.execute_input":"2021-12-31T17:43:16.619621Z","iopub.status.idle":"2021-12-31T17:43:16.626191Z","shell.execute_reply.started":"2021-12-31T17:43:16.619583Z","shell.execute_reply":"2021-12-31T17:43:16.625422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create model","metadata":{}},{"cell_type":"code","source":"# the dimension of image\nIMAGE_HEIGHT=128\nIMAGE_WIDTH=128\nCHANNEL = 3","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:18.362224Z","iopub.execute_input":"2021-12-31T17:43:18.36276Z","iopub.status.idle":"2021-12-31T17:43:18.366451Z","shell.execute_reply.started":"2021-12-31T17:43:18.362722Z","shell.execute_reply":"2021-12-31T17:43:18.365627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"get_model will give us model with Unet. One point to be noted here we have used padding as same, If we read the architecture carefully they are using \ndifferent concatenationa as well as loss function. For this notebook we will get overview of unet","metadata":{}},{"cell_type":"code","source":"def get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL):\n    inputs = keras.Input(shape = (IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL))\n    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(inputs)\n    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_1)\n    # conv_1\n\n    conv_2 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_1)\n    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n\n    conv_3 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_2)\n    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n\n    conv_4 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_3)\n    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n\n    conv_5 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_4)\n    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n    \n    conv_6 = keras.layers.Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding='same')(conv_5)\n    conv_6 = keras.layers.concatenate([conv_4, conv_6])\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n\n    conv_7 = keras.layers.Conv2DTranspose(filters = 64, kernel_size = 2, strides = 2, padding='same')(conv_6)\n    conv_7 = keras.layers.concatenate([conv_3, conv_7])\n    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n\n    conv_8 = keras.layers.Conv2DTranspose(filters = 32, kernel_size = 2, strides = 2, padding='same')(conv_7)\n    conv_8 = keras.layers.concatenate([conv_2, conv_8])\n    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n\n\n    conv_9 = keras.layers.Conv2DTranspose(filters = 16, kernel_size = 2, strides = 2, padding='same')(conv_8)\n    conv_9 = keras.layers.concatenate([conv_1, conv_9])\n    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n\n    output = keras.layers.Conv2D(filters = 1, kernel_size = 3, padding='same', activation='relu')(conv_9)\n    model = keras.Model(inputs, output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:21.441314Z","iopub.execute_input":"2021-12-31T17:43:21.44188Z","iopub.status.idle":"2021-12-31T17:43:21.462395Z","shell.execute_reply.started":"2021-12-31T17:43:21.441843Z","shell.execute_reply":"2021-12-31T17:43:21.4609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:22.728399Z","iopub.execute_input":"2021-12-31T17:43:22.72944Z","iopub.status.idle":"2021-12-31T17:43:22.984912Z","shell.execute_reply.started":"2021-12-31T17:43:22.729372Z","shell.execute_reply":"2021-12-31T17:43:22.984166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:25.492838Z","iopub.execute_input":"2021-12-31T17:43:25.493568Z","iopub.status.idle":"2021-12-31T17:43:25.507986Z","shell.execute_reply.started":"2021-12-31T17:43:25.493525Z","shell.execute_reply":"2021-12-31T17:43:25.507155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will create baseline model and execute for 10 epochs\n\nstart = time.time()\nhistory = model.fit(train_ds, validation_data=valid_ds, epochs = 10, verbose=False)\n\nend = time.time()\nprint(f'Time required for the execution is {end - start}')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:43:34.711852Z","iopub.execute_input":"2021-12-31T17:43:34.71212Z","iopub.status.idle":"2021-12-31T17:52:04.440959Z","shell.execute_reply.started":"2021-12-31T17:43:34.712091Z","shell.execute_reply":"2021-12-31T17:52:04.440177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:52:04.44254Z","iopub.execute_input":"2021-12-31T17:52:04.442853Z","iopub.status.idle":"2021-12-31T17:52:04.449532Z","shell.execute_reply.started":"2021-12-31T17:52:04.442815Z","shell.execute_reply":"2021-12-31T17:52:04.44853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_valid_curcve(df)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:52:04.450891Z","iopub.execute_input":"2021-12-31T17:52:04.451316Z","iopub.status.idle":"2021-12-31T17:52:04.561304Z","shell.execute_reply.started":"2021-12-31T17:52:04.451279Z","shell.execute_reply":"2021-12-31T17:52:04.560523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Create data pipeline using tensor slices","metadata":{}},{"cell_type":"markdown","source":"As we have seen previous data pipeline was taking too much time for each epoch so we will use tf.data.Dataset object","metadata":{}},{"cell_type":"code","source":"model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:54:41.687981Z","iopub.execute_input":"2021-12-31T17:54:41.688227Z","iopub.status.idle":"2021-12-31T17:54:41.877879Z","shell.execute_reply.started":"2021-12-31T17:54:41.688201Z","shell.execute_reply":"2021-12-31T17:54:41.876992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As we have already created class through which we can call image and mask, We will write for loop and create data pipeline ,\n# Let's see if we can spped up the processing.\n\nx_train_slices = []\ny_train_slices = []\n\nx_test_slices = []\ny_test_slices = []\n\nfor (train, train_label)  in tqdm(train_ds):\n    for x_train, y_train in zip(train, train_label):\n        x_train_slices.append(x_train.numpy())\n        y_train_slices.append(y_train.numpy())\n        \nfor (valid, valid_label)  in tqdm( valid_ds):\n    for  x_test, y_test in zip( valid, valid_label):\n        \n        x_test_slices.append(x_test.numpy())\n        y_test_slices.append(y_test.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:54:42.471394Z","iopub.execute_input":"2021-12-31T17:54:42.471653Z","iopub.status.idle":"2021-12-31T17:55:31.378484Z","shell.execute_reply.started":"2021-12-31T17:54:42.471625Z","shell.execute_reply":"2021-12-31T17:55:31.37781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tensor_ds = tf.data.Dataset.from_tensor_slices((x_train_slices, y_train_slices))\nvalid_tensor_ds = tf.data.Dataset.from_tensor_slices((x_test_slices, y_test_slices))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:55:31.380187Z","iopub.execute_input":"2021-12-31T17:55:31.380447Z","iopub.status.idle":"2021-12-31T17:56:07.506399Z","shell.execute_reply.started":"2021-12-31T17:55:31.380402Z","shell.execute_reply":"2021-12-31T17:56:07.505687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\ntrain_tensor_ds = train_tensor_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\nvalid_tensor_ds = valid_tensor_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:56:07.507813Z","iopub.execute_input":"2021-12-31T17:56:07.508066Z","iopub.status.idle":"2021-12-31T17:56:07.516681Z","shell.execute_reply.started":"2021-12-31T17:56:07.508034Z","shell.execute_reply":"2021-12-31T17:56:07.516003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 2","metadata":{}},{"cell_type":"markdown","source":"As we can see from the time required  to train the model is significantly reduced","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:56:07.518673Z","iopub.execute_input":"2021-12-31T17:56:07.518992Z","iopub.status.idle":"2021-12-31T17:56:07.52964Z","shell.execute_reply.started":"2021-12-31T17:56:07.518957Z","shell.execute_reply":"2021-12-31T17:56:07.528887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nstart = time.time()\nhistory = model.fit(train_tensor_ds, validation_data = valid_tensor_ds, epochs = 100, verbose=False)\n\nend = time.time()\n\nprint(f'Time required for the execution is {end - start}')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:56:07.531085Z","iopub.execute_input":"2021-12-31T17:56:07.531341Z","iopub.status.idle":"2021-12-31T17:57:23.155066Z","shell.execute_reply.started":"2021-12-31T17:56:07.531307Z","shell.execute_reply":"2021-12-31T17:57:23.154167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:57:23.156429Z","iopub.execute_input":"2021-12-31T17:57:23.156773Z","iopub.status.idle":"2021-12-31T17:57:23.164334Z","shell.execute_reply.started":"2021-12-31T17:57:23.156734Z","shell.execute_reply":"2021-12-31T17:57:23.163451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_valid_curcve(df)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:57:23.1663Z","iopub.execute_input":"2021-12-31T17:57:23.166666Z","iopub.status.idle":"2021-12-31T17:57:23.187773Z","shell.execute_reply.started":"2021-12-31T17:57:23.166631Z","shell.execute_reply":"2021-12-31T17:57:23.186979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(np.array(x_test_slices))\npred_t = (pred >0.5).astype('uint8')\n\nfor plot_image in range(3):\n    random_image = np.random.randint(0, len(x_test_slices))\n    plot_predicted_image(np.array(x_test_slices)[random_image], np.array(y_test_slices)[random_image],  pred_t[random_image])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:57:23.188962Z","iopub.execute_input":"2021-12-31T17:57:23.189472Z","iopub.status.idle":"2021-12-31T17:57:25.758108Z","shell.execute_reply.started":"2021-12-31T17:57:23.189434Z","shell.execute_reply":"2021-12-31T17:57:25.757316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 3","metadata":{}},{"cell_type":"markdown","source":"In this model we will try to use learning scheduler and let's see this makes any difference","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch):\n    if epoch <50:\n        return 0.001\n#     elif ( 30 <= epoch and epoch <=50):\n#         return 0.001\n    elif (50<= epoch and epoch <=70 ):\n        return 0.0001\n    \n    elif (epoch>70):\n        return 0.0001 \ncall_back = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:57:25.759536Z","iopub.execute_input":"2021-12-31T17:57:25.759868Z","iopub.status.idle":"2021-12-31T17:57:25.76615Z","shell.execute_reply.started":"2021-12-31T17:57:25.759831Z","shell.execute_reply":"2021-12-31T17:57:25.765237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n\nstart = time.time()\n\nhistory = model.fit(train_tensor_ds, validation_data = valid_tensor_ds, epochs = 100, callbacks = [call_back], verbose=False)\n\nend = time.time()\n\nprint(f'Time required for the execution is {end - start}')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:57:25.768531Z","iopub.execute_input":"2021-12-31T17:57:25.769278Z","iopub.status.idle":"2021-12-31T17:58:39.586032Z","shell.execute_reply.started":"2021-12-31T17:57:25.769238Z","shell.execute_reply":"2021-12-31T17:58:39.585176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(history.history)\nplot_train_valid_curcve(df1)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:58:39.589428Z","iopub.execute_input":"2021-12-31T17:58:39.591114Z","iopub.status.idle":"2021-12-31T17:58:39.61991Z","shell.execute_reply.started":"2021-12-31T17:58:39.591071Z","shell.execute_reply":"2021-12-31T17:58:39.61892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the prediction on test image","metadata":{}},{"cell_type":"code","source":"pred = model.predict(np.array(x_test_slices))\npred_t = (pred >0.5).astype('uint8')\n\nfor plot_image in range(3):\n    random_image = np.random.randint(0, len(x_test_slices))\n    plot_predicted_image(np.array(x_test_slices)[random_image], np.array(y_test_slices)[random_image],  pred_t[random_image])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T17:58:39.624418Z","iopub.execute_input":"2021-12-31T17:58:39.624753Z","iopub.status.idle":"2021-12-31T17:58:41.478099Z","shell.execute_reply.started":"2021-12-31T17:58:39.624717Z","shell.execute_reply":"2021-12-31T17:58:41.477295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook gives us understandin how to proceed with image segmentation!! Please upvote if you like.\nIn next vesion I will use different loss function and accuracy metric.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}