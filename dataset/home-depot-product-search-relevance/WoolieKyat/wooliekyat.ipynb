{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n#from  stem.snowball import SnowballStemmer\nfrom nltk.stem import PorterStemmer\n#from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n#from nltk.corpus import stopwords\nps = PorterStemmer()\n#stop_words = set(stopwords.words('english'))\n#stemmer = SnowballStemmer('english')\nimport matplotlib.pyplot as plt\nfrom optparse import OptionParser\nimport sys\nfrom time import time\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.extmath import density\nfrom sklearn import metrics\n\n# loading data\ntraining_data = pd.read_csv(\"../input/train.csv\", encoding=\"ISO-8859-1\")\ntesting_data = pd.read_csv(\"../input/test.csv\", encoding=\"ISO-8859-1\")\nattribute_data = pd.read_csv(\"../input/attributes.csv\")\ndescriptions = pd.read_csv(\"../input/product_descriptions.csv\")\n\n\n# concatenating and merging product and brands name to test and training dataset to preform data cleansing analysis\nall_train_test = pd.concat((training_data, testing_data), axis=0, ignore_index=True)\nnum_train_obs = testing_data.shape[0] #keeping track of the number of obs in the training set\nall_train_test_desc = pd.merge(all_train_test, descriptions, how='left', on='product_uid')\n\nattribute_data.name.value_counts()\n\nbrand_names = attribute_data[attribute_data.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand_name\"})\nall_train_test_desc_band = pd.merge(all_train_test_desc, brand_names, how='left', on='product_uid')\n\n\nbrand_names = attribute_data[attribute_data.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand_name\"})\nall_train_test_desc_band = pd.merge(all_train_test_desc, brand_names, how='left', on='product_uid')\n\n#Product measurements\nProduct_Width = attribute_data[attribute_data.name == \"Product Width (in.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Product_Width\"})\nProduct_Height = attribute_data[attribute_data.name == \"Product Height (in.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Product_Height\"})\nProduct_Depth = attribute_data[attribute_data.name == \"Product Depth (in.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Product_Depth\"})\nProduct_Weight = attribute_data[attribute_data.name == \"Product Weight (lb.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Product_Weight\"})\nw_h = pd.merge(Product_Height, Product_Width, how='outer', on='product_uid')\nw_h_d = pd.merge(w_h, Product_Depth, how='outer', on='product_uid')\nw_h_d_We= pd.merge(w_h_d, Product_Weight, how='outer', on='product_uid')\nall_train_test_desc_band_P = pd.merge(all_train_test_desc_band, w_h_d_We, how='left', on='product_uid')\n#Assembled measurements\nAssembled_Height = attribute_data[attribute_data.name == \"Assembled Height (in.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Assembled_Height\"})\nAssembled_Width = attribute_data[attribute_data.name == \"Assembled Width (in.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Assembled_Width\"})\nAssembled_Depth = attribute_data[attribute_data.name == \"Assembled Depth (in.)\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Assembled_Depth\"})\nComm_Res = attribute_data[(attribute_data.name == \"Commercial / Residential\") | (attribute_data.name == \"Commercial/Residential Use\") | (attribute_data.name == \"Commercial\") | (attribute_data.name == \"Residential/Commercial/industrial Use\")][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Comm_Res\"})\nENERGY_STAR = attribute_data[(attribute_data.name == \"ENERGY STAR Certified\")|(attribute_data.name==\"Energy Star Qualified\") ][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"ENERGY_STAR\"})\naw_ah = pd.merge(Assembled_Height, Assembled_Width, how='outer', on='product_uid')\naw_ah_ad = pd.merge(aw_ah, Assembled_Depth, how='outer', on='product_uid')\nass_com_res = pd.merge(aw_ah_ad, Comm_Res, how='outer', on='product_uid')\nass_com_res_estar = pd.merge(ass_com_res, ENERGY_STAR, how='outer', on='product_uid')\n\n#Color\ncolor= attribute_data[(attribute_data.name==\"Finish Family\") |(attribute_data.name==\"Finish\") |(attribute_data.name==\"Color/Finish\") |(attribute_data.name==\"Color Family\") | (attribute_data.name==\"Color\")| (attribute_data.name==\"Fixture Color/Finish\")| (attribute_data.name==\"Finish Family\")| (attribute_data.name==\"Color/Finish Family\")][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Colour\"})\nVoltage= attribute_data[(attribute_data.name==\"Voltage (volts)\")|(attribute_data.name==\"Wattage (watts)\")][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"Voltage\"})\n\nall_train_test_desc_band_P_A = pd.merge(all_train_test_desc_band_P, ass_com_res_estar, how='left', on='product_uid')\n\npat=r'Color|Finish'\ncolour=attribute_data.name.str.extract(pat, expand=True)\ncolour.value_counts()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}