{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"code","outputs":[],"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"58e78333-bb67-4191-bdd6-8ddc086b9c62","_uuid":"bfcb90f9908d9daceabffa2d9cb249c5a19aad90"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor\nfrom nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer('english')\n\ndf_train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")\ndf_test = pd.read_csv('../input/test.csv', encoding=\"ISO-8859-1\")\ndf_attr = pd.read_csv('../input/attributes.csv')\ndf_pro_desc = pd.read_csv('../input/product_descriptions.csv')","metadata":{"collapsed":true,"_cell_guid":"57c951ce-079d-4bc8-a3bd-74e0f135cd42","_uuid":"05a884aa537dabad280ea6cd3462868a45ea1eef"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"df_attr.head()","metadata":{}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"## get shape of actual train dataframe\nnum_train = df_train.shape[0]\ndf_train.head()","metadata":{"_cell_guid":"480b786e-bf09-49bc-a0ca-f71189e4e796","_uuid":"419fda5e51695bc0298e7a555fa120acb512fb8b"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"\ndef str_stemmer(s):\n    ''' To stem and lamatize the sentences so that we can avoid the difference between computing , computed , computs'''\n    return \" \".join([stemmer.stem(word) for word in s.lower().split()])\n\ndef str_common_word(str1, str2):\n    '''Get count of words common in two input strings. Basic word matching'''\n    return sum(int(str2.find(word)>=0) for word in str1.split())","metadata":{"collapsed":true,"_cell_guid":"bdd5a04e-5cb4-457c-ae5e-0bebd5b0a599","_uuid":"a031b14c937c1b3df37677cef7168c16c27bb7ed"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### concatenate both train and test data set.\ndf_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n\n### add all product info to the above dataframe\ndf_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n\n### applying str_stemmer to stem and lamitize the values\ndf_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\ndf_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\ndf_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n### calculating the length of search term\ndf_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n### combine search_term , product_title and product_description\ndf_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n### get common words in search_term and product_title\ndf_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n### get count of common words in search_term and product_description\ndf_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n### display first rows in dataframe\ndf_all.head()","metadata":{"scrolled":false,"_cell_guid":"15638f28-fd88-49fc-8ce6-352546fb8153","_uuid":"9208f7b185ba946406b1a7bd41de68415feebb55"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### taking a sub-set of dataframe to train from above df_all\ndf_train = df_all.iloc[:num_train]\n### seperate test data from df_all\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\n\n### test and train data\ny_train = df_train['relevance'].values\nX_train = df_train[[w for w in list(df_train.columns) if w not in ['search_term','product_title','product_description','product_info' , 'id','relevance']]].values\nX_test = df_test[[w for w in list(df_test.columns) if w not in ['search_term','product_title','product_description','product_info' ,'id','relevance']]].values\n\n### training a random forest regressor\nrf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\nclf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n### to test model performance \ny_true_pred = clf.predict(X_train)\n\nprint ('RMSE using Random Forest Regressor consedering basic features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))\n#pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)","metadata":{"_cell_guid":"7eb45988-71d5-49ac-ba43-ce305990aecd","_uuid":"e48120a5c0ca9ccd78007179d900738c98a420c2"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"from fuzzywuzzy import fuzz\ndef fuzzy_partial_ratio(string_1 , string_2):\n    return fuzz.partial_ratio(string_1, string_2)\n\nfuzzy_partial_ratio('delta vero 1-handl shower onli faucet trim kit...' , 'shower onli faucet')","metadata":{"_cell_guid":"72520a23-0735-4fe6-8538-d5976f6ea00e","_uuid":"172d59275438125800148ad6fecdafed05be928e"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"def fuzzy_token_sort_ratio(string_1,string_2):\n    return fuzz.token_sort_ratio(string_1,string_2)\nfuzzy_token_sort_ratio('delta vero 1-handl shower onli faucet trim kit...' , 'shower onli faucet')","metadata":{"_cell_guid":"3260bca3-dcaf-4d32-ab97-8af8356031e3","_uuid":"c68a20b667c6a08950c8e3f3447cddf7c2d9cee1"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### adding new features\n### 1. Fuzzy partial ratio on 'search_term' and 'product_title' \n### 2. Fuzzy partial ratio on  'search_term' and 'product_description'\ndf_all['fuzzy_ratio_in_title'] = df_all['product_info'].map(lambda x:fuzzy_partial_ratio(x.split('\\t')[0],x.split('\\t')[1]))\ndf_all['fuzzy_ratio_in_description'] = df_all['product_info'].map(lambda x:fuzzy_partial_ratio(x.split('\\t')[0],x.split('\\t')[2]))\n\ndf_all.head()","metadata":{"_cell_guid":"d9296996-7ba4-4e7d-99b3-ca886657b525","_uuid":"8cf05e0cc1d390fc2bf6575cd4193b29994ac0a5"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### adding new features\n### 1. Fuzzy token_sort_ratio on 'search_term' and 'product_title' \n### 2. Fuzzy token_sort_ratio on  'search_term' and 'product_description'\n\ndf_all['fuzzy_token_sort_ratio_in_title'] = df_all['product_info'].map(lambda x:fuzzy_token_sort_ratio(x.split('\\t')[0],x.split('\\t')[1]))\ndf_all['fuzzy_token_sort_ratio_in_description'] = df_all['product_info'].map(lambda x:fuzzy_token_sort_ratio(x.split('\\t')[0],x.split('\\t')[2]))\n\ndf_all.head()","metadata":{"_cell_guid":"4d5789b1-d1db-4dc3-94ac-4dff96a97537","_uuid":"427f936736b712d0d7fbc869d2a07a6935548991"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"columns_to_train = ['len_of_query' , 'word_in_title' , 'word_in_description' , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description' , 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description']\n### taking a sub-set of dataframe to train from above df_all\ndf_train = df_all.iloc[:num_train]\n### seperate test data from df_all\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\n\n### test and train data\n### training using all previous and fuzzy features\ny_train = df_train['relevance'].values\nX_train = df_train[columns_to_train].values\nX_test = df_test[columns_to_train].values\n\n### training a random forest regressor\nrf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\nclf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n### to test model performance \ny_true_pred = clf.predict(X_train)\n\nprint ('RMSE using Random Forest Regressor consedering basic and fuzzy features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))","metadata":{"_cell_guid":"8b68ab43-52e0-4f66-bd99-b52efcf03068","_uuid":"3d577151fec857026e454a7a788523e9eac160cd"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"columns_to_train = ['len_of_query'  , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description', 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description']\n### taking a sub-set of dataframe to train from above df_all\ndf_train = df_all.iloc[:num_train]\n### seperate test data from df_all\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\n\n### test and train data\n### training using fuzzy features\ny_train = df_train['relevance'].values\nX_train = df_train[columns_to_train].values\nX_test = df_test[columns_to_train].values\n\n### training a random forest regressor\nrf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\nclf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n### to test model performance \ny_true_pred = clf.predict(X_train)\n\nprint ('RMSE using Random Forest Regressor consedering only fuzzy features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))","metadata":{"_cell_guid":"eb63d5aa-72d3-4446-89b8-bc831795c591","_uuid":"385fa6e673bbe7b0b79a1820c2112542e3e6c625"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"import xgboost as xgb\nfrom sklearn.datasets import dump_svmlight_file\nfrom xgboost import plot_importance\n\ncolumns_to_train = ['len_of_query' , 'word_in_title' , 'word_in_description' , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description' , 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description']\n### taking a sub-set of dataframe to train from above df_all\ndf_train = df_all.iloc[:num_train]\n### seperate test data from df_all\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\n\n### test and train data\n### training using all previous and fuzzy features\ny_train = df_train['relevance'].values\nX_train = df_train[columns_to_train]\nX_test = df_test[columns_to_train]","metadata":{"collapsed":true,"_cell_guid":"4f3c587d-dcfa-4350-a8f4-e970fb1548e7","_uuid":"d8b6eb7cf6834343ce655cf6aff3478d946b6dbb"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"bst = xgb.XGBRegressor(max_depth = 6,\n                    n_estimators = 100).fit(X_train , y_train)","metadata":{"collapsed":true,"_cell_guid":"392b88ca-bc74-4f76-8142-c9a490ac52fa","_uuid":"ebce51b8ee7365b221527bc8b3ffb12b4e0a6e59"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### to test model performance \ny_true_pred = bst.predict(X_train)\nprint ('RMSE using XGBoost Regressor consedering basic and fuzzy features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))\n","metadata":{"_cell_guid":"5c1ff775-af9c-4871-9631-860008bbe2b9","_uuid":"fe1d08d911ba6ed00111c998fc375e0bfdf4a29f"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"## plotting the feature importance\nplot_importance(bst)\n\n","metadata":{"scrolled":true,"_cell_guid":"b85d2cd4-901f-48b4-b37f-b55c29fe7099","_uuid":"4221b14d6c69a473d77070321fb5f08369b28e74"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"","metadata":{"collapsed":true}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### adding new features\n### 1. Fuzzy token_sort_ratio on 'search_term' and 'product_title' \n### 2. Fuzzy token_sort_ratio on  'search_term' and 'product_description'\n\ndf_all['fuzzy_ratio_in_title_description'] = df_all['product_info'].map(lambda x:fuzzy_partial_ratio(x.split('\\t')[0],\" \".join(x.split('\\t')[1:])))\ndf_all['fuzzy_token_sort_ratio_in_title_description'] = df_all['product_info'].map(lambda x:fuzzy_token_sort_ratio(x.split('\\t')[0],\" \".join(x.split('\\t')[1:])))\n\ndf_all.head()","metadata":{}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"import xgboost as xgb\nfrom sklearn.datasets import dump_svmlight_file\nfrom xgboost import plot_importance\n\ncolumns_to_train = ['len_of_query' , 'word_in_title' , 'word_in_description' , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description' , 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description' , 'fuzzy_ratio_in_title_description' , 'fuzzy_token_sort_ratio_in_title_description']\n### taking a sub-set of dataframe to train from above df_all\ndf_train = df_all.iloc[:num_train]\n### seperate test data from df_all\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\n\n### test and train data\n### training using all previous and fuzzy features\ny_train = df_train['relevance'].values\nX_train = df_train[columns_to_train]\nX_test = df_test[columns_to_train]\n\nbst = xgb.XGBRegressor(max_depth = 6,\n                    n_estimators = 50).fit(X_train , y_train)","metadata":{"collapsed":true}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### to test model performance \ny_true_pred = bst.predict(X_train)\nprint ('RMSE using XGBoost Regressor consedering basic and fuzzy features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))","metadata":{}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"","metadata":{"collapsed":true}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.cross_validation import train_test_split\n\n\nsvr = SVR(kernel='linear')\nlm = LinearRegression()\n#svr.fit(X_train,y_train)\nlm.fit(X_train, y_train)\n\n### to test model performance \ny_true_pred = lm.predict(X_train)\nprint ('RMSE using linear Regressor consedering basic and fuzzy features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))\n### to test model performance \ny_true_pred = svr.predict(X_train)\nprint ('RMSE using SVM Regressor consedering basic and fuzzy features : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))\n\n","metadata":{}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"y_pred = bst.predict(X_test)\npd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)","metadata":{"collapsed":true,"_cell_guid":"50c66c8f-f4f3-4823-8f39-0e187ca8d109","_uuid":"d94debe2bbfe54dcca3311974c0cace674b43a47"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### searching for best parameters\n\nfrom sklearn.model_selection import KFold, train_test_split, GridSearchCV\nxgb_model = xgb.XGBRegressor()\nclf = GridSearchCV(xgb_model,\n                   {'max_depth': [2,4,6,8],\n                    'n_estimators': [20,50,100,200]}, verbose=1)\nclf.fit(X_train , y_train)\nprint(clf.best_score_)\nprint(clf.best_params_)","metadata":{"scrolled":false,"_cell_guid":"1341db72-8ffd-45c5-8c30-75fb5b50ed6f","_uuid":"fdb21ad82f5661f4d7ee009a7c54936b95cacd0c"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"### to test model performance \ny_true_pred = clf.predict(X_train)\nprint ('RMSE for all features using XGB : ' , np.sqrt(((y_train - y_true_pred) ** 2).mean()))","metadata":{"collapsed":true,"_cell_guid":"be1dfb86-ba20-4cde-b34f-22834aeb4ff3","_uuid":"552901aa868347b820123dd352d84483a8834399"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"#Choose all predictors except target & IDcols\npredictors = ['len_of_query' , 'word_in_title' , 'word_in_description' , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description' , 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description']\nxgb1 = xgb.XGBRegressor(\n learning_rate =0.01,\n n_estimators=100,\n max_depth=4,\n min_child_weight=2,\n gamma=0.3,\n subsample=0.8,\n colsample_bytree=0.8,\n nthread=4,\n scale_pos_weight=1,\n seed=27)\n\nxgb1.fit(X_train , y_train)","metadata":{"collapsed":true,"_cell_guid":"bbae36d2-4624-4042-9693-1476ceb4cbc4","_uuid":"8ecf7ec4f9970a45b7c8eb55a0635efefe600d77"}}],"metadata":{"language_info":{"nbconvert_exporter":"python","name":"python","version":"3.6.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}