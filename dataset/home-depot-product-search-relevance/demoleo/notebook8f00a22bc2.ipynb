{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"78f424ef-353a-04e5-5aad-f2d9e735c0ca","_active":false},"outputs":[],"source":"# import sys  \n# reload(sys)  \n# sys.setdefaultencoding('utf8')  ","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"59910803-6392-ca98-8313-31078e87ed7b","_active":true},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom nltk.stem.snowball import SnowballStemmer","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"a41ab303-1f7d-4c8a-d05a-cfa1047485ba","_active":false},"outputs":[],"source":"stemmer = SnowballStemmer('english')","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"83ae15a3-aa7c-da07-8336-5cde2ee1c135","_active":false},"outputs":[],"source":"df_train = pd.read_csv('train.csv', encoding=\"ISO-8859-1\")\ndf_test = pd.read_csv('test.csv', encoding=\"ISO-8859-1\")\ndf_pro_desc = pd.read_csv('product_descriptions.csv', encoding=\"ISO-8859-1\")\ndf_attr = pd.read_csv('attributes.csv')","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"6638789a-8ba1-fa6d-5d37-dd3ec4a6cc0a","_active":false},"source":"### 1.Exploration","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"3cf9978b-65db-19b6-36c2-e821a892830a","_active":false},"outputs":[],"source":"num_train = df_train.shape[0]\nnum_train","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"9f3d75b2-adaf-b5e1-69d6-9f67acd2a987","_active":false},"outputs":[],"source":"num_test = df_test.shape[0]\nnum_test","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"a0c3ea17-9952-a5bf-c0cb-4b4fe9691bf9","_active":false},"outputs":[],"source":"num_pro_desc = df_pro_desc.shape[0]\nnum_pro_desc","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"5123e07a-dd19-ba76-68d9-33643867f0e2","_active":false},"outputs":[],"source":"num_attr = df_attr.shape[0]\nnum_attr","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"5cf4e5dd-b124-f384-434b-9b636851c6ad","_active":false},"outputs":[],"source":"def str_stemmer(s):\n    return ' '.join([stemmer.stem(word) for word in s.lower().split()])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"0cfece47-a87e-0bbf-cc4a-01fb37f49566","_active":false},"outputs":[],"source":"# if there are str1 in str2\ndef str_common_word(str1,str2):\n    return sum(int(str2.find(word)>=0) for word in str1.split())   # int(True)=1   ","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"b6a1ca03-2a3e-d113-8a63-636d9ec33298","_active":false},"outputs":[],"source":"df_all = pd.concat([df_train, df_test], axis = 0, ignore_index = True)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"77020374-9047-4b26-d0aa-871f57cf1efe","_active":false},"outputs":[],"source":"#merge product description\ndf_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"832d050d-5b87-3e28-06ae-f4e71cd6c773","_active":false},"outputs":[],"source":"df_all.head()","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"9cae46ee-d7d1-10c1-ab57-09f5229def22","_active":false},"outputs":[],"source":"# clean: remove affixes\ndf_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\ndf_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\ndf_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"638f5792-e1d3-b517-56a2-c0eeed81e038","_active":false},"outputs":[],"source":"df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"a396e396-66a8-f6ae-daa2-efe0530ad863","_active":false},"outputs":[],"source":"df_all['commons_in_title'] = df_all.apply(lambda x:str_common_word(x['search_term'],x['product_title']), axis=1)\ndf_all['commons_in_desc'] = df_all.apply(lambda x:str_common_word(x['search_term'],x['product_description']), axis=1)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"scrolled":false,"_cell_guid":"5e1f9f32-8fb1-dee9-b175-234a815577fd","_active":false},"outputs":[],"source":"# Levenshtein\nimport Levenshtein\ndf_all['dist_in_title'] = df_all.apply(lambda x:Levenshtein.ratio(x['search_term'],x['product_title']), axis=1)\ndf_all['dist_in_desc'] = df_all.apply(lambda x:Levenshtein.ratio(x['search_term'],x['product_description']), axis=1)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"e10287b3-4301-222a-0458-4f9a15f39e88","_active":false},"outputs":[],"source":"# TF-IDF   \ndf_all['all_texts']=df_all['product_title'] + ' . ' + df_all['product_description']","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"667b8504-a3e9-c53c-479a-6fa44238fe85","_active":false},"outputs":[],"source":"from gensim.utils import tokenize\nfrom gensim.corpora.dictionary import Dictionary\ndictionary = Dictionary(list(tokenize(x, errors='ignore')) for x in df_all['all_texts'].values)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"a2b3a219-14ae-e3e3-cb34-aee72b7f2da3","_active":false},"outputs":[],"source":"len(dictionary)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"eda2c594-60b7-c492-561b-8cd7059a479e","_active":false},"outputs":[],"source":"class MyCorpus(object):\n    def __iter__(self):\n        for x in df_all['all_texts'].values:\n            yield dictionary.doc2bow(list(tokenize(x, errors='ignore')))\ncorpus = MyCorpus()","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"b950ea72-36b3-2ea7-2190-287f10552ddf","_active":false},"outputs":[],"source":"from gensim.models.tfidfmodel import TfidfModel\ntfidf = TfidfModel(corpus)\nfrom gensim.similarities import MatrixSimilarity\n\n# 先把刚刚那句话包装成一个方法\ndef to_tfidf(text):\n    res = tfidf[dictionary.doc2bow(list(tokenize(text, errors='ignore')))]\n    return res\n\n# 然后，我们创造一个cosine similarity的比较方法\ndef cos_sim(text1, text2):\n    tfidf1 = to_tfidf(text1)\n    tfidf2 = to_tfidf(text2)\n    index = MatrixSimilarity([tfidf1],num_features=len(dictionary))\n    sim = index[tfidf2]\n    # 本来sim输出是一个array，我们不需要一个array来表示，\n    # 所以我们直接cast成一个float\n    return float(sim[0])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"05b350f1-bab1-a982-e3dd-eced99b153ed","_active":false},"outputs":[],"source":"#TF-IDF similarity\ndf_all['tfidf_cos_sim_in_title'] = df_all.apply(lambda x: cos_sim(x['search_term'], x['product_title']), axis=1)\ndf_all['tfidf_cos_sim_in_desc'] = df_all.apply(lambda x: cos_sim(x['search_term'], x['product_description']), axis=1)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"42910830-c19e-ada5-ced1-313f72969caa","_active":false},"outputs":[],"source":"#word2vec\nimport nltk\n# nltk也是自带一个强大的句子分割器。\ntokenizer = nltk.data.load('tokenizers/punkt/english.pickle')","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"c1a4a81c-8781-d985-b0b1-a5f4be1cb6e4","_active":false},"outputs":[],"source":"sentences = [tokenizer.tokenize(x) for x in df_all['all_texts'].values]\nsentences = [y for x in sentences for y in x]","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"f1842496-99e7-87b2-e323-1efcdafded68","_active":false},"outputs":[],"source":"from nltk.tokenize import word_tokenize\nw2v_corpus = [word_tokenize(x) for x in sentences]","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"6de86462-c8ad-dfeb-8bbe-592709a8c504","_active":false},"outputs":[],"source":"from gensim.models.word2vec import Word2Vec\nmodel = Word2Vec(w2v_corpus, size=128, window=5, min_count=5, workers=4)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"2c270aad-8519-676c-a1b0-07dcd6e72e44","_active":false},"outputs":[],"source":"# 先拿到全部的vocabulary\nvocab = model.vocab\n\n# 得到任意text的vector\ndef get_vector(text):\n    # 建立一个全是0的array\n    res =np.zeros([128])\n    count = 0\n    for word in word_tokenize(text):\n        if word in vocab:\n            res += model[word]\n            count += 1\n    return res/count  ","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"0080a349-938b-83c3-2ded-f5a2b3adc583","_active":false},"outputs":[],"source":"from scipy import spatial\n# 这里，我们再玩儿个新的方法，用scipy的spatial\ndef w2v_cos_sim(text1, text2):\n    try:\n        w2v1 = get_vector(text1)\n        w2v2 = get_vector(text2)\n        sim = 1 - spatial.distance.cosine(w2v1, w2v2)\n        return float(sim)\n    except:\n        return float(0)\n# 这里加个try exception，以防我们得到的vector是个[0,0,0,...]","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"17f46510-7239-0743-aa94-4b0be41ecf3b","_active":false},"outputs":[],"source":"# word2vec similarity\ndf_all['w2v_cos_sim_in_title'] = df_all.apply(lambda x: w2v_cos_sim(x['search_term'], x['product_title']), axis=1)\ndf_all['w2v_cos_sim_in_desc'] = df_all.apply(lambda x: w2v_cos_sim(x['search_term'], x['product_description']), axis=1)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"e861b868-054f-ed0d-8553-305d1eb36daa","_active":false},"outputs":[],"source":"#remove the text, leave number only\ndf = df_all.drop(['search_term','product_title','product_description','all_texts'], axis=1)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"8adfbbd0-6432-285a-fa1a-72d182d319b7","_active":false},"outputs":[],"source":"df_train = df.iloc[:num_train]\ndf_test = df.iloc[num_train:]\nid_test = df_test['id']","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"9772fbd0-ae0f-ffdb-9c6f-01aae84b24ee","_active":false},"outputs":[],"source":"y_train = df_train['relevance'].values\nX_train = df_train.drop(['id','relevance'],axis=1).values\nX_test = df_test.drop(['id','relevance'],axis=1).values","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"cdd1312c-b6ff-a64d-fa46-bea273e3efc1","_active":false},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cross_validation import cross_val_score\n\nparams_rf = range(1,11)\ntest_score_rf = []\nfor param in params_rf:\n    rfr = RandomForestRegressor(n_estimators=30, max_depth=param)\n    test_score = np.sqrt(-cross_val_score(rfr, X_train, y_train, cv=5, scoring='mean_squared_error'))\n    test_score_rf.append(np.mean(test_score))","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"2fa22a0c-bec7-511b-7f4c-1ea7abec001c","_active":false},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.plot(params_rf, test_score_rf)\nplt.title(\"Random Forest-Number of trees\");","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"bf652b5c-8c60-7959-0b59-4340e2c45a62","_active":false},"outputs":[],"source":"test_score_rf","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"160ffae0-2e70-b97b-1b75-ec8ef47ee678","_active":false},"outputs":[],"source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.cross_validation import cross_val_score\n\nparams_gbrt = range(1,11)\ntest_scores_gbrt = []\nfor param in params_gbrt:\n    gbr = GradientBoostingRegressor(n_estimators=10, max_depth=param)\n    test_score = np.sqrt(-cross_val_score(gbr, X_train, y_train, cv=5, scoring='mean_squared_error'))\n    test_scores_gbrt.append(np.mean(test_score))","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"53e081bc-0411-fc99-f1bc-142d8b7b1c6a","_active":false},"outputs":[],"source":"plt.plot(params, test_scores)\nplt.title(\"GBRT-number of stages\");","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"8e62f539-36ee-2541-31ee-4a6ce12b469e","_active":false},"outputs":[],"source":"test_scores_gbrt","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"eea4522e-60de-0b59-6550-704e98e207d2","_active":false},"outputs":[],"source":"rf = RandomForestRegressor(n_estimators=30, max_depth=9)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"6e295fb7-2f73-13fd-d8dd-0f11db8d926f","_active":false},"outputs":[],"source":"pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"_cell_guid":"54a9b878-a713-ff16-8a0a-99947d9dbf24","_active":false},"outputs":[],"source":null,"execution_state":"idle"}]}