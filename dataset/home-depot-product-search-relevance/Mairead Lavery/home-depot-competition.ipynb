{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T19:16:29.489812Z","iopub.execute_input":"2021-06-29T19:16:29.490186Z","iopub.status.idle":"2021-06-29T19:16:29.4947Z","shell.execute_reply.started":"2021-06-29T19:16:29.490155Z","shell.execute_reply":"2021-06-29T19:16:29.493877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import the data\natt=pd.read_csv('../input/home-depot-product-search-relevance/attributes.csv.zip')\ndesc=pd.read_csv('../input/home-depot-product-search-relevance/product_descriptions.csv.zip')\ntrain=pd.read_csv('../input/home-depot-product-search-relevance/train.csv.zip', encoding='latin-1')\ntest=pd.read_csv('../input/home-depot-product-search-relevance/test.csv.zip',encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T19:16:15.552259Z","iopub.execute_input":"2021-06-29T19:16:15.552678Z","iopub.status.idle":"2021-06-29T19:16:15.636808Z","shell.execute_reply.started":"2021-06-29T19:16:15.552585Z","shell.execute_reply":"2021-06-29T19:16:15.634969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clean attribute file by casting id and concatenating the name and value columns\natt = att.fillna(0)\natt['product_uid'] = att['product_uid'].astype(np.int64)\natt['string']=att['name'].map(str)+' '+att['value'].map(str)\natt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pivot attribute table to have one long string of attributes for each product_id\natt1=pd.pivot_table(att,index=['product_uid'],values=['string'],aggfunc=lambda x: ' '.join(x))\natt1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge datasets to create the raw training set\ntrain=pd.merge(train, desc, how='left', on='product_uid')\ntrain=pd.merge(train, att1, how='left', on='product_uid')\ntrain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature engineer\n#find overlap of search term words in description and attributes\ntrain['string'] = train['string'].replace(np.nan, '', regex=True)\ntrain['term_desc'] = [len(set(a.split()) & set(b.split())) for a, b in zip(train.search_term, train.product_description)]\ntrain['term_att'] = [len(set(a.split()) & set(b.split())) for a, b in zip(train.search_term, train.string)]\ntrain['term_prod'] = [len(set(a.split()) & set(b.split())) for a, b in zip(train.search_term, train.product_title)]\n#calculate ratios here\ntrain['sum']=train['term_desc']+train['term_att']\ntrain['q_length']=[len(a.split()) for a in train['search_term']]\ntrain['ratio1']=train['term_prod']/train['q_length']\ntrain['ratio2']=train['sum']/train['q_length']\ntrain.sort_values('relevance')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replicate process for test set\ntest=pd.merge(test, desc, how='left', on='product_uid')\ntest=pd.merge(test, att1, how='left', on='product_uid')\n\ntest['string'] = test['string'].replace(np.nan, '', regex=True)\ntest['term_desc'] = [len(set(a.split()) & set(b.split())) for a, b in zip(test.search_term, test.product_description)]\ntest['term_att'] = [len(set(a.split()) & set(b.split())) for a, b in zip(test.search_term, test.string)]\ntest['term_prod'] = [len(set(a.split()) & set(b.split())) for a, b in zip(test.search_term, test.product_title)]\ntest['sum']=test['term_desc']+test['term_att']\ntest['q_length']=[len(a.split()) for a in test['search_term']]\ntest['ratio1']=test['term_prod']/test['q_length']\ntest['ratio2']=test['sum']/test['q_length']\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trim dataframes to just the usable features\nready=train[['relevance','term_desc','term_att','sum','term_prod','q_length','ratio1','ratio2']]\ntest1=test[['id','term_desc','term_att','sum','term_prod','q_length','ratio1','ratio2']]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test/train split and build Ridge regression model on training set\nX = ready.loc[:, ready.columns != 'relevance']\ny = ready.loc[:, ready.columns == 'relevance']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\nrg= Ridge(alpha=.1)\nrg.fit(X_train, y_train.values.ravel())\ny_pred = rg.predict(X_test)\nrg_mse = mean_squared_error(y_pred, y_test)\nrg_rmse = np.sqrt(rg_mse)\nprint('Ridge RMSE: %.4f' % rg_rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#generate predictions on test set\nXt = test1.loc[:, test1.columns != 'id']\ny_pred = rg.predict(Xt)\ny_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save and export results\nresults=pd.DataFrame()\nresults['id']=test1['id']\nresults['relevance']=y_pred\nresults.to_csv(\"home_depot.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}