{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36d0fc1f-e99a-43f6-99a0-48ff37866868"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"72b98f77-920a-42e0-b6bd-c615845183b0"},"outputs":[],"source":"# load files\ntrain_data = pd.read_csv(\"../input/train.csv\", encoding=\"ISO-8859-1\")\ntest_data = pd.read_csv(\"../input/test.csv\", encoding=\"ISO-8859-1\")\natt_data = pd.read_csv(\"../input/attributes.csv\")\ndescriptions = pd.read_csv(\"../input/product_descriptions.csv\")\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28aff103-6b18-4bea-bc33-5b508685cc87"},"outputs":[],"source":"from nltk.stem.snowball import SnowballStemmer\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nstemmer = SnowballStemmer('english')\ndef stm(s):\n    return ' '.join([stemmer.stem(word)  for word in str(s).split() if word not in stop])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60017ab9-5be4-4fb1-b2c1-4c2e4e9eda9e"},"outputs":[],"source":"train_data['search_term']=train_data['search_term'].map(lambda x: stm(x))\ndescriptions['product_description']=descriptions['product_description'].map(lambda x: stm(x))\nbrands=att_data[['product_uid','value']][att_data.name=='MFG Brand Name']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c765157-15b8-4d7a-a703-9fe531d67299"},"outputs":[],"source":"att_data['value']=att_data['value'].map(lambda x: stm(x))\nser_att=pd.Series()\nfor p,v in zip(att_data['product_uid'],att_data['value']):\n\ts=' '.join([str(ser_att.get(p,'')),v])\n\tser_att[p]=s"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cae3478d-b5db-4ce2-aa66-51a19f79247d"},"outputs":[],"source":"def search_in_str(search,s):\n    return sum([s.count(term) for term in search.split()])\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cf7a211-bd37-47f1-ba59-fcd6d6818ac0"},"outputs":[],"source":"train_data=train_data.merge(brands,how='left',on='product_uid')\ntrain_data.columns=['id', 'product_uid', 'product_title', 'search_term', 'relevance','brand']\ntrain_data=train_data.merge(descriptions,how='left',on='product_uid')\ntrain_data['search_in_title']=[search_in_str(x,y) for (x,y) in zip(train_data['search_term'],train_data['product_title'])]\ntrain_data['search_in_brand']=[search_in_str(str(x),str(y)) for (x,y) in zip(train_data['search_term'],train_data['brand'])]\ntrain_data['search_in_desc']=[search_in_str(str(x),str(y)) for (x,y) in zip(train_data['search_term'],train_data['product_description'])]\ntrain_data['attr']=train_data['product_uid'].map(lambda x: ser_att.get(x,''))\ntrain_data['search_in_att']=[search_in_str(str(x),str(y)) for (x,y) in zip(train_data['search_term'],train_data['attr'])]\n#del train_data['attr']\n#del train_data['product_title']\n#del train_data['brand']\n#del train_data['product_description']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05e50e61-8273-4c70-b685-0397ebd3e9b9"},"outputs":[],"source":"test_data = pd.read_csv(\"../input/test.csv\", encoding=\"ISO-8859-1\")\ntest_data['search_term']=test_data['search_term'].map(lambda x: stm(x))\ntest_data=test_data.merge(brands,how='left',on='product_uid')\ntest_data.columns=['id', 'product_uid', 'product_title', 'search_term','brand']\ntest_data=test_data.merge(descriptions,how='left',on='product_uid')\ntest_data['search_in_title']=[search_in_str(x,y) for (x,y) in zip(test_data['search_term'],test_data['product_title'])]\ntest_data['search_in_brand']=[search_in_str(str(x),str(y)) for (x,y) in zip(test_data['search_term'],test_data['brand'])]\ntest_data['search_in_desc']=[search_in_str(str(x),str(y)) for (x,y) in zip(test_data['search_term'],test_data['product_description'])]\ntest_data['attr']=test_data['product_uid'].map(lambda x: ser_att.get(x,''))\ntest_data['search_in_att']=[search_in_str(str(x),str(y)) for (x,y) in zip(test_data['search_term'],test_data['attr'])]\n#del test_data['product_title']\n#del test_data['brand']\n#del test_data['product_description']\n#del test_data['attr']\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15f8615f-2209-4e0a-9e61-31dd6b46f052"},"outputs":[],"source":"predictors=['search_in_title','search_in_brand','search_in_desc','search_in_att']\ny_train = train_data['relevance'].values\nX_train = train_data[predictors].values\nX_test = test_data[predictors].values\nid_test = test_data['id']\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\npd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99b69f39-2b5a-472f-8c1c-fb71a9a12298"},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn import cross_validation\nimport math\nrf = RandomForestRegressor(n_estimators=15, max_depth=3, random_state=0)\n\npredictors=['search_in_title','search_in_brand','search_in_desc','search_in_att']\nscores=cross_validation.cross_val_score(clf,train_data[predictors],train_data['relevance'],cv=5,scoring='mean_squared_error')\nprint(np.mean([math.sqrt(-x) for x in scores]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a3c63d5-79fc-4baf-b6c8-b94e4855eeb0"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}