{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import time\nstart_time = time.time()\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n#from sklearn import pipeline, model_selection\nfrom sklearn import pipeline, grid_search\n#from sklearn.feature_extraction import DictVectorizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import TruncatedSVD\n#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import mean_squared_error, make_scorer\n#from nltk.metrics import edit_distance\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\n#from nltk.stem.snowball import SnowballStemmer #0.003 improvement but takes twice as long as PorterStemmer\n#stemmer = SnowballStemmer('english')\nimport re\n#import enchant\nimport random\nrandom.seed(2016)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\ndf_train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")\ndf_test = pd.read_csv('../input/test.csv', encoding=\"ISO-8859-1\")\ndf_pro_desc = pd.read_csv('../input/product_descriptions.csv')\ndf_attr = pd.read_csv('../input/attributes.csv')\ndf_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\nnum_train = df_train.shape[0]\ndf_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\ndf_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\ndf_all = pd.merge(df_all, df_brand, how='left', on='product_uid')\n\ndef str_stem(s): \n    if isinstance(s, str):\n        s = s.lower()\n        s = s.replace(\"'\",\"in.\") \n        s = s.replace(\"inches\",\"in.\") \n        s = s.replace(\"inch\",\"in.\")\n        s = s.replace(\" in \",\"in. \") \n        s = s.replace(\" in.\",\"in.\") \n\n        s = s.replace(\"''\",\"ft.\") \n        s = s.replace(\" feet \",\"ft. \") \n        s = s.replace(\"feet\",\"ft.\") \n        s = s.replace(\"foot\",\"ft.\") \n        s = s.replace(\" ft \",\"ft. \") \n        s = s.replace(\" ft.\",\"ft.\") \n    \n        s = s.replace(\" pounds \",\"lb. \")\n        s = s.replace(\" pound \",\"lb. \") \n        s = s.replace(\"pound\",\"lb.\") \n        s = s.replace(\" lb \",\"lb. \") \n        s = s.replace(\" lb.\",\"lb.\") \n        s = s.replace(\" lbs \",\"lb. \") \n        s = s.replace(\"lbs.\",\"lb.\") \n\n        s = s.replace(\" x \",\" xby \")\n        s = s.replace(\"*\",\" xby \")\n        s = s.replace(\" by \",\" xby\")\n        s = s.replace(\"x0\",\" xby 0\")\n        s = s.replace(\"x1\",\" xby 1\")\n        s = s.replace(\"x2\",\" xby 2\")\n        s = s.replace(\"x3\",\" xby 3\")\n        s = s.replace(\"x4\",\" xby 4\")\n        s = s.replace(\"x5\",\" xby 5\")\n        s = s.replace(\"x6\",\" xby 6\")\n        s = s.replace(\"x7\",\" xby 7\")\n        s = s.replace(\"x8\",\" xby 8\")\n        s = s.replace(\"x9\",\" xby 9\")\n        s = s.replace(\"0x\",\"0 xby \")\n        s = s.replace(\"1x\",\"1 xby \")\n        s = s.replace(\"2x\",\"2 xby \")\n        s = s.replace(\"3x\",\"3 xby \")\n        s = s.replace(\"4x\",\"4 xby \")\n        s = s.replace(\"5x\",\"5 xby \")\n        s = s.replace(\"6x\",\"6 xby \")\n        s = s.replace(\"7x\",\"7 xby \")\n        s = s.replace(\"8x\",\"8 xby \")\n        s = s.replace(\"9x\",\"9 xby \")\n    \n        s = s.replace(\" sq ft\",\"sq.ft. \") \n        s = s.replace(\"sq ft\",\"sq.ft. \")\n        s = s.replace(\"sqft\",\"sq.ft. \")\n        s = s.replace(\" sqft \",\"sq.ft. \") \n        s = s.replace(\"sq. ft\",\"sq.ft. \") \n        s = s.replace(\"sq ft.\",\"sq.ft. \") \n        s = s.replace(\"sq feet\",\"sq.ft. \") \n        s = s.replace(\"square feet\",\"sq.ft. \") \n    \n        s = s.replace(\" gallons \",\"gal. \") \n        s = s.replace(\" gallon \",\"gal. \") \n        s = s.replace(\"gallons\",\"gal.\") \n        s = s.replace(\"gallon\",\"gal.\") \n        s = s.replace(\" gal \",\"gal. \") \n        s = s.replace(\" gal\",\"gal.\") \n\n        s = s.replace(\"ounces\",\"oz.\")\n        s = s.replace(\"ounce\",\"oz.\")\n        s = s.replace(\" oz.\",\"oz. \")\n        s = s.replace(\" oz \",\"oz. \")\n\n        s = s.replace(\"centimeters\",\"cm.\")    \n        s = s.replace(\" cm.\",\"cm.\")\n        s = s.replace(\" cm \",\"cm. \")\n        \n        s = s.replace(\"milimeters\",\"mm.\")\n        s = s.replace(\" mm.\",\"mm.\")\n        s = s.replace(\" mm \",\"mm. \")\n        \n        s = s.replace(\"Â°\",\"deg. \")\n        s = s.replace(\"degrees\",\"deg. \")\n        s = s.replace(\"degree\",\"deg. \")\n        \n        s = s.replace(\"volts\",\"volt. \")\n        s = s.replace(\"volt\",\"volt. \")\n\n        s = s.replace(\"watts\",\"watt. \")\n        s = s.replace(\"watt\",\"watt. \")\n\n        s = s.replace(\"ampere\",\"amp. \")\n        s = s.replace(\"amps\",\"amp. \")\n        s = s.replace(\" amp \",\"amp. \")\n        \n        s = s.replace(\"whirpool\",\"whirlpool\")\n        s = s.replace(\"whirlpoolga\", \"whirlpool\")\n        s = s.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n\n        s = s.replace(\"  \",\" \")\n        #s = (\" \").join([stemmer.stem(z) for z in s.lower().split(\" \")])\n        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n        return s.lower()\n    else:\n        return \"null\"\n\ndef str_common_word(str1, str2):\n    words, cnt = str1.split(), 0\n    for word in words:\n        if str2.find(word)>=0:\n            cnt+=1\n    return cnt\n\ndef str_whole_word(str1, str2, i_):\n    cnt = 0\n    while i_ < len(str2):\n        i_ = str2.find(str1, i_)\n        if i_ == -1:\n            return cnt\n        else:\n            cnt += 1\n            i_ += len(str1)\n    return cnt\n\ndef fmean_squared_error(ground_truth, predictions):\n    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n    return fmean_squared_error_\n\nRMSE  = make_scorer(fmean_squared_error, greater_is_better=False)\n\nclass cust_regression_vals(BaseEstimator, TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, hd_searches):\n        d_col_drops=['id','relevance','search_term','product_title','product_description','product_info','attr','brand']\n        hd_searches = hd_searches.drop(d_col_drops,axis=1).values\n        return hd_searches\n\nclass cust_txt_col(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n    def fit(self, x, y=None):\n        return self\n    def transform(self, data_dict):\n        return data_dict[self.key].apply(str)\n\ndef fmean_squared_error(ground_truth, predictions):\n    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n    return fmean_squared_error_\n\nRMSE  = make_scorer(fmean_squared_error, greater_is_better=False)\n\n#comment out the lines below use df_all.csv for further grid search testing\n#if adding features consider any drops on the 'cust_regression_vals' class\ndf_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x))\ndf_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\ndf_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\ndf_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))\ndf_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\ndf_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\ndf_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))\ndf_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\ndf_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\ndf_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']\ndf_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']\ndf_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']\ndf_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\ndf_all['ratio_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\ndf_brand = pd.unique(df_all.brand.ravel())\nd={}\ni = 1\nfor s in df_brand:\n    d[s]=i\n    i+=1\ndf_all['brand_feature'] = df_all['brand'].map(lambda x:d[x])\ndf_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x))\n#df_all.to_csv('df_all.csv')\n#df_all = pd.read_csv('df_all.csv', encoding=\"ISO-8859-1\", index_col=0)\ndf_train = df_all.iloc[:num_train]\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\ny_train = df_train['relevance'].values\nX_train =df_train[:]\nX_test = df_test[:]\ndf_all.to_csv('monkey-47-features.csv',index=False)\nprint(\"--- Features Set: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_all = pd.read_csv('monkey-47-features.csv')\nnum_train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\").shape[0]\n\ndf_train = df_all.iloc[:num_train]\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\ny_train = df_train['relevance'].values\nX_train =df_train[:]\nX_test = df_test[:]\n\n\nrfr = RandomForestRegressor(n_estimators = 190, n_jobs = -1, random_state = 2016, verbose = 1)\ntfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\ntsvd = TruncatedSVD(n_components=25, random_state = 2016)\nclf = pipeline.Pipeline([\n        ('union', FeatureUnion(\n                    transformer_list = [\n                        ('cst',  cust_regression_vals()),  \n                        ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n                        ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])),\n                        ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n                        ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))\n                        ],\n                    transformer_weights = {\n                        'cst': 1.0,\n                        'txt1': 0.5,\n                        'txt2': 0.25,\n                        'txt3': 0.0,\n                        'txt4': 0.5\n                        },\n                n_jobs = -1\n                )), \n        ('rfr', rfr)])\nparam_grid = {'rfr__max_features': [24], 'rfr__max_depth': [30]}\nmodel = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 2, verbose = 20, scoring=RMSE)\nmodel.fit(X_train, y_train)\n\nprint(\"Best parameters found by grid search:\")\nprint(model.best_params_)\nprint(\"Best CV score:\")\nprint(model.best_score_)\n\ny_pred = model.predict(X_test)\npd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)\nprint(\"--- Training & Testing: %s minutes ---\" % round(((time.time() - start_time)/60),2))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}