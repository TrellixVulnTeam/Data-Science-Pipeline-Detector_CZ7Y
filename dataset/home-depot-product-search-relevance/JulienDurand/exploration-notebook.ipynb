{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# load files\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\", encoding=\"ISO-8859-1\")\ntraining_data = pd.read_csv(\"../input/train.csv\", encoding=\"ISO-8859-1\")\ntesting_data = pd.read_csv(\"../input/test.csv\", encoding=\"ISO-8859-1\")\nattribute_data = pd.read_csv(\"../input/attributes.csv\")\ndescriptions = pd.read_csv(\"../input/product_descriptions.csv\")\n\n# explore\n#print('Training Data')\n#print(str(training_data.info()))\n#print(training_data[:10])\n#print(' ')\n\n#print('attribute_data Data')\n#print(str(attribute_data.info()))\n#print(attribute_data[:10])\n#print('unique')\n#attributes = attribute_data.sort(['name'])['name'].unique()\n#for attr in attributes:\n#    print(attr)\n#print(len(attributes))\n#print(' ')\n\n#print('descriptions Data')\n\n#print(str(descriptions.info()))\n#print(descriptions[:10])\n#print(' ')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor\nfrom nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer('english')\n\ndf_train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")\ndf_test = pd.read_csv('../input/test.csv', encoding=\"ISO-8859-1\")\n# df_attr = pd.read_csv('../input/attributes.csv')\ndf_pro_desc = pd.read_csv('../input/product_descriptions.csv')\n\nnum_train = df_train.shape[0]\n\ndef str_stemmer(s):\n\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n\ndef str_common_word(str1, str2):\n\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n\n\ndf_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n\ndf_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n\ndf_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\ndf_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\ndf_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n\ndf_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n\ndf_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n\ndf_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\ndf_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n\ndf_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n\ndf_train = df_all.iloc[:num_train]\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\n\ny_train = df_train['relevance'].values\nX_train = df_train.drop(['id','relevance'],axis=1).values\nX_test = df_test.drop(['id','relevance'],axis=1).values\n\nrf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\nclf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\npd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}