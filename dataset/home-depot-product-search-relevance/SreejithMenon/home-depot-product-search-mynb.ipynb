{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport seaborn as sns\nimport copy\n\nTOTAL_RECORDS = 10000\nPERCENT_TRAINING = 0.8\nTRAINING_RECORDS = int(TOTAL_RECORDS * PERCENT_TRAINING)","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true},"cell_type":"markdown","source":"## Read Input"},{"metadata":{"_uuid":"bfa4740e60d114dddadc3c9ec1c07c22fd2675ee","_cell_guid":"3ea0a7f8-ce41-4496-bd1d-18704c14e916","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")\ndf_test = pd.read_csv('../input/test.csv', encoding=\"ISO-8859-1\")\n\ndf_attr = pd.read_csv('../input/attributes.csv')\ndf_pro_desc = pd.read_csv('../input/product_descriptions.csv')\n\nprint(\"number of training samples : %i\" %len(df_train) )\nprint(\"number of testing samples : %i\" %len(df_test) )\n\n# Merge  training and testing\n### concatenate both train and test data set.\ndf_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n### add all product info to the above dataframe\ndf_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n\n\ndf_all = df_all.iloc[:TOTAL_RECORDS] # TO-DO: remove hardcodings\nprint(\"total number of samples : %i\" %len(df_all))","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"1732bd3b2daf704016d5ae48f02ea9ac0a606810","_cell_guid":"34c9b388-530e-4a11-bf87-aeed986396eb"},"cell_type":"markdown","source":"## Utility functions for stemming etc."},{"metadata":{"_uuid":"fda4675ea85ba38c3318642d9b15bdbabd46cd45","_cell_guid":"5e5e2498-9017-4876-ae6a-c9e3c997a232","collapsed":true,"trusted":true},"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer('english')\n\ndef str_stemmer(s):\n    ''' To stem and lamatize the sentences so that we can avoid the difference between computing , computed , computs'''\n    return \" \".join([stemmer.stem(word) for word in s.lower().split()])\n\ndef str_common_word(str1, str2):\n    '''Get count of words common in two input strings. Basic word matching'''\n    return sum(int(str2.find(word)>=0) for word in str1.split())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8596df7aa692696c79d4e2f617e7f44d511dfa05","_cell_guid":"87d73446-50ee-4953-82df-3b3faffef3aa"},"cell_type":"markdown","source":"## Feature engineering - set 1"},{"metadata":{"_uuid":"22867817f7a8b56526caab88d3bffb4eb42df4fd","_cell_guid":"5dbeb31e-35ad-4202-ab5a-c88e81e0ba84","trusted":true,"collapsed":true},"cell_type":"code","source":"def runFeatureEngineeringSet1(df_all):    \n    df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n    df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n    df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n\n    # calculating the length of search term\n    df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n\n    # combine search_term , product_title and product_description\n    df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n\n    # get common words in search_term and product_title\n    df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n\n    # get count of common words in search_term and product_description\n    df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n\n    # display first rows in dataframe\n    print(df_all.head())\n    \n    return df_all\n\ndf_all = runFeatureEngineeringSet1(df_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b43098ee5980c697d60dc877ff12c01c9f1e5e53","_cell_guid":"2bd1a413-620d-40d4-a368-a2033e528841"},"cell_type":"markdown","source":"# ML functions "},{"metadata":{"_uuid":"9a910523ce33292083828ff151c7472afc2212c6","_cell_guid":"5932d430-a30d-4486-9e1d-0577215227ac","collapsed":true},"cell_type":"markdown","source":"### Base class implementation"},{"metadata":{"_uuid":"37f28dab4521380e8954d0c665076372cd24d730","_cell_guid":"28867291-c78f-439a-99b5-e58f355b5ab1","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nclass TreeCapsule:\n    def __init__(self, max_depth=50, n_estimators=100, min_child_weight=2, learning_rate=0.01):\n        self.max_depth = max_depth\n        self.n_estimators = n_estimators\n        self.min_child_weight = min_child_weight\n        self.learning_rate = learning_rate\n        self.sklearnHook = None\n        self.sklearnHookReady = False\n        self.y_hat = None\n        \n        \n    def getTrainingTestingData(self, df, numTrain, columnsToTrain=None):\n        df_train = df.iloc[:numTrain]\n        df_test = df.iloc[numTrain:]\n\n        if not columnsToTrain: # include all columns except \"relevance\"\n            print(\"using all columns except 'relevance'\")\n            columnsToTrain = list(df.columns)\n            columnsToTrain.remove(\"relevance\")\n            \n        self.x_train = df_train[columnsToTrain]\n        self.y_train = df_train[\"relevance\"]\n        \n        \n        self.x_test = df_test[columnsToTrain]\n        self.y_test = list(df_test[\"relevance\"])\n        \n        return self.x_train, self.y_train, self.x_test, self.y_test\n    \n    \n    def fit(self):\n        assert self.sklearnHook != None, \"cannot init base class object\"\n        \n        if self.sklearnHookReady:\n            # assign default params\n            self.sklearnHook.max_depth = self.max_depth\n            self.sklearnHook.n_estimators = self.n_estimators\n            self.sklearnHook.min_child_weight = self.min_child_weight\n            self.sklearnHook.learning_rate = self.learning_rate\n        \n            self.sklearnHook.fit(self.x_train, self.y_train)\n        \n        \n    def predict(self):\n        assert self.sklearnHookReady, \"cannot run predictions on unfitted algo\"\n        \n        self.y_hat = list(self.sklearnHook.predict(self.x_test))\n        \n    \n    def calculateMetrics(self):\n        assert self.y_hat , \"no predictions to run metrics on\"\n        \n        self.rmse = metrics.mean_squared_error(self.y_test, self.y_hat)\n        # self.accuracyScore = metrics.accuracy_score(self.y_test, self.y_hat)\n        \n        \n    def reset(self):\n        self.sklearnHookReady = False\n        \n    \n    def run(self):\n        self.fit()\n        self.predict()\n        self.calculateMetrics()\n        \n        return {\"rmse\" : self.rmse}\n        # return json.dumps({\"accuracyScore\" : \"self.accuracyScore\", \"rmse\" : self.rmse}, indent=4)\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ec5810b26873af3c950d7c40a07f113d7b01126","_cell_guid":"77c0da26-0c85-4f91-93d8-483870a9e8b5"},"cell_type":"markdown","source":"### Specialized class**"},{"metadata":{"_uuid":"a3e6d39bba8266c6a0ca6bf4d5c2b3f4a7ce5e09","_cell_guid":"4529fccc-4b59-4f89-9417-097919045f9d","collapsed":true,"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import plot_importance\n\nclass XGBoostCapsule(TreeCapsule):\n    def __init__(self, max_depth=50, n_estimators=100, min_child_weight=2, learning_rate=0.01):\n        super().__init__(max_depth, n_estimators, min_child_weight, learning_rate)\n        self.sklearnHook = xgb.XGBRegressor()\n        self.sklearnHookReady = True\n        \n    def run(self):\n        val = super().run()\n        plot_importance(self.sklearnHook)\n        return val\n        \nfrom sklearn.ensemble import RandomForestRegressor\nclass RandomForestCapsule(TreeCapsule):\n    def __init__(self, max_depth=50, n_estimators=100, min_child_weight=2, learning_rate=0.01):\n        super().__init__(max_depth, n_estimators, min_child_weight, learning_rate)\n        self.sklearnHook = RandomForestRegressor()\n        self.sklearnHookReady = True\n        \nfrom sklearn.ensemble import BaggingRegressor\nclass BaggingRegressorCapsule(TreeCapsule):\n    def __init__(self, max_depth=50, n_estimators=100, min_child_weight=2, learning_rate=0.01):\n        super().__init__(max_depth, n_estimators, min_child_weight, learning_rate)\n        self.sklearnHook = BaggingRegressor()\n        self.sklearnHookReady = True\n        \n        \nfrom sklearn.ensemble import GradientBoostingRegressor\nclass GradBoostingRegressorCapsule(TreeCapsule):\n     def __init__(self, max_depth=50, n_estimators=100, min_child_weight=2, learning_rate=0.01):\n        super().__init__(max_depth, n_estimators, min_child_weight, learning_rate)\n        self.sklearnHook = GradientBoostingRegressor()\n        self.sklearnHookReady = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac99de2696956697724ffcbe905b43db4524fd97","_cell_guid":"ea99ecfe-7795-4c86-8ca4-4ef8d52e6e91"},"cell_type":"markdown","source":"## Column selection"},{"metadata":{"_uuid":"4eeb9f8a71bed5958d8c82aa090f1a55b69a9acd","_cell_guid":"641bead4-ac7d-4a13-8ea6-8255fdd7e594","collapsed":true,"trusted":true},"cell_type":"code","source":"columnsToTrain = ['len_of_query' , 'word_in_title' , 'word_in_description']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc953162cd026e34373426ef9a604c4bb6012f3d","_cell_guid":"dd478272-5172-4ae0-b295-ec9cf63c705a"},"cell_type":"markdown","source":"# Feature Engineering Set 2"},{"metadata":{"_uuid":"b59f1a8dd56ea72799a4b7f8916915e85da31c4f","_cell_guid":"7f51c105-a7e5-49bf-91a8-96b94f80e910","collapsed":true,"trusted":true},"cell_type":"code","source":"from fuzzywuzzy import fuzz\ndef fuzzy_partial_ratio(string_1 , string_2):\n    return fuzz.partial_ratio(string_1, string_2)\n\ndef fuzzy_token_sort_ratio(string_1,string_2):\n    return fuzz.token_sort_ratio(string_1,string_2)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"955eb94f6c6322e0f80316d1041f4c78f91dd423","_cell_guid":"4cd6ec3d-4b8a-4787-9146-5547799c0152","trusted":true},"cell_type":"code","source":"def runFeatureEngineeringSet2(df_all):\n    df_all['fuzzy_ratio_in_title'] = df_all['product_info'].map(lambda x:fuzzy_partial_ratio(x.split('\\t')[0],x.split('\\t')[1]))\n    df_all['fuzzy_ratio_in_description'] = df_all['product_info'].map(lambda x:fuzzy_partial_ratio(x.split('\\t')[0],x.split('\\t')[2]))\n    df_all['fuzzy_ratio_in_title_description'] = df_all['product_info'].map(lambda x:fuzzy_partial_ratio(x.split('\\t')[0],\" \".join(x.split('\\t')[1:])))\n    df_all['fuzzy_token_sort_ratio_in_title_description'] = df_all['product_info'].map(lambda x:fuzzy_token_sort_ratio(x.split('\\t')[0],\" \".join(x.split('\\t')[1:])))\n    df_all['fuzzy_token_sort_ratio_in_title'] = df_all['product_info'].map(lambda x:fuzzy_token_sort_ratio(x.split('\\t')[0],x.split('\\t')[1]))\n    df_all['fuzzy_token_sort_ratio_in_description'] = df_all['product_info'].map(lambda x:fuzzy_token_sort_ratio(x.split('\\t')[0],x.split('\\t')[2]))\n    \n    return df_all\n\ndf_all = runFeatureEngineeringSet2(df_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85041c13c2be58d5f5f02b5a5b2e60af17409e25","_cell_guid":"e2d6565f-c8be-4d39-a289-800aaddd005b","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a1e77f49c567b546af1f58405f7349b7fc2216c","_cell_guid":"89df268f-0576-41b0-82a5-02dcc1739499"},"cell_type":"markdown","source":"## Random Forests"},{"metadata":{"_uuid":"35ddf8b47363a9c45ae35dbbb0935167f42cb7ac","_cell_guid":"d665b935-657a-4203-9853-ff6c68364b76","collapsed":true,"trusted":true},"cell_type":"code","source":" def rnd(columnsToTrain):\n    print(\"Random Forests\")\n    rndForest = RandomForestCapsule()\n    _ = rndForest.getTrainingTestingData(df_all, TRAINING_RECORDS, columnsToTrain)\n\n    print(rndForest.run())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e52c728ad80a12ce68131941fee7d958bcc0cbd0","_cell_guid":"7898cb7c-3db5-479b-a12a-56a5250aac8f"},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"_uuid":"3df5232c2ccc29c81e5e0082af77613aeb9d6405","_cell_guid":"fe2b2678-be2d-4d2a-afe8-d259e308b5f6","collapsed":true,"trusted":true},"cell_type":"code","source":"def xboost(columnsToTrain):\n    print(\"XG Boost\")\n    xgBoost = XGBoostCapsule()\n    _ = xgBoost.getTrainingTestingData(df_all, TRAINING_RECORDS, columnsToTrain)\n\n    print(xgBoost.run())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34aebe848199732b0e537778c694e04c29bac00c","_cell_guid":"0ea9b631-6403-401e-9fd1-a722d78449af"},"cell_type":"markdown","source":"## Bagging Regressor"},{"metadata":{"_uuid":"bdec852a4b87aea25938b425f878bd47bbef9f3b","_cell_guid":"64ddb5c0-14ee-4793-92a7-d642c7efd6fe","collapsed":true,"trusted":true},"cell_type":"code","source":"def bag(columnsToTrain):   \n    print(\"Bagging Regressor\")\n    bagging = BaggingRegressorCapsule()\n    _ = bagging.getTrainingTestingData(df_all, TRAINING_RECORDS, columnsToTrain)\n\n    print(bagging.run())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a380c4b0a3a0a93b82d8dca0e63b85b2624dad","_cell_guid":"ac1b543e-0c20-47c3-93db-35b8c87f8db9"},"cell_type":"markdown","source":"## Gradient Boosted Regressor"},{"metadata":{"_uuid":"988571a37900ebcaf23461213ff2dd4593b36494","collapsed":true,"_cell_guid":"1227d55a-e99f-47a7-90e7-3577f7e6e18b","trusted":true},"cell_type":"code","source":"def grad(columnsToTrain):\n    print(\"Gradient Boosted Regressor\")\n    gradRegressor = GradBoostingRegressorCapsule()\n    _ = gradRegressor.getTrainingTestingData(df_all, TRAINING_RECORDS, columnsToTrain)\n\n    print(gradRegressor.run())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ef07f6385637ab765c27c8672f37fc309420bc6","_cell_guid":"77111760-6d0c-483d-b820-6bae220ac987","trusted":true,"collapsed":true},"cell_type":"code","source":"columnsToTrain = ['len_of_query' , 'word_in_title' , 'word_in_description' , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description' , 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description' , 'fuzzy_ratio_in_title_description' , 'fuzzy_token_sort_ratio_in_title_description']\ncolumnsToTrainMaster = copy(columnsToTrain)\nrnd(columnsToTrain)\nxboost(columnsToTrain)\nbag(columnsToTrain)\ngrad(columnsToTrain)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4760a9cc6ba8e365ac73fa7e9a4dcf6b279d8c21","_cell_guid":"1dbf59e4-3a9f-4db2-ae72-c542888fc7ee"},"cell_type":"markdown","source":"## Feature selection "},{"metadata":{"_uuid":"f3b617635e51668890fafb7dbb29fa053c835017","_cell_guid":"cf704812-0c09-47a3-ae6a-a3abb21df405"},"cell_type":"markdown","source":"### Co-relation matrix"},{"metadata":{"_uuid":"ea7b01f56c2f5c263391bb3587117a2542e9c40d","_cell_guid":"489a9fe0-120d-4749-af20-6a297ad6f3a4","trusted":true,"collapsed":true},"cell_type":"code","source":"corr_matrix = df_all.corr()\nprint(corr_matrix[\"relevance\"].map(lambda x : abs(x)).sort_values(ascending=False))\nsns.heatmap(corr_matrix, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ff74a60ede72d1f2fc27d4349e829f919452cb6","_cell_guid":"e5a38bcf-6738-4f13-88f9-1fa177bf2390","trusted":false,"collapsed":true},"cell_type":"code","source":"# use only the highest correlation values - we do not care if the co-relation is positive or negative\ncolumnsToTrain = [\"fuzzy_ratio_in_title\", \"fuzzy_ratio_in_title_description\", \"fuzzy_ratio_in_description\", \"word_in_title\", \"word_in_description\", \"fuzzy_token_sort_ratio_in_title\"]\n\nrnd(columnsToTrain)\nxboost(columnsToTrain)\nbag(columnsToTrain)\ngrad(columnsToTrain)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94c809b308df5283a9f3ee98013d865de6e0eefe","_cell_guid":"bc1647ba-fd12-476b-be06-412e92b9ad3a"},"cell_type":"markdown","source":"## Using only important features from XGBoost"},{"metadata":{"_uuid":"b984f017b08ffc7c3f205b223c69e4911ebf51a7","_cell_guid":"1e2fc7a0-c01d-4312-8de8-21603018f3b2","trusted":false,"collapsed":true},"cell_type":"code","source":"# use only the highest correlation values - we do not care if the co-relation is positive or negative\ncolumnsToTrain = [\"fuzzy_token_sort_ratio_in_title\", \"fuzzy_ratio_in_title\", \"fuzzy_ratio_in_description\", \"fuzzy_ratio_in_title_description\", \"word_in_title\", \"fuzzy_token_sort_ratio_in_description\"]\n\nrnd(columnsToTrain)\nxboost(columnsToTrain)\nbag(columnsToTrain)\ngrad(columnsToTrain)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9eab8a23e3e63eb95cffe70bf02127e810ee811","_cell_guid":"4f81cf25-a24e-4c43-b514-002e01558f68"},"cell_type":"markdown","source":"## Feature selection techniques from sklearn"},{"metadata":{"_uuid":"f24cdd3631fa78ceecb899f5f340ff368f919da3","_cell_guid":"5fc5c24a-16b2-47c8-b884-b10336b2300e","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\ncolumnsToTrain = ['len_of_query' , 'word_in_title' , 'word_in_description' , 'fuzzy_ratio_in_title' , 'fuzzy_ratio_in_description' , 'fuzzy_token_sort_ratio_in_title' , 'fuzzy_token_sort_ratio_in_description' , 'fuzzy_ratio_in_title_description' , 'fuzzy_token_sort_ratio_in_title_description']\ncapObj = TreeCapsule()\nx_train, y_train, _, _ = capObj.getTrainingTestingData(df_all, 600, columnsToTrain)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1f75a74f4637730c7b9392b27e2c960abe56078","_cell_guid":"5c805691-33a9-47ba-b284-174e135aa151","trusted":false,"collapsed":true},"cell_type":"code","source":"skb = SelectKBest(f_regression, k=5)\nskb.fit(x_train, y_train)\n\nx_train_transformed = skb.transform(x_train)\nsorted(zip(map(lambda x: round(x, 4), skb.scores_), columnsToTrain), \n             reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17d2db0fc6757a7cfc60a16dd228646a11973b94","_cell_guid":"45755fc3-3e4c-47f9-9fef-eabf4f60b1d6","trusted":false,"collapsed":true},"cell_type":"code","source":"columnsToTrain =  ['fuzzy_ratio_in_title', 'fuzzy_ratio_in_title_description','word_in_title', 'fuzzy_ratio_in_description', 'word_in_description']\nrnd(columnsToTrain)\nxboost(columnsToTrain)\nbag(columnsToTrain)\ngrad(columnsToTrain)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"037f32b2ee984b826971936187deb7348bc53534","_cell_guid":"6dc08790-a6e6-4a5d-bcfe-a2e967bc2be4","trusted":false,"collapsed":true},"cell_type":"code","source":"from random import shuffle\n\nfor column in columnsToTrain:\n    print(\"shuffling column : %s\" %column)\n    df_all_copy = copy.deepcopy(df_all)\n    allValues = list(df_all_copy[column])\n    shuffle(allValues)\n    df_all_copy[column] = allValues\n    \n    rnd(columnsToTrain)\n    xboost(columnsToTrain)\n    bag(columnsToTrain)\n    grad(columnsToTrain)\n    \n    print(\"\\n\\n\")\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48ec7f24a9029ab1d38bec049cb566e3415d3f68","_cell_guid":"f6461ed2-32bc-4710-810d-0c54c2601a26","collapsed":true},"cell_type":"markdown","source":"# Grid Search - Parameter Hypertuning"},{"metadata":{"_uuid":"8052dedef9ca442a25ac335e846bfc4ee7b75e91","_cell_guid":"ac4d31c6-cc01-4bde-8f52-2cbb905a1d9b","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}