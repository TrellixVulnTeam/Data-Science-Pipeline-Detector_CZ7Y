{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\nDự đoán độ tương quan giữa từ khóa tìm kiếm và sản phẩm trả về với dữ liệu từ HomeDepot.com\n--------------------------------------------------------\n","metadata":{"_cell_guid":"3915d195-fc94-761b-21b9-f3b1edd7d991"}},{"cell_type":"markdown","source":"Đây chỉ là là cell được cung cấp bởi Kaggle.  \n  \nNó import thư viện **numpy** cho việc tính toán toán học, **pandas** cho việc xử lý dữ liệu, **matplotlib** cho việc vẽ biểu đồ, và **re** cho việc xử lý ký pháp **regex**.  \n  \nNgoài ra, kaggle còn cho ta xem đường dẫn đến dữ liệu với hàm **ls** trong linux để liệt kê các thư mục / files trong đường dẫn mà họ cho trước.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","metadata":{"_cell_guid":"8ca0f34d-e8e7-4d20-7f39-01a1c39d465b","execution":{"iopub.status.busy":"2021-05-25T06:31:51.965265Z","iopub.execute_input":"2021-05-25T06:31:51.965582Z","iopub.status.idle":"2021-05-25T06:31:51.985684Z","shell.execute_reply.started":"2021-05-25T06:31:51.96556Z","shell.execute_reply":"2021-05-25T06:31:51.983932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tổng quan**\n--------------\n  \nHome Depot đã xây dựng ra bộ dữ liệu được người đánh giá về mức độ liên quan giữa kết quả tìm kiếm và từ tìm kiếm, có khả năng thay đổi tích cực đến chất lượng dịch vụ.  \n  \nNotebook này sẽ xây dựng một mô hình đánh giá độ tương quan giữa các từ khóa tìm kiếm và kết quả trả về, dựa trên dữ liệu của Home Depot.  ","metadata":{"_cell_guid":"06145092-57a8-1478-7082-c261b2973c90"}},{"cell_type":"markdown","source":"# Mục lục  \n* [Đọc dữ liệu](#read_data)  \n* [Khám phá dữ liệu](#data_exploration)  \n    - [Khám phá dữ liệu training](#training_data_exploration)\n    - [Khám phá dữ liệu testing](#testing_data_exploration)\n    - [Khám phá dữ liệu attribute](#attribute_data_exploration)\n    - [Khám phá dữ liệu description](#description_data_exploration)\n* [Xử lý, phân tích, và xây dựng dữ liệu](#data_processing)  \n    - [Xây dựng dữ liệu brand mới, join brand và description](#new_brand)\n    - [Xây dựng dữ liệu attribute mới](#new_attribute)\n    - [Tạo ra một số dữ liệu định lượng](#new_quantitative)\n    - [Tiền xử lý](#pre_processing)\n        - [Chuẩn hóa các xâu](#normalization)\n        - [Stemming](#stem)\n* [Biểu diễn dữ liệu](#data_representation)  \n    - [Tf-idf](#tfidf)\n    - [TruncatedSVD](#svd)\n    - [Pipeline dữ liệu](#tfidf_svd)\n    - [Hàm mất mát](#loss)\n    - [Phân tách dữ liệu train-test](#data_split)\n* [Huấn luyện mô hình](#model_training)\n    - [Khởi tạo mô hình](#model_selection)\n    - [Tìm kiếm bộ tham số tối ưu](#find_best_param)\n    - [Huấn luyện với bộ tham số tối ưu](#best_param_training)\n    - [Dự đoán kết quả cuối cùng](#prediction)\n* [Kết quả ](#result)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"read_data\"></a>\n# Đọc dữ liệu  ","metadata":{"_cell_guid":"328bcea9-15f5-c53f-7cab-a9773bc380ce"}},{"cell_type":"markdown","source":"Giờ ta sẽ cần đọc dữ liệu csv từ nguồn dữ liệu được lưu trữ dưới dạng **.csv.zip**.  \n\nSử dụng hàm **pandas.read_csv**, ta sẽ có khả năng giải nén đồng thời trong quá trình đọc. \n\nCác file **.zip** tự động được giải nén và đọc dưới dạng **pd.DataFrame**.  \nCác dữ liệu được đọc là \"**training_data**\", \"**testing_data**\", \"**attribute_data**\", và \"**description**\".  \n  \nDựa vào tên ta có thể đoán được các dữ liệu này làm gì, tuy nhiên để chắc chắn ta sẽ cần khám phá từng cái một.  ","metadata":{"_cell_guid":"f6c01ae6-ef20-17d1-5aa5-a36925c629dc"}},{"cell_type":"code","source":"# Load files\ntraining_data = pd.read_csv(\"../input/home-depot-product-search-relevance/train.csv.zip\", encoding=\"ISO-8859-1\")\ntesting_data = pd.read_csv(\"../input/home-depot-product-search-relevance/test.csv.zip\", encoding=\"ISO-8859-1\")\nattribute_data = pd.read_csv('../input/home-depot-product-search-relevance/attributes.csv.zip')\ndescriptions = pd.read_csv('../input/home-depot-product-search-relevance/product_descriptions.csv.zip')","metadata":{"_cell_guid":"f2a05654-1519-de35-bf07-3b5e843e8d6a","execution":{"iopub.status.busy":"2021-05-25T06:31:51.9872Z","iopub.execute_input":"2021-05-25T06:31:51.987445Z","iopub.status.idle":"2021-05-25T06:31:58.629395Z","shell.execute_reply.started":"2021-05-25T06:31:51.98742Z","shell.execute_reply":"2021-05-25T06:31:58.628374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_exploration\"></a>\n# Khám phá dữ liệu","metadata":{}},{"cell_type":"markdown","source":"<a id=\"training_data_exploration\"></a>\n## Khám phá training_data","metadata":{}},{"cell_type":"markdown","source":"Hiện ta không biết **training_data** mang ý nghĩa gì.  \n  \nTiếp cận đầu tiên là tên các cột của các dữ liệu. Ta sẽ sử dụng hàm **pandas.DataFrame.columns.values** trả về một list các tên của các cột trong DataFrame đó.  \n  \n**Training_data** có 5 cột, dựa vào tên ta có thể suy ra được:  \n- **product_uid**: Mã của sản phẩm. Các sản phẩm khác nhau sẽ có mã sản phẩm khác nhau.  \n- **product_title**: Tiêu đề tên sản phẩm.  \n- **search_term**: Từ khóa tìm kiếm.  \n- **relevance**: Điểm tương quan như đã mô tả.  \n  \nNhư vậy, đây là dữ liệu huấn luyện của ta.    ","metadata":{}},{"cell_type":"code","source":"print(\"Train data columns are: {}\".format(training_data.columns.values))\nprint(\"Test data columns are: {}\".format(testing_data.columns.values))\nprint(\"Attribute data columns are: {}\".format(attribute_data.columns.values))\nprint(\"Description data columns are: {}\".format(descriptions.columns.values))","metadata":{"_cell_guid":"43bdb419-2242-b795-56e7-441d6da8c43c","execution":{"iopub.status.busy":"2021-05-25T06:33:40.124231Z","iopub.execute_input":"2021-05-25T06:33:40.124749Z","iopub.status.idle":"2021-05-25T06:33:40.132584Z","shell.execute_reply.started":"2021-05-25T06:33:40.124714Z","shell.execute_reply":"2021-05-25T06:33:40.131323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ đã biết ý nghĩa của các trường thông tin, ta muốn hiểu rõ hơn về kiểu dữ liệu trong dataframe này.  \n  \nHàm **pandas.DataFrame.info()** sẽ cho ta biết các cột mang những giá trị như thế nào.  \n  \nNhìn vào kết quả, ta thấy dữ liệu có **74067**, hoàn toàn không có dữ liệu **null**.  \nViệc này khá tuyệt, ta sẽ không phải xử lý dữ liệu **null** trong bảng.  \n  \nTuy nhiên, **product_title** và **search_term** mang loại object, ta sẽ cần xem chi tiết hơn về chúng.  ","metadata":{}},{"cell_type":"code","source":"training_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:33:42.001288Z","iopub.execute_input":"2021-05-25T06:33:42.001585Z","iopub.status.idle":"2021-05-25T06:33:42.039375Z","shell.execute_reply.started":"2021-05-25T06:33:42.001557Z","shell.execute_reply":"2021-05-25T06:33:42.037772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta muốn xem một số hàng đầu của **product_title** và **search_term**.  \nHàm **pandas.DataFrame.head()** trả về 5 hàng đầu của dữ liệu.  \n  \nTa nhận thấy Tiêu đề này chứa các dữ liệu văn bản chưa được chuẩn hóa, i.e chứa các ký tự in hoa lẫn thường, ký tự đặc biệt, ... Ta sẽ cần chuẩn hóa lại để tiện cho việc xử lý sau này.  ","metadata":{}},{"cell_type":"code","source":"training_data[['product_title', 'search_term']].head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:33:44.54252Z","iopub.execute_input":"2021-05-25T06:33:44.542889Z","iopub.status.idle":"2021-05-25T06:33:44.564685Z","shell.execute_reply.started":"2021-05-25T06:33:44.542855Z","shell.execute_reply":"2021-05-25T06:33:44.563819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta cũng muốn tìm hiểu dữ liệu **relevance** được phân bố thế nào.  \n  \nHàm **pandas.DataFrame.describe()** sẽ cho chúng ta dữ liệu thống kê về nó.  \n  \nPhần lớn độ tương quan đánh giá sẽ nằm trong đoạn 2.00 đến 3.00 (50% percentile là 2.33).  \nDữ liệu sẽ chênh nhau khá lớn về các mẫu có độ tương quan lớn.","metadata":{}},{"cell_type":"code","source":"training_data['relevance'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:33:46.817176Z","iopub.execute_input":"2021-05-25T06:33:46.817583Z","iopub.status.idle":"2021-05-25T06:33:46.834895Z","shell.execute_reply.started":"2021-05-25T06:33:46.817543Z","shell.execute_reply":"2021-05-25T06:33:46.833566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Để nhìn rõ hơn sự phân bố của **relevance**, ta sử dụng hàm **pandas.DataFrame.Series.hist()** để vẽ hiểu đồ histogram.  \n  \nKết quả ta nhận thấy cũng giống như đã xem ở số liệu thống kê, với số lượng mẫu mang độ relevance chiếm đại đa số.","metadata":{}},{"cell_type":"code","source":"training_data.relevance.hist()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:33:49.617231Z","iopub.execute_input":"2021-05-25T06:33:49.617548Z","iopub.status.idle":"2021-05-25T06:33:49.824844Z","shell.execute_reply.started":"2021-05-25T06:33:49.617513Z","shell.execute_reply":"2021-05-25T06:33:49.823906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"testing_data_exploration\"></a>\nLúc này, ta đoán dữ liệu **testing_data** sẽ mang tính kiểm duyệt để nộp ra kết quả cuối cùng, do đó nó cũng mang dữ liệu tương tự với **training_data**, chỉ bỏ đi trường **relevance**.  \n  \nTa kiểm tra bằng hàm **pandas.DataFrame.info()** và kết quả đúng như vậy.  ","metadata":{}},{"cell_type":"code","source":"testing_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:33:52.740918Z","iopub.execute_input":"2021-05-25T06:33:52.741214Z","iopub.status.idle":"2021-05-25T06:33:52.769875Z","shell.execute_reply.started":"2021-05-25T06:33:52.74119Z","shell.execute_reply":"2021-05-25T06:33:52.768441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"attribute_data_exploration\"></a>\n## Khám phá dữ liệu thông tin thuộc tính","metadata":{}},{"cell_type":"markdown","source":"Ta muốn xem **attribute_data** mang những thông tin gì.  \n  \nTa dùng hàm **pandas.DataFrame.head()** để xem một số dòng đầu của dữ liệu.  \n  \nDựa vào kết quả thu được, ta có một số nhận xét sau:  \n- **product_uid**: Mã sản phẩm. Mã này lại được ghi dưới dạng số thập phân, ta sẽ cần sửa lại thành dạng số nguyên để đồng nhất với các dữ liệu khác. <a id=\"float-id\"></a> \n- **name**: Tên thuộc tính. Mỗi sản phẩm theo product_uid có thể mang nhiều thuộc tính. Tên các thuộc tính đã được giấu đi và thay thế bằng các cụm từ gồm chữ latin in hoa, thường và số.  \n- **value**: Thông tin về thuộc tính tương ứng.  Trường thông tin này mang nhiều loại ký tự.  \n  \nNhìn vào kết quả, ta sẽ cần xem xét thêm trường **name**, khi thấy nó mang những giá trị \"**bullet**\" (các chấm đầu dòng thay vì một từ mang ý nghĩa nào đó).","metadata":{}},{"cell_type":"code","source":"print(attribute_data.head())","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:33:58.237539Z","iopub.execute_input":"2021-05-25T06:33:58.237898Z","iopub.status.idle":"2021-05-25T06:33:58.246352Z","shell.execute_reply.started":"2021-05-25T06:33:58.237872Z","shell.execute_reply":"2021-05-25T06:33:58.245053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Như đã nhắc đến ở cell bên trên, ta sẽ thử xem trường **name** mang các dữ liệu thế nào.  \n  \nNhìn vài kết quả, ta thấy nhiều tên thuộc tính là **Bullet**, tức là các gạch đầu dòng, không mang ý nghĩa gì. Tuy nhiên, lại có những thông tin mang ngữ nghĩa.  \n  \nCó 5411 trường thông tin khác nhau, trên tổng số 2 triệu mẫu, tức là ta hoàn toàn có khả năng dựa vào thông tin này để lấy đặc trưng.  ","metadata":{}},{"cell_type":"code","source":"print(attribute_data['name'].unique())\nprint(len(attribute_data['name'].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:34:03.23615Z","iopub.execute_input":"2021-05-25T06:34:03.23643Z","iopub.status.idle":"2021-05-25T06:34:03.811703Z","shell.execute_reply.started":"2021-05-25T06:34:03.236407Z","shell.execute_reply":"2021-05-25T06:34:03.809958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"mfg\"></a>\nTa sẽ thử xem tên các thuộc tính xuất hiện với tần suất nào.  \n  \nCó một trường thông tin là **MFG Brand Name** xuất hiện nhiều nhất, ngữ nghĩa của nó là trường mang thông tin nhà sản xuất sản phẩm đó (**Manufacturing Brand Name**).  \n\nĐây sẽ là một trường thông tin rất hữu ích.  ","metadata":{}},{"cell_type":"code","source":"attribute_counts = attribute_data.name.value_counts()\nprint(attribute_counts)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:37:04.542618Z","iopub.execute_input":"2021-05-25T06:37:04.542992Z","iopub.status.idle":"2021-05-25T06:37:04.982443Z","shell.execute_reply.started":"2021-05-25T06:37:04.542962Z","shell.execute_reply":"2021-05-25T06:37:04.980469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"description_data_exploration\"></a>\n## Khám phá dữ liệu mô tả.","metadata":{}},{"cell_type":"markdown","source":"Hiện ta chưa biết dữ liệu **description** mang thông tin gì.  \n\nTa sẽ in ra một số dòng đầu của dữ liệu mô tả bằng hàm **pandas.DataFrame.head()**.  \n  \nNhìn vào dữ liệu, ta thế dữ liệu này mang 2 thông tin:  \n    - **product_uid**: Mã sản phẩm.  \n    - **product_description**: Dữ liệu văn bản mô tả sản phẩm. Dữ liệu này bao gồm cả các ký tự latin viết hoa, viết thường, các chữ số và ký tự đặc biệt.    \n    \nDữ liệu này không có gì đặc biệt lắm. Tuy nhiên, trường **product_desciption** có thể mang những từ liên quan đến **search_term**, ta sẽ tìm hiểu sau.  ","metadata":{}},{"cell_type":"code","source":"descriptions.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:40:19.640257Z","iopub.execute_input":"2021-05-25T06:40:19.640635Z","iopub.status.idle":"2021-05-25T06:40:19.653027Z","shell.execute_reply.started":"2021-05-25T06:40:19.640599Z","shell.execute_reply":"2021-05-25T06:40:19.651901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_processing\"></a>\n# Xử lý, phân tích, và xây dựng dữ liệu","metadata":{}},{"cell_type":"markdown","source":"<a id=\"new_brand\"></a>\n## Xây dựng thông tin brand, và join dữ liệu brand và description","metadata":{}},{"cell_type":"markdown","source":"Trước tiên, ta thấy **training_data** và **testing_data** đều mang thông tin giống nhau (chỉ khác là **testing_data** không có trường **relevance**).  \n\nDo đó để xử lý ta sẽ nối chúng với nhau để làm một thể, hơn là chia nhau để xử lý.  \n\nHàm **pandas.concat** sẽ nối 2 DataFrame với nhau, trường thông tin bị thiếu sẽ được thay bằng **NaN**.  \n  \nKết quả thu được là một DataFrame tổng hợp của **training_data** và **testing_data**. Ta có thể nhìn qua một chút về chúng qua hàm **all_data.tail()** (**relevance** của **tesing_data** được ép về NaN), và có tổng cộng 240760 hàng tất cả.","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([training_data, testing_data], axis=0, ignore_index=True)\nprint(all_data.tail())\nlen(all_data)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:00:50.719607Z","iopub.execute_input":"2021-05-25T07:00:50.719932Z","iopub.status.idle":"2021-05-25T07:00:50.741457Z","shell.execute_reply.started":"2021-05-25T07:00:50.719907Z","shell.execute_reply":"2021-05-25T07:00:50.739791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Như đã nhắc đến ở [đây](#mfg), **MFG Brand Name** là một thông tin hữu ích.  \n  \nỞ đây tôi muốn xây dựng một dataFrame khác chỉ dựa trên thông tin này, bằng việc chọn những hàng ở **attribute_data** có **attribute_data.name == \"MFG Brand Name\"**, lấy **product_uid** và \"**value**\", và trường **value** được thay bằng thông tin mới: **brand** - tên nhãn hiệu.  \n  \nKết quả thu được là **brand_data**, mang thông tin nhãn hiệu của các sản phẩm, ta có thể nhìn qua chúng một chút qua hàm **brand_data.head()**.  ","metadata":{}},{"cell_type":"code","source":"brand_data = attribute_data[attribute_data.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\nbrand_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:07:53.471771Z","iopub.execute_input":"2021-05-25T07:07:53.472069Z","iopub.status.idle":"2021-05-25T07:07:53.634289Z","shell.execute_reply.started":"2021-05-25T07:07:53.472046Z","shell.execute_reply":"2021-05-25T07:07:53.633452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dữ liệu **search_term** có chứa số, và pandas có thể ép kiểu nó thành số ở một số hàng.  \nTrong khi rõ ràng ta muốn **search_term** là xâu, ta cần ép kiểu chúng thành **str**.  \n  \nTa dùng hàm **astype(str)** để ép chúng thành **str**.  \n  \nKết quả thu được là mọi **search_term** đều là xâu, thuận tiện cho sau này.  \n  \nNgoài ra, ta cũng làm tương tự với thông tin brand của **brand_data**, sau khi loại bỏ mọi dữ liệu **na**.","metadata":{}},{"cell_type":"code","source":"all_data[\"search_term\"]= all_data[\"search_term\"].astype(str)\nbrand_data.dropna(inplace=True)\nbrand_data['brand'] = brand_data['brand'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:24:28.063202Z","iopub.execute_input":"2021-05-25T07:24:28.063505Z","iopub.status.idle":"2021-05-25T07:24:28.123155Z","shell.execute_reply.started":"2021-05-25T07:24:28.06348Z","shell.execute_reply":"2021-05-25T07:24:28.121596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Như đã nói ở [đây](#float-id), ta sẽ muốn ép kiểu **product_uid** của **attribute_data** về dạng **int** để chuẩn hơn trong quá trình chuyển hóa sau này.  \n  \nNgoài ra, ta cũng loại bỏ các trường **na** ở **attribute_data** và **descriptions** luôn.  \n  \nKết quả là **attribute_data** và **descriptions** đều chỉ mang các dữ liệu chuẩn.","metadata":{}},{"cell_type":"code","source":"attribute_data.dropna(inplace=True)\nattribute_data['product_uid'] = attribute_data['product_uid'].astype(int)\ndescriptions.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:24:30.872574Z","iopub.execute_input":"2021-05-25T07:24:30.872987Z","iopub.status.idle":"2021-05-25T07:24:31.190847Z","shell.execute_reply.started":"2021-05-25T07:24:30.872963Z","shell.execute_reply":"2021-05-25T07:24:31.189058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vấn đề ở đây là, **descritions** và **brand_data** đều là những thông tin hữu ích, nhưng nó lại nằm ở các DataFrame khác nhau, khó khăn cho việc sử dụng.  \n  \nĐều sở hữu trường **product_uid**, ta hoàn toàn có thể join chúng với **all_data**, bằng **left_join**.   \n  \nKết quả là **all_data**, xét theo **product_uid**, **all_data** sẽ được \"gắn\" thêm thông tin **descritions** và **brand_data** tương ứng. Ta có thể dễ dàng xem chúng với hàm **all_data.head()**.    ","metadata":{}},{"cell_type":"code","source":"all_data = pd.merge(all_data, descriptions, how='left', on='product_uid')\nall_data = pd.merge(all_data, brand_data, how='left', on='product_uid')\nall_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:16:57.196406Z","iopub.execute_input":"2021-05-25T07:16:57.196781Z","iopub.status.idle":"2021-05-25T07:16:57.41038Z","shell.execute_reply.started":"2021-05-25T07:16:57.196744Z","shell.execute_reply":"2021-05-25T07:16:57.409623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"new_attribute\"></a>\n### Xây dựng attribute_data mới","metadata":{}},{"cell_type":"markdown","source":"Hiện ta muốn xây dựng một trường **attribute_data** mới, chỉ gồm 2 trường là **product_uid** và **attribute** (text).  \n  \nNhư đã nói đến ở [đây](#mfg), thông tin \"**Bullet**\" là vô nghĩa và tôi muốn xóa chúng.  \nTrước tiên, tôi tạo **attribute_data_stripped** mới (để tránh thay đổi dữ liệu gốc), với hàm **re.sub** để xóa đi các \"**Bullet**\", thay bằng xâu rỗng.","metadata":{}},{"cell_type":"code","source":"attribute_data_stripped = attribute_data\nattribute_data_stripped['name'] = attribute_data_stripped['name'].apply(lambda s: re.sub(r\"Bullet([0-9]+)\", \"\", s))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:24:35.321691Z","iopub.execute_input":"2021-05-25T07:24:35.32206Z","iopub.status.idle":"2021-05-25T07:24:39.168428Z","shell.execute_reply.started":"2021-05-25T07:24:35.322031Z","shell.execute_reply":"2021-05-25T07:24:39.166889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sau bước bên trên, giờ attribute sẽ cần mang dữ liệu từ cả **name** và **value**, do đó ta cộng xâu lại.  \n  \nTa xây dựng trường **attribute** bằng việc cộng xâu, với khoảng trắng ở giữa, giữa tên **attribute** và trường **value**.  \n  \nSau bước này, dữ liệu **attribute** đã có và sẵn sàng để tại DataFrame mới.  ","metadata":{}},{"cell_type":"code","source":"attribute_data_stripped['attribute'] = attribute_data_stripped['name'] + \" \" + attribute_data_stripped['value']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:24:45.362272Z","iopub.execute_input":"2021-05-25T07:24:45.362685Z","iopub.status.idle":"2021-05-25T07:24:46.082481Z","shell.execute_reply.started":"2021-05-25T07:24:45.36263Z","shell.execute_reply":"2021-05-25T07:24:46.081266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sau bước trên, ta vẫn thấy có vấn đề, đó là một **product_uid** chứa nhiều **attribute**.  \n  \nDo đó, ta nhóm hết các dữ liệu bằng hàm **groupby('product_uid')**, sau đó cộng xâu chúng lại bằng hàm **' '.join(...)** với **agg()**, phân tách bởi dấu cách.  \n  \nKết quả là **attribute_data_new**, với 2 trường là **product_uid** và **attribute**, sẵn sàng cho việc gộp vào dữ liệu chính **all_data** như **brand_data** và **descriptions**.","metadata":{}},{"cell_type":"code","source":"attribute_data_new = attribute_data_stripped.groupby('product_uid').agg({'attribute': lambda s : ' '.join(s.astype(str))}).reset_index()\nattribute_data_new.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:27:41.874828Z","iopub.execute_input":"2021-05-25T07:27:41.875188Z","iopub.status.idle":"2021-05-25T07:27:48.99323Z","shell.execute_reply.started":"2021-05-25T07:27:41.875158Z","shell.execute_reply":"2021-05-25T07:27:48.99199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"normalize\"></a>\n**attribute_data** vẫn đứng độc lập, giờ ta cần gộp nó vào với **all_data**.  \n  \nGiống như với brand_data và descriptions, ta sẽ thực hiện **left_join** giữa **all_data** và **attribue_data_new**, dựa trên **product_uid** bằng hàm **pandas.merge()**.  \n  \nKết quả thu được là **all_data** với thêm thông tin **attribute**.","metadata":{}},{"cell_type":"code","source":"all_data = pd.merge(all_data, attribute_data_new, how = 'left', on = 'product_uid')\nall_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:29:29.845034Z","iopub.execute_input":"2021-05-25T07:29:29.845394Z","iopub.status.idle":"2021-05-25T07:29:29.943204Z","shell.execute_reply.started":"2021-05-25T07:29:29.845365Z","shell.execute_reply":"2021-05-25T07:29:29.94201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"pre_processing\"></a>\n## Tiền xử lý","metadata":{}},{"cell_type":"markdown","source":"Nhắc đến việc tiền xử lý, ta nghĩ đến một số bước phổ biến sau:  \n* Chuẩn hóa xâu (viết thường hết, loại bỏ các ký tự đặc biệt, ....)  \n* Thay những từ cùng nghĩa nhưng có cách viết khác (ví dụ như số nhiều, số ít, chia thì, ...)  \n  \nTrước tiên ta sẽ Import những thư viện cần thiết, chuẩn bị các hàm cho việc xử lý.  ","metadata":{}},{"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:51:39.294673Z","iopub.execute_input":"2021-05-25T06:51:39.295091Z","iopub.status.idle":"2021-05-25T06:51:41.367886Z","shell.execute_reply.started":"2021-05-25T06:51:39.295061Z","shell.execute_reply":"2021-05-25T06:51:41.366767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"normalization\"></a>\n### Chuẩn hóa xâu","metadata":{}},{"cell_type":"markdown","source":"Như đã nhắc đến bên trên, đầu tiên là việc chuẩn hóa xâu.  \n  \nTa xây dựng hàng **normalize_string** với input là 1 xâu, kết quả trả về một xâu đã chuẩn hóa.  \nCác bước chuẩn hóa được chú thích từng dòng trong code.  \nĐể việc xử lý thuận tiện, ta sử dụng ký pháp **regex** và thư viện **re** của python.  \nViệc này giúp tốc độ xử lý xâu đạt cao nhất.  \n  \nSau cell này ta đã có hàm chuẩn hóa xâu **normalize_string**, sau này nếu muốn dùng ta chỉ việc **apply** nó cho các thuộc tính của DataFrame.","metadata":{}},{"cell_type":"code","source":"def normalize_string(input_str: str):\n    # Loại bỏ tất cả các ký tự đặc biệt\n    input_str = re.sub('\\W', ' ', input_str.lower())\n    # Loại bỏ các ký tự đứng một mình\n    input_str = re.sub('\\s+[a-zA-Z]\\s+', ' ', input_str)\n    # Sau bước trên, còn sót lại các ký tự đứng 1 mình ở đầu câu\n    # Ta xóa nốt trường hợp này\n    input_str = re.sub(r'\\^[a-zA-Z]\\s+', ' ', input_str) \n    # Sẽ có nhiều dấu cách đứng cạnh nhau sau bước trên \n    # Ta sẽ thay toàn bộ các dấu cách đứng cạnh nhau thành 1 dấu duy nhất \n    input_str = re.sub('\\s+', ' ', input_str, flags=re.I)\n    \n    # Các số cũng rất quan trọng, tuy nhiên ta không muốn các số xuất hiện trong xâu.\n    # Ta thay các chữ số thành các chữ tiếng Anh tương ứng\n    input_str = re.sub(r\"zero\\.?\", r\"0 \", input_str)\n    input_str = re.sub(r\"one\\.?\", r\"1 \", input_str)\n    input_str = re.sub(r\"two\\.?\", r\"2 \", input_str)\n    input_str = re.sub(r\"three\\.?\", r\"3 \", input_str)\n    input_str = re.sub(r\"four\\.?\", r\"4 \", input_str)\n    input_str = re.sub(r\"five\\.?\", r\"5 \", input_str)\n    input_str = re.sub(r\"six\\.?\", r\"6 \", input_str)\n    input_str = re.sub(r\"seven\\.?\", r\"7 \", input_str)\n    input_str = re.sub(r\"eight\\.?\", r\"8 \", input_str)\n    input_str = re.sub(r\"nine\\.?\", r\"9 \", input_str)\n\n    return input_str","metadata":{"execution":{"iopub.status.busy":"2021-05-25T06:56:03.465621Z","iopub.execute_input":"2021-05-25T06:56:03.465948Z","iopub.status.idle":"2021-05-25T06:56:03.472949Z","shell.execute_reply.started":"2021-05-25T06:56:03.465924Z","shell.execute_reply":"2021-05-25T06:56:03.472142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Từ [đây](#normalize), ta sẽ chuẩn hóa mọi thông tin là xâu, bao gồm:  \n* **search_term**  \n* **product_title**  \n* **product_description**  \n* **attribute**  \nđiều này có thể được thực hiện bằng hàm **apply(normalize_string)**.  \n  \nDo thời gian chạy khá lâu nên ta import thêm thư viện time để tính xem đã mất bao nhiều thời gian.  \n  \nKết quả thu được là **all_data** đã được chuẩn hóa mọi xâu.","metadata":{}},{"cell_type":"code","source":"import time\n\nstart_time = time.time()\n\nall_data['search_term'] = all_data['search_term'].apply(str).apply(normalize_string)\nall_data['product_title'] = all_data['product_title'].apply(str).apply(normalize_string)\nall_data['product_description'] = all_data['product_description'].apply(str).apply(normalize_string)\nall_data['attribute'] = all_data['attribute'].apply(str).apply(normalize_string)\nprint(all_data.head())\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:32:56.965688Z","iopub.execute_input":"2021-05-25T07:32:56.96598Z","iopub.status.idle":"2021-05-25T07:34:39.040508Z","shell.execute_reply.started":"2021-05-25T07:32:56.965958Z","shell.execute_reply":"2021-05-25T07:34:39.039092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"stem\"></a>\n### Stemming","metadata":{}},{"cell_type":"markdown","source":"Như đã nhắc đến, ta muốn thay những từ gần giống nhau chỉ bằng 1 từ duy nhất (ví dụ như số nhiều, số ít, chia thì, ...), đây gọi là quá trình \"**stemmed**\".  \n  \nTa sẽ sử dụng thư viện đã hỗ trợ của **nltk**, đó là **SnowballStemmer** với ngôn ngữ là english.  \nVới mỗi từ có được bằng hàm **str.split()**, ta thay nó bằng từ gốc (nếu có).  \n  \nKết quả ta được hàm **str_stemmer**, nhận đầu vào là một xâu, và trả về một xâu đã được \"**stemmed**\".  ","metadata":{}},{"cell_type":"code","source":"stemmer = SnowballStemmer('english')\n\ndef str_stemmer(s):\n    return \" \".join([stemmer.stem(word) for word in s.lower().split()])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:35:05.003208Z","iopub.execute_input":"2021-05-25T07:35:05.003615Z","iopub.status.idle":"2021-05-25T07:35:05.008902Z","shell.execute_reply.started":"2021-05-25T07:35:05.003584Z","shell.execute_reply":"2021-05-25T07:35:05.008038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta áp dụng hàm trên vào **all_data** với hàm **apply(str_stemmer)**.  \n  \nTương tự như phần chuẩn hóa xâu, ta cũng đo thời gian chạy.  \n  \nKết quả thu được là **all_data** với các xâu đã chỉ chứa những từ gốc, chứ không còn biến thể nữa.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nall_data['search_term'] = all_data['search_term'].apply(str).apply(str_stemmer)\nall_data['product_title'] = all_data['product_title'].apply(str).apply(str_stemmer)\nall_data['product_description'] = all_data['product_description'].apply(str).apply(str_stemmer)\nall_data['attribute'] = all_data['attribute'].apply(str).apply(str_stemmer)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T07:35:24.843708Z","iopub.execute_input":"2021-05-25T07:35:24.844201Z","iopub.status.idle":"2021-05-25T07:53:02.418822Z","shell.execute_reply.started":"2021-05-25T07:35:24.84417Z","shell.execute_reply":"2021-05-25T07:53:02.417871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"new_quantitative\"></a>\n## Tạo ra một số dữ liệu định lượng","metadata":{}},{"cell_type":"markdown","source":"Để có thể xây dựng thêm các trường thông tin, ta cần biết nó có ảnh hưởng thế nào đến **relevance** - yếu tố ta cần đoán.  \n  \nĐể ý đến độ dài của các trường thông tin văn bản, ta sẽ vẽ thử chúng trên đồ thị và 1 đường **regression**.  \nTa sử dụng thư viện **matplotlib** để vẽ đồ thị này.  \nChi tiết hơn được giải thích trong code.\n  \nTa được một hàm see_correlation vẽ ra sự tương quan giữa độ dài của một trường thông tin bất kỳ với **relevance**. Tham số **transform** sẽ bằng **True** nếu ta muốn lấy độ dài của **data_field**, và bằng **False** nếu ta muốn lấy luôn giá trị của **data_field**.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef see_correlation(data_field, transform=True):\n    # Ta chỉ lấy 1 phần từ dữ liệu ban đầu để cho hiệu quả tốt nhất\n    # Và ta chỉ lấy phần của training_data, thứ chứa relevance\n    data_sample = all_data[:len(training_data) - 1].sample(frac=.1)\n    # Lấy độ dài của trường thông tin\n    x_ar = np.array(data_sample[data_field].map(lambda x:len(str(x).split())).astype(np.int64)) if transform else data_sample[data_field]\n    # Lấy relevance tương ứng\n    y_ar = np.array(data_sample['relevance'])\n    # Vẽ các điểm dữ liệu lên đồ thị\n    plt.plot(x_ar, y_ar, 'o')\n    # Tìm tham số m và b để vẽ đường regression\n    m, b = np.polyfit(x_ar, y_ar, 1)\n    # Vẽ được regression\n    plt.plot(x_ar, m * x_ar + b)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:06.551136Z","iopub.execute_input":"2021-05-25T08:27:06.551712Z","iopub.status.idle":"2021-05-25T08:27:06.560777Z","shell.execute_reply.started":"2021-05-25T08:27:06.551678Z","shell.execute_reply":"2021-05-25T08:27:06.559449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Như đã giải thích ở trên, giờ ta sẽ vẽ thử ra sự tương quan của **relevance** với lần lượt độ dài của từng trường thông tin, bắt đầu với **product_title**.  \n  \nTheo kết quả, các điểm **relevance** phân bố rất đều nhau trên mọi độ dài **product_title**, đường regression gần như đi ngang. Ta có thể nhận xét rằng **product_title** gần như không ảnh hưởng gì đến **relevance** cả.  \n  \nDo đó, do sự không khả quan, sau này ta sẽ không sử dụng đặc trưng này vào khâu huấn luyện.","metadata":{}},{"cell_type":"code","source":"see_correlation('product_title')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:11.939982Z","iopub.execute_input":"2021-05-25T08:27:11.9404Z","iopub.status.idle":"2021-05-25T08:27:12.110918Z","shell.execute_reply.started":"2021-05-25T08:27:11.940376Z","shell.execute_reply":"2021-05-25T08:27:12.108892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Product_title** không mang lại kết quả, ta tiếp tục với **search_term**.  \n  \nTheo kết quả, các điểm relevance phân bố khá đều trên mọi độ dài **search_term**, tuy nhiên lại có nhiều điểm khác thường mà theo xu hướng nào đó. Đường regression có độ dốc khá lớn.  \n  \nTa có thể nhận xét rằng **search_term** có ảnh hưởng đến **relevance**.  \n  \nDo đó, với kết quả khả quan khả quan, ta sẽ sử dụng đặc trưng này vào khâu huấn luyện.  ","metadata":{}},{"cell_type":"code","source":"see_correlation('search_term')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:14.893627Z","iopub.execute_input":"2021-05-25T08:27:14.894026Z","iopub.status.idle":"2021-05-25T08:27:15.433455Z","shell.execute_reply.started":"2021-05-25T08:27:14.893996Z","shell.execute_reply":"2021-05-25T08:27:15.431982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta tiếp tục với **product_description**.  \n  \nTheo kết quả, các điểm relevance phân bố khá đều trên mọi độ dài **product_description**, tuy nhiên lại có nhiều điểm khác thường mà theo xu hướng nào đó.  \nĐường regression có độ dốc đáng cũng khá đáng kể.  \n  \nTa có thể nhận xét rằng **product_description** có ảnh hưởng đến **relevance**.  \n  \nDo đó, cũng với kết quả khả quan khả quan, ta sẽ sử dụng đặc trưng này vào khâu huấn luyện. ","metadata":{}},{"cell_type":"code","source":"see_correlation('product_description')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:17.222127Z","iopub.execute_input":"2021-05-25T08:27:17.222511Z","iopub.status.idle":"2021-05-25T08:27:17.483908Z","shell.execute_reply.started":"2021-05-25T08:27:17.22248Z","shell.execute_reply":"2021-05-25T08:27:17.482594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta tiếp tục với **brand**.  \n  \nTheo kết quả, các điểm **relevance** phân bố khá đều trên mọi độ dài **brand**, tuy nhiên lại có nhiều điểm khác thường mà theo xu hướng nào đó.  \nĐường regression có độ dốc đáng cũng khá đáng kể.  \n  \nTa có thể nhận xét rằng brand có ảnh hưởng đến **relevance**.  \n  \nDo đó, cũng với kết quả khả quan khả quan, ta sẽ sử dụng đặc trưng này vào khâu huấn luyện. ","metadata":{}},{"cell_type":"code","source":"see_correlation('brand')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:20.162071Z","iopub.execute_input":"2021-05-25T08:27:20.162435Z","iopub.status.idle":"2021-05-25T08:27:20.31839Z","shell.execute_reply.started":"2021-05-25T08:27:20.162406Z","shell.execute_reply":"2021-05-25T08:27:20.31705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta tiếp tục với **attribute**.  \n  \nTheo kết quả, các điểm relevance phân bố khá đều trên mọi độ dài **attribute**, tuy nhiên lại có nhiều điểm khác thường mà theo xu hướng nào đó.  \nĐường regression có độ dốc đáng cũng khá đáng kể.  \n  \nTa có thể nhận xét rằng **attribute** có ảnh hưởng đến **relevance**.  \n  \nDo đó, cũng với kết quả khả quan khả quan, ta sẽ sử dụng đặc trưng này vào khâu huấn luyện. ","metadata":{}},{"cell_type":"code","source":"see_correlation('attribute')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:23.244604Z","iopub.execute_input":"2021-05-25T08:27:23.244956Z","iopub.status.idle":"2021-05-25T08:27:23.434006Z","shell.execute_reply.started":"2021-05-25T08:27:23.244931Z","shell.execute_reply":"2021-05-25T08:27:23.432557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dựa vào các đồ thị regression trên, ta thấy chiều dài của các thông tin, trừ **title** và **attribute** cũng có ảnh hưởng đến relevance.  \n  \nDo đó ta đưa thông tin chiều dài title bằng hàm **len(title)** vào thành một trường thông tin khác.  \nĐộ dài của **query**, **brand**, **descrition**, **attribute** cũng tương tự.  \n  \nTa thêm vào **all_data** các thông tin sau, là độ dài các thông tin nội sinh của dữ liệu, bao gồm:\n* **len_of_query**: Số từ (ngăn cách bởi dấu cách) trong cụm từ tìm kiếm  \n* **len_of_brand**: Độ dài số từ trong tên nhãn hiệu  \n* **len_of_description**: Độ dài đoạn văn bản mô tả của sản phẩm  ","metadata":{}},{"cell_type":"code","source":"all_data['len_of_query'] = all_data['search_term'].map(lambda x:len(str(x).split())).astype(np.int64)\n\nall_data['len_of_brand'] = all_data['brand'].map(lambda x:len(str(x).split())).astype(np.int64)\n\nall_data['len_of_description'] = all_data['product_description'].map(lambda x:len(str(x).split())).astype(np.int64)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:16:25.159421Z","iopub.execute_input":"2021-05-25T08:16:25.159796Z","iopub.status.idle":"2021-05-25T08:16:27.029678Z","shell.execute_reply.started":"2021-05-25T08:16:25.159767Z","shell.execute_reply":"2021-05-25T08:16:27.028414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dựa vào chính thực tế sử dụng các công cụ tìm kiếm, ta đoán rằng các search engine thường dựa vào các từ trong **search_term** mà xuất hiện trong văn bản.  \n  \nDo đó, ta sẽ đếm số lượng các từ nằm trong từ khóa tìm kiếm (**search_term**) mà xuất hiện trong:  \n* Tiêu đề: **word_in_title**  \n* Mô tả sản phẩm: **word_in_description**  \n  \nĐể làm được điều này, ta định nghĩa hàm **str_common_word**, nhận vào 2 xâu, trả về số lượng từ trong xâu 1 đã xuất hiện trong xâu 2.  ","metadata":{}},{"cell_type":"code","source":"def str_common_word(str1, str2):\n    return sum([1 if str2.find(word) >= 0 else 0 for word in set(str1.split())])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:20:55.76256Z","iopub.execute_input":"2021-05-25T08:20:55.763018Z","iopub.status.idle":"2021-05-25T08:20:55.770148Z","shell.execute_reply.started":"2021-05-25T08:20:55.762975Z","shell.execute_reply":"2021-05-25T08:20:55.768906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trước tiên ta tạo một trường thông tin là **product_info** để tiện xử lý sau này.  \nThông tin này được gộp từ tất cả các dữ liệu mang thông tin sản phẩm:  \n* **search_term**: Cụm từ tìm kiếm.  \n* **product_title**: Tiêu đề sản phẩm  \n* **product_description**: Mô tả sản phẩm  \n  \nTa gộp chúng lại, phân tách bằng ký tự \"\\t\", để sau này tiện tách ra.  \n  \nKết quả thu được là **all_data** với trường **product_info**.","metadata":{}},{"cell_type":"code","source":"all_data['product_info'] = all_data['search_term'] + '\\t' + all_data['product_title'] + '\\t' + all_data['product_description']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:21:54.054323Z","iopub.execute_input":"2021-05-25T08:21:54.054714Z","iopub.status.idle":"2021-05-25T08:21:54.612399Z","shell.execute_reply.started":"2021-05-25T08:21:54.054684Z","shell.execute_reply":"2021-05-25T08:21:54.610992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta cần tính **word_in_title** và **word_in_description** mà đã nhắc đến bên trên.  \n  \nTừ **product_info**, đầu tiên ta tách 3 thông tin ra bằng hàm split('\\t'), thì kết quả đầu tiên là **search_term**, thứ 2 là **title**, thứ 3 là **description**.  \nTiếp đó, ta sử dụng hàm **str_common_word** đã định nghĩa để đếm số từ trong **search_term** trong lần lượt 2 thông tin **title** và **description**.  \n  \nKết quả là 2 trường thông tin mới trong **all_data**, là **word_in_title** và **word_in_description**.","metadata":{}},{"cell_type":"code","source":"all_data['word_in_title'] = all_data['product_info'].map(lambda x:str_common_word(str(x).split('\\t')[0], str(x).split('\\t')[1]))\nall_data['word_in_description'] = all_data['product_info'].map(lambda x:str_common_word(str(x).split('\\t')[0], str(x).split('\\t')[2]))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:24:45.448551Z","iopub.execute_input":"2021-05-25T08:24:45.448917Z","iopub.status.idle":"2021-05-25T08:24:48.44571Z","shell.execute_reply.started":"2021-05-25T08:24:45.448887Z","shell.execute_reply":"2021-05-25T08:24:48.444591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta muốn đánh giá xem các thông tin mới này có ảnh hưởng đến **relevance** không.\n  \nTa dùng lại hàm **see_correlation**, với tham số thứ 2 là **False**, tức là không cần lấy **len** - độ dài văn bản nữa mà lấy trực tiếp dữ liệu luôn.  \n  \nBắt đầu với **word_in_description**, với đường regression có độ dốc rất lớn, ta thấy nó ảnh hưởng khá nhiều đến **relevance**.  \n  \nĐây sẽ là một thông tin hữu ích mà ta sử dụng cho việc huấn luyện.","metadata":{}},{"cell_type":"code","source":"see_correlation('word_in_description', False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:30.278685Z","iopub.execute_input":"2021-05-25T08:27:30.27906Z","iopub.status.idle":"2021-05-25T08:27:30.437497Z","shell.execute_reply.started":"2021-05-25T08:27:30.279027Z","shell.execute_reply":"2021-05-25T08:27:30.435799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tiếp tục với **word_in_title**, làm tương tự bên trên.  \n  \nTa thấy nó ảnh hưởng khá lớn đến relevance khi đường regression có độ dốc khá lớn, đây cũng sẽ là một thông tin hữu ích.","metadata":{}},{"cell_type":"code","source":"see_correlation('word_in_title', False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:27:32.932445Z","iopub.execute_input":"2021-05-25T08:27:32.932754Z","iopub.status.idle":"2021-05-25T08:27:33.070859Z","shell.execute_reply.started":"2021-05-25T08:27:32.932731Z","shell.execute_reply":"2021-05-25T08:27:33.069327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta thấy một vấn đề, đó là số lượng có thể không phải là một con số cụ thể về sự tương quan giữa các dữ liệu.  \nTa còn cần phải xét đến tỷ lệ xuất hiện trong các ngữ cảnh nữa.  \nCụ thể, dựa vào số đếm vừa tính bên trên, ta tính tỷ lệ các từ xuất hiện trong **search_term** của các trường thông tin sau:  \n* Tiêu đề: **ratio_title**  \n* Mô tả: **ratio_description**  \nViệc tính 2 chỉ số này cũng đơn giản, ta chỉ cần lấy thương của 2 trường thông tin đã có, **word_in_title** / **word_in_description** tương ứng, với mẫu là **all_of_query**.\n  \nKết quả là **all_data** với thêm 2 trường, là **ratio_title** và **ratio_description**.","metadata":{}},{"cell_type":"code","source":"all_data['ratio_title'] = all_data['word_in_title'] / all_data['len_of_query']\nall_data['ratio_description'] = all_data['word_in_description'] / all_data['len_of_query']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:29:27.3035Z","iopub.execute_input":"2021-05-25T08:29:27.303832Z","iopub.status.idle":"2021-05-25T08:29:27.312199Z","shell.execute_reply.started":"2021-05-25T08:29:27.303808Z","shell.execute_reply":"2021-05-25T08:29:27.311314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta muốn biết chúng có ảnh hưởng đến **relevance** hay không. Ta bắt đầu với **ratio_title**.  \n  \nTa tiếp tục sử dụng hàm **see_correlation** như trên.  \n  \nĐường regression chạy từ **relevance** bằng **2.0** đến gần **2.75**, kết quả cho thấy đây là một thông tin rất hữu ích, và ta có thể sử dụng thông tin này như một feature cho việc huấn luyện.","metadata":{}},{"cell_type":"code","source":"see_correlation('ratio_title', False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:30:12.112276Z","iopub.execute_input":"2021-05-25T08:30:12.112553Z","iopub.status.idle":"2021-05-25T08:30:12.263151Z","shell.execute_reply.started":"2021-05-25T08:30:12.112528Z","shell.execute_reply":"2021-05-25T08:30:12.262108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta muốn biết **ratio_description** có ảnh hưởng đến **relevance** hay không.  \n  \nTa tiếp tục sử dụng hàm **see_correlation** như trên.  \n  \nĐường regression chạy từ **relevance** bằng **2.0** đến hơn **2.5**, kết quả cho thấy đây là một thông tin rất hữu ích, và ta có thể sử dụng thông tin này như một feature cho việc huấn luyện.","metadata":{}},{"cell_type":"code","source":"see_correlation('ratio_description', False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:31:18.176407Z","iopub.execute_input":"2021-05-25T08:31:18.1769Z","iopub.status.idle":"2021-05-25T08:31:18.335797Z","shell.execute_reply.started":"2021-05-25T08:31:18.176868Z","shell.execute_reply":"2021-05-25T08:31:18.334194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hiện tại, còn duy nhất một thông tin mà ta chưa nhắc đến, đó là bản thân văn bản của **description**, **brand**, và **attribute**.  \n  \nĐể sử dụng cho bước sau, ta gộp tiếp 3 trường thông tin: **descriptions**, **brand**, **attribute** lại thành một.  \n  \nKết quả là **all_data** có thêm trường **prod_desc_merge**.","metadata":{}},{"cell_type":"code","source":"all_data[\"prod_desc_merge\"] = all_data[\"product_description\"].map(str) +' ' + all_data[\"brand\"].fillna('') + ' ' + all_data[\"attribute\"].fillna('').map(str)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:32:55.70686Z","iopub.execute_input":"2021-05-25T08:32:55.70725Z","iopub.status.idle":"2021-05-25T08:32:56.944743Z","shell.execute_reply.started":"2021-05-25T08:32:55.707219Z","shell.execute_reply":"2021-05-25T08:32:56.943519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ta nhận thấy trong quá trình, có rất nhiều cột đã được sinh mới ra nhưng không dùng đến, hoặc chúng đã được gộp lại để tiện xử lý.  \n  \nTa tạo một cells để xóa chúng đi, sử dụng làm **pandas.DataFrame.drop(inplace=True, axis=1)**, tức là xóa theo cột, và xóa luôn trong **all_data**.  \n  \nKết quả thu được là **all_data** chỉ còn các trường thông tin mà ta cho là hữu ích.","metadata":{}},{"cell_type":"code","source":"for column in [\"attr\", \"product_description\", \"brand\", \"attribute\", \"product_attributes\", \"product_info\", 'last_word_title_match', 'first_word_title_match', 'last_word_description_match', 'first_word_description_match']:\n    if column in all_data:\n        if column in all_data:\n            all_data.drop(column, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:38:18.679955Z","iopub.execute_input":"2021-05-25T08:38:18.680513Z","iopub.status.idle":"2021-05-25T08:38:19.07135Z","shell.execute_reply.started":"2021-05-25T08:38:18.680463Z","shell.execute_reply":"2021-05-25T08:38:19.070292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_representation\"></a>\n# Biểu diễn dữ liệu","metadata":{}},{"cell_type":"markdown","source":"<a id=\"tfidf\"></a>\n## TF-IDF","metadata":{}},{"cell_type":"markdown","source":"Hiện ta cần biểu diễn các dữ liệu xâu cuối cùng thành số, bao gồm **search_term**, **product_title**, và **prod_desc_merge**.  \n  \nỞ bước này, ta sử dụng **tf-idf**.  \n  \n**TF-iDF** là một phép thống kê, với tác dụng phản ánh tầm quan trọng của một từ / dấu hiệu (token) với tập hợp văn bản. Giá trị của **tf-idf** tăng tỷ lệ thuận với số lần xuất hiện của từ đó trong tài liệu, và được giảm đi với số lượng các văn bản chứa từ / dấu hiệu này. Mô hình này cũng được cung cấp trong thư viện scikit-learn.  \n  \nKết quả thu được sau cell này là một object **tfidf** với **ngram_range** là 1 đến 2, tức là xét các từ đơn và từ ghép 2 từ, cùng với đó là loại bỏ các **stop_words** trong tiếng Anh.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:42:25.476044Z","iopub.execute_input":"2021-05-25T08:42:25.476355Z","iopub.status.idle":"2021-05-25T08:42:25.480469Z","shell.execute_reply.started":"2021-05-25T08:42:25.47633Z","shell.execute_reply":"2021-05-25T08:42:25.479726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"svd\"></a>\n## TruncatedSVD","metadata":{}},{"cell_type":"markdown","source":"Số chiều của các dữ liệu cũng rất lớn.  \n  \nĐể xử lý việc này, làm cho tốc độ xử lý được nhanh hơn, ta sử dụng **TruncatedSVD** để giảm chiều của dữ liệu.  \n  \nKết quả sau cell này là một object của **truncatedSVD** với số chiều là 100 - con số tôi thử nghiệm mà đem lại kết quả khả quan trong thời gian chấp nhận được.","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\nsvd = TruncatedSVD(n_components=100, random_state = 2021)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:42:27.677057Z","iopub.execute_input":"2021-05-25T08:42:27.677379Z","iopub.status.idle":"2021-05-25T08:42:27.722268Z","shell.execute_reply.started":"2021-05-25T08:42:27.677353Z","shell.execute_reply":"2021-05-25T08:42:27.721615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"tfidf_svd\"></a>\n## Pipeline của dữ liệu","metadata":{}},{"cell_type":"markdown","source":"Giờ ta muốn dữ liệu sẽ được xử lý lần lượt bằng **tfidf** và **svd**, tuy nhiên việc viết fit 2 lần sẽ làm ta code bất tiện hơn.  \n  \nDo đó ta sử dụng **PipeLine** từ thư viện **sklearn**, cho ta nối **tfidf** với **svd**.  \n  \nKết quả của cell là một pipeline, cho phép dữ liệu đầu vào đi qua mọi khâu trong **pipeline**, rất thuận tiện cho việc xử lý.","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npipe = Pipeline(steps=[('tfidf', tfidf), ('svd', svd)])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:43:55.742231Z","iopub.execute_input":"2021-05-25T08:43:55.74252Z","iopub.status.idle":"2021-05-25T08:43:55.752399Z","shell.execute_reply.started":"2021-05-25T08:43:55.742496Z","shell.execute_reply":"2021-05-25T08:43:55.750162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ở bước này, như đã nói, ta xử lý:\n* **product_title**  \n* **search_term**  \n* **prod_desc_merge**  \nvới pipeline ở trên, thông qua hàm **pipe.fit_transform(input_data)**.  \n  \nKết quả là các trường thông tin trên được biểu diễn dưới dạng máy có thể dễ dàng hiểu được, chuẩn bị cho khâu huấn luyện.  \n  \nNgoài ra, khâu này cũng sẽ mất nhiều thời gian nên tôi muốn đo thời gian chạy bằng thư viện time.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nall_data[\"product_title\"] = pipe.fit_transform(all_data[\"product_title\"])\nall_data[\"search_term\"] = pipe.fit_transform(all_data[\"search_term\"])\nall_data[\"prod_desc_merge\"] = pipe.fit_transform(all_data[\"prod_desc_merge\"])\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:45:37.93494Z","iopub.execute_input":"2021-05-25T08:45:37.935259Z","iopub.status.idle":"2021-05-25T08:52:34.889663Z","shell.execute_reply.started":"2021-05-25T08:45:37.935228Z","shell.execute_reply":"2021-05-25T08:52:34.888717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n\n# with open('processed_transformed.data', 'wb') as picklefile:\n#     pickle.dump(all_data, picklefile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n\n# with open('../input/processed-data-sets/processed_transformed.data', 'rb') as object_to_be_loaded:\n#     all_data = pickle.load(object_to_be_loaded)\n    \n# print(len(all_data))\n# all_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"loss\"></a>\n## Hàm mất mát","metadata":{}},{"cell_type":"markdown","source":"Giờ ta cần một hàm đánh giá sai số của mô hình.  \n  \nNhư đề bài đã mô tả cách đánh giá kết quả, ta cũng sử dụng hàm **mean_squared_error**, đã được cung cấp trong thư viện scikit-learn.  \nTa cũng sử dụng hàm **make_scorer** trong thư viện này để tạo ra một đối tượng để thư viện huấn luyện gọi được, với tham số **greater_is_better=False**, tức là hàm càng trả về kết quả nhỏ thì càng tốt.  \n  \nKết quả của cell này là định nghĩa hàm **fmean_square_error** và đối tượng **RMSE** để sau này sử dụng cho việc đánh giá sai số của mô hình.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, make_scorer\n\ndef fmean_squared_error(ground_truth, predictions):\n    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.1\n    return fmean_squared_error_\n\nRMSE = make_scorer(fmean_squared_error, greater_is_better=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:52:34.891162Z","iopub.execute_input":"2021-05-25T08:52:34.89172Z","iopub.status.idle":"2021-05-25T08:52:34.897905Z","shell.execute_reply.started":"2021-05-25T08:52:34.891677Z","shell.execute_reply":"2021-05-25T08:52:34.896567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_split\"></a>\n## Phân tách dữ liệu train-test","metadata":{}},{"cell_type":"markdown","source":"Hiện giờ mọi dữ liệu đều đã được xử lý, tuy nhiên chúng ta lại cần tách ra dưới dạng **training_data** và **testing_data**.  \n  \nTa dùng hàm **all_data.iloc** để tách lại dữ liệu **train** và **test**.  \nBởi thứ tự của các mẫu không thay đổi, ta chỉ đơn giản là lấy theo số lượng mẫu trong **training_data**.  \n  \nKết quả sau cell này là 2 dataFrames, **df_train** - dữ liệu dùng để train, và **df_test** - dữ liệu test để lấy kết quả nộp bài.","metadata":{}},{"cell_type":"code","source":"df_train = all_data.iloc[:len(training_data)]\ndf_test = all_data.iloc[len(training_data):]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:52:34.899581Z","iopub.execute_input":"2021-05-25T08:52:34.90011Z","iopub.status.idle":"2021-05-25T08:52:34.918687Z","shell.execute_reply.started":"2021-05-25T08:52:34.900073Z","shell.execute_reply":"2021-05-25T08:52:34.917182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta cần tách rõ ràng **X_train**, **X_test**, **y_train** để huấn luyện.  \n  \nTa sẽ lấy các thông tin này như sau:  \n* X_train: là **df_train**, nhưng không có trường **relevance**  \n* y_train: là **df_train** chỉ với trường **relevance**  \n* X_test: là **df_test**, nhưng không có trường **relevance**  \n  \nNgoài ra, ta còn tạo thêm một dữ liệu khác, là **id_test**, để thực hiện việc lấy kết quả dự doán và submit sau này.  \n  \nKết quả sau cell này là các dữ liệu **X_train**, **X_test**, **y_train**, và **id_test** như đã mô tả.","metadata":{}},{"cell_type":"code","source":"# là df_train, nhưng không có trường relevance \nX_train = df_train.drop('relevance', axis=1)\n# là df_train chỉ với trường relevance\ny_train = df_train['relevance'].values\n# là df_test, nhưng không có trường relevance\nX_test = df_test.drop('relevance', axis=1)\n\n# id_test để thực hiện dự đoán và submit kết quả sau này\nid_test = df_test['id']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:55:50.654376Z","iopub.execute_input":"2021-05-25T08:55:50.654939Z","iopub.status.idle":"2021-05-25T08:55:50.676634Z","shell.execute_reply.started":"2021-05-25T08:55:50.654897Z","shell.execute_reply":"2021-05-25T08:55:50.675214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Huấn luyện mô hình","metadata":{}},{"cell_type":"markdown","source":"<a id=\"model_selection\"></a>\n## Khởi tạo mô hình ","metadata":{}},{"cell_type":"markdown","source":"Giờ ta chỉ cần định nghĩa, thử nghiệm các mô hình.  \n  \nĐầu tiên, tôi muốn thử **GradientBoostingRegressor**, một mô hình ensemble khá nổi tiếng, đã được cung cấp trong thư viện scikit-learn.  \n  \nKết quả là một object của mô hình **GBR** này.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:57:46.820345Z","iopub.execute_input":"2021-05-25T08:57:46.820809Z","iopub.status.idle":"2021-05-25T08:57:46.999049Z","shell.execute_reply.started":"2021-05-25T08:57:46.820775Z","shell.execute_reply":"2021-05-25T08:57:46.998125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"find_best_param\"></a>\n## Tìm tham số tối ưu","metadata":{}},{"cell_type":"markdown","source":"Mô hình để chạy tốt được cần phải có bộ tham số tối ưu.  \n  \nQua tham khảo, tôi thấy có 2 trường thông tin quan trọng có thể hiệu chỉnh, đó là **n_estimators** và **max_depth**:\n* **n_estimators**: Số lượng khâu boost cần thực hiện. Vì tốc độ, và qua tham khảo, tôi muốn lấy n_estimators là các số nguyên trong khoảng 30-40, với hàm **numpy.linspace**.     \n* **max_depth**: Độ sâu giới hạn của các node. Theo tham khảo, tôi thử nghiệm trên các số {2, 4, 6, 8, 10}, với hàm **numy.linspace**.     \n  \nKết quả của cell này là một dictionary mang các tham số cần hiệu chỉnh cho cell sau.","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    'n_estimators' : np.array([int(e) for e in np.linspace(30, 40, 11)]),\n    'max_depth': np.array([int(e) for e in np.linspace(2, 10, 5)])\n}","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:57:51.094455Z","iopub.execute_input":"2021-05-25T08:57:51.094784Z","iopub.status.idle":"2021-05-25T08:57:51.100731Z","shell.execute_reply.started":"2021-05-25T08:57:51.094759Z","shell.execute_reply":"2021-05-25T08:57:51.099386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ ta cần chạy mô hình nhiều lần để tìm được bộ tham số tối ưu.  \n  \nThư viện scikit-learn đã cung cấp class **GridSearchCV** cho việc này. Ta sẽ truyền vào đối tượng cần tối ưu là **gbr** đã định nghĩa bên trên, **param_gid=param_grid** đã định nghĩa, là bộ các tham số cần tìm tối ưu, hàm điểm **scorring=RMSE** đã định nghĩa trước đó, với **cv=3**, là 3 lần kiểm định chéo **cross-validation**.  \n  \nKết quả cell này là đối tượng gs để tìm bộ tham số tối ưu.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ngs = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=3, scoring=RMSE)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:04:57.620253Z","iopub.execute_input":"2021-05-25T09:04:57.620595Z","iopub.status.idle":"2021-05-25T09:04:57.625964Z","shell.execute_reply.started":"2021-05-25T09:04:57.620571Z","shell.execute_reply":"2021-05-25T09:04:57.62514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giờ công việc của ta là chạy object **gs** với **X_train**, đối chiếu trên **y_train**, để tìm ra bộ tham số tối ưu.  \n  \nTa sử dụng hàm **gs.fit(X_train, y_train)**.  \n  \nKết quả của cell này là object **gs** đã chứa những tham số, và điểm tối ưu có được trong các khâu cross-validation.  ","metadata":{}},{"cell_type":"code","source":"%time _ = gs.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:05:00.619108Z","iopub.execute_input":"2021-05-25T09:05:00.619512Z","iopub.status.idle":"2021-05-25T09:34:18.756202Z","shell.execute_reply.started":"2021-05-25T09:05:00.619488Z","shell.execute_reply":"2021-05-25T09:34:18.755127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Như đã nói ở cell trên, giờ ta chỉ việc in ra bộ tham số tối ưu.  \n  \nTa sẽ gọi **gs.best_params_** để in ra bộ tham số tối ưu, và **gs.best_score_** để in ra điểm tối ưu đã đạt được.  \n  \nKết quả của cell này sẽ được lấy để huấn luyện mô hình cuối và dự đoán kết quả cuối cùng, nộp lên kaggle để tính điểm.","metadata":{}},{"cell_type":"code","source":"gs.best_params_, gs.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:34:18.758306Z","iopub.execute_input":"2021-05-25T09:34:18.758673Z","iopub.status.idle":"2021-05-25T09:34:18.764281Z","shell.execute_reply.started":"2021-05-25T09:34:18.758614Z","shell.execute_reply":"2021-05-25T09:34:18.76372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"best_param_training\"></a>\n## Huấn luyện mô hình với tham số tối ưu","metadata":{}},{"cell_type":"markdown","source":"Giờ ta cần định nghĩa mô hình cuối cùng, dựa trên bộ tham số tối ưu đã có.  \n  \nTa khởi tạo lại **gbr_best** bằng **GradientBoostingRegressor**, với bộ tham số tối ưu có bên trên.  \nSau cùng, ta gọi hàm **gbr_best.fit(X_train, y_train)** để huấn luyện mô hình.  \n  \nKết quả là mô hình GradientBoostingRegressor tối ưu mà ta sẽ sử dụng để dự đoán dữ liệu test, còn nộp lên lấy kết quả.","metadata":{}},{"cell_type":"code","source":"gbr_best = GradientBoostingRegressor(max_depth=gs.best_params_['max_depth'],\n                                     n_estimators=gs.best_params_['n_estimators'])\n\ngbr_best.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:31.657022Z","iopub.execute_input":"2021-05-25T09:38:31.657415Z","iopub.status.idle":"2021-05-25T09:38:50.181456Z","shell.execute_reply.started":"2021-05-25T09:38:31.657383Z","shell.execute_reply":"2021-05-25T09:38:50.180725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"prediction\"></a>\n## Dự đoán kết quả và nộp","metadata":{}},{"cell_type":"markdown","source":"Giờ công việc của là cần dự đoán kết quả của **X_test**.  \n  \nTa gọi **gbr_best.predit(X_test)** để được kết quả dự đoán.  \n  \nKết quả là **y_pred** mang các giá trị **relevance** mà ta dự đoán được.","metadata":{}},{"cell_type":"code","source":"y_pred = gbr_best.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:50.182789Z","iopub.execute_input":"2021-05-25T09:38:50.183216Z","iopub.status.idle":"2021-05-25T09:38:50.419304Z","shell.execute_reply.started":"2021-05-25T09:38:50.183183Z","shell.execute_reply":"2021-05-25T09:38:50.418712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cuối cùng, ta cần lưu lại file output theo đúng format để nộp.  \n  \nTa sử dụng hàm **pandas.DataFrame.to_csv** để lưu lại file, với 2 trường thông tin là **id** và **relevance** - **y_pred** đã tính được.  ","metadata":{}},{"cell_type":"code","source":"pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission_gbr.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:50.420752Z","iopub.execute_input":"2021-05-25T09:38:50.421174Z","iopub.status.idle":"2021-05-25T09:38:50.865216Z","shell.execute_reply.started":"2021-05-25T09:38:50.421133Z","shell.execute_reply":"2021-05-25T09:38:50.863982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"result\"></a>\n# Kết quả  \n  \nPrivate score là **0.48009**","metadata":{}}]}