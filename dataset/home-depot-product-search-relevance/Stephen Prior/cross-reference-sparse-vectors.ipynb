{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nfrom nltk.collocations import *\nimport scipy\n\ndef LoadFiles(training_filename, description_filename):\n    df = pd.read_csv(training_filename, encoding=\"ISO-8859-1\")\n    #samples limited to reduce runtime - but this impacts quality of feature extraction\n    df = df.sample(5000)\n\n    df[\"search_term\"] = df[\"search_term\"].str.lower()\n    df[\"product_title\"] = df[\"product_title\"].str.lower()\n\n    descr = pd.read_csv(description_filename,encoding=\"ISO-8859-1\")\n    descr[\"product_description\"] = descr[\"product_description\"].str.lower()\n    df = df.merge(descr, on=\"product_uid\")\n    df = df.assign(prod_complete = lambda x: (x['product_title'] + ' ' + x['product_description']))\n    return df   \n\n#T\nclass cross_ref:\n\n    def __init__(self):\n        self.df = pd.DataFrame()\n        \n    def fit(self, X,y):  \n        from sklearn.feature_extraction.text import CountVectorizer\n        from sklearn.feature_extraction.text import TfidfTransformer\n        import sklearn\n        self.vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=1, max_df = 0.2)\n        search_counts = self.vectorizer.fit_transform(X[\"search_term\"])\n        distinct_title_counts = self.vectorizer.transform(X[\"product_title\"].drop_duplicates())\n        distinct_descr_counts = self.vectorizer.transform(\n            X[\"product_description\"].drop_duplicates())\n        feature_counts = scipy.sparse.vstack(\n            [search_counts,distinct_title_counts,distinct_descr_counts])\n        self.tfidf = TfidfTransformer()\n        self.tfidf.fit(feature_counts)\n        from sklearn.pipeline import make_pipeline\n        self.pipeline = make_pipeline(self.vectorizer, self.tfidf)\n        self.search_vecs = self.pipeline.transform(X[\"search_term\"])\n        self.title_vecs = self.pipeline.transform(X[\"prod_complete\"])\n        self.common_vecs = self.search_vecs.multiply(self.title_vecs)\n\n        from sklearn import linear_model\n        from sklearn import cross_validation\n        clf = linear_model.Ridge (alpha = 0.5)\n        self.fitted_clf = clf.fit(self.common_vecs,y)\n\n\n    def transform(self,X):\n        return self.fitted_clf(X)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df = LoadFiles('../input/train.csv','../input/product_descriptions.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"y=df['relevance']\n\ncr = cross_ref()\ncr.fit(df,y)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"cr.common_vecs = cr.search_vecs.multiply(cr.title_vecs)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"cr.common_vecs"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n\ndf['sums'] = cr.common_vecs.sum(axis=1)\ndf['counts'] = cr.common_vecs.getnnz(axis=1)\ndf['mean'] = df['sums'] / df['counts']\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df[df['relevance'] < 1.5].sample(3)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df[df['relevance'] > 2.5].sample(3)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"notrelevant = df[df['relevance'] < 1.5]\nrelevant = df[df['relevance'] > 2.5]\nnotrelevant['sums'].mean()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"relevant['sums'].mean()\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.scatter(df['relevance'],df['sums'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.scatter(df['relevance'],df['counts'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.scatter(df['relevance'],df['maxes'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#whats in bottom right of these\ndf[(df['relevance'] > 2.5) & (df['sums']<0.1)].sample(10)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"srch_sum = cr.search_vecs.sum(axis=1)\ndf['srch_sum'] = srch_sum"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.scatter(df['relevance'],df['sums']/df['srch_sum'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.scatter(df['relevance'], df['mean'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}