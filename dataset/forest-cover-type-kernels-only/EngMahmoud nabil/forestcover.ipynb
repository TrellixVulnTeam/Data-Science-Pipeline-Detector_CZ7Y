{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this project ,we will try to predict the forest cover type ,inorder to achieve this goal we first need to explore and imporve each section in the database using pandas for data proccessing and matplotlib for data anlysis on graphs."},{"metadata":{},"cell_type":"markdown","source":"We start by importing the libraries we will use."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n%matplotlib inline\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\n\nfrom sklearn.decomposition import PCA\nfrom sklearn import ensemble\nfrom sklearn.ensemble import RandomForestClassifier\n#from scipy.stats import linregress\nimport scipy\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.import zipfilepath.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"importing the database csv file and getting a general overview of the dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\n\nzf=zipfile.ZipFile('/kaggle/input/forest-cover-type-kernels-only/train.csv.zip')\nzf2=zipfile.ZipFile('/kaggle/input/forest-cover-type-kernels-only/test.csv.zip')\n\nsample_submission= pd.read_csv('../input/forest-cover-type-kernels-only/sample_submission.csv.zip')\nsampleSubmission= pd.read_csv('../input/forest-cover-type-kernels-only/sampleSubmission.csv.zip')\ntrain= pd.read_csv(zf.open('train.csv'))\ntest= pd.read_csv(zf2.open('test.csv'))\n\nprint('train (r,c)=',train.shape)\nprint('test (r,c)=',test.shape)\nprint('sample_submission (r,c)=',sample_submission.shape)\nprint('sampleSubmission (r,c)=',sampleSubmission.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overview of train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head().describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overview of test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head().describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Overview of sample_submission dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head().describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overview of sampleSubmission dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmission.head().describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now based on our observation of the dataset we will change its indexing to be based on the ID ."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmission.set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to identify the data values with Nan values in the train dataset that we will work with and replace them with 'unkown'."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of null values in the dataset=', len(train[train.isnull()]) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Replacing the null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna('unknown')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will make a simple graph to see the realation between Elevation and Aspect by making a perfect fit line in each graph.\nBy this perfect fit line we will be able to judge the realtionship between Elevation and Aspect."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train.Elevation, train.Aspect)\nplt.show()\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see its hard to judge the realationship between them by ploting them as raw data so we will only use thier mean,number,min and max"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first we group the data by its elevation and compare it by the number of aspects , minumin of aspects and max of aspects\np=train.groupby(['Elevation']).Aspect.agg([len, min, max])\n\n#plt.scatter(p)\nplt.plot(p.len)\nplt.xlabel('Elevation')\nplt.ylabel('Number of Apects')\nplt.show()  # or plt.savefig(\"name.png\")\n# plt.scatter(x, y)\n# y = train.\n# z=\n# plt.scatter(train.Elevation, )\n# plt.show()  # or plt.savefig(\"name.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=train.groupby(['Elevation']).Aspect.mean()\np.astype('int')\nplt.plot(p)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.Elevation.mean()\nplt.scatter(x,train.Aspect.mean())\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now to the main task which is clarifying each tree cover type according to its ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"#row1 is Id OF train row2 is Id of Cover_Type\n# def add(row1,row2) :\n#     if (row1.Id == row2.Id):\n#         x= pd.concat([row1, row2.Cover_Type])\n#     else:\n#         print('unkown value')\n#     return x    \n# ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left= train.set_index('Id')\nright= sample_submission.set_index('Id')\noutput=left.join(right, lsuffix='_')\nfinal_data = output.drop(columns=\"Cover_Type\")\nfinal_data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submiting the final output"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data.to_csv('FinalSampleSubmition', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}