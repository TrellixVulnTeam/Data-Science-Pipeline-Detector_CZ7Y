{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Restrict minor warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n# 读入数据\ndf_train = pd.read_csv('../input/train.csv')\ndf_Test = pd.read_csv('../input/test.csv')\ndf_test = df_Test\n# 删除无效特征\ndf_train = df_train.drop(['Soil_Type7', 'Soil_Type15','Soil_Type8', 'Soil_Type25'], axis = 1)\ndf_test = df_test.drop(['Soil_Type7', 'Soil_Type15','Soil_Type8', 'Soil_Type25'], axis = 1)\n\n# 去掉 'Id'列\ndf_train = df_train.iloc[:,1:]\ndf_test = df_test.iloc[:,1:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d32fb5d2f636cc15d706694d8a850be0eb21729f"},"cell_type":"code","source":"# 设置变量\nSize = 10\nX_temp = df_train.iloc[:,:Size]\nX_test_temp = df_test.iloc[:,:Size]\nr,c = df_train.shape\nX_train = np.concatenate((X_temp,df_train.iloc[:,Size:c-1]),axis=1)\ny_train = df_train.Cover_Type.values\nr,c = df_test.shape\nX_test = np.concatenate((X_test_temp, df_test.iloc[:,Size:c]), axis = 1)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nx_data, x_test_data, y_data, y_test_data = train_test_split(X_train, y_train, test_size = 0.3)\nrf_para = [{'n_estimators':[50, 100], 'max_depth':[5,10,15], 'max_features':[0.1, 0.3], \\\n           'min_samples_leaf':[1,3], 'bootstrap':[True, False]}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee13397db31e4395b6f2be44314078070a75cd68"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nrfc = GridSearchCV(RandomForestClassifier(), param_grid=rf_para, cv = 10, n_jobs=-1)\nrfc.fit(x_data, y_data)\nrfc.best_params_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"285fdf9f553993537ef0e4440c7b79a87acf6303"},"cell_type":"code","source":"print ('Best accuracy obtained: {}'.format(rfc.best_score_))\nprint ('Parameters:')\nfor key, value in rfc.best_params_.items():\n    print('\\t{}:{}'.format(key,value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97859629d81878ac827e445f6b8dc5bb52042d34"},"cell_type":"code","source":"RFC = RandomForestClassifier(n_estimators=100, max_depth=10, max_features=0.3, bootstrap=True, min_samples_leaf=1,\\\n                             n_jobs=-1)\nRFC.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a34fd7e37bbc489e96b1b8e4778156bc1bd9f915"},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\ndef plot_learning_curve(model,title, X, y,n_jobs = 1, ylim = None, cv = None,train_sizes = np.linspace(0.1, 1, 5)):\n    \n    # Figrue parameters\n    plt.figure(figsize=(10,8))\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('Training Examples')\n    plt.ylabel('Score')\n    \n    train_sizes, train_score, test_score = learning_curve(model, X, y, cv = cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    \n    # Calculate mean and std\n    train_score_mean = np.mean(train_score, axis=1)\n    train_score_std = np.std(train_score, axis=1)\n    test_score_mean = np.mean(test_score, axis=1)\n    test_score_std = np.std(test_score, axis=1)\n    \n    plt.grid()\n    plt.fill_between(train_sizes, train_score_mean - train_score_std, train_score_mean + train_score_std,\\\n                    alpha = 0.1, color = 'r')\n    plt.fill_between(train_sizes, test_score_mean - test_score_std, test_score_mean + test_score_std,\\\n                    alpha = 0.1, color = 'g')\n    \n    plt.plot(train_sizes, train_score_mean, 'o-', color=\"r\", label=\"Training score\")\n    plt.plot(train_sizes, test_score_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n    \n    plt.legend(loc = \"best\")\n    return plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d4c22c930b047fa4639e7580bdfef150bdd1d04"},"cell_type":"code","source":"title = 'Learning Curve(Random Forest)'\nmodel = RFC\ncv = ShuffleSplit(n_splits=50, test_size=0.2,random_state=0)\nplot_learning_curve(model,title,X_train, y_train, n_jobs=-1,ylim=None,cv=cv)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a40a6c8c34f957dca9522f15028a979c2ad17012"},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n#from sklearn.cross_validation import StratifiedKFold\nfrom scipy.stats import randint, uniform\nfrom sklearn.model_selection import train_test_split\nx_data, x_test_data, y_data, y_test_data = train_test_split(X_train, y_train, test_size = 0.3,random_state=123)\n\neval_set = [(x_test_data, y_test_data)]\n\nXGBC = XGBClassifier(silent=1,n_estimators=641,learning_rate=0.2,max_depth=10,gamma=0.5,nthread=-1,\\\n                    reg_alpha = 0.05, reg_lambda= 0.35, max_delta_step = 1, subsample = 0.83, colsample_bytree = 0.6)\n# Calculating error\nXGBC.fit(x_data, y_data, early_stopping_rounds=100, eval_set=eval_set, eval_metric='merror', verbose=True)\n\npred = XGBC.predict(x_test_data)\n\naccuracy = accuracy_score(y_test_data, pred);\nprint ('accuracy:%0.2f%%'%(accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebb7d9c15be2f2f98bb035c0ff502628b8099775"},"cell_type":"code","source":"xgbc_pred= XGBC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f50396a9c01150352dad836a0f27460cbbc0271"},"cell_type":"code","source":"solution = pd.DataFrame({'Id':df_Test.Id, 'Cover_Type':xgbc_pred}, columns = ['Id','Cover_Type'])\nsolution.to_csv('result_sol.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}