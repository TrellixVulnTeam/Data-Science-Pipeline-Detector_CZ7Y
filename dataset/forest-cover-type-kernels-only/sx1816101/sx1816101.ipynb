{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nfrom pandas.tools.plotting import parallel_coordinates\nfrom sklearn.decomposition import PCA\nfrom sklearn import ensemble\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.drop(['Id'], inplace = True, axis = 1 )\ntrain.drop(['Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\ntest.drop(['Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\n\nprint('size of train data',train.shape)\nprint('size of test data',test.shape)\n\ntrain.head()\ntrain.info()\n\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of forest categories(Target Variable)\")\nax = sns.distplot(train[\"Cover_Type\"])\n\nsns.FacetGrid(train, hue=\"Cover_Type\", size=10).map(plt.scatter, \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\").add_legend()\n\nplt.figure(figsize=(15,15))\nsns.heatmap(train.corr(),fmt=\".2f\",cmap=\"YlGnBu\")\n\ntemp = train[['Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Cover_Type']]\nplt.figure(figsize=(15,11))\nparallel_coordinates(temp,'Cover_Type', colormap=plt.get_cmap(\"Set1\"))\nplt.title(\"parallel plots of Hillshade with forest categories\")\nplt.xlabel(\"Hillshade\")\nplt.show()\n\ntrain.describe()\n\nsoil_list = []\nsoil_not=[7,8,15,25]\nfor i in range(1, 41):\n    if i not in soil_not:\n       soil_list.append('Soil_Type' + str(i))\n\nwilderness_area_list = ['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']\n\nprint(soil_list, \"\\n\")\nprint(wilderness_area_list)\n\n\npca = PCA(n_components=3) # for simplicity i choose 3\npca_results = pca.fit_transform(train.drop([\"Cover_Type\"], axis=1))\ncmap = sns.cubehelix_palette(as_cmap=True)\ntp, ax = plt.subplots(figsize=(20,15))\ntemp = ax.scatter(pca_results[:,0], pca_results[:,1], c=train.Cover_Type, s=50, cmap=cmap)\ntp.colorbar(temp)\nplt.show()\n\n# Feature engineering 特征工程\n# Training data\ntrain['HF1'] = train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Fire_Points']\ntrain['HF2'] = abs(train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Fire_Points'])\ntrain['HR1'] = abs(train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Roadways'])\ntrain['HR2'] = abs(train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Roadways'])\ntrain['FR1'] = abs(train['Horizontal_Distance_To_Fire_Points']+train['Horizontal_Distance_To_Roadways'])\ntrain['FR2'] = abs(train['Horizontal_Distance_To_Fire_Points']-train['Horizontal_Distance_To_Roadways'])\ntrain['ele_vert'] = train.Elevation-train.Vertical_Distance_To_Hydrology\n# 毕达哥拉斯定理\ntrain['slope_hyd'] = (train['Horizontal_Distance_To_Hydrology']**2+train['Vertical_Distance_To_Hydrology']**2)**0.5\ntrain.slope_hyd=train.slope_hyd.map(lambda x: 0 if np.isinf(x) else x)\n# Means distance to amenities\ntrain['Mean_Amenities']=(train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Roadways) / 3  \ntrain['Mean_Fire_Hyd']=(train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology) / 2 \n# Testing data\ntest['HF1'] = test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Fire_Points']\ntest['HF2'] = abs(test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Fire_Points'])\ntest['HR1'] = abs(test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Roadways'])\ntest['HR2'] = abs(test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Roadways'])\ntest['FR1'] = abs(test['Horizontal_Distance_To_Fire_Points']+test['Horizontal_Distance_To_Roadways'])\ntest['FR2'] = abs(test['Horizontal_Distance_To_Fire_Points']-test['Horizontal_Distance_To_Roadways'])\ntest['ele_vert'] = test.Elevation-test.Vertical_Distance_To_Hydrology\n# Pythagoras theorem\ntest['slope_hyd'] = (test['Horizontal_Distance_To_Hydrology']**2+test['Vertical_Distance_To_Hydrology']**2)**0.5\ntest.slope_hyd=test.slope_hyd.map(lambda x: 0 if np.isinf(x) else x) # remove infinite value if any\n# Means\ntest['Mean_Amenities']=(test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Roadways) / 3 \ntest['Mean_Fire_Hyd']=(test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Hydrology) / 2\n\n\n\ntrain.head()\n\nfrom sklearn.model_selection import train_test_split\nx = train.drop(['Cover_Type'], axis = 1)\ny = train['Cover_Type']\nprint( y.head() )\nx_train, x_test, y_train, y_test = train_test_split( x.values, y.values, test_size=0.05, random_state=42 )\nunique, count= np.unique(y_train, return_counts=True)\nprint(\"The number of occurances of each class in the dataset = %s \" % dict (zip(unique, count) ), \"\\n\" )\n\nfrom sklearn import datasets\nfrom sklearn import metrics\n# load the iris datasets\ndataset = datasets.load_iris()\n# fit an Extra Trees model to the data\nclf = ExtraTreesClassifier()\nclf.fit(x_train,y_train)\n# display the relative importance of each attribute\nz = clf.feature_importances_\n#make a dataframe to display every value and its column name\ndf = pd.DataFrame()\nprint(len(z))\nprint(len(list(x.columns.values)))\n\ndf[\"values\"] = z\ndf['column'] = list(x.columns.values)\n# Sort then descendingly to get the worst features at the end\ndf.sort_values(by='values', ascending=False, inplace = True)\ndf.head(100)\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import decomposition\nscaler = StandardScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\n\ntrain.isna().sum()\n\n###### from sklearn.svm import SVC\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n#n_estimators the number of trees\n#from xgboost import XGBClassifier\nclf = ExtraTreesClassifier(n_estimators=950, random_state=0)\nclf.fit(x_train, y_train)\nprint('Accuracy of classifier on training set: {:.2f}'.format(clf.score(x_train, y_train) * 100))\nprint('Accuracy of classifier on test set: {:.2f}'.format(clf.score(x_test, y_test) * 100))\n\ntest.head()\nid = test['Id']\ntest.drop(['Id'] , inplace = True , axis = 1)\ntest = scaler.transform(test)\n\n# predictions = grid.best_estimator_.predict(test)\npredictions = clf.predict(test)\n#output\nout = pd.DataFrame()\nout['Id'] = id\nout['Cover_Type'] = predictions\nout.to_csv('my_submission.csv', index=False)\nout.head(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}