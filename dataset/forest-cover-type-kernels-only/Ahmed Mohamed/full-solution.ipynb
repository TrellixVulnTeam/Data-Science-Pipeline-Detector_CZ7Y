{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-08-24T16:25:45.489514Z","iopub.execute_input":"2021-08-24T16:25:45.490145Z","iopub.status.idle":"2021-08-24T16:25:45.511625Z","shell.execute_reply.started":"2021-08-24T16:25:45.49001Z","shell.execute_reply":"2021-08-24T16:25:45.510283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of Contents:\n     - Exploratory Analysis\n     - Data Cleaning\n     - Outlier Detection\n     - Feature Engineering\n     - Modeling","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport zipfile\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport os\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\n\n# visualization configurations\n%matplotlib inline\nbase_color = sb.color_palette()[0]\nstandard = [14.70, 8.27]\npanorama = [20,8.27]\nplt.rcParams.update({'font.size': 12})\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:25:48.701654Z","iopub.execute_input":"2021-08-24T16:25:48.702142Z","iopub.status.idle":"2021-08-24T16:25:50.790634Z","shell.execute_reply.started":"2021-08-24T16:25:48.702111Z","shell.execute_reply":"2021-08-24T16:25:50.78945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting data files","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        with zipfile.ZipFile(os.path.join(dirname, filename), 'r') as zip_ref:\n            zip_ref.extractall(os.path.join('./kaggle/input'))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:25:50.792154Z","iopub.execute_input":"2021-08-24T16:25:50.792465Z","iopub.status.idle":"2021-08-24T16:25:51.913712Z","shell.execute_reply.started":"2021-08-24T16:25:50.792437Z","shell.execute_reply":"2021-08-24T16:25:51.912405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_base_path = './kaggle/input/'\ntrain_path = 'train.csv'\ntest_path = 'test.csv'","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:00.043112Z","iopub.execute_input":"2021-08-24T16:26:00.043837Z","iopub.status.idle":"2021-08-24T16:26:00.047941Z","shell.execute_reply.started":"2021-08-24T16:26:00.043801Z","shell.execute_reply":"2021-08-24T16:26:00.04698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(os.path.join(data_base_path,train_path))\nprint(train_data.shape)\ntrain_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:01.421473Z","iopub.execute_input":"2021-08-24T16:26:01.421893Z","iopub.status.idle":"2021-08-24T16:26:01.541107Z","shell.execute_reply.started":"2021-08-24T16:26:01.421858Z","shell.execute_reply":"2021-08-24T16:26:01.539164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The train data-set is of 15,120 rows with 55 feature and 1 label.\n\nLet's start the expolaratory analysis to find out more about the data-set.","metadata":{}},{"cell_type":"markdown","source":"# Expolratory Analysis","metadata":{}},{"cell_type":"markdown","source":"Printing the data feature names and if any is missing","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:03.668162Z","iopub.execute_input":"2021-08-24T16:26:03.668539Z","iopub.status.idle":"2021-08-24T16:26:03.695589Z","shell.execute_reply.started":"2021-08-24T16:26:03.668509Z","shell.execute_reply":"2021-08-24T16:26:03.694519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = train_data.isnull().sum().sum() \nprint(\"There are {} missing values\".format(missing_values))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:04.372489Z","iopub.execute_input":"2021-08-24T16:26:04.372877Z","iopub.status.idle":"2021-08-24T16:26:04.38262Z","shell.execute_reply.started":"2021-08-24T16:26:04.372836Z","shell.execute_reply":"2021-08-24T16:26:04.38098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" - Apparently there are no missing values.\n - Id is just an index, we can drop it.\n - It appears that all the features are just integeres. But with reading the data description we know that:\n     - Soil_Types --> binary features (0 = absence or 1 = presence)\n     - Wilderness_Areas  --> binary feature (0 = absence or 1 = presence)\n     - (Elevation, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Horizontal_Distance_To_Fire_Points) --> integers represent distances\n     - Slope, Aspect --> integer represent angle in degrees.\n     - Hillshade_ --> Hillshade index (0 to 255 index).\n     \n \n\n#### Note:\nHillshade defniniton : \"The hillshade function produces a grayscale 3D representation of the terrain surface, with the sun's relative position taken into account for shading the image. Hillshading is a technique for visualizing terrain determined by a light source and the slope and aspect of the elevation surface. It is a qualitative method for visualizing topography and does not give absolute elevation values. \" more on hillshade [here](https://pro.arcgis.com/en/pro-app/2.7/help/analysis/raster-functions/hillshade-function.htm)","metadata":{}},{"cell_type":"markdown","source":"## correlation matrix","metadata":{}},{"cell_type":"markdown","source":"Fatsest way to get any insight is to plot the correlation matrix as long as the number of features allows that. In our case, it is easy to plot 56x56 matrix.","metadata":{}},{"cell_type":"code","source":"feature_size = train_data.shape[1]\nf = plt.figure(figsize=panorama)\nplt.matshow(train_data.corr(), fignum=f.number)\nplt.xticks(range(feature_size), range(feature_size), fontsize=8, rotation=90)\nplt.yticks(range(feature_size), range(feature_size), fontsize=8)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:06.665862Z","iopub.execute_input":"2021-08-24T16:26:06.666406Z","iopub.status.idle":"2021-08-24T16:26:09.363751Z","shell.execute_reply.started":"2021-08-24T16:26:06.666351Z","shell.execute_reply":"2021-08-24T16:26:09.362513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there are 3 features that has zero correlation with all other features. They seem to have constant value.","metadata":{}},{"cell_type":"markdown","source":"### Univariant &Bivariant Exploration\n\n\n\n#### 1 - Binary features\n\nSince their number is high, we can get intuition about their distribution from numbers faster than visualizing histograms. ","metadata":{}},{"cell_type":"code","source":"def get_common_prefix_columns(data, prefix):\n     \"\"\"\n     This function return list with features names in the data variable that share same prefix\n     \"\"\"     \n     return [col  for col in data.columns if set(prefix).issubset(col)]\n\n\ndef get_binary_stats(data, prefix):\n    \"\"\"\n    This function returns the percentage of each unique value in features in data variable that share same prefix.\n    It is built to be used for scaning the distribution of binary features\n    \"\"\"\n    features = get_common_prefix_columns(data, prefix)\n    for feature in features:\n        value_counts = data[feature].value_counts(normalize = True).to_dict()\n        print(feature, value_counts)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:11.664715Z","iopub.execute_input":"2021-08-24T16:26:11.665076Z","iopub.status.idle":"2021-08-24T16:26:11.671957Z","shell.execute_reply.started":"2021-08-24T16:26:11.665045Z","shell.execute_reply":"2021-08-24T16:26:11.670763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_binary_stats(train_data, prefix = 'Wilderness_Area')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:12.505121Z","iopub.execute_input":"2021-08-24T16:26:12.505506Z","iopub.status.idle":"2021-08-24T16:26:12.53743Z","shell.execute_reply.started":"2021-08-24T16:26:12.505474Z","shell.execute_reply":"2021-08-24T16:26:12.535964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" - wilderness_Area2 is the most uncommon area to be present.\n - Area3 and Area2 are the most two common areas.","metadata":{}},{"cell_type":"code","source":"get_binary_stats(train_data, prefix = 'Soil_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:13.925964Z","iopub.execute_input":"2021-08-24T16:26:13.926422Z","iopub.status.idle":"2021-08-24T16:26:13.993433Z","shell.execute_reply.started":"2021-08-24T16:26:13.926388Z","shell.execute_reply":"2021-08-24T16:26:13.99236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" - Soil types 7 and 15 are never present. Therefore we can ignore these 2 features.\n - A lot of Soil features have 99+ % as zeros. These features maybe useless to predict the Cover Type. ","metadata":{}},{"cell_type":"markdown","source":"#### 2 - Hillshade features.\n\nSince they can be any value between 0-255, it is better to visualize it bu histograms.","metadata":{}},{"cell_type":"code","source":"train_data.hist(get_common_prefix_columns(train_data, prefix = 'Hillshade'), bins = 25);\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:15.73124Z","iopub.execute_input":"2021-08-24T16:26:15.731633Z","iopub.status.idle":"2021-08-24T16:26:16.371578Z","shell.execute_reply.started":"2021-08-24T16:26:15.731602Z","shell.execute_reply":"2021-08-24T16:26:16.370424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" - we can see how the mean value is nearly the same in 9am and Noon, but shifted at 3pm. Let's see the absolute numbers.","metadata":{}},{"cell_type":"code","source":"train_data[get_common_prefix_columns(train_data, prefix = 'Hillshade')].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:17.978294Z","iopub.execute_input":"2021-08-24T16:26:17.978707Z","iopub.status.idle":"2021-08-24T16:26:18.010741Z","shell.execute_reply.started":"2021-08-24T16:26:17.978675Z","shell.execute_reply":"2021-08-24T16:26:18.009938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It will be interesting to see if the shift happens in all cover types (our label)?\n\nLet's print the mean for each Hillshade and for cover type. ","metadata":{}},{"cell_type":"code","source":"train_data.groupby('Cover_Type').mean()[get_common_prefix_columns(train_data, prefix = 'Hillshade')]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:19.387972Z","iopub.execute_input":"2021-08-24T16:26:19.388491Z","iopub.status.idle":"2021-08-24T16:26:19.416295Z","shell.execute_reply.started":"2021-08-24T16:26:19.388451Z","shell.execute_reply":"2021-08-24T16:26:19.415356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that the Hillshade mean shifts for all the Cover Types.","metadata":{}},{"cell_type":"markdown","source":"Let's see the features fistribution and their summary statistics (mean, IQR) in a violin plot. We can build a function to call it for each distance.","metadata":{}},{"cell_type":"code","source":"def draw_box_plot_per_label(data, feature, label):\n    plt.figure(figsize = standard)\n    Means = data.groupby(label)[feature].mean()\n    sb.violinplot(y = data[feature], x = train_data[label], inner='quartile');\n    plt.scatter(x=range(len(Means)),y=Means,c=\"k\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:21.46999Z","iopub.execute_input":"2021-08-24T16:26:21.470399Z","iopub.status.idle":"2021-08-24T16:26:21.476818Z","shell.execute_reply.started":"2021-08-24T16:26:21.470362Z","shell.execute_reply":"2021-08-24T16:26:21.475609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_box_plot_per_label(train_data, 'Hillshade_9am', 'Cover_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:22.18513Z","iopub.execute_input":"2021-08-24T16:26:22.185545Z","iopub.status.idle":"2021-08-24T16:26:22.724675Z","shell.execute_reply.started":"2021-08-24T16:26:22.185511Z","shell.execute_reply":"2021-08-24T16:26:22.723479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_box_plot_per_label(train_data, 'Hillshade_Noon', 'Cover_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:23.488506Z","iopub.execute_input":"2021-08-24T16:26:23.488893Z","iopub.status.idle":"2021-08-24T16:26:23.820795Z","shell.execute_reply.started":"2021-08-24T16:26:23.488863Z","shell.execute_reply":"2021-08-24T16:26:23.819794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_box_plot_per_label(train_data, 'Hillshade_3pm', 'Cover_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:26:24.178056Z","iopub.execute_input":"2021-08-24T16:26:24.178415Z","iopub.status.idle":"2021-08-24T16:26:24.509344Z","shell.execute_reply.started":"2021-08-24T16:26:24.178383Z","shell.execute_reply":"2021-08-24T16:26:24.508111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - The distribution per Cover Type do not tell much.","metadata":{}},{"cell_type":"markdown","source":"### 3 - Distances","metadata":{}},{"cell_type":"code","source":"get_common_prefix_columns(train_data, prefix = 'Distance')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:07.817464Z","iopub.execute_input":"2021-08-24T16:28:07.817845Z","iopub.status.idle":"2021-08-24T16:28:07.826183Z","shell.execute_reply.started":"2021-08-24T16:28:07.817814Z","shell.execute_reply":"2021-08-24T16:28:07.82452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from the features names, we can see that the first two are related, maybe better to be visualized by 2D points.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = standard)\nsb.scatterplot(x = train_data['Horizontal_Distance_To_Hydrology'], y=train_data['Vertical_Distance_To_Hydrology'], alpha = 0.5);","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:09.206793Z","iopub.execute_input":"2021-08-24T16:28:09.207462Z","iopub.status.idle":"2021-08-24T16:28:09.551593Z","shell.execute_reply.started":"2021-08-24T16:28:09.207387Z","shell.execute_reply":"2021-08-24T16:28:09.5505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - distances in the range of [0,400] appear mroe than other values in the data-set\n    - vertical and horizontal distance seems to be directly porpotional. But, Let's add more flavour to the plot and see how these 2 features interact with the Cover Type.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = standard)\nsb.scatterplot(x = train_data['Horizontal_Distance_To_Hydrology'], y=train_data['Vertical_Distance_To_Hydrology'],\n                hue = train_data['Cover_Type'], palette = 'tab10');","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:11.147431Z","iopub.execute_input":"2021-08-24T16:28:11.14808Z","iopub.status.idle":"2021-08-24T16:28:12.506064Z","shell.execute_reply.started":"2021-08-24T16:28:11.148027Z","shell.execute_reply":"2021-08-24T16:28:12.504661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - Almost all of type 3 clustered in x = [0,400] and y =[0,300] --> smaller distances than other types.\n    - Types [1,2,7] appear over the whole x values.\n    - There are 3 instances of type 2 have larger y values than the whole data-set. Maybe needs further investigation.","metadata":{}},{"cell_type":"markdown","source":"Now, we still have horizontal distance to roadways, fire points. Since they are horizontal let's add horizontal distance to hydrology to the comparison.","metadata":{}},{"cell_type":"code","source":"Horizontal_distances = get_common_prefix_columns(train_data, prefix = 'Horizontal')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:28.769164Z","iopub.execute_input":"2021-08-24T16:28:28.76981Z","iopub.status.idle":"2021-08-24T16:28:28.775856Z","shell.execute_reply.started":"2021-08-24T16:28:28.76976Z","shell.execute_reply":"2021-08-24T16:28:28.774502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[Horizontal_distances].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:31.737943Z","iopub.execute_input":"2021-08-24T16:28:31.738491Z","iopub.status.idle":"2021-08-24T16:28:31.763888Z","shell.execute_reply.started":"2021-08-24T16:28:31.738457Z","shell.execute_reply":"2021-08-24T16:28:31.762923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - In general, Hydrology is the most near between these distances. \n    - The maximum distances indicate that maybe there are some outliers. --> let's investigate by the historgram and box plot of each distance.","metadata":{}},{"cell_type":"code","source":"def draw_hist_box_distances(distance):\n    fig, ax =plt.subplots(1,2, figsize = standard)\n    sb.histplot(x = train_data[distance], ax = ax[0]);\n    sb.boxplot(x = train_data[distance], ax = ax[1]);\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:57.754707Z","iopub.execute_input":"2021-08-24T16:28:57.755161Z","iopub.status.idle":"2021-08-24T16:28:57.76284Z","shell.execute_reply.started":"2021-08-24T16:28:57.755127Z","shell.execute_reply":"2021-08-24T16:28:57.761091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_hist_box_distances('Horizontal_Distance_To_Hydrology')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:58.269705Z","iopub.execute_input":"2021-08-24T16:28:58.270492Z","iopub.status.idle":"2021-08-24T16:28:59.049838Z","shell.execute_reply.started":"2021-08-24T16:28:58.270439Z","shell.execute_reply":"2021-08-24T16:28:59.046875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_hist_box_distances('Horizontal_Distance_To_Fire_Points')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:28:59.854445Z","iopub.execute_input":"2021-08-24T16:28:59.854885Z","iopub.status.idle":"2021-08-24T16:29:00.462649Z","shell.execute_reply.started":"2021-08-24T16:28:59.854852Z","shell.execute_reply":"2021-08-24T16:29:00.461615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_hist_box_distances('Horizontal_Distance_To_Roadways')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:00.956363Z","iopub.execute_input":"2021-08-24T16:29:00.956852Z","iopub.status.idle":"2021-08-24T16:29:01.489562Z","shell.execute_reply.started":"2021-08-24T16:29:00.956812Z","shell.execute_reply":"2021-08-24T16:29:01.488486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - The three distances are left skewed, regradless of their order of magnitude.\n    - The three distances have outliers. --> we can make sure later by the features Z-score.","metadata":{}},{"cell_type":"markdown","source":"After exploring the horizontal distance individually (univariant), let's explore its interaction with Cover Type (BiVariant).\n\nSince we need to visualize the distribution for each distance for each covertype, we will use Violinplots. We can draw additional point at the mean value for each cover type to make the plot more informative.","metadata":{}},{"cell_type":"code","source":"draw_box_plot_per_label(train_data, 'Horizontal_Distance_To_Hydrology', 'Cover_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:04.653985Z","iopub.execute_input":"2021-08-24T16:29:04.654413Z","iopub.status.idle":"2021-08-24T16:29:04.991555Z","shell.execute_reply.started":"2021-08-24T16:29:04.65438Z","shell.execute_reply":"2021-08-24T16:29:04.99064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"     - Cover Type 4 looks the most unique and the most probable to be if the value is between [0,100]","metadata":{}},{"cell_type":"code","source":"draw_box_plot_per_label(train_data, 'Horizontal_Distance_To_Roadways', 'Cover_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:07.554552Z","iopub.execute_input":"2021-08-24T16:29:07.554972Z","iopub.status.idle":"2021-08-24T16:29:07.882881Z","shell.execute_reply.started":"2021-08-24T16:29:07.554937Z","shell.execute_reply":"2021-08-24T16:29:07.881499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - This feature can help us eliminate the Cover Types 3,4,6 if the distance to roadways exceeds 4000.","metadata":{}},{"cell_type":"code","source":"draw_box_plot_per_label(train_data, 'Horizontal_Distance_To_Fire_Points', 'Cover_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:09.741592Z","iopub.execute_input":"2021-08-24T16:29:09.741957Z","iopub.status.idle":"2021-08-24T16:29:10.113093Z","shell.execute_reply.started":"2021-08-24T16:29:09.74192Z","shell.execute_reply":"2021-08-24T16:29:10.111599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - These three plots gives the intuition that mean distance of the three distances could be a useful feature to be engineered.","metadata":{}},{"cell_type":"markdown","source":"### 4- Elevation\n\nWe will start by the feature statsitics, and visualizing a historgram.","metadata":{}},{"cell_type":"code","source":"train_data['Elevation'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:12.091849Z","iopub.execute_input":"2021-08-24T16:29:12.092496Z","iopub.status.idle":"2021-08-24T16:29:12.107137Z","shell.execute_reply.started":"2021-08-24T16:29:12.09243Z","shell.execute_reply":"2021-08-24T16:29:12.105398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = standard)\nsb.histplot(x = train_data['Elevation'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:12.843565Z","iopub.execute_input":"2021-08-24T16:29:12.843931Z","iopub.status.idle":"2021-08-24T16:29:13.159948Z","shell.execute_reply.started":"2021-08-24T16:29:12.843901Z","shell.execute_reply":"2021-08-24T16:29:13.158643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - The histogram looks like following tri-modal distribution. Yet, visualizing the distribution per each Cover Type may help more.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = standard)\nsb.kdeplot(x = train_data['Elevation'], hue = train_data['Cover_Type'], palette = 'tab10');","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:14.550433Z","iopub.execute_input":"2021-08-24T16:29:14.550836Z","iopub.status.idle":"2021-08-24T16:29:14.948465Z","shell.execute_reply.started":"2021-08-24T16:29:14.550805Z","shell.execute_reply":"2021-08-24T16:29:14.947567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - Elevation seems like the perfect feature to differentiate between Cover Types 4,5,7 as there kernel estimation almost do not overlap.\n    - It appears now that the distribtuion of Cover types 4,5,7 are the reason for the trimodal distribtuion appeared in the histogram above.","metadata":{}},{"cell_type":"markdown","source":"### 6- Slop, Aspect","metadata":{}},{"cell_type":"code","source":"degree_features = ['Slope','Aspect']","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:19.140148Z","iopub.execute_input":"2021-08-24T16:29:19.140522Z","iopub.status.idle":"2021-08-24T16:29:19.145691Z","shell.execute_reply.started":"2021-08-24T16:29:19.140491Z","shell.execute_reply":"2021-08-24T16:29:19.144439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[degree_features].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:20.124363Z","iopub.execute_input":"2021-08-24T16:29:20.124715Z","iopub.status.idle":"2021-08-24T16:29:20.14759Z","shell.execute_reply.started":"2021-08-24T16:29:20.124686Z","shell.execute_reply":"2021-08-24T16:29:20.1468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"     - There 5 number summary shows summary to each feature by itself. We can see they have different scale. Slope is in order of tens, while Aspect is in order of hundreds.\n     - We can go further and plot their distribution to further investigate how each feature distribution looks like. We will use Kernel density estimation  as it is easier to visualize more than density estimation in one plot, so we can plot the distribution of each feature for each Cover Type.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = standard)\nsb.kdeplot(x = train_data['Slope'], color = base_color, hue = train_data['Cover_Type'], palette ='tab10');","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:51.254093Z","iopub.execute_input":"2021-08-24T16:29:51.25462Z","iopub.status.idle":"2021-08-24T16:29:51.652387Z","shell.execute_reply.started":"2021-08-24T16:29:51.254583Z","shell.execute_reply":"2021-08-24T16:29:51.651375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"     - We can see different distribution for each Cover Type. Some are left skewed bell curves and others are bimodal.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = standard)\nsb.kdeplot(x = train_data['Aspect'], color = base_color, hue = train_data['Cover_Type'], palette ='tab10');","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:29:58.708836Z","iopub.execute_input":"2021-08-24T16:29:58.709347Z","iopub.status.idle":"2021-08-24T16:29:59.125589Z","shell.execute_reply.started":"2021-08-24T16:29:58.709284Z","shell.execute_reply":"2021-08-24T16:29:59.124204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"     - The Aspect follow bimodal distribution for all Cover Types.","metadata":{}},{"cell_type":"markdown","source":"# Data cleaning\n\nThere is no much to do in cleaning the data, already clean. But maybe:\n        - remove the zero correlation faetures with the label, and data index.","metadata":{}},{"cell_type":"code","source":"def drop_features(data, features):\n    for feature in features:\n        if feature in data.columns:\n            data = data.drop(columns = [feature])\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:01.297682Z","iopub.execute_input":"2021-08-24T16:30:01.298054Z","iopub.status.idle":"2021-08-24T16:30:01.302958Z","shell.execute_reply.started":"2021-08-24T16:30:01.298025Z","shell.execute_reply":"2021-08-24T16:30:01.302086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = drop_features(train_data, ['Id','Soil_Type7','Soil_Type8','Soil_Type15'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:02.165584Z","iopub.execute_input":"2021-08-24T16:30:02.166123Z","iopub.status.idle":"2021-08-24T16:30:02.189141Z","shell.execute_reply.started":"2021-08-24T16:30:02.166071Z","shell.execute_reply":"2021-08-24T16:30:02.187625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outlier Detection","metadata":{}},{"cell_type":"markdown","source":"Using Z-score with the continuous features to detect outliers. We will keep any data point that lies between +/-3 standard deviations from the mean value.\n\n3 std from means that --> 99.7% of the data points lie between +/- 3 standard deviation","metadata":{}},{"cell_type":"code","source":"features = get_common_prefix_columns(train_data, 'Distances')\nothers = ['Elevation','Slope','Aspect']\n\nfor other in others:\n    features.append(other)\n\nfeatures","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:04.342464Z","iopub.execute_input":"2021-08-24T16:30:04.342988Z","iopub.status.idle":"2021-08-24T16:30:04.350594Z","shell.execute_reply.started":"2021-08-24T16:30:04.342955Z","shell.execute_reply":"2021-08-24T16:30:04.349576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_zscore = pd.DataFrame()\nfor feature in features[:-1]:\n    data_zscore[feature] = train_data[feature]\n    data_zscore[feature+\"_zscore\"] = (train_data[feature] - train_data[feature].mean()) / train_data[feature].std(ddof=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:05.263763Z","iopub.execute_input":"2021-08-24T16:30:05.264129Z","iopub.status.idle":"2021-08-24T16:30:05.293404Z","shell.execute_reply.started":"2021-08-24T16:30:05.2641Z","shell.execute_reply":"2021-08-24T16:30:05.292148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in features[:-1]:\n    data_zscore[feature+\"_outlier\"] = (abs(data_zscore[feature+\"_zscore\"])>3).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:06.01748Z","iopub.execute_input":"2021-08-24T16:30:06.017964Z","iopub.status.idle":"2021-08-24T16:30:06.035552Z","shell.execute_reply.started":"2021-08-24T16:30:06.017931Z","shell.execute_reply":"2021-08-24T16:30:06.033834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_zscore.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:06.732789Z","iopub.execute_input":"2021-08-24T16:30:06.733254Z","iopub.status.idle":"2021-08-24T16:30:06.744702Z","shell.execute_reply.started":"2021-08-24T16:30:06.733222Z","shell.execute_reply":"2021-08-24T16:30:06.743175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicies_set = set()\nfor col in data_zscore.columns:\n    if \"outlier\" in col:\n        indicies_set.update(data_zscore.loc[data_zscore[col]==1].index.to_list())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:08.451077Z","iopub.execute_input":"2021-08-24T16:30:08.451795Z","iopub.status.idle":"2021-08-24T16:30:08.469338Z","shell.execute_reply.started":"2021-08-24T16:30:08.451723Z","shell.execute_reply":"2021-08-24T16:30:08.468179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(list(indicies_set)) / train_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:09.069255Z","iopub.execute_input":"2021-08-24T16:30:09.069627Z","iopub.status.idle":"2021-08-24T16:30:09.078534Z","shell.execute_reply.started":"2021-08-24T16:30:09.069599Z","shell.execute_reply":"2021-08-24T16:30:09.076868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"nearly 6% of the data makred as having at least one outlier in the mentioned features using Z-score with 3 standard deviations from the mean.","metadata":{}},{"cell_type":"markdown","source":"These data-points could be treated by replacing the values by the mode value in their corresponding label, but for simplicity we will just drop them in this notebook.","metadata":{}},{"cell_type":"code","source":"train_data = train_data.drop(indicies_set)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:10.914018Z","iopub.execute_input":"2021-08-24T16:30:10.914479Z","iopub.status.idle":"2021-08-24T16:30:10.923987Z","shell.execute_reply.started":"2021-08-24T16:30:10.91443Z","shell.execute_reply":"2021-08-24T16:30:10.923169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:30:11.597955Z","iopub.execute_input":"2021-08-24T16:30:11.59861Z","iopub.status.idle":"2021-08-24T16:30:11.603803Z","shell.execute_reply.started":"2021-08-24T16:30:11.598546Z","shell.execute_reply":"2021-08-24T16:30:11.60305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"There are some new features that could be engineered from the features we explored. let's define them mathmatically for now:\n\n    - Diagonal distance to Hydrology.\n         - Just by intuition, if we have the horizontal and vertical distances, let's calculate their diagonal distance\n    - Mean distance from water, fire, and road.\n        - Since water, fire  and road are the main sources of services in the data-set, maybe the average distance to all three can reflect a useful number.\n    \n    \n    \nThere are some other ideas, but with the lack of description for the data-set it is hard to be more creative about engineering more featurs.\n    - I can see that Vertical distance to Hydrology has something to do with Elevation, but can't get a relation between them.","metadata":{}},{"cell_type":"code","source":"def diagonal_distance(data,x,y):\n    return np.sqrt(data[x]**2 + data[y]**2)\n\n\ndef mean_value(data,feature_list):\n    sum_ = 0\n    for feature in feature_list:\n        sum_ += data[feature]\n    return sum_ / len(feature_list)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:34:20.40783Z","iopub.execute_input":"2021-08-24T16:34:20.408529Z","iopub.status.idle":"2021-08-24T16:34:20.41491Z","shell.execute_reply.started":"2021-08-24T16:34:20.408465Z","shell.execute_reply":"2021-08-24T16:34:20.413468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Hydrology_distances = get_common_prefix_columns(train_data, 'Hydrology')\ntrain_data['Diagonal_Distance_To_Hydrology'] = diagonal_distance(train_data, Hydrology_distances[0], Hydrology_distances[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:34:21.232966Z","iopub.execute_input":"2021-08-24T16:34:21.233516Z","iopub.status.idle":"2021-08-24T16:34:21.242041Z","shell.execute_reply.started":"2021-08-24T16:34:21.233485Z","shell.execute_reply":"2021-08-24T16:34:21.240992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Horizontal_distances = get_common_prefix_columns(train_data, 'Horizontal')\ntrain_data['Mean_Horizontal_Distance'] = mean_value(train_data,Horizontal_distances)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:34:23.299218Z","iopub.execute_input":"2021-08-24T16:34:23.299727Z","iopub.status.idle":"2021-08-24T16:34:23.310304Z","shell.execute_reply.started":"2021-08-24T16:34:23.299686Z","shell.execute_reply":"2021-08-24T16:34:23.309097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:39:48.779344Z","iopub.execute_input":"2021-08-24T16:39:48.779854Z","iopub.status.idle":"2021-08-24T16:39:48.790176Z","shell.execute_reply.started":"2021-08-24T16:39:48.779818Z","shell.execute_reply":"2021-08-24T16:39:48.789022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = train_data['Cover_Type']\nX = train_data.drop(columns=['Cover_Type'])\nprint(\"train data is of shape {} with {} labels\".format(X.shape,Y.shape))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:39:50.512966Z","iopub.execute_input":"2021-08-24T16:39:50.513522Z","iopub.status.idle":"2021-08-24T16:39:50.52568Z","shell.execute_reply.started":"2021-08-24T16:39:50.513478Z","shell.execute_reply":"2021-08-24T16:39:50.524421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, since we agreed to the previous data cleaning, and feature engineering steps, we can build a function to do that transformation and use it over the test data.","metadata":{}},{"cell_type":"code","source":"def transform_features(data):\n    data = drop_features(data, ['Id','Soil_Type7','Soil_Type8','Soil_Type15'])\n    \n    Horizontal_distances = get_common_prefix_columns(data, 'Horizontal')\n    data['Mean_Horizontal_Distance'] = mean_value(data,Horizontal_distances)\n    \n    Hydrology_distances = get_common_prefix_columns(data, 'Hydrology')\n    data['Diagonal_Distance_To_Hydrology'] = diagonal_distance(data, Hydrology_distances[0], Hydrology_distances[1])\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:40:00.401374Z","iopub.execute_input":"2021-08-24T16:40:00.401796Z","iopub.status.idle":"2021-08-24T16:40:00.408564Z","shell.execute_reply.started":"2021-08-24T16:40:00.401763Z","shell.execute_reply":"2021-08-24T16:40:00.407468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Selection\n\nWe will use Random Forest as baseline model for this notebook.","metadata":{}},{"cell_type":"code","source":"def train_predict(clf, X_train, X_valid, y_train):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_valid)\n    return y_pred\n\ndef evaluate(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:40:04.464027Z","iopub.execute_input":"2021-08-24T16:40:04.464398Z","iopub.status.idle":"2021-08-24T16:40:04.469886Z","shell.execute_reply.started":"2021-08-24T16:40:04.464369Z","shell.execute_reply":"2021-08-24T16:40:04.46879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = RandomForestClassifier(random_state = 0)\nstrtfdKFold = StratifiedKFold(n_splits=10)\nkfold = strtfdKFold.split(X, Y)\nscores = []\n\nX = transform_features(X)\n\nfor k, (train, valid) in enumerate(kfold):\n    y_pred = train_predict(clf, X.iloc[train, :], X.iloc[valid, :], Y.iloc[train])\n    score = evaluate(Y.iloc[valid], y_pred)\n    scores.append(score)\n    print('Fold: %2d,  Accuracy: %.3f' % (k+1, score))\n \nprint('\\n\\nCross-Validation accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:42:57.409374Z","iopub.execute_input":"2021-08-24T16:42:57.410102Z","iopub.status.idle":"2021-08-24T16:43:25.063136Z","shell.execute_reply.started":"2021-08-24T16:42:57.41004Z","shell.execute_reply":"2021-08-24T16:43:25.061777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"using 10 startified folds to ensure the robustness of the model.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(os.path.join(data_base_path,test_path))\nprint(test_data.shape)\ntest_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:43:37.833273Z","iopub.execute_input":"2021-08-24T16:43:37.833656Z","iopub.status.idle":"2021-08-24T16:43:40.481753Z","shell.execute_reply.started":"2021-08-24T16:43:37.833626Z","shell.execute_reply":"2021-08-24T16:43:40.480644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## construct submission file","metadata":{}},{"cell_type":"code","source":"test_df = pd.DataFrame()\ntest_df['Id'] = test_data['Id']\ntest_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:43:42.377837Z","iopub.execute_input":"2021-08-24T16:43:42.378181Z","iopub.status.idle":"2021-08-24T16:43:42.459713Z","shell.execute_reply.started":"2021-08-24T16:43:42.378153Z","shell.execute_reply":"2021-08-24T16:43:42.458584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = transform_features(test_data)\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:43:44.715934Z","iopub.execute_input":"2021-08-24T16:43:44.716299Z","iopub.status.idle":"2021-08-24T16:43:45.129578Z","shell.execute_reply.started":"2021-08-24T16:43:44.716269Z","shell.execute_reply":"2021-08-24T16:43:45.128725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = clf.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:43:55.019438Z","iopub.execute_input":"2021-08-24T16:43:55.019838Z","iopub.status.idle":"2021-08-24T16:44:03.42107Z","shell.execute_reply.started":"2021-08-24T16:43:55.019806Z","shell.execute_reply":"2021-08-24T16:44:03.419676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Cover_Type'] = y_test\ntest_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:47:29.795071Z","iopub.execute_input":"2021-08-24T16:47:29.795475Z","iopub.status.idle":"2021-08-24T16:47:30.913752Z","shell.execute_reply.started":"2021-08-24T16:47:29.795441Z","shell.execute_reply":"2021-08-24T16:47:30.9126Z"},"trusted":true},"execution_count":null,"outputs":[]}]}