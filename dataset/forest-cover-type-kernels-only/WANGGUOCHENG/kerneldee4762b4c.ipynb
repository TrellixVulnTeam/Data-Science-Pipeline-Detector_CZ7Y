{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\n\n\nMax_len = 15120\n\ndef normalize(df):\n    result = df.copy()\n    for feature_name in df.columns:\n        max_value = df[feature_name].max()\n        min_value = df[feature_name].min()\n        if ((max_value - min_value) == 0):\n            result[feature_name] = 0\n        else:\n            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)  ## 被除数为0\n    return result\n\n\ndef label(train_y_N):\n    array = [0, 0, 0, 0, 0, 0, 0]\n    array[train_y_N[0] - 1] = 1\n    for i in range(1, len(train_y_N)):\n        new_array = [0, 0, 0, 0, 0, 0, 0]\n        new_array[train_y_N[i] - 1] = 1\n        array = np.row_stack((array, new_array))\n    return array\n\n\ndef RecoverToNumber(train_y_L):\n    array = []\n    for tr_L in train_y_L:\n        list = tr_L.tolist()\n        max_index = list.index(max(list))+1\n        array.append(max_index)\n    return array\n\n\ndef add_layer(inputs, in_size, out_size, activation_function=None, ):\n    layer_name = 'layer1'\n    with tf.name_scope(layer_name):\n        with tf.name_scope('weights'):\n            # add one more layer and return the output of this layer\n            Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n            tf.summary.histogram(layer_name + '/weights', Weights)  # tensorflow >= 0.12\n        with tf.name_scope('biases'):\n            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n            tf.summary.histogram(layer_name + '/biases', biases)  # Tensorflow >= 0.12\n        with tf.name_scope('Wx_plus_b'):\n            Wx_plus_b = tf.matmul(inputs, Weights) + biases\n\n        if activation_function is None:\n            outputs = Wx_plus_b\n        else:\n            outputs = activation_function(Wx_plus_b, )\n        tf.summary.histogram(layer_name + '/outputs', outputs)\n    return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce70f6de6c6b25177aea08515cfa30caf5b80f06"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# train = pd.read_csv('data/train.csv')\n# test = pd.read_csv('data/test.csv')\n\n# 将数据拆分成两列\ntrain_x = train.iloc[:, 1:55]\ntrain_y = label(train.Cover_Type)\n\n# 对train_x test_x标准化\ntrain_x_nmlz = normalize(train_x)\ntest_x = normalize(test.iloc[:,1::])\n\nsess = tf.Session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80f74f3cf6fa42b72165db99cc1780f3e67fc60a"},"cell_type":"code","source":"xs = tf.placeholder(tf.float32, [None, 54])\nys = tf.placeholder(tf.float32, [None, 7])  ## 为啥莫凡就可以写10？ 因为他的数据","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"370efba67f76128ef9e7e1060837dbaae5514380"},"cell_type":"code","source":"prediction = add_layer(xs, 54, 7, activation_function=tf.nn.softmax)\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))  # loss\ntrain_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)\n\ninit = tf.global_variables_initializer()\n\nsess.run(init)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4ac6a64c452337b9698cf2d4bf3f987266750d5"},"cell_type":"code","source":"for i in range(1500):\n    batch_xs, batch_ys = train_x_nmlz.iloc[(i * 100) % Max_len: (100 + i *100)%Max_len, :], train_y[(i * 100)%Max_len : (100 + i * 100)%Max_len]\n    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})  ##","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"936be78d641092e6f4d2d76c33cd5250f3ac3708"},"cell_type":"code","source":"y_pre = sess.run(prediction, feed_dict={xs:test_x})\ny_pre = RecoverToNumber(y_pre)\nId = test.Id\ndatafram = pd.DataFrame({'Id':Id,'Cover_Type':y_pre})\ndatafram.to_csv('res2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"006eafca2e0086bc47b306542b5c6e6045da4855"},"cell_type":"code","source":"datafram","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}