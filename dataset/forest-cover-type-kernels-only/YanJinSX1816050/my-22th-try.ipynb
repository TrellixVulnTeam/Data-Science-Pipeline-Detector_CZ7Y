{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MaxAbsScaler\nimport warnings\nfrom numpy import hstack,vstack,array,nan\n\n\n###SelectKBest(lambda X, Y: array(map(lambda x:mic(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target)\n\nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nx_columns = [x for x in train.columns if x not in ['Id',\n            'Soil_Type5'\n             ,'Soil_Type7','Soil_Type8','Soil_Type9','Soil_Type14'\n             ,'Soil_Type15','Soil_Type16','Soil_Type18','Soil_Type19','Soil_Type21'\n            ,'Soil_Type25','Soil_Type26','Soil_Type27','Soil_Type28'\n             ,'Soil_Type34','Soil_Type36','Soil_Type37'\n             ,'Cover_Type']]\nx1_columns = [x for x in test.columns if x not in ['Id',\n            'Soil_Type5'\n             ,'Soil_Type7','Soil_Type8','Soil_Type9','Soil_Type14'\n             ,'Soil_Type15','Soil_Type16','Soil_Type18','Soil_Type19','Soil_Type21'\n            ,'Soil_Type25','Soil_Type26','Soil_Type27','Soil_Type28'\n             ,'Soil_Type34','Soil_Type36','Soil_Type37'\n             ]]\n\nX1 = test[x1_columns]\nX = train[x_columns]\nY = train['Cover_Type']\n\nX = X.values\nY = Y.values\nX1 = X1.values\nprint (type(X))\n\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=10)\n\nss=RobustScaler()\n\nX_train[:14]=ss.fit_transform(X_train[:14])\nX_test[:14]=ss.transform(X_test[:14])\nX1[:14]=ss.transform(X1[:14])\nX_test = X1\n\nnew_feature=[] #装每个模型产生的新特征列\nnew_label_test=[]\n#模型模块\nclf1=LogisticRegression()\nclf2=KNeighborsClassifier(n_neighbors=3,weights='distance')\nclf3=GaussianNB()\nclf4=RandomForestClassifier(n_estimators= 182)\n\nset_Train=[]\nset_Test=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f5aa07127809dc0c229e54e9d21e792eaf7cfe"},"cell_type":"code","source":"for k in range(5):\n    span=int(X_train.shape[0]/5)\n    i=k*span\n    j=(k+1)*span\n    #将X_train和y_train均划分成为5分被后续交叉验证使用\n    set_Train.append(X_train[i:j])\n    set_Test.append(y_train[i:j])\n\nmodel=[clf1,clf2,clf3,clf4]\nf = []\nfor index,clf in enumerate(model):\n    model_list=[] #将每一轮交叉验证的预测label存入其中,再转为array做转置.\n    label_list=[] #总的测试集对应的预测标签\n    #k折交叉验证\n    for k in range(5):\n        ##选择做交叉验证的测试集\n        XXtest=[]\n        XXtest.append(set_Train[k])\n        #选择做交叉验证训练的训练集\n        XXtrain=[]\n        YYtest=[]\n        for kk in range(5):\n            if kk==k:\n                continue\n            else:\n                XXtrain.append(set_Train[kk])\n                YYtest.append(set_Test[kk])\n        #模型的训练\n        XXXtrain=array(vstack((XXtrain[0],XXtrain[1],XXtrain[2],XXtrain[3]))) \n        YYYtrain=array(hstack((YYtest[0],YYtest[1],YYtest[2],YYtest[3])))\n        XXXtest=array(vstack(XXtest)) #XXtest.shape=1*24*4,不是想要的96x4\n        clf.fit(XXXtrain,YYYtrain)\n        y_predict=clf.predict(XXXtest)\n        model_list.append(y_predict) #将第k折验证中第k折为测试集的预测标签存储起来\n        test_y_pred=clf.predict(X_test)\n        label_list.append(test_y_pred)\n    new_k_feature=array(hstack((model_list[0],model_list[1],model_list[2],model_list[3],model_list[4]))) #hstack() takes 1 positional argument,所以参数使用一个tuple来封装\n    print ('new_k_feature',new_k_feature.shape)\n    new_feature.append(new_k_feature)\n    print (len(new_feature[index]))\n    new_k_test=array(vstack((label_list[0],label_list[1],label_list[2],label_list[3],label_list[4]))).T #hstack() takes 1 positional argument,所以参数使用一个tuple来封装\n    print ('new_k_test',new_k_test.shape)\n    new_label_test.append(array(list(map(int,list(map(round,new_k_test.mean(axis=1)))))))\n    print (len(new_label_test[index]))\n#将5个基模型训练好的预分类标签组合成为新的特征供后续使用(X_train')\nprint (X_train[:,0])\nnewfeature_from_train=array(vstack((new_feature[0],new_feature[1],new_feature[2],new_feature[3],X_train[:,0],X_train[:,5],X_train[:,9],X_train[:,3],X_train[:,4],X_train[:,6]))).T #拼接完成后做转置\nprint ('newfeature_from_train',newfeature_from_train.shape)\n#将交叉验证获得的label拼接起来(X_test')\npredict_from_test_average=array(vstack((new_label_test[0],new_label_test[1],new_label_test[2],new_label_test[3],X_test[:,0],X_test[:,5],X_test[:,9],X_test[:,3],X_test[:,4],X_test[:,6]))).T\nprint ('predict_from_test_average',predict_from_test_average.shape)\n\"\"\"1.3.meta_classifier 模型\"\"\"\nclf5=GradientBoostingClassifier()\nclf5.fit(newfeature_from_train,y_train)\n\npredict1=clf5.predict(predict_from_test_average)\n\nprint ('predict over')\nn = [x for x in range(15121,581013)]\npredDf=pd.DataFrame(\n    {'Id':n,\n    'Cover_Type':predict1})\n\npredDf.to_csv('mypred21.csv',index=False)\nprint ('over')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68a60c981b9a2a66030d1fa01c09149f2f4e7331"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}