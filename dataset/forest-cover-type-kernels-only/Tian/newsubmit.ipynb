{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"\n#include <cv.h>       // opencv general include file\n\n#include <ml.h>\t\t  // opencv machine learning include file\n\n#include <stdio.h>\n#include <conio.h>\n\nusing namespace cv; // OpenCV API is in the C++ \"cv\" namespace\n\t\t\t\t\t/******************************************************************************/\n\t\t\t\t\t// global definitions (for speed and ease of use)\n\t\t\t\t\t//手写体数字识别\n#define NUMBER_OF_TRAINING_SAMPLES 15120//训练集样本数\n\n#define ATTRIBUTES_PER_SAMPLE 54//特征数\n\n#define NUMBER_OF_TESTING_SAMPLES 565892//测试集样本数\n\n#define NUMBER_OF_CLASSES 7//分类\n\n\t\t\t\t\t// N.B. classes are integer handwritten digits in range 0-9\n\n\t\t\t\t\t/******************************************************************************/\n\t\t\t\t\t// loads the sample database from file (which is a CSV text file)\n\nint read_data_from_csv(const char* filename, Mat data, Mat classes,\n\tint n_samples)//读取csv文件数据\n{\n\tfloat tmp;\n\t// if we can't read the input file then return 0\n\tFILE* f = fopen(filename, \"r\");\n\tif (!f)\n\t{\n\t\tprintf(\"ERROR: cannot read file %s\\n\", filename);\n\t\treturn 0; // all not OK\n\t}\n\t// for each sample in the file\n\tfor (int line = 0; line < n_samples; line++)\n\t{\n\t\t// for each attribute on the line in the file\n\t\tfor (int attribute = 0; attribute< (ATTRIBUTES_PER_SAMPLE + 1); attribute++)\n\t\t{\n\t\t\t\tif (attribute < ATTRIBUTES_PER_SAMPLE)\n\t\t\t\t{\n\t\t\t\t\t// first 64 elements (0-63) in each line are the attributes\n\t\t\t\t\tfscanf(f, \"%f,\", &tmp);//fscanf(文件指针，格式字符串，输入列表);\n\t\t\t\t\tdata.at<float>(line, attribute) = tmp;//特征项\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  //printf(\"%f,\", data.at<float>(line, attribute-1));\n\t\t\t\t}\n\t\t\t\telse if (attribute == ATTRIBUTES_PER_SAMPLE)\n\t\t\t\t{\n\t\t\t\t\t// attribute 65 is the class label {0 ... 9}\n\t\t\t\t\tfscanf(f, \"%f,\", &tmp);\n\t\t\t\t\tclasses.at<float>(line, 0) = tmp;//结果项\n\t\t\t\t\t\t\t\t\t\t\t\t\t //printf(\"%f\\n\", classes.at<float>(line, 0));\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t//printf(\"Testing train Sample at %i \\n\", classes.at<float>(line, 0));\n\tfclose(f);\n\treturn 1; // all OK\n}\n\n/******************************************************************************/\nint main(int argc, char** argv)\n{\n\tfor (int i = 0; i< argc; i++)\n\t\tstd::cout << argv[i] << std::endl;\n\t// lets just check the version first\n\tprintf(\"OpenCV version %s (%d.%d.%d)\\n\",\n\t\tCV_VERSION,\n\t\tCV_MAJOR_VERSION, CV_MINOR_VERSION, CV_SUBMINOR_VERSION);\n\tFILE* fp = fopen(\"sample.csv\", \"w\");\n\tif (fp == NULL)\n\t{\n\t\tprintf(\"无法打开文件\\n!\");\n\t\texit(0);\n\t}\n\n\t//定义训练数据与标签矩阵\n\tMat training_data = Mat(NUMBER_OF_TRAINING_SAMPLES, ATTRIBUTES_PER_SAMPLE, CV_32FC1);\n\tMat training_classifications = Mat(NUMBER_OF_TRAINING_SAMPLES, 1, CV_32FC1);\n\t//定义测试数据矩阵与标签\n\tMat testing_data = Mat(NUMBER_OF_TESTING_SAMPLES, ATTRIBUTES_PER_SAMPLE, CV_32FC1);\n\tMat testing_classifications = Mat(NUMBER_OF_TESTING_SAMPLES, 1, CV_32FC1);\n\t// define all the attributes as numerical\n\t// alternatives are CV_VAR_CATEGORICAL or CV_VAR_ORDERED(=CV_VAR_NUMERICAL)\n\t// that can be assigned on a per attribute basis\n\tMat var_type = Mat(ATTRIBUTES_PER_SAMPLE + 1, 1, CV_8U);\n\tvar_type.setTo(Scalar(CV_VAR_NUMERICAL)); // all inputs are numerical\n\n\t\t\t\t\t\t\t\t\t\t\t  // this is a classification problem (i.e. predict a discrete number of class\n\n\t\t\t\t\t\t\t\t\t\t\t  // outputs) so reset the last (+1) output var_type element to CV_VAR_CATEGORICAL\n\n\tvar_type.at<uchar>(ATTRIBUTES_PER_SAMPLE, 0) = CV_VAR_CATEGORICAL;\n\tdouble result; // value returned from a prediction\n\t\t\t\t   //加载训练数据集和测试数据集\n\tif (read_data_from_csv(argv[1], training_data, training_classifications, NUMBER_OF_TRAINING_SAMPLES) &&\n\t\tread_data_from_csv(argv[2], testing_data, testing_classifications, NUMBER_OF_TESTING_SAMPLES))\n\t{\n\t\t/*for (int i = 0; i < NUMBER_OF_TRAINING_SAMPLES; i++) {\n\t\t\tprintf(\"Testing train Sample %f at %i \\n\", training_classifications.at<float>(i, 0),i);\n\t\t}*/\n\t\t/*for (int i = 0; i < NUMBER_OF_TESTING_SAMPLES; i++) {\n\t\t\tprintf(\"Testing test Sample %f \\n\", testing_classifications.at<float>(i,0));\n\t\t}*/\n\t\t/********************************步骤1：定义初始化Random Trees的参数******************************/\n\t\tfloat priors[] = { 1,1,1,1,1,1,1 };  // weights of each classification for classes\n\t\tCvRTParams params = CvRTParams(25, // max depth 较低不符合，较高会过拟合\n\t\t\t5, // min sample count 叶节点上需要分割的最小样本数\n\t\t\t0, // regression accuracy: N/A here 回归树的终止条件当前节点上所有样本的真实值和预测值之间的差小于这个数值时，停止生产这个节点，并将其作为叶子节点\n\t\t\tfalse, // compute surrogate split, no missing data 是否使用代理\n\t\t\t15, // max number of categories (use sub-optimal algorithm for larger numbers)k均值的最大分类数\n\t\t\tpriors, // the array of priors先验知识 分配权重数量较少样本类的分类正确率也不会太低\n\t\t\tfalse,  // calculate variable importance 计算变量重要性\n\t\t\t4,       // number of variables randomly selected at node and used to find the best split(s).每个树节点上随机选择的要素子集的大小，用于查找最佳分割\n\t\t\t100,\t // max number of trees in the forest随机森林中树的最大颗数\n\t\t\t0.01f,\t\t\t\t// forrest accuracy \n\t\t\tCV_TERMCRIT_ITER | CV_TERMCRIT_EPS // termination cirteria CV_TERMCRIT_ITER通过max_num_of_trees_in_the_forest终止学习;CV_TERMCRIT_EPS通过forest_accuracy终止学习;CV_TERMCRIT_ITER | CV_TERMCRIT_EPS使用两个终止条件。\n\t\t);\n\n\t\t/****************************步骤2：训练 Random Decision Forest(RDF)分类器*********************/\n\t\tprintf(\"\\nUsing training database: %s\\n\\n\", argv[1]);\n\t\tCvRTrees* rtree = new CvRTrees;\n\t\trtree->train(training_data, CV_ROW_SAMPLE, training_classifications,\n\t\t\tMat(), Mat(), var_type, Mat(), params);//训练\n\t\t// perform classifier testing and report results\n\t\tMat test_sample;\n\t\tint correct_class = 0;\n\t\tint wrong_class = 0;\n\t\tint false_positives[NUMBER_OF_CLASSES] = { 0,0,0,0,0,0,0,};\n\t\tprintf(\"\\nUsing testing database: %s\\n\\n\", argv[2]);\n\t\tfor (int tsample = 0; tsample < NUMBER_OF_TESTING_SAMPLES; tsample++)\n\t\t{\n\t\t\t// extract a row from the testing matrix\n\t\t\ttest_sample = testing_data.row(tsample);\n\t\t\t/********************************步骤3：预测*********************************************/\n\t\t\tresult = rtree->predict(test_sample, Mat());//预测\n\t\t\tfprintf(fp, \"%f \\n\", result);\n\t\t\t// if the prediction and the (true) testing classification are the same\n\t\t\t// (N.B. openCV uses a floating point decision tree implementation!)\n\t\t\tif (fabs(result - testing_classifications.at<float>(tsample, 0))\n\t\t\t\t>= FLT_EPSILON)//预测结果与实际结果相差大于某个值\n\t\t\t{\n\t\t\t\t//printf(\"Testing wrong Sample %f ->result %f\\n\", testing_classifications.at<float>(tsample, 0), result);\n\t\t\t\t// if they differ more than floating point error => wrong class\n\t\t\t\twrong_class++;\n\t\t\t\tfalse_positives[(int)result]++;//在错误分类的样本数加1\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t//printf(\"Testing correct Sample %f \\n->result %f\\n\", testing_classifications.at<float>(tsample, 0), result);\n\t\t\t\t// otherwise correct\n\t\t\t\tcorrect_class++;\n\t\t\t}\n\t\t}\n\t\tprintf(\"\\nResults on the testing database: %s\\n\"\n\t\t\t\"\\tCorrect classification: %d (%g%%)\\n\"\n\t\t\t\"\\tWrong classifications: %d (%g%%)\\n\",\n\t\t\targv[2],\n\t\t\tcorrect_class, (double)correct_class * 100 / NUMBER_OF_TESTING_SAMPLES,\n\t\t\twrong_class, (double)wrong_class * 100 / NUMBER_OF_TESTING_SAMPLES);\n\t\tfor (int i = 0; i < NUMBER_OF_CLASSES; i++)\n\t\t{\n\t\t\tprintf(\"\\tClass (digit %d) false postives \t%d (%g%%)\\n\", i,\n\t\t\t\tfalse_positives[i],\n\t\t\t\t(double)false_positives[i] * 100 / NUMBER_OF_TESTING_SAMPLES);\n\t\t}\n\t\t// all matrix memory free by destructors\n\t\t// all OK : main returns 0\n\t\t_getch();\n\t\treturn 0;\n\t}\n\t// not OK : main returns -1\n\treturn -1;\n}\n\n/******************************************************************************/\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}