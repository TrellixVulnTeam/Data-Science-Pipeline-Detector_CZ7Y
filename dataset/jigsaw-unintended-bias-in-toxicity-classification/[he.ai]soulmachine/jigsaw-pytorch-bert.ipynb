{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Jigsaw Unintended Bias in Toxicity Classification"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport dask.bag as db\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom tqdm import tqdm, tqdm_notebook\n\nimport os\nimport random\nimport subprocess\nimport sys\nimport time","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import platform\nprint(f'Python version: {platform.python_version()}')\nprint(f'PyTorch version: {torch.__version__}')","execution_count":2,"outputs":[{"output_type":"stream","text":"Python version: 3.6.6\nPyTorch version: 1.0.1.post2\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 1. Initialize Environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This notebook runs on GPU\nassert torch.cuda.is_available()\n\nDEVICE = torch.device('cuda')\nNUM_GPUS = torch.cuda.device_count()\nassert NUM_GPUS > 0","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\nimport logging\nlogging.basicConfig(level=logging.INFO)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define flags**:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse\n\ndef define_args(str_list):\n    '''\n    A lite version of args at https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L565\n    \n    The following flags are set to constant values implicitly thus they're removed from args:\n      * local_rank=-1\n      * fp16=True\n      * cache_dir=''\n      \n    '''\n    parser = argparse.ArgumentParser()\n\n    ## Required parameters\n    parser.add_argument(\"--data_dir\",\n                        default=None,\n                        type=str,\n                        required=True,\n                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n    parser.add_argument(\"--bert_model\", default=None, type=str, required=True,\n                        help=\"Bert pre-trained model name selected in the list: bert-base-uncased, \"\n                        \"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"\n                        \"bert-base-multilingual-cased, bert-base-chinese.\")\n    parser.add_argument(\"--max_seq_length\",\n                        default=None,\n                        type=int,\n                        required=True,\n                        help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n                             \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n                             \"than this will be padded.\")\n\n    ## Other parameters\n    parser.add_argument(\"--do_lower_case\",\n                        action='store_true',\n                        help=\"Set this flag if you are using an uncased model.\")\n    parser.add_argument(\"--train_batch_size\",\n                        default=32,\n                        type=int,\n                        help=\"Total batch size for training.\")\n    parser.add_argument(\"--eval_batch_size\",\n                        default=8,\n                        type=int,\n                        help=\"Total batch size for eval.\")\n    parser.add_argument(\"--learning_rate\",\n                        default=5e-5,\n                        type=float,\n                        help=\"The initial learning rate for Adam.\")\n    parser.add_argument(\"--begin_epoch\",\n                        default=0,\n                        type=int,\n                        help=\"The begin training epoch, starts from 0.\")\n    parser.add_argument(\"--end_epoch\",\n                        default=1,\n                        type=int,\n                        help=\"The end training epoch, excluded.\")\n    parser.add_argument(\"--warmup_proportion\",\n                        default=0.1,\n                        type=float,\n                        help=\"Proportion of training to perform linear learning rate warmup for. \"\n                             \"E.g., 0.1 = 10%% of training.\")\n    parser.add_argument('--seed',\n                        type=int,\n                        default=42,\n                        help=\"random seed for initialization\")\n    parser.add_argument('--gradient_accumulation_steps',\n                        type=int,\n                        default=1,\n                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n    parser.add_argument('--fp16',\n                        action='store_true',\n                        help=\"Whether to use 16-bit float precision instead of 32-bit\")\n    parser.add_argument('--loss_scale',\n                        type=float, default=0,\n                        help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n                             \"0 (default value): dynamic loss scaling.\\n\"\n                             \"Positive power of 2: static loss scaling value.\\n\")\n    parser.add_argument('--verbose', '-v', action='count')\n\n    args = parser.parse_args(str_list)\n\n    args.do_lower_case = 'uncased' in args.bert_model\n    # see dataset https://www.kaggle.com/soulmachine/bert-fine-tuned-for-jigsaw\n    args.output_dir = f'../input/bert-fine-tuned-for-jigsaw/jigsaw-{args.bert_model}-len-{args.max_seq_length}-{\"fp16\" if args.fp16 else \"fp32\"}'\n\n    return args","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args = define_args([\n    '--data_dir', '../input/jigsaw-unintended-bias-in-toxicity-classification',\n    '--bert_model', 'bert-base-uncased',\n    '--max_seq_length', '220',\n    '--fp16',\n    '--learning_rate', '2e-5',\n    '--begin_epoch', '0',\n    '--end_epoch', '4',\n    '-v',\n])\nargs","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Namespace(begin_epoch=0, bert_model='bert-base-uncased', data_dir='../input/jigsaw-unintended-bias-in-toxicity-classification', do_lower_case=True, end_epoch=4, eval_batch_size=8, fp16=True, gradient_accumulation_steps=1, learning_rate=2e-05, loss_scale=0, max_seq_length=220, output_dir='../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-base-uncased-len-220-fp16', seed=42, train_batch_size=32, verbose=1, warmup_proportion=0.1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If the last checkpoint exists, skip training\nIS_TRAINING = not os.path.exists(f'{args.output_dir}/epoch-{args.end_epoch-1}')\nIS_TRAINING","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"False"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_args(args):\n    assert args.begin_epoch < args.end_epoch\n    if args.begin_epoch > 0:\n        assert os.path.exists(f'{args.output_dir}/epoch-{args.begin_epoch-1}')\n    if IS_TRAINING:\n        for i in range(args.begin_epoch, args.end_epoch):\n            assert not os.path.exists(f'{args.output_dir}/epoch-{i}')\n    else:\n        assert os.path.exists(f'{args.output_dir}/epoch-{args.end_epoch-1}')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_args(args)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make Pytorch **deterministic**:"},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(args.seed)\nnp.random.seed(args.seed)\ntorch.manual_seed(args.seed)\ntorch.cuda.manual_seed(args.seed)\ntorch.cuda.manual_seed_all(args.seed)\n\ntorch.backends.cudnn.deterministic = True","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Install requirements"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Install Apex"},{"metadata":{"trusted":true},"cell_type":"code","source":"def install_apex():\n    try:\n        import apex\n    except ModuleNotFoundError:\n        print('Installing NVIDIA Apex')\n        if 'KAGGLE_URL_BASE' in os.environ:  # kaggle kernel\n            APEX_SRC = '../input/nvidia-apex/apex-master/apex-master'\n            assert os.path.exists(APEX_SRC)\n            print(subprocess.check_output(\n                f'{sys.executable} -m pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" {APEX_SRC}',\n                shell=True).decode('utf-8'))\n        else:\n            APEX_SRC = '../input/apex'\n            if not os.path.exists(APEX_SRC):\n                os.makedirs(APEX_SRC)\n                print(subprocess.check_output(f'git clone https://github.com/NVIDIA/apex {APEX_SRC}', shell=True).decode('utf-8'))\n            else:\n                print(f'{APEX_SRC} already exists')\n            print(subprocess.check_output(\n                f'sudo {sys.executable} -m pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" {APEX_SRC}',\n                shell=True).decode('utf-8'))\n        import apex\n        print('Installed apex successfully')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_TRAINING and args.fp16:\n    install_apex()","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Install pytorch-pretrained-bert"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    from pytorch_pretrained_bert import BertTokenizer, BertModel\nexcept ModuleNotFoundError:\n    print('Installing Install pytorch-pretrained-bert ...')\n    if 'KAGGLE_URL_BASE' in os.environ:  # kaggle kernel\n        bert_lib = '../input/pytorchpretrainedbert/pytorch-pretrained-bert-master/pytorch-pretrained-BERT-master'\n        assert os.path.exists(bert_lib)\n        sys.path.insert(0, bert_lib)\n    else:\n        print(subprocess.check_output('sudo -u jupyter conda install -y -c conda-forge pytorch-pretrained-bert', shell=True).decode('utf-8'))\n    print('Installed pytorch-pretrained-bert successfully')","execution_count":13,"outputs":[{"output_type":"stream","text":"Installing Install pytorch-pretrained-bert ...\nInstalled pytorch-pretrained-bert successfully\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE, WEIGHTS_NAME, CONFIG_NAME\nfrom pytorch_pretrained_bert.modeling import BertModel, BertForSequenceClassification, BertConfig, BertForMaskedLM\nfrom pytorch_pretrained_bert.tokenization import BertTokenizer\nfrom pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule","execution_count":14,"outputs":[{"output_type":"stream","text":"INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"## 3. Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_columns=['target']","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tokenizer**:"},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'KAGGLE_URL_BASE' in os.environ:  # kaggle kernel\n    MODELS_ROOT_DIR = '../input/pretrained-bert-models-for-pytorch'\n    VOCAB_FILE = f'{MODELS_ROOT_DIR}/{args.bert_model}-vocab.txt'\n    tokenizer = BertTokenizer.from_pretrained(VOCAB_FILE, do_lower_case=args.do_lower_case, cache_dir=None)\nelse:\n    tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)","execution_count":16,"outputs":[{"output_type":"stream","text":"INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file ../input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Training Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_lines(lines, max_seq_length, tokenizer):\n    '''\n      Converting the lines to BERT format.\n      \n      Copied from https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\n    '''\n    max_seq_length -= 2  # CLS, SEP\n    all_tokens = []\n    longer = 0\n    for text in tqdm_notebook(lines):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>max_seq_length:\n            tokens_a = tokens_a[:max_seq_length]\n            longer += 1\n        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n        all_tokens.append(one_token)\n    print(f'longer: {longer}')\n    return np.array(all_tokens)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_lines_parallel(i):\n    total_lines = len(X_train)\n    num_lines_per_thread = total_lines // os.cpu_count() + 1\n    lines = X_train[i * num_lines_per_thread : (i+1) * num_lines_per_thread]\n    return convert_lines(lines, args.max_seq_length, tokenizer)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(df, has_label=True):\n    # Make sure all comment_text values are strings\n    df['comment_text'] = df['comment_text'].astype(str).fillna(\"DUMMY_VALUE\")\n    if has_label:\n        # convert target to 0,1\n        df['target']=(df['target']>=0.5).astype(float)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_TRAINING:\n    train_df = pd.read_csv(os.path.join(args.data_dir, \"train.csv\"))#.sample(num_to_load+valid_size,random_state=args.seed)\n    preprocess_data(train_df)\n    \n    X_train = train_df[\"comment_text\"]\n    X_train = np.vstack(db.from_sequence(list(range(os.cpu_count()))).map(convert_lines_parallel).compute())\n    Y_train = train_df[y_columns].values\n\n    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(Y_train,dtype=torch.float))\n    num_train_optimization_steps = int(\n        len(train_dataset) / args.train_batch_size / args.gradient_accumulation_steps) * (args.end_epoch-args.begin_epoch)\n    \n    assert Y_train.shape[1] == 1\n    print(X_train.shape)\n    print(Y_train.shape)\n    print(X_train.dtype)\n    print(Y_train.dtype)","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Validation Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_VALID_SAMPLES = 100000\n\nvalid_df = pd.read_csv(os.path.join(args.data_dir, \"train.csv\")).sample(NUM_VALID_SAMPLES, random_state=args.seed)\npreprocess_data(valid_df)\n\nX_valid = convert_lines(valid_df['comment_text'], args.max_seq_length, tokenizer)\nY_valid = valid_df[y_columns].values\nvalid_dataset = torch.utils.data.TensorDataset(torch.tensor(X_valid, dtype=torch.long))\n\nassert Y_valid.shape[1] == 1\nprint(X_valid.shape)\nprint(Y_valid.shape)\nprint(X_valid.dtype)\nprint(Y_valid.dtype)","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"101ee0811d9e46c3bbab8b9ea9221ca7"}},"metadata":{}},{"output_type":"stream","text":"\nlonger: 2246\n(100000, 220)\n(100000, 1)\nint64\nfloat64\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(args.data_dir, \"test.csv\"))\npreprocess_data(test_df, has_label=False)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = convert_lines(test_df[\"comment_text\"], args.max_seq_length, tokenizer)","execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=97320), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221978cb10b849ba8b61458b25bfdb81"}},"metadata":{}},{"output_type":"stream","text":"\nlonger: 2191\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test.shape)\nprint(X_test.dtype)","execution_count":26,"outputs":[{"output_type":"stream","text":"(97320, 220)\nint64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Training"},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Load BERT model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_model(model):\n    '''\n      See https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py\n    '''\n#     if args.fp16:\n#         # Users should not manually cast their model or data to .half()\n#         # see https://nvidia.github.io/apex/amp.html\n#         model.half()\n    model.zero_grad()\n    model.to(DEVICE)\n    if NUM_GPUS > 1:\n        model = torch.nn.DataParallel(model)\n    return model","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model():\n    if args.begin_epoch == 0:  # load BERT model\n        print('Load BERT model')\n        if 'KAGGLE_URL_BASE' in os.environ:  # kaggle kernel\n            MODELS_ROOT_DIR = '../input/pretrained-bert-models-for-pytorch'\n            MODEL_PATH = f'{MODELS_ROOT_DIR}/{args.bert_model}'\n            model = BertForSequenceClassification.from_pretrained(MODEL_PATH, cache_dir=None, num_labels=len(y_columns))\n        else:\n            model = BertForSequenceClassification.from_pretrained(args.bert_model, cache_dir=None, num_labels=len(y_columns))\n    else:  # args.begin_epoch > 0\n        print('Load previous checkpoint')\n        model_dir = f'{args.output_dir}/epoch-{args.begin_epoch-1}'\n        assert os.path.exists(model_dir)\n        model = BertForSequenceClassification.from_pretrained(model_dir, num_labels=len(y_columns), cache_dir=None)\n\n    return model","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_TRAINING:\n    model = prepare_model(load_model())","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_optimizer(model):\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n    ]\n    if False:  # args.fp16\n        try:\n            from apex.optimizers import FP16_Optimizer\n            from apex.optimizers import FusedAdam\n        except ImportError:\n            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n\n        optimizer = FusedAdam(optimizer_grouped_parameters,\n                              lr=args.learning_rate,\n                              bias_correction=False,\n                              max_grad_norm=1.0)\n        if args.loss_scale == 0:\n            optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n        else:\n            optimizer = FP16_Optimizer(optimizer, static_loss_scale=args.loss_scale)\n    else:\n        optimizer = BertAdam(optimizer_grouped_parameters,\n                             lr=args.learning_rate,\n                             warmup=args.warmup_proportion,\n                             t_total=num_train_optimization_steps)\n    return optimizer","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_TRAINING:\n    optimizer = prepare_optimizer(model)","execution_count":32,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Start Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(model, tokenizer, output_dir):\n    '''\n      Save a trained model and configuration.\n    '''\n    if os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(output_dir))\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    # Save a trained model and configuration\n    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n\n    # If we save using the predefined names, we can load using `from_pretrained`\n    output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n    output_config_file = os.path.join(output_dir, CONFIG_NAME)\n\n    torch.save(model_to_save.state_dict(), output_model_file)\n    model_to_save.config.to_json_file(output_config_file)\n    tokenizer.save_vocabulary(output_dir)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, optimizer, train_dataset):\n    if args.fp16:\n        # Allow Amp to perform casts as required by the opt_level\n        model, optimizer = apex.amp.initialize(model, optimizer, opt_level=\"O1\")\n        warmup_linear = WarmupLinearSchedule(warmup=args.warmup_proportion,\n                                             t_total=num_train_optimization_steps)\n    global_step = 0\n\n    model=model.train()\n\n    start_time = time.time()\n    outer_tq = tqdm_notebook(range(args.begin_epoch, args.end_epoch))\n    for epoch in outer_tq:\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.train_batch_size, shuffle=True)\n        avg_loss = 0.\n        avg_accuracy = 0.\n        lossf=None\n        epoch_start_time = time.time()\n\n        #for step, batch in enumerate(tqdm(train_dataloader, desc= f'Iteration {epoch}')):\n        #    batch = tuple(t.to(DEVICE) for t in batch)\n\n        inner_tq = tqdm_notebook(enumerate(train_loader), total=len(train_loader),leave=False, desc= f'Iteration {epoch}')\n        for step, (x_batch, y_batch) in inner_tq:\n            optimizer.zero_grad()\n            y_pred = model(x_batch.to(DEVICE), attention_mask=(x_batch>0).to(DEVICE), labels=None)\n            loss =  F.binary_cross_entropy_with_logits(y_pred, y_batch.to(DEVICE))\n\n            if NUM_GPUS > 1:\n                loss = loss.mean() # mean() to average on multi-gpu.\n            if args.gradient_accumulation_steps > 1:\n                loss = loss / args.gradient_accumulation_steps\n\n            if args.fp16:\n                # optimizer.backward(loss)\n                with apex.amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n            else:\n                loss.backward()\n\n            if (step + 1) % args.gradient_accumulation_steps == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n                global_step += 1\n\n            if lossf:\n                lossf = 0.98*lossf+0.02*loss.item()\n            else:\n                lossf = loss.item()\n            inner_tq.set_postfix(loss = lossf)\n            avg_loss += loss.item() / len(train_loader)\n            avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(DEVICE)).to(torch.float) ).item()/len(train_loader)\n        outer_tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n        save_model(model, tokenizer, f'{args.output_dir}/epoch-{epoch}')\n        epoch_end_time = time.time()\n        print(f'Iteration {step} time elapsed {int(epoch_end_time-epoch_start_time)}s')\n\n    end_time = time.time()\n    print(f'Time elapsed {int(end_time-start_time)}s')","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists(f'{args.output_dir}/epoch-{args.end_epoch-1}'):\n    train(model, optimizer, train_dataset)","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_eval_model(model_dir):\n    # Load a trained model and vocabulary that you have fine-tuned\n    model = BertForSequenceClassification.from_pretrained(model_dir, num_labels=len(y_columns), cache_dir=None)\n    tokenizer = BertTokenizer.from_pretrained(model_dir, do_lower_case=args.do_lower_case, cache_dir=None)\n    model.to(DEVICE)\n    model.eval()\n    for param in model.parameters():\n        param.requires_grad = False\n    return model","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, valid_dataset):\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.eval_batch_size, shuffle=False)\n    batch_size=args.eval_batch_size\n    valid_preds = np.zeros((len(valid_dataset)))\n    \n    for step, (x_batch, ) in tqdm_notebook(enumerate(valid_loader), total=len(valid_loader)):\n        y_pred = model(x_batch.to(DEVICE), attention_mask=(x_batch>0).to(DEVICE), labels=None)\n        valid_preds[step*batch_size:(step+1)*batch_size]=y_pred[:,0].detach().cpu().squeeze().numpy()\n    return valid_preds","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_eval_model(f'{args.output_dir}/epoch-{args.end_epoch-1}')","execution_count":38,"outputs":[{"output_type":"stream","text":"INFO:pytorch_pretrained_bert.modeling:loading archive file ../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-base-uncased-len-220-fp16/epoch-3\nINFO:pytorch_pretrained_bert.modeling:Model config {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 30522\n}\n\nINFO:pytorch_pretrained_bert.tokenization:loading vocabulary file ../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-base-uncased-len-220-fp16/epoch-3/vocab.txt\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_preds = predict(model, valid_dataset)","execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f8c56f406f4c7a8301b8f21d373f44"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From baseline kernel\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]>0.5\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n\n\n\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]>0.5]\n    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_NAME = 'model1'\n# List all identities\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n\nvalid_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\nTOXICITY_COLUMN = 'target'\nbias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, MODEL_NAME, 'target')","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bias_metrics_df","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"   bnsp_auc  bpsn_auc      ...       subgroup_auc  subgroup_size\n2  0.997251  0.989425      ...           0.985782            589\n5  0.997275  0.992224      ...           0.989549           1097\n6  0.996869  0.994188      ...           0.990870            775\n8  0.997225  0.991195      ...           0.990917            254\n7  0.997795  0.993662      ...           0.993453           1255\n0  0.997280  0.996412      ...           0.995283           2256\n3  0.996119  0.997583      ...           0.995751           1965\n1  0.997392  0.997024      ...           0.996360           2873\n4  0.998642  0.997087      ...           0.999053            380\n\n[9 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bnsp_auc</th>\n      <th>bpsn_auc</th>\n      <th>subgroup</th>\n      <th>subgroup_auc</th>\n      <th>subgroup_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.997251</td>\n      <td>0.989425</td>\n      <td>homosexual_gay_or_lesbian</td>\n      <td>0.985782</td>\n      <td>589</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.997275</td>\n      <td>0.992224</td>\n      <td>muslim</td>\n      <td>0.989549</td>\n      <td>1097</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.996869</td>\n      <td>0.994188</td>\n      <td>black</td>\n      <td>0.990870</td>\n      <td>775</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.997225</td>\n      <td>0.991195</td>\n      <td>psychiatric_or_mental_illness</td>\n      <td>0.990917</td>\n      <td>254</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.997795</td>\n      <td>0.993662</td>\n      <td>white</td>\n      <td>0.993453</td>\n      <td>1255</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.997280</td>\n      <td>0.996412</td>\n      <td>male</td>\n      <td>0.995283</td>\n      <td>2256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.996119</td>\n      <td>0.997583</td>\n      <td>christian</td>\n      <td>0.995751</td>\n      <td>1965</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.997392</td>\n      <td>0.997024</td>\n      <td>female</td>\n      <td>0.996360</td>\n      <td>2873</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.998642</td>\n      <td>0.997087</td>\n      <td>jewish</td>\n      <td>0.999053</td>\n      <td>380</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_final_metric(bias_metrics_df, calculate_overall_auc(valid_df, MODEL_NAME))","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"0.995863367277334"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 6. Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = predict(model, test_dataset)","execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=12165), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f8b98d69854cff974a2d56a9e0cf9f"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"(97320,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = torch.sigmoid(torch.tensor(y_test)).numpy().ravel()","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred.shape","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"(97320,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame.from_dict({\n    'id': test_df['id'],\n    'prediction': test_pred\n})\nsubmission.to_csv('submission.csv', index=False)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"        id  prediction\n0  7000000    0.000012\n1  7000001    0.000012\n2  7000002    0.000011\n3  7000003    0.000017\n4  7000004    0.997005","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7000000</td>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7000001</td>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7000002</td>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7000003</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7000004</td>\n      <td>0.997005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}