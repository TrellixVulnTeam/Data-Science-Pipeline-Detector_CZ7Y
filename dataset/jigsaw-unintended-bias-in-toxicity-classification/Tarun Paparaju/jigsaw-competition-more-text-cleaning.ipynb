{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n### In this kernel, I will walk you through some extra text cleaning methods and how they work on sample comments."},{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/CtyQ8Ag.png\" width=\"250px\"></center>"},{"metadata":{},"cell_type":"markdown","source":"## Acknowledgements\nI have borrowed the text cleaning functions from Dimitrios in [this great kernel](https://www.kaggle.com/deffro/text-pre-processing-techniques) from the Quora Insincere Questions Classification competition."},{"metadata":{},"cell_type":"markdown","source":"### Import necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\n\nimport re\nimport numpy as np\nimport pandas as pd\n\nimport nltk\nfrom nltk.corpus import wordnet, stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.porter import PorterStemmer\n\nfrom colorama import Fore, Back, Style","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Download data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### See first few rows of dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract comments from data"},{"metadata":{"trusted":true},"cell_type":"code","source":"comments = train_df['comment_text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create function for visualizing the effect of text cleaning function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def example_cleaning_results(function):\n    select_comments = []\n    for i, comment in enumerate(comments):\n        if comment != function(comment):\n            select_comments.append(comment)\n        if len(select_comments) == 5:\n            break\n    \n    print(\"                          \" +\\\n          f'{Style.DIM}'+\\\n          \"EXAMPLE WORKING OF TEXT CLEANING FUNCTION\"+\\\n          f'{Style.RESET_ALL}')\n    print(\"                          \" +\\\n          f'{Style.DIM}'+\\\n          \"-------------------------------------------\"+\\\n          f'{Style.RESET_ALL}')\n    print(\"\")\n\n    for comment in select_comments:\n        print(f'{Fore.YELLOW}{Style.DIM}' + comment + f'{Style.RESET_ALL}' +\\\n              '\\n\\n' + \"                                     \"+\\\n              'CHANGES TO' + '\\n\\n' +\\\n              f'{Fore.CYAN}{Style.DIM}' + function(comment) + f'{Style.RESET_ALL}')\n        \n        print(\"\")\n        \n        print(f'{Fore.WHITE}{Style.DIM}' +\\\n              \"-------------------------\"+\\\n              \"-------------------------\"+\\\n              \"-------------------------\"+\\\n              \"------------------\" +\\\n              f'{Style.RESET_ALL}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove the numbers\nThis function removes all the numbers in the comment\n\nEg. I'm 25 years old. --> I'm years old."},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_numbers(text):\n    \"\"\" Removes integers \"\"\"\n    text = ''.join([i for i in text if not i.isdigit()])         \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(remove_numbers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove the exclamation, question and full stop marks\nThis function removes the exclamation, question and full stop marks from the comment.\n\nEg. This is awesome ! --> This is awesome"},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_multi_exclamation_mark(text):\n    \"\"\" Replaces repetitions of exlamation marks \"\"\"\n    text = re.sub(r\"(\\!)\\1+\", ' multiExclamation ', text)\n    return text\n\ndef replace_multi_question_mark(text):\n    \"\"\" Replaces repetitions of question marks \"\"\"\n    text = re.sub(r\"(\\?)\\1+\", ' multiQuestion ', text)\n    return text\n\ndef replace_multi_stop_mark(text):\n    \"\"\" Replaces repetitions of stop marks \"\"\"\n    text = re.sub(r\"(\\.)\\1+\", ' multiStop ', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(lambda x: replace_multi_exclamation_mark(replace_multi_question_mark(replace_multi_stop_mark(x))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove the exclamation, question and full stop marks\nThis function removes the exclamation, question and full stop marks from the comment.\n\nEg. You love cats !? I prefer dogs. --> You love cats I prefer dogs"},{"metadata":{"trusted":true},"cell_type":"code","source":"contraction_patterns = [(r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'),\\\n                        (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'),\\\n                        (r'(\\w+)n\\'t', '\\g<1> not'),\\\n                        (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'),\\\n                        (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'),\\\n                        (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'),\\\n                        (r'wont', 'will not')]\n\ndef replace_contraction(text):\n    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n    for (pattern, repl) in patterns:\n        (text, count) = re.subn(pattern, repl, text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(replace_contraction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace the negations with antonyms\nThis function rplaces negations with their respective antonyms.\n\nEg. I am not happy. --> I am unhappy."},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace(word, pos=None):\n    \"\"\" Creates a set of all antonyms for the word and if there is only one antonym, it returns it \"\"\"\n    antonyms = set()\n    for syn in wordnet.synsets(word, pos=pos):\n        for lemma in syn.lemmas():\n            for antonym in lemma.antonyms():\n                antonyms.add(antonym.name())\n    if len(antonyms) == 1:\n        return antonyms.pop()\n    else:\n        return None\n\ndef replace_negations(text):\n    \"\"\" Finds \"not\" and antonym for the next word and if found, replaces not and the next word with the antonym \"\"\"\n    i, l = 0, len(text)\n    words = []\n    while i < l:\n        word = text[i]\n        if word == 'not' and i+1 < l:\n            ant = replace(text[i+1])\n            if ant:\n                words.append(ant)\n                i += 2\n                continue\n        words.append(word)\n        i += 1\n    return words\n\ndef tokenize_and_replace_negations(text):\n    tokens = nltk.word_tokenize(text)\n    tokens = replace_negations(tokens)\n    text = \" \".join(tokens)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(tokenize_and_replace_negations)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove stopwords\nThis function removes the most common words used in English (stop words) like 'a', 'is', 'are' etc.\n\nEg. He is a very humorous person. --> He very humorous person."},{"metadata":{"trusted":true},"cell_type":"code","source":"stoplist = stopwords.words('english')\n\ndef remove_stop_words(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        if (w not in stoplist):\n            finalTokens.append(w)\n    text = \" \".join(finalTokens)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(remove_stop_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace elongated words with the basic form\nThis function replaces elongated words with its basic form.\n\nEg. I eat little food --> I eat litle food"},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_elongated(word):\n    \"\"\" Replaces an elongated word with its basic form, unless the word exists in the lexicon \"\"\"\n\n    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n    repl = r'\\1\\2\\3'\n    if wordnet.synsets(word):\n        return word\n    repl_word = repeat_regexp.sub(repl, word)\n    if repl_word != word:      \n        return replace_elongated(repl_word)\n    else:       \n        return repl_word\n    \ndef replace_elongated_words(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(replace_elongated(w))\n    text = \" \".join(finalTokens)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(replace_elongated_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stem words\nThis function \"stems\" the words in the comments. It only keeps the stem of the word, which need not be an actual word.\n\nEg. I love swimming and driving happily --> I love swimm and driv happi"},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()\n\ndef stem_words(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(stemmer.stem(w))\n    text = \" \".join(finalTokens)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(stem_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lemmatize words\nThe function lemmatizes the words in the comments. It only keeps the lemma of the actual words, which needs to be an actual word.\n\nEg. I love swimming and driving happily --> I love swim and drive happy"},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\n\ndef lemmatize_words(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(lemmatizer.lemmatize(w))\n    text = \" \".join(finalTokens)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_cleaning_results(lemmatize_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### That's it ! Thanks for reading my kernel and I hope you found it useful. Your upvote will be appreciated :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}