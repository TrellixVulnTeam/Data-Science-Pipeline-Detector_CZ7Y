{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello. \n\nIn the process of studying the kernels of a given competitions, I often saw a code that is used for estimate cover by a dictionary of vector representations.\n\nThis method is good, but it looks \"not pythonically\" outwardly. For example, I do not understand the point of using \"try-except\". Below is my solution."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom keras.preprocessing.text import Tokenizer\n\ntqdm.pandas()\n\ntrain = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_vocab(texts):\n    sentences = texts.progress_apply(lambda x: x.split()).values\n    vocab = {}\n    for sentence in sentences:\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab\n\ndef get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in f)\n    \nembedding_index = load_embeddings(\"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(lower=False)\ntokenizer.fit_on_texts(train.comment_text.tolist() + test.comment_text.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is my solution (I hope.. I have not met a kernel with something similar)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndef check_coverage_new(word_counts, wanted_keys):\n    a = {key: val for key, val in word_counts.items() if key not in wanted_keys}\n    print(f'Found embeddings for {1-len(a)/len(word_counts):.2%} of vocablen')\n    print(f'Found embeddings for {1-sum(a.values())/sum(word_counts.values()):.2%} of all text')\n    return sorted(a.items(), key= lambda x : x[1], reverse=True)\n\nwanted_keys = embedding_index.keys()\nsort_x = check_coverage_new(tokenizer.word_counts, wanted_keys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nimport operator \n\ndef check_coverage(vocab, embeddings_index):\n    a = {}\n    oov = {}\n    k = 0\n    i = 0\n    for word in tqdm(vocab):\n        try:\n            a[word] = embeddings_index[word]\n            k += vocab[word]\n        except:\n\n            oov[word] = vocab[word]\n            i += vocab[word]\n            pass\n\n    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n\n    return sorted_x\n\nsort_y = check_coverage(tokenizer.word_counts, embedding_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the course of work, you will use the \"check_coverage_new\" function several times, but you no longer need to override the \"wanted_keys\" (if you use one set of vector views), which speeds up the definition."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndef check_coverage_new(word_counts, wanted_keys):\n    a = {key: val for key, val in word_counts.items() if key not in wanted_keys}\n    print(f'Found embeddings for {1-len(a)/len(word_counts):.2%} of vocablen')\n    print(f'Found embeddings for {1-sum(a.values())/sum(word_counts.values()):.2%} of all text')\n    return sorted(a.items(), key= lambda x : x[1], reverse=True)\n\nsort_x = check_coverage_new(tokenizer.word_counts, wanted_keys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sort_x[:10], sort_y[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total:\n1. Execution speed at ~ 100ms- ~ 200ms faster. On this dataset this is not critical, but in larger datasets this can be a significant plus;\n2. The function has become shorter;\n3. One less import.\n\nI hope my decision will be useful for you."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}