{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kernel details\n\nWe will use the GLUEProcessor in XLNet to finetune and train the Unintended Bias Toxicity Classification Dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport spacy\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\n#Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport tensorflow as tf\ntf.logging.set_verbosity(tf.logging.INFO)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ndf_test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\ndf_sample = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lengths = df_train.comment_text.str.len()\nlengths.mean(), lengths.std(), lengths.min(), lengths.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lengths = df_test.comment_text.str.len()\nlengths.mean(), lengths.std(), lengths.min(), lengths.max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocess and create TSV files to perform XLNet classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_reviews(text):\n    text = re.sub(r'<[^>]*>', ' ', text, re.UNICODE)\n    text = re.sub(r'[^\\w\\s]', '', text, re.UNICODE)\n    text = re.sub(r'[^0-9a-zA-Z]+',' ',text, re.UNICODE)\n    text = \" \".join(text.split())\n    text = text.lower()\n    return text\n\ndf_train['comment_text'] = df_train.comment_text.apply(lambda x: preprocess_reviews(x))\ndf_test['comment_text'] = df_test.comment_text.apply(lambda x: preprocess_reviews(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# force train into cola format, test is fine as it is\ndf_train = df_train[['id', 'target', 'comment_text']]\ndf_train['target'] = np.where(df_train['target']>=0.5,1,0)\n\n#Sampling 30% to save training time\ndf_train = df_train.sample(frac=0.3)\n\n# export as tab seperated\ndf_train.to_csv('train.tsv', sep='\\t', index=False, header=False)\ndf_test.to_csv('test.tsv', sep='\\t', index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's copy the XLNet files from git repo to working folder for easy reference**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\nfor f in os.listdir('../input/xlnetcode/'):\n    try:\n        if f.split('.')[1] in ['py', 'json']:\n            copyfile(src = \"../input/xlnetcode/\"+f, dst = \"../working/\"+f)\n    except:\n        continue\nprint(os.listdir('../working'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from absl import flags\nimport xlnet\nfrom run_classifier import *\nimport sys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Performing this step to initialise FLAGS in IPython Notebook**"},{"metadata":{"trusted":true},"cell_type":"code","source":"remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\nassert(remaining_args == [sys.argv[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FLAGS.spiece_model_file = '../input/xlnetcode/spiece.model'\nFLAGS.model_config_path = '../input/xlnetcode/xlnet_config.json'\nFLAGS.output_dir =\"../\"\nFLAGS.model_dir = \"../\"\nFLAGS.data_dir = \"../working/\"\nFLAGS.do_train = False\nFLAGS.train_steps = 1000\nFLAGS.warmup_steps = 0\nFLAGS.learning_rate = 1e-5\nFLAGS.max_save = 999999\nFLAGS.use_tpu = False\n\n#Used not take any of the processors and get from the tasks\nFLAGS.cls_scope = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using appropriate XLNet implementation from here\n**SentencePiece Tokenizer implementation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tokenization\nimport sentencepiece as spm\nfrom prepro_utils import preprocess_text, encode_ids\n\nsp = spm.SentencePieceProcessor()\nsp.Load(FLAGS.spiece_model_file)\ndef tokenize_fn(text):\n    text = preprocess_text(text, lower=FLAGS.uncased)\n    return encode_ids(sp, text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Initialise GLUEProcessor and specify the column indexes in test and train datasets and create examples**"},{"metadata":{"trusted":true},"cell_type":"code","source":"processor = GLUEProcessor()\nlabel_list = processor.get_labels()\nprocessor.label_column = 1\nprocessor.text_a_column = 2\nprocessor.test_text_a_column = 1\ntrain_examples = processor.get_train_examples(FLAGS.data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_examples[0].label, train_examples[0].text_a, train_examples[0].text_b ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nprint(\"--------------------------------------------------------\")\nprint(\"Starting to Train\")\nprint(\"--------------------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file = os.path.join(FLAGS.output_dir, \"train.tf_record\")\ntf.logging.info(\"Use tfrecord file {}\".format(train_file))\nnp.random.shuffle(train_examples)\ntf.logging.info(\"Num of train samples: {}\".format(len(train_examples)))\nfile_based_convert_examples_to_features(\n        train_examples, label_list, FLAGS.max_seq_length, tokenize_fn,\n        train_file, FLAGS.num_passes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RunConfig contains hyperparameters that could be different between pretraining and finetuning.\ntpu_cluster_resolver = None\nis_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n\nrun_config = tf.contrib.tpu.RunConfig(\n    cluster=tpu_cluster_resolver,\n    master=FLAGS.master,\n    model_dir=FLAGS.output_dir,\n    save_checkpoints_steps=FLAGS.save_steps,\n    tpu_config=tf.contrib.tpu.TPUConfig(\n        iterations_per_loop=FLAGS.iterations,\n        num_shards=FLAGS.num_core_per_host,\n        per_host_input_for_training=is_per_host))\nmodel_fn = get_model_fn(len(label_list) if label_list is not None else None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.logging.set_verbosity(tf.logging.INFO)\nestimator = tf.contrib.tpu.TPUEstimator(\n        use_tpu=FLAGS.use_tpu,\n        model_fn=model_fn,\n        config=run_config,\n        train_batch_size=FLAGS.train_batch_size,\n        predict_batch_size=FLAGS.predict_batch_size,\n        eval_batch_size=FLAGS.eval_batch_size)\n\ntf.logging.info(\"***** Running training *****\")\ntf.logging.info(\"  Num examples = %d\", len(train_examples))\ntf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\ntf.logging.info(\"  Num steps = %d\", FLAGS.iterations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_input_fn = file_based_input_fn_builder(\n        input_file=train_file,\n        seq_length=FLAGS.max_seq_length,\n        is_training=True,\n        drop_remainder=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"end = time.time()\nprint(\"--------------------------------------------------------\")\nprint(\"Total time taken to complete training - \", end - start, \" seconds\")\nprint(\"--------------------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_examples = processor.get_test_examples(FLAGS.data_dir)\ntf.logging.info(\"Num of test samples: {}\".format(len(test_examples)))\neval_file = os.path.join(FLAGS.output_dir, \"predict.tf_record\")\nfile_based_convert_examples_to_features(\n        test_examples, label_list, FLAGS.max_seq_length, tokenize_fn,\n        eval_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.path.getsize('../predict.tf_record')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_input_fn = file_based_input_fn_builder(\n        input_file=eval_file,\n        seq_length=FLAGS.max_seq_length,\n        is_training=False,\n        drop_remainder=False)\npredict_results = []\nwith tf.gfile.Open(\"test_results.tsv\", \"w\") as fout:\n    fout.write(\"index\\tprediction\\n\")\n\n    for pred_cnt, result in enumerate(estimator.predict(\n        input_fn=pred_input_fn,\n        yield_single_examples=True)):\n        if pred_cnt % 1000 == 0:\n            tf.logging.info(\"Predicting submission for example: {}\".format(\n              pred_cnt))\n\n        logits = [float(x) for x in result[\"logits\"].flat]\n        predict_results.append(logits)\n\n        if len(logits) == 1:\n            label_out = logits[0]\n        elif len(logits) == 2:\n            if logits[1] - logits[0] > FLAGS.predict_threshold:\n                label_out = label_list[1]\n            else:\n                label_out = label_list[0]\n        elif len(logits) > 2:\n            max_index = np.argmax(np.array(logits, dtype=np.float32))\n            label_out = label_list[max_index]\n        else:\n            raise NotImplementedError\n\n        fout.write(\"{}\\t{}\\n\".format(pred_cnt, label_out))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_examples), len(predict_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating submission file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_out = pd.read_csv('test_results.tsv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([df_sample.iloc[:,0], df_test_out.iloc[:,1]], axis=1)\nsubmission.columns = ['id','prediction']\nsubmission.to_csv('submission.csv', index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}