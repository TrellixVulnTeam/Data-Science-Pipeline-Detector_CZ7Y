{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kernel Details\nWe will create a classifier using XLNET - Base model for Jigsaw Unintended Bias in Toxicity Classification."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport spacy\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\n#Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ndf_test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\ndf_sample = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lengths = df_train.comment_text.str.len()\nlengths.mean(), lengths.std(), lengths.min(), lengths.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lengths = df_test.comment_text.str.len()\nlengths.mean(), lengths.std(), lengths.min(), lengths.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_reviews(text):\n    text = re.sub(r'<[^>]*>', ' ', text, re.UNICODE)\n    text = re.sub(r'[^\\w\\s]', '', text, re.UNICODE)\n    text = re.sub(r'[^0-9a-zA-Z]+',' ',text, re.UNICODE)\n    text = text.lower()\n    return text\n\ndf_train['processed_comment_text'] = df_train.comment_text.apply(lambda x: preprocess_reviews(x))\ndf_test['processed_comment_text'] = df_test.comment_text.apply(lambda x: preprocess_reviews(x))\n\ndf_train = df_train.sample(frac=0.4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Creating folders which will suit XLNet implementation for reading data and creating examples for IMDB **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\nfor f in os.listdir('../input/xlnetcode/'):\n    try:\n        if f.split('.')[1] in ['py', 'json']:\n            copyfile(src = \"../input/xlnetcode/\"+f, dst = \"../working/\"+f)\n    except:\n        continue\nprint(os.listdir('../working'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir '../input/train'\n!mkdir '../input/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir '../input/train/pos'\n!mkdir '../input/train/neg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df_train[['target','processed_comment_text']]\ntrain['target'] = np.where(train['target']>=0.5,1,0)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, data in train.iterrows():\n    if data['target'] == 0:\n        f = open('../input/train/neg/' + str(index) + '.txt', \"w\")\n        f.write(data['processed_comment_text'])\n        f.close()\n    else:\n        f = open('../input/train/pos/' + str(index) + '.txt', \"w\")\n        f.write(data['processed_comment_text'])\n        f.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df_test[['processed_comment_text']]\ntest.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create parameters for running the classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"overwrite_data = True\noutput_dir = '../working'\ndata_dir = '../working'\niterations_per_loop = 1000\nnum_hosts = 1\nnum_core_per_host = 8\nmax_save = 0\nsave_steps = None\nstrategy = None\nmax_seq_length = 128\nnum_passes = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SCRIPTS_DIR = '../working' #@param {type:\"string\"}\nDATA_DIR = '../input/' #@param {type:\"string\"}\nOUTPUT_DIR = '../' #@param {type:\"string\"}\nPRETRAINED_MODEL_DIR = '../input/xlnetcode' #@param {type:\"string\"}\nCHECKPOINT_DIR = '../' #@param {type:\"string\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_command = \"python run_classifier.py \\\n  --do_train=True \\\n  --do_eval=False \\\n  --eval_all_ckpt=True \\\n  --task_name=imdb \\\n  --data_dir=\"+DATA_DIR+\" \\\n  --output_dir=\"+OUTPUT_DIR+\" \\\n  --model_dir=\"+CHECKPOINT_DIR+\" \\\n  --uncased=False \\\n  --spiece_model_file=\"+PRETRAINED_MODEL_DIR+\"/spiece.model \\\n  --model_config_path=\"+PRETRAINED_MODEL_DIR+\"/xlnet_config.json \\\n  --init_checkpoint=\"+PRETRAINED_MODEL_DIR+\"/xlnet_model.ckpt \\\n  --max_seq_length=128 \\\n  --train_batch_size=8 \\\n  --eval_batch_size=8 \\\n  --num_hosts=1 \\\n  --num_core_per_host=1 \\\n  --learning_rate=2e-5 \\\n  --train_steps=4000 \\\n  --warmup_steps=500 \\\n  --save_steps=500 \\\n  --iterations=2\"\n\n! {train_command}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}