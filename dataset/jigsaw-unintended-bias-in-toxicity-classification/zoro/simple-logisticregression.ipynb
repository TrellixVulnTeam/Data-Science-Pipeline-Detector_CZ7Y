{"cells":[{"metadata":{},"cell_type":"markdown","source":"# GOAL\nIn this competition we are asked to build a model that recognizes toxicity and minimizes unintended bias"},{"metadata":{},"cell_type":"markdown","source":"### `Table of contents`\n\n1. [Loading packages](#load)\n2. [Understainding unintended bias](#bias)\n3. [loading data](#data)\n4. [Data Cleaning](#clean)\n5. [Training data](#traindata)\n6. [Baseline Model](#model)\n7. [Traning Stage](#modeltrain)\n8. [Prediction](#Prediction)\n9. [Submission](#Submission)"},{"metadata":{},"cell_type":"markdown","source":"## Loading packages <a class=\"anchor\" id=\"load\"></a>"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_is_fitted\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy import sparse\nimport re\nimport string","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"## Understainding unintended bias <a class=\"anchor\" id=\"bias\"></a>"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"HTML('<iframe width=\"800\" height=\"400\" src=\"https://www.youtube.com/embed/59bMh59JQDo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## loading data <a class=\"anchor\" id=\"data\"></a>"},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"Examples\n\nSome examples of comments and their associated toxicity and identity labels. Label values range from 0.0 - 1.0 represented the fraction of raters who believed the label fit the comment.\n\n1. Comment: I'm a white woman in my late 60's and believe me, they are not too crazy about me either!!\n\n    Toxicity Labels:` All 0.0`\n    \n    Identity Mention Labels: `female: 1.0, white: 1.0 (all others 0.0)`\n\n2. Comment: Why would you assume that the nurses in this story were women?\n\n    Toxicity Labels: `All 0.0`\n    \n    Identity Mention Labels: `female: 0.8 (all others 0.0)`\n\n3. Comment: Continue to stand strong LGBT community. Yes, indeed, you'll overcome and you have.\n\n    Toxicity Labels: `All 0.0`\n    \n    Identity Mention Labels: `homosexual_gay_or_lesbian: 0.8, bisexual: 0.6, transgender: 0.3 (all others 0.0)`"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning <a class=\"anchor\" id=\"clean\"></a>\n\n`TfidfVectorizer` - It Transforms text to feature vectors that can be used as input to estimator."},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"text = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return text.sub(r' \\1 ', s).split()\nlength = train_df.shape[0]\nVectorize = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training data <a class=\"anchor\" id=\"traindata\"></a>"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"train = Vectorize.fit_transform(train_df[\"comment_text\"])\ntest = Vectorize.transform(test_df[\"comment_text\"])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#Target\ny = np.where(train_df['target'] >= 0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model <a class=\"anchor\" id=\"model\"></a>"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n    def __init__(self, C=1.0, dual=False, n_jobs=1):\n        self.C = C\n        self.dual = dual\n        self.n_jobs = n_jobs\n\n    def predict(self, x):\n        # Verify that model has been fit\n        check_is_fitted(self, ['_r', '_clf'])\n        return self._clf.predict(x.multiply(self._r))\n\n    def predict_proba(self, x):\n        # Verify that model has been fit\n        check_is_fitted(self, ['_r', '_clf'])\n        return self._clf.predict_proba(x.multiply(self._r))\n\n    def fit(self, x, y):\n        y = y\n        x, y = check_X_y(x, y, accept_sparse=True)\n\n        def pr(x, y_i, y):\n            p = x[y==y_i].sum(0)\n            return (p+1) / ((y==y_i).sum()+1)\n        \n        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n        x_nb = x.multiply(self._r)\n        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n        return self","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Traning Stage <a class=\"anchor\" id=\"modeltrain\"></a>"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"NbSvm = NbSvmClassifier(C=1.5, dual=True, n_jobs=-1)\nNbSvm.fit(train, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction <a class=\"anchor\" id=\"Prediction\"></a>"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"prediction=NbSvm.predict_proba(test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission <a class=\"anchor\" id=\"Submission\"></a>"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['prediction'] = prediction\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Refrence : \n[Kernel](https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}