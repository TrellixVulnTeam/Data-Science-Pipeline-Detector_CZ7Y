{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Introduction**\n\nHello All,\n\nI'm a beginner in NLP and machine learning that I have recently started to explore. I have learned Keras and tensorflow and I wanted to impliment a bert kernal in keras, so I found out this github repository https://github.com/CyberZHG/keras-bert which is also mentioned in https://www.kaggle.com/httpwwwfszyc/bert-keras-with-warmup-and-excluding-wd-parameters/notebook, I packed this in my dataset https://www.kaggle.com/gauravs90/keras-bert-by-cyberzhg-github, I have to create this dataset as existing ones did not include the tokenizer and AdamWarmup.\n\nThanks for Jon Mischo (https://www.kaggle.com/supertaz) for uploading BERT Models + Scripts :)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Copy All the files to working directory**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_bert' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_pos_embd' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_embed_sim' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_position_wise_feed_forward' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_layer_normalization' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_self_attention' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_multi_head' '/kaggle/working'\n!cp -r '../input/keras-bert-by-cyberzhg-github/keras_bert/keras_transformer' '/kaggle/working'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras as keras\nimport keras.backend as K\nfrom keras.models import load_model\n\nfrom keras_bert import load_trained_model_from_checkpoint, load_vocabulary\nfrom keras_bert import Tokenizer\nfrom keras_bert import AdamWarmup, calc_train_steps\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEQ_LEN = 64\nBATCH_SIZE = 128\nEPOCHS = 1\nLR = 1e-4\n\npretrained_path = '../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12'\nconfig_path = os.path.join(pretrained_path, 'bert_config.json')\ncheckpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\nvocab_path = os.path.join(pretrained_path, 'vocab.txt')\n\nDATA_COLUMN = 'comment_text'\nLABEL_COLUMN = 'target'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get Tokenizer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"token_dict = load_vocabulary(vocab_path)\ntokenizer = Tokenizer(token_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load and Convert to data that BERT understand**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_data(data_df):\n    global tokenizer\n    indices, targets = [], []\n    for i in tqdm(range(len(data_df))):\n        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n        indices.append(ids)\n        targets.append(data_df[LABEL_COLUMN][i])\n    items = list(zip(indices, targets))\n    np.random.shuffle(items)\n    indices, targets = zip(*items)\n    indices = np.array(indices)\n    return [indices, np.zeros_like(indices)], np.array(targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(path):\n    data_df = pd.read_csv(path, nrows=10000)\n    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n    data_x, data_y = convert_data(data_df)\n    return data_x, data_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, train_y = load_data('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Model from Checkpoint**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_trained_model_from_checkpoint(\n    config_path,\n    checkpoint_path,\n    training=True,\n    trainable=True,\n    seq_len=SEQ_LEN,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create Keras Model and compile it**"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = model.inputs[:2]\ndense = model.layers[-3].output\noutputs = keras.layers.Dense(1, activation='sigmoid', kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n                             name = 'real_output')(dense)\n\ndecay_steps, warmup_steps = calc_train_steps(\n    train_y.shape[0],\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n)\n\nmodel = keras.models.Model(inputs, outputs)\nmodel.compile(\n    AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=LR),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sess = K.get_session()\nuninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\ninit_op = tf.variables_initializer(\n    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n)\nsess.run(init_op)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n        train_x,\n        train_y,\n        epochs=EPOCHS,\n        batch_size=BATCH_SIZE,\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load the test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_test(test_df):\n    global tokenizer\n    indices = []\n    for i in tqdm(range(len(test_df))):\n        ids, segments = tokenizer.encode(test_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n        indices.append(ids)\n    indices = np.array(indices)\n    return [indices, np.zeros_like(indices)]\n\ndef load_test(path):\n    data_df = pd.read_csv(path, nrows=5000)\n    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n    data_x = convert_test(data_df)\n    return data_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = load_test('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict and Submit**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test_x)\nsubmission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv', index_col='id', nrows=5000)\nsubmission['prediction'] = prediction\nsubmission.reset_index(drop=False, inplace=True)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}