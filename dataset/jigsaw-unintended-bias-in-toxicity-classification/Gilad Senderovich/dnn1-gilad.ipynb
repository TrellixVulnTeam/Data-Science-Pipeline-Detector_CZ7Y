{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# my imports\nfrom shutil import copyfile\nimport nltk\nfrom nltk.corpus import stopwords, words\nimport os, sys, re, collections, string\nfrom operator import itemgetter as at\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom gensim.models import Word2Vec\nfrom sklearn.feature_extraction import text\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, auc, confusion_matrix\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nimport lightgbm as lgb\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom collections import Counter\nfrom nltk.corpus import brown\nfrom nltk.stem import SnowballStemmer\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.utils.fixes import signature\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingClassifier as xgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nstop_words = set(stopwords.words('english')) \n","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets Load the data:\nJIGSAW_PATH = \"../input/\"\ntrain = pd.read_csv(os.path.join(JIGSAW_PATH,'train.csv'), index_col='id')\ntest = pd.read_csv(os.path.join(JIGSAW_PATH,'test.csv'), index_col='id')\n","execution_count":49,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  mask |= (ar1 == a)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.dropna(subset = ['comment_text'], axis=0)\ntrain.isna().sum()\ntrain.shape","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"(144388, 44)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Preprocess_:\n#     def __init__(self):\n#         pass\n    \n    @staticmethod     \n    def remove_html(given_text):\n        \"\"\" remove html format from a string\"\"\"\n        html_regex = r\"<[^>]*>\"\n        return re.sub(html_regex,\" \",given_text)\n\n    @staticmethod \n    def remove_punct(given_text):\n        \"remove punctuation from a string \"\n        punct_regex = r\"[^\\s\\w<>]\"\n        return re.sub(punct_regex,\" \",given_text)\n\n    @staticmethod \n    def remove_stopwords(given_text, stop_words):\n#         stop = stopwords.words('english')\n        return \" \".join(x for x in given_text.split() if x not in stop_words)\n\n    @staticmethod \n    def num_tokenizaion(given_text):\n        num_regex = r\"\\d[\\d\\.\\$]*\"\n        return re.sub(num_regex,\"<NUM>\",given_text)\n    \n    @staticmethod \n    def connect_very_with_next_word(given_text):\n        my_regex = r\"(?<=\\svery)\\s\"\n        return re.sub(my_regex,\"_\", given_text)\n    \n    @staticmethod \n    def get_last_sentense(given_text):\n        return given_text.split(r'. [A-Z]')[-1]\n    \n    @staticmethod\n    def reduce_lengthening(given_text):\n        pattern = re.compile(r\"(.)\\1{2,}\")\n        return pattern.sub(r\"\\1\\1\", given_text)\n\n    @staticmethod\n    def correct_word_(given_text):\n        return \" \".join([difflib.get_close_matches(word, words.words(), n=1)[0]\n                for word in given_text.split()])\n    \n    @staticmethod\n    def lower_case(given_text):\n        return \" \".join([word.lower()\n                for word in given_text.split()])     ","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_get_pr_curve(y_test, y_score, title_=''):\n    print()\n    preds = y_score[:, 0]\n    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n\n    step_kwargs = ({'step': 'post'}\n                   if 'step' in signature(plt.fill_between).parameters\n                   else {})\n    plt.step(recall, precision, color='b', alpha=0.2,\n             where='post')\n    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title(title_)\n    plt.show()\n    return precision, recall, thresholds","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cleanining the text:\ndef clean_text(text_series):\n    clean_text_series = text_series.apply(lambda x: x.lower())\\\n    .apply(lambda x: Preprocess_.remove_punct(x))\\\n    .apply(lambda x: Preprocess_.num_tokenizaion(x))\n    return clean_text_series\n\n\ndef tokenize(s):\n    return text.sub(r' \\1 ', s).split()","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.comment_text = clean_text(train.comment_text)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's build our first model - we will use a TFIDF vectorizer with 1 to 3 grams:\nvectorizer = text.TfidfVectorizer(TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1))\nvectorizer.fit(train.comment_text)\n# BATCHSIZE = len()\n# voc_ = {}\n# for i in range(BATCHSIZE,len(ballanced_train),BATCHSIZE):\n#     print(i)\n#     vectorizer.fit(ballanced_train[(i-BATCHSIZE) : i].comment_text)\n#     voc_ = {k: vectorizer.vocabulary_.get(k, 0)\n#             + voc_.get(k, 0) \n#             for k in set(vectorizer.vocabulary_) \n#             | set(voc_) }","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8',\n        input=TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=1,\n        stop_words=None, strip_accents='unicode', sublinear_tf=1,\n        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n        tokenizer=<function tokenize at 0x7f435c2ad488>, use_idf=1,\n        vocabulary=None),\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n        stop_words=None, strip_accents=None, sublinear_tf=False,\n        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n        vocabulary=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = vectorizer.transform(train.comment_text)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(C=1.0, dual=False, n_jobs=1)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = \\\ntrain_test_split(X,\n                 [1 if val > 0.5 else 0 for val in train.target],\n                 test_size=0.3,\n                 random_state=42)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":73,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","name":"stderr"},{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=1,\n          penalty='l2', random_state=None, solver='warn', tol=0.0001,\n          verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicions_train = model.predict(X_train)\npredicions_test = model.predict(X_test)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, predicions_test))\n# confusion_matrix()","execution_count":75,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.88      0.94      0.91     21821\n           1       0.94      0.87      0.90     21496\n\n   micro avg       0.91      0.91      0.91     43317\n   macro avg       0.91      0.91      0.91     43317\nweighted avg       0.91      0.91      0.91     43317\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":76,"outputs":[{"output_type":"execute_result","execution_count":76,"data":{"text/plain":"                                              comment_text\nid                                                        \n7000000  Jeff Sessions is another one of Trump's Orwell...\n7000001  I actually inspected the infrastructure on Gra...\n7000002  No it won't . That's just wishful thinking on ...\n7000003  Instead of wringing our hands and nibbling the...\n7000004  how many of you commenters have garbage piled ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7000000</th>\n      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n    </tr>\n    <tr>\n      <th>7000001</th>\n      <td>I actually inspected the infrastructure on Gra...</td>\n    </tr>\n    <tr>\n      <th>7000002</th>\n      <td>No it won't . That's just wishful thinking on ...</td>\n    </tr>\n    <tr>\n      <th>7000003</th>\n      <td>Instead of wringing our hands and nibbling the...</td>\n    </tr>\n    <tr>\n      <th>7000004</th>\n      <td>how many of you commenters have garbage piled ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(JIGSAW_PATH)\n","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"['test.csv', 'train.csv', 'sample_submission.csv']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit = pd.read_csv(os.path.join(JIGSAW_PATH,'sample_submission.csv'), index_col='id')\ndf_submit.head()","execution_count":78,"outputs":[{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"         prediction\nid                 \n7000000         0.0\n7000001         0.0\n7000002         0.0\n7000003         0.0\n7000004         0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7000000</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7000001</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7000002</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7000003</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7000004</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_proba(vectorizer.transform(clean_text(test.comment_text)))[:,1]\ndf_submit.prediction = predictions","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit.to_csv(os.path.join('submission.csv'), index=True)\ndf_submit.head()","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"         prediction\nid                 \n7000000    0.440684\n7000001    0.086695\n7000002    0.228119\n7000003    0.130384\n7000004    0.949728","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7000000</th>\n      <td>0.440684</td>\n    </tr>\n    <tr>\n      <th>7000001</th>\n      <td>0.086695</td>\n    </tr>\n    <tr>\n      <th>7000002</th>\n      <td>0.228119</td>\n    </tr>\n    <tr>\n      <th>7000003</th>\n      <td>0.130384</td>\n    </tr>\n    <tr>\n      <th>7000004</th>\n      <td>0.949728</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join('submission.csv'))","execution_count":38,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}