{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nThis is a simple demonstration of fine tuning BERT for this competition. We make use of the fact that BERT comes with a binary classification example we can repurpose for this competition (cola). I am confident it is not possible to fine-tune BERT for a complete epoch on the entire data set in 2HR kernel, so here I've had to make some adjustments to stay within the time limits:\n\n* We only use 1/3 of the training data\n* We use a maximum sequence length of 72\n\nI think compute might be a big factor in this competition!\n\nThanks for Jon Mischo (https://www.kaggle.com/supertaz) for uploading BERT Models + Scripts :)"},{"metadata":{},"cell_type":"markdown","source":"## Libraries\n\nWe'll add the BERT repo to path so we can import directly."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport collections\nimport csv\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport time\n\n# BERT files\n\nos.listdir(\"../input/pretrained-bert-including-scripts/master/bert-master\")\nsys.path.insert(0, '../input/pretrained-bert-including-scripts/master/bert-master')\n\nfrom run_classifier import *\nimport modeling\nimport optimization\nimport tokenization","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data\n\nTo keep things simple we adapt the competition data to the format that BERT expects for cola. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# import data\n\ntrain=pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest=pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n\n# remove new lines etc.\n\ntrain['comment_text'] = train['comment_text'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\n',  ' ', regex=True)\ntest['comment_text'] = test['comment_text'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\n',  ' ', regex=True)\n\n# force train into cola format, test is fine as it is\n\ntrain['dummy_1'] = 'meh'\ntrain['dummy_2'] = '*'\n\ntrain = train[['dummy_1','target','dummy_2','comment_text']]\ntrain['target'] = np.where(train['target']>=0.5,1,0)\n\ntrain = train.sample(frac=0.33)\n\n# export as tab seperated\n\ntrain.to_csv('train.tsv', sep='\\t', index=False, header=False)\ntest.to_csv('test.tsv', sep='\\t', index=False, header=True)","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters\n\nSee https://github.com/google-research/bert/blob/master/run_classifier.py"},{"metadata":{"trusted":true},"cell_type":"code","source":"task_name = 'cola'\nbert_config_file = '../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/bert_config.json'\nvocab_file = '../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/vocab.txt'\ninit_checkpoint = '../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/bert_model.ckpt'\ndata_dir = './'\noutput_dir = './'\ndo_lower_case = True\nmax_seq_length = 72\ndo_train = True\ndo_eval = False\ndo_predict = False\ntrain_batch_size = 32\neval_batch_size = 32\npredict_batch_size = 32\nlearning_rate = 2e-5 \nnum_train_epochs = 1.0\nwarmup_proportion = 0.1\nuse_tpu = False\nmaster = None\nsave_checkpoints_steps = 99999999 # <----- don't want to save any checkpoints\niterations_per_loop = 1000\nnum_tpu_cores = 8\ntpu_cluster_resolver = None","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine Tuning\n\nWe'll run over the entire data set for a single epoch. Following code is just lifted from run_classifier.py - apologies for the mess :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nprint(\"--------------------------------------------------------\")\nprint(\"Starting training ...\")\nprint(\"--------------------------------------------------------\")","execution_count":4,"outputs":[{"output_type":"stream","text":"--------------------------------------------------------\nStarting training ...\n--------------------------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n\nprocessor = ColaProcessor()\nlabel_list = processor.get_labels()\n\ntokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n\ntpu_cluster_resolver = None\nis_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n\nrun_config = tf.contrib.tpu.RunConfig(\n  cluster=tpu_cluster_resolver,\n  master=master,\n  model_dir=output_dir,\n  save_checkpoints_steps=save_checkpoints_steps,\n  tpu_config=tf.contrib.tpu.TPUConfig(\n      iterations_per_loop=iterations_per_loop,\n      num_shards=num_tpu_cores,\n      per_host_input_for_training=is_per_host))\n\ntrain_examples = processor.get_train_examples(data_dir)\nnum_train_steps = int(len(train_examples) / train_batch_size * num_train_epochs)\nnum_warmup_steps = int(num_train_steps * warmup_proportion)\n\nmodel_fn = model_fn_builder(\n      bert_config=bert_config,\n      num_labels=len(label_list),\n      init_checkpoint=init_checkpoint,\n      learning_rate=learning_rate,\n      num_train_steps=num_train_steps,\n      num_warmup_steps=num_warmup_steps,\n      use_tpu=use_tpu,\n      use_one_hot_embeddings=use_tpu)\n\nestimator = tf.contrib.tpu.TPUEstimator(\n      use_tpu=use_tpu,\n      model_fn=model_fn,\n      config=run_config,\n      train_batch_size=train_batch_size)\n      \n      \ntrain_file = os.path.join(output_dir, \"train.tf_record\")\n\nfile_based_convert_examples_to_features(\n    train_examples, label_list, max_seq_length, tokenizer, train_file)\n\ntf.logging.info(\"***** Running training *****\")\ntf.logging.info(\"  Num examples = %d\", len(train_examples))\ntf.logging.info(\"  Batch size = %d\", train_batch_size)\ntf.logging.info(\"  Num steps = %d\", num_train_steps)\n\ntrain_input_fn = file_based_input_fn_builder(\n    input_file=train_file,\n    seq_length=max_seq_length,\n    is_training=True,\n    drop_remainder=True)\n    \nestimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","execution_count":5,"outputs":[{"output_type":"stream","text":"\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\nIf you depend on functionality not listed there, please file an issue.\n\nWARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcb8146eae8>) includes params argument, but params are not passed to Estimator.\nINFO:tensorflow:Using config: {'_model_dir': './', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 99999999, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb86907eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\nINFO:tensorflow:_TPUContext: eval_on_tpu True\nWARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\nINFO:tensorflow:Writing example 0 of 595608\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: train-0\nINFO:tensorflow:tokens: [CLS] \" leave it to the globe and mail to f ##ois ##t up a headline that will seen by some as red meat and will make their faces cherry red in outrage . i dunn ##o , a person from down in tennessee saying to a reporter from canada : â€œ i ' m fine with canada , i think they ' re just an extension of the united states [SEP]\nINFO:tensorflow:input_ids: 101 1000 2681 2009 2000 1996 7595 1998 5653 2000 1042 10054 2102 2039 1037 17653 2008 2097 2464 2011 2070 2004 2417 6240 1998 2097 2191 2037 5344 9115 2417 1999 19006 1012 1045 14145 2080 1010 1037 2711 2013 2091 1999 5298 3038 2000 1037 6398 2013 2710 1024 1523 1045 1005 1049 2986 2007 2710 1010 1045 2228 2027 1005 2128 2074 2019 5331 1997 1996 2142 2163 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: train-1\nINFO:tensorflow:tokens: [CLS] \" off - hand , i would suppose some rules are rather minor , and need not be followed when the circumstances make following the rule irrational . i say \" \" off - hand , \" \" because i cannot think of any such rules right now , but suppose that not all rules have the same gravity . it ' s one thing to illegally park , something [SEP]\nINFO:tensorflow:input_ids: 101 1000 2125 1011 2192 1010 1045 2052 6814 2070 3513 2024 2738 3576 1010 1998 2342 2025 2022 2628 2043 1996 6214 2191 2206 1996 3627 23179 1012 1045 2360 1000 1000 2125 1011 2192 1010 1000 1000 2138 1045 3685 2228 1997 2151 2107 3513 2157 2085 1010 2021 6814 2008 2025 2035 3513 2031 1996 2168 8992 1012 2009 1005 1055 2028 2518 2000 17800 2380 1010 2242 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: train-2\nINFO:tensorflow:tokens: [CLS] mr . rein ##hard , my relative was assaulted in his bedroom by a 13 year old girl who had been so aggressive he had asked the state to move her four times . terrified , and right ##ly so , he told no one . he was a foster parent and was very sick . the police were trying to charge the girl for her many accusations - 6 [SEP]\nINFO:tensorflow:input_ids: 101 2720 1012 27788 11783 1010 2026 5816 2001 17536 1999 2010 5010 2011 1037 2410 2095 2214 2611 2040 2018 2042 2061 9376 2002 2018 2356 1996 2110 2000 2693 2014 2176 2335 1012 10215 1010 1998 2157 2135 2061 1010 2002 2409 2053 2028 1012 2002 2001 1037 6469 6687 1998 2001 2200 5305 1012 1996 2610 2020 2667 2000 3715 1996 2611 2005 2014 2116 13519 1011 1020 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: train-3\nINFO:tensorflow:tokens: [CLS] \" this dude should have likely kept his \" \" lips together . \" \" \" [SEP]\nINFO:tensorflow:input_ids: 101 1000 2023 12043 2323 2031 3497 2921 2010 1000 1000 2970 2362 1012 1000 1000 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: train-4\nINFO:tensorflow:tokens: [CLS] \" \" \" hey slaves ! if you just light ##en up about this ' in shack ##les ' thing your problems might disappear ! \" \" \" [SEP]\nINFO:tensorflow:input_ids: 101 1000 1000 1000 4931 7179 999 2065 2017 2074 2422 2368 2039 2055 2023 1005 1999 22200 4244 1005 2518 2115 3471 2453 10436 999 1000 1000 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:Writing example 10000 of 595608\nINFO:tensorflow:Writing example 20000 of 595608\nINFO:tensorflow:Writing example 30000 of 595608\nINFO:tensorflow:Writing example 40000 of 595608\nINFO:tensorflow:Writing example 50000 of 595608\nINFO:tensorflow:Writing example 60000 of 595608\nINFO:tensorflow:Writing example 70000 of 595608\nINFO:tensorflow:Writing example 80000 of 595608\nINFO:tensorflow:Writing example 90000 of 595608\nINFO:tensorflow:Writing example 100000 of 595608\nINFO:tensorflow:Writing example 110000 of 595608\nINFO:tensorflow:Writing example 120000 of 595608\nINFO:tensorflow:Writing example 130000 of 595608\nINFO:tensorflow:Writing example 140000 of 595608\nINFO:tensorflow:Writing example 150000 of 595608\nINFO:tensorflow:Writing example 160000 of 595608\nINFO:tensorflow:Writing example 170000 of 595608\nINFO:tensorflow:Writing example 180000 of 595608\nINFO:tensorflow:Writing example 190000 of 595608\nINFO:tensorflow:Writing example 200000 of 595608\nINFO:tensorflow:Writing example 210000 of 595608\nINFO:tensorflow:Writing example 220000 of 595608\nINFO:tensorflow:Writing example 230000 of 595608\nINFO:tensorflow:Writing example 240000 of 595608\nINFO:tensorflow:Writing example 250000 of 595608\nINFO:tensorflow:Writing example 260000 of 595608\nINFO:tensorflow:Writing example 270000 of 595608\nINFO:tensorflow:Writing example 280000 of 595608\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:Writing example 290000 of 595608\nINFO:tensorflow:Writing example 300000 of 595608\nINFO:tensorflow:Writing example 310000 of 595608\nINFO:tensorflow:Writing example 320000 of 595608\nINFO:tensorflow:Writing example 330000 of 595608\nINFO:tensorflow:Writing example 340000 of 595608\nINFO:tensorflow:Writing example 350000 of 595608\nINFO:tensorflow:Writing example 360000 of 595608\nINFO:tensorflow:Writing example 370000 of 595608\nINFO:tensorflow:Writing example 380000 of 595608\nINFO:tensorflow:Writing example 390000 of 595608\nINFO:tensorflow:Writing example 400000 of 595608\nINFO:tensorflow:Writing example 410000 of 595608\nINFO:tensorflow:Writing example 420000 of 595608\nINFO:tensorflow:Writing example 430000 of 595608\nINFO:tensorflow:Writing example 440000 of 595608\nINFO:tensorflow:Writing example 450000 of 595608\nINFO:tensorflow:Writing example 460000 of 595608\nINFO:tensorflow:Writing example 470000 of 595608\nINFO:tensorflow:Writing example 480000 of 595608\nINFO:tensorflow:Writing example 490000 of 595608\nINFO:tensorflow:Writing example 500000 of 595608\nINFO:tensorflow:Writing example 510000 of 595608\nINFO:tensorflow:Writing example 520000 of 595608\nINFO:tensorflow:Writing example 530000 of 595608\nINFO:tensorflow:Writing example 540000 of 595608\nINFO:tensorflow:Writing example 550000 of 595608\nINFO:tensorflow:Writing example 560000 of 595608\nINFO:tensorflow:Writing example 570000 of 595608\nINFO:tensorflow:Writing example 580000 of 595608\nINFO:tensorflow:Writing example 590000 of 595608\nINFO:tensorflow:***** Running training *****\nINFO:tensorflow:  Num examples = 595608\nINFO:tensorflow:  Batch size = 32\nINFO:tensorflow:  Num steps = 18612\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From ../input/pretrained-bert-including-scripts/master/bert-master/run_classifier.py:550: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.experimental.map_and_batch(...)`.\nWARNING:tensorflow:From ../input/pretrained-bert-including-scripts/master/bert-master/run_classifier.py:530: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Running train on CPU\nINFO:tensorflow:*** Features ***\nINFO:tensorflow:  name = input_ids, shape = (32, 72)\nINFO:tensorflow:  name = input_mask, shape = (32, 72)\nINFO:tensorflow:  name = is_real_example, shape = (32,)\nINFO:tensorflow:  name = label_ids, shape = (32,)\nINFO:tensorflow:  name = segment_ids, shape = (32, 72)\nWARNING:tensorflow:From ../input/pretrained-bert-including-scripts/master/bert-master/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWARNING:tensorflow:From ../input/pretrained-bert-including-scripts/master/bert-master/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dense instead.\nINFO:tensorflow:**** Trainable Variables ****\nINFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = output_weights:0, shape = (2, 768)\nINFO:tensorflow:  name = output_bias:0, shape = (2,)\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into ./model.ckpt.\nINFO:tensorflow:global_step/sec: 3.04391\nINFO:tensorflow:examples/sec: 97.405\nINFO:tensorflow:global_step/sec: 3.46664\nINFO:tensorflow:examples/sec: 110.933\nINFO:tensorflow:global_step/sec: 3.46764\nINFO:tensorflow:examples/sec: 110.965\nINFO:tensorflow:global_step/sec: 3.46945\nINFO:tensorflow:examples/sec: 111.022\nINFO:tensorflow:global_step/sec: 3.46719\nINFO:tensorflow:examples/sec: 110.95\nINFO:tensorflow:global_step/sec: 3.46934\nINFO:tensorflow:examples/sec: 111.019\nINFO:tensorflow:global_step/sec: 3.46951\nINFO:tensorflow:examples/sec: 111.024\nINFO:tensorflow:global_step/sec: 3.46986\nINFO:tensorflow:examples/sec: 111.035\nINFO:tensorflow:global_step/sec: 3.46809\nINFO:tensorflow:examples/sec: 110.979\nINFO:tensorflow:global_step/sec: 3.46921\nINFO:tensorflow:examples/sec: 111.015\nINFO:tensorflow:global_step/sec: 3.46804\nINFO:tensorflow:examples/sec: 110.977\nINFO:tensorflow:global_step/sec: 3.46766\nINFO:tensorflow:examples/sec: 110.965\nINFO:tensorflow:global_step/sec: 3.46695\nINFO:tensorflow:examples/sec: 110.942\nINFO:tensorflow:global_step/sec: 3.46853\nINFO:tensorflow:examples/sec: 110.993\nINFO:tensorflow:global_step/sec: 3.46909\nINFO:tensorflow:examples/sec: 111.011\nINFO:tensorflow:global_step/sec: 3.46616\nINFO:tensorflow:examples/sec: 110.917\nINFO:tensorflow:global_step/sec: 3.47072\nINFO:tensorflow:examples/sec: 111.063\nINFO:tensorflow:global_step/sec: 3.4707\nINFO:tensorflow:examples/sec: 111.062\nINFO:tensorflow:global_step/sec: 3.46951\nINFO:tensorflow:examples/sec: 111.024\nINFO:tensorflow:global_step/sec: 3.47027\nINFO:tensorflow:examples/sec: 111.049\nINFO:tensorflow:global_step/sec: 3.47012\nINFO:tensorflow:examples/sec: 111.044\nINFO:tensorflow:global_step/sec: 3.47034\nINFO:tensorflow:examples/sec: 111.051\nINFO:tensorflow:global_step/sec: 3.46833\nINFO:tensorflow:examples/sec: 110.987\nINFO:tensorflow:global_step/sec: 3.46806\nINFO:tensorflow:examples/sec: 110.978\nINFO:tensorflow:global_step/sec: 3.47106\nINFO:tensorflow:examples/sec: 111.074\nINFO:tensorflow:global_step/sec: 3.47071\nINFO:tensorflow:examples/sec: 111.063\nINFO:tensorflow:global_step/sec: 3.46709\nINFO:tensorflow:examples/sec: 110.947\nINFO:tensorflow:global_step/sec: 3.47046\nINFO:tensorflow:examples/sec: 111.055\nINFO:tensorflow:global_step/sec: 3.47085\nINFO:tensorflow:examples/sec: 111.067\nINFO:tensorflow:global_step/sec: 3.47156\nINFO:tensorflow:examples/sec: 111.09\nINFO:tensorflow:global_step/sec: 3.47123\nINFO:tensorflow:examples/sec: 111.079\nINFO:tensorflow:global_step/sec: 3.466\nINFO:tensorflow:examples/sec: 110.912\nINFO:tensorflow:global_step/sec: 3.46854\nINFO:tensorflow:examples/sec: 110.993\nINFO:tensorflow:global_step/sec: 3.46717\nINFO:tensorflow:examples/sec: 110.949\nINFO:tensorflow:global_step/sec: 3.4687\nINFO:tensorflow:examples/sec: 110.998\nINFO:tensorflow:global_step/sec: 3.46937\nINFO:tensorflow:examples/sec: 111.02\nINFO:tensorflow:global_step/sec: 3.47004\nINFO:tensorflow:examples/sec: 111.041\nINFO:tensorflow:global_step/sec: 3.4679\nINFO:tensorflow:examples/sec: 110.973\nINFO:tensorflow:global_step/sec: 3.47073\nINFO:tensorflow:examples/sec: 111.063\nINFO:tensorflow:global_step/sec: 3.47145\nINFO:tensorflow:examples/sec: 111.086\nINFO:tensorflow:global_step/sec: 3.47049\nINFO:tensorflow:examples/sec: 111.056\nINFO:tensorflow:global_step/sec: 3.47239\nINFO:tensorflow:examples/sec: 111.116\nINFO:tensorflow:global_step/sec: 3.47035\nINFO:tensorflow:examples/sec: 111.051\nINFO:tensorflow:global_step/sec: 3.47157\nINFO:tensorflow:examples/sec: 111.09\nINFO:tensorflow:global_step/sec: 3.46991\nINFO:tensorflow:examples/sec: 111.037\nINFO:tensorflow:global_step/sec: 3.4706\nINFO:tensorflow:examples/sec: 111.059\nINFO:tensorflow:global_step/sec: 3.46983\nINFO:tensorflow:examples/sec: 111.035\nINFO:tensorflow:global_step/sec: 3.47066\nINFO:tensorflow:examples/sec: 111.061\nINFO:tensorflow:global_step/sec: 3.4685\nINFO:tensorflow:examples/sec: 110.992\nINFO:tensorflow:global_step/sec: 3.47146\nINFO:tensorflow:examples/sec: 111.087\nINFO:tensorflow:global_step/sec: 3.47204\nINFO:tensorflow:examples/sec: 111.105\nINFO:tensorflow:global_step/sec: 3.46984\nINFO:tensorflow:examples/sec: 111.035\nINFO:tensorflow:global_step/sec: 3.46939\nINFO:tensorflow:examples/sec: 111.021\nINFO:tensorflow:global_step/sec: 3.47087\nINFO:tensorflow:examples/sec: 111.068\nINFO:tensorflow:global_step/sec: 3.47069\nINFO:tensorflow:examples/sec: 111.062\nINFO:tensorflow:global_step/sec: 3.47055\nINFO:tensorflow:examples/sec: 111.058\nINFO:tensorflow:global_step/sec: 3.47127\nINFO:tensorflow:examples/sec: 111.081\nINFO:tensorflow:global_step/sec: 3.47146\nINFO:tensorflow:examples/sec: 111.087\nINFO:tensorflow:global_step/sec: 3.47116\nINFO:tensorflow:examples/sec: 111.077\nINFO:tensorflow:global_step/sec: 3.47189\nINFO:tensorflow:examples/sec: 111.1\nINFO:tensorflow:global_step/sec: 3.47254\nINFO:tensorflow:examples/sec: 111.121\nINFO:tensorflow:global_step/sec: 3.47232\nINFO:tensorflow:examples/sec: 111.114\nINFO:tensorflow:global_step/sec: 3.47218\nINFO:tensorflow:examples/sec: 111.11\nINFO:tensorflow:global_step/sec: 3.47241\nINFO:tensorflow:examples/sec: 111.117\nINFO:tensorflow:global_step/sec: 3.47193\nINFO:tensorflow:examples/sec: 111.102\nINFO:tensorflow:global_step/sec: 3.47001\nINFO:tensorflow:examples/sec: 111.04\nINFO:tensorflow:global_step/sec: 3.47201\nINFO:tensorflow:examples/sec: 111.104\nINFO:tensorflow:global_step/sec: 3.47094\nINFO:tensorflow:examples/sec: 111.07\nINFO:tensorflow:global_step/sec: 3.47139\nINFO:tensorflow:examples/sec: 111.085\nINFO:tensorflow:global_step/sec: 3.47031\nINFO:tensorflow:examples/sec: 111.05\nINFO:tensorflow:global_step/sec: 3.47259\nINFO:tensorflow:examples/sec: 111.123\nINFO:tensorflow:global_step/sec: 3.47204\nINFO:tensorflow:examples/sec: 111.105\nINFO:tensorflow:global_step/sec: 3.47\nINFO:tensorflow:examples/sec: 111.04\nINFO:tensorflow:global_step/sec: 3.46973\nINFO:tensorflow:examples/sec: 111.031\nINFO:tensorflow:global_step/sec: 3.47232\nINFO:tensorflow:examples/sec: 111.114\nINFO:tensorflow:global_step/sec: 3.4703\nINFO:tensorflow:examples/sec: 111.05\nINFO:tensorflow:global_step/sec: 3.46926\nINFO:tensorflow:examples/sec: 111.016\nINFO:tensorflow:global_step/sec: 3.47124\nINFO:tensorflow:examples/sec: 111.08\nINFO:tensorflow:global_step/sec: 3.47276\nINFO:tensorflow:examples/sec: 111.128\nINFO:tensorflow:global_step/sec: 3.47201\nINFO:tensorflow:examples/sec: 111.104\nINFO:tensorflow:global_step/sec: 3.47047\nINFO:tensorflow:examples/sec: 111.055\nINFO:tensorflow:global_step/sec: 3.47176\nINFO:tensorflow:examples/sec: 111.096\nINFO:tensorflow:global_step/sec: 3.47268\nINFO:tensorflow:examples/sec: 111.126\nINFO:tensorflow:global_step/sec: 3.47322\nINFO:tensorflow:examples/sec: 111.143\nINFO:tensorflow:global_step/sec: 3.47159\nINFO:tensorflow:examples/sec: 111.091\nINFO:tensorflow:global_step/sec: 3.47147\nINFO:tensorflow:examples/sec: 111.087\nINFO:tensorflow:global_step/sec: 3.46999\nINFO:tensorflow:examples/sec: 111.04\nINFO:tensorflow:global_step/sec: 3.47292\nINFO:tensorflow:examples/sec: 111.134\nINFO:tensorflow:global_step/sec: 3.47275\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:examples/sec: 111.128\nINFO:tensorflow:global_step/sec: 3.47312\nINFO:tensorflow:examples/sec: 111.14\nINFO:tensorflow:global_step/sec: 3.47157\nINFO:tensorflow:examples/sec: 111.09\nINFO:tensorflow:global_step/sec: 3.47053\nINFO:tensorflow:examples/sec: 111.057\nINFO:tensorflow:global_step/sec: 3.47322\nINFO:tensorflow:examples/sec: 111.143\nINFO:tensorflow:global_step/sec: 3.47222\nINFO:tensorflow:examples/sec: 111.111\nINFO:tensorflow:global_step/sec: 3.47291\nINFO:tensorflow:examples/sec: 111.133\nINFO:tensorflow:global_step/sec: 3.47202\nINFO:tensorflow:examples/sec: 111.105\nINFO:tensorflow:global_step/sec: 3.4716\nINFO:tensorflow:examples/sec: 111.091\nINFO:tensorflow:global_step/sec: 3.47136\nINFO:tensorflow:examples/sec: 111.084\nINFO:tensorflow:global_step/sec: 3.4704\nINFO:tensorflow:examples/sec: 111.053\nINFO:tensorflow:global_step/sec: 3.47098\nINFO:tensorflow:examples/sec: 111.071\nINFO:tensorflow:global_step/sec: 3.47249\nINFO:tensorflow:examples/sec: 111.12\nINFO:tensorflow:global_step/sec: 3.47082\nINFO:tensorflow:examples/sec: 111.066\nINFO:tensorflow:global_step/sec: 3.47208\nINFO:tensorflow:examples/sec: 111.106\nINFO:tensorflow:global_step/sec: 3.47358\nINFO:tensorflow:examples/sec: 111.154\nINFO:tensorflow:global_step/sec: 3.47277\nINFO:tensorflow:examples/sec: 111.129\nINFO:tensorflow:global_step/sec: 3.47262\nINFO:tensorflow:examples/sec: 111.124\nINFO:tensorflow:global_step/sec: 3.47089\nINFO:tensorflow:examples/sec: 111.068\nINFO:tensorflow:global_step/sec: 3.47126\nINFO:tensorflow:examples/sec: 111.08\nINFO:tensorflow:global_step/sec: 3.47311\nINFO:tensorflow:examples/sec: 111.14\nINFO:tensorflow:global_step/sec: 3.47206\nINFO:tensorflow:examples/sec: 111.106\nINFO:tensorflow:global_step/sec: 3.47154\nINFO:tensorflow:examples/sec: 111.089\nINFO:tensorflow:global_step/sec: 3.47023\nINFO:tensorflow:examples/sec: 111.047\nINFO:tensorflow:global_step/sec: 3.46809\nINFO:tensorflow:examples/sec: 110.979\nINFO:tensorflow:global_step/sec: 3.47092\nINFO:tensorflow:examples/sec: 111.069\nINFO:tensorflow:global_step/sec: 3.47156\nINFO:tensorflow:examples/sec: 111.09\nINFO:tensorflow:global_step/sec: 3.47075\nINFO:tensorflow:examples/sec: 111.064\nINFO:tensorflow:global_step/sec: 3.47256\nINFO:tensorflow:examples/sec: 111.122\nINFO:tensorflow:global_step/sec: 3.47333\nINFO:tensorflow:examples/sec: 111.146\nINFO:tensorflow:global_step/sec: 3.47068\nINFO:tensorflow:examples/sec: 111.062\nINFO:tensorflow:global_step/sec: 3.47265\nINFO:tensorflow:examples/sec: 111.125\nINFO:tensorflow:global_step/sec: 3.47369\nINFO:tensorflow:examples/sec: 111.158\nINFO:tensorflow:global_step/sec: 3.47226\nINFO:tensorflow:examples/sec: 111.112\nINFO:tensorflow:global_step/sec: 3.4734\nINFO:tensorflow:examples/sec: 111.149\nINFO:tensorflow:global_step/sec: 3.47009\nINFO:tensorflow:examples/sec: 111.043\nINFO:tensorflow:global_step/sec: 3.47249\nINFO:tensorflow:examples/sec: 111.12\nINFO:tensorflow:global_step/sec: 3.47336\nINFO:tensorflow:examples/sec: 111.147\nINFO:tensorflow:global_step/sec: 3.47282\nINFO:tensorflow:examples/sec: 111.13\nINFO:tensorflow:global_step/sec: 3.47115\nINFO:tensorflow:examples/sec: 111.077\nINFO:tensorflow:global_step/sec: 3.47239\nINFO:tensorflow:examples/sec: 111.116\nINFO:tensorflow:global_step/sec: 3.47253\nINFO:tensorflow:examples/sec: 111.121\nINFO:tensorflow:global_step/sec: 3.47291\nINFO:tensorflow:examples/sec: 111.133\nINFO:tensorflow:global_step/sec: 3.47295\nINFO:tensorflow:examples/sec: 111.134\nINFO:tensorflow:global_step/sec: 3.47214\nINFO:tensorflow:examples/sec: 111.109\nINFO:tensorflow:global_step/sec: 3.47456\nINFO:tensorflow:examples/sec: 111.186\nINFO:tensorflow:global_step/sec: 3.47131\nINFO:tensorflow:examples/sec: 111.082\nINFO:tensorflow:global_step/sec: 3.47286\nINFO:tensorflow:examples/sec: 111.132\nINFO:tensorflow:global_step/sec: 3.46418\nINFO:tensorflow:examples/sec: 110.854\nINFO:tensorflow:global_step/sec: 3.45508\nINFO:tensorflow:examples/sec: 110.562\nINFO:tensorflow:global_step/sec: 3.45338\nINFO:tensorflow:examples/sec: 110.508\nINFO:tensorflow:global_step/sec: 3.45453\nINFO:tensorflow:examples/sec: 110.545\nINFO:tensorflow:global_step/sec: 3.45461\nINFO:tensorflow:examples/sec: 110.547\nINFO:tensorflow:global_step/sec: 3.45542\nINFO:tensorflow:examples/sec: 110.574\nINFO:tensorflow:global_step/sec: 3.45627\nINFO:tensorflow:examples/sec: 110.601\nINFO:tensorflow:global_step/sec: 3.45557\nINFO:tensorflow:examples/sec: 110.578\nINFO:tensorflow:global_step/sec: 3.45546\nINFO:tensorflow:examples/sec: 110.575\nINFO:tensorflow:global_step/sec: 3.4542\nINFO:tensorflow:examples/sec: 110.534\nINFO:tensorflow:global_step/sec: 3.45334\nINFO:tensorflow:examples/sec: 110.507\nINFO:tensorflow:global_step/sec: 3.45421\nINFO:tensorflow:examples/sec: 110.535\nINFO:tensorflow:global_step/sec: 3.45415\nINFO:tensorflow:examples/sec: 110.533\nINFO:tensorflow:global_step/sec: 3.45387\nINFO:tensorflow:examples/sec: 110.524\nINFO:tensorflow:global_step/sec: 3.45491\nINFO:tensorflow:examples/sec: 110.557\nINFO:tensorflow:global_step/sec: 3.45456\nINFO:tensorflow:examples/sec: 110.546\nINFO:tensorflow:global_step/sec: 3.45428\nINFO:tensorflow:examples/sec: 110.537\nINFO:tensorflow:global_step/sec: 3.4548\nINFO:tensorflow:examples/sec: 110.554\nINFO:tensorflow:global_step/sec: 3.45432\nINFO:tensorflow:examples/sec: 110.538\nINFO:tensorflow:global_step/sec: 3.4545\nINFO:tensorflow:examples/sec: 110.544\nINFO:tensorflow:global_step/sec: 3.46113\nINFO:tensorflow:examples/sec: 110.756\nINFO:tensorflow:global_step/sec: 3.46045\nINFO:tensorflow:examples/sec: 110.734\nINFO:tensorflow:global_step/sec: 3.46065\nINFO:tensorflow:examples/sec: 110.741\nINFO:tensorflow:global_step/sec: 3.46236\nINFO:tensorflow:examples/sec: 110.796\nINFO:tensorflow:global_step/sec: 3.45857\nINFO:tensorflow:examples/sec: 110.674\nINFO:tensorflow:global_step/sec: 3.46173\nINFO:tensorflow:examples/sec: 110.775\nINFO:tensorflow:global_step/sec: 3.46121\nINFO:tensorflow:examples/sec: 110.759\nINFO:tensorflow:global_step/sec: 3.46189\nINFO:tensorflow:examples/sec: 110.781\nINFO:tensorflow:global_step/sec: 3.46151\nINFO:tensorflow:examples/sec: 110.768\nINFO:tensorflow:global_step/sec: 3.46186\nINFO:tensorflow:examples/sec: 110.78\nINFO:tensorflow:global_step/sec: 3.46052\nINFO:tensorflow:examples/sec: 110.737\nINFO:tensorflow:global_step/sec: 3.46211\nINFO:tensorflow:examples/sec: 110.788\nINFO:tensorflow:global_step/sec: 3.46154\nINFO:tensorflow:examples/sec: 110.769\nINFO:tensorflow:global_step/sec: 3.46169\nINFO:tensorflow:examples/sec: 110.774\nINFO:tensorflow:global_step/sec: 3.46179\nINFO:tensorflow:examples/sec: 110.777\nINFO:tensorflow:global_step/sec: 3.46221\nINFO:tensorflow:examples/sec: 110.791\nINFO:tensorflow:global_step/sec: 3.46255\nINFO:tensorflow:examples/sec: 110.802\nINFO:tensorflow:global_step/sec: 3.46264\nINFO:tensorflow:examples/sec: 110.805\nINFO:tensorflow:global_step/sec: 3.46149\nINFO:tensorflow:examples/sec: 110.768\nINFO:tensorflow:global_step/sec: 3.46304\nINFO:tensorflow:examples/sec: 110.817\nINFO:tensorflow:global_step/sec: 3.46133\nINFO:tensorflow:examples/sec: 110.762\nINFO:tensorflow:global_step/sec: 3.4605\nINFO:tensorflow:examples/sec: 110.736\nINFO:tensorflow:global_step/sec: 3.46223\nINFO:tensorflow:examples/sec: 110.791\nINFO:tensorflow:global_step/sec: 3.46172\nINFO:tensorflow:examples/sec: 110.775\nINFO:tensorflow:global_step/sec: 3.46198\nINFO:tensorflow:examples/sec: 110.783\nINFO:tensorflow:global_step/sec: 3.46106\nINFO:tensorflow:examples/sec: 110.754\nINFO:tensorflow:global_step/sec: 3.46194\nINFO:tensorflow:examples/sec: 110.782\nINFO:tensorflow:global_step/sec: 3.46216\nINFO:tensorflow:examples/sec: 110.789\nINFO:tensorflow:global_step/sec: 3.46278\nINFO:tensorflow:examples/sec: 110.809\nINFO:tensorflow:global_step/sec: 3.4617\nINFO:tensorflow:examples/sec: 110.774\nINFO:tensorflow:Saving checkpoints for 18612 into ./model.ckpt.\nINFO:tensorflow:Loss for final step: 0.4782197.\nINFO:tensorflow:training_loop marked as finished\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<tensorflow.contrib.tpu.python.tpu.tpu_estimator.TPUEstimator at 0x7fcb86907b00>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"end = time.time()\nprint(\"--------------------------------------------------------\")\nprint(\"Training complete in \", end - start, \" seconds\")\nprint(\"--------------------------------------------------------\")","execution_count":6,"outputs":[{"output_type":"stream","text":"--------------------------------------------------------\nTraining complete in  6220.163527011871  seconds\n--------------------------------------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Inference\n\nFor some reason I've had issues with batch_size - I'm not quite sure where this parameter comes from. For now I just hard code it in the function below, which should work fine. As I spend more time with the code, hopefully it becomes clearer.\n\nInference should only take about 10 minutes for public test set (~100k rows).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def file_based_input_fn_builder(input_file, seq_length, is_training,\n                                drop_remainder):\n  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n\n  name_to_features = {\n      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n      \"label_ids\": tf.FixedLenFeature([], tf.int64),\n      \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n  }\n\n  def _decode_record(record, name_to_features):\n    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n      t = example[name]\n      if t.dtype == tf.int64:\n        t = tf.to_int32(t)\n      example[name] = t\n\n    return example\n\n  def input_fn(params):\n    \"\"\"The actual input function.\"\"\"\n    \n    #batch_size = params[\"batch_size\"]\n    batch_size = 64 # <----- hardcoded batch_size added here \n    \n    # For training, we want a lot of parallel reading and shuffling.\n    # For eval, we want no shuffling and parallel reading doesn't matter.\n    d = tf.data.TFRecordDataset(input_file)\n    if is_training:\n      d = d.repeat()\n      d = d.shuffle(buffer_size=100)\n\n    d = d.apply(\n        tf.contrib.data.map_and_batch(\n            lambda record: _decode_record(record, name_to_features),\n            batch_size=batch_size,\n            drop_remainder=drop_remainder))\n\n    return d\n\n  return input_fn","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nprint(\"--------------------------------------------------------\")\nprint(\"Starting inference ...\")\nprint(\"--------------------------------------------------------\")","execution_count":8,"outputs":[{"output_type":"stream","text":"--------------------------------------------------------\nStarting inference ...\n--------------------------------------------------------\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"predict_examples = processor.get_test_examples(data_dir)\nnum_actual_predict_examples = len(predict_examples)\n\npredict_file = os.path.join(output_dir, \"predict.tf_record\")\n\nfile_based_convert_examples_to_features(predict_examples, label_list,\n                                        max_seq_length, tokenizer,\n                                        predict_file)\n\ntf.logging.info(\"***** Running prediction*****\")\ntf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n                len(predict_examples), num_actual_predict_examples,\n                len(predict_examples) - num_actual_predict_examples)\ntf.logging.info(\"  Batch size = %d\", predict_batch_size)\n\npredict_drop_remainder = True if use_tpu else False\npredict_input_fn = file_based_input_fn_builder(\n    input_file=predict_file,\n    seq_length=max_seq_length,\n    is_training=False,\n    drop_remainder=predict_drop_remainder)\n\nresult = estimator.predict(input_fn=predict_input_fn)\n\noutput_predict_file = os.path.join(output_dir, \"test_results.tsv\")\n\nwith tf.gfile.GFile(output_predict_file, \"w\") as writer:\n    num_written_lines = 0\n    tf.logging.info(\"***** Predict results *****\")\n    for (i, prediction) in enumerate(result):\n        probabilities = prediction[\"probabilities\"]\n        if i >= num_actual_predict_examples:\n            break\n        output_line = \"\\t\".join(\n            str(class_probability)\n            for class_probability in probabilities) + \"\\n\"\n        writer.write(output_line)\n        num_written_lines += 1\n","execution_count":9,"outputs":[{"output_type":"stream","text":"INFO:tensorflow:Writing example 0 of 97320\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: test-1\nINFO:tensorflow:tokens: [CLS] jeff sessions is another one of trump ' s or ##well ##ian choices . he believes and has believed his entire career the exact opposite of what the position requires . [SEP]\nINFO:tensorflow:input_ids: 101 5076 6521 2003 2178 2028 1997 8398 1005 1055 2030 4381 2937 9804 1012 2002 7164 1998 2038 3373 2010 2972 2476 1996 6635 4500 1997 2054 1996 2597 5942 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: test-2\nINFO:tensorflow:tokens: [CLS] i actually inspected the infrastructure on grand chief stewart philip ' s home pen ##tic ##ton first nation in both 2010 and 2013 . exactly zero projects that had been identified in previous inspection reports had been funded by the federal government , and the entire band was housed in at ##co trailers . clearly the harper conservatives had already reduced the cash his band was sent to zero . [SEP]\nINFO:tensorflow:input_ids: 101 1045 2941 20456 1996 6502 2006 2882 2708 5954 5170 1005 1055 2188 7279 4588 2669 2034 3842 1999 2119 2230 1998 2286 1012 3599 5717 3934 2008 2018 2042 4453 1999 3025 10569 4311 2018 2042 6787 2011 1996 2976 2231 1010 1998 1996 2972 2316 2001 7431 1999 2012 3597 21389 1012 4415 1996 8500 11992 2018 2525 4359 1996 5356 2010 2316 2001 2741 2000 5717 1012 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: test-3\nINFO:tensorflow:tokens: [CLS] no it won ' t . that ' s just wish ##ful thinking on democrats fault . for the 100 th time , walker cited the cost of drug users treatment as being lost with obama ##care . i laugh every time i hear a liberal claim republicans want to hurt people , and that ' s why they dumped obama ##care . [SEP]\nINFO:tensorflow:input_ids: 101 2053 2009 2180 1005 1056 1012 2008 1005 1055 2074 4299 3993 3241 2006 8037 6346 1012 2005 1996 2531 16215 2051 1010 5232 6563 1996 3465 1997 4319 5198 3949 2004 2108 2439 2007 8112 16302 1012 1045 4756 2296 2051 1045 2963 1037 4314 4366 10643 2215 2000 3480 2111 1010 1998 2008 1005 1055 2339 2027 14019 8112 16302 1012 102 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: test-4\nINFO:tensorflow:tokens: [CLS] instead of wr ##inging our hands and ni ##bbling the periphery of the issue , how about we face the actual issue head on ? i would support a city ordinance against lo ##iter ##ing , and app ##lau ##d city council ##ors who champion a real and permanent solution . the details could be determined , but would include a limit to persons sitting , standing , lying , [SEP]\nINFO:tensorflow:input_ids: 101 2612 1997 23277 23180 2256 2398 1998 9152 15343 1996 23275 1997 1996 3277 1010 2129 2055 2057 2227 1996 5025 3277 2132 2006 1029 1045 2052 2490 1037 2103 16692 2114 8840 21646 2075 1010 1998 10439 17298 2094 2103 2473 5668 2040 3410 1037 2613 1998 4568 5576 1012 1996 4751 2071 2022 4340 1010 2021 2052 2421 1037 5787 2000 5381 3564 1010 3061 1010 4688 1010 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: test-5\nINFO:tensorflow:tokens: [CLS] how many of you comment ##ers have garbage piled high in your yard , bald tires , dead batteries , rotten pal ##lets , car parts , blah blah blah . this town is a pig ##pen . drive around and look for yourself , its pathetic . [SEP]\nINFO:tensorflow:input_ids: 101 2129 2116 1997 2017 7615 2545 2031 13044 17835 2152 1999 2115 4220 1010 13852 13310 1010 2757 10274 1010 11083 14412 13461 1010 2482 3033 1010 27984 27984 27984 1012 2023 2237 2003 1037 10369 11837 1012 3298 2105 1998 2298 2005 4426 1010 2049 17203 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:Writing example 10000 of 97320\nINFO:tensorflow:Writing example 20000 of 97320\nINFO:tensorflow:Writing example 30000 of 97320\nINFO:tensorflow:Writing example 40000 of 97320\nINFO:tensorflow:Writing example 50000 of 97320\nINFO:tensorflow:Writing example 60000 of 97320\nINFO:tensorflow:Writing example 70000 of 97320\nINFO:tensorflow:Writing example 80000 of 97320\nINFO:tensorflow:Writing example 90000 of 97320\nINFO:tensorflow:***** Running prediction*****\nINFO:tensorflow:  Num examples = 97320 (97320 actual, 0 padding)\nINFO:tensorflow:  Batch size = 32\nINFO:tensorflow:***** Predict results *****\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Running infer on CPU\nINFO:tensorflow:*** Features ***\nINFO:tensorflow:  name = input_ids, shape = (?, 72)\nINFO:tensorflow:  name = input_mask, shape = (?, 72)\nINFO:tensorflow:  name = is_real_example, shape = (?,)\nINFO:tensorflow:  name = label_ids, shape = (?,)\nINFO:tensorflow:  name = segment_ids, shape = (?, 72)\nINFO:tensorflow:**** Trainable Variables ****\nINFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nINFO:tensorflow:  name = output_weights:0, shape = (2, 768)\nINFO:tensorflow:  name = output_bias:0, shape = (2,)\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nINFO:tensorflow:Restoring parameters from ./model.ckpt-18612\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:prediction_loop marked as finished\nINFO:tensorflow:prediction_loop marked as finished\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"end = time.time()\nprint(\"--------------------------------------------------------\")\nprint(\"Inference complete in \", end - start, \" seconds\")\nprint(\"--------------------------------------------------------\")","execution_count":10,"outputs":[{"output_type":"stream","text":"--------------------------------------------------------\nInference complete in  383.9845440387726  seconds\n--------------------------------------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')\npredictions = pd.read_csv('./test_results.tsv', header=None, sep='\\t')\n\nsubmission = pd.concat([sample_submission.iloc[:,0], predictions.iloc[:,1]], axis=1)\nsubmission.columns = ['id','prediction']\nsubmission.to_csv('submission.csv', index=False, header=True)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"        id  prediction\n0  7000000    0.001987\n1  7000001    0.005423\n2  7000002    0.003889\n3  7000003    0.015710\n4  7000004    0.985373","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7000000</td>\n      <td>0.001987</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7000001</td>\n      <td>0.005423</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7000002</td>\n      <td>0.003889</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7000003</td>\n      <td>0.015710</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7000004</td>\n      <td>0.985373</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}