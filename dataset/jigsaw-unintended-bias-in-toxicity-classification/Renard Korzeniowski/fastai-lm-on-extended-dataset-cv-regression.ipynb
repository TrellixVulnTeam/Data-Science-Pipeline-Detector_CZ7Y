{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ULMFiT on toxic bias"},{"metadata":{},"cell_type":"markdown","source":"### Content\nIn this notebook, we are exploring the possibility of using transfer learning in the biased class prediction problem. \n- First, we fit a language model that was pretrained on WikiText to our specific dataset\n- Then we perform stratified sorted spliting of the data into K folds so that we can perform Cross Validation on K-1 of those folds and use Kth fold as testset\n- Using the models trained on K-1 folds we predict probabilites for Kth fold i.e. data that none of the models ever seen and calculate toxic metric used in the competition\n- Finally, we train a model on the full dataset using the best parameters we found on our validation set and create a submission"},{"metadata":{},"cell_type":"markdown","source":"We've also used quite a handy API 'neptune' that helps us keep results of our experiments organized"},{"metadata":{},"cell_type":"markdown","source":"### Additional Remarks"},{"metadata":{},"cell_type":"markdown","source":"- Most of the calculations were performed on the Google cloud and training logs are shown as pictures\n- Ideas that I think might improve the performance of the model will be scattered all over the notebook. I'm planning to implement them when I find a little bit of free time. If they enhance the performance I'll add them to this kernel in the other case there will be a note '(Not improved performance)' next to the ideas that failed\n- Any comments about ideas that might be improved this kernel or any mistakes that I've made are welcome\n- If you spot that I've added some code from other kernel and forgot to add reference please let me know"},{"metadata":{},"cell_type":"markdown","source":"### General Improvement Ideas\n- Implement loss functions that weights samples that belong to minority classes according to their importance in regression. Similarly to `sample_weights` in [Simple LSTM](https://www.kaggle.com/thousandvoices/simple-lstm) kernel (but in Simple LSTM we perform binary classification)\n- Use google translate to perform data augmentation. Since it's quite expensive it could be done only on the most underrepresented subgroups\n- Replace words that can are distinctive for given ethnicity with tokens  so that model cant generalize to unwanted bias\n- Apply data cleaning from greate kernel [clean-data-keras-embbedings-cudnn-predict](https://www.kaggle.com/nikhilsharma00/clean-data-keras-embbedings-cudnn-predict) on toxic biased train/test on check if already cleaned old toxic data can get any cleaner"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pickle\n\nimport pandas as pd\nfrom pathlib import Path\nfrom fastai import *\nfrom fastai.text import *\nfrom sklearn import metrics\nfrom torch import nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import neptune","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MSELoss(nn.MSELoss):\n  \"Mean Absolute Error Loss\"\n  def forward(self, input:Tensor, target:Tensor) -> Rank0Tensor:\n    return super().forward(input.view(-1), target.view(-1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"k_folds = 8\ntarget_col_name = 'target'\ntarget_class_col_name = 'class_target'\nx_col_name = 'comment_text'\n\nepochs = 1\nlayer1_lr = 2e-2\nlayer2_lr = slice(1e-2/(2.6**4),1e-2)\nmomentum = (0.8,0.7)\nloss_function = MSELoss\nDROP_MULT = 0.5\nfreeze_layer_idx = -2\narchitecture = AWD_LSTM\n\nbs = 40\nSEED = 777\n\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Paths"},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/toxic-regression-model/exported_reg_mse_toxic_lm_extended_15ep.pkl ../working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # data\npath = Path('../input/jigsaw-unintended-bias-in-toxicity-classification')\nclas_csv_file = 'train.csv'\ntest_csv_file = 'test.csv'\n\npath_lm = Path('../input/data')\nlm_csv_file = 'combined_toxic_lm.csv'\n\n# pretrained\npretrained_lm_path = Path('../input/basic-toxic-languagemodel-extended-15ep')\nencoder_file = 'fine_tuned_encoder_basic_toxic_lm15ep_extended'\ndata_lm_file = 'data_reg_basic_toxic_lm_extended_15ep.pkl'\npretrained_reg_path = Path('../working')\nreg_model_file = 'exported_reg_mse_toxic_lm_extended_15ep.pkl'\n\n# results\nexp_nb = 2\nmodel_cv_result_file = 'toxic_test_cv_{}'\nmodel_prod_cv_result_file = 'toxic_production_cv_{}'\nk_folds_file = 'holdout_and_k_folds_idxs_exp_nb_{}.pkl'.format(exp_nb)\nmodels_performance_file = 'toxic_CV_models_performance_exp_nb_{}.pkl'.format(exp_nb)\nsubmission_predictions = 'toxic_CV_submission_exp_nb_{}.csv'.format(exp_nb)\n\nfinal_model_result_file = 'toxic_final_model_{}'.format(exp_nb)\nfinal_model_prod_result_file = 'toxic_production_final_{}'.format(exp_nb)\nfinal_submission_predictions = 'toxic_final_submission_exp_nb_{}.csv'.format(exp_nb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start logging the experiment using neptune"},{"metadata":{"trusted":true},"cell_type":"code","source":"neptune.init(api_token='YOUR_API_TOKEN',\n             project_qualified_name='lachonman/toxic-bias')\n\nnep_exp = neptune.create_experiment(name='FastAI_regression_exp_nb_{}'.format(exp_nb),\n                          description=' Regression model implemented in FastAI that predicts'\n                          'probablity that given text belongs to toxic category. It uses pretrained'\n                          'Language Model that was trained on train+test and old toxic text corpora.'\n                          'Official metric used to evaluate model performance is \"toxic_metric\".'\n                          'Sorted stratificated k fold cross validation with 1'\n                          'holdout is used to tune paramters and measure metrics.',\n                          params={'loss_func': str(loss_function.__name__),\n                                  'lr_layer1': layer1_lr,\n                                  'lr_layer2': layer2_lr,\n                                  'momentum': momentum,\n                                  'epochs_count': epochs,\n                                  'dropout': DROP_MULT,\n                                  'freeze_layer_idx': freeze_layer_idx,\n                                  'architecture': architecture,\n                                  'k_folds': k_folds})\n\nnep_exp.append_tag('regression')\nnep_exp.append_tag('k folds CV')\nnep_exp.append_tag('pretrained extended LangModel')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit pretrained Language Model from FastAI"},{"metadata":{},"cell_type":"markdown","source":"### Load combined data\nOur combined data consists of toxic biased train+test and old cleaned toxic data. We can use unlabeled data to train the language model because labels for the language model can be created from the text itself"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = (TextList.from_csv(path_lm, lm_csv_file, cols='comment_text')\n                .split_by_rand_pct(0.1)\n                .label_for_lm()\n                .databunch(bs=bs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.save(pre_trained_path/data_lm_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = load_data(pre_trained_path, data_lm_file, bs=bs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit Language Model\nBy default langauge model from FastAI is pretrained on WikiText"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, pretrained=True, drop_mult=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot(skip_end=15, suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/fastai-lm-on-extended-datasetcv-regression-source/lm_lr_find1.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/fastai-lm-on-extended-datasetcv-regression-source/lm_fit_ep1_loss_table.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fit_head_basic_toxic_lm1ep_extended')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('fit_head_basic_toxic_lm1ep_extended');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(15, 1e-3, moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/fastai-lm-on-extended-datasetcv-regression-source/lm_fit_ep15_loss_table.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fine_tuned_basic_toxic_lm15ep_extended')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('fine_tuned_basic_toxic_lm15ep_extended');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encoder is the part of language model that we want to use in our classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('fine_tuned_encoder_basic_toxic_lm15ep_extended')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If our language model is a bit too big we can save only vocabulaty that will be used by classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('fine_tuned_basic_toxic_vocab_lm15ep_extended.pcl', 'wb') as f:\n    pickle.dump(data_lm.vocab, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Load data and split into folds using sorted stratification"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"def get_k_stratified_folds_indexes_given_continues_variable(df, k_folds, continuous_target_col_name):\n    nb_samples = df.shape[0]\n    split_remainder = nb_samples%k_folds\n    groups_count = nb_samples//k_folds\n    \n    idxs_train_remainder = df[:split_remainder].index.values\n    idxs_train_trimmed = df[split_remainder:]\n\n    idxs_train_sorted = idxs_train_trimmed.sort_values(by=continuous_target_col_name).index.values\n\n    k_groups = np.split(idxs_train_sorted, groups_count)\n    list(map(np.random.shuffle, k_groups))\n    folds_idxs = [np.array(x) for x in zip(*k_groups)]\n    folds_idxs[0] = np.concatenate([folds_idxs[0], idxs_train_remainder])\n    \n    return np.array(folds_idxs)\n\ndef get_train_and_valid_idxs_split_given_fold_nb(folds_idxs, k):\n    mask = np.ones(len(folds_idxs), dtype=bool)\n    mask[k] = 0\n    folds_idxs[mask]\n    train_idxs = np.concatenate(folds_idxs[mask])\n    \n    test_idxs = folds_idxs[1]\n    return train_idxs, test_idxs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"source kernel: https://www.kaggle.com/dborkan/benchmark-kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Convert taget and identity columns to booleans\ndef get_col_converted_to_bool(df, col_name):\n    return np.where(df[col_name] >= 0.5, True, False)\n    \ndef get_df_with_converted_categorical_cols_to_bool(df, categorical_cols):\n    for col in categorical_cols:\n        df[col] = get_col_converted_to_bool(df, col)\n    return df\n\ndef get_df_with_class_target_col(df, target_col_name, target_class_col_name):\n    df[target_class_col_name] = get_col_converted_to_bool(df, target_col_name)\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the training data for classificatior"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_initial = pd.read_csv(path/clas_csv_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert categorical columns to bool"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_initial = get_df_with_converted_categorical_cols_to_bool(\n    df=df_train_initial,\n    categorical_cols=identity_columns)\ndf_train_initial = get_df_with_class_target_col(\n    df=df_train_initial,\n    target_col_name=target_col_name,\n    target_class_col_name=target_class_col_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create K stratified sorted folds\nUse sorted stratification to get more reprezentative distribution of the data in folds. Implemented based on blog post https://scottclowe.com/2016-03-19-stratified-regression-partitions/"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_initial = df_train_initial.sample(frac=1 ,random_state=SEED)\n\nholdout_and_k_folds_idxs = get_k_stratified_folds_indexes_given_continues_variable(df_train_initial, k_folds, target_col_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model on each of the K folds and store the results\nSince in target we are given a probabilites I wanted to try to perform regression instead of classification and submmit predicted value from 0 to 1 as probability that given text is toxic"},{"metadata":{"trusted":true},"cell_type":"code","source":"models_performance = {}\n# if holdout then k-1 cuz one fold went on holdout\nfor k in range(k_folds-1):\n\n    train_idxs, valid_idxs = get_train_and_valid_idxs_split_given_fold_nb(folds_idxs, k)\n    \n    data_clas = (TextList.from_df(df_train_initial, path=path, cols=x_col_name, vocab=data_lm.vocab)\n             .split_by_idxs(train_idx=train_idxs, valid_idx=valid_idxs)\n             .label_from_df(cols=target_col_name, label_cls=FloatList)             \n             .databunch(bs=bs))\n\n    learn = text_classifier_learner(data_clas, architecture, drop_mult=DROP_MULT, metrics=[mse, ToxicMetric()])\n    learn.load_encoder(encoder_file)\n    \n    learn.loss = loss_function\n    learn.fit_one_cycle(epochs, layer1_lr, moms=momentum)\n    learn.freeze_to(freeze_layer_idx)\n    learn.fit_one_cycle(epochs, layer2_lr, moms=momentum)\n    learn.save(model_cv_result_file.format(k))\n    learn.export(model_prod_cv_result_file.format(k))\n    \n    learn.data.add_test(df_train_initial[x_col_name][holdout_idx])\n    prob_preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n    batch_preds = [pred[0] for pred in prob_preds[0].numpy()]\n    models_performance[k] = {'holdout_preds': batch_preds,\n                             'train_loss': learn.recorder.losses,\n                             'valid_loss': learn.recorder.val_losses}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Metrics"},{"metadata":{},"cell_type":"markdown","source":"### Train loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_folds_losses = []\nfor model_nb in models_performance:\n    train_loss = models_performance[model_nb]['train_loss']\n    train_score = [float(step.numpy()) for step in train_loss]\n    train_folds_losses.append(train_score)\n\nfolds_train_losses = [x[-1] for x in train_folds_losses]\nprint('folds train losses', folds_train_losses)\navg_train_losses = np.mean(train_folds_losses, axis=0)\navg_train_loss = avg_train_losses[-1]\nprint('avg train loss', avg_train_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds train losses [0.018044915050268173, 0.019446002319455147, 0.018564680591225624, 0.017788488417863846, 0.018882934004068375, 0.01710507646203041, 0.017085056751966476]\navg train loss 0.01813102194241115","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Valid loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_folds_losses = [models_performance[x]['valid_loss'][-1] for x in models_performance]\nprint('folds valid losses', valid_folds_losses)\navg_valid_loss = np.mean(valid_folds_losses, axis=0)\nprint('avg valid loss', avg_valid_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds valid losses [0.5292527, 54.811653, 0.017135596, 0.29703587, 0.026240299, 26.354286, 0.049951334]\navg valid loss 11.726507","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Improvment idea] Check what was the problem with 2 out of 7 folds that had very high loss rate"},{"metadata":{},"cell_type":"markdown","source":"### Houldout loss and accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout_group_preds = [models_performance[x]['holdout_preds'] for x in models_performance]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_holdout_preds = np.mean(holdout_group_preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_preds_count = 0\nmse_loss_holdout = []\nsample_count = len(avg_holdout_preds)\nfor i in range(sample_count):\n    single_holdout_idx = holdout_idx[i]\n    target = df_train_initial['target'].loc[single_holdout_idx]\n    ensamble_pred = avg_holdout_preds[i]\n    mse_pred = (ensamble_pred - target)**2\n    mse_loss_holdout.append(mse_pred)\n    if (ensamble_pred>0.5 and target>0.5) or (ensamble_pred<0.5 and target<0.5):\n        correct_preds_count += 1\nholdout_acc = correct_preds_count/sample_count\nprint('holdout_acc', holdout_acc)\nholdout_loss = sum(mse_loss_holdout)/len(mse_loss_holdout)\nprint('holdout_loss ', holdout_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout_acc 0.9462703502932038\nholdout_loss  5.278712082137559","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Calculate biased metric"},{"metadata":{},"cell_type":"markdown","source":"source kernel: https://www.kaggle.com/dborkan/benchmark-kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"SUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_NAME = 'regression'\nvalidate_df = df_train_initial.loc[holdout_idx]\nvalidate_df[MODEL_NAME] = avg_holdout_preds\nTOXICITY_COLUMN = target_class_col_name\n\nbias_metrics_df = compute_bias_metrics_for_model(validate_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\nbias_metrics_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/fastai-lm-on-extended-datasetcv-regression-source/toxic_subgroups_auc.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxic_metric_acc = get_final_metric(bias_metrics_df, calculate_overall_auc(validate_df, MODEL_NAME))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Summary of ensamble scores\n- train loss 0.021\n- valid loss 0.66\n- holdout loss 0.169\n- holdout acc 0.946 (toxicity classification)\n- toxic holdout metric acc 0.919\n- testset avg CV acc 0.91310\n- toxic metric testset full_train acc 0.91394"},{"metadata":{},"cell_type":"markdown","source":" ## Send results of training to neptune\n- [Improvment Idea] What you can do is add to callback that updates metrics during traning of a model"},{"metadata":{},"cell_type":"markdown","source":"#### Send final valid loss of every fold"},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold_nb in range(len(valid_folds_losses)):\n    neptune.send_metric(channel_name='valid_loss per fold', x=fold_nb, y=valid_folds_losses[fold_nb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Send average training loss history"},{"metadata":{"trusted":true},"cell_type":"code","source":"for step in range(len(avg_train_losses)):\n    neptune.send_metric(channel_name='train_avg_folds_losses', x=step, y=avg_train_losses[step])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neptune.send_metric(channel_name='avg_train_loss', x=exp_nb, y=avg_train_loss)\nneptune.send_metric(channel_name='avg_valid_loss', x=exp_nb, y=avg_valid_loss)\n\nneptune.send_metric(channel_name='holdout_loss', x=exp_nb, y=holdout_loss)\nneptune.send_metric(channel_name='holdout_acc', x=exp_nb, y=holdout_acc)\n\nneptune.send_metric(channel_name='toxic_metric', x=exp_nb, y=toxic_metric_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Send score of each subgroup"},{"metadata":{"trusted":true},"cell_type":"code","source":"for _, row in bias_metrics_df.iterrows():\n    key = 'subgroup_'+row['subgroup']+'_auc'\n    neptune.send_metric(channel_name=key, x=exp_nb, y=row['subgroup_auc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Send registered usage of gpu and cpu during the experiment"},{"metadata":{"trusted":true},"cell_type":"code","source":"neptune.experiments.get_current_experiment().get_hardware_utilization()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### End the experiment"},{"metadata":{"trusted":true},"cell_type":"code","source":"neptune.stop()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##   Final predictions on testset"},{"metadata":{},"cell_type":"markdown","source":"After finding the best parameters using cross validation and holdout we should use those paramters to train a model on full data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas = (TextList.from_df(df_train_initial, path=path, cols=x_col_name, vocab=data_lm.vocab)\n         .split_none()\n         .label_from_df(cols=target_col_name, label_cls=FloatList)             \n         .databunch(bs=bs))\n\nlearn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=DROP_MULT)\nlearn.load_encoder(encoder_file)\n\nlearn.loss = loss_function\nlearn.fit_one_cycle(epochs, layer1_lr, moms=momentum)\nlearn.freeze_to(freeze_layer_idx)\nlearn.fit_one_cycle(epochs, layer2_lr, moms=momentum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/fastai-lm-on-extended-datasetcv-regression-source/final_model_table_loss.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use export method so that only essentail part of the model that is nessecary for predicting is saved"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export(final_model_prod_result_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict for submission\nFinally we load our exported model and use it to produce binary class probabilities used in our submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(path/test_csv_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn = load_learner(pretrained_reg_path, reg_model_file)\n\nlearn.data.add_test(test_df[x_col_name])\nprob_preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\nbatch_preds = [pred[0] for pred in prob_preds[0].numpy()]\nbatch_preds[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['prediction'] = batch_preds\nsubmission = test_df[['id','prediction']]\nsubmission[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(path/final_submission_predictions, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit = pd.read_csv('../input/preds-toxic-reg/toxic_final_submission_exp_nb_2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}