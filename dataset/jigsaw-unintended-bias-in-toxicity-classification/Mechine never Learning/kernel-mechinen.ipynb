{"cells":[{"metadata":{"id":"8p8tfimDRsVf","colab_type":"code","outputId":"0b341dde-19ee-4ed3-a6ff-24a41c4673ab","executionInfo":{"status":"ok","timestamp":1561112135857,"user_tz":-480,"elapsed":238030,"user":{"displayName":"X Heramy","photoUrl":"","userId":"10077397363865813933"}},"colab":{"base_uri":"https://localhost:8080/","height":4818},"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nprint(os.listdir(\"../input/\"))\nprint(os.listdir(\"../input/nvidiaapex/repository/NVIDIA-apex-39e153a\"))\n# Installing Nvidia Apex\n! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a\n\n\n\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport pkg_resources\nimport seaborn as sns\nimport time\nimport scipy.stats as stats\nimport gc\nimport re\nimport operator \nimport sys\nfrom sklearn import metrics\nfrom sklearn import model_selection\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom nltk.stem import PorterStemmer\nfrom sklearn.metrics import roc_auc_score\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom tqdm import tqdm, tqdm_notebook\nimport os\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport warnings\nwarnings.filterwarnings(action='once')\nimport pickle\nfrom apex import amp\nimport shutil\ndevice=torch.device('cuda')\n\nMAX_SEQUENCE_LENGTH = 220\nSEED = 1234\nEPOCHS = 1\nData_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification\"\nInput_dir = \"../input\"\nWORK_DIR = \"../working/\"\nnum_to_load=1000000                         #Train size to match time limit\nvalid_size= 100000                          #Validation Size\nTOXICITY_COLUMN = 'target'\n\npackage_dir_a = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\nsys.path.insert(0, package_dir_a)\n\nfrom pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the Bert configuration file\nfrom pytorch_pretrained_bert import BertConfig\n\noutput_model_file = '../input/kernel6433b88374/bert_pytorch.bin'\nbert_config = BertConfig('../input/kernel6433b88374/bert_config.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Predicting BERT base model......\")\n\n\ndef convert_lines(example, max_seq_length,tokenizer):\n    max_seq_length -=2\n    all_tokens = []\n    longer = 0\n    for text in tqdm_notebook(example):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>max_seq_length:\n            tokens_a = tokens_a[:max_seq_length]\n            longer += 1\n        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n        all_tokens.append(one_token)\n    print(longer)\n    return np.array(all_tokens)\nBERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\ny_columns=['target']\nbatch_size = 32\n\ntest_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\nX_test = convert_lines(test_df[\"comment_text\"].fillna(\"DUMMY_VALUE\"), MAX_SEQUENCE_LENGTH, tokenizer)\ntest = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n\nmodel = BertForSequenceClassification(bert_config,num_labels=len(y_columns))\nmodel.load_state_dict(torch.load(output_model_file ))\nmodel.to(device)\n\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.eval()\n\n# Predicting\ntest_preds = np.zeros((test_df.shape[0],1))\nmodel_preds = np.zeros((len(X_test)))\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\ntk0 = tqdm(test_loader)\nfor i, (x_batch,) in enumerate(tk0):\n        pred = model(x_batch.to(device), attention_mask=(x_batch > 0).to(device), labels=None)\n        model_preds[i * batch_size:(i + 1) * batch_size] = pred[:, 0].detach().cpu().squeeze().numpy()\n\ntest_preds[:,0] = torch.sigmoid(torch.tensor(model_preds)).numpy().ravel()\n\n#del model\n#gc.collect()\n\n# Sub-model prediction\nbert_submission = pd.DataFrame.from_dict({\n'id': test_df['id'],\n'prediction': test_preds.mean(axis=1)})\nbert_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"jiasaw.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}