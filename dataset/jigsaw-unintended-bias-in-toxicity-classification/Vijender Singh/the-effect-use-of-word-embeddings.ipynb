{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# import plotly\n# import colorlover as cl\n# import plotly.offline as py\n# import plotly.graph_objs as go\n\n# plotly.tools.set_credentials_file(username='nholloway', api_key='Ef8vuHMUdvaIpvtC2lux')\n# py.init_notebook_mode(connected=True)\n\nimport os\nimport urllib\nimport zipfile\nimport nltk\nimport numpy as np\nimport tensorflow as tf","metadata":{"scrolled":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FASTTEXT_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\nGLOVE_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\nNUMBERBATCH_PATH = '../input/conceptnet-numberbatch-vectors/numberbatch-en-17.06.txt/numberbatch-en-17.06.txt'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First we define our procedure for loading the embeddings and vocabulary into an embedding matrix.","metadata":{}},{"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in f)\n\ndef build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in word_index.items():\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            pass\n    return embedding_matrix","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will preprocess our text by mapping punctuation and contractions to strings to make it easier to find embeddings. ","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"bold_start = '\\033[1m'\nbold_end = '\\033[0m'\n    \ndef cosine_similarity(a, b):\n    nominator = np.dot(a, b)\n    \n    a_norm = np.sqrt(np.sum(a**2))\n    b_norm = np.sqrt(np.sum(b**2))\n    \n    denominator = a_norm * b_norm\n    \n    cosine_similarity = nominator / denominator\n    \n    return cosine_similarity\n\ndef similarity_text(embed_name,embed_dict,word1,word2):\n\n    if embed_name in ['bert','roberta','distilbert']:\n        w1 = embed_dict.encode(word1,show_progress_bar=False)\n        w2 = embed_dict.encode(word2,show_progress_bar=False)\n    else:\n        w1 = embed_dict[word1]\n        w2 = embed_dict[word2]\n\n    print(f\"Cosine similarity using {bold_start}'{embed_name}'{bold_end} for pair \\t\\t\\t\\t\\t ({word1,word2}) = {cosine_similarity(w1,w2)}\")\n    return \n\n# similarity_text(\"insurance\",\"policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='fasttext'></a>\n## FastText \n---","metadata":{}},{"cell_type":"code","source":"%%time\nfasttext_dict = load_embeddings(FASTTEXT_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_text(embed_name=\"Fasttext Embedding\",embed_dict=fasttext_dict,word1=\"insurance\",word2=\"policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='glove'></a>\n## GloVE \n---","metadata":{}},{"cell_type":"code","source":"%%time\nglove_dict = load_embeddings(GLOVE_PATH)","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_text(embed_name=\"Glove Embedding\",embed_dict=glove_dict,word1=\"insurance\",word2=\"policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Other popular models seem to use GloVe and Fasttext embeddings- but I have yet to see the use of [ConceptNet Numberbatch](https://github.com/commonsense/conceptnet-numberbatch) embeddings- which according to the README were specifically created for dealing with bias in text.  ","metadata":{}},{"cell_type":"markdown","source":"<a id='numberbatch'></a>\n## Conceptnet Numberbatch\n---","metadata":{}},{"cell_type":"code","source":"%%time\nconceptnet_numberbatch_dict = load_embeddings(NUMBERBATCH_PATH)","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_text(embed_name=\"Conceptnet Numberbatch Embedding\",embed_dict=conceptnet_numberbatch_dict,word1=\"insurance\",word2=\"policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='bert'></a>\n## BERT Embeddings\n---","metadata":{}},{"cell_type":"markdown","source":"In this section I'll show how to create custom BERT embeddings from a pretrained BERT model. Unfortunately, the BERT embeddings have 768 dimensions when trained on the small pre-trained model (and 1024 for the larger one) and I wasn't able train a model to benchmark because there isn't a lot of text pre-processing in this kernel and the vocabulary is really large. If you run into memory issues with the larger BERT embeddings consider decreasing the vocabulary.","metadata":{}},{"cell_type":"code","source":"!pip install -q sentence-transformers\n!pip install --upgrade numpy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsbert_model = SentenceTransformer('bert-base-nli-mean-tokens')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=\"health insurance\",word2=\"health policy\")\nsimilarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=\"life insurance\",word2=\"car insurance\")\nsimilarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=\"home loan\",word2=\"credit loan\")\nsimilarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=\"car insurance\",word2=\"personal policy\")\nsimilarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=\"health life insurance\",word2=\"life insurance policy\")\nsimilarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=\"investment insurance plan\",word2=\"claim insurance policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Roberta","metadata":{}},{"cell_type":"code","source":"roberta_model = SentenceTransformer('stsb-roberta-base-v2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=\"health insurance\",word2=\"health policy\")\nsimilarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=\"life insurance\",word2=\"car insurance\")\nsimilarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=\"home loan\",word2=\"credit loan\")\nsimilarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=\"car insurance\",word2=\"personal policy\")\nsimilarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=\"health life insurance\",word2=\"life insurance policy\")\nsimilarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=\"investment insurance plan\",word2=\"claim insurance policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## msmarco-distilbert-base-v3 Model finetune to use for cosine score","metadata":{}},{"cell_type":"code","source":"distilbert_model = SentenceTransformer('msmarco-distilbert-base-v3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=\"health insurance\",word2=\"health policy\")\nsimilarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=\"life insurance\",word2=\"car insurance\")\nsimilarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=\"home loan\",word2=\"credit loan\")\nsimilarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=\"car insurance\",word2=\"personal policy\")\nsimilarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=\"health life insurance\",word2=\"life insurance policy\")\nsimilarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=\"investment insurance plan\",word2=\"claim insurance policy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scope\nhttps://www.sbert.net/docs/pretrained_models.html","metadata":{}},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"my_list = [(\"table\",\"desk\"),\n(\"football\",\"baseball\"),\n('water','fire'),\n('table','desk'),\n('football','baseball'),\n('water','fire'),\n('computer','calculator'),\n('number','math'),\n('boy','girl'),\n('sad','happy'),\n('good','bad'),\n('turkey','television'),\n('awesome','great'),\n('coffee','giraffe'),\n('cat','barcelona'),\n('school','disaster')]\n\nfor i in my_list:\n    a,b = i\n    similarity_text(embed_name=\"Glove\",embed_dict=glove_dict,word1=a,word2=b)\n    similarity_text(embed_name=\"Fasttext\",embed_dict=fasttext_dict,word1=a,word2=b)\n    similarity_text(embed_name=\"Conceptnet\",embed_dict=conceptnet_numberbatch_dict,word1=a,word2=b)\n    similarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=a,word2=b)\n    similarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=a,word2=b)\n    similarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=a,word2=b)\n    print(\"-----------------------------------------------------------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_list = [(\"health\",\"policy\"),\n(\"insurance\",\"health\"),\n('customer','bot'),\n('bajaj','health'),\n('costly','expensive'),\n('cheap','costly'),\n('king','queen')]\n\nfor i in my_list:\n    a,b = i\n    similarity_text(embed_name=\"Glove\",embed_dict=glove_dict,word1=a,word2=b)\n    similarity_text(embed_name=\"Fasttext\",embed_dict=fasttext_dict,word1=a,word2=b)\n    similarity_text(embed_name=\"Conceptnet\",embed_dict=conceptnet_numberbatch_dict,word1=a,word2=b)\n    similarity_text(embed_name=\"bert\",embed_dict=sbert_model,word1=a,word2=b)\n    similarity_text(embed_name=\"roberta\",embed_dict=roberta_model,word1=a,word2=b)\n    similarity_text(embed_name=\"distilbert\",embed_dict=distilbert_model,word1=a,word2=b)\n    print(\"-----------------------------------------------------------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}