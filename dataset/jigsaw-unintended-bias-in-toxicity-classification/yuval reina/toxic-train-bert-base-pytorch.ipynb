{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport pkg_resources\nimport seaborn as sns\nimport time\nimport scipy.stats as stats\nimport gc\nimport re\nimport operator \nimport sys\nfrom sklearn import metrics\nfrom sklearn import model_selection\nimport matplotlib.pyplot as plt\n#from keras.preprocessing.text import Tokenizer\n#from keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom nltk.stem import PorterStemmer\nfrom sklearn.metrics import roc_auc_score\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom tqdm import tqdm, tqdm_notebook\nimport os\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport warnings\nwarnings.filterwarnings(action='once')\nimport pickle\nfrom apex import amp\nfrom joblib import Parallel, delayed\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndevice=torch.device('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 200\nSEED = 1234\nnum_epoch=1\nlr=2e-5\nbatch_size=32\naccumulation_steps=2\n\nData_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification\"\nInput_dir = \"../input\"\nWORK_DIR = \"../working/\"\n#sequences_path=\"../input/pickled-bert-sequences/bert_sequences.pkl\"\n#predict_weights_file = \"../input/vesla-trained-bert/bert_classifier.bin\"\ntrained_bert_path = None\nos.listdir(WORK_DIR)\npartial_train = 0.5 \nTOXICITY_COLUMN = 'target'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\nconvert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n    BERT_MODEL_PATH + 'bert_model.ckpt',\nBERT_MODEL_PATH + 'bert_config.json',\nWORK_DIR + 'pytorch_model.bin')\n\nshutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_pretrained_bert import BertConfig\n\nbert_config = BertConfig('../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'+'bert_config.json')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_lines_onfly(example, max_seq_length,tokenizer,min_seq=0):\n    max_seq_length -=2\n    results =np.zeros((example.shape[0],max_seq_length+2),dtype=np.long)\n    longest=min_seq\n    for i,text in enumerate(example):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>longest:\n            longest = len(tokens_a) \n        if len(tokens_a)>max_seq_length:\n# if too long, randomly erase tokens\n            a = np.arange(len(tokens_a))\n            np.random.shuffle(a)\n            tokens_a = list(np.array(tokens_a)[np.sort(a[:max_seq_length])])\n# This is for head - tail instead of random\n#            tokens_a=tokens_a[:max_seq_length//2]+tokens_a[len(tokens_a)-max_seq_length//2:]   \n        results[i] = np.array(tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a)))\n    results=results[:,:min(max_seq_length,longest)+2]\n    return np.array(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We don't really need this.\n\ndef preprocess(data,hint=None,do_lower=True):\n    '''\n    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n    '''\n    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'+\"\\n\\t\"\n    def clean_special_chars(text, punct):\n        for p in punct:\n            text = text.replace(p, ' '+p+' ')\n        return text\n    \n    def intonation(text,hint,do_lower):\n        new_text=[]\n        for token in text.split():\n            if do_lower:\n                new_text.append(token.lower())\n            else:\n                new_text.append(token)\n            if hint and token.isupper() and len(token)>1:\n                new_text.append(hint)\n        return \" \".join(new_text) \n    data = data.astype(str).apply(lambda x: clean_special_chars(intonation(x,hint,do_lower), punct))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\ntrain_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\")).sample(frac=partial_train,random_state=SEED)\nprint('loaded %d records' % len(train_df))\ntest_df=train_df.tail(100000)\ntrain_df = train_df.head(((train_df.shape[0]-100000)//batch_size)*batch_size)\n# Make sure all comment_text values are strings\nsentences = sentences = preprocess(train_df['comment_text'].astype(str).fillna(\"DUMMY_VALUE\")).values \ntrain_df=train_df.fillna(0)\n# List all identities\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\ny_columns=['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']+identity_columns\nidentity_sp = [ 'homosexual_gay_or_lesbian','muslim', 'black', 'white']\n# Convert taget and identity columns to booleans\n\ntrain_df = train_df.drop(['comment_text'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef calculate_weights(train):\n    has_identity = torch.sigmoid(10*(torch.tensor((train[identity_columns].fillna(0).max(axis=1)).values)-0.4))\n    has_target = torch.sigmoid(10*(torch.tensor(train['target'].values)-0.4))\n    weights = (torch.ones(train.shape[0],dtype=torch.float64)+has_identity+has_identity*(1-has_target)+has_target*(1-has_identity)) / 4\n    weights = weights.to(dtype=torch.float32)\n    return weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make sure every batch has similar sentences length, and shuffle the batchs\nsort_idx=np.argsort(np.array([len(x.split()) for x in sentences])).reshape(train_df.shape[0]//batch_size,batch_size)\nnp.random.shuffle(sort_idx)\nsort_idx=sort_idx.reshape(train_df.shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsentences = sentences[sort_idx]\nX = sentences                #[train_df.idx]\ny = train_df[y_columns].values[sort_idx]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_tensor=calculate_weights(train_df)[sort_idx].repeat(len(y_columns),1).transpose(0,1)\nweights_tensor[:,0]=weights_tensor[:,0]*(len(y_columns))/4\nweights_tensor[:,6:]=weights_tensor[:,6:]*0.25\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_dataset = torch.utils.data.TensorDataset(torch.arange(len(X)), torch.tensor((np.abs(2.0*y-1.0)**0.5*np.sign(y-0.5)+1)/2,dtype=torch.float), weights_tensor)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_model_file = \"../working\"\noutput_model_file = \"bert_pytorch.bin\"\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.cuda.empty_cache()\n\nmodel = BertForSequenceClassification.from_pretrained(\"../working\",cache_dir=None,num_labels=len(y_columns))\n\nmodel.zero_grad()\n_=model.to(device)\n\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n    ]\ntrain = train_dataset\n\navg_val_loss = 0.\navg_val_accuracy = 0.\nnum_train_optimization_steps = int(num_epoch*len(train)/batch_size/accumulation_steps)\n\noptimizer = BertAdam(optimizer_grouped_parameters,\n                     lr=lr,\n                     warmup=0.05,\n                     t_total=num_train_optimization_steps)\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\nmodel=model.train()\n\ntq = tqdm_notebook(range(num_epoch))\nfor epoch in tq:\n#    optimizer.lr = epoch[0]\n    torch.cuda.empty_cache()\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n\n    avg_loss = 0.\n    avg_accuracy = 0.\n    lossf=None\n    optimizer.zero_grad()\n    tk0 = tqdm_notebook(train_loader,leave=False)\n    for i,(ind_batch, y_batch, w_batch) in enumerate(tk0):\n        ind_batch.requires_grad = False\n        x_batch=torch.tensor(convert_lines_onfly(X[ind_batch.numpy()], MAX_SEQUENCE_LENGTH,tokenizer))\n        y_pred = model(x_batch.to(device))\n        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device),weight=w_batch.to(device))/accumulation_steps\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n        #loss.backward()\n        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n            optimizer.step()                            # Now we can do an optimizer step\n            optimizer.zero_grad()\n\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()*accumulation_steps\n        else:\n            lossf = loss.item()\n        tk0.set_postfix(loss = lossf)\n        avg_loss += loss.item()*accumulation_steps / len(train_loader)\n        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n    tq.set_postfix(avg_val_loss=avg_val_loss,avg_val_accuracy=avg_val_accuracy,avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n    lossf=None\n\n\ntorch.save(model.state_dict(), output_model_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From baseline kernel\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]>0.5\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n\n\n\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]>0.5]\n    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run validation\n# The following 2 lines are not needed but show how to download the model for prediction\nsentences = preprocess(test_df['comment_text'].astype(str).fillna(\"DUMMY_VALUE\")).values\ntest_df=test_df.fillna(0)\nsort_idx=np.flip(np.argsort(np.array([len(x.split()) for x in sentences])))\norg_idx=np.argsort(sort_idx)\nX = sentences[sort_idx]\ntest_preds = torch.zeros((len(X)))\nx_test = torch.arange(len(X))\ntest = torch.utils.data.TensorDataset(x_test)\nbatchs = batch_size\nmx = 320\nmodel = BertForSequenceClassification(bert_config,num_labels=len(y_columns))\nmodel.load_state_dict(torch.load(output_model_file ))\nfor p in model.parameters():\n    p.requires_grad = False\n_=model.to(device)\ntorch.cuda.empty_cache()\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batchs, shuffle=False)\nmodel=model.eval()\ntk0 = tqdm_notebook(test_loader,leave=False)\ntranct=0\nfor i,(ind_batch,) in enumerate(tk0):\n    x_batch=torch.tensor(convert_lines_onfly(X[ind_batch.numpy()], mx,tokenizer))\n    y_pred = model(x_batch.to(device))\n    test_preds[i * batchs:(i+1) * batchs] = test_preds[i * batchs:(i+1) * batchs]+torch.sigmoid(y_pred[:, 0].cpu())\n    tranct=tranct+batchs*(x_batch.shape[1]==mx)\n    tk0.set_postfix(trunct=tranct,gpu_memory=torch.cuda.memory_allocated() // 1024 ** 2,batch_len=x_batch.shape[1])\n\n    \nMODEL_NAME = 'model1'\ntest_df[MODEL_NAME]=torch.sigmoid(torch.tensor(test_preds[org_idx])).numpy()\nTOXICITY_COLUMN = 'target'\nbias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\nbias_metrics_df\nget_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}