{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Introduction\nThis is a simple kernel that uses a k Nearest Neighbors classifier on a Singular Value Decomposed Bag-Of-Words feature representation.  The kernel itself does not obtain a high score but I created because I wanted to incorporate a kNN weak learner in an ensemble method in another kernel that I am working on.  "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os \n\nimport numpy as np\n\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn import metrics","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"raw_train = pd.read_csv('../input/train.csv')\n\nraw_test = pd.read_csv('../input/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 100000\n\nmax_length = 220\n\ntext_column = 'comment_text'\n\ntarget_column = 'target'\n\ndimensionality = 300\n\n\"\"\"Validation\"\"\"\n\nval_fraction = 0.2\n\nn_components_list = [1, 2, 5]\n\nk_list = [1, 2, 5]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_val_data(x_train, y_train, val_fraction):\n    \n    x_train, y_train = joint_shuffle(x_train, y_train)\n    \n    val_size = int(val_fraction*x_train.shape[0])\n    \n    partial_x_train = x_train[val_size:]\n    \n    partial_y_train = y_train[val_size:]\n    \n    val_x_train = x_train[:val_size]\n    \n    val_y_train = y_train[:val_size]\n    \n    return partial_x_train, partial_y_train, val_x_train, val_y_train\n\n\ndef bow_prepare_data(train_data, test_data, text_column, target_column, vocab_size):\n    \n    \"\"\"Prepares train_data and test_data DataFrames into bag-of-words\n    SciPy CSR sparse matrices.\"\"\"\n    \n    raw_x_test = test_data[text_column].astype(str)\n    \n    raw_x_train = train_data[text_column].astype(str)\n    \n    y_train = train_data[target_column].values\n    \n    word_corpus = list(raw_x_test) + list(raw_x_train)\n    \n    vectorizer = CountVectorizer(strip_accents='ascii', max_features=vocab_size)\n\n    vectorizer.fit_transform(word_corpus)\n    \n    bow_x_test = vectorizer.transform(raw_x_test)\n    \n    bow_x_train = vectorizer.transform(raw_x_train)\n    \n    return bow_x_train, y_train, bow_x_test, vectorizer\n\n\ndef SVD(bow_x_train, bow_x_test, n_components):\n    \n    svd = TruncatedSVD(n_components=n_components).fit(bow_x_train)\n    \n    svd_train_data = svd.transform(bow_x_train)\n    \n    svd_test_data = svd.transform(bow_x_test)\n    \n    return svd_train_data, svd_test_data\n\n\ndef sgn(y):\n    \n    new_y = np.zeros(shape=y.shape)\n    \n    for i in range(len(y)):\n        \n        if y[i] >= 0.5:\n            \n            new_y[i] = 1\n            \n    return new_y\n\n\ndef joint_shuffle(x_data, y_data):\n    \n    if x_data.shape[0] == y_data.shape[0]:\n    \n        p = np.random.permutation(x_data.shape[0])\n    \n    return x_data[p], y_data[p]\n\n\ndef svd_knn_val_test(x_train, y_train, x_test, y_test, n_components, k_list):\n    \n    class_y_train = sgn(y_train)\n    \n    class_y_test = sgn(y_test)\n    \n    svd_x_train, svd_x_test = SVD(x_train, x_test, n_components)\n    \n    training_auc = []\n    \n    val_auc = []\n    \n    for k in k_list:\n        \n        nbh = KNeighborsClassifier(n_neighbors=k)\n    \n        nbh.fit(svd_x_train, class_y_train)\n    \n        training_auc.append(metrics.roc_auc_score(class_y_train, nbh.predict(svd_x_train)))\n    \n        val_auc.append(metrics.roc_auc_score(class_y_test, nbh.predict(svd_x_test)))\n    \n    return training_auc, val_auc\n\n\ndef svd_knn_val(x_train, y_train, x_test, y_test, n_components_list, k_list):\n    \n    training_auc = np.zeros(shape=(len(n_components_list), len(k_list)))\n    \n    val_auc = np.zeros(shape=(len(n_components_list), len(k_list)))\n    \n    for i in range(len(n_components_list)):\n        \n        print(\"Performing validation on n_component =\", n_components_list[i])\n            \n        training_auc[i], val_auc[i] = svd_knn_val_test(x_train, \n                                                       y_train,\n                                                       x_test, \n                                                       y_test, \n                                                       n_components_list[i], \n                                                       k_list)\n    \n    return training_auc, val_auc\n\n\ndef val_assess(val_auc, hyper_p_list_1, hyper_p_list_2):\n    \n    val_index = np.unravel_index(np.argmax(val_auc, axis=None), val_auc.shape)\n    \n    best_hyper_p_1 = hyper_p_list_1[val_index[0]]\n    \n    best_hyper_p_2 = hyper_p_list_2[val_index[1]]\n        \n    return best_hyper_p_1, best_hyper_p_2\n\n\ndef predict_svd_knn(x_train, y_train, x_test, raw_test, best_n_component, best_k):\n    \n    class_y_train = sgn(y_train)\n    \n    svd_x_train, svd_x_test = SVD(x_train, x_test, best_n_component)\n    \n    nbh = KNeighborsClassifier(n_neighbors=best_k)\n    \n    nbh.fit(svd_x_train, class_y_train)\n    \n    predicted_y = nbh.predict(svd_x_test)\n    \n    submission = pd.DataFrame.from_dict({'id': raw_test.id, 'prediction': predicted_y})\n    \n    submission.to_csv('submission.csv', index=False)\n    \n    return submission","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_x_train, y_train, bow_x_test, vectorizer = bow_prepare_data(raw_train, \n                                                                raw_test, \n                                                                text_column, \n                                                                target_column, \n                                                                vocab_size)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partial_x_train, partial_y_train, val_x_train, val_y_train = create_val_data(bow_x_train, \n                                                                             y_train, \n                                                                             val_fraction)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_auc, val_auc = svd_knn_val(partial_x_train, \n                                    partial_y_train, \n                                    val_x_train, \n                                    val_y_train, \n                                    n_components_list, \n                                    k_list)\n\nbest_n_component, best_k = val_assess(val_auc, n_components_list, k_list)\n\nsubmission = predict_svd_knn(bow_x_train, y_train, bow_x_test, raw_test, best_n_component, best_k)\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Performing validation on n_component = 1\nPerforming validation on n_component = 2\nPerforming validation on n_component = 5\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}