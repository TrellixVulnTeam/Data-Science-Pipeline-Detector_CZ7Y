{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Machine Learning Tasks**\n* Problem statement\n* Read in Data\n* Understand Data/Visualize Data\n* Clean Data\n* Preprocessing\n    * Tokenization\n    * Embedding\n* Build Model\n* Train\n* Prediction \n* Problems with models"},{"metadata":{},"cell_type":"markdown","source":"**Problem statement**\n\n> \"Can you help detect toxic comments ― and minimize unintended model bias? That's your challenge in this competition.\n> \n> The Conversation AI team, a research initiative founded by Jigsaw and Google (both part of Alphabet), builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion.\"\n\nhttps://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.preprocessing import text, sequence\nfrom gensim.models import KeyedVectors\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# capture start time for metrics\nstart = time.time()\n# show all columns when printing out tables\npd.options.display.max_columns = None\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read in data**\n\n> At the end of 2017 the Civil Comments platform shut down and chose make their ~2m public comments from their platform available in a lasting open archive so that researchers could understand and improve civility in online conversations for years to come. Jigsaw sponsored this effort and extended annotation of this data by human raters for various toxic conversational attributes.\n\nhttps://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data\n\nWe can read in the input data files by storing them in a Pandas dataframes.\nYou can use the dataframe method 'head(n)' to view the first n rows of a dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=1000000)\n#EXERCISE:Let's look at some rows of the data. You can see this with the pandas .head() function\n#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv', nrows=1000000)\n#EXERCISE:Let's use the head function again to see how the test set differs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Understand Data**\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"**Correlation** \n\nRelationship between each feature and target variable:\n*     Positive Correlation: both variables change in the same direction.\n*     Neutral Correlation: No relationship in the change of the variables.\n*     Negative Correlation: variables change in opposite directions."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_for_pairwise_correlation = ['severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual', 'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu', 'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability', 'jewish', 'latino', 'male', 'muslim', 'other_disability', 'other_gender', 'other_race_or_ethnicity', 'other_religion', 'other_sexual_orientation', 'physical_disability', 'psychiatric_or_mental_illness', 'transgender', 'white', 'funny', 'wow', 'sad', 'likes', 'disagree', 'sexual_explicit', 'identity_annotator_count', 'toxicity_annotator_count']\ntarget_col_for_pairwise_correlation = 'target'\npairwise_correlation = []\n\nfor col in cols_for_pairwise_correlation:\n    # Compute pairwise correlation of columns, excluding NA/null values.\n    corr = train_df[col].corr(train_df[target_col_for_pairwise_correlation])\n    #print(\"Correlation between {} and {}: {:f}\".format(target_col, col, corr))\n    pairwise_correlation.append({'Score': corr, 'Feature': col})\n\ncorrelation_df = pd.DataFrame(pairwise_correlation)\ncorrelation_df.sort_values(by=['Score'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring the comment_text column "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average comment length:\", train_df.comment_text.str.len().mean())\nprint(\"Max comment length:\", train_df.comment_text.str.len().max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution**\n\nVisualize the distribution of the target variable using Kernel Density Estimate Plot.\nIn statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function (PDF) of a random variable. This function uses Gaussian kernels and includes automatic bandwidth determination."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Full data set takes a long time to plot \ntrain_df['target'].head(10000).plot.kde()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clean up data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select the data that we're going to use in our experiment\n\nx_train = train_df['comment_text'].astype(str)\nx_test = test_df['comment_text'].astype(str)\ny_train = train_df['target'].values\n\ny_aux_train = train_df[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert values for most common identity labels to boolean\nIDENTITY_COLUMNS = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness'\n]\nfor column in IDENTITY_COLUMNS + ['target']:\n    train_df[column] = np.where(train_df[column] >= 0.5, True, False) \n    \n#EXERCISE:Use the head function again to see the updated dataframe\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**"},{"metadata":{},"cell_type":"markdown","source":"Use tokenizer to create dictionary of words"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nCHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π' \n\n# Let's first break down comment texts\ntokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE, lower=False)\n\n#http://faroit.com/keras-docs/1.2.2/preprocessing/text/#tokenizer\n#EXERCISE: call the tokenizer fit_on_texts method that fits on x_train and x_test, then display word_index dictionary for tokenizer\n#what can you observe?\n\n# fit_on_texts Updates internal vocabulary based on a list of texts. \n# It creates the vocabulary index based on word frequency, the lower value the more frequent the word is (value 0 is reserved for padding). \n# eg \"The cat sat on the mat.\" => will create a dictionary s.t. word_index[\"the\"] = 1; word_index[\"cat\"] = 2 ..\n\n#EXERCISE: display the dictionary of words created by tokenizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXERCISE:Use the tokenizer texts_to_sequences method to transform each comment_text to a sequence of integers. Each word in the comment should be replaced \n# with its corresponding integer value from the word_index dictionary. Then, display a sample comment\nx_train = # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXERCISE do the same for the test data\n\nx_test = # \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will be processing comment vectors so it's useful to make them the same length.\n# pad_sequences is used to ensure that all sequences in a list have the same length. \n# By default this is done by padding 0 in the beginning of each sequence \nMAX_LEN = 297\nx_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n#EXERCISE display the vector above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXERCISE Call pad_sequences for the test data\nx_test = #\n#EXERCISE display the vector above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We converted comments to vectors of numbers \n#\n# What about the meaning of words used in the comments?\n# \nEMBEDDING_FILES = [\n    '../input/gensim-embeddings-dataset/crawl-300d-2M.gensim',\n    '../input/gensim-embeddings-dataset/glove.840B.300d.gensim'\n]\n\n# Lets load one of the embedding files to see what's there\nembeddings = KeyedVectors.load('../input/gensim-embeddings-dataset/crawl-300d-2M.gensim', mmap='r')\n#\n# How are words represented in a numerical space?\n\n#https://radimrehurek.com/gensim/models/keyedvectors.html\n#EXERCISE Use word_vec method to display a word vector for a word 'apple'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXERCISE What's the length of that vector? Use size property\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What is the \"distance\" between two words?\n#\nw1 = embeddings.word_vec('king')\nw2 = embeddings.word_vec('queen')\n\ndist = np.linalg.norm(w1-w2)\n\nprint(dist)\n#EXERCISE Try different words and rerun the cell to see their distances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate 'king' - 'man' + 'woman' = ?\n\nembeddings.most_similar(positive=['woman', 'king'], negative=['man'])\n\n#EXERCISE try something different embeddings.most_similar(positive=['beans', 'stew', 'Texas'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What else can we do using embeddings?\n#\nembeddings.doesnt_match(\"cat mouse rose dog\".split())\n\n#EXERCISE Try differnet set of words and doesnt_match method to check which word doesn't match the rest\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings.similarity('cat', 'dog')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It indicates similarity of meaning of words not their spelling:\nembeddings.similarity('cat', 'car')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Our model we're be building will require embedding information for the words used in the comments\n# We will construct an embedding_matrix for the words in word_index\n# using pre-trained embedding word vectors from resource in path\ndef build_matrix(word_index, path):\n    # we've seen the embeddings already\n    embedding_index = KeyedVectors.load(path, mmap='r')\n    \n    # embedding_matrix is a matrix of len(word_index)+1  x 300\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    \n    # use word_index to get the index of each word \n    # and place its embedding in the matrix at that index\n    for word, i in word_index.items():\n        for candidate_word in [word, word.lower()]:\n            if candidate_word in embedding_index:\n                embedding_matrix[i] = embedding_index[candidate_word]\n                break\n    return embedding_matrix\n\n# concatenate results for each type of embedding\nembedding_matrix = np.concatenate(\n    [build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To address the bias aspect we will create a set of weights that will reduce significance of samples containing identity words\n# Build an array to provide a weight for each training sample. \n# (we'll indicating the weight for each of those samples during the training)\nsample_weights = np.ones(len(x_train), dtype=np.float32)\nsample_weights += train_df[IDENTITY_COLUMNS].sum(axis=1)\nsample_weights += train_df['target'] * (~train_df[IDENTITY_COLUMNS]).sum(axis=1)\nsample_weights += (~train_df['target']) * train_df[IDENTITY_COLUMNS].sum(axis=1) * 5\nsample_weights /= sample_weights.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building Our Model**\n\nNow that we've preproccessed the data, it's time to build and train a model with the embeddings we created so that we can make predictions on comments.\nIn the below function, we create the different layers of the model using the Keras.layers libray."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D\n\n\n#units parameters in Keras.layers.LSTM/cuDNNLSTM\n#it it the dimension of the output vector of each LSTM cell.\nLSTM_UNITS = 128\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n\n# embedding_matrix: The matrix we created in the preprocessing stage\n# num_aux_targets: The number of auxiliary target variables we have.\ndef build_model(embedding_matrix, num_aux_targets):\n    words = Input(shape=(None,))\n    \n    #The Keras Embedding will turn our matrix of indexes into dense vectors of fixed size\n    #The first parameter represents our max index integer \n    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n    #Randomlly drop 0.2% of input values to help prevent overfitting (This prevents units from coadapting too much)\n    x = SpatialDropout1D(0.2)(x)\n    \n    #CuDNNLSTM is a LSTM implementation using the Nvidia cuDNN library \n    #The LSTM units is the dimension of the output vector of each LSTM cell\n    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n\n    hidden = concatenate([\n        #Global max pooling has a pool size equal to the size of the input.\n        GlobalMaxPooling1D()(x),\n        GlobalMaxPooling1D()(x),\n    ])\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    result = Dense(1, activation='sigmoid')(hidden)\n    aux_result = Dense(num_aux_targets, activation='sigmoid')(hidden)\n    \n    model = Model(inputs=words, outputs=[result, aux_result])\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now call our build_model function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXCERCISE: Lets call the above method to build our model \nmodel = #\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing Our Model**\n\nWe have now constructed a model that we can fit with our data. Before we do this, we can visualize our model to get a better understanding of what we just did.\n\nThe Keras Model has a summary() function that shows the layers of the model we've created:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXCERCISE: Use the .summary() function on the model we created above to help see a summary of the different layers in the model\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see another representation of our model by using a Keras utility function called plot_model and passing in our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\n\n#EXCERCISE: Use the plot_model function with our model as a parameter for another visual \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see the above model prints out two output layers, why does this make sense for our model?"},{"metadata":{},"cell_type":"markdown","source":"We can now train our model and do some prediction. In the below code, we loop over our data 4 times, training and predicting on it each time, and then taking the average of those predictions."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#this is the number of training samples to put in the model each step\nBATCH_SIZE = 512\n\nEPOCHS = 4\ncheckpoint_predictions = []\nweights = []\nfor global_epoch in range(EPOCHS):\n    model.fit(\n        x_train,\n        [y_train, y_aux_train],\n        batch_size=BATCH_SIZE,\n        epochs=1,\n        verbose=2,\n        sample_weight=[sample_weights.values, np.ones_like(sample_weights)]\n        )\n    checkpoint_predictions.append(model.predict(x_test, batch_size=2048)[0].flatten())\n    weights.append(2 ** global_epoch)\n\npredictions = np.average(checkpoint_predictions, weights=weights, axis=0)\n\nsubmission = pd.DataFrame.from_dict({\n    'id': test_df.id,\n    'prediction': predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(predictions)\nend = time.time()\nprint(\"Total time taken:\", end - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How do you think we did with our predictions? Let's compare our predictions with the original test comments and see if our predictions seem right.\n\nRecall that test_df was our original dataframe with the comments. Try playing around with the below for loop to compare comments with our predictions. Do they make sense?"},{"metadata":{"trusted":true},"cell_type":"code","source":"##EXCERCISE: Write a for loop to loop over each entry in our predictions and explore our toxicity predictions\n#For example, output the index of each prediction > 80 and compare it with the original text\n\nfor prediction in predictions:\n\n\n#print(test_df.comment_text[index])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}