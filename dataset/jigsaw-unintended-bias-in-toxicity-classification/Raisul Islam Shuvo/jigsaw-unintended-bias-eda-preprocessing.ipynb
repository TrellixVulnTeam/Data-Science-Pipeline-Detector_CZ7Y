{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> Jigsaw Unintended Bias in Toxicity Classification","metadata":{}},{"cell_type":"markdown","source":"# 1.0 Problem Description\n\n<b>The Conversation AI team</b> (it was a research initiated by Jigsaw and Google) build a toxicity model, they found that the model incorrectly learned to associate the names of frequently attacked identities with toxicity. So model predicted high toxicity for those comments which contains word like <b>gay, black, muslim, white, lesbian</b> etc, even when comments were not actually toxic (e.g. I am a gay women.). This happened because the dataset was collected from the sources where such words (or identities) are considered as highly offensive. A model is need to be build which can find the toxicity in the comments and minimize the unintended bias with respect to some identities.\n\n- A toxic comment is that comments which are offensive and sometimes they makes some people leave the discussion (on public forums).\n- <b>Unintended bias</b> is related to <b>unplanned bias</b> which happend because the data was collected from such sources which considered some words (or identities) very offensive.\n\n>credit: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Objective and Constraint\n\n<b>Objective</b>\n\n- Predicting whether a comment is toxic or not.\n- Minimize the unintended bias.\n\n<b>Constraint</b>\n\n- No strict latency requirements","metadata":{}},{"cell_type":"markdown","source":"# 2.0 Data\n\n> Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.\n\n### 2.1 Data Overview\n\n<b>Data Files</b>\n\n- Train Data\n - There is only one file for training and there are 45 columns in the train.csv data. But out of these 45 columns only, a few columns are important for this case study.\n\n- Test data\n - Test data (test.csv) has only two columns (id and comment_text).\n\nSo we'll be making our model using this common_text feature which will predict the target (whether a comment is toxic or not).","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Understanding The Shape of Data\n\n### Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:04.603149Z","iopub.execute_input":"2021-06-29T15:59:04.60352Z","iopub.status.idle":"2021-06-29T15:59:04.616819Z","shell.execute_reply.started":"2021-06-29T15:59:04.603487Z","shell.execute_reply":"2021-06-29T15:59:04.615587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.1 Understanding The Shape of Data","metadata":{}},{"cell_type":"code","source":"# load the data\ntrain = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:04.618405Z","iopub.execute_input":"2021-06-29T15:59:04.61897Z","iopub.status.idle":"2021-06-29T15:59:14.854486Z","shell.execute_reply.started":"2021-06-29T15:59:04.618934Z","shell.execute_reply":"2021-06-29T15:59:14.853546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, lets count how much data we have!\ntrain_len, test_len = len(train.index), len(test.index)\nprint(f'train size: {train_len}, test size: {test_len}')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:14.856544Z","iopub.execute_input":"2021-06-29T15:59:14.856858Z","iopub.status.idle":"2021-06-29T15:59:14.862489Z","shell.execute_reply.started":"2021-06-29T15:59:14.85683Z","shell.execute_reply":"2021-06-29T15:59:14.861357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Also, lets take a quick look at what we have \ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:14.864017Z","iopub.execute_input":"2021-06-29T15:59:14.864605Z","iopub.status.idle":"2021-06-29T15:59:14.893812Z","shell.execute_reply.started":"2021-06-29T15:59:14.86457Z","shell.execute_reply":"2021-06-29T15:59:14.892837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing the info of all the colums in our training dataset\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:14.895126Z","iopub.execute_input":"2021-06-29T15:59:14.895561Z","iopub.status.idle":"2021-06-29T15:59:14.91157Z","shell.execute_reply.started":"2021-06-29T15:59:14.895457Z","shell.execute_reply":"2021-06-29T15:59:14.910772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It's always a good idea to count the amount of missing values before diving into any analysis\n# Lets also see how many missing values (in percentage) we are dealing with\n\nmiss_val_train_df = train.isnull().sum(axis=0) / train_len\nmiss_val_train_df = miss_val_train_df[miss_val_train_df > 0] * 100\nmiss_val_train_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:14.913289Z","iopub.execute_input":"2021-06-29T15:59:14.913575Z","iopub.status.idle":"2021-06-29T15:59:15.759991Z","shell.execute_reply.started":"2021-06-29T15:59:14.91355Z","shell.execute_reply":"2021-06-29T15:59:15.759145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As we can see from the table above, a large portion of the data is missing the identity tag. However, as the number is the same for the tags, I assume that the data is complete for the part which has identity tags.","metadata":{}},{"cell_type":"markdown","source":"<b>Some features might have relations with Toxicity, like capitals letters in the text, punctuations in the texts. Add the new features into the training set.<b/>","metadata":{}},{"cell_type":"code","source":"train['total_length'] = train['comment_text'].apply(len)\ntrain['capitals'] = train['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntrain['caps_vs_length'] = train.apply(lambda row: float(row['capitals'])/float(row['total_length']),axis=1)\ntrain['num_exclamation_marks'] = train['comment_text'].apply(lambda comment: comment.count('!'))\ntrain['num_question_marks'] = train['comment_text'].apply(lambda comment: comment.count('?'))\ntrain['num_punctuation'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\ntrain['num_symbols'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\ntrain['num_words'] = train['comment_text'].apply(lambda comment: len(comment.split()))\ntrain['num_unique_words'] = train['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\ntrain['words_vs_unique'] = train['num_unique_words'] / train['num_words']\ntrain['num_smilies'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T15:59:15.76278Z","iopub.execute_input":"2021-06-29T15:59:15.763171Z","iopub.status.idle":"2021-06-29T16:00:56.785252Z","shell.execute_reply.started":"2021-06-29T15:59:15.763129Z","shell.execute_reply":"2021-06-29T16:00:56.784392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ('total_length', 'capitals', 'caps_vs_length', 'num_exclamation_marks','num_question_marks', 'num_punctuation', 'num_words', 'num_unique_words','words_vs_unique', 'num_smilies', 'num_symbols')\ncolumns = ('target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'funny', 'wow', 'sad', 'likes', 'disagree', 'sexual_explicit','identity_annotator_count', 'toxicity_annotator_count')\nrows = [{c:train[f].corr(train[c]) for c in columns} for f in features]\ntrain_correlations = pd.DataFrame(rows, index=features)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:00:56.787224Z","iopub.execute_input":"2021-06-29T16:00:56.78771Z","iopub.status.idle":"2021-06-29T16:01:00.131221Z","shell.execute_reply.started":"2021-06-29T16:00:56.787671Z","shell.execute_reply":"2021-06-29T16:01:00.130381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see the correlations between new features and targets.\n\ntrain_correlations","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:00.132527Z","iopub.execute_input":"2021-06-29T16:01:00.132934Z","iopub.status.idle":"2021-06-29T16:01:00.154411Z","shell.execute_reply.started":"2021-06-29T16:01:00.132885Z","shell.execute_reply":"2021-06-29T16:01:00.153365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlations between new features and targets in heatmap:\n\nplt.figure(figsize=(10, 6))\nsns.set(font_scale=1)\nax = sns.heatmap(train_correlations, vmin=-0.1, vmax=0.1, center=0.0)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:00.156064Z","iopub.execute_input":"2021-06-29T16:01:00.156433Z","iopub.status.idle":"2021-06-29T16:01:00.610996Z","shell.execute_reply.started":"2021-06-29T16:01:00.156396Z","shell.execute_reply":"2021-06-29T16:01:00.610103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percent of toxic comments related to different identities, using target and popolation amount of each identity as weights:\n\ndemographics = train.loc[:, ['target']+list(train)[slice(8,32)]].dropna()\nweighted_toxic = demographics.iloc[:, 1:].multiply(demographics.iloc[:, 0], axis=\"index\").sum()/demographics.iloc[:, 1:][demographics.iloc[:, 1:]>0].count()\nweighted_toxic = weighted_toxic.sort_values(ascending=False)\nplt.figure(figsize=(30,20))\nsns.set(font_scale=3)\nax = sns.barplot(x = weighted_toxic.values, y = weighted_toxic.index, alpha=0.8)\nplt.ylabel('Demographics')\nplt.xlabel('Weighted Toxic')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:00.612365Z","iopub.execute_input":"2021-06-29T16:01:00.612698Z","iopub.status.idle":"2021-06-29T16:01:02.132164Z","shell.execute_reply.started":"2021-06-29T16:01:00.612662Z","shell.execute_reply":"2021-06-29T16:01:02.131329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Meanwhile, we can check the correlations between identities and the comment labels.\n\nidentities = tuple(train.iloc[:, 8:32])\nrows = [{c:train[f].corr(train[c]) for c in columns} for f in identities]\npoptoxicity_correlations = pd.DataFrame(rows, index=identities)\n\npoptoxicity_correlations","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:02.13351Z","iopub.execute_input":"2021-06-29T16:01:02.133967Z","iopub.status.idle":"2021-06-29T16:01:10.141248Z","shell.execute_reply.started":"2021-06-29T16:01:02.133923Z","shell.execute_reply":"2021-06-29T16:01:10.140359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap for the correlations\n\nplt.figure(figsize=(12, 8))\nsns.set(font_scale=1)\nax = sns.heatmap(poptoxicity_correlations, vmin=-0.1, vmax=0.1, center=0.0)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:10.142616Z","iopub.execute_input":"2021-06-29T16:01:10.143149Z","iopub.status.idle":"2021-06-29T16:01:10.904927Z","shell.execute_reply.started":"2021-06-29T16:01:10.143104Z","shell.execute_reply":"2021-06-29T16:01:10.904105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\ndel train_correlations\ndel poptoxicity_correlations\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:10.908643Z","iopub.execute_input":"2021-06-29T16:01:10.910591Z","iopub.status.idle":"2021-06-29T16:01:11.107297Z","shell.execute_reply.started":"2021-06-29T16:01:10.910551Z","shell.execute_reply":"2021-06-29T16:01:11.106421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.0 Time Series Analysis of Comments Made","metadata":{}},{"cell_type":"code","source":"# Lets again create a list of all the identities tagged in this dataset. This list given in the data section of this competition. \n\nidentities_all = ['male','female','transgender','other_gender','heterosexual','homosexual_gay_or_lesbian',\n              'bisexual','other_sexual_orientation','christian','jewish','muslim','hindu','buddhist',\n              'atheist','other_religion','black','white','asian','latino','other_race_or_ethnicity',\n              'physical_disability','intellectual_or_learning_disability','psychiatric_or_mental_illness',\n              'other_disability']\n\n# Now getting the dataframe with identities tagged\n#train_labeled_df = train.loc[:, ['target'] + identities_all].dropna()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:11.111734Z","iopub.execute_input":"2021-06-29T16:01:11.114141Z","iopub.status.idle":"2021-06-29T16:01:11.120853Z","shell.execute_reply.started":"2021-06-29T16:01:11.1141Z","shell.execute_reply":"2021-06-29T16:01:11.119866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can also check the Time Series for Toxicity with different identities:\nwithdate = train.loc[:, ['created_date', 'target'] + identities_all].dropna()\nraceweighted = withdate.iloc[:, 2:]/withdate.iloc[:, 2:].sum()\nrace_target_weighted = raceweighted.multiply(withdate.iloc[:, 1], axis=\"index\")\nrace_target_weighted['comment_count'] = 1\n# now we add the date to our newly created dataframe (also parse the text date as datetime)\nrace_target_weighted['created_date'] = pd.to_datetime(withdate['created_date']).values.astype('datetime64[M]')\nweighted_demo = race_target_weighted.groupby(['created_date']).sum().sort_index()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:11.125061Z","iopub.execute_input":"2021-06-29T16:01:11.12749Z","iopub.status.idle":"2021-06-29T16:01:12.167511Z","shell.execute_reply.started":"2021-06-29T16:01:11.127452Z","shell.execute_reply":"2021-06-29T16:01:12.16662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install chart_studio","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:12.168955Z","iopub.execute_input":"2021-06-29T16:01:12.169331Z","iopub.status.idle":"2021-06-29T16:01:17.95899Z","shell.execute_reply.started":"2021-06-29T16:01:12.169279Z","shell.execute_reply":"2021-06-29T16:01:17.958077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing plotly credentials for time series datavisualizations\n\nimport plotly\nimport chart_studio\nimport chart_studio.plotly as py\nimport cufflinks as cf\nimport plotly.graph_objs as go\nchart_studio.tools.set_credentials_file(username='raisul_bd', api_key='gkmwlmRYR0UBe11MnK4O')\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:17.960717Z","iopub.execute_input":"2021-06-29T16:01:17.96111Z","iopub.status.idle":"2021-06-29T16:01:17.972518Z","shell.execute_reply.started":"2021-06-29T16:01:17.961069Z","shell.execute_reply":"2021-06-29T16:01:17.971695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weighted_demo[['white', 'asian', 'black', 'jewish', 'latino', 'other_race_or_ethnicity']].iplot(title = 'Time Series Toxicity & Race', filename='Time Series Toxicity & Race' )\n\n# Click on the legend to change display. Double click for single identity.","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:17.977937Z","iopub.execute_input":"2021-06-29T16:01:17.978188Z","iopub.status.idle":"2021-06-29T16:01:21.520033Z","shell.execute_reply.started":"2021-06-29T16:01:17.978164Z","shell.execute_reply":"2021-06-29T16:01:21.519234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <b>Here we see the relative weighted toxic score for each identity of races for two year span.<b/>","metadata":{}},{"cell_type":"code","source":"weighted_demo[['atheist', 'buddhist', 'christian', 'hindu', 'muslim', 'other_religion']].iplot(title = 'Time Series Toxicity & Religion', filename='Time Series Toxicity & Religion')\n\n# Click on the legend to change display. Double click for single identity.","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:21.522778Z","iopub.execute_input":"2021-06-29T16:01:21.523128Z","iopub.status.idle":"2021-06-29T16:01:26.748141Z","shell.execute_reply.started":"2021-06-29T16:01:21.523097Z","shell.execute_reply":"2021-06-29T16:01:26.747242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <b>Here we see the relative weighted toxic score for each identity of Religion for two year span.<b/>","metadata":{}},{"cell_type":"code","source":"weighted_demo[['heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation']].iplot(title = 'Time Series Toxicity & Sexual Orientation', filename='Time Series Toxicity & Sexual Orientation')\n\n# Click on the legend to change display. Double click for single identity.","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:26.749484Z","iopub.execute_input":"2021-06-29T16:01:26.749813Z","iopub.status.idle":"2021-06-29T16:01:30.107123Z","shell.execute_reply.started":"2021-06-29T16:01:26.749776Z","shell.execute_reply":"2021-06-29T16:01:30.10635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <b>Here we see the relative weighted toxic score for each identity of Sexual Orientation for two year span.<b/>","metadata":{}},{"cell_type":"code","source":"weighted_demo[['male', 'female', 'transgender', 'other_gender']].iplot(title = 'Time Series Toxicity & Gender', filename='Time Series Toxicity & Gender')\n\n# Click on the legend to change display. Double click for single identity.","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:30.108359Z","iopub.execute_input":"2021-06-29T16:01:30.108688Z","iopub.status.idle":"2021-06-29T16:01:33.628435Z","shell.execute_reply.started":"2021-06-29T16:01:30.108651Z","shell.execute_reply":"2021-06-29T16:01:33.627628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <b>Here we see the relative weighted toxic score for each identity of Gender for two year span. It's clearly visible that the Toxicity level for Transgenders is significantly higher than the other Genders.<b/>","metadata":{}},{"cell_type":"code","source":"weighted_demo[['physical_disability', 'intellectual_or_learning_disability', 'psychiatric_or_mental_illness', 'other_disability']].iplot(title = 'Time Series Toxicity & Disability', filename='Time Series Toxicity & Disability')\n\n# Click on the legend to change display. Double click for single identity.","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:33.629754Z","iopub.execute_input":"2021-06-29T16:01:33.630102Z","iopub.status.idle":"2021-06-29T16:01:37.167952Z","shell.execute_reply.started":"2021-06-29T16:01:33.630066Z","shell.execute_reply":"2021-06-29T16:01:37.167052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <b>Here we see the relative weighted toxic score for each identity of Disability for two year span.<b/>","metadata":{}},{"cell_type":"markdown","source":"# 4.0 Zooming Into the Peaks","metadata":{}},{"cell_type":"markdown","source":"> #### Observation: After plotting these charts, we have found that most data have a peak around Jan 2017. A bit curious. Let's check what's different between Jan 2017 and other time.","metadata":{}},{"cell_type":"code","source":"alldate_toxicity = train[train['target'] >= 0.5].loc[:, ['created_date', 'target', 'comment_text']].dropna()\nalldate_toxicity['created_date'] = pd.to_datetime(alldate_toxicity['created_date']).values.astype('datetime64[M]')\njan_2017_toxicity = alldate_toxicity[alldate_toxicity['created_date'] == '2017-01-01']\n\nfrom nltk.corpus import stopwords\ndef check_frequency(data = alldate_toxicity['comment_text'], n = 20):\n    stop = stopwords.words('english')\n    data  = data.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n    data = data.str.replace('[^\\w\\s]','')\n    data = data.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n    freq = pd.Series(' '.join(data).split()).value_counts()[:n]\n    return freq\n\ntop_10_toxicity_othertime = check_frequency(data = alldate_toxicity[alldate_toxicity['created_date'] != '2017-01-01']['comment_text'], n = 10)\ntop_10_toxicity_jan_2017 = check_frequency(data = jan_2017_toxicity['comment_text'], n = 10)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:37.169244Z","iopub.execute_input":"2021-06-29T16:01:37.169717Z","iopub.status.idle":"2021-06-29T16:01:55.759365Z","shell.execute_reply.started":"2021-06-29T16:01:37.169675Z","shell.execute_reply":"2021-06-29T16:01:55.758441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check, which toxicity related word appears Top 10 in jan_2017, but not in other time Top 10.","metadata":{}},{"cell_type":"code","source":"top_10_toxicity_jan_2017.index.difference(top_10_toxicity_othertime.index)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:55.760689Z","iopub.execute_input":"2021-06-29T16:01:55.761051Z","iopub.status.idle":"2021-06-29T16:01:55.767078Z","shell.execute_reply.started":"2021-06-29T16:01:55.761016Z","shell.execute_reply":"2021-06-29T16:01:55.76631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently, none of them. All the same. Then let's theck their frequency.","metadata":{}},{"cell_type":"code","source":"percent_toxicity_othertime = top_10_toxicity_othertime/alldate_toxicity[alldate_toxicity['created_date'] != '2017-01-01']['comment_text'].str.split().str.len().sum()\npercent_toxicity_jan_2017 = top_10_toxicity_jan_2017/jan_2017_toxicity['comment_text'].str.split().str.len().sum()\ntop_toxicity = pd.concat([percent_toxicity_jan_2017, percent_toxicity_othertime], axis=1, sort=False)\ntop_toxicity.columns = ['Jan_2017', 'Other_Time']\ntop_toxicity['Difference'] = top_toxicity['Jan_2017'] - top_toxicity['Other_Time']","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:55.768237Z","iopub.execute_input":"2021-06-29T16:01:55.768704Z","iopub.status.idle":"2021-06-29T16:01:57.011576Z","shell.execute_reply.started":"2021-06-29T16:01:55.768666Z","shell.execute_reply":"2021-06-29T16:01:57.010432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_toxicity.head(30)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:57.012941Z","iopub.execute_input":"2021-06-29T16:01:57.013299Z","iopub.status.idle":"2021-06-29T16:01:57.02581Z","shell.execute_reply.started":"2021-06-29T16:01:57.013246Z","shell.execute_reply":"2021-06-29T16:01:57.024769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets Plot the values to see the frequency over words.","metadata":{}},{"cell_type":"code","source":"import chart_studio.plotly as py\nimport plotly.graph_objects as go\n\ntrace1 = go.Bar(\n    x=top_toxicity.index,\n    y=top_toxicity['Jan_2017'],\n    name='Jan_2017'\n)\ntrace2 = go.Bar(\n    x=top_toxicity.index,\n    y=top_toxicity['Other_Time'],\n    name='Other_Time'\n)\n\ndata = [trace2, trace1]\nlayout = go.Layout(\n    barmode='group'\n)\nlayout = go.Layout(yaxis=dict(tickformat=\".2%\"))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, title = 'Top Toxicity Comarision', filename='top_toxicity_comarision')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:01:57.027362Z","iopub.execute_input":"2021-06-29T16:01:57.027775Z","iopub.status.idle":"2021-06-29T16:02:00.484581Z","shell.execute_reply.started":"2021-06-29T16:01:57.027734Z","shell.execute_reply":"2021-06-29T16:02:00.483687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After checking the whole time series, let's see that, which Time of the day People are more Toxic.\n\ntrain['datetime64'] = pd.to_datetime(train['created_date']).values.astype('datetime64[h]')\ntrain['hour'] = train['datetime64'].dt.hour\nall_comments_by_hour = train['target'].groupby(train['hour']).sum().sort_index()/train['target'].groupby(train['hour']).sum().sum()\ntoxic_comments_by_hour = train[train['target'] >= 0.5]['target'].groupby(train['hour']).sum().sort_index()/train[train['target'] >= 0.5]['target'].groupby(train['hour']).sum().sum()\ncomments_hour_check = pd.concat([all_comments_by_hour, toxic_comments_by_hour], axis=1, sort=False)\ncomments_hour_check.columns = ['all_comments', 'toxic_comments']","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:00.488785Z","iopub.execute_input":"2021-06-29T16:02:00.490949Z","iopub.status.idle":"2021-06-29T16:02:02.251408Z","shell.execute_reply.started":"2021-06-29T16:02:00.490908Z","shell.execute_reply":"2021-06-29T16:02:02.250533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Midnight', 'Morning', 'Noon', 'Evening', 'Midnight']\ntickvals = ['0', '6', '12', '18', comments_hour_check.index.max()]\n\ntrace1 = go.Scatter(\n    x=comments_hour_check.index,\n    y=comments_hour_check['all_comments'],\n    name = 'comment percent per H',\n    line = dict(\n        color = ('rgb(22, 96, 167)'),\n        width = 1)\n)\ntrace2 = go.Scatter(\n    x=comments_hour_check.index,\n    y=comments_hour_check['toxic_comments'],\n    name = 'toxic comment percent per H',\n    line = dict(\n        color = ('rgb(205, 12, 24)'),\n        width = 1,)\n)\n\ntrace3 = go.Bar(\n    x=comments_hour_check.index,\n    y=comments_hour_check['toxic_comments']-comments_hour_check['all_comments'],\n    name = 'More Toxic Comment Ratio'\n)\n\ndata = [trace1, trace2, trace3]\n\nlayout = go.Layout(yaxis=dict(tickformat=\".2%\"),\n                   title = 'Which Time are People More Toxic',\n                   xaxis=go.layout.XAxis(\n                       ticktext=labels, \n                       tickvals=tickvals\n                   ),\n                  )\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='Which Time are People More Toxic')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:02.252795Z","iopub.execute_input":"2021-06-29T16:02:02.253136Z","iopub.status.idle":"2021-06-29T16:02:05.636639Z","shell.execute_reply.started":"2021-06-29T16:02:02.2531Z","shell.execute_reply":"2021-06-29T16:02:05.635826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Interestingly, this shows Evening is the most busy part of the day when people uses Toxic words.","metadata":{}},{"cell_type":"markdown","source":"# 5.0 Scatter Plots for a given identity","metadata":{}},{"cell_type":"markdown","source":"Since there are so many spikes in our dataset, it is very easy to get distracted. To have a better idea we must zoom out. In this section we do that by extracting the peaks. This could be challenging, as we are not just looking for one global maximum. On the other hand, even if we sort it, we will not be able to find all the relative maximums without writing a complex algorithm to do so.\n\nFortunately, there is a great algorithm from scipy library called 'argrelextrema' that will allow us to extract the relative maximum points from our dataset. \n\nFor more details about this algorithm, check out the document section: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.argrelextrema.html","metadata":{}},{"cell_type":"code","source":"# Lets import the algorithm\nfrom scipy.signal import argrelextrema","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:05.637916Z","iopub.execute_input":"2021-06-29T16:02:05.63825Z","iopub.status.idle":"2021-06-29T16:02:05.643557Z","shell.execute_reply.started":"2021-06-29T16:02:05.638213Z","shell.execute_reply":"2021-06-29T16:02:05.642386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using this algorithm, we want to create a pandas dataframe to capture all the extreme points in our dataset that captures all the peak points per identity group. We will also want to do a scatter plot in the next section, and scatterplot implementation needs both values (x and y) to be numeric. So we also better create a column to represent the dates in a more numeric form.\n\nWe can do this by taking the date of the first comment as our reference point, and counting how many days the comment was made from the first comment in our dataset. Therefore, in the end we should get a dataframe with the following columns:\n\n| identity | created data | score | days_from_first |","metadata":{}},{"cell_type":"code","source":"# lets group most of the identities into three major categories as follows for simplified analysis\n\nraces = ['black','white','asian','latino','other_race_or_ethnicity']\nreligions = ['atheist', 'buddhist', 'christian', 'hindu', 'muslim', 'jewish','other_religion']\nsexual_orientation = ['heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation']","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:05.645035Z","iopub.execute_input":"2021-06-29T16:02:05.645649Z","iopub.status.idle":"2021-06-29T16:02:05.653937Z","shell.execute_reply.started":"2021-06-29T16:02:05.645608Z","shell.execute_reply":"2021-06-29T16:02:05.653198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will store all the different datapoints in the following dataframe\npeaks_df = pd.DataFrame()\n\n# first we loop through all the different identities we are interested in\nfor col in races + religions + sexual_orientation:\n    # we pass the values through the algorithm to get an index of the rel. maximums \n    _max_index = argrelextrema(weighted_demo[col].values, np.greater, order=15)\n    # we use the index returned to create a dataframe of the values for those index. in this case \n    # we are interested in the created date and the score, notice how the dataframe needs to be \n    # transformed because of the orientation of the arrays we started off with\n    col_peaks_df = pd.DataFrame(data = [weighted_demo.index[_max_index], weighted_demo[col].values[_max_index]]).T\n    col_peaks_df.columns = ['created_date','score']\n    # we create a new column labeling the identity so we can track which peak came from which identity\n    col_peaks_df['identity'] = col\n    # and we keep appending to our main dataframe \n    peaks_df = peaks_df.append(col_peaks_df)\n\n# lets set identity as our index and we are done\npeaks_df = peaks_df.set_index('identity')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:05.655438Z","iopub.execute_input":"2021-06-29T16:02:05.655789Z","iopub.status.idle":"2021-06-29T16:02:05.71217Z","shell.execute_reply.started":"2021-06-29T16:02:05.655754Z","shell.execute_reply":"2021-06-29T16:02:05.711439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets create a list of all the identities tagged in this dataset. This list given in the data section of this competition. \n\nidentities = ['male','female','transgender','other_gender','heterosexual','homosexual_gay_or_lesbian',\n              'bisexual','other_sexual_orientation','christian','jewish','muslim','hindu','buddhist',\n              'atheist','other_religion','black','white','asian','latino','other_race_or_ethnicity',\n              'physical_disability','intellectual_or_learning_disability','psychiatric_or_mental_illness',\n              'other_disability']","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:05.71341Z","iopub.execute_input":"2021-06-29T16:02:05.713758Z","iopub.status.idle":"2021-06-29T16:02:05.718455Z","shell.execute_reply.started":"2021-06-29T16:02:05.713724Z","shell.execute_reply":"2021-06-29T16:02:05.717453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To count the number of days from the first comment, we take our labeled data and convert the created date column\n\ncomments_with_date_df = train.loc[:, ['created_date', 'target','comment_text'] + identities].dropna()\ncomments_with_date_df['created_date'] = pd.to_datetime(withdate['created_date'].apply(lambda dt: dt[:10]))\ncomments_with_date_df['comment_count'] = 1","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:05.719807Z","iopub.execute_input":"2021-06-29T16:02:05.72015Z","iopub.status.idle":"2021-06-29T16:02:06.845875Z","shell.execute_reply.started":"2021-06-29T16:02:05.720112Z","shell.execute_reply":"2021-06-29T16:02:06.84502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate days from first comment\n\nfirst_dt = min(comments_with_date_df['created_date'].values)\nlast_dt = max(comments_with_date_df['created_date'].values)\npeaks_df['days_from_first'] = (peaks_df['created_date'] - first_dt).dt.days","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:06.847144Z","iopub.execute_input":"2021-06-29T16:02:06.847522Z","iopub.status.idle":"2021-06-29T16:02:09.19068Z","shell.execute_reply.started":"2021-06-29T16:02:06.847485Z","shell.execute_reply":"2021-06-29T16:02:09.188749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here is a peak at what our peaks_df looks like\npeaks_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.192215Z","iopub.execute_input":"2021-06-29T16:02:09.192573Z","iopub.status.idle":"2021-06-29T16:02:09.209298Z","shell.execute_reply.started":"2021-06-29T16:02:09.192536Z","shell.execute_reply":"2021-06-29T16:02:09.20835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have the peaks, lets visualize it. Scatter plot is typically used to show if there is a correlation between two variables. However, in this case, we can also use scatterplot to draw the relative maximums as descrete points. The nice thing about a scatter plot is that we can visualize a third variable as the size of the point. Let's take advantage of this and use the number of comments made as the size of the relative maximum points.","metadata":{}},{"cell_type":"code","source":"# lets create a function that returns the peaks dataframe for a given identity\n# we also want to get the number of toxic comments made against that identity in the dataframe\n\ndef get_identity_peaks_df(identity, peaks_df, comments_with_date_df):\n    # select subset and sort\n    identity_peaks_df = peaks_df[peaks_df.index==identity].sort_values(by='score', ascending=False)\n    # change the score type to float\n    identity_peaks_df['score'] = identity_peaks_df.score.astype(float)\n    # use created date as the index so we can join over in later step\n    identity_peaks_df = identity_peaks_df.set_index('created_date')\n    # calculate how many toxic comments were made targetting the given identity group\n    identity_comment_count_df = comments_with_date_df[comments_with_date_df[identity] > 0][['created_date','comment_count']].groupby('created_date').sum()\n    # do an inner join to also get the total number of comments made that day for the given identity\n    identity_peaks_df = identity_peaks_df.join(identity_comment_count_df)\n    return identity_peaks_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.210701Z","iopub.execute_input":"2021-06-29T16:02:09.211181Z","iopub.status.idle":"2021-06-29T16:02:09.219855Z","shell.execute_reply.started":"2021-06-29T16:02:09.211152Z","shell.execute_reply":"2021-06-29T16:02:09.219068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To make our scatter plot more presentable we will set the max and min of our y axis\ny_lim_min = peaks_df['score'].max() + peaks_df['score'].max() / 3 # adding a little bit head room on y axis\ny_lim_max = peaks_df['score'].min()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.221117Z","iopub.execute_input":"2021-06-29T16:02:09.22152Z","iopub.status.idle":"2021-06-29T16:02:09.231985Z","shell.execute_reply.started":"2021-06-29T16:02:09.221483Z","shell.execute_reply":"2021-06-29T16:02:09.231127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now lets write a function that draws the scatter plot for a given identity\n\ndef identity_scatter_plot(identity, identity_peaks_df, y_lim_min, y_lim_max):\n    x = identity_peaks_df['days_from_first'].values\n    y = identity_peaks_df['score'].values\n    size = identity_peaks_df['comment_count'].values\n    label = identity_peaks_df['comment_count'].index\n    plt.figure(figsize=(15,7))\n    plt.tick_params(axis='both', which='major', labelsize=16)\n    plt.scatter(x, y, s=size, label=label)\n    plt.ylim(y_lim_max, y_lim_min)\n    axis_font = {'fontname':'Arial', 'size':'14'}\n    plt.title('Relative Maximums - Targeted Against '+ identity.capitalize() +' Identity', fontsize=15)\n    plt.xlabel('Comment Date', fontsize=15)\n    plt.ylabel('Relative Weighted Toxic Score', fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.233154Z","iopub.execute_input":"2021-06-29T16:02:09.23358Z","iopub.status.idle":"2021-06-29T16:02:09.243422Z","shell.execute_reply.started":"2021-06-29T16:02:09.233544Z","shell.execute_reply":"2021-06-29T16:02:09.242606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are ready to plot each relative maximums per identity group. However, lets only look at top 5 for now. If you remember the horizontal bar plot we did at the start of our tutorial (second graph from the top), you can see that the identities that are most frequently targeted are white, black, homosexual_gay_or_lesbian, muslim, and jewish.","metadata":{}},{"cell_type":"code","source":"identity = 'white'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_scatter_plot(identity, identity_peaks_df, y_lim_min, y_lim_max)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.244676Z","iopub.execute_input":"2021-06-29T16:02:09.245199Z","iopub.status.idle":"2021-06-29T16:02:09.492682Z","shell.execute_reply.started":"2021-06-29T16:02:09.245163Z","shell.execute_reply":"2021-06-29T16:02:09.491715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'black'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_scatter_plot(identity, identity_peaks_df, y_lim_min, y_lim_max)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.494143Z","iopub.execute_input":"2021-06-29T16:02:09.494506Z","iopub.status.idle":"2021-06-29T16:02:09.722029Z","shell.execute_reply.started":"2021-06-29T16:02:09.494469Z","shell.execute_reply":"2021-06-29T16:02:09.721053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'homosexual_gay_or_lesbian'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_scatter_plot(identity, identity_peaks_df, y_lim_min, y_lim_max)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.723482Z","iopub.execute_input":"2021-06-29T16:02:09.723827Z","iopub.status.idle":"2021-06-29T16:02:09.953232Z","shell.execute_reply.started":"2021-06-29T16:02:09.72379Z","shell.execute_reply":"2021-06-29T16:02:09.95221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'muslim'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_scatter_plot(identity, identity_peaks_df, y_lim_min, y_lim_max)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:09.954686Z","iopub.execute_input":"2021-06-29T16:02:09.955037Z","iopub.status.idle":"2021-06-29T16:02:10.166506Z","shell.execute_reply.started":"2021-06-29T16:02:09.954999Z","shell.execute_reply":"2021-06-29T16:02:10.165539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'jewish'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_scatter_plot(identity, identity_peaks_df, y_lim_min, y_lim_max)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:10.168392Z","iopub.execute_input":"2021-06-29T16:02:10.168865Z","iopub.status.idle":"2021-06-29T16:02:10.390975Z","shell.execute_reply.started":"2021-06-29T16:02:10.168822Z","shell.execute_reply":"2021-06-29T16:02:10.389996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.1 Correlation and Heatmap of Identities\n\nTo better understand the dataset, we need to look at the correlation between each identities. Thus, in this section we will calculate the correlation between each of the identities and see if identities are often mentioned together. We are also interested to know which identities are frequently mentioned (or not mentioned) together. Understanding correlation for a large number of columns would be very difficult without visualization. However, this task is very simple once we draw a heatmap.","metadata":{}},{"cell_type":"code","source":"# Lets import seaborn\nimport seaborn as sns\n\n# Compute the correlation matrix\ncorr = comments_with_date_df[identities].corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nsns.set(font_scale = 1)\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:10.39238Z","iopub.execute_input":"2021-06-29T16:02:10.39275Z","iopub.status.idle":"2021-06-29T16:02:11.931271Z","shell.execute_reply.started":"2021-06-29T16:02:10.39271Z","shell.execute_reply":"2021-06-29T16:02:11.93047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The heatmap plot of the correlation between the identities is very insightful. I will summarize my observations below.\n\n- It is interesting to see that strong correlations form triangular area at the edge of diagonal.\n- This basically means that there is a strong correlation between the groups of the identity (gender, religion, races, disabilities). This means, the comments where male identity is the target, female identity is also very likely to be the target.\n- In another words, in toxic and non-toxic comments, people tend to make it about one group vs another quiet frequently.","metadata":{}},{"cell_type":"markdown","source":"# 6.0 Generating Word Clouds","metadata":{}},{"cell_type":"markdown","source":"Tag cloud or word cloud is an effective way to visualize text data. Also, to clear the clutter and focus better, I will only use the comments from the peaks per identity and create word cloud of the most frequent words. To do this we will use a popular python library called WordCloud. We will also use NLTK to take stop words (like the, it, and so on) out of our WordCloud.\n\nReference: https://www.datacamp.com/community/tutorials/wordcloud-python","metadata":{}},{"cell_type":"code","source":"# Import wordcloud\nfrom wordcloud import WordCloud\n# import NLTK mainly for stopwords\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:11.932515Z","iopub.execute_input":"2021-06-29T16:02:11.932839Z","iopub.status.idle":"2021-06-29T16:02:12.076886Z","shell.execute_reply.started":"2021-06-29T16:02:11.932804Z","shell.execute_reply":"2021-06-29T16:02:12.076016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will write a simple function to generate the wordcloud per identity group\n\ndef generate_word_cloud(identity, toxic_comments, non_toxic_comments):\n    # convert stop words to sets as required by the wordcloud library\n    stop_words = set(stopwords.words(\"english\"))\n    # create toxic wordcloud\n    wordcloud_toxic = WordCloud(max_font_size=100, max_words=100, background_color=\"white\", stopwords=stop_words).generate(toxic_comments)\n    # create non-toxic wordcloud\n    wordcloud_non_toxic = WordCloud(max_font_size=100, max_words=100, background_color=\"white\", stopwords=stop_words).generate(non_toxic_comments)\n    # draw the two wordclouds side by side using subplot\n    fig = plt.figure(figsize=[15,5])\n    fig.add_subplot(1, 2, 1).set_title(\"Toxic Wordcloud\", fontsize=10)\n    plt.imshow(wordcloud_toxic, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    fig.add_subplot(1, 2, 2).set_title(\"Non Toxic Wordcloud\", fontsize=10)\n    plt.imshow(wordcloud_non_toxic, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.subplots_adjust(top=0.85)\n    plt.suptitle('Word Cloud - {} Identity'.format(identity), size = 16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:12.078039Z","iopub.execute_input":"2021-06-29T16:02:12.078373Z","iopub.status.idle":"2021-06-29T16:02:12.086431Z","shell.execute_reply.started":"2021-06-29T16:02:12.078337Z","shell.execute_reply":"2021-06-29T16:02:12.085427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function returns a tuple (toxic comments, non toxic comments) for the peaks\n\ndef get_comments(identity, identity_peaks_df):\n    # create an empty array to return comments\n    toxic_comments, non_toxic_comments = np.array([]), np.array([])\n    # go over all the dates and grab the relevant comments for the given identity\n    for dt in identity_peaks_df.index:\n        # get the toxic comments\n        comments_dt_df = comments_with_date_df[(comments_with_date_df['created_date'] == dt) \\\n                                               & (comments_with_date_df[identity] > 0) \\\n                                               & (comments_with_date_df['target'] >= .5)]\n        toxic_comments = np.append(toxic_comments, comments_dt_df['comment_text'].values)\n        \n        # get the non toxic comments\n        comments_dt_df = comments_with_date_df[(comments_with_date_df['created_date'] == dt) \\\n                                               & (comments_with_date_df[identity] > 0) \\\n                                               & (comments_with_date_df['target'] < .5)]\n        non_toxic_comments = np.append(non_toxic_comments, comments_dt_df['comment_text'].values)\n    \n    return (toxic_comments, non_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:12.087862Z","iopub.execute_input":"2021-06-29T16:02:12.088226Z","iopub.status.idle":"2021-06-29T16:02:12.09871Z","shell.execute_reply.started":"2021-06-29T16:02:12.088188Z","shell.execute_reply":"2021-06-29T16:02:12.097851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets draw the wordcloud for white identity\n\nidentity = 'white'\n# get the peaks for the given identity\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\n# get the comments for the given identity for the peaks\nidentity_comments = get_comments(identity, identity_peaks_df)\n# lets convert the comments as one long string (as needed by wordcloud)\ntoxic_comments = ' '.join(identity_comments[0])\nnon_toxic_comments = ' '.join(identity_comments[1])\n# draw the wordcloud using the function we created earlier\ngenerate_word_cloud(identity, toxic_comments, non_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:12.09993Z","iopub.execute_input":"2021-06-29T16:02:12.100289Z","iopub.status.idle":"2021-06-29T16:02:12.743414Z","shell.execute_reply.started":"2021-06-29T16:02:12.100241Z","shell.execute_reply":"2021-06-29T16:02:12.742545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Like white identity, lets draw the wordcloud for the other top identities\n\nidentity = 'black'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_comments = get_comments(identity, identity_peaks_df)\ntoxic_comments = ' '.join(identity_comments[0])\nnon_toxic_comments = ' '.join(identity_comments[1])\ngenerate_word_cloud(identity, toxic_comments, non_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:12.744678Z","iopub.execute_input":"2021-06-29T16:02:12.745019Z","iopub.status.idle":"2021-06-29T16:02:13.37903Z","shell.execute_reply.started":"2021-06-29T16:02:12.744982Z","shell.execute_reply":"2021-06-29T16:02:13.378012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'homosexual_gay_or_lesbian'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_comments = get_comments(identity, identity_peaks_df)\ntoxic_comments = ' '.join(identity_comments[0])\nnon_toxic_comments = ' '.join(identity_comments[1])\ngenerate_word_cloud(identity, toxic_comments, non_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:13.380474Z","iopub.execute_input":"2021-06-29T16:02:13.380819Z","iopub.status.idle":"2021-06-29T16:02:13.995704Z","shell.execute_reply.started":"2021-06-29T16:02:13.380784Z","shell.execute_reply":"2021-06-29T16:02:13.994738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'muslim'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_comments = get_comments(identity, identity_peaks_df)\ntoxic_comments = ' '.join(identity_comments[0])\nnon_toxic_comments = ' '.join(identity_comments[1])\ngenerate_word_cloud(identity, toxic_comments, non_toxic_comments)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:13.99716Z","iopub.execute_input":"2021-06-29T16:02:13.99752Z","iopub.status.idle":"2021-06-29T16:02:14.974543Z","shell.execute_reply.started":"2021-06-29T16:02:13.997483Z","shell.execute_reply":"2021-06-29T16:02:14.969042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = 'jewish'\nidentity_peaks_df = get_identity_peaks_df(identity, peaks_df, comments_with_date_df)\nidentity_comments = get_comments(identity, identity_peaks_df)\ntoxic_comments = ' '.join(identity_comments[0])\nnon_toxic_comments = ' '.join(identity_comments[1])\ngenerate_word_cloud(identity, toxic_comments, non_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:14.978738Z","iopub.execute_input":"2021-06-29T16:02:14.979098Z","iopub.status.idle":"2021-06-29T16:02:15.911309Z","shell.execute_reply.started":"2021-06-29T16:02:14.979061Z","shell.execute_reply":"2021-06-29T16:02:15.910345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic_comments = comments_with_date_df[comments_with_date_df['target'] >= .5]['comment_text'].values\nnon_toxic_comments = comments_with_date_df[comments_with_date_df['target'] < .5]['comment_text'].values\ntoxic_comments = ' '.join(toxic_comments)\nnon_toxic_comments = ' '.join(non_toxic_comments)\ngenerate_word_cloud('All', toxic_comments, non_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T16:02:15.916832Z","iopub.execute_input":"2021-06-29T16:02:15.917331Z","iopub.status.idle":"2021-06-29T16:03:39.907589Z","shell.execute_reply.started":"2021-06-29T16:02:15.917289Z","shell.execute_reply":"2021-06-29T16:03:39.906748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The wordcloud above is really interesting. Looking at it, I have made the following observations:\n\nAlthough the sentiment within the sentences (probably) varies in toxic and non-toxic comments, looking at it from top word frequencies, the differences are not that big.\nBetween comments about White and Black identity, there is a huge overlap!\nComments towards homosexual have more unique set of words (as imagined) from the other identity groups. However, between toxic and non-toxic comment there isn't a big variation in terms of the high frequenty words.\nFor comments about Jewish identity, the word Muslim appears frequently. After reviewing a lot of the samples of such comments I noticed that a large number of comments about Jewish identity is toxic towards Muslim identity.\nIronically, Trump is a very frequent common topic of discussion in toxic and non-toxic comments. However, frequency of Trump appearing is more in toxic comments. \"Trump\" or \"Trump Supporters\" could be a identitity in itself =)","metadata":{}}]}