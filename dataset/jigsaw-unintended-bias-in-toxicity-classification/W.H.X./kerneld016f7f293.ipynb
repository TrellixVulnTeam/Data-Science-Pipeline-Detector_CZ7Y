{"cells":[{"metadata":{},"cell_type":"markdown","source":"## I.Preprocess"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import SpatialDropout1D, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"Train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsub = pd.read_csv('../input/sample_submission.csv')","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = Train","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IDENTITY_COLUMNS = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness'\n]\nAUX_COLUMNS = ['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\nTEXT_COLUMN = 'comment_text'\nTARGET_COLUMN = 'target'","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.lancaster import LancasterStemmer\nenglish_punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\ndef preprocess(sentences):\n    list_sentences = list(sentences)\n    text_tokenized = [[word.lower() for word in word_tokenize(sen)] for sen in list_sentences]\n    text_filtered = [[word for word in sen if not word in english_punctuations] for sen in text_tokenized]\n    st = LancasterStemmer()\n    texts_stemmed = [[st.stem(word) for word in sen] for sen in text_filtered]\n    preprocessed_sentences = [\" \".join(sen) for sen in texts_stemmed]\n    return preprocessed_sentences","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train[TARGET_COLUMN].values\ny_aux_train = train[AUX_COLUMNS].values\nlist_sentences_train = preprocess(train[\"comment_text\"])\nlist_sentences_test = preprocess(test[\"comment_text\"])","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 200\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[IDENTITY_COLUMNS+AUX_COLUMNS].fillna(0).values","execution_count":50,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## II. Build Model\nAfter finish prepocessing of data, we start to build our LSTM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = Input(shape=(maxlen, ))\nembed_size = 128\nLSTM_UNITS = 128\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = Embedding(max_features, embed_size)(inp)\nx = SpatialDropout1D(0.2)(x)\nx = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\nx = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)","execution_count":52,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden = concatenate([\n        GlobalMaxPooling1D()(x),\n        GlobalAveragePooling1D()(x),\n    ])\nhidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\nhidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\nresult = Dense(1, activation='sigmoid')(hidden)\naux_result = Dense(len(AUX_COLUMNS), activation='sigmoid')(hidden)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs=inp, outputs=[result, aux_result])\nmodel.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])","execution_count":54,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## III. Runtime"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 2\nmodel.fit(X_t,[y_train, y_aux_train], batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":55,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nTrain on 90000 samples, validate on 10000 samples\nEpoch 1/2\n90000/90000 [==============================] - 149s 2ms/step - loss: 0.3842 - dense_3_loss: 0.2637 - dense_4_loss: 0.1204 - dense_3_acc: 0.7021 - dense_4_acc: 0.8555 - val_loss: 0.3617 - val_dense_3_loss: 0.2490 - val_dense_4_loss: 0.1127 - val_dense_3_acc: 0.7048 - val_dense_4_acc: 0.8578\nEpoch 2/2\n90000/90000 [==============================] - 144s 2ms/step - loss: 0.3491 - dense_3_loss: 0.2398 - dense_4_loss: 0.1093 - dense_3_acc: 0.7027 - dense_4_acc: 0.8559 - val_loss: 0.3545 - val_dense_3_loss: 0.2448 - val_dense_4_loss: 0.1097 - val_dense_3_acc: 0.7053 - val_dense_4_acc: 0.8580\n","name":"stdout"},{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"<keras.callbacks.History at 0x7f51602fcda0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_te)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = predictions[0]\noutput_df = pd.DataFrame(probabilities, columns=['prediction'])\nmerged_df =  pd.concat([test, output_df], axis=1)\nsubmission = merged_df.drop(['comment_text'], axis=1)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}