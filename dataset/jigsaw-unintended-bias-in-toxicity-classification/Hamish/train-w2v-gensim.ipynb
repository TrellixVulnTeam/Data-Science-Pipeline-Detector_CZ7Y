{"cells":[{"metadata":{},"cell_type":"markdown","source":"Here is a w2v model trained over the two jigsaw toxic comment competitions. As you can see I've not included the test data from the lastest competition - as you can see it doesn't include the test data from the lastest comp. Feel free to fork and add it if you need"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['jigsaw-unintended-bias-in-toxicity-classification', 'cleaned-toxic-comments']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Note (again) - deliberately don't use test2 here"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_1 = pd.read_csv('../input/cleaned-toxic-comments/train_preprocessed.csv')\ndf_test_1 = pd.read_csv('../input/cleaned-toxic-comments/test_preprocessed.csv')\ndf_train_2 = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n# df_test_2 = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_1.sample(3)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                             comment_text   ...    toxicity\n31668   freeing myself from bothering with being on th...   ...         0.0\n106911  hell my suspicion was true wikipedia is driven...   ...         1.0\n142875  also the canoe slam article is from years ago ...   ...         0.0\n\n[3 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>id</th>\n      <th>identity_hate</th>\n      <th>insult</th>\n      <th>obscene</th>\n      <th>set</th>\n      <th>severe_toxic</th>\n      <th>threat</th>\n      <th>toxic</th>\n      <th>toxicity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31668</th>\n      <td>freeing myself from bothering with being on th...</td>\n      <td>541b00ccfef15003</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>106911</th>\n      <td>hell my suspicion was true wikipedia is driven...</td>\n      <td>3bb2d4ae8fdccb12</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>142875</th>\n      <td>also the canoe slam article is from years ago ...</td>\n      <td>fc14fc5a388ca1fb</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_preprocess(data):\n    data = str(data)\n    data = data.lower()\n    '''\n    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n    '''\n    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n    def clean_special_chars(text, punct):        \n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = clean_special_chars(data, punct)\n    return data","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_1['clean'] = df_train_1['comment_text'].apply(basic_preprocess)\ndf_test_1['clean'] = df_test_1['comment_text'].apply(basic_preprocess)\ndf_train_2['clean'] = df_train_2['comment_text'].apply(basic_preprocess)\n# df_test_2['clean'] = df_test_2['comment_text'].apply(basic_preprocess)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To train gensim we need to prep the data. This is a 3 part process\n\n- concatenate the data into a single list\n- split each string into a list of words\n- filter out some junk\n\nAt that point we have a list of lists"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = list(df_train_2['clean'] + df_train_1['clean'] + df_test_1['clean'])\n\nall_text = list(map(lambda s: str(s).split(' '), all_text))\nall_text = list(map(lambda s: list(filter(lambda w: str(w).strip() != \"\", s)), all_text))\n\nall_text[:3]","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"[['this',\n  'is',\n  'so',\n  'cool',\n  'it',\n  's',\n  'like',\n  'would',\n  'you',\n  'want',\n  'your',\n  'mother',\n  'to',\n  'read',\n  'this',\n  'really',\n  'great',\n  'idea',\n  'well',\n  'done',\n  'explanation',\n  'why',\n  'the',\n  'edits',\n  'made',\n  'under',\n  'my',\n  'username',\n  'hardcore',\n  'metallica',\n  'fan',\n  'were',\n  'reverted',\n  'they',\n  'weren',\n  't',\n  'vandalisms',\n  'just',\n  'closure',\n  'on',\n  'some',\n  'gas',\n  'after',\n  'i',\n  'voted',\n  'at',\n  'new',\n  'york',\n  'dolls',\n  'fac',\n  'and',\n  'please',\n  'don',\n  't',\n  'remove',\n  'the',\n  'template',\n  'from',\n  'the',\n  'talk',\n  'page',\n  'since',\n  'i',\n  'm',\n  'retired',\n  'now',\n  'yo',\n  'bitch',\n  'ja',\n  'rule',\n  'is',\n  'more',\n  'succesful',\n  'then',\n  'you',\n  'll',\n  'ever',\n  'be',\n  'whats',\n  'up',\n  'with',\n  'you',\n  'and',\n  'hating',\n  'you',\n  'sad',\n  'mo',\n  'fuck',\n  'as',\n  'i',\n  'should',\n  'bitch',\n  'slap',\n  'ur',\n  'pethedic',\n  'white',\n  'faces',\n  'and',\n  'get',\n  'you',\n  'to',\n  'kiss',\n  'my',\n  'ass',\n  'you',\n  'guys',\n  'sicken',\n  'me',\n  'ja',\n  'rule',\n  'is',\n  'about',\n  'pride',\n  'in',\n  'da',\n  'music',\n  'man',\n  'dont',\n  'diss',\n  'that',\n  'shit',\n  'on',\n  'him',\n  'and',\n  'nothin',\n  'is',\n  'wrong',\n  'bein',\n  'like',\n  'tupac',\n  'he',\n  'was',\n  'a',\n  'brother',\n  'too',\n  'fuck',\n  'in',\n  'white',\n  'boys',\n  'get',\n  'things',\n  'right',\n  'next',\n  'time'],\n ['thank',\n  'you',\n  'this',\n  'would',\n  'make',\n  'my',\n  'life',\n  'a',\n  'lot',\n  'less',\n  'anxiety',\n  'inducing',\n  'keep',\n  'it',\n  'up',\n  'and',\n  'don',\n  't',\n  'let',\n  'anyone',\n  'get',\n  'in',\n  'your',\n  'way',\n  'd',\n  'aww',\n  'he',\n  'matches',\n  'this',\n  'background',\n  'colour',\n  'i',\n  'm',\n  'seemingly',\n  'stuck',\n  'with',\n  'thanks',\n  'talk',\n  'january',\n  'utc',\n  'from',\n  'rfc',\n  'the',\n  'title',\n  'is',\n  'fine',\n  'as',\n  'it',\n  'is',\n  'imo'],\n ['this',\n  'is',\n  'such',\n  'an',\n  'urgent',\n  'design',\n  'problem',\n  'kudos',\n  'to',\n  'you',\n  'for',\n  'taking',\n  'it',\n  'on',\n  'very',\n  'impressive',\n  'hey',\n  'man',\n  'i',\n  'm',\n  'really',\n  'not',\n  'trying',\n  'to',\n  'edit',\n  'war',\n  'it',\n  's',\n  'just',\n  'that',\n  'this',\n  'guy',\n  'is',\n  'constantly',\n  'removing',\n  'relevant',\n  'information',\n  'and',\n  'talking',\n  'to',\n  'me',\n  'through',\n  'edits',\n  'instead',\n  'of',\n  'my',\n  'talk',\n  'page',\n  'he',\n  'seems',\n  'to',\n  'care',\n  'more',\n  'about',\n  'the',\n  'formatting',\n  'than',\n  'the',\n  'actual',\n  'info',\n  'sources',\n  'zawe',\n  'ashton',\n  'on',\n  'lapland']]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to be careful with the default parameters of gensim. We want a vector size of 300 dimensions, a min occurance count of 1 and a window size (for training) of 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ngensim_model = gensim.models.Word2Vec(all_text, size=300, min_count=1, iter=25, window=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gensim_model.wv.most_similar(\"khadr\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gensim_model.save('jigsaw_w2v_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}