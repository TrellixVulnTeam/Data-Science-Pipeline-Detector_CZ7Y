{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd;pd.set_option('display.max_column',300)\nimport numpy as np\nimport seaborn as sns\nimport pylab as plt\n%matplotlib inline\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nimport re\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dropout,Dense,Embedding,Flatten","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"MAX_FEATURE = 100000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['target']>=0.5,'target'] = 1\ntrain.loc[train['target']<0.5,'target'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_all = list(train['comment_text'])+list(test['comment_text'])\nfrom tqdm import tqdm\nlength_list = []\nword_all = []\nfor i in tqdm(list_all):\n    length_list.append(len(i))\n    for j in i.split():\n        word_all.append(j)\nset_all = set(word_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"a sentence has max words:\",max(length_list))\nprint(\"a sentence has min words:\",min(length_list))\nprint('a sentence has average words:',int(sum(length_list)/len(length_list)))\nprint('there are total',len(set_all),'unique words')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_1 = []\ntemp = ''\nfor k in set_all:\n    common = 'qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'\n    for l in common:\n        k = k.replace(l,'')\n    list_1.append(k)\n# set(list_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str_1 = ''\nfor i in list_1:\n    str_1+=i\nset_1 = set(str_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punct_1 = ''\nfor i in set_1:\n    punct_1+=i\npunct_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\"dom't\":\"do not\",\n                 \"didn't\": \"did not\", \"does'nt\": \"does not\",\"doesn't\": \"does not\", \"don't\": \"do not\",\n                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\"here's\":\"here is\",\n                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"that''s\":\"that is\",\"there's\": \"there is\",\n                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\"wasn't\":\"was not\",\n                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\"opp's\":\"opps\",\n                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\",\n                \"ican't\":\"I can not\",\"are't\":\"are not\",\"dind't\":\"did not\",\"whataboutism\":\"what about ism\",\n                \"ya'know\":\"you know\",\"havent't\":\"have not\",\"how'd\":\"how had\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_1(data):\n    '''\n    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n    '''\n    punct = punct_1.replace(\"'\",'')#首先去掉除了单引号的其他字符。单引号在执行完误拼后再去除。\n    def clean_special_chars(text, punct):\n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_misspell(misspell_dict):\n    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n    return misspell_dict, misspell_re\n\n\ndef replace_typical_misspell(text):\n    misspellings, misspellings_re = _get_misspell(misspell_dict)\n\n    def replace(match):\n        return misspellings[match.group(0)]\n\n    return misspellings_re.sub(replace, text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_numbers(x):\n    return re.sub('\\d+', ' ', x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lower\ntrain['comment_text'] = train['comment_text'].str.lower()\ntest['comment_text'] = test['comment_text'].str.lower()\n# clean numbers\nimport re\ntrain['comment_text'] = train['comment_text'].apply(clean_numbers)\ntest['comment_text'] = test['comment_text'].apply(clean_numbers)\n# clean the text\ntrain['comment_text'] = preprocess_1(train['comment_text'])\ntest['comment_text'] = preprocess_1(test['comment_text'])\n# clean misspellings\ntrain['comment_text'] = train['comment_text'].apply(replace_typical_misspell)\ntest['comment_text'] = test['comment_text'].apply(replace_typical_misspell)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_2(data):\n    '''\n    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n    '''\n    punct = \"'\"#首先去掉除了单引号的其他字符。单引号在执行完误拼后再去除。\n    def clean_special_chars(text, punct):\n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean the text again\ntrain['comment_text'] = preprocess_2(train['comment_text'])\ntest['comment_text'] = preprocess_2(test['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['comment_text'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train['comment_text']\nX_test = test['comment_text']\ny_train = train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=MAX_FEATURE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(list(X_train)+list(X_test))\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = sequence.pad_sequences(X_train,maxlen=220)\nX_test = sequence.pad_sequences(X_test,maxlen=220)\nX_train[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim=MAX_FEATURE,output_dim=300))\nmodel.add(LSTM(units=128,dropout=0.2))\nmodel.add(Dense(1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.fit(X_train,y_train,batch_size=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit = pd.read_csv('../input/sample_submission.csv')\ndf_submit.prediction = predictions\ndf_submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}