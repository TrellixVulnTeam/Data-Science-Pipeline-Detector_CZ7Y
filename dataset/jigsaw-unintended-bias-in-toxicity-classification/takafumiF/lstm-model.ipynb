{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport re\nfrom scipy.sparse import csr_matrix\nfrom keras.models import Sequential\nfrom keras.layers import CuDNNLSTM, Dense, Embedding, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def arrange_words(text):\n    text = text.replace('!', '')\n    text = text.replace('?', '')\n    text = text.replace(',', '')\n    text = text.replace('.', '')\n    text = text.replace('“', '')\n    text = text.replace('”', '')\n    text = text.replace('‘', '')\n    text = text.replace('’', '')\n    text = text.replace('•', '')\n    text = text.replace('・', '')\n    text = text.replace('…', '')\n    text = text.replace(':', '')\n    text = text.replace(';', '')\n    text = text.replace('(', '')\n    text = text.replace(')', '')\n    text = text.replace('{', '')\n    text = text.replace('}', '')\n    text = text.replace('[', '')\n    text = text.replace(']', '')\n    text = text.replace('<', '')\n    text = text.replace('>', '')\n    text = text.replace('\\'', '')\n    text = text.replace('\\/', '')\n    text = text.replace('\"', '')\n    text = text.replace('-', ' ')\n    text = text.replace('_', ' ')\n    text = text.replace('\\n', ' ')\n    text = text.replace('\\r', ' ')\n    text = text.replace('#', '')\n    text = re.sub(r'[0-9]+', \"0\", text)\n    text = ' ' + text + ' '\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtypes = {\n        'id':                                             'category',\n        'target':                                       'float16', \n        'comment_text':                           'category', \n        'severe_toxicity':                           'float16', \n        'obscene':                                    'float16', \n        'identity_attack':                           'float16', \n        'insult':                                         'float16', \n        'threat':                                        'float16', \n        'asian':                                         'float16', \n        'atheist':                                       'float16', \n        'bisexual':                                     'float16', \n        'black':                                         'float16', \n        'buddhist':                                    'float16', \n        'christian':                                    'float16', \n        'female':                                       'float16', \n        'heterosexual':                              'float16', \n        'hindu':                                         'float16', \n        'homosexual_gay_or_lesbian':        'float16', \n        'intellectual_or_learning_disability': 'float16', \n        'jewish':                                        'float16', \n        'latino':                                         'float16', \n        'male':                                          'float16', \n        'muslim':                                       'float16', \n        'other_disability':                           'float16', \n        'other_gender':                             'float16', \n        'other_race_or_ethnicity':              'float16', \n        'other_religion':                             'float16', \n        'other_sexual_orientation':             'float16', \n        'physical_disability':                       'float16', \n        'psychiatric_or_mental_illness':       'float16', \n        'transgender':                                'float16', \n        'white':                                          'float16', \n        'created_date':                              'category', \n        'publication_id':                             'category', \n        'parent_id':                                    'category', \n        'article_id':                                     'category', \n        'rating':                                         'category', \n        'funny':                                         'int8', \n        'wow':                                           'int8', \n        'sad':                                             'int8', \n        'likes':                                            'int8', \n        'disagree':                                     'int8', \n        'sexual_explicit':                             'float16', \n        'identity_annotator_count':             'int8', \n        'toxicity_annotator_count':             'int8', \n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', dtype=dtypes)\ntest  = pd.read_csv('../input/test.csv',  dtype=dtypes)\ntrain_ids = train.index\ntest_ids  = test.index\ntrain_y = train['target'].apply(lambda x: 1 if x>=0.5 else 0)\ntrain_X = train.drop('target', axis=1)\ntest_X = test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X['comment_text_arranged'] = train_X['comment_text'].map(arrange_words)\ntest_X['comment_text_arranged'] = test_X['comment_text'].map(arrange_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=100000)\ntokenizer.fit_on_texts(pd.concat([train_X['comment_text_arranged'], test_X['comment_text_arranged']]))\ntrain_X_tokenized = tokenizer.texts_to_sequences(train_X['comment_text_arranged'])\ntest_X_tokenized = tokenizer.texts_to_sequences(test_X['comment_text_arranged'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = np.array([len(sentence) for sentence in train_X_tokenized + test_X_tokenized]).max()\ntrain_X_padded = pad_sequences(train_X_tokenized, maxlen=max_len)\ntest_X_padded = pad_sequences(test_X_tokenized, maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result  = np.zeros(test_ids.shape[0])\nvocabulary_size = len(tokenizer.word_index) + 1\n\nX_fit = csr_matrix(train_X_padded, dtype='float32')\ny_fit = train_y\ngc.collect()\n\nmodel = Sequential()\n\nmodel.add(Embedding(input_dim=vocabulary_size, output_dim=64))\nmodel.add(CuDNNLSTM(512, return_sequences=False))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_fit, y_fit, epochs=2, batch_size=32)\n\n\n\ndel X_fit\ngc.collect()\n    \ntest = csr_matrix(test_X_padded, dtype='float32')\ntest_result += model.predict_proba(test)[:,0]\n\ndel test\ngc.collect()\n    \n\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['prediction'] = test_result\nsubmission.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}