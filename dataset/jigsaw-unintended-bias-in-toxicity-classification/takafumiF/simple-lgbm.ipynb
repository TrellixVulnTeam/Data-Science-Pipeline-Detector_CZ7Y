{"cells":[{"metadata":{},"cell_type":"markdown","source":"LightGBMを用いたシンプルなコードを作成しました。  \nインバランスドデータへの対処・モデルの訓練・バリデーションの部分は  \n下記のkernelの影響を大きく受けています。\n\nSimple code using LightGBM.  \nThe parts of dealing with inbalanced data, fiiting model and validation   \nare highly influenced by following kernel.    \n\n\n[LightGBM. Baseline Model Using Sparse Matrix](https://www.kaggle.com/bogorodvo/lightgbm-baseline-model-using-sparse-matrix)\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nimport lightgbm as lgb\nfrom scipy.sparse import vstack, hstack, csr_matrix, spmatrix\nfrom scipy.stats import binom\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import CountVectorizer as CV\nimport datetime\nimport gc\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#文字列中の記号を除去する関数\n#The function to remove noisy marks in text\ndef arrange_words(text):\n    text = text.replace('!', '')\n    text = text.replace('?', '')\n    text = text.replace(',', '')\n    text = text.replace('.', '')\n    text = text.replace('“', '')\n    text = text.replace('”', '')\n    text = text.replace('‘', '')\n    text = text.replace('’', '')\n    text = text.replace('•', '')\n    text = text.replace('・', '')\n    text = text.replace('…', '')\n    text = text.replace(':', '')\n    text = text.replace(';', '')\n    text = text.replace('(', '')\n    text = text.replace(')', '')\n    text = text.replace('{', '')\n    text = text.replace('}', '')\n    text = text.replace('[', '')\n    text = text.replace(']', '')\n    text = text.replace('<', '')\n    text = text.replace('>', '')\n    text = text.replace('\\'', '')\n    text = text.replace('\\/', '')\n    text = text.replace('\"', '')\n    text = text.replace('-', ' ')\n    text = text.replace('_', ' ')\n    text = text.replace('\\n', ' ')\n    text = text.replace('\\r', ' ')\n    text = text.replace('#', '')\n    text = re.sub(r'[0-9]+', \"0\", text)\n    text = ' ' + text + ' '\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Series全体に含まれる全ての単語とその個数を集計する関数\n#The function to count all words and the number of those through overall texts\ndef get_word_counts(texts):\n    word_counts = defaultdict(int)\n    for text in texts.values:\n        for word in text.split(' '):\n            word_counts[word.lower()] += 1\n    return word_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#二項分布を用いて有効な単語を抽出する関数\n#The function to select useful words based on probability of binomial distribution\ndef extract_useful_column(dataset, all_words, significance_level):\n    texts = dataset.copy()\n    useful_words = []\n    p = texts['target'].sum() / texts['comment_text_arranged'].count()\n    for word in all_words:\n        texts['comment_text_arranged'] = dataset['comment_text_arranged'].map(lambda x: 1 if ' ' + word + ' ' in x else 0)\n        k = texts[texts['comment_text_arranged']==1]['target'].sum()\n        N = texts[texts['comment_text_arranged']==1]['comment_text_arranged'].count()\n#        print(binom.cdf(k, N, p))\n#        if (binom.cdf(k, N, p)<(significance_level/2)) or (binom.cdf(k, N, p)>(1-significance_level/2)):\n        p_value = binom.cdf(k, N, p)\n        if (p_value<(significance_level/2)) or (p_value>(1-significance_level/2)):\n            print(word)\n            useful_words.append(word)\n    return useful_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#データ型を定義\n#Define data types\ndtypes = {\n        'id':                                             'category',\n        'target':                                       'float16', \n        'comment_text':                           'category', \n        'severe_toxicity':                           'float16', \n        'obscene':                                    'float16', \n        'identity_attack':                           'float16', \n        'insult':                                         'float16', \n        'threat':                                        'float16', \n        'asian':                                         'float16', \n        'atheist':                                       'float16', \n        'bisexual':                                     'float16', \n        'black':                                         'float16', \n        'buddhist':                                    'float16', \n        'christian':                                    'float16', \n        'female':                                       'float16', \n        'heterosexual':                              'float16', \n        'hindu':                                         'float16', \n        'homosexual_gay_or_lesbian':        'float16', \n        'intellectual_or_learning_disability': 'float16', \n        'jewish':                                        'float16', \n        'latino':                                         'float16', \n        'male':                                          'float16', \n        'muslim':                                       'float16', \n        'other_disability':                           'float16', \n        'other_gender':                             'float16', \n        'other_race_or_ethnicity':              'float16', \n        'other_religion':                             'float16', \n        'other_sexual_orientation':             'float16', \n        'physical_disability':                       'float16', \n        'psychiatric_or_mental_illness':       'float16', \n        'transgender':                                'float16', \n        'white':                                          'float16', \n        'created_date':                              'category', \n        'publication_id':                             'category', \n        'parent_id':                                    'category', \n        'article_id':                                     'category', \n        'rating':                                         'category', \n        'funny':                                         'int8', \n        'wow':                                           'int8', \n        'sad':                                             'int8', \n        'likes':                                            'int8', \n        'disagree':                                     'int8', \n        'sexual_explicit':                             'float16', \n        'identity_annotator_count':             'int8', \n        'toxicity_annotator_count':             'int8', \n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#訓練データ・テストデータをロード\n#Load DataSet\ntrain = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', dtype=dtypes)\ntest  = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv',  dtype=dtypes)\ntrain_ids = train.index\ntest_ids  = test.index\ntrain_y = train['target'].apply(lambda x: 1 if x>=0.5 else 0)\ntrain_X = train.drop('target', axis=1)\ntest_X = test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comment_textで使われている全ての単語の個数を取得\n#get the all words used in the column 'comment_text'\ntrain_X['comment_text_arranged'] = train_X['comment_text'].map(arrange_words)\ntest_X['comment_text_arranged'] = test_X['comment_text'].map(arrange_words)\ntrain_word_counts = get_word_counts(train_X['comment_text_arranged'])\ntest_word_counts = get_word_counts(test_X['comment_text_arranged'])\ntrain_word_counts_df = pd.DataFrame(list(train_word_counts.items()), columns=['word', 'count'])\ntest_word_counts_df = pd.DataFrame(list(test_word_counts.items()), columns=['word', 'count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#訓練データとテストデータ双方に存在する単語のみを抽出\n#extract just the words in both train data and test data\nword_counts_df = train_word_counts_df.merge(test_word_counts_df, on='word', how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#訓練データで極端に個数が少ない、又は訓練データ・テストデータで個数が極端に偏っている単語以外を抽出\n#drop the words extremely few or biased between train data and test data\nword_counts_df['scaled_total'] = word_counts_df['count_x'] + word_counts_df['count_y'] * 18\nword_counts_df = word_counts_df[word_counts_df['count_x']>100]\nword_counts_df = word_counts_df[(word_counts_df['count_x']/word_counts_df['scaled_total']>0.2) & (word_counts_df['count_x']/word_counts_df['scaled_total']<0.8)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#それぞれの単語を特徴量とするデータセットを作成\n#create dataset which has each words as features;\n\ncv = CV(vocabulary=word_counts_df['word'].tolist())\nprint(datetime.datetime.now())\ntrain_X_flattened = cv.fit_transform(list(train_X['comment_text_arranged'].values))\ntest_X_flattened = cv.fit_transform(list(test_X['comment_text_arranged'].values))\nprint(datetime.datetime.now())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LightGBMで訓練し、予測値を作成。バリデーションにはStratifiedKFoldを用いる。\n#train and predict using LightGBM. Validate using StratifiedKFold.\n\nlgb_test_result  = np.zeros(test_ids.shape[0])\nm = 100000\ncounter = 0\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nskf.get_n_splits(train_ids, np.array(train_y))\n\nfor train_index, test_index in skf.split(train_ids, train_y):\n    \n    print('Fold {}\\n'.format(counter + 1))\n    X_fit = train_X_flattened[train_index]\n    X_val = train_X_flattened[test_index]\n    X_fit, X_val = csr_matrix(X_fit, dtype='float32'), csr_matrix(X_val, dtype='float32')\n    y_fit, y_val = train_y[train_index], train_y[test_index]\n    \n    gc.collect()\n\n    lgb_model = lgb.LGBMClassifier(max_depth=-1,\n                                   n_estimators=1000,\n                                   learning_rate=0.05,\n                                   num_leaves=2**9-1,\n                                   colsample_bytree=0.28,\n                                   objective='binary', \n                                   n_jobs=-1)\n                                   \n    \n                               \n    lgb_model.fit(X_fit, y_fit, eval_metric='auc', \n                  eval_set=[(X_val, y_val)], \n                  verbose=100, early_stopping_rounds=100)\n                  \n    \n    del X_fit, X_val, y_fit, y_val, train_index, test_index\n    gc.collect()\n    \n    test = csr_matrix(test_X_flattened, dtype='float32')\n    lgb_test_result += lgb_model.predict_proba(test)[:,1]\n    counter += 1\n    \n    del test\n    gc.collect()\n    \n\nsubmission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')\nsubmission['prediction'] = lgb_test_result / counter\nsubmission.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}