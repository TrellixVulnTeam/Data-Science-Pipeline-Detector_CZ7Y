{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nfrom gensim import corpora, models\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.naive_bayes import MultinomialNB\nimport spacy\nfrom spacy import displacy\nfrom spacy.matcher import Matcher\nfrom spacy.tokens import Span\nimport en_core_web_lg\nfrom wordcloud import WordCloud\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/train.csv\", usecols=[0,1,2])\ndata.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target"},{"metadata":{},"cell_type":"markdown","source":"Inspect distribution of target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.target.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data.target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert continuous target variable to binary variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[:,\"target_binary\"] = np.where(data.target < 0.5, 0, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.target_binary.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide data into two dataframes: positive and negative\npositive = data[data.target_binary == 0]\npositive = positive.sample(100000)\n\nnegative = data[data.target_binary == 1]\nnegative = negative.sample(100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert content of positive comment_text column to one single string\npositive_string = \" \".join([word for word in positive.comment_text])\nprint(len(positive_string))\nprint(positive_string[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(max_font_size=50, background_color=\"white\").generate(positive_string)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert content of negative comment_text column to one single string\nnegative_string = \" \".join([word for word in negative.comment_text])\nprint(len(negative_string))\nprint(negative_string[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(max_font_size=50, background_color=\"white\").generate(negative_string)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = data.sample(1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use spaCy functionalities to preprocess the comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load spaCy's english large language model\nnlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am disabling the pipeline step \"NER\" in order to be able to set my own NER tags later. These are remaining steps names and classes, which the en_core_web_lg pipeline executes after configuration:"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp.pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"spaCy's Matcher class offers the opportunity to search for words, defined by attributes and rules:\n* Official docs: https://spacy.io/usage/rule-based-matching#matcher\n* Rule Explorer: https://explosion.ai/demos/matcher"},{"metadata":{},"cell_type":"markdown","source":"Set up Matcher class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate Matcher\nmatcher = Matcher(nlp.vocab)\n\n# define pattern\npattern = [{\"IS_ALPHA\": True,\n            \"IS_STOP\": False,\n            \"LENGTH\": {\">\": 1},\n            \"LENGTH\": {\"<=\": 20}\n           }]\n\n# add pattern to matcher\nmatcher.add(\"Cleaning\", None, pattern)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply matcher on comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize empty list for proccessed texts\ntexts = []\n\nfor idx, row in sample.iterrows():\n    # get nlp doc of comment text\n    doc = nlp(row.comment_text)\n    \n    # apply matcher on doc\n    matches = matcher(doc)\n    \n    # initialize empty list for matched tokens\n    token_matches = []\n    \n    for match_id, start, end in matches:\n        # add custom entitiy \"MATCH\" to doc.ents\n        doc.ents = list(doc.ents) + [Span(doc, start, end, label=\"MATCH\")]  \n    \n        # get lemma for matched tokens and write to data frame\n        token_matches.append(doc[start:end].lemma_.lower())\n        sample.loc[idx, \"comment_preprocessed\"] = \" \".join(token_matches)\n    \n    # append processed comment to list of texts\n    texts.append(token_matches)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use displaCy to inspect matched tokens"},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(doc, style=\"ent\", options={\"ents\": [\"MATCH\"]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample[[\"comment_text\", \"comment_preprocessed\"]].sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use gensim functionalities to vectorize the preprocessed comment text"},{"metadata":{},"cell_type":"markdown","source":"Convert list of comments to gensim dictionary "},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = corpora.Dictionary(texts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The dictionary consists of {} different tokens. In total, {} documents were processed.\".format(dictionary.num_pos, dictionary.num_docs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert dictionary to tfidf-weighted corpus and serialize corpus"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get bow representation for each text\ncorpus_bow = [dictionary.doc2bow(text) for text in texts]\n\n# serialize corpus\ncorpora.MmCorpus.serialize(\"corpus.mm\", corpus_bow)\n\n# get tfidf representation for each text\ncorpus_tfidf = models.TfidfModel(corpus_bow)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspect resulting tfidf corpus: list of tuples constisting of token id and tfidf weight."},{"metadata":{"trusted":true},"cell_type":"code","source":"#for document in corpus_tfidf[corpus_bow]:\n#    for token in document:\n#        print(token)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for token, id in dictionary.token2id.items():   \n    if id == 6007:\n        print(token)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning\nUse simple NaivesBayes to challenge different preprocessing techniques."},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate NB model\nclf = MultinomialNB()\n\n# fit classifier on data\nclf.fit(corpus_tfidf[corpus_bow], list(sample.target_binary.values))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}