{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport zipfile\nfrom zipfile import ZipFile\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport os\n\nimport numpy\nfrom keras.datasets import imdb\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM,Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping\nimport os\nprint(os.listdir(\"../input\"))","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsub = pd.read_csv('../input/sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"((1000, 45), (1000, 2))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words = 20000\nmax_len = 220\nemb_size = 256\nnum_model = 3","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer=Tokenizer(num_words=num_words)\ntokenizer.fit_on_texts(list(train['comment_text']) + list(test['comment_text']))\nY=np.where(train['target']>=0.5,1,0)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tokenizer.document_count)","execution_count":64,"outputs":[{"output_type":"stream","text":"2000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tokenizer.texts_to_sequences(list(train['comment_text']))\ntest_X = tokenizer.texts_to_sequences(list(test['comment_text']))","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = sequence.pad_sequences(X, maxlen = max_len)\ntest_X = sequence.pad_sequences(test_X, maxlen = max_len)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the model\nembedding_vecor_length = emb_size\nmodel = Sequential()\nmodel.add(Embedding(num_words, embedding_vecor_length, input_length=X.shape[1]))\nmodel.add(Dropout(0.25))\nmodel.add(LSTM(128))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","execution_count":79,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_10 (Embedding)     (None, 220, 256)          5120000   \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 220, 256)          0         \n_________________________________________________________________\nlstm_10 (LSTM)               (None, 128)               197120    \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 1)                 129       \n=================================================================\nTotal params: 5,317,249\nTrainable params: 5,317,249\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"score=[]\npredictions=[]\nfor i in range(num_model):\n    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20)\n    es = EarlyStopping(monitor='val_loss', patience=100)\n    model.fit(X_train,Y_train, validation_data=(X_test, Y_test), epochs=3, batch_size=1024,callbacks=[es])\n    pred = model.predict(test_X)\n    scores = model.evaluate(test_X, pred, verbose=0)\n    score.append(scores)\n    predictions.append(pred)\n    print(i)","execution_count":80,"outputs":[{"output_type":"stream","text":"Train on 800 samples, validate on 200 samples\nEpoch 1/3\n800/800 [==============================] - 3s 4ms/step - loss: 0.6897 - acc: 0.6313 - val_loss: 0.6754 - val_acc: 0.9200\nEpoch 2/3\n800/800 [==============================] - 1s 758us/step - loss: 0.6728 - acc: 0.9350 - val_loss: 0.6587 - val_acc: 0.9200\nEpoch 3/3\n800/800 [==============================] - 1s 747us/step - loss: 0.6525 - acc: 0.9450 - val_loss: 0.6372 - val_acc: 0.9200\n0\nTrain on 800 samples, validate on 200 samples\nEpoch 1/3\n800/800 [==============================] - 1s 750us/step - loss: 0.6282 - acc: 0.9388 - val_loss: 0.5961 - val_acc: 0.9450\nEpoch 2/3\n800/800 [==============================] - 1s 747us/step - loss: 0.5945 - acc: 0.9388 - val_loss: 0.5474 - val_acc: 0.9450\nEpoch 3/3\n800/800 [==============================] - 1s 760us/step - loss: 0.5446 - acc: 0.9388 - val_loss: 0.4730 - val_acc: 0.9450\n1\nTrain on 800 samples, validate on 200 samples\nEpoch 1/3\n800/800 [==============================] - 1s 755us/step - loss: 0.4741 - acc: 0.9438 - val_loss: 0.3597 - val_acc: 0.9250\nEpoch 2/3\n800/800 [==============================] - 1s 751us/step - loss: 0.3659 - acc: 0.9438 - val_loss: 0.2583 - val_acc: 0.9250\nEpoch 3/3\n800/800 [==============================] - 1s 756us/step - loss: 0.2476 - acc: 0.9438 - val_loss: 0.2752 - val_acc: 0.9250\n2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=pd.DataFrame(score)\nscore[0].mean()","execution_count":81,"outputs":[{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"0.4936319772402445"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fina_pred=np.average(predictions,axis=0)\nfina_pred=pd.DataFrame(fina_pred)","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids=test['id']\nids=pd.DataFrame(ids)","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.concat([ids,fina_pred],axis=1)\nsubmission['prediction']=submission.iloc[:,1:]\nsubmission=submission.drop([0],axis=1)\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":84,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}