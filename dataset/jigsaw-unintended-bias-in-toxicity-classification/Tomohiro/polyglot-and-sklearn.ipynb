{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip\n!apt-get install -y libicu-dev\n!pip install polyglot\n!pip install pyicu\n!pip install pycld2\n!pip install morfessor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!polyglot download embeddings2.en pos2.en\n!polyglot download ner2.en\n!polyglot download sentiment2.en","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport matplotlib as plt\nfrom polyglot.text import Text, Word\nfrom polyglot.detect import Detector\nfrom polyglot.downloader import downloader\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\n\n# Any results you write to the current directory are saved as out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_class = ['VERB', 'DET', 'NOUN', 'PRON', 'PUNCT', 'ADP', 'ADV', 'ADJ']\nword_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_index_col = []\nordinal_num_max = 3\n\nfor class_name in word_class:\n    i = 0\n    for i in range(ordinal_num_max):\n        class_index_col.append(class_name + \"_\" + \"INX\" + str(i))\n\nclass_index_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_count_col = []\n\nfor class_name in word_class:\n    class_count_col.append(class_name + \"_\" + \"CNT\")\n\nclass_count_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_percent_col = []\n\nfor class_name in word_class:\n    class_percent_col.append(class_name + \"_\" + \"PER\")\n\nclass_percent_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"posi_index_col = []\n\ni = 0\nfor i in range(ordinal_num_max):\n    posi_index_col.append(\"POSI_INX\" +  str(i))\n\nposi_index_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nega_index_col = []\n\ni = 0\nfor i in range(ordinal_num_max):\n    nega_index_col.append(\"NEGA_INX\" +  str(i))\n\nnega_index_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_data_read(columns_data, skiprows, nrows):\n    data = pd.read_csv(\"../input/train.csv\",\n                   names = columns_data,\n                   skiprows = skiprows,\n                   nrows = nrows\n                  )\n    return data\n\ndef index_cal(index_list, th_number):\n    if ((th_number) < (len(index_list))):\n        return index_list[th_number]\n    else:\n        return 101\n\ndef flat_reshape(input_list):\n    i = 0\n    work_area = input_list\n    output_list = []\n    for i in range(len(input_list)):\n        output_list.append(work_area[i].flatten())\n    \n    return output_list","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/train.csv\",\n               nrows = 10000\n              )    \n\ny_target = np.array(data[\"target\"],dtype = \"float16\")\n\ntext = data.comment_text\ntext = text.values\n\ni = 0\nj = 0\nwords = 0\ntags = 0\n\nclass_index_all = []\nposi_index_all = []\nnega_index_all = []\n\nclass_count_all = []\nposi_count_all = []\nnega_count_all = []\n\ntext_length = []\n\nfor i in range(len(text)):\n    try:\n        twords    = Text(text[i])  #comment_data\n        words     = twords.words   #comment divided into words\n        tag_words =  (np.array(twords.pos_tags).T[0])  #tags of tagged words\n        tags      =  (np.array(twords.pos_tags).T[1])  #words of tagged words\n\n        posi_index_0 = []\n        nega_index_0 = []\n        posi_index_1 = []\n        nega_index_1 = []\n        class_order_0 = []\n        class_count_0 = []\n        posi_count_0 = 0\n        nega_count_0 = 0\n        check_count_0 = 0\n\n\n        for i,w in enumerate(words):\n            if w.polarity == 1:\n                posi_count_0 += 1\n                posi_index_0.append(i)\n            if w.polarity == -1:\n                nega_count_0 += 1\n                nega_index_0.append(i)\n\n        j = 0\n        for j in range(ordinal_num_max):\n            posi_work = index_cal(posi_index_0,j)\n            nega_work = index_cal(nega_index_0,j)\n\n            posi_index_1.append(posi_work)\n            nega_index_1.append(nega_work)\n\n        k = 0\n        for w in word_class:\n            word_work = np.where(tags == w)[0]\n            class_order_1 = []\n            class_count_0.append(len(word_work))\n\n            for k in range(ordinal_num_max):\n                word_index = index_cal(word_work,k)\n                class_order_1.append(word_index)\n            class_order_0.append(class_order_1)\n\n        posi_count_all.append(posi_count_0)\n        nega_count_all.append(nega_count_0)\n        posi_index_all.append(posi_index_1)\n        nega_index_all.append(nega_index_1)\n\n        class_count_all.append(np.array(class_count_0))\n        class_index_all.append(np.array(class_order_0))\n        text_length.append(len(words))\n\n    except: \n        posi_index_0 = []\n        nega_index_0 = []\n        posi_index_1 = []\n        nega_index_1 = []\n        class_order_0 = []\n        class_count_0 = []\n        posi_count_0 = 0\n        nega_count_0 = 0\n        check_count_0 = 0\n\n\n        for j in range(ordinal_num_max):\n            posi_work = index_cal(posi_index_0,j)\n            nega_work = index_cal(nega_index_0,j)\n\n            posi_index_1.append(posi_work)\n            nega_index_1.append(nega_work)\n\n        for w in word_class:\n            class_order_1 = []\n            class_count_0.append(0)\n            for k in range(ordinal_num_max):\n                word_index = 100\n                class_order_1.append(word_index)\n            class_order_0.append(class_order_1)\n\n        posi_count_all.append(0)\n        nega_count_all.append(0)\n        posi_index_all.append(posi_index_1)\n        nega_index_all.append(nega_index_1)\n\n        class_count_all.append(np.array(class_count_0))\n        class_index_all.append(np.array(class_order_0))\n        text_length.append(0) \n\n\n\nl = 0\nclass_index_all_work = class_index_all\nclass_index_all = []\nfor i in range(len(class_index_all_work)):\n    class_index_all.append(class_index_all_work[i].flatten())\n\nflat_reshape(class_index_all)\n\ntext_length_wide = []\nl = 0\nfor i in range(len(np.array(class_count_all).T)):\n    text_length_wide.append (text_length)\ntext_length_wide\n\nclass_per_all = []\nl = 0\nfor i in range(len(class_count_all)):\n    class_per_all.append(np.array(class_count_all[i], dtype = \"int16\") * 1000 / (np.array(text_length_wide,  dtype = \"int16\").T))\n\nclass_per_all = class_per_all[0]\n\n\nposi_per_all = np.array(posi_count_all, dtype = \"int16\") * 1000 / (np.array(text_length,  dtype = \"int16\"))\nnega_per_all = np.array(nega_count_all, dtype = \"int16\") * 1000 / (np.array(text_length,  dtype = \"int16\"))\n\n\ntarget_data = pd.DataFrame(y_target,columns = [\"target\"])\nanalyze = pd.DataFrame(class_index_all,columns = class_index_col)\n\nfor i,w in enumerate(posi_index_col):\n    analyze[w] = np.array(posi_index_all).T[i]\n\nfor i,w in enumerate(nega_index_col):\n    analyze[w] = np.array(nega_index_all).T[i]\n\nfor i,w in enumerate(class_count_col):\n    analyze[w] = np.array(class_count_all).T[i]\n\nanalyze[\"posi_count\"] = posi_count_all\nanalyze[\"nega_count\"] = nega_count_all  \n\n#for i,w in enumerate(class_percent_col):\n#    analyze[w] = np.array(class_per_all).T[i]\n\n#analyze[\"posi_percent\"] = posi_per_all\n#analyze[\"nega_percent\"] = nega_per_all\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analyze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np_analyze = analyze.values\nnp_analyze = np_analyze.astype(np.int16)\nnp_analyze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np_target = target_data.values\nnp_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features = PolynomialFeatures(degree=2, include_bias = False)\nX_poly = poly_features.fit_transform(np_analyze)\nX_poly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg = LinearRegression()\nlin_reg.fit(X_poly,y_target)\nlin_reg.intercept_, lin_reg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predict = lin_reg.predict(X_poly)\ntrain_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\",\n               nrows = 100\n              )    \n\ntext = test.comment_text\ntext = text.values\n\ni = 0\nj = 0\nwords = 0\ntags = 0\n\nclass_index_all = []\nposi_index_all = []\nnega_index_all = []\n\nclass_count_all = []\nposi_count_all = []\nnega_count_all = []\n\ntext_length = []\n\nfor i in range(len(text)):\n    try:\n        twords    = Text(text[i])  #comment_data\n        words     = twords.words   #comment divided into words\n        tag_words =  (np.array(twords.pos_tags).T[0])  #tags of tagged words\n        tags      =  (np.array(twords.pos_tags).T[1])  #words of tagged words\n\n        posi_index_0 = []\n        nega_index_0 = []\n        posi_index_1 = []\n        nega_index_1 = []\n        class_order_0 = []\n        class_count_0 = []\n        posi_count_0 = 0\n        nega_count_0 = 0\n        check_count_0 = 0\n\n\n        for i,w in enumerate(words):\n            if w.polarity == 1:\n                posi_count_0 += 1\n                posi_index_0.append(i)\n            if w.polarity == -1:\n                nega_count_0 += 1\n                nega_index_0.append(i)\n\n        j = 0\n        for j in range(ordinal_num_max):\n            posi_work = index_cal(posi_index_0,j)\n            nega_work = index_cal(nega_index_0,j)\n\n            posi_index_1.append(posi_work)\n            nega_index_1.append(nega_work)\n\n        k = 0\n        for w in word_class:\n            word_work = np.where(tags == w)[0]\n            class_order_1 = []\n            class_count_0.append(len(word_work))\n\n            for k in range(ordinal_num_max):\n                word_index = index_cal(word_work,k)\n                class_order_1.append(word_index)\n            class_order_0.append(class_order_1)\n\n        posi_count_all.append(posi_count_0)\n        nega_count_all.append(nega_count_0)\n        posi_index_all.append(posi_index_1)\n        nega_index_all.append(nega_index_1)\n\n        class_count_all.append(np.array(class_count_0))\n        class_index_all.append(np.array(class_order_0))\n        text_length.append(len(words))\n\n    except: \n        posi_index_0 = []\n        nega_index_0 = []\n        posi_index_1 = []\n        nega_index_1 = []\n        class_order_0 = []\n        class_count_0 = []\n        posi_count_0 = 0\n        nega_count_0 = 0\n        check_count_0 = 0\n\n\n        for j in range(ordinal_num_max):\n            posi_work = index_cal(posi_index_0,j)\n            nega_work = index_cal(nega_index_0,j)\n\n            posi_index_1.append(posi_work)\n            nega_index_1.append(nega_work)\n\n        for w in word_class:\n            class_order_1 = []\n            class_count_0.append(0)\n            for k in range(ordinal_num_max):\n                word_index = 100\n                class_order_1.append(word_index)\n            class_order_0.append(class_order_1)\n\n        posi_count_all.append(0)\n        nega_count_all.append(0)\n        posi_index_all.append(posi_index_1)\n        nega_index_all.append(nega_index_1)\n\n        class_count_all.append(np.array(class_count_0))\n        class_index_all.append(np.array(class_order_0))\n        text_length.append(0) \n\n\n\nl = 0\nclass_index_all_work = class_index_all\nclass_index_all = []\nfor i in range(len(class_index_all_work)):\n    class_index_all.append(class_index_all_work[i].flatten())\n\nflat_reshape(class_index_all)\n\ntext_length_wide = []\nl = 0\nfor i in range(len(np.array(class_count_all).T)):\n    text_length_wide.append (text_length)\ntext_length_wide\n\nclass_per_all = []\nl = 0\nfor i in range(len(class_count_all)):\n    class_per_all.append(np.array(class_count_all[i], dtype = \"int16\") * 1000 / (np.array(text_length_wide,  dtype = \"int16\").T))\n\nclass_per_all = class_per_all[0]\n\n\nposi_per_all = np.array(posi_count_all, dtype = \"int16\") * 1000 / (np.array(text_length,  dtype = \"int16\"))\nnega_per_all = np.array(nega_count_all, dtype = \"int16\") * 1000 / (np.array(text_length,  dtype = \"int16\"))\n\n\ntarget_data = pd.DataFrame(y_target,columns = [\"target\"])\ntest_analyze = pd.DataFrame(class_index_all,columns = class_index_col)\n\nfor i,w in enumerate(posi_index_col):\n    test_analyze[w] = np.array(posi_index_all).T[i]\n\nfor i,w in enumerate(nega_index_col):\n    test_analyze[w] = np.array(nega_index_all).T[i]\n\nfor i,w in enumerate(class_count_col):\n    test_analyze[w] = np.array(class_count_all).T[i]\n\ntest_analyze[\"posi_count\"] = posi_count_all\ntest_analyze[\"nega_count\"] = nega_count_all  \n\n#for i,w in enumerate(class_percent_col):\n#    test_analyze[w] = np.array(class_per_all).T[i]\n\n#test_analyze[\"posi_percent\"] = posi_per_all\n#test_analyze[\"nega_percent\"] = nega_per_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_analyze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np_test_analyze = test_analyze.values\nnp_test_analyze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features = PolynomialFeatures(degree=2, include_bias = False)\nX_poly = poly_features.fit_transform(np_test_analyze)\nX_poly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = lin_reg.predict(X_poly)\ntest_predict","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}