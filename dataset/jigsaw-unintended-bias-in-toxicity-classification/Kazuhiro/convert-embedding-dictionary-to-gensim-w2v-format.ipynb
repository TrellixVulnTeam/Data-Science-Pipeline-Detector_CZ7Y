{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel converts a Python dict of word embedding vectors into gensim's word2vec binary format. \n\nThis leads to faster loading and you can do pretty stuffs with gensim.\n\nSource:\n[scikit learn \\- Convert Python dictionary to Word2Vec object \\- Stack Overflow](https://stackoverflow.com/questions/45981305/convert-python-dictionary-to-word2vec-object)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load embedding in a usual way"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr[:-1], dtype='float32')\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.split(' ')) for line in f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncrawl_emb_dict = load_embeddings(CRAWL_EMBEDDING_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(crawl_emb_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crawl_emb_dict['kaggle'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crawl_emb_dict['kaggle']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save it in gensim w2v binary format"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_word2vec_format(fname, vocab, vector_size, binary=True):\n    \"\"\"Store the input-hidden weight matrix in the same format used by the original\n    C word2vec-tool, for compatibility.\n\n    Parameters\n    ----------\n    fname : str\n        The file path used to save the vectors in.\n    vocab : dict\n        The vocabulary of words.\n    vector_size : int\n        The number of dimensions of word vectors.\n    binary : bool, optional\n        If True, the data wil be saved in binary word2vec format, else it will be saved in plain text.\n\n\n    \"\"\"\n    \n    total_vec = len(vocab)\n    with gensim.utils.smart_open(fname, 'wb') as fout:\n        print(total_vec, vector_size)\n        fout.write(gensim.utils.to_utf8(\"%s %s\\n\" % (total_vec, vector_size)))\n        # store in sorted order: most frequent words at the top\n        for word, row in tqdm(vocab.items()):\n            if binary:\n                row = row.astype(np.float32)\n                fout.write(gensim.utils.to_utf8(word) + b\" \" + row.tostring())\n            else:\n                fout.write(gensim.utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val) for val in row))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('dummy_text_to_prevent_kernel_page_loding_from_being_heavy.txt', 'w') as f:\n    f.write(':3')\n    ","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsave_word2vec_format(binary=True, fname='crawl-300d-2M.bin', vocab=crawl_emb_dict, vector_size=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('dummy_text_to_prevent_kernel_page_loding_from_being_heavy2.txt', 'w') as f:\n    f.write(':9')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load it again"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = gensim.models.KeyedVectors.load_word2vec_format('crawl-300d-2M.bin', binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model['kaggle']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel.most_similar('kaggle')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}