{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/fastai-sigsaw-1-epoch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\n# Installing Nvidia Apex\n! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\npackage_dir_a = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\nsys.path.insert(0, package_dir_a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# library\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport numpy as np\nimport pandas as pd\n\nfrom typing import *\nfrom pathlib import Path\n\nimport torch\nimport torch.optim as optim\n\nfrom fastai import *\nfrom fastai.text import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ntqdm.pandas(desc=\"my bar!\")\nimport torch.utils.data\nfrom sklearn import metrics\nfrom scipy.stats import rankdata\nfrom tqdm import tqdm_notebook as tqdm\nfrom nltk.tokenize.treebank import TreebankWordTokenizer\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam, BertConfig, convert_tf_checkpoint_to_pytorch\n\nimport re\nimport psutil\nimport multiprocessing as mp\nfrom multiprocessing import Pool\n\nfrom gensim.models import KeyedVectors\n\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Translate model from tensorflow to pytorch\nBERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\nWORK_DIR = '../working/'\nconvert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(BERT_MODEL_PATH + 'bert_model.ckpt',\n                                                                  BERT_MODEL_PATH + 'bert_config.json',\n                                                                  WORK_DIR + 'pytorch_model.bin')\n\nshutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(action='once')\ndevice = torch.device('cuda')\nMAX_SEQUENCE_LENGTH = 220\nSEED = 620402\nBATCH_SIZE = 16\nBERT_MODEL_BIN = '../working'\nbert_config = BertConfig(BERT_MODEL_PATH + 'bert_config.json')\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the tokenizer\nbert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None, do_lower_case=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FastAiBertTokenizer(BaseTokenizer):\n    \"\"\"Wrapper around a BertTokenizer to be a BaseTokenizer in fastai\"\"\"\n    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=300, **kwargs):\n        self._pretrained_tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n\n    def __call__(self, *args, **kwargs):\n        return self\n\n    def tokenizer(self, t:str) -> List[str]:\n        \"\"\"Limits the maximum sequence length\"\"\"\n        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenizer fo fastai\nfastai_tokenizer = Tokenizer(\n    tok_func = FastAiBertTokenizer(bert_tokenizer, max_seq_len = MAX_SEQUENCE_LENGTH), \n    pre_rules=[], \n    post_rules=[]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set vocabulary\nfastai_bert_vocab = Vocab(list(bert_tokenizer.vocab.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# load the train and test dataset\ntrain_origin = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")\ntest_df = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_test = len(test_df)\nlen_train_origin = len(train_origin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_test, len_train_origin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_origin['target']=(train_origin['target']>=0.5).astype(int)\ntrain_orgin_0 = train_origin[train_origin['target'] == 0]\ntrain_orgin_1 = train_origin[train_origin['target'] > 0]\nlen_orgin_0 = len(train_orgin_0)\nlen_orgin_1 = len(train_orgin_1)\nn_div_01 = len_orgin_0 // len_orgin_1\nlen_orgin_0, len_orgin_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_0 = train_orgin_0.sample(len_test*10, replace=True)\ntrain_df_1 = train_orgin_1.sample(len_test*10, replace=True)\ntrain_df = pd.concat([train_df_0, train_df_1]).reset_index(drop=True)\ntrain_df['target']=(train_df['target']>=0.5).astype(int)\nlen(train_df), train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sum(train_df):\n    sum_1 = train_df[train_df['target'] == 1].shape\n    sum_0 = train_df[train_df['target'] == 0].shape\n    print(sum_0, sum_1)\nget_sum(train_df)\nget_sum(train_df_0)\nget_sum(train_df_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(data):\n    '''\n    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n    '''\n    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n    def clean_special_chars(text, punct):\n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# preprocess\ntrain_df['comment_text'] = preprocess(train_df['comment_text']).astype(str) \ntest_df['comment_text'] = preprocess(test_df['comment_text']).astype(str) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_test_split(train_df)\ntest = test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, val.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(set(train_df['target']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df, test_df, train_origin\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertTokenizeProcessor(TokenizeProcessor):\n    def __init__(self, tokenizer):\n        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n\nclass BertNumericalizeProcessor(NumericalizeProcessor):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, vocab=Vocab(list(bert_tokenizer.vocab.keys())), **kwargs)\n\ndef get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n    \"\"\"\n    Constructing preprocessors for BERT\n    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n    We also use a custom vocabulary to match the numericalization with the original BERT model.\n    \"\"\"\n    return [BertTokenizeProcessor(tokenizer=tokenizer),\n            NumericalizeProcessor(vocab=vocab)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertDataBunch(TextDataBunch):\n    @classmethod\n    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n        \"Create a `TextDataBunch` from DataFrames.\"\n        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n        # use our custom processors while taking tokenizer and vocab as kwargs\n        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n        return src.databunch(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this will produce a virtually identical databunch to the code above\ndatabunch = BertDataBunch.from_df(\"../input/jigsaw-unintended-bias-in-toxicity-classification\", train, val, test,\n                  tokenizer=fastai_tokenizer,\n                  vocab=fastai_bert_vocab,\n                  text_cols=\"comment_text\",\n                  label_cols='target',\n                  bs=BATCH_SIZE,\n                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_model = BertForSequenceClassification.from_pretrained(BERT_MODEL_BIN, num_labels=2)\nloss_func = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(databunch,\n           bert_model,\n           loss_func=loss_func,\n           metrics=[accuracy],\n           model_dir='/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/fastai-sigsaw-1-epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/fastai-sigsaw-1-epoch/train_epoch_8.pth /kaggle/working/train_epoch_8.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.path = '../input/fastai-sigsaw-1-epoch'\nlearn.load('train_epoch_8')\n# learn.path = '/kaggle/working'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = learn.to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 1e-6, moms=[0.8, 0.7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('train_epoch_9')\nlearn.path = Path('.')\nlearn.export('./train_epoch_9.pkl')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}