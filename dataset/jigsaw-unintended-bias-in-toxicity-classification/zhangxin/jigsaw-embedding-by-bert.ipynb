{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Get Embedding\n\nIn this script, I use some models to generate embedding for ‘Jigsaw Unintended Bias in Toxicity Classification‘ task.\n\n- BERT-uncased-1024\n\nThe embedding data will be used for train a model to classify the toxicity comment."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pytorch-pretrained-bert","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install spacy ftfy==4.4.3\n!python -m spacy download en","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below code is modified from [the html page](https://www.ctolib.com/huggingface-pytorch-pretrained-BERT.html)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook, tqdm\ntqdm.pandas('my bar!')\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n\n# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load pre-trained model tokenizer (vocabulary)\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n\n# Tokenized input\ntext = \"[CLS] Who was Jim Henson ? Jim Henson was a puppeteer [SEP]\"\ntokenized_text = tokenizer.tokenize(text)\n\n# Convert token to vocabulary indices\nindexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n# Define sentence\nsegments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n# Convert inputs to PyTorch tensors\ntokens_tensor = torch.tensor([indexed_tokens])\nsegments_tensors = torch.tensor([segments_ids])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load pre-trained model (weights)\nmodel = BertModel.from_pretrained('bert-large-uncased')\nmodel.eval()\n\n# If you have a GPU, put everything on cuda\ntokens_tensor = tokens_tensor.to('cuda')\nsegments_tensors = segments_tensors.to('cuda')\nmodel.to('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict hidden states features for each layer\nwith torch.no_grad():\n    _, embedding_data = model(tokens_tensor, segments_tensors, output_all_encoded_layers=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_data.cpu().numpy()[0][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQ_LENGTH = 220","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_lines(example, max_seq_length, tokenizer):\n    max_seq_length -=2\n    all_tokens = []\n    longer = 0\n    for text in tqdm_notebook(example):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>max_seq_length:\n            tokens_a = tokens_a[:max_seq_length]\n            longer += 1\n        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n        all_tokens.append(one_token)\n        # for testing the aactivity of the program\n#         if longer > 3:\n#             break\n    print(longer)\n    return np.array(all_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized_text = convert_lines(train_df['comment_text'].values, MAX_SEQ_LENGTH, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized_text.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_BERT_embedding(model, sentence_index):\n    # If you have a GPU, put everything on cuda\n    tokens_tensor = torch.tensor([sentence_index])\n    tokens_tensor = tokens_tensor.to('cuda')\n    model.to('cuda')\n    # Predict hidden states features for each layer\n    with torch.no_grad():\n        _, embedding_data = model(tokens_tensor, output_all_encoded_layers=False)\n    return embedding_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_BERT_embeddings(model, sentence_indexes):\n    embeddings = []\n    for i in tqdm_notebook(range(len(sentence_indexes))):        \n        embeddings.append(get_BERT_embedding(model, sentence_indexes[i])[0].cpu().numpy())\n    return embeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = get_BERT_embeddings(model, tokenized_text)\nembeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'embedding' : embeddings})\nsub.to_csv('embedding', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}