{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set up matplotlib style \nplt.style.use('ggplot')\n\n# And libraries for data transformation\nfrom string import punctuation\nfrom nltk.tokenize import word_tokenize \nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.target = train.target.apply(lambda x: 1 if x>0.45 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sub = train.drop(['id','comment_text'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\n\nmatrix = train_sub.corr()\nsns.heatmap(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english')) \n\ntrain['comment_text'] = train.comment_text.apply(lambda x: x.lower())\n\ntrain['cleaned_comment'] = train.comment_text.apply(lambda x: word_tokenize(x))\n\ntrain['cleaned_comment'] = train.cleaned_comment.apply(lambda x: [w for w in x if w not in stop_words])\n\ntrain['cleaned_comment'] = train.cleaned_comment.apply(lambda x: ' '.join(x))\n\ntrain.drop('comment_text',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\ny = train.target\n\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.33,random_state=53)\n\n# Initialize a CountVectorizer object: count_vectorizer\ncount_vectorizer = CountVectorizer(stop_words=\"english\")\n\n# Transform the training data using only the 'text' column values: count_train \ncount_train = count_vectorizer.fit_transform(X_train[\"cleaned_comment\"])\n\ny_train = np.asarray(y_train.values)\n\n# Pick up the most effective words\nch2 = SelectKBest(chi2, k = 300)\n\nX_new = ch2.fit_transform(count_train, y_train)\n\n# Transform the test data using only the 'text' column values: count_test \ncount_test = count_vectorizer.transform(X_test[\"cleaned_comment\"])\n\nX_test_new = ch2.transform(X=count_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\n# Fit the classifier to the training data\nclf.fit(X_new, y_train)\n\n# Create the predicted tags: pred\npred = clf.predict(X_test_new)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(metrics.confusion_matrix(pred,y_test),annot=True,fmt='2.0f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import compress\n\nfeatures = count_vectorizer.get_feature_names()\nmask = ch2.get_support()\nfeatures = list(compress(features, mask))\nimportances = clf.feature_importances_\nindices = np.argsort(importances)\n\nsns.set(rc={'figure.figsize':(11,50)})\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nX_test_new = X_test_new.toarray()\n\nperm = PermutationImportance(clf, random_state=1).fit(X_test_new, y_test)\neli5.show_weights(perm, feature_names = features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = count_vectorizer.get_feature_names()\nmask = ch2.get_support()\nfeatures = list(compress(features, mask))\n\ntrain_df = pd.DataFrame(X_new.todense(), columns=features)\n\ntest_df = pd.DataFrame(X_test_new.todense(), columns=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_df.join(X_train.drop(['target','cleaned_comment','created_date','publication_id','parent_id', 'article_id,rating'],axis=1))\n\ntest_data = test_df.join(X_test.drop(['target','cleaned_comment','created_date','publication_id','parent_id', 'article_id,rating'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier()\n# Fit the classifier to the training data\nclf.fit(train_data, y_train)\n\n# Create the predicted tags: pred\npred = clf.predict(test_data)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['comment_text'] = test.comment_text.apply(lambda x: x.lower())\n\ntest['cleaned_comment'] = test.comment_text.apply(lambda x: word_tokenize(x))\n\ntest['cleaned_comment'] = test.cleaned_comment.apply(lambda x: [w for w in x if w not in stop_words])\n\ntest['cleaned_comment'] = test.cleaned_comment.apply(lambda x: ' '.join(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test['cleaned_comment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_train = count_vectorizer.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_test = count_vectorizer.transform(test)\n\ntest = ch2.transform(count_test)\n\nprediction = clf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\n\nsubmission['prediction'] = prediction\n\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}