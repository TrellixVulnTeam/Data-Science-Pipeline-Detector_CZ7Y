{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About spaCY\n\nspaCy is **a free, open-source library** for **advanced Natural Language Processing (NLP)** in Python.\n\nIf you’re working with a lot of text, you’ll eventually want to know more about it. For example, \n- what’s it about? <br>\n- What do the words mean in context? <br>\n- Who is doing what to whom? <br>\n- What companies and products are mentioned? Which texts are similar to each other? <br>\n\nspaCy is designed specifically for production use and helps you build applications that process and “understand” large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.\n\n# What spaCy isn’t\n\n**spaCy is not a platform** or **“an API”**. Unlike a platform, spaCy does not provide a software as a service, or a web application. It’s an open-source library designed to help you build NLP applications, not a consumable service.\n\n**spaCy is not an out-of-the-box chat bot engine**. While spaCy can be used to power conversational applications, it’s not designed specifically for chat bots, and only provides the underlying text processing capabilities.\n\n**spaCy is not research software**. It’s built on the latest research, but it’s designed to get things done. This leads to fairly different design decisions than NLTK or CoreNLP, which were created as platforms for teaching and research. The main difference is that spaCy is integrated and opinionated. spaCy tries to avoid asking the user to choose between multiple algorithms that deliver equivalent functionality. Keeping the menu small lets spaCy deliver generally better performance and developer experience.\n\n**spaCy is not a company**. It’s an open-source library. Our company publishing spaCy and other software is called Explosion AI.\n[Reference: Spacy.io](https://spacy.io/usage/spacy-101)"},{"metadata":{},"cell_type":"markdown","source":"# spaCY Library Architecture\nThe central data structures in spaCy are the **Doc** and the Vocab. The **Doc** object owns the sequence of tokens and all their annotations. The Vocab object owns a set of look-up tables that make common information available across documents. By centralizing strings, word vectors and lexical attributes, we avoid storing multiple copies of this data. This saves memory, and ensures there’s a single source of truth.\n\nText annotations are also designed to allow a single source of truth: the **Doc** object owns the data, and Span and Token are views that point into it. The Doc object is constructed by the Tokenizer, and then modified in place by the components of the pipeline. The Language object coordinates these components. It takes raw text and sends it through the pipeline, returning an annotated document. It also orchestrates training and serialization.\n\n![architecture](https://i.ibb.co/7pPtMcf/sp.png)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['comment_text'][8]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Token\nBelow I am explaining the token-level entity annotation using the **BILUO** tagging scheme to describe the entity boundaries.\n![](https://i.ibb.co/sJ3rcpc/spacy.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pprint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp('The ranchers seem motivated by mostly by greed; no one should have the right to allow their animals destroy public land.')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint.pprint([(X, X.ent_iob_, X.ent_type_) for X in doc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc1=nlp(\"My Name is Nikki Sharma. I love Nature Languge Processing.\")\nfor word in doc1.ents:\n    print(word)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explanation \n**\"B\"** means the token begins an entity, **\"I\"** means it is inside an entity, **\"O\"** means it is outside an entity, and **\"\"** means no entity tag is set."},{"metadata":{},"cell_type":"markdown","source":"# Extracting named entity from an article\n\nNow let’s do some serious stuff  with SpaCy and extracting named entities from toxic comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"text= df['comment_text'][19]\ntext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"article = nlp(text)\nlen(article.ents)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 3 entities in the article and they are represented as 3 unique labels:"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [x.label_ for x in article.ents]\nCounter(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following are three most frequent tokens."},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp(text)\npprint.pprint([(X.text, X.label_) for X in doc.ents])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Racists is NORD (nationalities or religious or political groups), 150 is a number hence Cardinal and here is the funny part Math is represented as Person ):"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = df['comment_text'][119]\nsentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(nlp(str(sentence)), jupyter=True, style='ent')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Excellent classification Minorities repreents Person Police represents ORGANIZATION (ORG), Natives, literal meaning is group of local residents which is somewhat similar to ORG and atlast one is numerical which is CRADINAL GREAT !!!!!!"},{"metadata":{},"cell_type":"markdown","source":"Lets Explore some other sentences for more fun."},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_1 = df['comment_text'][350]\nsentence_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(nlp(str(sentence_1)), jupyter=True, style='ent')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_2 = df['comment_text'][970]\nsentence_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(nlp(str(sentence_2)), jupyter=True, style='ent')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using spaCy’s built-in **displaCy visualizer**, here’s what the above sentence and its dependencies look like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(nlp(str(sentence)), style='dep', jupyter = True, options = {'distance': 120})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dependency visualizer, **dep**, shows **part-of-speech tags** and **syntactic dependencies**.\n\nThe argument **options** lets you specify a dictionary of settings to customize the layout.\nFor a list of all available options, see the  [displacy API documentation](https://spacy.io/api/top-level#displacy_options)\n\nNext, we verbatim, extract part-of-speech and lemmatize this sentence.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"[(x.orth_,x.pos_, x.lemma_) for x in [y \n                                      for y\n                                      in nlp(str(sentence)) \n                                      if not y.is_stop and y.pos_ != 'PUNCT']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict([(str(x), x.label_) for x in nlp(str(sentence_2)).ents])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finally I am going to explore the entity of entire article of NY times article "},{"metadata":{"trusted":true},"cell_type":"code","source":"article = nlp('By the time Prime Minister Boris Johnson finished taking questions in Parliament on Wednesday, he had ushered in a new season of political mayhem in Britain, one in which the voters are now as likely as their feuding leaders to resolve the questions over how and when Britain should leave the European Union. The raucous spectacle in the House of Commons illustrated the obstacles Mr. Johnson will face as he tries to lead Britain out of the European Union next month. On Wednesday, Parliament handed he prime minister two stinging defeats.It first blocked his plans to leave the union with or without an agreement. And it then stymied his bid, at least for the moment, to call an election for Oct. 15, out of fear he could secure a new majority in favor of breaking with Europe, deal or no deal.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(article.ents)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = [x for x in article.sents]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(nlp(str(sentences)), jupyter=True, style='ent')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}