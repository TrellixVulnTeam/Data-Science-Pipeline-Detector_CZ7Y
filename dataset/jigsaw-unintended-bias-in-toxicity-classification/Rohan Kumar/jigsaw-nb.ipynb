{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Bidirectional, Flatten, Activation, Embedding, Concatenate, Input, Dense, Dropout, MaxPool2D\nfrom keras.layers import Reshape, Flatten, Conv1D, MaxPool1D, Embedding,BatchNormalization, LSTM,merge, Conv2D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential, Model\nimport keras.utils as ku \nimport numpy as np\nfrom keras import regularizers\nimport pickle as pkl\ntokenizer = Tokenizer()\nfrom html import unescape\nfrom nltk.stem import SnowballStemmer\nimport re\nfrom nltk.corpus import stopwords\nimport sys\nsys.stdout.write('hello')","execution_count":48,"outputs":[{"output_type":"stream","text":"hello","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#stop=set(stopwords.words('english'))\n#stem=SnowballStemmer('english')\ndf=pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')#, sep='\\t')\ndf_un=pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')#, sep='\\t')\ndf['bin'] = df.target>=0.5","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def re_clean(text):\n    #c.append('')\n    #if len(c)%1000==0:\n        #pass\n        #print(len(c))\n    text=text.lower()\n    symbol = \"\"\"!#$%^&*();:\\t\\\\\\\"!\\{\\}\\[\\]<>-\\?\\-\\\\\\\"—\\.,1234567890\"\"\"\n    text=re.sub(\"\\'ll\", ' will', text)\n    text=re.sub(\"\\'ve\", ' have', text)\n    text=re.sub(\"\\'s\", ' is', text)\n    text=re.sub('[{}]'.format(symbol),' ', text)\n    #text=re.sub('[\\W]',' ', text)\n    text=re.sub('\\n',' ', text)\n    text=re.sub(' +',' ', text)\n    text=re.sub('^\\s', '', text)\n    #text=' '.join([stem.stem(i) for i in text.split() if not i in stop])\n    #text=[i for i in text.split() if i not in stop]\n    return text #' '.join(text)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sys.stdout.write('Cleaning start')\ndf['text']=df.comment_text.apply(re_clean)\ndf_un['text']=df_un.comment_text.apply(re_clean)\nsys.stdout.write('Cleaning done')","execution_count":4,"outputs":[{"output_type":"stream","text":"Cleaning start\nCleaning done\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/glove840b300dtxt && ls","execution_count":5,"outputs":[{"output_type":"stream","text":"glove.840B.300d.txt\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntokenizer.fit_on_texts(list(df.text)+list(df_un.text))\nsys.stdout.write('tokenizing done!')","execution_count":6,"outputs":[{"output_type":"stream","text":"tokenizing done!\nCPU times: user 1min 52s, sys: 568 ms, total: 1min 53s\nWall time: 1min 53s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=220","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_train_seq_trunc = tokenizer.texts_to_sequences(df.text)\n\nX_train_seq_trunc = pad_sequences(X_train_seq_trunc, maxlen=m, truncating='post', padding='post')\n#from sklearn.model_selection import train_test_split\ny_train = df.bin\n#X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, y_train, test_size=0.1, random_state=37)\n\n#assert X_valid_emb.shape[0] == y_valid_emb.shape[0]\n#assert X_train_emb.shape[0] == y_train_emb.shape[0]\n\n#print('Shape of validation set:',X_valid_emb.shape)\n#del X_train_seq_trunc\ndel df\n\nsys.stdout.write('sequencing done!')","execution_count":8,"outputs":[{"output_type":"stream","text":"sequencing done!\nCPU times: user 1min 46s, sys: 1.4 s, total: 1min 47s\nWall time: 1min 47s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.word_index","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"{'the': 1,\n 'to': 2,\n 'and': 3,\n 'is': 4,\n 'of': 5,\n 'a': 6,\n 'in': 7,\n 'that': 8,\n 'it': 9,\n 'you': 10,\n 'for': 11,\n 'i': 12,\n 'are': 13,\n 'not': 14,\n 'have': 15,\n 'be': 16,\n 'on': 17,\n 'this': 18,\n 'they': 19,\n 'with': 20,\n 'as': 21,\n 'was': 22,\n 'or': 23,\n 'but': 24,\n 'he': 25,\n 'will': 26,\n 'we': 27,\n 'if': 28,\n 'all': 29,\n 'what': 30,\n 'their': 31,\n 'by': 32,\n 'so': 33,\n 'who': 34,\n 'from': 35,\n 'your': 36,\n 'at': 37,\n 'no': 38,\n 'do': 39,\n 'people': 40,\n 'would': 41,\n 'about': 42,\n 'has': 43,\n 'there': 44,\n 'an': 45,\n 'more': 46,\n 'his': 47,\n 'one': 48,\n 'just': 49,\n 'like': 50,\n 'can': 51,\n 'trump': 52,\n 'out': 53,\n 'when': 54,\n 'up': 55,\n 'our': 56,\n \"don't\": 57,\n 'how': 58,\n 'them': 59,\n 'my': 60,\n 'get': 61,\n 'should': 62,\n 'than': 63,\n 'us': 64,\n 'been': 65,\n 'were': 66,\n 'only': 67,\n 'time': 68,\n 'any': 69,\n 'some': 70,\n 'other': 71,\n 'because': 72,\n 'now': 73,\n 'think': 74,\n 'those': 75,\n 'why': 76,\n 'many': 77,\n 'know': 78,\n 'good': 79,\n 'then': 80,\n 'which': 81,\n 'even': 82,\n 'right': 83,\n 'had': 84,\n 'these': 85,\n 'over': 86,\n 'me': 87,\n 'years': 88,\n 'did': 89,\n 'see': 90,\n 'being': 91,\n 'make': 92,\n 'much': 93,\n 'well': 94,\n 'way': 95,\n 'she': 96,\n 'government': 97,\n 'need': 98,\n 'most': 99,\n 'could': 100,\n 'state': 101,\n 'very': 102,\n 'want': 103,\n 'money': 104,\n 'him': 105,\n 'go': 106,\n 'her': 107,\n 'does': 108,\n 'into': 109,\n 'here': 110,\n 'also': 111,\n 'where': 112,\n 'tax': 113,\n 'going': 114,\n 'too': 115,\n 'same': 116,\n 'say': 117,\n 'never': 118,\n 'canada': 119,\n 'take': 120,\n 'really': 121,\n \"i'm\": 122,\n 'its': 123,\n 'back': 124,\n 'own': 125,\n 'said': 126,\n 'after': 127,\n 'new': 128,\n 'still': 129,\n 'work': 130,\n 'first': 131,\n 'world': 132,\n 'pay': 133,\n 'year': 134,\n 'country': 135,\n 'nothing': 136,\n 'down': 137,\n 'every': 138,\n 'better': 139,\n 'public': 140,\n 'another': 141,\n 'may': 142,\n 'off': 143,\n \"can't\": 144,\n 'am': 145,\n 'let': 146,\n 'while': 147,\n 'before': 148,\n 'president': 149,\n 'such': 150,\n \"doesn't\": 151,\n 'long': 152,\n 'law': 153,\n 'two': 154,\n 'against': 155,\n 'use': 156,\n 'point': 157,\n 'thing': 158,\n 'made': 159,\n 'actually': 160,\n 'care': 161,\n 'something': 162,\n 'believe': 163,\n 'great': 164,\n 's': 165,\n 'last': 166,\n 'life': 167,\n 'sure': 168,\n 'article': 169,\n 'again': 170,\n 'problem': 171,\n 'news': 172,\n \"didn't\": 173,\n 'real': 174,\n 'fact': 175,\n 'look': 176,\n 'both': 177,\n 'since': 178,\n 'someone': 179,\n 'things': 180,\n 'day': 181,\n 'come': 182,\n 'party': 183,\n 'left': 184,\n 'keep': 185,\n 'without': 186,\n 'anything': 187,\n 'maybe': 188,\n 'yes': 189,\n 'read': 190,\n 'support': 191,\n 'far': 192,\n 'vote': 193,\n 'change': 194,\n 'always': 195,\n 'free': 196,\n 'anyone': 197,\n 'got': 198,\n 'must': 199,\n 'under': 200,\n 'system': 201,\n \"you're\": 202,\n 'little': 203,\n 'part': 204,\n 'doing': 205,\n 'ever': 206,\n 'put': 207,\n 'white': 208,\n 'big': 209,\n 'oil': 210,\n 'obama': 211,\n 'person': 212,\n 'man': 213,\n 'give': 214,\n 'alaska': 215,\n 'political': 216,\n 'women': 217,\n 'enough': 218,\n 'might': 219,\n 'bad': 220,\n 'done': 221,\n 'business': 222,\n 'less': 223,\n 'lot': 224,\n 'find': 225,\n 'best': 226,\n \"isn't\": 227,\n 'few': 228,\n 'job': 229,\n 'through': 230,\n 'agree': 231,\n 'around': 232,\n 'wrong': 233,\n 'american': 234,\n 'already': 235,\n 'help': 236,\n 'old': 237,\n 'used': 238,\n 'stop': 239,\n 'city': 240,\n 'taxes': 241,\n 'media': 242,\n 'away': 243,\n 'needs': 244,\n 'yet': 245,\n 'election': 246,\n 'health': 247,\n 'next': 248,\n 'com': 249,\n 'high': 250,\n 'issue': 251,\n 'least': 252,\n 'everyone': 253,\n 'others': 254,\n 'canadian': 255,\n 'comment': 256,\n 'live': 257,\n 'seems': 258,\n 'place': 259,\n 'mr': 260,\n 'family': 261,\n 'www': 262,\n 'etc': 263,\n 'liberal': 264,\n 'church': 265,\n 'course': 266,\n 'america': 267,\n 'trudeau': 268,\n 'power': 269,\n 'post': 270,\n 'getting': 271,\n 'case': 272,\n 'making': 273,\n 'house': 274,\n 'god': 275,\n 'true': 276,\n 'end': 277,\n 'cost': 278,\n 'million': 279,\n 'home': 280,\n 'states': 281,\n 'trying': 282,\n 'hope': 283,\n 'until': 284,\n 'school': 285,\n 'having': 286,\n 'story': 287,\n 'children': 288,\n 'war': 289,\n 'comments': 290,\n 'understand': 291,\n 'either': 292,\n 'mean': 293,\n 'reason': 294,\n 'makes': 295,\n 'else': 296,\n 'tell': 297,\n 'federal': 298,\n 'please': 299,\n 'try': 300,\n 'income': 301,\n 'different': 302,\n 'today': 303,\n 'matter': 304,\n 'times': 305,\n 'u': 306,\n 'hard': 307,\n 'called': 308,\n 'probably': 309,\n 'history': 310,\n 'between': 311,\n 'based': 312,\n 'run': 313,\n 'clinton': 314,\n 'instead': 315,\n 'question': 316,\n 'liberals': 317,\n 'police': 318,\n 'ago': 319,\n 'rather': 320,\n 'jobs': 321,\n 'once': 322,\n 'thought': 323,\n 'saying': 324,\n 'start': 325,\n 'rights': 326,\n \"won't\": 327,\n 'perhaps': 328,\n 'http': 329,\n 'love': 330,\n 'guy': 331,\n 'working': 332,\n 'call': 333,\n 'simply': 334,\n 'show': 335,\n 'hillary': 336,\n 'means': 337,\n 'themselves': 338,\n 'feel': 339,\n 'non': 340,\n 'however': 341,\n 'bill': 342,\n 'name': 343,\n 'paid': 344,\n 'oh': 345,\n 'says': 346,\n 'though': 347,\n 'given': 348,\n 'poor': 349,\n 'during': 350,\n 'control': 351,\n 'idea': 352,\n 'kids': 353,\n 'men': 354,\n 'americans': 355,\n 'past': 356,\n 'https': 357,\n 'each': 358,\n 'cannot': 359,\n 'canadians': 360,\n 'line': 361,\n 'republican': 362,\n 'everything': 363,\n 'deal': 364,\n 'human': 365,\n 'facts': 366,\n 'issues': 367,\n 'become': 368,\n 'per': 369,\n 'guess': 370,\n 'opinion': 371,\n 'small': 372,\n 'countries': 373,\n 'office': 374,\n 'national': 375,\n 'truth': 376,\n 'pretty': 377,\n 'using': 378,\n 'likely': 379,\n 'sense': 380,\n 'kind': 381,\n 'seem': 382,\n 'private': 383,\n 'days': 384,\n 'majority': 385,\n 'social': 386,\n 'self': 387,\n 'republicans': 388,\n 'laws': 389,\n 'court': 390,\n 'number': 391,\n 'able': 392,\n 'evidence': 393,\n 'rest': 394,\n 'military': 395,\n 'thank': 396,\n 'lost': 397,\n 'living': 398,\n 'plan': 399,\n 'example': 400,\n 'china': 401,\n 'market': 402,\n 'thanks': 403,\n 'democrats': 404,\n 'remember': 405,\n 'black': 406,\n 'citizens': 407,\n 'current': 408,\n 'move': 409,\n 'hate': 410,\n 'gun': 411,\n 'economy': 412,\n 'exactly': 413,\n 'paying': 414,\n 'folks': 415,\n 'illegal': 416,\n 'full': 417,\n 'especially': 418,\n 'buy': 419,\n 'wants': 420,\n 'taking': 421,\n 'continue': 422,\n 'legal': 423,\n 'wonder': 424,\n 'term': 425,\n 'whole': 426,\n 'game': 427,\n 'future': 428,\n 'costs': 429,\n 'local': 430,\n 'society': 431,\n 'side': 432,\n 'education': 433,\n 'gets': 434,\n 'class': 435,\n 'anti': 436,\n 'including': 437,\n 'low': 438,\n 'seen': 439,\n 'group': 440,\n \"they're\": 441,\n 'donald': 442,\n 'act': 443,\n 'comes': 444,\n 'mind': 445,\n 'words': 446,\n 'russia': 447,\n 'talking': 448,\n 'community': 449,\n 'companies': 450,\n 'hawaii': 451,\n 'whether': 452,\n 'insurance': 453,\n \"aren't\": 454,\n 'often': 455,\n 'order': 456,\n 'almost': 457,\n 'coming': 458,\n 'young': 459,\n 'certainly': 460,\n 'nation': 461,\n 'civil': 462,\n 'looking': 463,\n 'ask': 464,\n 'cut': 465,\n '”': 466,\n 'watch': 467,\n 'elected': 468,\n 'important': 469,\n 'land': 470,\n 'happen': 471,\n 'water': 472,\n 'policy': 473,\n 'personal': 474,\n 'three': 475,\n 'middle': 476,\n 'service': 477,\n 'level': 478,\n 'billion': 479,\n \"wouldn't\": 480,\n 'quite': 481,\n 'word': 482,\n 'goes': 483,\n 'open': 484,\n 'lives': 485,\n 'sad': 486,\n 'dollars': 487,\n 'information': 488,\n 'nice': 489,\n 'crime': 490,\n 'found': 491,\n 'clear': 492,\n 'along': 493,\n 'sorry': 494,\n 'went': 495,\n 'interest': 496,\n 'property': 497,\n 'campaign': 498,\n 'conservative': 499,\n 'child': 500,\n 'industry': 501,\n 'talk': 502,\n 'voters': 503,\n 'win': 504,\n 'politics': 505,\n 'reality': 506,\n 'team': 507,\n 'leave': 508,\n 'due': 509,\n 'problems': 510,\n 'north': 511,\n 'rate': 512,\n 'catholic': 513,\n 'budget': 514,\n 'head': 515,\n 'voted': 516,\n 'told': 517,\n 'foreign': 518,\n 'single': 519,\n 'took': 520,\n 'population': 521,\n \"wasn't\": 522,\n 'economic': 523,\n 'gas': 524,\n 'e': 525,\n 'hand': 526,\n 'face': 527,\n 'thinking': 528,\n 'came': 529,\n 'top': 530,\n 'climate': 531,\n 'second': 532,\n 'provide': 533,\n 'rail': 534,\n 'woman': 535,\n 'choice': 536,\n 'happened': 537,\n 'yourself': 538,\n 'play': 539,\n 'clearly': 540,\n 'company': 541,\n 'large': 542,\n 'car': 543,\n 'spending': 544,\n 'correct': 545,\n 'ones': 546,\n 'claim': 547,\n 'answer': 548,\n 'set': 549,\n 'bit': 550,\n 'm': 551,\n 'politicians': 552,\n 'higher': 553,\n 'racist': 554,\n 'hear': 555,\n 'half': 556,\n 'fake': 557,\n \"i'd\": 558,\n 'possible': 559,\n 'death': 560,\n 'increase': 561,\n 'unless': 562,\n 'worse': 563,\n 'united': 564,\n 'wait': 565,\n 'millions': 566,\n 'common': 567,\n 'process': 568,\n 'within': 569,\n 'allowed': 570,\n 'schools': 571,\n 'bring': 572,\n 'interesting': 573,\n 'members': 574,\n 'price': 575,\n 'speech': 576,\n 'food': 577,\n 'longer': 578,\n 'cause': 579,\n 'himself': 580,\n 'stupid': 581,\n 'stand': 582,\n 'housing': 583,\n 'th': 584,\n 'behind': 585,\n 'taken': 586,\n 'usa': 587,\n 'immigration': 588,\n 'congress': 589,\n 'area': 590,\n 'needed': 591,\n 'lack': 592,\n 'lol': 593,\n 'running': 594,\n 'position': 595,\n 'difference': 596,\n 'except': 597,\n 'knows': 598,\n 'whatever': 599,\n 'k': 600,\n 'rich': 601,\n 'spend': 602,\n 'general': 603,\n 'security': 604,\n 'blame': 605,\n 'fund': 606,\n 'fair': 607,\n 'b': 608,\n 'religious': 609,\n 'doubt': 610,\n 'g': 611,\n 'parents': 612,\n 'huge': 613,\n 'respect': 614,\n 'trade': 615,\n 'turn': 616,\n 'fire': 617,\n 'close': 618,\n 'administration': 619,\n 'entire': 620,\n 'bc': 621,\n 'experience': 622,\n 'services': 623,\n 'expect': 624,\n 're': 625,\n 'situation': 626,\n 'simple': 627,\n 'justice': 628,\n \"we're\": 629,\n 'report': 630,\n 'stay': 631,\n 'criminal': 632,\n 'russian': 633,\n 'statement': 634,\n 'debt': 635,\n 'harper': 636,\n 'actions': 637,\n 'heard': 638,\n 'allow': 639,\n 'ontario': 640,\n 'major': 641,\n 'workers': 642,\n 'violence': 643,\n 'months': 644,\n 'sounds': 645,\n 'lower': 646,\n 'decision': 647,\n 'completely': 648,\n 'reading': 649,\n 'nor': 650,\n 'students': 651,\n 'medical': 652,\n 'building': 653,\n 'check': 654,\n 'easy': 655,\n 'rules': 656,\n 'ok': 657,\n 'c': 658,\n 'several': 659,\n 'view': 660,\n 'week': 661,\n 'wanted': 662,\n 'friends': 663,\n 'argument': 664,\n 'road': 665,\n 'lies': 666,\n 'benefit': 667,\n 'program': 668,\n 'age': 669,\n 'speak': 670,\n 'science': 671,\n 'energy': 672,\n 'attack': 673,\n 'force': 674,\n 'religion': 675,\n 'above': 676,\n 'hold': 677,\n 'action': 678,\n 'soon': 679,\n 'race': 680,\n 'list': 681,\n 'yeah': 682,\n 'voting': 683,\n 'short': 684,\n 'south': 685,\n 'started': 686,\n 'pass': 687,\n 'involved': 688,\n 'value': 689,\n 'jesus': 690,\n 'build': 691,\n 'result': 692,\n 'consider': 693,\n 'gone': 694,\n 'fine': 695,\n 'leader': 696,\n 'further': 697,\n 'wish': 698,\n 'democratic': 699,\n 'guys': 700,\n 'john': 701,\n 'constitution': 702,\n 'absolutely': 703,\n 'known': 704,\n 'works': 705,\n 'benefits': 706,\n 'looks': 707,\n 'obviously': 708,\n 'worked': 709,\n 'stuff': 710,\n 'learn': 711,\n 'killed': 712,\n 'giving': 713,\n 'conservatives': 714,\n 'lose': 715,\n 'kill': 716,\n 'freedom': 717,\n 'none': 718,\n 'employees': 719,\n 'prices': 720,\n 'mention': 721,\n 'knew': 722,\n 'serious': 723,\n \"'\": 724,\n 'homeless': 725,\n 'response': 726,\n 'rates': 727,\n 'guns': 728,\n 'outside': 729,\n 'chance': 730,\n 'actual': 731,\n 'gop': 732,\n 'risk': 733,\n 'save': 734,\n 'happy': 735,\n 'follow': 736,\n 'disagree': 737,\n 'spent': 738,\n 'd': 739,\n 'funny': 740,\n 'takes': 741,\n 'fear': 742,\n 'wing': 743,\n 'research': 744,\n 'board': 745,\n 'special': 746,\n 'votes': 747,\n 'college': 748,\n 'itself': 749,\n 'truly': 750,\n 'lie': 751,\n 'share': 752,\n 'worth': 753,\n 'protect': 754,\n 'sexual': 755,\n 'numbers': 756,\n 'amount': 757,\n 'immigrants': 758,\n 'couple': 759,\n 'decades': 760,\n 'alone': 761,\n 'false': 762,\n 'groups': 763,\n 'together': 764,\n 'sex': 765,\n 'calling': 766,\n 'ways': 767,\n 'oregon': 768,\n 'asked': 769,\n 'project': 770,\n 'candidate': 771,\n 'muslim': 772,\n 'drug': 773,\n 'families': 774,\n 'wow': 775,\n 'globe': 776,\n 'safe': 777,\n 'responsible': 778,\n 'funding': 779,\n 'air': 780,\n 'average': 781,\n 'street': 782,\n 'attention': 783,\n 'thousands': 784,\n 'culture': 785,\n 'among': 786,\n 'dead': 787,\n 'certain': 788,\n 'access': 789,\n 'shows': 790,\n 'seriously': 791,\n 'apparently': 792,\n 'form': 793,\n 'gave': 794,\n 'otherwise': 795,\n 'leaders': 796,\n 'senate': 797,\n 'sell': 798,\n 'according': 799,\n 'failed': 800,\n 'union': 801,\n 'global': 802,\n 'supporters': 803,\n 'lead': 804,\n 'record': 805,\n 'across': 806,\n 'won': 807,\n 'realize': 808,\n 'happens': 809,\n 'later': 810,\n 'financial': 811,\n 'toronto': 812,\n 'total': 813,\n 'individual': 814,\n 'points': 815,\n 'policies': 816,\n 'org': 817,\n 'democracy': 818,\n 'add': 819,\n 'judge': 820,\n 'hit': 821,\n 'leadership': 822,\n 'finally': 823,\n 'created': 824,\n 'beyond': 825,\n 'abuse': 826,\n 'source': 827,\n 'trust': 828,\n 'hands': 829,\n 'mass': 830,\n 'former': 831,\n 'forget': 832,\n \"couldn't\": 833,\n 'available': 834,\n 'choose': 835,\n 'write': 836,\n 'piece': 837,\n 'lots': 838,\n 'st': 839,\n 'early': 840,\n 'month': 841,\n 'create': 842,\n 'native': 843,\n 'alaskans': 844,\n 'drive': 845,\n 'indeed': 846,\n 'earth': 847,\n 'corporate': 848,\n 'willing': 849,\n 'solution': 850,\n 'reasons': 851,\n 'upon': 852,\n 'ndp': 853,\n \"haven't\": 854,\n 'dog': 855,\n 'written': 856,\n 'worst': 857,\n 'democrat': 858,\n 'data': 859,\n 'similar': 860,\n 'press': 861,\n 'accept': 862,\n 'saw': 863,\n 'west': 864,\n 'justin': 865,\n 'afford': 866,\n 'nobody': 867,\n 'university': 868,\n 'front': 869,\n 'investigation': 870,\n 'tried': 871,\n 'behavior': 872,\n 'charge': 873,\n 'suggest': 874,\n 'anchorage': 875,\n 'totally': 876,\n 'resources': 877,\n 'chinese': 878,\n 'cars': 879,\n 'wall': 880,\n 'return': 881,\n 'fight': 882,\n 'healthcare': 883,\n 'built': 884,\n 'legislature': 885,\n 'christian': 886,\n 'night': 887,\n 'forward': 888,\n 'racism': 889,\n 'mayor': 890,\n 'questions': 891,\n 'owners': 892,\n 'obvious': 893,\n 'imagine': 894,\n 'waste': 895,\n 'muslims': 896,\n 'putin': 897,\n 'four': 898,\n 'pm': 899,\n 'responsibility': 900,\n 'agenda': 901,\n 'revenue': 902,\n 'driving': 903,\n 'taxpayers': 904,\n 'natural': 905,\n 'faith': 906,\n 'ms': 907,\n 'subject': 908,\n 'defense': 909,\n 'type': 910,\n 'unfortunately': 911,\n 'rule': 912,\n 'required': 913,\n 'parties': 914,\n 'step': 915,\n 'room': 916,\n 'bush': 917,\n 'governor': 918,\n 'pro': 919,\n 'light': 920,\n 'changes': 921,\n 'sales': 922,\n 'changed': 923,\n 'washington': 924,\n 'hours': 925,\n 'county': 926,\n 'book': 927,\n 'town': 928,\n 'pope': 929,\n 'safety': 930,\n 'cases': 931,\n 'areas': 932,\n 'sort': 933,\n 'father': 934,\n 'base': 935,\n 'late': 936,\n 'demand': 937,\n 'sound': 938,\n 'supposed': 939,\n 'ban': 940,\n 'zero': 941,\n 'staff': 942,\n 'profit': 943,\n 'east': 944,\n 'growth': 945,\n 'although': 946,\n 't': 947,\n 'wife': 948,\n 'governments': 949,\n 'nations': 950,\n 'recent': 951,\n 'cash': 952,\n 'hey': 953,\n 'neither': 954,\n 'cover': 955,\n \"shouldn't\": 956,\n 'shot': 957,\n 'values': 958,\n 'funds': 959,\n 'strong': 960,\n 'period': 961,\n 'born': 962,\n 'programs': 963,\n 'co': 964,\n 'traffic': 965,\n 'lying': 966,\n 'held': 967,\n 'brought': 968,\n 'anyway': 969,\n 'considered': 970,\n 'study': 971,\n 'complete': 972,\n 'sector': 973,\n 'bank': 974,\n 'sometimes': 975,\n 'figure': 976,\n 'playing': 977,\n 'minister': 978,\n 'drugs': 979,\n 'korea': 980,\n 'nonsense': 981,\n 'council': 982,\n 'discussion': 983,\n 'carbon': 984,\n 'break': 985,\n 'telling': 986,\n 'interests': 987,\n 'results': 988,\n 'attempt': 989,\n 'proof': 990,\n 'near': 991,\n 'corrupt': 992,\n 'expensive': 993,\n 'killing': 994,\n 'fix': 995,\n 'red': 996,\n 'plus': 997,\n 'bet': 998,\n 'raise': 999,\n 'regardless': 1000,\n ...}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNB_WORDS=len(tokenizer.word_index)\nGLOVE_DIM=300\n\n\nemb_matrix = np.zeros((NB_WORDS+1, GLOVE_DIM))\ndef emb():\n    with open('/kaggle/input/glove840b300dtxt/glove.840B.300d.txt') as f:\n        for n, i in enumerate(f):\n            i = i.split()\n            if tokenizer.word_index.get(' '.join(i[:-300])):\n                #print(' '.join(i[:-300]))\n                emb_matrix[tokenizer.word_index.get(' '.join(i[:-300]))] = np.array(i[-300:])\n            if n%500000==0:\n                sys.stdout.write(n)","execution_count":39,"outputs":[{"output_type":"stream","text":"CPU times: user 0 ns, sys: 4 ms, total: 4 ms\nWall time: 4.54 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb()","execution_count":40,"outputs":[{"output_type":"stream","text":"0\n500000\n1000000\n1500000\n2000000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_matrix","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.27204 , -0.06203 , -0.1884  , ...,  0.13015 , -0.18317 ,\n         0.1323  ],\n       [ 0.31924 ,  0.06316 , -0.27858 , ...,  0.082745,  0.097801,\n         0.25045 ],\n       ...,\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.71899 , -0.6913  ,  0.042406, ..., -0.71715 , -0.015302,\n         0.20028 ]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_filters = 256\nfilter_sizes = [3,4,5]\ndropout = 0.5\nembedding_dim = 300\nvocabulary_size = NB_WORDS\nsequence_length = m","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp1=Input((m,))\nemb=Embedding(NB_WORDS+1,embedding_dim, weights=[emb_matrix],trainable=False)(inp1)\n#lstm1=Bidirectional(LSTM(128, return_sequences=True))(emb)\n#drop1=Dropout(dropout)(lstm1)\n#lstm2=Bidirectional(LSTM(128, return_sequences=True))(drop1)\n#drop2=Dropout(dropout)(lstm2)\n#lstm2=Bidirectional(LSTM(128, return_sequences=False))(drop2)\n#dense_lstm=Dense(128, activation='relu')(lstm2)\nreshape = Reshape((sequence_length,embedding_dim,1))(emb)\nconv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\nconv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\nconv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\nmaxpool_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\nmaxpool_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\nmaxpool_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\nconcatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])#, maxpool_3])\nflatten = Flatten()(concatenated_tensor)\n#dense_con=Dense(128, activation='relu')(flatten)\n#conc=conc=merge.multiply(([dense_con, dense_lstm]))\nbatch1=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', \n                              gamma_initializer='ones', moving_mean_initializer='zeros', \n                              moving_variance_initializer='ones', beta_regularizer=None,\n                              gamma_regularizer=None, beta_constraint=None,\n                              gamma_constraint=None)(flatten)\ndense3=Dense(128, activation='relu')(batch1)\ndrop4=Dropout(0.5)(dense3)\ndense4=Dense(128, activation='relu')(drop4)\n\"\"\"batch2=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', \n                          gamma_initializer='ones', moving_mean_initializer='zeros', \n                          moving_variance_initializer='ones', beta_regularizer=None,\n                          gamma_regularizer=None, beta_constraint=None,\n                          gamma_constraint=None)(dense4)\"\"\"\n#conc=Concatenate()([dense7, out1])\ndrop5=Dropout(0.5)(dense4)\ndense7=Dense(128, activation='relu')(drop5)\nout=Dense(1, activation='sigmoid')(dense7)\nmodel= Model(inp1, out)","execution_count":43,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nadam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n\ncheckpoint = ModelCheckpoint('jigsaw.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\nmodel.compile(loss='binary_crossentropy', optimizer=adam,\n              metrics=['accuracy'], )\n\ngc.collect()","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sys.stdout.write('Training...')\nhistory=model.fit(X_train_seq_trunc\n                       , y_train\n                       , epochs=8\n                       , batch_size=2048\n                       , validation_split= 0.1 #(X_valid_emb, y_valid_emb)\n                       , verbose=1, callbacks=[checkpoint])\nsys.stdout.write(\"Trained!\")","execution_count":47,"outputs":[{"output_type":"stream","text":"Train on 1624386 samples, validate on 180488 samples\nEpoch 1/8\n 570768/1624386 [=========>....................] - ETA: 3:01 - loss: 0.2322 - acc: 0.9214","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-183c222f8081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m#(X_valid_emb, y_valid_emb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        , verbose=1, callbacks=[checkpoint])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_seq_trunc = tokenizer.texts_to_sequences(df_un.text)\nX_test_seq_trunc = pad_sequences(X_test_seq_trunc, maxlen=m, truncating='post', padding='post')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel=load_model('jigsaw.hdf5')\npre=model.predict(X_test_seq_trunc, verbose=1)\ndf3=pd.DataFrame(pre, index=df_un.id, columns=['prediction'])\ndf3.to_csv('submission.csv')\nsys.stdout.write('Done!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}