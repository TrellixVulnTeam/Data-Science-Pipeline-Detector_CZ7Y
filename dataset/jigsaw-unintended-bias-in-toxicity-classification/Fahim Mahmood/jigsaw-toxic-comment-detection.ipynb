{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport multiprocessing\nimport warnings\nwarnings.simplefilter('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport nltk\nimport re\nimport string\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.lancaster import LancasterStemmer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T11:17:16.541885Z","iopub.execute_input":"2021-06-25T11:17:16.542312Z","iopub.status.idle":"2021-06-25T11:17:18.237001Z","shell.execute_reply.started":"2021-06-25T11:17:16.542229Z","shell.execute_reply":"2021-06-25T11:17:18.235664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:17:52.416287Z","iopub.execute_input":"2021-06-25T11:17:52.416724Z","iopub.status.idle":"2021-06-25T11:17:52.444902Z","shell.execute_reply.started":"2021-06-25T11:17:52.416682Z","shell.execute_reply":"2021-06-25T11:17:52.443733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files=['../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv',\n       '../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv',\n       '../input/jigsaw-unintended-bias-in-toxicity-classification/all_data.csv',\n       '../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv'\n      ]\n\ndef load_data(file):\n    return pd.read_csv(file)\nwith multiprocessing.Pool() as pool:\n    test,train,all_data,sub=pool.map(load_data,files)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:17:57.008234Z","iopub.execute_input":"2021-06-25T11:17:57.008628Z","iopub.status.idle":"2021-06-25T11:18:55.007157Z","shell.execute_reply.started":"2021-06-25T11:17:57.008594Z","shell.execute_reply":"2021-06-25T11:18:55.005224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for col in all_data.columns:\n#     print(\"{} -----------> {}\".format(col,all_data[col].dtypes))\n#     print(\"{} ===========> {}\".format(col,train[col].dtypes))\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:00.177639Z","iopub.execute_input":"2021-06-25T11:19:00.17802Z","iopub.status.idle":"2021-06-25T11:19:00.434645Z","shell.execute_reply.started":"2021-06-25T11:19:00.177982Z","shell.execute_reply":"2021-06-25T11:19:00.433325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.target.value_counts(dropna=True).head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:00.628665Z","iopub.execute_input":"2021-06-25T11:19:00.629044Z","iopub.status.idle":"2021-06-25T11:19:00.687111Z","shell.execute_reply.started":"2021-06-25T11:19:00.629009Z","shell.execute_reply":"2021-06-25T11:19:00.686105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:05.523037Z","iopub.execute_input":"2021-06-25T11:19:05.523411Z","iopub.status.idle":"2021-06-25T11:19:05.53105Z","shell.execute_reply.started":"2021-06-25T11:19:05.523376Z","shell.execute_reply":"2021-06-25T11:19:05.52961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:08.385966Z","iopub.execute_input":"2021-06-25T11:19:08.386435Z","iopub.status.idle":"2021-06-25T11:19:08.399494Z","shell.execute_reply.started":"2021-06-25T11:19:08.386399Z","shell.execute_reply":"2021-06-25T11:19:08.398184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train[['comment_text','target']]\ntrain.columns.values","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:19.917012Z","iopub.execute_input":"2021-06-25T11:19:19.917479Z","iopub.status.idle":"2021-06-25T11:19:20.009897Z","shell.execute_reply.started":"2021-06-25T11:19:19.917427Z","shell.execute_reply":"2021-06-25T11:19:20.008737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:35.773867Z","iopub.execute_input":"2021-06-25T11:19:35.774228Z","iopub.status.idle":"2021-06-25T11:19:35.9194Z","shell.execute_reply.started":"2021-06-25T11:19:35.774197Z","shell.execute_reply":"2021-06-25T11:19:35.918089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tox=0\nneut=0\nno_of_rows=X.shape[0]\nfor row in range(no_of_rows):\n    if X['target'][row]>0.7:\n        tox+=1\n    else:\n        neut+=1","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:39.501186Z","iopub.execute_input":"2021-06-25T11:19:39.501566Z","iopub.status.idle":"2021-06-25T11:19:55.905708Z","shell.execute_reply.started":"2021-06-25T11:19:39.501532Z","shell.execute_reply":"2021-06-25T11:19:55.904616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{round((tox*100)/no_of_rows,3)}% data contains toxic comments')\nprint(f'{round((neut*100/no_of_rows),3)}% data contains neutral comments')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:19:58.61985Z","iopub.execute_input":"2021-06-25T11:19:58.620218Z","iopub.status.idle":"2021-06-25T11:19:58.626071Z","shell.execute_reply.started":"2021-06-25T11:19:58.620184Z","shell.execute_reply":"2021-06-25T11:19:58.624948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprocessing comment_text for training**","metadata":{}},{"cell_type":"code","source":"# remove all numbers with letters attached to them\nalphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n\n# '[%s]' % re.escape(string.punctuation),' ' - replace punctuation with white space\n# .lower() - convert all strings to lowercase \npunc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n\n# Remove all '\\n' in the string and replace it with a space\nremove_n = lambda x: re.sub(\"\\n\", \" \", x)\n\n# Remove all non-ascii characters \nremove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n\n# Apply all the lambda functions wrote previously through .map on the comments column\nX['comment_text'] = X['comment_text'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:20:02.317789Z","iopub.execute_input":"2021-06-25T11:20:02.318388Z","iopub.status.idle":"2021-06-25T11:22:47.154451Z","shell.execute_reply.started":"2021-06-25T11:20:02.31835Z","shell.execute_reply":"2021-06-25T11:22:47.153436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wordcloud\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\ndef wordcloud(df, label):\n    \n    \n    subset=df[df[label]>0.7]\n    text=subset.comment_text.values\n    wc= WordCloud(background_color=\"white\",max_words=4000)\n\n    wc.generate(\" \".join(text))\n\n    plt.figure(figsize=(20,20))\n    plt.subplot(221)\n    plt.axis(\"off\")\n    plt.title(\"Words frequented in {}\".format(label), fontsize=20)\n    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244), alpha=0.98)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:14.082369Z","iopub.execute_input":"2021-06-25T11:23:14.083251Z","iopub.status.idle":"2021-06-25T11:23:14.185365Z","shell.execute_reply.started":"2021-06-25T11:23:14.0832Z","shell.execute_reply":"2021-06-25T11:23:14.184171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud(X,'target')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:14.565604Z","iopub.execute_input":"2021-06-25T11:23:14.566059Z","iopub.status.idle":"2021-06-25T11:23:22.79008Z","shell.execute_reply.started":"2021-06-25T11:23:14.56602Z","shell.execute_reply":"2021-06-25T11:23:22.789035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Class Imbalance","metadata":{}},{"cell_type":"code","source":"toxic_train=X[X['target']>0.7].iloc[0:45451,:]\ntoxic_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:25.533312Z","iopub.execute_input":"2021-06-25T11:23:25.533943Z","iopub.status.idle":"2021-06-25T11:23:25.559662Z","shell.execute_reply.started":"2021-06-25T11:23:25.533906Z","shell.execute_reply":"2021-06-25T11:23:25.558093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neutral_train=X[X['target']<=0.7].iloc[0:150000,:]\nneutral_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:25.935217Z","iopub.execute_input":"2021-06-25T11:23:25.935606Z","iopub.status.idle":"2021-06-25T11:23:26.104052Z","shell.execute_reply.started":"2021-06-25T11:23:25.935572Z","shell.execute_reply":"2021-06-25T11:23:26.103027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_train=pd.concat([toxic_train,neutral_train],axis=0)\nbalanced_train.shape\n\n# balanced_train=X","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:32.1581Z","iopub.execute_input":"2021-06-25T11:23:32.158654Z","iopub.status.idle":"2021-06-25T11:23:32.18117Z","shell.execute_reply.started":"2021-06-25T11:23:32.15862Z","shell.execute_reply":"2021-06-25T11:23:32.179625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del toxic_train, neutral_train","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:45.57865Z","iopub.execute_input":"2021-06-25T11:23:45.579197Z","iopub.status.idle":"2021-06-25T11:23:45.623305Z","shell.execute_reply.started":"2021-06-25T11:23:45.579163Z","shell.execute_reply":"2021-06-25T11:23:45.621771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import packages for pre-processing\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import SelectFromModel\n\n# Import tools to split data and evaluate model performance\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix, accuracy_score\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# Import ML algos\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:48.070598Z","iopub.execute_input":"2021-06-25T11:23:48.070955Z","iopub.status.idle":"2021-06-25T11:23:48.328662Z","shell.execute_reply.started":"2021-06-25T11:23:48.070925Z","shell.execute_reply":"2021-06-25T11:23:48.327163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model F1 Score Comparison ","metadata":{}},{"cell_type":"code","source":"'''\nvectorizer values: CountVectorizer, TfidfVectorizer\ngram_range values: (1,1) for unigram, (2,2) for bigram\n'''\ndef cv_tf_train_test(df_done,label,vectorizer,ngram):\n\n    ''' Train/Test split'''\n    # Split the data into X and y data sets\n    X = df_done.comment_text\n    y = df_done[label]\n\n    # Split our data into training and test data \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    ''' Count Vectorizer/TF-IDF '''\n\n    # Create a Vectorizer object and remove stopwords from the table\n    cv1 = vectorizer(ngram_range=(ngram), stop_words='english')\n    \n    X_train_cv1 = cv1.fit_transform(X_train) # Learn the vocabulary dictionary and return term-document matrix\n    X_test_cv1  = cv1.transform(X_test)      # Learn a vocabulary dictionary of all tokens in the raw documents.\n    \n        \n    ''' Initialize all model objects and fit the models on the training data '''\n    lr = LogisticRegression()\n    lr.fit(X_train_cv1, y_train)\n    print('lr done')\n\n    knn = KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X_train_cv1, y_train)\n\n\n    xgb=XGBClassifier()\n    xgb.fit(X_train_cv1,y_train)\n    \n    svm_model = LinearSVC()\n    svm_model.fit(X_train_cv1, y_train)\n\n    randomforest = RandomForestClassifier(n_estimators=100, random_state=42)\n    randomforest.fit(X_train_cv1, y_train)\n    print('rdf done')\n    \n    # Create a list of F1 score of all models \n    f1_score_data = {'F1 Score':[f1_score(lr.predict(X_test_cv1), y_test), f1_score(knn.predict(X_test_cv1), y_test), \n                                f1_score(xgb.predict(X_test_cv1),y_test),\n                                f1_score(svm_model.predict(X_test_cv1), y_test), f1_score(randomforest.predict(X_test_cv1), y_test)]} \n                          \n    # Create DataFrame with the model names as column labels \n    df_f1 = pd.DataFrame(f1_score_data, index=['Log Regression','KNN', 'XGB', 'SVM', 'Random Forest'])\n\n#     accuracy_data = {'Accuracy Score':[accuracy_score(lr.predict(X_test_cv1), y_test), accuracy_score(knn.predict(X_test_cv1), y_test), \n#                                 accuracy_score(xgb.predict(X_test_cv1),y_test),\n#                                 accuracy_score(svm_model.predict(X_test_cv1), y_test), accuracy_score(randomforest.predict(X_test_cv1), y_test)]} \n                          \n    # Create DataFrame with the model names as column labels \n#     df_acc = pd.DataFrame(accuracy_data, index=['Log Regression','KNN', 'XGB', 'SVM', 'Random Forest'])\n    return df_f1\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:50.503875Z","iopub.execute_input":"2021-06-25T11:23:50.504294Z","iopub.status.idle":"2021-06-25T11:23:50.518262Z","shell.execute_reply.started":"2021-06-25T11:23:50.504262Z","shell.execute_reply":"2021-06-25T11:23:50.516688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assigning Binary Value to Labels","metadata":{}},{"cell_type":"code","source":"balanced_train['target']=np.where(balanced_train['target']>0.7,1.0,0.0)\nbalanced_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:23:56.919143Z","iopub.execute_input":"2021-06-25T11:23:56.919509Z","iopub.status.idle":"2021-06-25T11:23:56.937335Z","shell.execute_reply.started":"2021-06-25T11:23:56.919478Z","shell.execute_reply":"2021-06-25T11:23:56.936054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nt0 = time.time()\n\ndf_tox_cv = cv_tf_train_test(balanced_train, 'target', TfidfVectorizer, (1,1))\ndf_tox_cv.rename(columns={'F1 Score': 'F1 Score(target)'}, inplace=True)\n\nt1 = time.time()\n\ntotal = 'Time taken: {} seconds'.format(t1-t0)\nprint(total)\n\ndf_tox_cv","metadata":{"execution":{"iopub.status.busy":"2021-06-25T11:24:00.347716Z","iopub.execute_input":"2021-06-25T11:24:00.348212Z","iopub.status.idle":"2021-06-25T11:33:43.783517Z","shell.execute_reply.started":"2021-06-25T11:24:00.348175Z","shell.execute_reply":"2021-06-25T11:33:43.77972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = balanced_train.comment_text\ny = balanced_train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initiate a Tfidf vectorizer\ntfv = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n\nX_train_fit = tfv.fit_transform(X_train)  # Convert the X data into a document term matrix dataframe\nX_test_fit = tfv.transform(X_test)  # Converts the X_test comments into Vectorized format\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:18:20.127474Z","iopub.execute_input":"2021-06-24T19:18:20.127818Z","iopub.status.idle":"2021-06-24T19:18:20.622826Z","shell.execute_reply.started":"2021-06-24T19:18:20.127787Z","shell.execute_reply":"2021-06-24T19:18:20.621491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM CLassifier","metadata":{}},{"cell_type":"code","source":"# from sklearn.calibration import CalibratedClassifierCV\n# svm_model = LinearSVC()\n# clf = CalibratedClassifierCV(svm_model) \n# clf.fit(X_train_fit, y_train)\n    \n\n# my_ans=[]\n# for row in range(test.shape[0]):\n#     comment=[test['comment_text'][row]]\n#     cmt=tfv.transform(comment)\n#     my_ans.append(clf.predict_proba(cmt)[:,1])\n\n# data={'id':[],\n#       'prediction':[]\n#      }\n# df=pd.DataFrame(data)\n\n# df['id']=test['id']\n\n# df['prediction']=pd.DataFrame(my_ans)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:23:41.820532Z","iopub.execute_input":"2021-06-24T19:23:41.820971Z","iopub.status.idle":"2021-06-24T19:27:03.332978Z","shell.execute_reply.started":"2021-06-24T19:23:41.820912Z","shell.execute_reply":"2021-06-24T19:27:03.332159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regressor CLassifier","metadata":{}},{"cell_type":"code","source":"# lr=LogisticRegression()\n# lr.fit(X_train_fit,y_train)\n\n# my_ans=[]\n# for row in range(test.shape[0]):\n#     comment=[test['comment_text'][row]]\n#     cmt=tfv.transform(comment)\n#     my_ans.append(lr.predict_proba(cmt)[:,1])\n\n# data={'id':[],\n#       'prediction':[]\n#      }\n# df=pd.DataFrame(data)\n\n# df['id']=test['id']\n\n# df['prediction']=pd.DataFrame(my_ans)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:18:20.731686Z","iopub.status.idle":"2021-06-24T19:18:20.732202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest CLassifier","metadata":{}},{"cell_type":"code","source":"randomforest = RandomForestClassifier(n_estimators=100,random_state=42)\nrandomforest.fit(X_train_fit,y_train)\n\nmy_ans=[]\nfor row in range(test.shape[0]):\n    comment=[test['comment_text'][row]]\n    cmt=tfv.transform(comment)\n    my_ans.append(randomforest.predict_proba(cmt)[:,1])\n\ndata={'id':[],\n      'prediction':[]\n     }\ndf=pd.DataFrame(data)\n\ndf['id']=test['id']\n\ndf['prediction']=pd.DataFrame(my_ans)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:18:20.73329Z","iopub.status.idle":"2021-06-24T19:18:20.733738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:27:30.036446Z","iopub.execute_input":"2021-06-24T19:27:30.03699Z","iopub.status.idle":"2021-06-24T19:27:30.270136Z","shell.execute_reply.started":"2021-06-24T19:27:30.036959Z","shell.execute_reply":"2021-06-24T19:27:30.268406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}