{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A loss function for the Jigsaw Unintended Bias in Toxicity Classification competition \n### (Public LB rank = 5)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport pandas as pd \nimport numpy as np\n\ndef convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)       \n    \ndef convert_dataframe_to_bool(df, columns):        \n    bool_df = df.copy()\n    for col in columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\naux_target_columns = ['sexual_explicit', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\nnum_identity = len(identity_columns)\n\ntrain = pd.read_csv('../input/train.csv')\ntrain.fillna(0, inplace = True)\ntrain = convert_dataframe_to_bool(train, ['target'] + identity_columns)\n\n\nweights = np.ones((len(train),))\n\n# Positive and negative examples get balanced weights in each part\n\n# These samples participate in the over all AUC term\nweights[train['target']]   =  1 / train['target'].sum()                \nweights[~train['target']]   =  1 / (~train['target']).sum()\nfor col in identity_columns:\n    hasIdentity = train[col]\n    # These samples participate in the subgroup AUC and BNSP terms    \n    weights[hasIdentity & train['target']]   +=  2 / (( hasIdentity &  train['target']).sum() * num_identity)\n    # These samples participate in the subgroup AUC and BPSN terms\n    weights[hasIdentity & ~train['target']]  +=  2 / (( hasIdentity & ~train['target']).sum() * num_identity)\n    # These samples participate in the BPSN term\n    weights[~hasIdentity & train['target']]  +=  1 / ((~hasIdentity &  train['target']).sum() * num_identity)\n    # These samples participate in the BNSP term\n    weights[~hasIdentity & ~train['target']] +=  1 / ((~hasIdentity & ~train['target']).sum() * num_identity)\n    \n    \n    \nweights = weights / weights.max()\n\n\ny_train = train['target'].values\ny_aux_train = train[aux_target_columns].values\ny_combined =  np.concatenate((y_train.reshape((-1, 1)), weights.reshape((-1, 1)), y_aux_train.reshape((-1, len(aux_target_columns)))), axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For loss weights, equal weights (both = 1) gave me the best results. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_loss(data, targets):    \n    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,1:2])(data[:,:1],targets[:,:1])\n    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,1:],targets[:,2:])\n    return (bce_loss_1 * 1) + (bce_loss_2 * 1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}