{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"bJc7aPazCJPl"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport pickle","metadata":{"id":"IRbqFedcHJqc","execution":{"iopub.status.busy":"2021-10-05T16:09:12.312408Z","iopub.execute_input":"2021-10-05T16:09:12.313129Z","iopub.status.idle":"2021-10-05T16:09:16.531535Z","shell.execute_reply.started":"2021-10-05T16:09:12.313034Z","shell.execute_reply":"2021-10-05T16:09:16.530734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and Preprocess Train and Test data","metadata":{"id":"Vuod4aDGCL1N"}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")\n# test_data = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\")","metadata":{"id":"qfjuFhElBj5A","execution":{"iopub.status.busy":"2021-10-05T16:09:34.924882Z","iopub.execute_input":"2021-10-05T16:09:34.92575Z","iopub.status.idle":"2021-10-05T16:09:57.711899Z","shell.execute_reply.started":"2021-10-05T16:09:34.925711Z","shell.execute_reply":"2021-10-05T16:09:57.711143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning","metadata":{}},{"cell_type":"code","source":"train_data['comment_text'] = train_data['comment_text'].astype(str) \n# test_data['comment_text'] = test_data['comment_text'].astype(str) ","metadata":{"id":"Z6q6zIuXCSHb","execution":{"iopub.status.busy":"2021-10-05T16:09:57.713431Z","iopub.execute_input":"2021-10-05T16:09:57.713709Z","iopub.status.idle":"2021-10-05T16:09:57.983767Z","shell.execute_reply.started":"2021-10-05T16:09:57.713672Z","shell.execute_reply":"2021-10-05T16:09:57.982964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']","metadata":{"id":"nAeO57kVCUVv","execution":{"iopub.status.busy":"2021-10-05T16:09:57.985135Z","iopub.execute_input":"2021-10-05T16:09:57.985425Z","iopub.status.idle":"2021-10-05T16:09:57.989924Z","shell.execute_reply.started":"2021-10-05T16:09:57.985385Z","shell.execute_reply":"2021-10-05T16:09:57.989054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n    \ndef convert_dataframe_to_bool(df):\n    bool_df = df.copy()\n    for col in ['target'] + identity_columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\ntrain_data = convert_dataframe_to_bool(train_data)","metadata":{"id":"y71beJPbCUPC","execution":{"iopub.status.busy":"2021-10-05T16:10:04.468615Z","iopub.execute_input":"2021-10-05T16:10:04.469538Z","iopub.status.idle":"2021-10-05T16:10:06.000413Z","shell.execute_reply.started":"2021-10-05T16:10:04.469489Z","shell.execute_reply":"2021-10-05T16:10:05.999637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train CV Split","metadata":{"id":"YXjJ1jpCCmFw"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, validate_df = train_test_split(train_data, test_size=0.2)\nprint('%d train comments, %d validate comments' % (len(train_df), len(validate_df)))","metadata":{"id":"JeEPG5GvBtqv","outputId":"ffc260c4-c698-44c5-9b26-2ed196a591c8","execution":{"iopub.status.busy":"2021-10-05T16:10:07.060469Z","iopub.execute_input":"2021-10-05T16:10:07.06132Z","iopub.status.idle":"2021-10-05T16:10:09.086874Z","shell.execute_reply.started":"2021-10-05T16:10:07.061247Z","shell.execute_reply":"2021-10-05T16:10:09.086083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer and Embedding Matrix","metadata":{"id":"lnTc1ibYEa6j"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, Conv1D, MaxPool1D, Dense, Dropout, Flatten, Embedding, concatenate, LSTM, BatchNormalization\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:23:11.814961Z","iopub.execute_input":"2021-10-05T16:23:11.815234Z","iopub.status.idle":"2021-10-05T16:23:11.82079Z","shell.execute_reply.started":"2021-10-05T16:23:11.815204Z","shell.execute_reply":"2021-10-05T16:23:11.819975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train tokenizer, only on training data\nMAX_VOCAB_SIZE = 10000\ntokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\ntokenizer.fit_on_texts(train_df['comment_text'])\n\nMAX_SEQUENCE_LENGTH = 250\ndef pad_text(texts, tokenizer):\n    return pad_sequences(tokenizer.texts_to_sequences(texts), maxlen=MAX_SEQUENCE_LENGTH)","metadata":{"id":"fGL7lcSpBtn2","execution":{"iopub.status.busy":"2021-10-05T16:10:21.330903Z","iopub.execute_input":"2021-10-05T16:10:21.331765Z","iopub.status.idle":"2021-10-05T16:11:30.34149Z","shell.execute_reply.started":"2021-10-05T16:10:21.331717Z","shell.execute_reply":"2021-10-05T16:11:30.340734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Loss and Utility Function","metadata":{}},{"cell_type":"code","source":"def custom_loss(y_true,y_pred):\n    #class 0\n    loss1 = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)(y_true[:,:1],y_pred[:,:1])\n    #class 1\n    loss2 = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)(y_true[:,1:],y_pred[:,1:])\n    \n    return (loss1*1+loss2*1)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:12:46.883597Z","iopub.execute_input":"2021-10-05T16:12:46.884143Z","iopub.status.idle":"2021-10-05T16:12:46.890306Z","shell.execute_reply.started":"2021-10-05T16:12:46.8841Z","shell.execute_reply":"2021-10-05T16:12:46.889544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-10-05T18:13:40.089158Z","iopub.execute_input":"2021-10-05T18:13:40.089545Z","iopub.status.idle":"2021-10-05T18:13:41.102595Z","shell.execute_reply.started":"2021-10-05T18:13:40.089457Z","shell.execute_reply":"2021-10-05T18:13:41.101519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]\n    predicted_labels = df[model_name]\n    return roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:12:47.16115Z","iopub.execute_input":"2021-10-05T16:12:47.161517Z","iopub.status.idle":"2021-10-05T16:12:47.175797Z","shell.execute_reply.started":"2021-10-05T16:12:47.161485Z","shell.execute_reply":"2021-10-05T16:12:47.175048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Simple CNN + Custom Loss","metadata":{}},{"cell_type":"code","source":"EMBEDDINGS_PATH = '../input/glove6b/glove.6B.200d.txt'\nEMBEDDINGS_DIMENSION = 200\nDROPOUT_RATE = 0.5\nLEARNING_RATE = 0.00001\nNUM_EPOCHS = 10\nBATCH_SIZE = 128\nTEXT_COLUMN='comment_text'\nTOXICITY_COLUMN='target'","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:25:23.367142Z","iopub.execute_input":"2021-10-05T16:25:23.367708Z","iopub.status.idle":"2021-10-05T16:25:23.373103Z","shell.execute_reply.started":"2021-10-05T16:25:23.367672Z","shell.execute_reply":"2021-10-05T16:25:23.371292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embedding_matrix(train_df, validate_df):\n    print(\"Padding tokenized sequences...\")\n    train_text = pad_text(train_df[TEXT_COLUMN], tokenizer)\n    train_labels = to_categorical(train_df[TOXICITY_COLUMN])\n    validate_text = pad_text(validate_df[TEXT_COLUMN], tokenizer)\n    validate_labels = to_categorical(validate_df[TOXICITY_COLUMN])\n    \n    print(\"Loading Embeddings...\")\n    # Create word to embedding vector dictionary\n    embeddings_index={}\n    with open(EMBEDDINGS_PATH) as f:\n        for line in f:\n            values = line.split()\n            word = values[0]\n            coefs = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = coefs\n    \n    # Create embedding matrix with all 0\n    embedding_matrix = np.zeros((len(tokenizer.word_index)+1,EMBEDDINGS_DIMENSION))\n    \n    # Update matrix\n    for word, i in tokenizer.word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    return train_text, train_labels, validate_text, validate_labels,embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:33:56.948736Z","iopub.execute_input":"2021-10-05T16:33:56.949373Z","iopub.status.idle":"2021-10-05T16:33:56.957181Z","shell.execute_reply.started":"2021-10-05T16:33:56.949336Z","shell.execute_reply":"2021-10-05T16:33:56.956432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text, train_labels, validate_text, validate_labels,embedding_matrix = get_embedding_matrix(train_df, validate_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:34:00.420956Z","iopub.execute_input":"2021-10-05T16:34:00.42144Z","iopub.status.idle":"2021-10-05T16:36:09.491074Z","shell.execute_reply.started":"2021-10-05T16:34:00.421401Z","shell.execute_reply":"2021-10-05T16:36:09.490316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def modelone_architecture(embedding_matrix):\n    '''Returns model'''\n    input_layer = Input(shape=(MAX_SEQUENCE_LENGTH), dtype='int32')\n    embedding_layer = Embedding(len(tokenizer.word_index)+1, EMBEDDINGS_DIMENSION, \\\n                                weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH,\\\n                               trainable=False)(input_layer)\n    conv_layer_1 = Conv1D(128, 2, activation='relu', padding='same')(embedding_layer)\n    max_pool_1 = MaxPool1D(5, padding='same')(conv_layer_1)\n    conv_layer_2 = Conv1D(128, 3, activation='relu', padding='same')(max_pool_1)\n    max_pool_2 = MaxPool1D(5, padding='same')(conv_layer_2)\n    conv_layer_3 = Conv1D(128, 4, activation='relu', padding='same')(max_pool_2)\n    max_pool_3 = MaxPool1D(40, padding='same')(conv_layer_3)\n    flat_layer = Flatten()(max_pool_3)\n    drop_layer = Dropout(DROPOUT_RATE)(flat_layer)\n    dense_layer = Dense(128, activation='relu')(drop_layer)\n    output_layer = Dense(2, activation='softmax')(dense_layer)\n    \n    model = Model(input_layer, output_layer)\n    model.summary()\n    dot_img_file = './model_1.png'\n    tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:36:09.492867Z","iopub.execute_input":"2021-10-05T16:36:09.493136Z","iopub.status.idle":"2021-10-05T16:36:09.503804Z","shell.execute_reply.started":"2021-10-05T16:36:09.493103Z","shell.execute_reply":"2021-10-05T16:36:09.503138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train_text, train_labels, validate_text, validate_labels, model):\n    \n    # model architecture is passed in function argument\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    print(\"Training model now...\")\n    model.fit(train_text,\n              train_labels,\n              batch_size=BATCH_SIZE,\n              epochs=NUM_EPOCHS,\n              validation_data=(validate_text, validate_labels),\n              verbose=2)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:03:32.266703Z","iopub.execute_input":"2021-10-05T17:03:32.267172Z","iopub.status.idle":"2021-10-05T17:03:32.272136Z","shell.execute_reply.started":"2021-10-05T17:03:32.267134Z","shell.execute_reply":"2021-10-05T17:03:32.271484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call architecture\nmodel_1_arch = modelone_architecture(embedding_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:36:09.519713Z","iopub.execute_input":"2021-10-05T16:36:09.520339Z","iopub.status.idle":"2021-10-05T16:36:11.042696Z","shell.execute_reply.started":"2021-10-05T16:36:09.520306Z","shell.execute_reply":"2021-10-05T16:36:11.041739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train\nmodel_1 = train_model(train_text, train_labels, validate_text, validate_labels, model_1_arch)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:03:37.62164Z","iopub.execute_input":"2021-10-05T17:03:37.622337Z","iopub.status.idle":"2021-10-05T17:25:09.449082Z","shell.execute_reply.started":"2021-10-05T17:03:37.622293Z","shell.execute_reply":"2021-10-05T17:25:09.448355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = 'model_1'\nvalidate_df[MODEL_NAME] = model_1.predict(pad_text(validate_df[TEXT_COLUMN], tokenizer))[:, 1]","metadata":{"id":"3cLGoK5WPXb_","execution":{"iopub.status.busy":"2021-10-05T17:26:01.736124Z","iopub.execute_input":"2021-10-05T17:26:01.736713Z","iopub.status.idle":"2021-10-05T17:26:48.006929Z","shell.execute_reply.started":"2021-10-05T17:26:01.736675Z","shell.execute_reply":"2021-10-05T17:26:48.006171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bias_metrics_df = compute_bias_metrics_for_model(validate_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\nbias_metrics_df","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:26:55.26462Z","iopub.execute_input":"2021-10-05T17:26:55.265344Z","iopub.status.idle":"2021-10-05T17:26:58.596839Z","shell.execute_reply.started":"2021-10-05T17:26:55.26529Z","shell.execute_reply":"2021-10-05T17:26:58.596015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_final_metric(bias_metrics_df, calculate_overall_auc(validate_df, MODEL_NAME)))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:27:05.532086Z","iopub.execute_input":"2021-10-05T17:27:05.532365Z","iopub.status.idle":"2021-10-05T17:27:05.637929Z","shell.execute_reply.started":"2021-10-05T17:27:05.532335Z","shell.execute_reply":"2021-10-05T17:27:05.637169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\nsubmission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:29:31.134544Z","iopub.execute_input":"2021-10-05T17:29:31.135288Z","iopub.status.idle":"2021-10-05T17:29:31.543769Z","shell.execute_reply.started":"2021-10-05T17:29:31.135237Z","shell.execute_reply":"2021-10-05T17:29:31.543063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['prediction'] = model_1.predict(pad_text(test[TEXT_COLUMN], tokenizer))[:, 1]\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:30:43.636094Z","iopub.execute_input":"2021-10-05T17:30:43.636683Z","iopub.status.idle":"2021-10-05T17:30:56.226304Z","shell.execute_reply.started":"2021-10-05T17:30:43.636645Z","shell.execute_reply":"2021-10-05T17:30:56.225567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}