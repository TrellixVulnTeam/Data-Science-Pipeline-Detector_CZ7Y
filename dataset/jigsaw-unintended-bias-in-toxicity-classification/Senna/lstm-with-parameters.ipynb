{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['glove840b300dtxt', 'fasttext-crawl-300d-2m', 'jigsaw-unintended-bias-in-toxicity-classification']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nimport gc\nimport random\nfrom tqdm._tqdm_notebook import tqdm_notebook as tqdm\nfrom keras.preprocessing import text, sequence\nimport torch\nfrom torch import nn\nfrom torch.utils import data\nfrom torch.nn import functional as F\nfrom fastai.train import Learner\nfrom fastai.train import DataBunch\nfrom fastai.callbacks import *\nfrom fastai.basic_data import DatasetType","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_interactive():\n   return 'SHLVL' not in os.environ\n\nif not is_interactive():\n    def nop(it, *a, **k):\n        return it\n\n    tqdm = nop","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=123):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\nGLOVE_EMBEDDING_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\nNUM_MODELS = 2\nLSTM_UNITS = 128\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nMAX_LEN = 220","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    unknown_words = []\n    \n    for word, i in word_index.items():\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            unknown_words.append(word)\n    return embedding_matrix, unknown_words","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1 + np.exp(-x))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(learn,test,output_dim,lr=0.0003,\n                batch_size=512, n_epochs=8,\n                enable_checkpoint_ensemble=True):\n    \n    all_test_preds = []\n    checkpoint_weights = [2 ** epoch for epoch in range(n_epochs)]\n    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n    n = len(learn.data.train_dl)\n    phases = [(TrainingPhase(n).schedule_hp('lr', lr * (0.6**(i)))) for i in range(n_epochs)]\n    sched = GeneralScheduler(learn, phases)\n    learn.callbacks.append(sched)\n    for epoch in range(n_epochs):\n        learn.fit(1)\n        test_preds = np.zeros((len(test), output_dim))    \n        for i, x_batch in enumerate(test_loader):\n            X = x_batch[0].cuda()\n            y_pred = sigmoid(learn.model(X).detach().cpu().numpy())\n            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred\n\n        all_test_preds.append(test_preds)\n\n\n    if enable_checkpoint_ensemble:\n        test_preds = np.average(all_test_preds, weights=checkpoint_weights, axis=0)    \n    else:\n        test_preds = all_test_preds[-1]\n        \n    return test_preds","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SpatialDropout(nn.Dropout2d):\n    def forward(self, x):\n        x = x.unsqueeze(2)    # (N, T, 1, K)\n        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n        x = x.squeeze(2)  # (N, T, K)\n        return x","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, embedding_matrix, num_aux_targets):\n        super(NeuralNet, self).__init__()\n        embed_size = embedding_matrix.shape[1]\n        \n        self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        self.embedding_dropout = SpatialDropout(0.3)\n        \n        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n    \n        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        \n        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n        \n    def forward(self, x):\n        h_embedding = self.embedding(x)\n        h_embedding = self.embedding_dropout(h_embedding)\n        \n        h_lstm1, _ = self.lstm1(h_embedding)\n        h_lstm2, _ = self.lstm2(h_lstm1)\n        \n        # global average pooling\n        avg_pool = torch.mean(h_lstm2, 1)\n        # global max pooling\n        max_pool, _ = torch.max(h_lstm2, 1)\n        \n        h_conc = torch.cat((max_pool, avg_pool), 1)\n        h_conc_linear1  = F.relu(self.linear1(h_conc))\n        h_conc_linear2  = F.relu(self.linear2(h_conc))\n        \n        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n        \n        result = self.linear_out(hidden)\n        aux_result = self.linear_aux_out(hidden)\n        out = torch.cat([result, aux_result], 1)\n        \n        return out\n        \ndef preprocess(data):\n    '''\n    Credit goes to \n    https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n    '''\n    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n    def clean_special_chars(text, punct):\n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n    return data","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n\nx_train = preprocess(train['comment_text'])\ny_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\nx_test = preprocess(test['comment_text'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = np.ones((len(x_train),)) / 4\n# Subgroup\nweights += (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n# Background Positive, Subgroup Negative\nweights += (( (train['target'].values>=0.5).astype(bool).astype(np.int) +\n   (train[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n# Background Negative, Subgroup Positive\nweights += (( (train['target'].values<0.5).astype(bool).astype(np.int) +\n   (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\nloss_weight = 1.0 / weights.mean()\ny_train = np.vstack([(train['target'].values>=0.5).astype(np.int),weights]).T\nmax_features = None\ntokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(list(x_train) + list(x_test))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\nx_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\nx_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = max_features or len(tokenizer.word_index) + 1\ncrawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\nprint('n unknown words (crawl): ', len(unknown_words_crawl))\nglove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\nprint('n unknown words (glove): ', len(unknown_words_glove))","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c400af86eed444b19d6a7d4b87f1883f"}},"metadata":{}},{"output_type":"stream","text":"\nn unknown words (crawl):  174141\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f783f166546a4e55a24b7bad98c01d83"}},"metadata":{}},{"output_type":"stream","text":"\nn unknown words (glove):  170837\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.concatenate([crawl_matrix, glove_matrix], axis=-1)\nembedding_matrix.shape\n\ndel crawl_matrix\ndel glove_matrix\ngc.collect()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_torch = torch.tensor(x_train, dtype=torch.long)\ny_train_torch = torch.tensor(np.hstack([y_train, y_aux_train]), dtype=torch.float32)\n\nx_test_torch = torch.tensor(x_test, dtype=torch.long)\n\nbatch_size = 512\n\ntrain_dataset = data.TensorDataset(x_train_torch, y_train_torch)\nvalid_dataset = data.TensorDataset(x_train_torch[:batch_size], y_train_torch[:batch_size])\ntest_dataset = data.TensorDataset(x_test_torch)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n\ndatabunch = DataBunch(train_dl=train_loader,valid_dl=valid_loader)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_loss(data, targets):\n    ''' Define custom loss function for weighted BCE on 'target' column '''\n    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,1:2])(data[:,:1],targets[:,:1])\n    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,1:],targets[:,2:])\n    return (bce_loss_1 * loss_weight) + bce_loss_2\n    \nall_test_preds = []\n\nfor model_idx in range(NUM_MODELS):\n    print('Model ', model_idx)\n    seed_everything(1 + model_idx)\n    model = NeuralNet(embedding_matrix, y_aux_train.shape[-1])\n    learn = Learner(databunch,model,loss_func=custom_loss)\n    test_preds = train_model(learn,test_dataset,output_dim=7)    \n    all_test_preds.append(test_preds)","execution_count":19,"outputs":[{"output_type":"stream","text":"Model  0\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.289986</td>\n      <td>0.145225</td>\n      <td>09:49</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.281813</td>\n      <td>0.153291</td>\n      <td>09:47</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.267938</td>\n      <td>0.147399</td>\n      <td>09:45</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.267940</td>\n      <td>0.143589</td>\n      <td>09:46</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.256947</td>\n      <td>0.145207</td>\n      <td>09:45</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.259090</td>\n      <td>0.147103</td>\n      <td>09:46</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.261098</td>\n      <td>0.138380</td>\n      <td>09:45</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.249610</td>\n      <td>0.139805</td>\n      <td>09:44</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"stream","text":"Model  1\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.289747</td>\n      <td>0.167170</td>\n      <td>09:43</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.273270</td>\n      <td>0.155686</td>\n      <td>09:45</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.266323</td>\n      <td>0.147469</td>\n      <td>09:46</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.278026</td>\n      <td>0.147128</td>\n      <td>09:44</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.263540</td>\n      <td>0.147214</td>\n      <td>09:43</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.259753</td>\n      <td>0.140327</td>\n      <td>09:41</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.256243</td>\n      <td>0.148477</td>\n      <td>09:43</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.250917</td>\n      <td>0.142403</td>\n      <td>09:41</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame.from_dict({\n    'id': test['id'],\n    'prediction': np.mean(all_test_preds, axis=0)[:, 0]})\nsubmission.to_csv('submission.csv', index=False)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"            id  prediction\n0      7000000    0.006312\n1      7000001    0.000077\n2      7000002    0.006003\n3      7000003    0.002958\n4      7000004    0.982301\n5      7000005    0.000083\n6      7000006    0.002432\n7      7000007    0.011392\n8      7000008    0.011611\n9      7000009    0.008347\n10     7000010    0.002668\n11     7000011    0.338563\n12     7000012    0.000175\n13     7000013    0.000190\n14     7000014    0.000739\n15     7000015    0.000487\n16     7000016    0.047822\n17     7000017    0.001467\n18     7000018    0.489628\n19     7000019    0.031217\n20     7000020    0.003596\n21     7000021    0.000380\n22     7000022    0.000129\n23     7000023    0.641345\n24     7000024    0.965211\n25     7000025    0.000712\n26     7000026    0.128955\n27     7000027    0.000531\n28     7000028    0.000465\n29     7000029    0.005135\n...        ...         ...\n97290  7097290    0.001888\n97291  7097291    0.525168\n97292  7097292    0.209121\n97293  7097293    0.000037\n97294  7097294    0.000653\n97295  7097295    0.001044\n97296  7097296    0.000234\n97297  7097297    0.000453\n97298  7097298    0.000473\n97299  7097299    0.024547\n97300  7097300    0.000870\n97301  7097301    0.004580\n97302  7097302    0.000186\n97303  7097303    0.000278\n97304  7097304    0.255317\n97305  7097305    0.247524\n97306  7097306    0.001516\n97307  7097307    0.000083\n97308  7097308    0.016587\n97309  7097309    0.010332\n97310  7097310    0.011419\n97311  7097311    0.004737\n97312  7097312    0.204543\n97313  7097313    0.067787\n97314  7097314    0.001962\n97315  7097315    0.004501\n97316  7097316    0.000037\n97317  7097317    0.007629\n97318  7097318    0.127937\n97319  7097319    0.000798\n\n[97320 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7000000</td>\n      <td>0.006312</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7000001</td>\n      <td>0.000077</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7000002</td>\n      <td>0.006003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7000003</td>\n      <td>0.002958</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7000004</td>\n      <td>0.982301</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7000005</td>\n      <td>0.000083</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7000006</td>\n      <td>0.002432</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7000007</td>\n      <td>0.011392</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7000008</td>\n      <td>0.011611</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7000009</td>\n      <td>0.008347</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7000010</td>\n      <td>0.002668</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7000011</td>\n      <td>0.338563</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7000012</td>\n      <td>0.000175</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7000013</td>\n      <td>0.000190</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7000014</td>\n      <td>0.000739</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>7000015</td>\n      <td>0.000487</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>7000016</td>\n      <td>0.047822</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>7000017</td>\n      <td>0.001467</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>7000018</td>\n      <td>0.489628</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>7000019</td>\n      <td>0.031217</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>7000020</td>\n      <td>0.003596</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>7000021</td>\n      <td>0.000380</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>7000022</td>\n      <td>0.000129</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>7000023</td>\n      <td>0.641345</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>7000024</td>\n      <td>0.965211</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>7000025</td>\n      <td>0.000712</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>7000026</td>\n      <td>0.128955</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>7000027</td>\n      <td>0.000531</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>7000028</td>\n      <td>0.000465</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>7000029</td>\n      <td>0.005135</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97290</th>\n      <td>7097290</td>\n      <td>0.001888</td>\n    </tr>\n    <tr>\n      <th>97291</th>\n      <td>7097291</td>\n      <td>0.525168</td>\n    </tr>\n    <tr>\n      <th>97292</th>\n      <td>7097292</td>\n      <td>0.209121</td>\n    </tr>\n    <tr>\n      <th>97293</th>\n      <td>7097293</td>\n      <td>0.000037</td>\n    </tr>\n    <tr>\n      <th>97294</th>\n      <td>7097294</td>\n      <td>0.000653</td>\n    </tr>\n    <tr>\n      <th>97295</th>\n      <td>7097295</td>\n      <td>0.001044</td>\n    </tr>\n    <tr>\n      <th>97296</th>\n      <td>7097296</td>\n      <td>0.000234</td>\n    </tr>\n    <tr>\n      <th>97297</th>\n      <td>7097297</td>\n      <td>0.000453</td>\n    </tr>\n    <tr>\n      <th>97298</th>\n      <td>7097298</td>\n      <td>0.000473</td>\n    </tr>\n    <tr>\n      <th>97299</th>\n      <td>7097299</td>\n      <td>0.024547</td>\n    </tr>\n    <tr>\n      <th>97300</th>\n      <td>7097300</td>\n      <td>0.000870</td>\n    </tr>\n    <tr>\n      <th>97301</th>\n      <td>7097301</td>\n      <td>0.004580</td>\n    </tr>\n    <tr>\n      <th>97302</th>\n      <td>7097302</td>\n      <td>0.000186</td>\n    </tr>\n    <tr>\n      <th>97303</th>\n      <td>7097303</td>\n      <td>0.000278</td>\n    </tr>\n    <tr>\n      <th>97304</th>\n      <td>7097304</td>\n      <td>0.255317</td>\n    </tr>\n    <tr>\n      <th>97305</th>\n      <td>7097305</td>\n      <td>0.247524</td>\n    </tr>\n    <tr>\n      <th>97306</th>\n      <td>7097306</td>\n      <td>0.001516</td>\n    </tr>\n    <tr>\n      <th>97307</th>\n      <td>7097307</td>\n      <td>0.000083</td>\n    </tr>\n    <tr>\n      <th>97308</th>\n      <td>7097308</td>\n      <td>0.016587</td>\n    </tr>\n    <tr>\n      <th>97309</th>\n      <td>7097309</td>\n      <td>0.010332</td>\n    </tr>\n    <tr>\n      <th>97310</th>\n      <td>7097310</td>\n      <td>0.011419</td>\n    </tr>\n    <tr>\n      <th>97311</th>\n      <td>7097311</td>\n      <td>0.004737</td>\n    </tr>\n    <tr>\n      <th>97312</th>\n      <td>7097312</td>\n      <td>0.204543</td>\n    </tr>\n    <tr>\n      <th>97313</th>\n      <td>7097313</td>\n      <td>0.067787</td>\n    </tr>\n    <tr>\n      <th>97314</th>\n      <td>7097314</td>\n      <td>0.001962</td>\n    </tr>\n    <tr>\n      <th>97315</th>\n      <td>7097315</td>\n      <td>0.004501</td>\n    </tr>\n    <tr>\n      <th>97316</th>\n      <td>7097316</td>\n      <td>0.000037</td>\n    </tr>\n    <tr>\n      <th>97317</th>\n      <td>7097317</td>\n      <td>0.007629</td>\n    </tr>\n    <tr>\n      <th>97318</th>\n      <td>7097318</td>\n      <td>0.127937</td>\n    </tr>\n    <tr>\n      <th>97319</th>\n      <td>7097319</td>\n      <td>0.000798</td>\n    </tr>\n  </tbody>\n</table>\n<p>97320 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}