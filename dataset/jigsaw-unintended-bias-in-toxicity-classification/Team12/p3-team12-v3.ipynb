{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['test.csv', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntrain_df = train_df[['id','comment_text', 'target']]\ntest_df = pd.read_csv(\"../input/test.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\")\ndef stemming(sentence):\n    stemSentence = \"\"\n    for word in sentence.split():\n        stem = stemmer.stem(word)\n        stemSentence += stem\n        stemSentence += \" \"\n    stemSentence = stemSentence.strip()\n    return stemSentence\n  \ntrain_df['comment_text'] = train_df['comment_text'].apply(stemming)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport re, string\nre_tok = re.compile(f'([{string.punctuation}])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n\nvect = TfidfVectorizer(input=\"content\", \n                encoding=\"utf-8\", \n                decode_error=\"strict\", \n                strip_accents=\"unicode\", \n                lowercase=True, \n                preprocessor=None, \n                tokenizer=tokenize, \n                analyzer=\"word\", \n                stop_words=None, \n                token_pattern=\"(?u)\\b\\w\\w+\\b\", \n                ngram_range=(1, 2), \n                max_df=0.9, \n                min_df=3, \n                max_features=None, \n                vocabulary=None, \n                binary=False, \n                norm=\"l2\", \n                use_idf=1, \n                smooth_idf=1, \n                sublinear_tf=1)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = vect.fit_transform(train_df[\"comment_text\"])\ny = np.where(train_df['target'] >= 0.5, 1, 0)\n\ntest_X = vect.transform(test_df[\"comment_text\"])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier  \n\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.333, random_state=42)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(penalty=\"l2\", \n                                             dual=False, \n                                             tol=0.0001, \n                                             C=1.0, \n                                             fit_intercept=True, \n                                             intercept_scaling=1, \n                                             class_weight=\"balanced\", \n                                             random_state=None, \n                                             solver=\"liblinear\", \n                                             max_iter=100, \n                                             multi_class=\"auto\", \n                                             verbose=0, \n                                             warm_start=False, \n                                             n_jobs=None)\n\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)","execution_count":8,"outputs":[{"output_type":"stream","text":"CPU times: user 4min 47s, sys: 868 ms, total: 4min 48s\nWall time: 4min 48s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_accuracy = cross_val_score(\n    LogisticRegression(C=5, random_state=42, solver='sag', max_iter=1000, n_jobs=-1), \n    X, y, cv=5, scoring='roc_auc'\n)\nprint(cv_accuracy)\nprint(cv_accuracy.mean())","execution_count":9,"outputs":[{"output_type":"stream","text":"[0.94640949 0.94477916 0.94682231 0.94477415 0.94504039]\n0.9455650988687235\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, y_pred)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"0.9202377941646257"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = lr.predict_proba(test_X)[:,1]","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['prediction'] = prediction\nsubmission.to_csv('submission.csv', index=False)","execution_count":12,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}