{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A simple Keras based bidirectional LSTM with self-attention ready for tuning!"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing.text import one_hot, Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import *\nfrom keras.layers.embeddings import Embedding\nfrom keras.models import Sequential\nimport pyprind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://pypi.org/project/keras-self-attention/\nimport sys\nsys.path.insert(0, '../input/attention')\nfrom seq_self_attention import SeqSelfAttention","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainig_sample = df.sample(100000, random_state=0)\nX_train = trainig_sample['comment_text'].astype(str)\nX_train = X_train.fillna('DUMMY')\ny_train = trainig_sample['target']\ny_train = y_train.apply(lambda x: 1 if x > 0.5 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_num_words = 20000\nmax_length = 128\ntokenizer = Tokenizer(num_words=max_num_words)\ntokenizer.fit_on_texts(X_train)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_seqs(text):\n    sequences = tokenizer.texts_to_sequences(text)\n    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n    return padded_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_num_words, 100, input_length=max_length))\nmodel.add(Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\nmodel.add(SeqSelfAttention(attention_activation='sigmoid'))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(get_seqs(X_train), y_train, epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_sample = df.sample(500, random_state=42)\nX_val = validation_sample['comment_text'].astype(str)\nX_val = X_val.fillna('DUMMY')\ny_val = validation_sample['target']\ny_val = y_val.apply(lambda x: 1 if x > 0.5 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(get_seqs(X_val), y_val)\nprint('Evaluation accuracy: {0}'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test['comment_text'].astype(str)\nX_test = X_test.fillna('DUMMY')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = model.predict(get_seqs(X_test), verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = [x[0] for x in probs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(test['id']).reset_index(drop=True)\nsubmission['prediction'] = pd.Series(probs, name='prediction')\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}