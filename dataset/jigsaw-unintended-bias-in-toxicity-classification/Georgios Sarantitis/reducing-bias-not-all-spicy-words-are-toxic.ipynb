{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is inspired from the extended word-to-word analysis of Deep_patience (https://www.kaggle.com/aisaactirona/cudnnlstm-cudnngru). I just wanted to point out that some of the words that could pertain to toxic sentences, do not necessarily do so. I give some example below, however more words can be found in a more extended search.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os ","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets keep only Comments and their toxicity 'level'"},{"metadata":{"trusted":true},"cell_type":"code","source":"comment_only = train[['comment_text', 'target']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example Word 1: 'Sex' "},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_comments = comment_only[comment_only['comment_text'].str.contains('sex')]\nprint(\"Mean toxicity of word 'Sex': {}\".format(np.round(sex_comments['target'].mean(),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(sex_comments['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example Word 2: 'damn' "},{"metadata":{"trusted":true},"cell_type":"code","source":"damn_comments = comment_only[comment_only['comment_text'].str.contains('damn')]\nprint(\"Mean toxicity of word 'damn': {}\".format(np.round(damn_comments['target'].mean(),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(damn_comments['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"god_comments = comment_only[comment_only['comment_text'].str.contains('God')]\nprint(\"Mean toxicity of word 'God': {}\".format(np.round(god_comments['target'].mean(),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(god_comments['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"porn_comments = comment_only[comment_only['comment_text'].str.contains('porn')]\nprint(\"Mean toxicity of word 'porn': {}\".format(np.round(porn_comments['target'].mean(),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(porn_comments['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets also include something sure toxic for sanity check :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"asshole_comments = comment_only[comment_only['comment_text'].str.contains('asshole')]\nprint(\"Mean toxicity of word 'asshole': {}\".format(np.round(asshole_comments['target'].mean(),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Right, so that concludes this quick analysis on bias on toxic terms. I hope it helps for model tuning!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}