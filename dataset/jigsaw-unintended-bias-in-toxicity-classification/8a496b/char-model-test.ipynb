{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard.notebook\n# %reload_ext tensorboard.notebook\n%tensorboard --logdir \"/kaggle/working/logs\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport sys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reducing dataframe : https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train = pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ndf_train = import_data('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.comment_text.apply(len).plot.hist(bins = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.comment_text.apply(lambda x : len(x.split())).plot.hist(bins = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 특문, 영어 대문자, 영어 소문자\n\nchar_list = [chr(char) for char in range(32, 127)]\nchar_list = [\"<UNK>\", \"<PAD>\"] + char_list\n\nchar2id = {char : idx for idx, char in enumerate(char_list)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def making_char_vector(input_text, max_char = 64):\n    if len(input_text) < max_char:\n        return([1] * (max_char - len(input_text)) + [char2id.get(char,0) for char in input_text.lower()[:max_char]])\n    else:\n        return([char2id.get(char,0) for char in input_text.lower()[:max_char]])\n\ndef printing_char_vector(char_vector):\n    return(\"\".join([char_list[char] for char in char_vector if char != 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printing_char_vector(making_char_vector(df_train.comment_text[0], 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making dataset\nfrom torch.utils.data import Dataset\n\nclass MakingDataset(Dataset):\n    def __init__(self, input_dataframe, max_char, is_it_test = False):\n        self.is_it_test = is_it_test\n        self.text_array = np.array([making_char_vector(text, max_char) for text in input_dataframe.comment_text])\n        if not is_it_test:\n            self.toxicity_array = np.array([int(toxicity >= 0.5) for toxicity in input_dataframe.target]) \n        \n    def __len__(self):\n        return len(self.text_array)\n\n    def __getitem__(self, data_index):\n        if not self.is_it_test:\n            return self.text_array[data_index], self.toxicity_array[data_index]\n        else:\n            return self.text_array[data_index]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making model\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass CharNet(nn.Module):\n    def __init__(self, max_char, emb_dim, nb_cls):\n        super(CharNet, self).__init__()\n        self.char_emb = nn.Embedding(len(char2id), emb_dim)\n        self.weight_char_emb = nn.Parameter(torch.randn(size = (max_char,)))\n        self.fc1 = nn.Linear(emb_dim, nb_cls)\n\n\n    def forward(self, input_x):\n        emb_x = self.char_emb(input_x)\n        w_avg_x = torch.einsum('bme, m-> be', [emb_x, self.weight_char_emb])\n        score = self.fc1(w_avg_x).squeeze(1)\n        return score\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\nmax_char = 100\n\ntrain_set = MakingDataset(input_dataframe = df_train.iloc[:int(df_train.shape[0] * 0.8)], max_char = max_char)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n\nval_set = MakingDataset(input_dataframe = df_train.iloc[int(df_train.shape[0] * 0.8):], max_char = max_char)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = CharNet(max_char = max_char, emb_dim = 200, nb_cls = 2)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnet.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lossfn = nn.CrossEntropyLoss(weight=torch.tensor([0.08,0.92]).to(device))\noptimizer = torch.optim.Adam(net.parameters(), lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_epoch = 10\n\ntr_index_list =[]\ntr_loss_list = []\ntr_acc_list= []\nval_loss_list= []\nval_acc_list = []\n\nfor idx_epoch in range(max_epoch):\n    net.train()\n    running_loss = 0.0\n    running_acc = 0.0\n    \n    for idx_iter, data in enumerate(train_loader):\n        text, labels = data\n        text = text.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = net(text)\n        loss = lossfn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        predicted = torch.max(outputs.data, 1)[1]\n        correct = (predicted == labels).sum().item()\n        acc = correct / batch_size\n            \n        running_acc += acc\n        \n        if idx_iter % 10 == 9:    # print every 2000 mini-batches\n            \n            sys.stdout.write(\n                \"\\r\" + '[%d, %5d] loss: %.5f acc : %.4f' %\n                  (idx_epoch + 1, idx_iter + 1, running_loss / 10, running_acc / 10))\n            \n            tr_index_list.append(idx_iter + 1)\n            tr_loss_list.append(running_loss / 10)\n            tr_acc_list.append(running_acc / 10)\n            \n            running_loss = 0.0\n            running_acc = 0.0\n            \n    net.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for idx, data in enumerate(val_loader):\n            text, labels = data\n            text = text.to(device)\n            labels = labels.to(device)\n            \n            outputs = net(text)\n            loss = lossfn(outputs, labels)\n            running_loss += loss\n            \n            predicted = torch.max(outputs.data, 1)[1]\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n        running_loss /= (idx + 1)\n        acc = correct / total\n        \n        val_loss_list.append(running_loss)\n        val_acc_list.append(acc)\n        \n        print(f\"\\n[Val] {idx_epoch+1}-Epoch Loss : {running_loss:.4f}, Acc : {acc:.4f}\")\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making df_val without shuffle\ndf_val = df_train.iloc[int(df_train.shape[0] * 0.8):].reset_index(drop = True)\n\nval_set = MakingDataset(input_dataframe = df_val, max_char = max_char)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# Prediction\nnet.eval()\noutput_list = []\nwith torch.no_grad():\n    for idx, data in enumerate(val_loader):\n        text, labels = data\n        text = text.to(device)\n        labels = labels.to(device)\n\n        outputs = net(text)\n        outputs = nn.Softmax(dim = 1)(outputs)\n        output_list = np.append(output_list, outputs[:,1].detach().cpu().numpy().flatten())\n\n# Add prediction to df\nMODEL_NAME = 'char_v1'\ndf_val[MODEL_NAME] = output_list\n\n# Edit df to be evaluated\ndef convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n    \ndef convert_dataframe_to_bool(df):\n    bool_df = df.copy()\n    for col in ['target'] + identity_columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\ndf_val = convert_dataframe_to_bool(df_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        print(f'{subgroup}__Done_subgroup_AUC')\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        print(f'{subgroup}__Done_BPSN_AUC')\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        print(f'{subgroup}__Done_BNSP_AUC')\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nidentity_columns = [\n    'male', \n    'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness'\n]\nTOXICITY_COLUMN = 'target'\nbias_metrics_df = compute_bias_metrics_for_model(df_val, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\nbias_metrics_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n    \nget_final_metric(bias_metrics_df, calculate_overall_auc(df_val, MODEL_NAME))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\nsubmission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_set = MakingDataset(input_dataframe = test, max_char = max_char, is_it_test = True)\nts_loader = torch.utils.data.DataLoader(ts_set, batch_size=batch_size, shuffle=False, num_workers=1)\n\n# Prediction\nnet.eval()\noutput_list = np.array([])\nwith torch.no_grad():\n    for _, data in enumerate(ts_loader):\n        text = data\n        text = text.to(device)\n\n        outputs = net(text)\n        outputs = nn.Softmax(dim = 1)(outputs)\n        output_list = np.append(output_list, outputs[:,1].detach().cpu().numpy().flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_list[output_list>0.5].shape[0] / output_list.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['prediction'] = output_list\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}