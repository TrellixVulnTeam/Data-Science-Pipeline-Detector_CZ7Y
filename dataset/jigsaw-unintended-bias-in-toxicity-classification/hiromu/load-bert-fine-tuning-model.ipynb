{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is continued from Save BERT fine-tuning model.\nIn this kernel, you can load the weights from that kernel and make a prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport random\nimport keras\nimport tensorflow as tf\nimport json\nsys.path.insert(0, '../input/pretrained-bert-including-scripts/master/bert-master')\n!cp -r '../input/kerasbert/keras_bert' '/kaggle/working'\nBERT_PRETRAINED_DIR = '../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12'\nprint('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\nimport tokenization  #Actually keras_bert contains tokenization part, here just for convenience","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"***** BERT pretrained directory: ../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12 *****\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Load raw model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_bert.keras_bert.bert import get_model\nfrom keras_bert.keras_bert.loader import load_trained_model_from_checkpoint\nfrom keras.optimizers import Adam\nadam = Adam(lr=2e-5,decay=0.01)\nmaxlen = 50\nprint('begin_build')\n\nconfig_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\ncheckpoint_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\nmodel = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True,seq_len=maxlen)\nmodel.summary(line_length=120)","execution_count":4,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nbegin_build\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n________________________________________________________________________________________________________________________\nLayer (type)                           Output Shape               Param #       Connected to                            \n========================================================================================================================\nInput-Token (InputLayer)               (None, 50)                 0                                                     \n________________________________________________________________________________________________________________________\nInput-Segment (InputLayer)             (None, 50)                 0                                                     \n________________________________________________________________________________________________________________________\nEmbedding-Token (TokenEmbedding)       [(None, 50, 768), (30522,  23440896      Input-Token[0][0]                       \n________________________________________________________________________________________________________________________\nEmbedding-Segment (Embedding)          (None, 50, 768)            1536          Input-Segment[0][0]                     \n________________________________________________________________________________________________________________________\nEmbedding-Token-Segment (Add)          (None, 50, 768)            0             Embedding-Token[0][0]                   \n                                                                                Embedding-Segment[0][0]                 \n________________________________________________________________________________________________________________________\nEmbedding-Position (PositionEmbedding) (None, 50, 768)            38400         Embedding-Token-Segment[0][0]           \n________________________________________________________________________________________________________________________\nEmbedding-Dropout (Dropout)            (None, 50, 768)            0             Embedding-Position[0][0]                \n________________________________________________________________________________________________________________________\nEmbedding-Norm (LayerNormalization)    (None, 50, 768)            1536          Embedding-Dropout[0][0]                 \n________________________________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Embedding-Norm[0][0]                    \n________________________________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-1-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Embedding-Norm[0][0]                    \n                                                                                Encoder-1-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-1-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-1-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-1-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-1-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-1-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-1-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-1-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-1-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-1-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-1-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-1-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-2-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-1-FeedForward-Norm[0][0]        \n                                                                                Encoder-2-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-2-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-2-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-2-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-2-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-2-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-2-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-2-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-2-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-2-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-2-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-2-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-3-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-2-FeedForward-Norm[0][0]        \n                                                                                Encoder-3-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-3-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-3-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-3-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-3-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-3-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-3-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-3-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-3-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-3-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-3-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-3-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-4-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-3-FeedForward-Norm[0][0]        \n                                                                                Encoder-4-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-4-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-4-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-4-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-4-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-4-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-4-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-4-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-4-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-4-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-4-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-4-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-5-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-4-FeedForward-Norm[0][0]        \n                                                                                Encoder-5-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-5-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-5-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-5-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-5-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-5-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-5-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-5-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-5-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-5-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-5-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-5-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-6-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-5-FeedForward-Norm[0][0]        \n                                                                                Encoder-6-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-6-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-6-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-6-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-6-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-6-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-6-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-6-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-6-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-6-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-6-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-6-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-7-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-6-FeedForward-Norm[0][0]        \n                                                                                Encoder-7-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-7-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-7-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-7-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-7-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-7-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-7-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-7-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-7-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-7-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-7-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-7-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-8-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-7-FeedForward-Norm[0][0]        \n                                                                                Encoder-8-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-8-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-8-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-8-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-8-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-8-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-8-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-8-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-8-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-8-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-8-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttention (Mult (None, 50, 768)            2362368       Encoder-8-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttention-Dropo (None, 50, 768)            0             Encoder-9-MultiHeadSelfAttention[0][0]  \n________________________________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttention-Add ( (None, 50, 768)            0             Encoder-8-FeedForward-Norm[0][0]        \n                                                                                Encoder-9-MultiHeadSelfAttention-Dropout\n________________________________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttention-Norm  (None, 50, 768)            1536          Encoder-9-MultiHeadSelfAttention-Add[0][\n________________________________________________________________________________________________________________________\nEncoder-9-FeedForward (FeedForward)    (None, 50, 768)            4722432       Encoder-9-MultiHeadSelfAttention-Norm[0]\n________________________________________________________________________________________________________________________\nEncoder-9-FeedForward-Dropout (Dropout (None, 50, 768)            0             Encoder-9-FeedForward[0][0]             \n________________________________________________________________________________________________________________________\nEncoder-9-FeedForward-Add (Add)        (None, 50, 768)            0             Encoder-9-MultiHeadSelfAttention-Norm[0]\n                                                                                Encoder-9-FeedForward-Dropout[0][0]     \n________________________________________________________________________________________________________________________\nEncoder-9-FeedForward-Norm (LayerNorma (None, 50, 768)            1536          Encoder-9-FeedForward-Add[0][0]         \n________________________________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttention (Mul (None, 50, 768)            2362368       Encoder-9-FeedForward-Norm[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttention-Drop (None, 50, 768)            0             Encoder-10-MultiHeadSelfAttention[0][0] \n________________________________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttention-Add  (None, 50, 768)            0             Encoder-9-FeedForward-Norm[0][0]        \n                                                                                Encoder-10-MultiHeadSelfAttention-Dropou\n________________________________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttention-Norm (None, 50, 768)            1536          Encoder-10-MultiHeadSelfAttention-Add[0]\n________________________________________________________________________________________________________________________\nEncoder-10-FeedForward (FeedForward)   (None, 50, 768)            4722432       Encoder-10-MultiHeadSelfAttention-Norm[0\n________________________________________________________________________________________________________________________\nEncoder-10-FeedForward-Dropout (Dropou (None, 50, 768)            0             Encoder-10-FeedForward[0][0]            \n________________________________________________________________________________________________________________________\nEncoder-10-FeedForward-Add (Add)       (None, 50, 768)            0             Encoder-10-MultiHeadSelfAttention-Norm[0\n                                                                                Encoder-10-FeedForward-Dropout[0][0]    \n________________________________________________________________________________________________________________________\nEncoder-10-FeedForward-Norm (LayerNorm (None, 50, 768)            1536          Encoder-10-FeedForward-Add[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttention (Mul (None, 50, 768)            2362368       Encoder-10-FeedForward-Norm[0][0]       \n________________________________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttention-Drop (None, 50, 768)            0             Encoder-11-MultiHeadSelfAttention[0][0] \n________________________________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttention-Add  (None, 50, 768)            0             Encoder-10-FeedForward-Norm[0][0]       \n                                                                                Encoder-11-MultiHeadSelfAttention-Dropou\n________________________________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttention-Norm (None, 50, 768)            1536          Encoder-11-MultiHeadSelfAttention-Add[0]\n________________________________________________________________________________________________________________________\nEncoder-11-FeedForward (FeedForward)   (None, 50, 768)            4722432       Encoder-11-MultiHeadSelfAttention-Norm[0\n________________________________________________________________________________________________________________________\nEncoder-11-FeedForward-Dropout (Dropou (None, 50, 768)            0             Encoder-11-FeedForward[0][0]            \n________________________________________________________________________________________________________________________\nEncoder-11-FeedForward-Add (Add)       (None, 50, 768)            0             Encoder-11-MultiHeadSelfAttention-Norm[0\n                                                                                Encoder-11-FeedForward-Dropout[0][0]    \n________________________________________________________________________________________________________________________\nEncoder-11-FeedForward-Norm (LayerNorm (None, 50, 768)            1536          Encoder-11-FeedForward-Add[0][0]        \n________________________________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttention (Mul (None, 50, 768)            2362368       Encoder-11-FeedForward-Norm[0][0]       \n________________________________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttention-Drop (None, 50, 768)            0             Encoder-12-MultiHeadSelfAttention[0][0] \n________________________________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttention-Add  (None, 50, 768)            0             Encoder-11-FeedForward-Norm[0][0]       \n                                                                                Encoder-12-MultiHeadSelfAttention-Dropou\n________________________________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttention-Norm (None, 50, 768)            1536          Encoder-12-MultiHeadSelfAttention-Add[0]\n________________________________________________________________________________________________________________________\nEncoder-12-FeedForward (FeedForward)   (None, 50, 768)            4722432       Encoder-12-MultiHeadSelfAttention-Norm[0\n________________________________________________________________________________________________________________________\nEncoder-12-FeedForward-Dropout (Dropou (None, 50, 768)            0             Encoder-12-FeedForward[0][0]            \n________________________________________________________________________________________________________________________\nEncoder-12-FeedForward-Add (Add)       (None, 50, 768)            0             Encoder-12-MultiHeadSelfAttention-Norm[0\n                                                                                Encoder-12-FeedForward-Dropout[0][0]    \n________________________________________________________________________________________________________________________\nEncoder-12-FeedForward-Norm (LayerNorm (None, 50, 768)            1536          Encoder-12-FeedForward-Add[0][0]        \n________________________________________________________________________________________________________________________\nMLM-Dense (Dense)                      (None, 50, 768)            590592        Encoder-12-FeedForward-Norm[0][0]       \n________________________________________________________________________________________________________________________\nMLM-Norm (LayerNormalization)          (None, 50, 768)            1536          MLM-Dense[0][0]                         \n________________________________________________________________________________________________________________________\nExtract (Extract)                      (None, 768)                0             Encoder-12-FeedForward-Norm[0][0]       \n________________________________________________________________________________________________________________________\nMLM-Sim (EmbeddingSimilarity)          (None, 50, 30522)          30522         MLM-Norm[0][0]                          \n                                                                                Embedding-Token[0][1]                   \n________________________________________________________________________________________________________________________\nInput-Masked (InputLayer)              (None, 50)                 0                                                     \n________________________________________________________________________________________________________________________\nNSP-Dense (Dense)                      (None, 768)                590592        Extract[0][0]                           \n________________________________________________________________________________________________________________________\nMLM (Masked)                           (None, 50, 30522)          0             MLM-Sim[0][0]                           \n                                                                                Input-Masked[0][0]                      \n________________________________________________________________________________________________________________________\nNSP (Dense)                            (None, 2)                  1538          NSP-Dense[0][0]                         \n========================================================================================================================\nTotal params: 109,751,612\nTrainable params: 109,751,612\nNon-trainable params: 0\n________________________________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Build classification model\n\nAs the Extract layer extracts only the first token where \"['CLS']\" used to be, we just take the layer and connect to the single neuron output."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\nfrom keras.models import Model\nimport keras.backend as K\nimport re\nimport codecs\n\nsequence_output  = model.layers[-6].output\npool_output = Dense(1, activation='sigmoid',kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),name = 'real_output')(sequence_output)\nmodel3  = Model(inputs=model.input, outputs=pool_output)\nmodel3.compile(loss='binary_crossentropy', optimizer=adam)\nmodel3.summary()","execution_count":5,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nInput-Token (InputLayer)        (None, 50)           0                                            \n__________________________________________________________________________________________________\nInput-Segment (InputLayer)      (None, 50)           0                                            \n__________________________________________________________________________________________________\nEmbedding-Token (TokenEmbedding [(None, 50, 768), (3 23440896    Input-Token[0][0]                \n__________________________________________________________________________________________________\nEmbedding-Segment (Embedding)   (None, 50, 768)      1536        Input-Segment[0][0]              \n__________________________________________________________________________________________________\nEmbedding-Token-Segment (Add)   (None, 50, 768)      0           Embedding-Token[0][0]            \n                                                                 Embedding-Segment[0][0]          \n__________________________________________________________________________________________________\nEmbedding-Position (PositionEmb (None, 50, 768)      38400       Embedding-Token-Segment[0][0]    \n__________________________________________________________________________________________________\nEmbedding-Dropout (Dropout)     (None, 50, 768)      0           Embedding-Position[0][0]         \n__________________________________________________________________________________________________\nEmbedding-Norm (LayerNormalizat (None, 50, 768)      1536        Embedding-Dropout[0][0]          \n__________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttentio (None, 50, 768)      2362368     Embedding-Norm[0][0]             \n__________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-1-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttentio (None, 50, 768)      0           Embedding-Norm[0][0]             \n                                                                 Encoder-1-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-1-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-1-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-1-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-1-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-1-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-1-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-1-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-1-MultiHeadSelfAttention-\n                                                                 Encoder-1-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-1-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-1-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-1-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-2-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-1-FeedForward-Norm[0][0] \n                                                                 Encoder-2-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-2-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-2-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-2-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-2-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-2-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-2-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-2-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-2-MultiHeadSelfAttention-\n                                                                 Encoder-2-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-2-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-2-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-2-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-3-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-2-FeedForward-Norm[0][0] \n                                                                 Encoder-3-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-3-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-3-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-3-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-3-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-3-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-3-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-3-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-3-MultiHeadSelfAttention-\n                                                                 Encoder-3-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-3-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-3-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-3-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-4-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-3-FeedForward-Norm[0][0] \n                                                                 Encoder-4-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-4-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-4-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-4-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-4-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-4-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-4-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-4-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-4-MultiHeadSelfAttention-\n                                                                 Encoder-4-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-4-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-4-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-4-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-5-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-4-FeedForward-Norm[0][0] \n                                                                 Encoder-5-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-5-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-5-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-5-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-5-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-5-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-5-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-5-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-5-MultiHeadSelfAttention-\n                                                                 Encoder-5-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-5-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-5-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-5-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-6-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-5-FeedForward-Norm[0][0] \n                                                                 Encoder-6-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-6-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-6-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-6-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-6-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-6-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-6-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-6-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-6-MultiHeadSelfAttention-\n                                                                 Encoder-6-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-6-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-6-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-6-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-7-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-6-FeedForward-Norm[0][0] \n                                                                 Encoder-7-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-7-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-7-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-7-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-7-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-7-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-7-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-7-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-7-MultiHeadSelfAttention-\n                                                                 Encoder-7-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-7-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-7-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-7-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-8-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-7-FeedForward-Norm[0][0] \n                                                                 Encoder-8-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-8-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-8-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-8-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-8-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-8-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-8-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-8-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-8-MultiHeadSelfAttention-\n                                                                 Encoder-8-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-8-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-8-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttentio (None, 50, 768)      2362368     Encoder-8-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-9-MultiHeadSelfAttention[\n__________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttentio (None, 50, 768)      0           Encoder-8-FeedForward-Norm[0][0] \n                                                                 Encoder-9-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-9-MultiHeadSelfAttentio (None, 50, 768)      1536        Encoder-9-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-9-FeedForward (FeedForw (None, 50, 768)      4722432     Encoder-9-MultiHeadSelfAttention-\n__________________________________________________________________________________________________\nEncoder-9-FeedForward-Dropout ( (None, 50, 768)      0           Encoder-9-FeedForward[0][0]      \n__________________________________________________________________________________________________\nEncoder-9-FeedForward-Add (Add) (None, 50, 768)      0           Encoder-9-MultiHeadSelfAttention-\n                                                                 Encoder-9-FeedForward-Dropout[0][\n__________________________________________________________________________________________________\nEncoder-9-FeedForward-Norm (Lay (None, 50, 768)      1536        Encoder-9-FeedForward-Add[0][0]  \n__________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttenti (None, 50, 768)      2362368     Encoder-9-FeedForward-Norm[0][0] \n__________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttenti (None, 50, 768)      0           Encoder-10-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttenti (None, 50, 768)      0           Encoder-9-FeedForward-Norm[0][0] \n                                                                 Encoder-10-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-10-MultiHeadSelfAttenti (None, 50, 768)      1536        Encoder-10-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-10-FeedForward (FeedFor (None, 50, 768)      4722432     Encoder-10-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-10-FeedForward-Dropout  (None, 50, 768)      0           Encoder-10-FeedForward[0][0]     \n__________________________________________________________________________________________________\nEncoder-10-FeedForward-Add (Add (None, 50, 768)      0           Encoder-10-MultiHeadSelfAttention\n                                                                 Encoder-10-FeedForward-Dropout[0]\n__________________________________________________________________________________________________\nEncoder-10-FeedForward-Norm (La (None, 50, 768)      1536        Encoder-10-FeedForward-Add[0][0] \n__________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttenti (None, 50, 768)      2362368     Encoder-10-FeedForward-Norm[0][0]\n__________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttenti (None, 50, 768)      0           Encoder-11-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttenti (None, 50, 768)      0           Encoder-10-FeedForward-Norm[0][0]\n                                                                 Encoder-11-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-11-MultiHeadSelfAttenti (None, 50, 768)      1536        Encoder-11-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-11-FeedForward (FeedFor (None, 50, 768)      4722432     Encoder-11-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-11-FeedForward-Dropout  (None, 50, 768)      0           Encoder-11-FeedForward[0][0]     \n__________________________________________________________________________________________________\nEncoder-11-FeedForward-Add (Add (None, 50, 768)      0           Encoder-11-MultiHeadSelfAttention\n                                                                 Encoder-11-FeedForward-Dropout[0]\n__________________________________________________________________________________________________\nEncoder-11-FeedForward-Norm (La (None, 50, 768)      1536        Encoder-11-FeedForward-Add[0][0] \n__________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttenti (None, 50, 768)      2362368     Encoder-11-FeedForward-Norm[0][0]\n__________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttenti (None, 50, 768)      0           Encoder-12-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttenti (None, 50, 768)      0           Encoder-11-FeedForward-Norm[0][0]\n                                                                 Encoder-12-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-12-MultiHeadSelfAttenti (None, 50, 768)      1536        Encoder-12-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-12-FeedForward (FeedFor (None, 50, 768)      4722432     Encoder-12-MultiHeadSelfAttention\n__________________________________________________________________________________________________\nEncoder-12-FeedForward-Dropout  (None, 50, 768)      0           Encoder-12-FeedForward[0][0]     \n__________________________________________________________________________________________________\nEncoder-12-FeedForward-Add (Add (None, 50, 768)      0           Encoder-12-MultiHeadSelfAttention\n                                                                 Encoder-12-FeedForward-Dropout[0]\n__________________________________________________________________________________________________\nEncoder-12-FeedForward-Norm (La (None, 50, 768)      1536        Encoder-12-FeedForward-Add[0][0] \n__________________________________________________________________________________________________\nExtract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n__________________________________________________________________________________________________\nreal_output (Dense)             (None, 1)            769         Extract[0][0]                    \n==================================================================================================\nTotal params: 108,537,601\nTrainable params: 108,537,601\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data, Training, Predicting\n\nFirst the model need train data like [token_input,seg_input,masked input], here we set all segment input to 0 and all masked input to 1.\n\nStill I am finding a more efficient way to do token-convert-to-ids"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_lines(example, max_seq_length,tokenizer):\n    max_seq_length -=2\n    all_tokens = []\n    longer = 0\n    for i in range(example.shape[0]):\n      tokens_a = tokenizer.tokenize(example[i])\n      if len(tokens_a)>max_seq_length:\n        tokens_a = tokens_a[:max_seq_length]\n        longer += 1\n      one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n      all_tokens.append(one_token)\n    print(longer)\n    return np.array(all_tokens)\n    \nnb_epochs=1\nbsz = 32\ndict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\ntokenizer = tokenization.FullTokenizer(vocab_file=dict_path, do_lower_case=True)\nprint('build tokenizer done')\ntrain_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntrain_df = train_df.sample(frac=0.01,random_state = 42)\n#train_df['comment_text'] = train_df['comment_text'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\n',  ' ', regex=True)","execution_count":6,"outputs":[{"output_type":"stream","text":"build tokenizer done\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can load the weights by this line\nprint('load model')\nmodel3.load_weights('../input/save-bert-fine-tuning-model/bert_weights.h5')","execution_count":7,"outputs":[{"output_type":"stream","text":"load model\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load test data\ntest_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n#test_df['comment_text'] = test_df['comment_text'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\n',  ' ', regex=True)\neval_lines = test_df['comment_text'].values\nprint(eval_lines.shape)\nprint('load data done')\ntoken_input2 = convert_lines(eval_lines,maxlen,tokenizer)\nseg_input2 = np.zeros((token_input2.shape[0],maxlen))\nmask_input2 = np.ones((token_input2.shape[0],maxlen))\nprint('test data done')\nprint(token_input2.shape)\nprint(seg_input2.shape)\nprint(mask_input2.shape)\nhehe = model3.predict([token_input2, seg_input2, mask_input2],verbose=1,batch_size=bsz)\nsubmission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv', index_col='id')\nsubmission['prediction'] = hehe\nsubmission.reset_index(drop=False, inplace=True)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[{"output_type":"stream","text":"(97320,)\nload data done\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"If you feel this kernel useful, please upvote this kernel and [save part kernel](https://www.kaggle.com/hiromoon166/save-bert-fine-tuning-model).\nAnd, don't forget to upvote [the great kernel](https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming) by Yue Zhang."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}