{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nstop_words = set(stopwords.words('english'))\nsnowball_stemmer = SnowballStemmer(\"english\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading input data for analysis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\n#test_df = pd.read_csv(\"../input/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get an idea about the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convertion of target to Binary class:**\n\nFrom the Background information provided, target with value >=0.5 can be considered toxic"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['target'] = [ 1 if target>=0.5 else 0 for target in train_df['target'] ]\n#train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check the class imbalance:**\n\nSince we converted the target variable to binary class, we can easily identify the class counts."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_label = ('Toxic comments', 'Non-toxic comments')\ny_axis =[ value_count/train_df.shape[0]*100 for value_count in train_df['target'].value_counts().tolist() ]\n#y_label = np.array(y_axis)\nbar_plot = plt.bar(x_label, y_axis)\nbar_plot[0].set_color('r')\nbar_plot[1].set_color('g')\nplt.ylabel('Total data range', fontsize=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocesing:\n\nOn **comment_text** column:\n1. convert characters to lower\n2. remove numbers\n\nSpecial characters and repeated letters can also be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df['comment_text']\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef pre_processing(X):\n    X = X.str.lower()\n    X = X.str.replace(r'\\r', ' ')\n    X = X.str.replace(r'\\n', ' ')\n    X = X.str.replace('[^a-zA-Z0-9 ]', '')\n    #X = re.sub('[^a-zA-Z0-9 \\n\\.]','', X)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pre_processing(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NLP Preprocessing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def nlp_preprocessing(document): \n    words = [snowball_stemmer.stem(word) for word in document.split() \n                 if word not in stop_words]\n    doc = ' '.join(words)\n    return doc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = X.apply(lambda document: nlp_preprocessing(document))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vecortizing the text feature using TF-IDF Vectorizer:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=0.01)\nx = vectorizer.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label Encoding the target/output variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"lencoder= LabelEncoder()\nenc_y = lencoder.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building Model:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras.backend as K\nfrom keras import layers, models, optimizers, regularizers\nfrom keras.layers import Bidirectional, LSTM\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp_input = layers.Input((x.shape[1], ), sparse=True)\nhidden_layer_1 = layers.Dense(500, activation=\"relu\")(nlp_input)\n\nhidden_drop_1 = layers.Dropout(0.3)(hidden_layer_1)\noutput_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_drop_1)\n\nclassifier_1 = models.Model(inputs = nlp_input, outputs = output_layer)\nclassifier_1.compile(optimizer=optimizers.adam(lr=0.001, amsgrad=True), \n                   loss='binary_crossentropy', \n                   metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model for textual feature:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\nmc = ModelCheckpoint('model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\n                       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_1.fit(x, enc_y, batch_size = 256, epochs = 10, callbacks=[es, mc], verbose=1  )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction for test data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X = pre_processing(test_df['comment_text'])\ntest_x = test_X.apply(lambda document: nlp_preprocessing(document))\ntest_x = vectorizer.transform(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = classifier_1.predict(test_x)\ny = np.where(y>=0.5,1,0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/sample_submission.csv')\nsub_df['prediction'] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}