{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook implements the contents of [my discussion](https://www.kaggle.com/competitions/smartphone-decimeter-2022/discussion/322596).  \nPhones mean improves in train, but there is no room for improvement in test because the number of phones is one.","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom scipy.interpolate import InterpolatedUnivariateSpline\n\nINPUT_PATH = '../input/smartphone-decimeter-2022'\nTRAIN_PATH = os.path.join(INPUT_PATH, 'train')\n\nWGS84_SEMI_MAJOR_AXIS = 6378137.0\nWGS84_SEMI_MINOR_AXIS = 6356752.314245\nWGS84_SQUARED_FIRST_ECCENTRICITY  = 6.69437999013e-3\nWGS84_SQUARED_SECOND_ECCENTRICITY = 6.73949674226e-3\n\nHAVERSINE_RADIUS = 6_371_000","metadata":{"execution":{"iopub.status.busy":"2022-05-03T06:11:02.359793Z","iopub.execute_input":"2022-05-03T06:11:02.360052Z","iopub.status.idle":"2022-05-03T06:11:02.365614Z","shell.execute_reply.started":"2022-05-03T06:11:02.360025Z","shell.execute_reply":"2022-05-03T06:11:02.364486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass ECEF:\n    x: np.array\n    y: np.array\n    z: np.array\n\n    def to_numpy(self):\n        return np.stack([self.x, self.y, self.z], axis=0)\n\n    @staticmethod\n    def from_numpy(pos):\n        x, y, z = [np.squeeze(w) for w in np.split(pos, 3, axis=-1)]\n        return ECEF(x=x, y=y, z=z)\n\n@dataclass\nclass BLH:\n    lat : np.array\n    lng : np.array\n    hgt : np.array\n\ndef ECEF_to_BLH(ecef):\n    a = WGS84_SEMI_MAJOR_AXIS\n    b = WGS84_SEMI_MINOR_AXIS\n    e2  = WGS84_SQUARED_FIRST_ECCENTRICITY\n    e2_ = WGS84_SQUARED_SECOND_ECCENTRICITY\n    x = ecef.x\n    y = ecef.y\n    z = ecef.z\n    r = np.sqrt(x**2 + y**2)\n    t = np.arctan2(z * (a/b), r)\n    B = np.arctan2(z + (e2_*b)*np.sin(t)**3, r - (e2*a)*np.cos(t)**3)\n    L = np.arctan2(y, x)\n    n = a / np.sqrt(1 - e2*np.sin(B)**2)\n    H = (r / np.cos(B)) - n\n    return BLH(lat=B, lng=L, hgt=H)\n\ndef haversine_distance(blh_1, blh_2):\n    dlat = blh_2.lat - blh_1.lat\n    dlng = blh_2.lng - blh_1.lng\n    a = np.sin(dlat/2)**2 + np.cos(blh_1.lat) * np.cos(blh_2.lat) * np.sin(dlng/2)**2\n    dist = 2 * HAVERSINE_RADIUS * np.arcsin(np.sqrt(a))\n    return dist\n\ndef pandas_haversine_distance(df1, df2):\n    blh1 = BLH(\n        lat=np.deg2rad(df1['LatitudeDegrees'].to_numpy()),\n        lng=np.deg2rad(df1['LongitudeDegrees'].to_numpy()),\n        hgt=0,\n    )\n    blh2 = BLH(\n        lat=np.deg2rad(df2['LatitudeDegrees'].to_numpy()),\n        lng=np.deg2rad(df2['LongitudeDegrees'].to_numpy()),\n        hgt=0,\n    )\n    return haversine_distance(blh1, blh2)\n\n\ndef ecef_to_lat_lng(tripID, gnss_df, UnixTimeMillis):\n    ecef_columns = ['WlsPositionXEcefMeters', 'WlsPositionYEcefMeters', 'WlsPositionZEcefMeters']\n    columns = ['utcTimeMillis'] + ecef_columns\n    ecef_df = (gnss_df.drop_duplicates(subset='utcTimeMillis')[columns]\n               .dropna().reset_index(drop=True))\n    ecef = ECEF.from_numpy(ecef_df[ecef_columns].to_numpy())\n    blh  = ECEF_to_BLH(ecef)\n\n    TIME = ecef_df['utcTimeMillis'].to_numpy()\n    lat = InterpolatedUnivariateSpline(TIME, blh.lat, ext=3)(UnixTimeMillis)\n    lng = InterpolatedUnivariateSpline(TIME, blh.lng, ext=3)(UnixTimeMillis)\n    return pd.DataFrame({\n        'tripId' : tripID,\n        'UnixTimeMillis'   : UnixTimeMillis,\n        'LatitudeDegrees'  : np.degrees(lat),\n        'LongitudeDegrees' : np.degrees(lng),\n    })\n\ndef calc_score(tripID, pred_df, gt_df):\n    d = pandas_haversine_distance(pred_df, gt_df)\n    score = np.mean([np.quantile(d, 0.50), np.quantile(d, 0.95)])    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-03T06:11:02.370648Z","iopub.execute_input":"2022-05-03T06:11:02.370945Z","iopub.status.idle":"2022-05-03T06:11:02.39219Z","shell.execute_reply.started":"2022-05-03T06:11:02.370916Z","shell.execute_reply":"2022-05-03T06:11:02.39122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_list = []\nfor phone_dir in tqdm(glob('../input/gsdc2-saito-latlon-baseline/train/*')):\n    phone_df = []\n    for path in glob(os.path.join(phone_dir, '*')):\n        phone_df.append(pd.read_csv(os.path.join(path, 'baseline.csv')))\n    phone_df = pd.concat(phone_df)\n    \n    # lat\n    lat_df = pd.pivot_table(\n        data=phone_df,\n        index=['UnixTimeMillis'],\n        columns=['tripId'],\n        values=['LatitudeDegrees']\n    )\n    lat_df = lat_df.interpolate(method='index', limit_direction='both')\n    lat_df = lat_df.mean(axis=1).reset_index()\n    lat_df.columns = ['UnixTimeMillis', 'LatitudeDegrees']\n    \n    # lon\n    lon_df = pd.pivot_table(\n        data=phone_df,\n        index=['UnixTimeMillis'],\n        columns=['tripId'],\n        values=['LongitudeDegrees']\n    )\n    lon_df = lon_df.interpolate(method='index', limit_direction='both')\n    lon_df = lon_df.mean(axis=1).reset_index()\n    lon_df.columns = ['UnixTimeMillis', 'LongitudeDegrees']\n    \n    phonemean_df = phone_df[['tripId', 'UnixTimeMillis']]\\\n                    .merge(lat_df, on='UnixTimeMillis', how='left')\\\n                    .merge(lon_df, on='UnixTimeMillis', how='left')   \n    \n    for tripId, grp_df in phonemean_df.groupby('tripId'):\n        gt_df = pd.read_csv(os.path.join(TRAIN_PATH, tripId, 'ground_truth.csv'))\n        score = calc_score(tripId, grp_df, gt_df)\n        print(f'{tripId:<45}: score = {score:.3f}')\n        score_list.append(score)\n\nmean_score = np.mean(score_list)\nprint(f'mean_score = {mean_score:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T06:11:02.393995Z","iopub.execute_input":"2022-05-03T06:11:02.394257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/smartphone-decimeter-2022/sample_submission.csv')\nsub_df = sub_df.drop(columns=['LatitudeDegrees', 'LongitudeDegrees'])\n\npred_dfs  = []\nfor phone_dir in tqdm(glob('../input/gsdc2-saito-latlon-baseline/test/*')):\n    phone_df = []\n    for path in glob(os.path.join(phone_dir, '*')):\n        phone_df.append(pd.read_csv(os.path.join(path, 'baseline.csv')))\n    phone_df = pd.concat(phone_df)\n    \n    # lat\n    lat_df = pd.pivot_table(\n        data=phone_df,\n        index=['UnixTimeMillis'],\n        columns=['tripId'],\n        values=['LatitudeDegrees']\n    )\n    lat_df = lat_df.interpolate(method='index', limit_direction='both')\n    lat_df = lat_df.mean(axis=1).reset_index()\n    lat_df.columns = ['UnixTimeMillis', 'LatitudeDegrees']\n    \n    # lon\n    lon_df = pd.pivot_table(\n        data=phone_df,\n        index=['UnixTimeMillis'],\n        columns=['tripId'],\n        values=['LongitudeDegrees']\n    )\n    lon_df = lon_df.interpolate(method='index', limit_direction='both')\n    lon_df = lon_df.mean(axis=1).reset_index()\n    lon_df.columns = ['UnixTimeMillis', 'LongitudeDegrees']\n    \n    phonemean_df = phone_df[['tripId', 'UnixTimeMillis']]\\\n                    .merge(lat_df, on='UnixTimeMillis', how='left')\\\n                    .merge(lon_df, on='UnixTimeMillis', how='left')   \n    pred_dfs.append(phonemean_df)\n    \nsub_df = sub_df.merge(pd.concat(pred_dfs), on=['tripId', 'UnixTimeMillis'])\nsub_df.to_csv('submission.csv', index=False)\ndisplay(sub_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}