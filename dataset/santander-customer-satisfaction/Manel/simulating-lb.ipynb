{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport csv\nfrom time import time\n\nimport matplotlib.pyplot as plt\n\nimport xgboost as xgb\n\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.cross_validation import train_test_split\n\nfrom sklearn.metrics import roc_auc_score"},{"cell_type":"markdown","metadata":{},"source":"### We select 9 features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print('Load data...')\ntrain = pd.read_csv(\"../input/train.csv\")\ntarget = train['TARGET']\n\n# Selected features (using forward selection with 4-Fold cv)\nselected_features = ['var15', 'saldo_var30', 'num_var22_ult3', 'imp_op_var39_ult1',\n                     'num_var45_hace3', 'saldo_medio_var5_hace2', 'var3',\n                     'saldo_medio_var8_ult3', 'ind_var41_0']\ntrain = train[selected_features]\nprint('We consider',len(selected_features),'features')"},{"cell_type":"markdown","metadata":{},"source":"### Generating train, test, test_public and test_private from train"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train, test, target, target_test = train_test_split(train, target, test_size=0.5, random_state=42)\ntest_Public, test_Private, target_test_Public, target_test_Private = train_test_split(test, target_test, test_size=0.5, random_state=42)\nprint(train.shape)\nprint(test.shape)"},{"cell_type":"markdown","metadata":{},"source":"### Making predictions for 10 seeds (n_seed) using xgb\n### For the train predictions we use 4-fold (cv_n) cross validation"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"num_rounds = 100\nearly_stopping = 200\nparams = {}\nparams[\"objective\"] = \"binary:logistic\"\nparams[\"eta\"] = 0.07\nparams[\"subsample\"] = 0.8\nparams[\"colsample_bytree\"] = 0.8\nparams[\"silent\"] = 1\nparams[\"max_depth\"] = 5\nparams[\"min_child_weight\"] = 1\nparams[\"eval_metric\"] = \"auc\"\n\ntrain0 = np.array(train)\ntest0 = np.array(test)\ntest_Public0 = np.array(test_Public)\ntest_Private0 = np.array(test_Private)\n\nX_train = train0\ny_train = target.values\n\nn_seed = 10\ntrain_pred = np.ones(train.shape[0])\ntrain_predictions = pd.DataFrame({\"pred1\": np.zeros(train.shape[0])})\ntest_predictions = pd.DataFrame({\"pred1\": np.zeros(test.shape[0])})\ntest_predictions_Public = pd.DataFrame({\"pred1\": np.zeros(test_Public.shape[0])})\ntest_predictions_Private = pd.DataFrame({\"pred1\": np.zeros(test_Private.shape[0])})\n\nscores_train = []\nscores_test = []\nscores_test_Public = []\nscores_test_Private = []\n# The folds are made by preserving the percentage of samples for each class!\ncv_n = 4\nkf = StratifiedKFold(target.values, n_folds=cv_n, shuffle=True)\n\nfor i in range(0,n_seed):\n    params['seed'] = 1+i\n    print('Making prediction for seed',params['seed'],'...')\n    for cv_train_index, cv_test_index in kf:\n        X_train, X_test = train0[cv_train_index, :], train0[cv_test_index, :]\n        y_train, y_test = target.iloc[cv_train_index].values, target.iloc[cv_test_index].values\n      # train machine learning\n        xg_train = xgb.DMatrix(X_train, label=y_train)\n        xg_test_cv = xgb.DMatrix(X_test, label=y_test)\n\n        watchlist = [(xg_train, 'train'), (xg_test_cv, 'test')]\n\n        xgclassifier_cv = xgb.train(params, xg_train, \n                                    num_rounds, watchlist,\n                                    early_stopping_rounds=early_stopping,\n                                    verbose_eval = False);\n\n        # predict\n        train_pred[cv_test_index] = xgclassifier_cv.predict(xg_test_cv)\n\n    # Prediction for the training set\n    train_predictions['pred'+str(params['seed'])] = train_pred\n    scores_train.append(roc_auc_score(target, train_pred))\n    print('AUC for train',roc_auc_score(target, train_pred))\n    # train machine learning\n    xg_train = xgb.DMatrix(X_train, label=y_train)\n    xg_test = xgb.DMatrix(test0)\n    xg_test_Public = xgb.DMatrix(test_Public0)\n    xg_test_Private = xgb.DMatrix(test_Private0)\n\n    watchlist = [(xg_train, 'train')]\n    xgclassifier = xgb.train(params, xg_train, num_rounds, watchlist, verbose_eval=False);\n\n    #Predicting test\n    test_pred = xgclassifier.predict(xg_test)\n    test_predictions['pred'+str(params['seed'])] = test_pred\n    #Predicting test public\n    test_pred_Public = xgclassifier.predict(xg_test_Public)\n    test_predictions_Public['pred'+str(params['seed'])] = test_pred_Public\n    #Predicting test private\n    test_pred_Private = xgclassifier.predict(xg_test_Private)\n    test_predictions_Private['pred'+str(params['seed'])] = test_pred_Private\n    \n    scores_test.append(roc_auc_score(target_test, test_pred))\n    scores_test_Public.append(roc_auc_score(target_test_Public, test_pred_Public))\n    scores_test_Private.append(roc_auc_score(target_test_Private, test_pred_Private))\n    print('AUC for test',roc_auc_score(target_test, test_pred))\n    print('AUC for test Public',roc_auc_score(target_test_Public, test_pred_Public))\n    print('AUC for test Private',roc_auc_score(target_test_Private, test_pred_Private))"},{"cell_type":"markdown","metadata":{},"source":"### Plots of train-test and Public-Private aucs for the 10 seeds\n### The blue dot is the auc corresponding to the mean of the predictions"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.figure(figsize=(15,10))\n\n#Train-Test\nxlim0 = np.min(scores_train)-0.001\nxlim1 = np.max(scores_train)+0.001\nylim0 = np.min(scores_test)-0.001\nylim1 = np.max(scores_test)+0.001\n\nblend_train = train_predictions.mean(axis=1)\nauc_blend_train = roc_auc_score(target, blend_train)\nblend_test = test_predictions.mean(axis=1)\nauc_blend_test = roc_auc_score(target_test, blend_test)\n# plot with various axes scales\nplt.subplot(221)\nplt.plot(scores_train, scores_test,'ro')\nplt.plot(auc_blend_train,auc_blend_test,'bo')\nplt.title('AUC train vs test')\nplt.axis([xlim0,xlim1,ylim0,ylim1])\nplt.xlabel('train')\nplt.ylabel('test')\n\n#Train-Test\nxlim0 = np.min(scores_test_Public)-0.001\nxlim1 = np.max(scores_test_Public)+0.001\nylim0 = np.min(scores_test_Private)-0.001\nylim1 = np.max(scores_test_Private)+0.001\n\nblend_test_Public = test_predictions_Public.mean(axis=1)\nauc_blend_test_Public = roc_auc_score(target_test_Public, blend_test_Public)\nblend_test_Private = test_predictions_Private.mean(axis=1)\nauc_blend_test_Private = roc_auc_score(target_test_Private, blend_test_Private)\n# plot with various axes scales\nplt.subplot(222)\nplt.plot(scores_test_Public, scores_test_Private,'ro')\nplt.plot(auc_blend_test_Public,auc_blend_test_Private,'bo')\nplt.title('AUC Public vs Private')\nplt.axis([xlim0,xlim1,ylim0,ylim1])\nplt.xlabel('Public')\nplt.ylabel('Private')\n\nplt.show()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}