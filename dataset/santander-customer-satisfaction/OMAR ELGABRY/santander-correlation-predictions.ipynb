{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# get santander & test csv files as a DataFrame\nsantander_df = pd.read_csv(\"../input/train.csv\")\ntest_df      = pd.read_csv(\"../input/test.csv\")\n\n# preview the data\nsantander_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"santander_df.info()\nprint(\"----------------------------\")\ntest_df.info()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\n\n# 1. constant columns\ncolumns_to_be_removed = []\ncunt_constant = 0\n\nfor col in santander_df.columns:\n    if santander_df[col].std() == 0:\n        columns_to_be_removed.append(col)\n        cunt_constant =  cunt_constant + 1\n\nsantander_df.drop(columns_to_be_removed, axis=1, inplace=True)\ntest_df.drop(columns_to_be_removed, axis=1, inplace=True)\n\n# 2. duplicated columns\ncolumns_to_be_removed = []\ncunt_duplicates = 0\n\nfor col_i in santander_df.columns:\n    for col_j in santander_df.columns:\n        if(col_i == col_j): continue\n        if((santander_df[col_i] == santander_df[col_j]).all()):\n            columns_to_be_removed.append(col_i)\n            cunt_duplicates = cunt_duplicates + 1\n            break\n            \nsantander_df.drop(columns_to_be_removed, axis=1, inplace=True)\ntest_df.drop(columns_to_be_removed, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# plot count of constant & duplicate columns\n\naxis = Series([cunt_constant, cunt_duplicates]).plot(kind='bar')\nlabels = axis.set_xticklabels([\"Constants\", \"Duplicates\"], rotation=0)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# get unique values for each column\ncunt_nunique = santander_df.apply(lambda col:col.nunique())\ncunt_nunique.drop(\"ID\", inplace=True)\n\n# plot frequency of unique values only for columns with <= 100 unique elements\ncunt_nunique[cunt_nunique <= 100].hist(bins=100, figsize=(15, 5))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Replace -999999 in var3 column with most common value \n\nmost_common_num = santander_df['var3'].value_counts().index[0]\nsantander_df[\"var3\"][santander_df[\"var3\"] == -999999] = most_common_num"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# define training and testing sets\n\nX_train = santander_df.drop([\"ID\",\"TARGET\"],axis=1)\nY_train = santander_df[\"TARGET\"]\nX_test  = test_df.drop(\"ID\",axis=1).copy()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict_proba(X_test)[:,1]\n\nlogreg.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict_proba(X_test)[:,1]\n\nrandom_forest.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Xgboost \n\nparams = {\"objective\": \"binary:logistic\"}\n\nT_train_xgb = xgb.DMatrix(X_train, Y_train)\nX_test_xgb  = xgb.DMatrix(X_test)\n\ngbm = xgb.train(params, T_train_xgb, 20)\nY_pred = gbm.predict(X_test_xgb)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# get Coefficient of Determination(R^2) for each feature using Logistic Regression\n\ncoeff_df = DataFrame(X_train.columns)\ncoeff_df.columns = ['Features']\ncoeff_df[\"Coefficient Estimate\"] = (pd.Series(logreg.coef_[0])) ** 2\n\n# preview\ncoeff_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Plot coefficient of determination in order\n\ncoeff_ser = Series(list(coeff_df[\"Coefficient Estimate\"]), index=coeff_df[\"Features\"]).sort_values()\ncoeff_ser.tail(15).plot(kind='barh', figsize=(15,5), title=\"Coefficient of Determination(R^2)\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Plot feature importance in order using Random Forest Classifier\n\nimp_ser = Series(random_forest.feature_importances_, index=X_train.columns).sort_values()\nimp_ser.tail(15).plot(kind='barh', figsize=(15,5), title=\"Feature importance\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Create submission\n\nsubmission = pd.DataFrame()\nsubmission[\"ID\"]     = test_df[\"ID\"]\nsubmission[\"TARGET\"] = Y_pred\n\nsubmission.to_csv('santander.csv', index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}