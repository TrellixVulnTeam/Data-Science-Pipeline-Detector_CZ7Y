{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-output":false,"collapsed":true,"trusted":true},"cell_type":"code","source":"# loading data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"d0a1d85e-49c8-4d11-b540-e4e9012cc290","_uuid":"042269d01f57ffaffd8bfb58b0590f6dcef9cca0","trusted":true},"cell_type":"code","source":"print(\"training set shape: \",train.shape)\nprint(\"testing set shape: \",test.shape)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"a365c61f-822d-437f-814e-363cabdb16ab","_uuid":"8c1f2ae8525c5a8dad94b3b6281c99b951bd65ad"},"cell_type":"markdown","source":"**Analysis**"},{"metadata":{"_cell_guid":"f285cdf2-9539-45cd-811c-904e25f49263","_uuid":"03b0083ca706d61d8d257f0260b86258c32ff93b"},"cell_type":"markdown","source":"* **Data exploration:**"},{"metadata":{"_cell_guid":"20eabdd3-207e-47ce-a4c0-a23d7f29e1e7","_uuid":"5a8ddb470fa8c9af534d3a39b38b3354ae402ddf","trusted":true},"cell_type":"code","source":"# basic statistics\ntrain.describe()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"ba8d087a-d4f6-4210-bed5-064729bc08a6","_uuid":"95ce29ece1c7e45ce74b62f7365c5db78a56c060","trusted":true},"cell_type":"code","source":"# Due to the high number of features (i.e. 370), it will be focused on a sample of features.\ntrain[['var3', 'var15', 'num_var46', 'saldo_var27', 'var38','TARGET']].describe()","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"e52b4ee4-473d-414f-8552-988954016e8d","_uuid":"9e683258f18771154af50b3520efe97c11dc77df","trusted":true},"cell_type":"code","source":"# # finding outliers in features\n# def find_outliers(df):\n#     outliers = {}\n#     for feature in df.columns.values:\n#         q1 = df[feature].quantile(0.25)\n#         q3 = df[feature].quantile(0.75)\n#         iqr = q3-q1 #Interquartile range\n#         fence_low  = q1-1.5*iqr\n#         fence_high = q3+1.5*iqr\n#         count = count_outliers(df[feature], fence_low, fence_high)\n#         outliers.update({feature: count})\n#     return outliers\n# def count_outliers(df, low, high):\n#     count = 0\n#     for v in df.values:\n#         if v > high or v < low:\n#             count +=1\n#     return count\n\n# result = find_outliers(train)\n# print('done')","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"3407b7e1-ac7e-4bce-9ac2-6e218cca3475","_uuid":"d27df0bbbf42248a3048c17a2cbf2cae9fa8123a","trusted":true},"cell_type":"code","source":"# # Sorting all features based on amount of outliers.\n# outliers_result = {}\n# features = sorted(result)\n# values = sorted(result.values())\n\n# for f,v in zip(features, values):\n#     outliers_result.update({f:v})\n\n# for k,v in outliers_result.items():\n#     print(k, \" : \", v)","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"0d3dbc02-b6fe-4dab-88a3-c36d793f9309","_uuid":"16c462a0ec07b3381324a40239abf34e809cf184"},"cell_type":"markdown","source":"Using feature sample above, it found that:\n*  feature (var3) has 15281 outliers\n*  feature (var15) has 14196 outliers\n*  feature (num_var46) has 3221 outliers\n*  feature (saldo_var27) has 11254 outliers\n*  feature (var38) has 15983 outliers\n*  feature (TARGET) has 0 outliers\n\nRemoving all features outliers will reduce the data-set dramatically, so this issue should be handled by using algorithms that are robust to outliers. "},{"metadata":{"_cell_guid":"aff94c9c-d2cc-45fb-8510-79888685f13e","_uuid":"e3747fa5629c6afb1bce4336d98d588e4e20456f","collapsed":true},"cell_type":"markdown","source":"\n**Exploratory Visualization**"},{"metadata":{"_cell_guid":"c8554705-084e-419a-9605-3822cf2689a3","_uuid":"cb646ccd7ac8fdcc9fff5b87f9a95f30ed52015a","trusted":true},"cell_type":"code","source":"# counting each class in TARGET variable.\n# 0: un-satisfied, 1: satisfied\ntrain['TARGET'].value_counts()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"64730a44-9047-40ce-a85d-7305a0a7da43","_uuid":"dfdba518895f580fb425ae5fff4f51482c0b7b7b","trusted":true},"cell_type":"code","source":"%matplotlib inline\n# a plot visualizes the imbalance in TARGET variable. \ntrain['TARGET'].plot(kind='hist')\nplt.show()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"6687a18a-95c7-4c27-87d0-8603f8efd30c","_uuid":"72ddf074b50996733c8ca97dd0807dd285849671","trusted":true},"cell_type":"code","source":"%matplotlib inline\n# a plot visualizes the distribution of features 'var3', 'var15', 'num_var46', 'saldo_var27', 'var38','TARGET'.\ntrain[['var3', 'var15', 'num_var46', 'saldo_var27', 'var38','TARGET']].hist(figsize=(12, 6),  bins=100)\nplt.show()","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"0da612c3-8ebd-4ee6-9bb9-343b74af5473","_uuid":"004a02488df0a8e338d1b5706128a0fd6899b690","trusted":true},"cell_type":"code","source":"%matplotlib inline\n# box plot to visualize the outliers of 'var3', 'var15', 'num_var46', 'saldo_var27', 'var38','TARGET'.\ntrain[['var3', 'var15', 'num_var46', 'saldo_var27', 'var38','TARGET']].plot(kind='box', subplots=True, figsize=(12, 6))\nplt.show()","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"67e73204-f0a8-43a8-9310-00458d062ae0","_uuid":"9d3885771be51b30535b479180379d1eec86549b"},"cell_type":"markdown","source":"**Data setup**\n\n- Seperate the labels.\n- Drop TARGET, ID variables from training set.\n- Drop ID variables from testing set."},{"metadata":{"_cell_guid":"4dfe7a6d-b590-497b-93f2-980dca6426bf","_uuid":"00ec809f4dd91b8beaf2ad81ce468208b1976afd","trusted":true},"cell_type":"code","source":"# Dropping target and ids from traning and testing data-sets\nlabels =  train['TARGET']\nids = test['ID']\ntrain.drop(['TARGET', 'ID'], axis = 1, inplace = True)\ntest.drop(['ID'], axis = 1, inplace = True)\nprint(train.shape, '=', test.shape)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"80d7c2db-15fd-414a-8b3a-7cb3b7ccc0bb","_uuid":"9dc48aa38be956e265e84ef5db4d65a997a38243"},"cell_type":"markdown","source":"**Data Preprocessing**\n\n- Remove constant columns, handle missing values and apply PCA on training and testing sets"},{"metadata":{"_cell_guid":"484ab70d-2b00-4a78-9fb3-572a2f56a3d3","_uuid":"5102ba3730263fcbbd94d0a8dfce1022fdc9ef4c","trusted":true},"cell_type":"code","source":"# 1st setp: remove constant columns in training data\nremove = []\nfor col in train.columns:\n    if train[col].std() == 0:\n        remove.append(col)\nprint(\" >> Constant columes: \",remove)\ntrain.drop(remove, axis=1, inplace=True)\nprint('>> train shape after removing constant columns: ', train.shape)","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"cd1d629e-8695-4302-a7a3-5472c1920cb3","_uuid":"98169c44f41029d6e227c46f7c0efae9af156c41","trusted":true},"cell_type":"code","source":"# 2nd step: handle missing values in training set\nprint((train == -999999).sum())","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"5d175c90-e0cf-4ce4-9fdf-baf6179bcdc8","_uuid":"710a8b950c03c3b7fb91bc6c532a7896146aacb4","trusted":true},"cell_type":"code","source":"# var3 has 116 missing values.\n# one way to handle this issue by replacing these values with the mode of var3\ntrain['var3'].replace(-999999,train['var3'].mode())","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"ef3cb7b4-2f95-4043-903c-63dfe5a5ebf9","_uuid":"9297fbc34185a9323dd68dfb2a210f0925652271","trusted":true,"collapsed":true},"cell_type":"code","source":"# 3rd step: Scaling the training data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(train)\nscaled_train = scaler.transform(train)","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"4a6027f0-aa19-4f83-9931-0d533ee8f143","_uuid":"e4b10b5b165b5a6f2f18f0055c4a203e74535a7a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Scaling the test data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(test)\nscaled_test = scaler.transform(test)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"a4f365cf-f884-49c2-8000-d59adb43827c","_uuid":"924c03f24ea41e95da620dfef300196ad81d002f"},"cell_type":"markdown","source":"**Pipe Line**\n\nBuild a pipeline to training, test a model and plot ROC curve"},{"metadata":{"_cell_guid":"d5e0180c-2bb9-44a5-8f38-850e23e6dff1","_uuid":"461553789bce14678dcb38522cdf78a538481df3","collapsed":true,"trusted":true},"cell_type":"code","source":"# Creating a Training and Predicting Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nimport time\ndef train_predict(learner, X_train, y_train, X_test, y_test): \n    '''\n    inputs:\n       - learner: the learning algorithm to be trained and predicted on\n       - X_train: features training set\n       - y_train: labels training set\n       - X_test: features testing set\n       - y_test: labels testing set\n    '''\n    \n    results = {}\n    start = time.time() # Get start time\n    learner = learner.fit(X_train, y_train)\n    end = time.time() # Get end time \n    # Calculate the training time\n    results['train_time'] = end - start\n    \n    start = time.time() # Get start time\n    predictions_test = learner.predict_proba(X_test)[:,1]\n    end = time.time() # Get end time \n    # Calculate the total prediction time\n    results['pred_time'] = end - start\n    \n    # Compute roc_auc_score\n    results['roc_auc_score'] = roc_auc_score(y_test, predictions_test)\n    \n    # plot roc_curve\n    fpr, tpr, thresholds = roc_curve(y_test, predictions_test)\n    plt.figure()\n    plt.plot(fpr, tpr, label='%s (area = %0.5f)' % (learner.__class__.__name__, results['roc_auc_score']))\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.savefig('Log_ROC')\n    plt.show()\n    \n    # Success\n    print(\"{} is trained.\".format(learner.__class__.__name__))\n        \n    # Return the results\n    return results","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"bff2f439-20c6-4088-8583-bbdc3d514fe7","_uuid":"1465c873b3d0afe05620b4b50b44cf575b8dd8c3","collapsed":true},"cell_type":"markdown","source":"**Benchmark**\n\nThe benchmark model is *LogisticRegression* on  data using all the features."},{"metadata":{"trusted":true,"_uuid":"c978df78a593e534d9fe27ec5b148762f3d85131"},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\n\n# Split the unscaled traning data into training and testing sets\n# Reserve the last 15204 raw of traning set for final testing\nbX_train, bX_test, by_train, by_test = train_test_split(train[:60817], labels[:60817], test_size = 0.2, random_state = 0)\n\n# Split the scaled traning data into training and testing sets\n# Reserve the last 15204 raw of traning set for final testing\nbsX_train, bsX_test, bsy_train, bsy_test = train_test_split(scaled_train[:60817], labels[:60817], test_size = 0.2, random_state = 0)","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"d77782c2-12f0-44e3-9e41-f5cc332c1e2a","_uuid":"4d46ea1d6c2e437a7601a4460c61fcf264b7028b","trusted":true},"cell_type":"code","source":"# Test the benchmark model using unscaled data\nfrom sklearn.linear_model import LogisticRegression\nlg = LogisticRegression()\nLogistic_results =  train_predict(lg, bX_train, by_train, bX_test, by_test)\n\nprint('Benchmark results using unscaled data : ', Logistic_results)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"499de8fc-c7a3-4b85-9c2f-6c6cc6c7a4d4","_uuid":"04c283ec8ab5425dd44bb3c0453181ce66cc5f9e","trusted":true},"cell_type":"code","source":"# using scaled data\nlg2 = LogisticRegression()\nLogistic_results2 =  train_predict(lg2, bsX_train, bsy_train, bsX_test, bsy_test)\n\nprint('Benchmark results using scaled data : ',Logistic_results2)","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"387d0cdf-4070-4d90-b190-5bd325133993","_uuid":"7ed79dc06e265198009e54e2c08d6035ab144d23","collapsed":true},"cell_type":"markdown","source":"**Implementation**\n\n- Apply PCA on training and testing sets.\n- Test RondomForest using scaled traing data and reduced data using PCA.\n- Test XgBoost using scaled traing data and reduced data using PCA."},{"metadata":{"_cell_guid":"45a1aa48-9b5f-45e2-bf57-7f0e54b99e2f","_uuid":"a7b6b7d02f6f26985ce929291128b71f0881786c","trusted":true},"cell_type":"code","source":"# applay PCA for dimensionality reduction and speed-up ML algorithm by selecting the important features on training and testing sets.\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=90)\npca.fit(scaled_train)","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"9a99914f-f1d1-4b4c-b557-bf0e2b55fde7","_uuid":"652cc8a1c9877ff5d9d085ff6b061b53f61183b1","trusted":true},"cell_type":"code","source":"print('components: ', pca.n_components_)","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"e80dac6f-6fda-42a0-959e-ab6cedab37b4","_uuid":"5a126d8c5030dfa760e472e8090bd5f2ebd8d22a","trusted":true},"cell_type":"code","source":"print('explained variance', sum(pca.explained_variance_ratio_))","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"0aee60c4-812d-49ed-8a1c-8d1eaf1ce5aa","_uuid":"1d450ae8f7100563d3ec3ffd4e839ff8b094bd2d","trusted":true},"cell_type":"code","source":"# applying transformation to the training data\nt_train = pca.transform(scaled_train)\n\nprint(' training set after transformation: ',t_train.shape)","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"dabc9d3f-e1c6-4cce-9503-ae77fe30632b","_uuid":"ee70e030c7d86c5db9afef01fb8b2aeb77e6025f","trusted":true},"cell_type":"code","source":"# applay PCA for testing sets.\nfrom sklearn.decomposition import PCA\npca2 = PCA(n_components=90)\npca2.fit(scaled_test)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"5d0a09b6-c7ba-4237-a574-354bac6c8d56","_uuid":"39fea5ae4d10984334f606b5d34f31afabda6402","trusted":true},"cell_type":"code","source":"t_test = pca2.transform(scaled_test)\nprint('components: ', pca2.n_components_)\nprint('explained variance', sum(pca2.explained_variance_ratio_))\nprint('testing set after transformation: ',t_test.shape)","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"26ace06a-daab-46b8-9fb8-811710bfd140","_uuid":"8dcec7b68d37d7a2f43c1907d2dd75e8c7146e9e","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\n\n# Split the scaled traning data into training and testing sets\n# Reserve the last 15204 raw of traning set for final testing\nX_train, X_test, y_train, y_test = train_test_split(scaled_train[:60817], labels[:60817], test_size = 0.2, random_state = 0)\n\n# Split the reduced traning data using PCA into training and testing sets\n# Reserve the last 15204 raw of traning set for final testing\ntX_train, tX_test, ty_train, ty_test = train_test_split(t_train[:60817], labels[:60817], test_size = 0.2, random_state = 0)","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"39b74a30-e7e6-4d52-bf32-c5090490848c","_uuid":"b8fcad7b4f567aebc12110bd065799c52e69ce62"},"cell_type":"markdown","source":"**1st model: Random Forest**"},{"metadata":{"_cell_guid":"462b81f8-ed48-4bc5-b3be-c69f52827e45","_uuid":"5fb82a5f85b9b7568e2a10def96bb0fbebf3afcf","trusted":true},"cell_type":"code","source":"# 1st model : Random Forest\n# Using scaled data and reduced data\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=100, max_depth=10)\nforest_results_scaled =  train_predict(clf, X_train, y_train, X_test, y_test)\n\nprint('Random Forest result with scaled data: ', forest_results_scaled)","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"0a9ded97-ca5b-44f7-9c2e-71707ae28c1f","_uuid":"fdcf054583f897646eacb6889a9f8d2c7a47ca35","trusted":true},"cell_type":"code","source":"forest_results_reduced =  train_predict(clf, tX_train, ty_train, tX_test, ty_test)\nprint('Random Forest result with reduced data: ',forest_results_reduced)","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"d403370b-cb93-4a73-9a9f-e2eb37ee4066","_uuid":"3ece57aa2d9dcdd7cb7a93c83030ff4d057b5632"},"cell_type":"markdown","source":"**2nd model: Xgboost**"},{"metadata":{"_cell_guid":"c353249d-1776-4609-8c6c-25e6817ddcd0","_uuid":"fc0ebb59c152d4860f6ce428c53833502b68acdc","trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(subsample=0.8, n_estimators=100, min_child_weight=10, max_depth=5, gamma=0.5, colsample_bytree=0.8)\nXgboost_results_scaled =  train_predict(xgc, X_train, y_train, X_test, y_test)\nprint('Xgboost results with scaled: ', Xgboost_results_scaled)","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"da504dde-f94e-4698-9dbf-cfbeacf75da9","_uuid":"f37a712487539f5fb4e7196285f20f192ab5f83f","trusted":true},"cell_type":"code","source":"Xgboost_results_reduced =  train_predict(xgc, tX_train, ty_train, tX_test, ty_test)\nprint('Xgboost results with reduced: ', Xgboost_results_reduced)","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"b6c34a98fc171ae849c497c938426a633d94bc35"},"cell_type":"markdown","source":"**XgBoost model gets higher score using scaled and reduced data, so it will be tunned to get better preformance**"},{"metadata":{"_cell_guid":"fddc9ed5-d88f-4d4a-9e92-1f1c279c4855","_uuid":"6a5cf5f80f1f64724e9e804662330c0d917ad99a"},"cell_type":"markdown","source":"**Xgboost tuning**\n\nAs XgBoost gets higher score using default parameters, GridSearchCV will be exhausted search that takes alot of time. Instead, *RandomizedSearchCV*  has a probability of 95% of finding a combination of parameters within the 5% optima with only 60 iterations. Also compared to other methods, it doesn't bog down in local optima."},{"metadata":{"_cell_guid":"d172ed6a-5cf2-441a-b138-197835345f1a","_uuid":"6fc8de9628f67539db1c7e2ac0481bff5ceab333","trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold\n# from sklearn.model_selection import RandomizedSearchCV\n\n# xgc2 = XGBClassifier()\n# # A parameter grid for XGBoost\n# params = {\n#         'n_estimators' : [100, 200, 300],\n#         'min_child_weight': [1, 5, 10],\n#         'gamma': [0.5, 1, 1.5, 2, 5],\n#         'subsample': [0.6, 0.8, 1.0],\n#         'colsample_bytree': [0.6, 0.8, 1.0],\n#         'max_depth': [3, 4, 5]\n#         }\n# kfold = StratifiedKFold(n_splits=3)\n# random_search = RandomizedSearchCV(xgc2, param_distributions=params, scoring='roc_auc', n_jobs=4, cv=kfold, verbose=5, n_iter=50)\n\n# start_time = time.time()\n# random_search.fit(tX_train, ty_train)\n# print('>> Tuning time: ',time.time()-start_time)\n\n","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"816e5116-8b40-443c-9d49-88c432b741f2","_uuid":"b609154b094f1eea8c55e745ca383ef3855ebe18","trusted":true},"cell_type":"code","source":"# print('\\nBest estimator:')\n# print(random_search.best_estimator_)\n# print(\"\\nscore :\")\n# print(random_search.best_score_ )\n# print('\\n Best hyperparameters:')\n# print(random_search.best_params_)","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"642c8044-bb44-440c-85a4-cddf5f122484","_uuid":"e2c84975823cf031a3f99da3befddbfe01d6b485","trusted":true},"cell_type":"code","source":"# tunned_model_results = train_predict(random_search.best_estimator_, tX_train, ty_train, tX_test, ty_test)\n# print('tunned Xgboost results with reduced: ', Xgboost_results_reduced)","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"8e21054e-e7a7-4d64-afbd-6a57f6e5b66f","_uuid":"bd525dc34d0b578b2ed8f860bde4b8362beae339","trusted":true},"cell_type":"code","source":"# untunned Xgboost parameters\n# xgc","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"a63fe07e-ecad-44ce-9656-773bbb8e0334","_uuid":"710957cd294b665d08bc0c7355448a5e37c56377","collapsed":true},"cell_type":"markdown","source":"**Final Prediction**\n\n- Testing the tunned model with last 15204 rows of *reduced training* set as tesing set.\n- Compare the result with Benchmark model prediction on last 15204 rows of *scaled traing set*."},{"metadata":{"_cell_guid":"a0664238-c1ff-4bfd-bbb5-fa0598d3ce28","_uuid":"ea5a939a5a0eb3f0cb2578f7dfedf384496ab890","collapsed":true,"trusted":true},"cell_type":"code","source":"# def get_final_score(learner, X_test, y_test):\n#     start = time.time() # Get start time\n#     predictions_test = learner.predict_proba(X_test)[:,1]\n#     end = time.time() # Get end time \n#     print('%s gets score of %0.5f , prediction time = %0.2f' % (learner.__class__.__name__, roc_auc_score(y_test, predictions_test),  end - start) ) ","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"53164d0d-fff0-4917-9098-d83054495afe","_uuid":"4a341a1eaa7021307d6da8807c6addf0769592be","trusted":true},"cell_type":"code","source":"# get_final_score(random_search.best_estimator_, t_train[60817:], labels[60817:])\n# get_final_score(lg2, scaled_train[60817:], labels[60817:])","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"5b569e10-dcc0-447e-bd88-a6e7fa9e1745","_uuid":"de60e8d861d79d75fff8326ee7718839aa553b55"},"cell_type":"markdown","source":"**Using the final tunned model on original Kaggle competition test set**"},{"metadata":{"_cell_guid":"1260d2ce-d377-48dc-bc4b-b679b21f9678","_uuid":"1b46cc6023e256fea8e7f6db009b3bb4eb70824e","trusted":true},"cell_type":"code","source":"results = xgc.predict_proba(t_test)[:,1]\nsubmission = pd.DataFrame({'ID': ids, 'TARGET':results})\nsubmission.to_csv('../working/submission16.csv', index=False)\nprint('done')","execution_count":44,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}