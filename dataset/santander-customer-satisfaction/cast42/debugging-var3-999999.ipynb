{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use(\"Agg\") #Needed to save figures\nfrom sklearn import cross_validation\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\n\ntraining = pd.read_csv(\"../input/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/test.csv\", index_col=0)\n\nprint(training.shape)\nprint(test.shape)\n\nX = training.iloc[:,:-1]\ny = training.TARGET\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, f_classif\n\nselectK = SelectKBest(f_classif, k=220)\nselectK.fit(X, y)\nX_sel = selectK.transform(X)\n\nfeatures = X.columns[selectK.get_support()]\nprint (features)\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X_sel, y, random_state=1301)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"features[0]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"training['var3'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"training.loc[training['var3'] != -999999, 'var3'].hist(bins=1000)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X_train = training.loc[training['var3'] != -999999, features[1:]]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"y_train = training.loc[training['var3'] != -999999, 'var3']"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X_test = training.loc[training['var3'] == -999999, features[1:]]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"clf = KNeighborsClassifier(n_neighbors=20)\nclf.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"y_test = clf.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"y_test"},{"cell_type":"markdown","metadata":{},"source":"Conclusion: replace -999999 values with most common values 2 is probably a good approach"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Check in what columns value -999999 appears\nprint ([f for f in X.columns if X[f][X[f] == -999999].shape[0] > 0])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Replace value -999999 in column var3\nX.var3 = X.var3.replace(-999999,2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}