{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\nclass EstimatorSelectionHelper:\n\n    def __init__(self, models, params):\n        if not set(models.keys()).issubset(set(params.keys())):\n            missing_params = list(set(models.keys()) - set(params.keys()))\n            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n        self.models = models\n        self.params = params\n        self.keys = models.keys()\n        self.grid_searches = {}\n\n    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n        for key in self.keys:\n            print(\"Running GridSearchCV for %s.\" % key)\n            model = self.models[key]\n            params = self.params[key]\n            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n                              verbose=verbose, scoring=scoring, refit=refit,\n                              return_train_score=True)\n            gs.fit(X,y)\n            self.grid_searches[key] = gs    \n\n    def score_summary(self, sort_by='mean_score'):\n        def row(key, scores, params):\n            d = {\n                 'estimator': key,\n                 'min_score': min(scores),\n                 'max_score': max(scores),\n                 'mean_score': np.mean(scores),\n                 'std_score': np.std(scores),\n            }\n            return pd.Series({**params,**d})\n\n        rows = []\n        for k in self.grid_searches:\n            print(k)\n            params = self.grid_searches[k].cv_results_['params']\n            scores = []\n            for i in range(self.grid_searches[k].cv):\n                key = \"split{}_test_score\".format(i)\n                r = self.grid_searches[k].cv_results_[key]        \n                scores.append(r.reshape(len(params),1))\n\n            all_scores = np.hstack(scores)\n            for p, s in zip(params,all_scores):\n                rows.append((row(k, s, p)))\n\n        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n\n        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n        columns = columns + [c for c in df.columns if c not in columns]\n\n        return df[columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing data\ntrain_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\n\n# cleaning data\nremove = []\nc = train_data.columns\nfor i in range(len(c)-1):\n    v = train_data[c[i]].values\n    for j in range(i+1,len(c)):\n        if np.array_equal(v,train_data[c[j]].values):\n            remove.append(c[j])\n\ntrain_data.drop(remove, axis=1, inplace=True)\n\n# Split into validation and training data\ntrain_X, test_X, train_y, test_y = train_test_split(train_data.drop([\"TARGET\",\"ID\"],axis=1),\n                                                  train_data.TARGET, \n                                                  random_state=0,\n                                                  test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature selection\n# need to select the most important features\n# will be using ExtraTreesClasifier for this task\n\nfeature_selection_model = ExtraTreesClassifier()\nfeature_selection_model.fit(train_X, train_y)\nsel = SelectFromModel(feature_selection_model, prefit = True)\n\nimportant_features = train_X.columns[(sel.get_support())]\n# print(important_features)\n\nfeat_imp = pd.Series(feature_selection_model.feature_importances_, index = train_X.columns.values).sort_values(ascending=False)\nfeat_imp[:len(important_features)].plot(kind='bar', title='Most important features based on ExtraTreesClassifier', figsize=(16, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding best model with best hyperparameters\nmodels1 = {\n    'ExtraTreesClassifier': ExtraTreesClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'AdaBoostClassifier': AdaBoostClassifier(),\n    'GradientBoostingClassifier': GradientBoostingClassifier(),\n    'XGBClassifier': XGBClassifier()\n}\n\nparams1 = {\n    'ExtraTreesClassifier': { 'n_estimators': [64, 128, 256, 512, 1024] },\n    'RandomForestClassifier': { 'n_estimators': [64, 128, 256, 512, 1024], 'min_samples_split': [2, 4, 8, 16] },\n    'AdaBoostClassifier':  { 'n_estimators': [64, 128, 256, 512, 1024] },\n    'GradientBoostingClassifier': { 'n_estimators': [64, 128, 256, 512, 1024], 'learning_rate': [0.8, 1.0] },\n    'XGBClassifier': { 'n_estimators': [64, 128, 256, 512, 1024], 'max_depth': [1, 2, 3, 4, 5, 6]}\n}\n\nhelper1 = EstimatorSelectionHelper(models1, params1)\nhelper1.fit(train_X[important_features], train_y, scoring='roc_auc', n_jobs=2, refit= True)\n\nhelper1.score_summary(sort_by='mean_score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting the best estimator\nclf = helper1.grid_searches.get('XGBClassifier').best_estimator_\nprint(helper1.grid_searches.get('XGBClassifier').best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building final model and submitting to competition\n\n#refit model with all train data\n# clf = XGBClassifier(n_estimators=256, max_depth=1)\nclf.fit(train_data.drop([\"TARGET\",\"ID\"],axis=1)[important_features], train_data.TARGET)\n\nsubmission_preds = clf.predict_proba(test_data[important_features])[:,1]\n\noutput = pd.DataFrame({'ID': test_data.ID,\n                      'TARGET': submission_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}