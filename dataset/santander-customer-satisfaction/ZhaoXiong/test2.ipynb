{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# remove columns with all identical value\n\ndef identify_constant_features(dataframe):\n    count_uniques = dataframe.apply(lambda x: len(x.unique()))\n    constants = count_uniques[count_uniques == 1].index.tolist()\n    return constants\n\nnonUnique_feature_train = set(identify_constant_features(train))\ntrain.drop(nonUnique_feature_train, inplace=True, axis=1)\n\nfrom itertools import combinations\nfrom numpy import array,array_equal\n\ndef identify_equal_features(dataframe):\n    features_to_compare = list(combinations(dataframe.columns.tolist(),2))\n    equal_features = []\n    for compare in features_to_compare:\n        is_equal = array_equal(dataframe[compare[0]],dataframe[compare[1]])\n        if is_equal:\n            equal_features.append(list(compare))\n    return equal_features\n\nequal_features_train = identify_equal_features(train)\n\n# Remove the second feature of each pair.\n\nfeatures_to_drop = array(equal_features_train)[:,1] \ntrain.drop(features_to_drop, axis=1, inplace=True)\n\ntest.drop(nonUnique_feature_train, inplace=True, axis=1)\ntest.drop(features_to_drop, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.loc[train[\"var3\"]==-999999,\"var3\"] = 2\nall_clomuns = list(train.columns.values)\nall_clomuns.remove(\"ID\")\nall_clomuns.remove(\"TARGET\")\nfrom sklearn.feature_selection import f_classif\nimport numpy as np\nf_values, p_values = f_classif(train[all_clomuns], train[\"TARGET\"])\np_values = -np.log10(p_values)\np_values_dict = {}\nfor idx,value in enumerate(p_values):\n    if value not in p_values_dict:\n        p_values_dict[value] = [all_clomuns[idx]]\n    else:\n        p_values_dict[value].append(all_clomuns[idx])\nidentical_pvalues = []\nfor value in p_values_dict.keys():\n    if (len(p_values_dict[value])>1):\n        for name in p_values_dict[value][1:]:\n            all_clomuns.remove(name)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train2 = train[all_clomuns]\ncorrMatrix=train2.corr()\n\ncorrMatrix.loc[:,:] =  np.tril(corrMatrix, k=-1) # borrowed from Karl D's answer\nalready_in = set()\nresult = []\nfor col in corrMatrix:\n    perfect_corr = corrMatrix[col][corrMatrix[col] > 0.9].index.tolist()\n    if perfect_corr and col not in already_in:\n        already_in.update(set(perfect_corr))\n        perfect_corr.append(col)\n        result.append(perfect_corr)\nfor pair in result:\n    for name in pair[1:]:\n        if name in all_clomuns:\n            all_clomuns.remove(name)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\n\ny_train = train['TARGET'].values\nX_train = train[all_clomuns].values\n\nid_test = test['ID']\nX_test = test[all_clomuns].values\n\n# length of dataset\nlen_train = len(X_train)\nlen_test  = len(X_test)\n\n# classifier\nclf = xgb.XGBClassifier(missing=np.nan, max_depth=6, n_estimators=500, learning_rate=0.02, nthread=4, subsample=0.75, colsample_bytree=0.75, seed=1024)\n\nX_fit, X_eval, y_fit, y_eval= train_test_split(X_train, y_train, test_size=0.3)\n\n# fitting\nclf.fit(X_train, y_train, early_stopping_rounds=30, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)],verbose=1)\n\n# predicting\ny_pred= clf.predict_proba(X_test)[:,1]\n\nsubmission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\nsubmission.to_csv(\"submission6.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}