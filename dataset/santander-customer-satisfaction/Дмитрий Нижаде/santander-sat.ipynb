{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndef plot_feature_importances(model, columns):\n    nr_f = 10\n    imp = pd.Series(data = model.best_estimator_.feature_importances_, \n                    index=columns).sort_values(ascending=False)\n    plt.figure(figsize=(7,5))\n    plt.title(\"Feature importance\")\n    ax = sns.barplot(y=imp.index[:nr_f], x=imp.values[:nr_f], orient='h')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/santander-customer-satisfaction/train.csv')\ndf_test_final =  pd.read_csv('/kaggle/input/santander-customer-satisfaction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# смотрим данные\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# доля таргета\ndf[\"TARGET\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# на всякий случай\ndf = df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сохранаяем тагет отдельно, а из теста выкидываем его и айди\ny = df['TARGET']\ndf.drop(['TARGET',\"ID\"], 1, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# скейлим\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nscaler.fit(df)\nscaled_features = scaler.transform(df)\ndf_sc = pd.DataFrame(scaled_features) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# трейн тест\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df_sc, y, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#решаем в лоб логрегрессией\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\n# какие параметры будем перебирать\ntuned_parameters = [{\n                    'penalty' : ['l1', 'l2'] # \n                #    'solver' : [ 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n                    }]\n\n#'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]\n\n# настройки перебора\nclf = GridSearchCV(\n        LogisticRegression(max_iter = 1000), tuned_parameters, scoring='roc_auc', verbose = 4, n_jobs = 3\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и считаем score\ny_pred_score = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n# делаем предсказания и считаем score\ny_pred_score = clf.predict_proba(X_test)[:,1]\nroc_auc_score(y_test,y_pred_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# какие параметры будем перебирать\ntuned_parameters = [{\n                    'penalty' : [ 'l2'],\n                    'solver' : [ 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n                    }]\n\n#'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]\n\n# настройки перебора\nclf = GridSearchCV(\n        LogisticRegression(max_iter = 100), tuned_parameters, scoring='roc_auc', verbose = 4, n_jobs = 3,cv=2\n    )\n\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сравниваем между собой подходы\nclf.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train: ',clf.best_score_)\ny_pred_score = clf.predict_proba(X_test)[:,1]\nprint('test rocauc:',roc_auc_score(y_test,y_pred_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# и еще раз\ntuned_parameters = [{\n                    'penalty' : [ 'l2'],\n                    'solver' : [ 'lbfgs'],\n                    'C': [0.001,0.01,0.1,1,10,100,1000]\n                    }]\n\n# настройки перебора\nclf = GridSearchCV(\n        LogisticRegression(max_iter = 100), tuned_parameters, scoring='roc_auc', verbose = 4, n_jobs = 3,cv=3\n    )\n\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train: ',clf.best_score_)\ny_pred_score = clf.predict_proba(X_test)[:,1]\nprint('test rocauc:',roc_auc_score(y_test,y_pred_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import RocCurveDisplay\n\nfpr, tpr, _ = roc_curve(y_test, y_pred_score, pos_label=clf.classes_[1])\nroc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import PrecisionRecallDisplay\n\nprec, recall, _ = precision_recall_curve(y_test, y_pred_score,\n                                         pos_label=clf.classes_[1])\npr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ntuned_parameters = [{'kernel': ['rbf'],#['linear','poly','rbf'], \n                    # 'gamma': [1e-3, 1e-4]\n                   #  'C': [1, 10, 100],\n                    #  'degree': range(1,3,1),\n                    # 'class_weight' : [None,'balanced']\n                     }]\n\ncv_svc = GridSearchCV(\n        SVC(probability=True), tuned_parameters, scoring='roc_auc', verbose = 4, n_jobs = 5, cv=2\n    )\ncv_svc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train: ',cv_svc.best_score_)\ny_pred_score = cv_svc.predict_proba(X_test)[:,1]\nprint('test rocauc:',roc_auc_score(y_test,y_pred_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# пробуем лес\nfrom sklearn.ensemble import RandomForestClassifier\n\ntuned_parameters = { \n    'n_estimators': [200] #, 700]\n    #'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(RandomForestClassifier(), tuned_parameters,verbose = 4, n_jobs = 5, cv= 2)\nCV_rfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train: ',CV_rfc.best_score_)\ny_pred_score = CV_rfc.predict_proba(X_test)[:,1]\nprint('test rocauc:',roc_auc_score(y_test,y_pred_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importances(CV_rfc, df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# пробуем бустинг\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ntuned_parameters = { \n    \"loss\":[\"deviance\"],\n    #\"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n    #\"min_samples_split\": np.linspace(0.1, 0.5, 12),\n    #\"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n    #\"max_depth\":[3,5,8],\n    #\"max_features\":[\"log2\",\"sqrt\"],\n    #\"criterion\": [\"friedman_mse\",  \"mae\"],\n    #\"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n    #\"n_estimators\":[10]\n}\n\nCV_gb = GridSearchCV(GradientBoostingClassifier(), tuned_parameters,verbose = 4, n_jobs = 5, cv= 2)\nCV_gb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train: ',CV_gb.best_score_)\ny_pred_score = CV_gb.predict_proba(X_test)[:,1]\nprint('test rocauc:',roc_auc_score(y_test,y_pred_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importances(CV_gb, df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем сделать некоторые переменные бинарными (те что по сути или равны нулю или большие сразу)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# отберем те пааметры где большинство значений (более 90%) являются нулями\nquants = df.quantile(0.9)\nquants_zero = quants[quants == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quants_zero.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bin = df.copy() # копируем в новый всве","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# для тех значений где 0.9перцентиль == 0 меняем все значения на бинарные\nfor q in quants_zero.index:\n    df_bin[q] = df[q].apply( lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# скалируем заново \nscaler_bin = StandardScaler()\n\nscaler_bin.fit(df_bin)\nscaled_features_bin = scaler_bin.transform(df_bin)\ndf_bin_sc = pd.DataFrame(scaled_features_bin) \n\n#и делим на трейн тест\nX_train_bin, X_test_bin, y_train_bin, y_test_bin = \\\n        train_test_split(df_bin_sc, y, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# и пробуем лог рег\ntuned_parameters = [{\n                    'penalty' : [ 'l2'],\n                    'solver' : [ 'lbfgs'],\n                    'C': [0.01]\n                    }]\n\n# настройки перебора\nclf_bin = GridSearchCV(\n        LogisticRegression(max_iter = 100), tuned_parameters, scoring='roc_auc', verbose = 4, n_jobs = 3,cv=3\n    )\n\nclf_bin.fit(X_train_bin, y_train_bin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train: ',clf_bin.best_score_)\ny_pred_score_bin = clf_bin.predict_proba(X_test_bin)[:,1]\nprint('test rocauc:',roc_auc_score(y_test_bin,y_pred_score_bin))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#подготавливаем данные для фин. тесат (нули, убираем айди, скейлим)\n\ndf_test_final = df_test_final.fillna(0)\ndf_test_ids = df_test_final[\"ID\"]\ndf_test_final.drop([\"ID\"], 1, inplace=True) \nscaled_features_fin = scaler.transform(df_test_final)\ndf_fin_sc = pd.DataFrame(scaled_features_fin) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#предиктим\n#y_pred_fin = clf.predict_proba(df_fin_sc)[:,1]\ny_pred_fin = CV_gb.predict_proba(df_fin_sc)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# возвращаем айдишники\nres = pd.concat([pd.DataFrame(df_test_ids), pd.DataFrame(data=y_pred_fin,columns=['TARGET'])],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.to_csv(\"/kaggle/working/res_gb.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# планы\n# затюнить random forest и gb","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}