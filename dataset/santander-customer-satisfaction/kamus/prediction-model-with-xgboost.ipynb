{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification project\nhttps://www.kaggle.com/c/santander-customer-satisfaction/"},{"metadata":{},"cell_type":"markdown","source":"# Import librairies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import metrics\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [20,15]\n\n#Show all columns\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################################################################################"},{"metadata":{},"cell_type":"markdown","source":"# DATA EXPLORATION"},{"metadata":{},"cell_type":"markdown","source":" ### Upload train.csv : <br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', index_col=0)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Upload test.csv : <br>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv', index_col=0)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create list for iterate on data processing "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test = [train, test]\nlen(train_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ratio happy  & unhappy customers\n*   0 : Happy\n*   1 : Unhappy"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.TARGET.value_counts()*100/train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"Nb_target=train[\"TARGET\"].value_counts(normalize=True).plot(kind=\"bar\")\nplt.title(\"TARGET\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We notice that the percentage of happier customers are way bigger than dissatisfied customers.\n* There is a risk for a bias! so, it's difficult to predict dissatisfied customers\n"},{"metadata":{},"cell_type":"markdown","source":"### Hypotheses of columns names \n* var4 : Numbers of products that a client has in this bank \n* Cash products: var05, var08, var06/29, var20, var24, var14 and var13. These sum up to var30\n* Credit products: var17, var44, var33. These sum up to var31\n* products: var25, var32. These sum up to var26.\n* Card products: var40, var41, var18, var34. These sum up to var01\n* product: var37"},{"metadata":{},"cell_type":"markdown","source":"############################################################################################"},{"metadata":{},"cell_type":"markdown","source":"# DATA PROCESSING"},{"metadata":{},"cell_type":"markdown","source":"We delete all culumns that have standart deviation equal O, cause can't improve the model of classification & others "},{"metadata":{},"cell_type":"markdown","source":"### Identify columns that have std = 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"delete = []\nfor col in train.columns:\n    if train[col].std() == 0:\n        delete.append(col) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Delete columns with std =0"},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in train_test:\n    df.drop(delete, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Supprimer les colonnes doublons"},{"metadata":{},"cell_type":"markdown","source":"1. ### List with duplicate columns (all same data between columns)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_duplicate(df,list_cols):\n    delete = []\n    for i in range(len(list_cols)-1):\n        v = df[list_cols[i]].values\n        for j in range(i+1,len(list_cols)):\n            if np.array_equal(v,df[list_cols[j]].values):\n                delete.append(list_cols[j])\n    return delete","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. ### Delete duplicate columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"delete = remove_duplicate(train,train.columns)\nfor df in train_test:\n    df.drop(delete, axis=1, inplace=True)\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.var3.value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see the outlier value (-9999999)"},{"metadata":{},"cell_type":"markdown","source":"### Replace outliers by most frequent value"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.replace(-999999,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.var3.value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Select Features & Label"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:,:-1]\ny = train.TARGET\n\n#X['n0'] = (X==0).sum(axis=1)\n#train['n0'] = X['n0']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Features Selections"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import f_classif,chi2\nfrom sklearn.preprocessing import Binarizer, scale\n\n#pourcentage des features à selectionner 3 /100 ==> pour 300 : environ 10 variables \np = 3\n\nX_bin = Binarizer().fit_transform(scale(X))\nselectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, y)\nselectF_classif = SelectPercentile(f_classif, percentile=p).fit(X, y)\n\n#Khi 2\nchi2_selected = selectChi2.get_support() # renvoi un mask\nchi2_selected_features = [ f for i,f in enumerate(X.columns) if chi2_selected[i]]\nprint('Chi2 selected {} features {}.'.format(chi2_selected.sum(),chi2_selected_features))\n\n#Fisher amélioré\nf_classif_selected = selectF_classif.get_support()\nf_classif_selected_features = [ f for i,f in enumerate(X.columns) if f_classif_selected[i]]\nprint('F_classif selected {} features {}.'.format(f_classif_selected.sum(),f_classif_selected_features))\n\n#Intersection khi2 & Fisher\nselected = chi2_selected & f_classif_selected\nprint('Chi2 & F_classif selected {} features'.format(selected.sum()))\nfeatures = [ f for f,s in zip(X.columns, selected) if s]\nprint (features)\n\n#Result\n#Chi2 selected 9 features ['var15', 'ind_var5', 'ind_var30', 'num_var5', 'num_var30', 'num_var42', 'saldo_var30', 'var36', 'num_meses_var5_ult3'].\n\n#F_classif selected 10 features ['var15', 'ind_var5', 'ind_var30', 'num_var4', 'num_var5', 'num_var30', 'num_var35', 'num_var42', 'var36', 'num_meses_var5_ult3'].\n\n#Chi2 & F_classif selected 8 features ['var15', 'ind_var5', 'ind_var30', 'num_var5', 'num_var30', 'num_var42', 'var36', 'num_meses_var5_ult3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model selection train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_sel = X[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X_sel, y, random_state=1301, stratify=y, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################################################################################"},{"metadata":{},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use xgboost model\nratio = float(np.sum(y == 1)) / np.sum(y==0)\n\nclf = xgb.XGBClassifier(missing=9999999999,\n                max_depth = 5,\n                n_estimators=1000,\n                learning_rate=0.1, \n                nthread=4,\n                subsample=1.0,\n                colsample_bytree=0.5,\n                min_child_weight = 3,\n                scale_pos_weight = ratio,\n                reg_alpha=0.03,\n                seed=1301)\n#Fit model\n                \nclf.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=\"auc\",\n        eval_set=[(X_train, y_train), (X_test, y_test)])\n        \n# Accuracy\nprint('Overall AUC:', roc_auc_score(y, clf.predict_proba(X_sel, ntree_limit=clf.best_iteration)[:,1]))\n    \n#Overall AUC: 0.8033776289761753","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"sel_test = test[features]\n#select best interation of xgboost\ny_pred = clf.predict_proba(sel_test, ntree_limit=clf.best_iteration)\ny_pred\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PLOTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_serie=pd.Series(clf.get_booster().get_fscore())\nscore_serie.sort_values().plot(kind=\"barh\", title=\"Features importance xgboost\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################################################################################"},{"metadata":{},"cell_type":"markdown","source":"### Create CSV submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggel_sub = pd.DataFrame({\"ID\":test.index, \"TARGET\":y_pred[:,1]})\nkaggel_sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}