{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np\nimport pandas as pd\nimport re\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npd.set_option('display.precision', 5)\n\ntraining = pd.read_csv(\"../input/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/test.csv\", index_col=0)\n\nprint(training.shape)\nprint(test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X = training.iloc[:,:-1]\ny = training.TARGET"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"y.value_counts() / float(y.size)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# ratio of nonzero elements\nX.apply(lambda x:x[x!=0].size).sum() / float(np.prod(training.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test.apply(lambda x:x[x!=0].size).sum() / float(np.prod(test.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X.dtypes.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X.columns"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"name_component = pd.Series(sum([re.sub(\"\\d+\", \"\", s).split(\"_\") for s in X.columns], []))\nname_component.replace(\"\", \"_0\", inplace=True)\nname_component.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"nuniques_train = X.apply(lambda x:x.nunique())\nnuniques_test = test.apply(lambda x:x.nunique())"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"no_variation_train = nuniques_train[nuniques_train==1].index\nno_variation_test = nuniques_train[nuniques_test==1].index\n\nprint(no_variation_train.size, no_variation_test.size)\n\nprint('\\nTrain[no variation in test]\\n#unique cnt\\n',nuniques_train[no_variation_test].value_counts())\nprint('\\nTest[no variation in train]\\n#unique cnt\\n', nuniques_test[no_variation_train].value_counts())"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X, test = [df.drop(no_variation_train, axis=1) for df in [X, test]]\nnuniques_train, nuniques_test = [s.drop(no_variation_train) for s in [nuniques_train, nuniques_test]]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"ax = nuniques_train[nuniques_train<100].hist(bins=100, figsize=(10, 7))\nax.set_xlabel(\"#uniques\")\nax.set_title(\"Histogram of #uniques (<100)\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"nuniques_train[nuniques_train<100].size"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"nuniques_train[nuniques_train>=100].size"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(X, y)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"feat_imp = pd.Series(rf.feature_importances_, index=X.columns)\nfeat_imp.sort_values(inplace=True)\nax = feat_imp.tail(20).plot(kind='barh', figsize=(10,7), title='Feature importance')"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}