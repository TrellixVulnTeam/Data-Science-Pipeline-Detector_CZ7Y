{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Importing required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, Conv1D, MaxPool1D\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imblearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/santander-customer-satisfaction/train.csv')\ntest=pd.read_csv('../input/santander-customer-satisfaction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing, Feature Engineering and transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the shape of the data\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for null values\ntrain.isnull().sum().sum() , test.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TARGET'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's remove ID column from both datasets and target column from train to make it a seperate series\ny_train_full=train['TARGET']\nx_train_full=train.drop(['ID', 'TARGET'], axis=1)\nx_test_final=test.drop(['ID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Oversampling using SMOTE\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking shape before any action\nx_train_full.shape, y_train_full.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smt=SMOTE()\nx_train_full, y_train_full = smt.fit_sample(x_train_full, y_train_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_full.shape, y_train_full.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the shape of the datasets\nx_train.shape, y_train.shape, x_test.shape, y_test.shape, x_test_final.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature selection methods: Filtering method"},{"metadata":{"trusted":true},"cell_type":"code","source":"quasi_filter=VarianceThreshold(0.01)\nx_train=quasi_filter.fit_transform(x_train)\nx_test=quasi_filter.transform(x_test)\nx_test_final=quasi_filter.transform(x_test_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape, x_test.shape, x_test_final.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Significant reduction of the useless features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check duplicated features now\n\nx_train_T=x_train.T\nx_test_T = x_test.T\nx_test_final_T=x_test_final.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_T=pd.DataFrame(x_train_T)\nx_test_T=pd.DataFrame(x_test_T)\nx_test_final_T=pd.DataFrame(x_test_final_T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_T.shape, x_test_T.shape, x_test_final_T.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_T.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicated_features=x_train_T.duplicated()\nduplicated_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features to keep will be inverse of duplicatd features\nfeatures_to_keep=[not index for index in duplicated_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=x_train_T[features_to_keep].T\nx_test=x_test_T[features_to_keep].T\nx_test_final=x_test_final_T[features_to_keep].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape, x_test.shape, x_test_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformation of the data now\n\nsc=StandardScaler()\nx_train_tx=sc.fit_transform(x_train)\nx_test_tx=sc.transform(x_test)\nx_test_final_tx=sc.transform(x_test_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the type of the dataset now\ntype(x_train_tx), type(x_test_tx), type(y_train), type(y_test), type(x_test_final_tx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we can see above, y train and y test are of pandas series type and not numpy array, hence we need to convert them to numpy array in order to proceed towards neural networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=y_train.to_numpy()\ny_test=y_test.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_train), type(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_tx=x_train_tx.reshape(x_train_tx.shape[0], x_train_tx.shape[1], 1)\nx_test_tx=x_test_tx.reshape(x_test_tx.shape[0], x_test_tx.shape[1], 1)\nx_test_final_tx=x_test_final_tx.reshape(x_test_final_tx.shape[0], x_test_final_tx.shape[1], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_tx[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv1D(32, 3, activation='relu', input_shape=x_train_tx[0].shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(64, 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(pool_size=2))\nmodel.add(Dropout(0.3))          \n\nmodel.add(Conv1D(128, 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(pool_size=2))\n          \nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\n          \nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\n          \nmodel.add(Dense(1, activation='sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(x_train_tx, y_train, validation_data=(x_test_tx, y_test), epochs=20, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(x_test_final_tx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=pd.DataFrame(y_pred, columns=['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred['TARGET']=np.where(y_pred['TARGET']>0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_new=pd.concat([test, y_pred], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=test_new[['ID', 'TARGET']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission4.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score on Kaggle is 0.71813","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}