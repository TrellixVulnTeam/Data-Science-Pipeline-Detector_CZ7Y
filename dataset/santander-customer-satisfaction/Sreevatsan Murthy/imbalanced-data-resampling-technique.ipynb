{"cells":[{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Data Exploration","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n\ntrain = pd.read_csv('../input/santander-customer-satisfaction/train.csv',index_col='ID')\ntest = pd.read_csv('../input/santander-customer-satisfaction/test.csv',index_col='ID')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"So we have imported the dataset. Let's look at the shape of the dataset","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"We have no categorical variables Now let's look at the null value situation","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.isnull().sum().unique()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"We can confirm that there are no null values or categorical variables and thus no requirement for cleaning the data","execution_count":null},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Vanilla Model - No Data Engineering","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Splitting the target variable and inputs","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"y = train.TARGET\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"x = train.drop(['TARGET'],axis=1) \nx.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Let's first attempt to build a plain vanilla model with no feature engineering whatsoever.","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(x,y,train_size=0.65,test_size=0.35,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true},"cell_type":"markdown","source":"### Vanilla model - Decision Tree","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import mean_absolute_error\n\n\nmodel = DecisionTreeClassifier(random_state=1)\nmodel.fit(X_train,Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"preds = model.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(preds,Y_val))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"This is a pretty horrible model. Although one might think that 93% accuracy is pretty good, we have to consider the precision and recall scores for both the classes - which is truly pathetic.","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"To emphasize that the problem lies in the dataset and not in the model chosen, let's use logistic regression to model this data","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(random_state=1)\n\nlr.fit(X_train,Y_train)\nprint(metrics.classification_report(lr.predict(X_val),Y_val))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"This confirms our problem - Imbalanced Dataset","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"print(y.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tackling Imbalanced Dataset problem","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are various ways one way can attack an imbalanced dataset problem. We discuss two\n\n1. Resampling Dataset : Under-sampling the majority class or over-sampling the minority class\n2. Using an ensemble model to achieve better generalization\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Resampling","execution_count":null},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"### Resampling : Under-sampling of majority class","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.TARGET.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Class 0 accounts for 96% of the dataset. Let's bring this down by selecting a subsample of class 0 to train with on class 1.","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"### General Function to randomly sample N*x , where N is the ratio of class 0 to class 1 points and \n### x is the number of class 1 points\n\ndef under_sampler(N,x = train.TARGET.value_counts()[1]):\n    class_0 = train[train['TARGET']==0].sample( int(N*x) ,random_state=1)\n    class_1 = train[train['TARGET']==1]\n    return pd.concat([class_0,class_1],axis=0)\n\ntrain_new = under_sampler(4)\ntrain_new.shape","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X = train_new.drop(columns='TARGET')\ny = train_new.TARGET\n\nX_train, X_val, y_train, y_val = train_test_split(X,y,random_state=1,train_size=0.8)\n\nmodel.fit(X_train,y_train)\npreds = model.predict(X_val)\nprint(metrics.classification_report(preds,y_val))\n","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"print(metrics.roc_auc_score(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"We already see tremendous improvement here in terms of precision , recall and Roc score","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Let's now experiment with different ratios in 1 to 5 in increments of 1","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"for N in np.arange(1.0,5.0,0.5):\n    train_new = under_sampler(N)\n    X = train_new.drop(columns='TARGET')\n    y = train_new.TARGET\n\n    X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=1,train_size=0.8)\n\n    model.fit(X_train,y_train)\n    preds = model.predict(X_val)\n    print(\"The ratio of majority to minor class is \",N)\n    print(metrics.classification_report(preds,y_val))\n","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"The trade-off between class 0 and class 1 precision scores are clear. For now an optimal solution seems like using a ratio of 3:1 for under-sampling. Let's move on to over-sampling and reviewing it's results","execution_count":null},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"### Resampling : Over-Sampling of minority class","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"There are majorly two ways one can achieve this\n1. Repition of class 1 data points\n2. SMOTE (Synthetic Minoirity Oversampling Technique)","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"##### Repitition","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Let's multiply the amount of class 1 points by two. The problem with this approach is that it risks overfitting since the classifier sees the same data over and over again (to be more precise, it sees it twice).","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train.TARGET.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train_new = train.copy()\n\ntrain_new = pd.concat([train_new,train_new[train_new.TARGET == 1]],axis=0)\ntrain_new.TARGET.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X = train_new.drop(columns='TARGET')\ny = train_new.TARGET\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,random_state=1,train_size=0.8)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)\npreds = model.predict(X_val)\nprint(metrics.classification_report(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(preds,y_val)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Surprisingly, we find better class 1 precision and recall scores without any effect on class 0 scores. Can we achieve better results while utilizing SMOTE?","execution_count":null},{"metadata":{"hidden":true},"cell_type":"markdown","source":"#### SMOTE (Synthetic Minority Oversampling Technique)","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"from collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"print(\"Ratio of minority to majority class points\",train.TARGET.value_counts()[1]/train.TARGET.value_counts()[0])","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"### CAUTION : Change n_jobs to match the number of threads that runs on your CPU. I have a CPU running 6 cores and 12 threads\n### and hence assinged n_jobs = 12. If you aren't sure of the number of threads on your CPU, remove the parameter n_jobs.\n\nsm = SMOTE(random_state=1,n_jobs=12,sampling_strategy = 0.25)# ratio of resampled minority class points to majority class points\n\nX_resampled, y_resampled = sm.fit_resample(X,y)\nprint(\"Before sampling : \",Counter(y),\"\\nAfter Sampling : \",Counter(y_resampled))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_resampled,y_resampled,random_state=1,train_size=0.8)\n\nmodel.fit(X_train,y_train)\npreds = model.predict(X_val)\nprint(metrics.classification_report(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(preds,y_val)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"A much better solution overall. We have greatly improved our scores using SMOTE. Now , what if we both under-sample majority class points and over sample minority class points after adjusting for ratios?","execution_count":null},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"predictions = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"out =pd.DataFrame({'ID':test.index,'TARGET':predictions})\nout.set_index('ID',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"out","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"out.to_csv(\"Predictions1.csv\",index=True)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"On kaggle this gives us a score of 0.58 auc","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Resampling : Both undersampling and oversampling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's under sample majojrity class points and over sample minority class points using SMOTE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Under-sampling : Take a sample of 4 times the number of minority class points","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = under_sampler(6)\n\nX = train_new.drop(columns='TARGET')\ny = train_new.TARGET\n\ny.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ratio of minority to majority class points is now 0.25 (1/4). Let's use SMOTE to bring this upto 0.5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=1,n_jobs=12,sampling_strategy = 0.4)\n\nX_resampled, y_resampled = sm.fit_resample(X,y)\nprint(\"Before sampling : \",Counter(y),\"\\nAfter Sampling : \",Counter(y_resampled))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's train the model and see","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_resampled,y_resampled,random_state=1,train_size=0.8)\n\nmodel.fit(X_train,y_train)\npreds = model.predict(X_val)\nprint(metrics.classification_report(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(preds,y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test)\nout =pd.DataFrame({'ID':test.index,'TARGET':predictions})\nout.set_index('ID',inplace=True)\nout.to_csv('Predicitions2.csv',index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On kaggle this gives us a score of 0.61 auc","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's try a couple of different combinations for sampling strategy in SMOTE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.TARGET.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = under_sampler(10)\n\nX = train_new.drop(columns='TARGET')\ny = train_new.TARGET","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_auc = 0\nfor i in np.arange(0.2,1,0.1):\n    sm = SMOTE(random_state=1,n_jobs=12,sampling_strategy = i)\n    X_resampled, y_resampled = sm.fit_resample(X,y)\n    #print(\"Before sampling : \",Counter(y),\"\\nAfter Sampling : \",Counter(y_resampled))\n    X_train,X_val,y_train,y_val = train_test_split(X_resampled,y_resampled,random_state=1,train_size=0.8)\n\n    model.fit(X_train,y_train)\n    preds = model.predict(X_val)\n    #print(metrics.classification_report(preds,y_val))\n    auc = metrics.roc_auc_score(preds,y_val)\n    if auc>max_auc:\n        max_auc = auc\n        SMOTE_ratio = i\n        \nprint(\"Optimal Soltution -\\nAUC Score : \",max_auc,\"\\nSMOTE Ratio : \",SMOTE_ratio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=1,n_jobs=12,sampling_strategy = 0.9)\nX_resampled, y_resampled = sm.fit_resample(X,y)\nprint(\"Before sampling : \",Counter(y),\"\\nAfter Sampling : \",Counter(y_resampled))\nX_train,X_val,y_train,y_val = train_test_split(X_resampled,y_resampled,random_state=1,train_size=0.8)\n\nmodel.fit(X_train,y_train)\npreds = model.predict(X_val)\nprint(metrics.classification_report(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(preds,y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test)\n\nout =pd.DataFrame({'ID':test.index,'TARGET':predictions})\nout.set_index('ID',inplace=True)\nout.to_csv('Predicitions3.csv',index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get a kaggle score of only 0.6 auc","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Ensemble models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The simplest ensemble model? Random Forest. Let's try that out","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X,y,train_size=0.8,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators = 100,n_jobs = 12,random_state=1)\nrfc.fit(X_train,y_train)\npreds = rfc.predict(X_val)\nprint(metrics.classification_report(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(preds,y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are still bad scores - especially precision and recall rates","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's combine our previous best method of under-sampling and over-sampling with RFC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = under_sampler(6)\n\nX = train_new.drop(columns='TARGET')\ny = train_new.TARGET\nsm = SMOTE(random_state=1,n_jobs=12,sampling_strategy = 0.4)\n\nX_resampled, y_resampled = sm.fit_resample(X,y)\n#print(\"Before sampling : \",Counter(y),\"\\nAfter Sampling : \",Counter(y_resampled))\nX_train,X_val,y_train,y_val = train_test_split(X_resampled,y_resampled,random_state=1,train_size=0.8)\n\nrfc.fit(X_train,y_train)\npreds = rfc.predict(X_val)\nprint(metrics.classification_report(preds,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(preds,y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rfc.predict(test)\n\nout =pd.DataFrame({'ID':test.index,'TARGET':predictions})\nout.set_index('ID',inplace=True)\nout.to_csv('Predicitions4.csv',index=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}