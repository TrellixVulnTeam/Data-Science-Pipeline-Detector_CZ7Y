{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cross_validation import KFold\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn import cross_validation, metrics\nfrom sklearn.metrics import confusion_matrix"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# read train and test data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n# remove constant columns\nremove = []\nfor col in train.columns:\n    if train[col].std() == 0:\n        remove.append(col)\n\ntrain.drop(remove, axis=1, inplace=True)\ntest.drop(remove, axis=1, inplace=True)\n\n# remove duplicated columns\nremove = []\nc = train.columns\nfor i in range(len(c)-1):\n    v = train[c[i]].values\n    for j in range(i+1,len(c)):\n        if np.array_equal(v,train[c[j]].values):\n            remove.append(c[j])\n\ntrain.drop(remove, axis=1, inplace=True)\ntest.drop(remove, axis=1, inplace=True)\nunhappy = train.loc[train['TARGET']==1]\nhappy = train.loc[train['TARGET']==0]\nnp.random.seed(10)\ntrain = pd.concat([unhappy.sample(len(happy), replace=True), happy], ignore_index=True)\ntrain = train.reindex(np.random.permutation(train.index)).reset_index(drop=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def modelfit(alg, dtrain, predictors, performCV=True,cv_folds=5):\n    X = dtrain[predictors].values\n    Y = dtrain['TARGET'].values\n    #Perform cross-validation:\n    if performCV:\n        cv_score = cross_validation.cross_val_score(\n            alg, X, Y, cv=cv_folds, scoring='roc_auc'\n        )\n    #Fit the algorithm on the data\n    alg.fit(X,Y)\n    #Predict training set:\n    dtrain_predictions = alg.predict(X)\n    dtrain_predprob = alg.predict_proba(X)[:,1]\n    #Print model report:\n    print(\"Model Report\")\n    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['TARGET'].values, dtrain_predictions))\n    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['TARGET'], dtrain_predprob))\n\n    if performCV:\n        print(\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"base_model = xgb.XGBClassifier(\n    objective='binary:logistic', n_estimators=300, learning_rate=0.04, \n    max_depth=5, nthread=4, subsample=0.7, colsample_bytree=0.5, \n    reg_lambda=6, reg_alpha=5, seed=10, silent=True\n)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"predictors = train.columns[1:-1]\nmodelfit(base_model, train, predictors)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\ndef model_score_and_feature(clf, features, n_feature=10):\n    sorted_index = np.argsort(clf.feature_importances_)[::-1]\n    top_feature = sorted_index[:n_feature]\n    top_feature_score = clf.feature_importances_[sorted_index[:n_feature]]\n    plt.barh(range(n_feature), top_feature_score[::-1])\n    ax = plt.gca()\n    ax.set_yticks(np.arange(n_feature)+0.5)\n    ax.set_yticklabels(features[top_feature][::-1])\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"model_score_and_feature(base_model, train.columns[1:-1])"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}