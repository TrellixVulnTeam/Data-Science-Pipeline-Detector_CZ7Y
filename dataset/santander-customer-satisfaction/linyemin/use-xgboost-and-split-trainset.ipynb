{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"导入需要用到的库"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV, cross_validate, KFold\n\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/santander-customer-satisfaction/train.csv\")\ntest = pd.read_csv(\"../input/santander-customer-satisfaction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在数据分析过程中，发现存在34个全为0的列，删除！"},{"metadata":{"trusted":true},"cell_type":"code","source":"remove = []\nfor col in train.columns:\n    if train[col].std() == 0:\n        remove.append(col)\n        \ntrain.drop(remove, axis=1, inplace=True)\ntest.drop(remove, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在数据分析过程中，发现存在30多个数据完全重复的列，删除！\n\n替换掉数值为-999999的值"},{"metadata":{"trusted":true},"cell_type":"code","source":"remove = []\ncols = train.columns\nfor i in range(len(cols)-1):\n    v = train[cols[i]].values\n    for j in range(i+1,len(cols)):\n        if np.array_equal(v,train[cols[j]].values):\n            remove.append(cols[j])\n            \ntrain.drop(remove, axis=1, inplace=True)\ntest.drop(remove, axis=1, inplace=True)\ntrain = train.replace(-999999,2)\ntest = test.replace(-999999,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test.ID\ntest = test.drop([\"ID\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"由于样本存在极度的不均衡，大致为96:4，\n\n因此考虑分割TARGET为0的样本，然后与TARGET为1的样本进行训练，大致2:1进行划分。"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_0 = train[train['TARGET'] == 0]\ntrain_df_1 = train[train['TARGET'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dfs = []\ntarget_df_length = len(train_df_1)\nfor i in range(len(train_df_0)//(target_df_length*2)):\n    item_df = train_df_0[target_df_length*2*i:target_df_length*2*(i+1)]\n    train_dfs.append(item_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"使用交叉验证进行调参，目前使用XGBoost模型。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n# for i in train_dfs[:1]:\n#     train_data_x = pd.concat([i,train_df_1]).drop(['TARGET','ID'],axis=1)\n#     train_data_y = [0]*len(i) + [1]*len(train_df_1)\n#     X, y = shuffle(train_data_x.values, train_data_y, random_state=0)\n#     model = xgb.XGBClassifier(max_depth = 5, n_estimators=160, learning_rate=0.02,nthread=4,\n#                 subsample=0.95, colsample_bytree=0.85)\n#     gscv = cross_validate(model, X, y, cv=5, scoring='roc_auc', n_jobs=-1)['test_score']\n#     print('Use model:{}'.format(model.__class__.__name__))\n#     print('Mean AUC:{:.5f}'.format(gscv.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"将分割的12组数据与TARGET为1的数据进行组合，并进行训练，形成12个训练模型。"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\npreds = []\nfor i in train_dfs:\n    train_data_x = pd.concat([i,train_df_1]).drop(['TARGET','ID'],axis=1)\n    train_data_y = [0]*len(i) + [1]*len(train_df_1)\n    X, y = shuffle(train_data_x.values, train_data_y, random_state=0)\n    model = xgb.XGBClassifier(max_depth = 5, n_estimators=160, learning_rate=0.02,nthread=4,\n            subsample=0.95, colsample_bytree=0.85) #0.840 0.836 0.840 0.840 0.838\n    model.fit(X, y)\n    models.append(model)\n    pred = model.predict_proba(test.values)\n    preds.append(pred[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"将test数据集通过模型进行预测，最后求12个模型预测结果的平均值，保存后提交成绩。"},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(preds).T\nres['sum'] = res.sum(axis=1)\nres['res1'] = res['sum']/12\nsubmission = pd.DataFrame({\"ID\":test_id, \"TARGET\": res['res1']})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}