{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightautoml","metadata":{"_kg_hide-output":true,"papermill":{"duration":15.040263,"end_time":"2021-06-09T14:25:58.561876","exception":false,"start_time":"2021-06-09T14:25:43.521613","status":"completed"},"tags":[],"scrolled":true,"execution":{"iopub.status.busy":"2021-08-22T08:47:44.616517Z","iopub.execute_input":"2021-08-22T08:47:44.617073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.stats import mode","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.923841,"end_time":"2021-06-09T14:25:59.520637","exception":false,"start_time":"2021-06-09T14:25:58.596796","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:31:59.777028Z","iopub.execute_input":"2021-08-22T07:31:59.777494Z","iopub.status.idle":"2021-08-22T07:31:59.781471Z","shell.execute_reply.started":"2021-08-22T07:31:59.777464Z","shell.execute_reply":"2021-08-22T07:31:59.780709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 3 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.3 # Test size for metric check\nTIMEOUT = 300 # Time in seconds for automl run\n\n\nTARGET_NAME = 'Survived' # Target column name\n# TARGET_NAME = 'TARGET' # Target column name\n\nTARGET_NAME","metadata":{"papermill":{"duration":0.040797,"end_time":"2021-06-09T14:25:59.595695","exception":false,"start_time":"2021-06-09T14:25:59.554898","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:32:00.462377Z","iopub.execute_input":"2021-08-22T07:32:00.462747Z","iopub.status.idle":"2021-08-22T07:32:00.469998Z","shell.execute_reply.started":"2021-08-22T07:32:00.462709Z","shell.execute_reply":"2021-08-22T07:32:00.469332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\nss = pd.read_csv('../input/titanic/gender_submission.csv')\n\n\n# train = pd.read_csv('../input/santander-customer-satisfaction/train.csv')\n# test = pd.read_csv('../input/santander-customer-satisfaction/test.csv')\n# ss = pd.read_csv('../input/santander-customer-satisfaction/sample_submission.csv')\n\n# for_drop = [col for col in train.columns if col.startswith('town_emb')] + ['id']\n# train.drop(for_drop, axis=1, inplace=True)","metadata":{"papermill":{"duration":1.36447,"end_time":"2021-06-09T14:26:00.993962","exception":false,"start_time":"2021-06-09T14:25:59.629492","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:32:00.974835Z","iopub.execute_input":"2021-08-22T07:32:00.976781Z","iopub.status.idle":"2021-08-22T07:32:01.018096Z","shell.execute_reply.started":"2021-08-22T07:32:00.976745Z","shell.execute_reply":"2021-08-22T07:32:01.017141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"papermill":{"duration":0.065183,"end_time":"2021-06-09T14:26:01.094088","exception":false,"start_time":"2021-06-09T14:26:01.028905","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:32:01.974056Z","iopub.execute_input":"2021-08-22T07:32:01.97439Z","iopub.status.idle":"2021-08-22T07:32:02.013203Z","shell.execute_reply.started":"2021-08-22T07:32:01.974358Z","shell.execute_reply":"2021-08-22T07:32:02.012382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(train, \n                                         test_size=TEST_SIZE, \n                                         stratify=train[TARGET_NAME], \n                                         random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: train_data = {}, test_data = {}'\n              .format(train_data.shape, test_data.shape))","metadata":{"papermill":{"duration":0.061066,"end_time":"2021-06-09T14:26:01.190126","exception":false,"start_time":"2021-06-09T14:26:01.12906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:32:02.802009Z","iopub.execute_input":"2021-08-22T07:32:02.802323Z","iopub.status.idle":"2021-08-22T07:32:02.816302Z","shell.execute_reply.started":"2021-08-22T07:32:02.802289Z","shell.execute_reply":"2021-08-22T07:32:02.815103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(columns=['TEST score'])","metadata":{"papermill":{"duration":0.044414,"end_time":"2021-06-09T14:26:01.269287","exception":false,"start_time":"2021-06-09T14:26:01.224873","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:32:03.726383Z","iopub.execute_input":"2021-08-22T07:32:03.726885Z","iopub.status.idle":"2021-08-22T07:32:03.733762Z","shell.execute_reply.started":"2021-08-22T07:32:03.726841Z","shell.execute_reply":"2021-08-22T07:32:03.733078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'drop': ['PassengerId', ],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\n# model0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\n# pie = ModelBasedImportanceEstimator()\n# selector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\n# model1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\n# pie1 = NpPermutationImportanceEstimator()\n# selector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=-9999)\n\n# pipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=4, top_numeric=4, check_mode=True, verbose_mode=True))\npipe = GroupByPipeline(None, top_category=4, top_numeric=4, check_mode=True, verbose_mode=True)\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], \n#                       pre_selection=selector, \n                      features_pipeline=pipe, \n#                       post_selection=selector1\n                     )\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=1)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())","metadata":{"execution":{"iopub.status.busy":"2021-08-22T07:33:43.296552Z","iopub.execute_input":"2021-08-22T07:33:43.299113Z","iopub.status.idle":"2021-08-22T07:33:46.178491Z","shell.execute_reply.started":"2021-08-22T07:33:43.299063Z","shell.execute_reply":"2021-08-22T07:33:46.177514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\n\n# Imports from our package\nfrom lightautoml.automl.base import AutoML\nfrom lightautoml.tasks import Task\n\nfrom lightautoml.dataset.roles import DatetimeRole, NumericRole, CategoryRole\nfrom lightautoml.dataset.np_pd_dataset import NumpyDataset, PandasDataset\n\nfrom lightautoml.pipelines.utils import get_columns_by_role\nfrom lightautoml.pipelines.features.base import EmptyFeaturePipeline, FeaturesPipeline, TabularDataFeatures\nfrom lightautoml.pipelines.features.base import FeaturesPipeline, TabularDataFeatures\n\nfrom lightautoml.pipelines.features.lgb_pipeline import LGBAdvancedPipeline, LGBSimpleFeatures\nfrom lightautoml.pipelines.ml.base import MLPipeline\n\nfrom lightautoml.pipelines.selection.base import  SelectionPipeline, ImportanceEstimator, PredefinedSelector\nfrom lightautoml.pipelines.selection.importance_based import ImportanceCutoffSelector, ModelBasedImportanceEstimator\nfrom lightautoml.pipelines.selection.permutation_importance_based import NpPermutationImportanceEstimator, \\\n    NpIterativeFeatureSelector, _create_chunks_from_list\n\nfrom lightautoml.ml_algo.boost_lgbm import BoostLGBM\nfrom lightautoml.ml_algo.utils import tune_and_fit_predict\n\n\nfrom lightautoml.transformers.base import LAMLTransformer, SequentialTransformer, UnionTransformer, ColumnsSelector, \\\n    ConvertDataset, ChangeRoles\nfrom lightautoml.transformers.numeric import FillnaMedian\nfrom lightautoml.transformers.categorical import LabelEncoder, OrdinalEncoder, CatIntersectstions, TargetEncoder\nfrom lightautoml.transformers.datetime import TimeToNum\n\nfrom lightautoml.reader.base import PandasToPandasReader\n","metadata":{"papermill":{"duration":5.544142,"end_time":"2021-06-09T14:26:06.848364","exception":false,"start_time":"2021-06-09T14:26:01.304222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-22T07:32:19.784227Z","iopub.execute_input":"2021-08-22T07:32:19.784748Z","iopub.status.idle":"2021-08-22T07:32:19.792787Z","shell.execute_reply.started":"2021-08-22T07:32:19.784707Z","shell.execute_reply":"2021-08-22T07:32:19.792154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LGBSimplerFeatures(FeaturesPipeline, TabularDataFeatures):\n    \"\"\"Creates simple pipeline for tree based models.\n    Simple but is ok for select features.\n    Numeric stay as is, Datetime transforms to numeric.\n    Categorical label encoding.\n    Maps input to output features exactly one-to-one.\n    \"\"\"\n    def __init__(self, feats_imp = None, top_category: int = 3, top_numeric: int = 3, to_TE=True, **kwargs):\n        \"\"\"\n\n        \"\"\"\n        super().__init__(feats_imp=feats_imp)\n        self.top_category = top_category\n        self.top_numeric = top_numeric\n        self.to_TE = to_TE\n\n    def create_pipeline(self, train):\n        \"\"\"Create tree pipeline.\n        Args:\n            train: Dataset with train features.\n        Returns:\n            Composite datetime, categorical, numeric transformer.\n        \"\"\"\n        \n        # TODO: Transformer params to config\n        transformers_list = []\n\n        # process categories\n        categories = get_columns_by_role(train, 'Category')\n        cat_feats_to_select = []\n        if len(categories) > self.top_category:\n            cat_feats_to_select = self.get_top_categories(train, self.top_category)\n        elif len(categories) > 0:\n            cat_feats_to_select = categories\n            \n        if len(categories) > 0:\n            cat_processing = SequentialTransformer([\n\n                ColumnsSelector(keys=categories),\n                LabelEncoder(subs=None, random_state=42),\n\n            ])\n            transformers_list.append(cat_processing)\n            \n        if len(categories) > 0:\n            trns = [\n                ColumnsSelector(keys=cat_feats_to_select),\n                CatIntersectstions(subs=None, random_state=42)]\n            if self.to_TE:\n                trns += [TargetEncoder()]\n            else:\n                trns += [ChangeRoles(CategoryRole(np.float32))]\n                \n            cat_inter = SequentialTransformer(trns)\n            transformers_list.append(cat_inter)   \n        \n\n        # process datetimes\n        datetimes = get_columns_by_role(train, 'Datetime')\n        if len(datetimes) > 0:\n            dt_processing = SequentialTransformer([\n\n                ColumnsSelector(keys=datetimes),\n                TimeToNum()\n\n            ])\n            transformers_list.append(dt_processing)\n\n        # process numbers\n        #\"\"\"\n        numerics = get_columns_by_role(train, 'Numeric')\n        if len(numerics) > 0:\n            num_processing = SequentialTransformer([\n\n                ColumnsSelector(keys=numerics),\n                ConvertDataset(dataset_type=NumpyDataset)\n\n            ])\n            transformers_list.append(num_processing)\n        #\"\"\"\n        union_all = UnionTransformer(transformers_list)\n\n        return union_all","metadata":{"papermill":{"duration":0.047934,"end_time":"2021-06-09T14:26:06.931984","exception":false,"start_time":"2021-06-09T14:26:06.88405","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': ['Name', 'Embarked', 'Sex', 'Ticket'],\n         'drop': ['PassengerId', ],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpPermutationImportanceEstimator()\nselector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=-9999)\n\npipe = LGBSimpleFeatures()\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())","metadata":{"papermill":{"duration":3.575396,"end_time":"2021-06-09T14:26:10.542334","exception":false,"start_time":"2021-06-09T14:26:06.966938","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['simple pipeline, no TE', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.046921,"end_time":"2021-06-09T14:26:10.624492","exception":false,"start_time":"2021-06-09T14:26:10.577571","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': ['Name', 'Embarked', 'Sex', 'Ticket'],\n         'drop': ['PassengerId', ],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpPermutationImportanceEstimator()\nselector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=-9999)\n\npipe = LGBSimplerFeatures(selector, top_category=2, to_TE=False)\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())","metadata":{"papermill":{"duration":4.560226,"end_time":"2021-06-09T14:26:15.220933","exception":false,"start_time":"2021-06-09T14:26:10.660707","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['simpler pipeline, 2 interactions, no TE', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.048077,"end_time":"2021-06-09T14:26:15.305209","exception":false,"start_time":"2021-06-09T14:26:15.257132","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': ['Name', 'Embarked', 'Sex', 'Ticket'],\n         'drop': ['PassengerId', ],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpPermutationImportanceEstimator()\nselector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=-9999)\n\npipe = LGBSimplerFeatures(selector, top_category=4)\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())","metadata":{"papermill":{"duration":5.587202,"end_time":"2021-06-09T14:26:20.929051","exception":false,"start_time":"2021-06-09T14:26:15.341849","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['simpler pipeline, TE', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.048882,"end_time":"2021-06-09T14:26:21.015741","exception":false,"start_time":"2021-06-09T14:26:20.966859","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GroupByTransformer(LAMLTransformer):\n    _fit_checks = ()\n    _transform_checks = ()\n    _fname_prefix = 'grb'\n\n    @property\n    def features(self):\n        \"\"\"Features list.\"\"\"\n\n        return self._features\n\n    def __init__(self, **kwargs):\n        super().__init__()\n        \n        self.dicts = {}        \n\n        self.check_mode = kwargs['check_mode'] if 'check_mode' in kwargs else False\n        self.verbose_mode = kwargs['verbose_mode'] if 'verbose_mode' in kwargs else False\n\n    def __get_mode(self, x):\n        return mode(x)[0][0]\n\n    def fit(self, dataset):    \n        \"\"\"fit\"\"\"\n\n        if self.verbose_mode: print('GroupByTransformer.__fit_new')\n        if self.verbose_mode: print('GroupByTransformer.__fit_new.type(dataset.data):', type(dataset.data.to_numpy()))\n\n        # set transformer names and add checks\n        for check_func in self._fit_checks:\n            check_func(dataset)\n            \n        # set transformer features\n\n        # convert to accepted dtype and get attributes\n        dataset = dataset.to_pandas()\n        \n        if self.check_mode: df = dataset.data\n            \n        cat_cols = get_columns_by_role(dataset, 'Category')\n        num_cols = get_columns_by_role(dataset, 'Numeric')\n        if self.verbose_mode: print('GroupByTransformer.__fit_new.cat_cols:', cat_cols)\n        if self.verbose_mode: print('GroupByTransformer.__fit_new.num_cols:', num_cols)\n        \n        col_names = np.array(cat_cols + num_cols)\n        col_values = dataset.data[col_names].to_numpy()\n\n        feats = []\n        for cat in cat_cols:\n            cat_index = np.where(col_names == cat)[0][0]\n            for num in num_cols:\n                num_index = np.where(col_names == num)[0][0]\n                \n                feature = f'{self._fname_prefix}__{cat}_delta_mean_{num}'\n                \n                if self.check_mode: _dict_check = df[[cat, num]].groupby(cat)[num].mean().to_dict()\n                _dict = {cat_current: np.nanmean(col_values[np.where(col_values[:, cat_index] == cat_current), num_index]) for cat_current in np.unique(col_values[:, cat_index])}\n                \n                if self.check_mode: assert np.array([np.allclose(_dict[k], _dict_check[k], equal_nan=True) for k in _dict]).all(), f'GroupByTransformer.__fit_new.not_equal.{cat}.{num}'\n                \n                self.dicts[feature] = {\n                    'cat': cat, \n                    'cat_index': cat_index, \n                    'num': num, \n                    'num_index': num_index, \n                    'values': _dict, \n                    'kind': 'num_diff'\n                }\n                feats.append(feature)\n                \n        for cat1 in cat_cols:\n            cat_index = np.where(col_names == cat1)[0][0]\n            for cat2 in cat_cols:\n                num_index = np.where(col_names == cat2)[0][0]\n                if cat1 != cat2:\n                    feature1 = f'{self._fname_prefix}__{cat1}_mode_{cat2}'\n                    \n                    if self.check_mode: _dict_check = df[[cat1, cat2]].groupby(cat1)[cat2].aggregate(self.__get_mode).to_dict()\n                    _dict = {\n                        cat_current: \n                            self.__get_mode(col_values[np.where(col_values[:, cat_index] == cat_current), num_index][0])\n                        for cat_current in np.unique(col_values[:, cat_index])\n                    }\n\n                    if self.check_mode: assert np.array([np.allclose(_dict[k], _dict_check[k], equal_nan=True) for k in _dict]).all(), f'GroupByTransformer.__fit_new.not_equal.{cat1}.{cat2}'\n                    \n                    self.dicts[feature1] = {\n                        'cat': cat1, \n                        'cat_index': cat_index, \n                        'num': cat2, \n                        'num_index': num_index, \n                        'values': _dict, \n                        'kind': 'cat_mode'\n                    }\n                    \n                    feature2 = f'{self._fname_prefix}__{cat1}_is_mode_{cat2}'\n                    self.dicts[feature2] = {\n                        'cat': cat1, \n                        'cat_index': cat_index, \n                        'num': cat2, \n                        'num_index': num_index, \n                        'values': _dict, \n                        'kind': 'cat_ismode'\n                    }\n                    feats.extend([feature1, feature2])\n            \n        self._features = feats\n        return self\n\n    def transform(self, dataset):\n        \"\"\"transform\"\"\"\n\n        # checks here\n        super().transform(dataset)\n        \n        # convert to accepted dtype and get attributes\n        if self.check_mode: df = dataset.data\n\n        cat_cols = get_columns_by_role(dataset, 'Category')\n        num_cols = get_columns_by_role(dataset, 'Numeric')\n        if self.verbose_mode: print('GroupByTransformer.__transform_new.cat_cols:', cat_cols)\n        if self.verbose_mode: print('GroupByTransformer.__transform_new.num_cols:', num_cols)\n\n        col_names = np.array(cat_cols + num_cols)\n        col_values = dataset.data[col_names].to_numpy()\n\n        # transform\n        roles = NumericRole()\n        outputs = []\n        \n        if self.verbose_mode: \n            print(\n#                 'GroupByTransformer.transform.self.dicts=', \n#                   *[(feat, (value['cat'], value['num'], value['kind'], value['values'], )) for feat, value in self.dicts.items()],\n#                   sep='\\n'\n                 )\n        \n        for feat, value in self.dicts.items():\n            cat, num = value['cat'], value['num']\n\n            if value['kind'] == 'num_diff':\n                if self.check_mode: new_arr_check = (df[num] - df[cat].map(value['values'])).values.reshape(-1, 1)\n                new_arr = (col_values[:, value['num_index']] - [value['values'][k] if k in value['values'] else np.nan for k in col_values[:, value['cat_index']] ]).reshape(-1, 1)\n                \n                if self.check_mode: assert np.allclose(new_arr_check, new_arr, equal_nan=True), f'GroupByTransformer.__transform_new.num_diff.not_equal.{cat}.{num}'\n    \n            elif value['kind'] == 'cat_mode':\n                if self.check_mode: new_arr_check = df[cat].map(value['values']).values.reshape(-1, 1)\n                new_arr = np.array([value['values'][k] if k in value['values'] else np.nan for k in col_values[:, value['cat_index']] ]).reshape(-1, 1)\n                \n                if self.check_mode: assert np.allclose(new_arr_check, new_arr, equal_nan=True), f'GroupByTransformer.__transform_new.cat_mode.not_equal.{cat}.{num}'\n                \n            elif value['kind'] == 'cat_ismode':\n                if self.check_mode: new_arr_check = (df[num] == df[cat].map(value['values'])).values.reshape(-1, 1)\n                new_arr = (col_values[:, value['num_index']] == [value['values'][k] if k in value['values'] else np.nan for k in col_values[:, value['cat_index']] ]).reshape(-1, 1)\n                \n                if self.check_mode: assert np.allclose(new_arr_check, new_arr, equal_nan=True), f'GroupByTransformer.__transform_new.cat_ismode.not_equal.{cat}.{num}'\n\n            output = dataset.empty().to_numpy()\n            output.set_data(new_arr, [feat], roles)\n            outputs.append(output)\n            \n        # create resulted        \n        return dataset.empty().to_numpy().concat(outputs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GroupByPipeline(FeaturesPipeline, TabularDataFeatures):\n    def __init__(self, feats_imp = None, top_category: int = 3, top_numeric: int = 3, **kwargs):\n        \"\"\"\n        \"\"\"\n        \n        super().__init__(feats_imp=feats_imp)\n        \n        self.top_category = top_category\n        self.top_numeric = top_numeric\n        \n        self.check_mode = kwargs['check_mode'] if 'check_mode' in kwargs else False\n        self.verbose_mode = kwargs['verbose_mode'] if 'verbose_mode' in kwargs else False\n\n    def create_pipeline(self, train):\n        \"\"\"create_pipeline\"\"\"\n        \n        if self.verbose_mode: print('GroupByPipeline.create_pipeline')\n\n        transformer_list = []\n\n        categories = get_columns_by_role(train, 'Category')\n        if self.verbose_mode: print('GroupByPipeline.create_pipeline.categories:', categories)\n\n        numerics = get_columns_by_role(train, 'Numeric')\n        if self.verbose_mode: print('GroupByPipeline.create_pipeline.numerics:', numerics)\n\n        cat_feats_to_select = []\n        num_feats_to_select = []\n        \n        if len(categories) > self.top_category:\n            cat_feats_to_select = self.get_top_categories(train, self.top_category)\n        elif len(categories) > 0:\n            cat_feats_to_select = categories\n        if self.verbose_mode: print('GroupByPipeline.create_pipeline.cat_feats_to_select:', cat_feats_to_select)\n            \n        if len(numerics) > self.top_numeric:\n            num_feats_to_select = self.get_top_numeric(train, self.top_numeric)\n        elif len(numerics) > 0:\n            num_feats_to_select = numerics        \n        if self.verbose_mode: print('GroupByPipeline.create_pipeline.num_feats_to_select:', num_feats_to_select)\n\n        if (len(cat_feats_to_select) > 0) and (len(num_feats_to_select) > 0):\n            groupby_processing = SequentialTransformer([\n                UnionTransformer([\n                    SequentialTransformer([\n                        ColumnsSelector(keys=categories),\n                        LabelEncoder(subs=None, random_state=42),\n#                         FillnaMedian(),\n                    ]),\n                    SequentialTransformer([\n                        ColumnsSelector(keys=num_feats_to_select)]),\n#                         FillnaMedian(),\n                    ]),\n#                 FillnaMedian(),\n                \n                GroupByTransformer(check_mode=self.check_mode, verbose_mode=self.verbose_mode),\n            ])\n            \n            transformer_list.append(groupby_processing)\n        else:\n            raise ValueError('GroupByPipeline expects at least 1 categorial and 1 numeric features')                \n            \n        if self.verbose_mode: print('GroupByPipeline.create_pipeline.transformer_list:', transformer_list)\n\n        return UnionTransformer(transformer_list)\n    \n    def get_top_numeric(self, train, top_n = 5):\n        \"\"\"get_top_numeric\"\"\"\n\n        nums = get_columns_by_role(train, 'Numeric')\n        if len(nums) == 0:\n            return []\n\n        df = pd.DataFrame({'importance': 0, 'cardinality': 0}, index=nums)\n        # importance if defined\n        if self.feats_imp is not None:\n            feats_imp = pd.Series(self.feats_imp.get_features_score()).sort_values(ascending=False)\n            df['importance'] = feats_imp[feats_imp.index.isin(nums)]\n            df['importance'].fillna(-np.inf)\n\n        # check for cardinality\n        df['cardinality'] = -self.get_uniques_cnt(train, nums)\n        # sort\n        df = df.sort_values(by=['importance', 'cardinality'], ascending=[False, self.ascending_by_cardinality])\n        # get top n\n        top = list(df.index[:top_n])\n\n        return top","metadata":{"papermill":{"duration":0.060033,"end_time":"2021-06-09T14:26:21.113349","exception":false,"start_time":"2021-06-09T14:26:21.053316","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'drop': ['PassengerId', ],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpPermutationImportanceEstimator()\nselector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=-9999)\n\npipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=4, top_numeric=4, check_mode=True, verbose_mode=True))\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=1)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())","metadata":{"papermill":{"duration":6.849574,"end_time":"2021-06-09T14:26:27.999804","exception":false,"start_time":"2021-06-09T14:26:21.15023","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['all features', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.049704,"end_time":"2021-06-09T14:26:28.087272","exception":false,"start_time":"2021-06-09T14:26:28.037568","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': [],\n         'drop': ['PassengerId', 'Name', 'Embarked', 'Sex', 'Ticket'],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpPermutationImportanceEstimator()\nselector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=0)\n\npipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=3, top_numeric=1))\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())\nprint(len(model.features))","metadata":{"papermill":{"duration":6.764024,"end_time":"2021-06-09T14:26:34.889253","exception":false,"start_time":"2021-06-09T14:26:28.125229","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['top imp, 1 iter imp, holdout', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.048544,"end_time":"2021-06-09T14:26:34.975565","exception":false,"start_time":"2021-06-09T14:26:34.927021","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NpCrossValPermutationImportanceEstimator(ImportanceEstimator):\n    \"\"\"Cross validation Permuation importance based estimator.\n\n    Importance calculate, using random permutation of items in single column for each feature.\n\n    \"\"\"\n\n    def __init__(self, random_state: int = 42, n_permut: int = 1):\n        super().__init__()\n        self.random_state = random_state\n        self.n_permut = n_permut\n\n\n    def fit(self, train_valid = None,\n            ml_algo = None,\n            preds = None):\n        \n        permutation_importance = {}\n        c = 0\n        for n, (idx, train, valid) in enumerate(train_valid):\n            normal_score = ml_algo.score(preds[idx])\n            valid_data = valid.to_numpy()\n            for it, col in enumerate(valid_data.features):\n                save_col = deepcopy(valid_data[:, col])\n                for j in range(self.n_permut):\n                    permutation = np.random.RandomState(seed=self.random_state+j).permutation(valid_data.shape[0])\n                    shuffled_col = valid_data[permutation, col]\n\n                    valid_data[col] = shuffled_col\n\n                    new_preds = ml_algo.predict_single_fold(ml_algo.models[n], valid_data)\n                    new_preds = new_preds.reshape((new_preds.shape[0], -1))\n                    preds_ds = valid_data.empty().to_numpy()\n                    preds_ds = ml_algo._set_prediction(preds_ds, new_preds)\n                    shuffled_score = ml_algo.score(preds_ds)\n                    if col in permutation_importance:\n                        permutation_importance[col] += (normal_score - shuffled_score)  / len(ml_algo.models) / self.n_permut\n                    else:\n                        permutation_importance[col] = (normal_score - shuffled_score)  / len(ml_algo.models) / self.n_permut\n\n                    # Set normal column back to the dataset\n                    valid_data[col] = save_col\n                    c += 1\n        \n        self.raw_importances = pd.Series(permutation_importance).sort_values(ascending=False)","metadata":{"papermill":{"duration":0.049872,"end_time":"2021-06-09T14:26:35.063618","exception":false,"start_time":"2021-06-09T14:26:35.013746","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': [],\n         'drop': ['PassengerId', 'Name', 'Embarked', 'Sex', 'Ticket'],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpCrossValPermutationImportanceEstimator(n_permut=20)\nselector1 = ImportanceCutoffSelector(EmptyFeaturePipeline(), model1, pie1, cutoff=0)\n\npipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=3, top_numeric=1))\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\nprint('')\nprint(pie1.get_features_score())\nprint(len(model.features))","metadata":{"papermill":{"duration":15.448817,"end_time":"2021-06-09T14:26:50.550988","exception":false,"start_time":"2021-06-09T14:26:35.102171","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['top imp, 20 iter imp', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.050713,"end_time":"2021-06-09T14:26:50.642183","exception":false,"start_time":"2021-06-09T14:26:50.59147","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PredefinedSelector(SelectionPipeline):\n\n    def __init__(self, columns_to_select):\n        super().__init__()\n        self.columns_to_select = set(columns_to_select)\n\n    def perform_selection(self, train_valid):\n\n        assert len(self.columns_to_select) == len(self.columns_to_select.intersection(set(train_valid.features))), \\\n            'Columns to select not match with dataset features'\n        self._selected_features = sorted(list(self.columns_to_select))\n\nclass IterativeFeatureSelector(SelectionPipeline):\n    def __init__(self, feature_pipeline: FeaturesPipeline,\n                 ml_algo = None,\n                 imp_estimator = None,\n                 fit_on_holdout = True,\n                 feature_group_size = 5,\n                 kind  = 'forward'\n                 ):\n\n        super().__init__(feature_pipeline, ml_algo, imp_estimator, fit_on_holdout)\n\n        self.feature_group_size = feature_group_size\n        self.kind = kind\n        \n    def _forward(self, train_valid = None):\n        # Calculate or receive permutation importances scores\n        imp = self.imp_estimator.get_features_score()\n\n        features_to_check = [x for x in imp.index if x in set(train_valid.features)]\n\n        # Perform iterative selection algo\n        chunks = _create_chunks_from_list(features_to_check, self.feature_group_size)\n        selected_feats = []\n        cnt_without_update = 0\n        cur_best_score = None\n\n        for it, chunk in enumerate(chunks):\n            selected_feats += chunk\n            cs = PredefinedSelector(selected_feats)\n            selected_cols_iterator = train_valid.apply_selector(cs)\n            # Create copy of MLAlgo for iterative algo only\n            ml_algo_for_iterative, preds = tune_and_fit_predict(deepcopy(self._empty_algo), self.tuner, selected_cols_iterator)\n\n            cur_score = ml_algo_for_iterative.score(preds)\n\n            if cur_best_score is None or cur_best_score < cur_score:\n                cur_best_score = cur_score\n                cnt_without_update = 0\n            else:\n                cnt_without_update += 1\n\n                selected_feats = selected_feats[:-len(chunk)]\n\n        imp = imp[imp.index.isin(selected_feats)]\n        self.map_raw_feature_importances(imp)\n\n        selected_feats = list(self.mapped_importances.index)\n        self._selected_features = selected_feats\n        \n    def _backward(self, train_valid = None):\n        imp = self.imp_estimator.get_features_score()\n        #imp = imp[imp > 0]\n        #print(imp)\n        features_to_check = [x for x in imp.index if x in set(train_valid.features)]\n\n        # Perform iterative selection algo\n        chunks = _create_chunks_from_list(features_to_check[::-1], self.feature_group_size)\n        selected_feats = sorted(features_to_check)\n        cs = PredefinedSelector(selected_feats)\n        selected_cols_iterator = train_valid.apply_selector(cs)\n        ml_algo_for_iterative, preds = tune_and_fit_predict(deepcopy(self._empty_algo), self.tuner, selected_cols_iterator)\n        cur_best_score = ml_algo_for_iterative.score(preds)\n        cnt_without_update = 0\n        for it, chunk in enumerate(chunks):\n            if cnt_without_update >= 30:\n                break\n        \n            selected_feats = sorted(list(set(selected_feats) -  set(chunk)))\n            cs = PredefinedSelector(selected_feats)\n            selected_cols_iterator = train_valid.apply_selector(cs)\n            ml_algo_for_iterative, preds = tune_and_fit_predict(deepcopy(self._empty_algo), self.tuner, selected_cols_iterator)\n\n            cur_score = ml_algo_for_iterative.score(preds)\n            #print(it, cur_best_score, cur_score, chunk)\n            if cur_best_score is None or cur_best_score < cur_score:\n                cur_best_score = cur_score\n                cnt_without_update = 0\n            else:\n                cnt_without_update += 1\n\n                selected_feats = sorted(list(set(selected_feats) |  set(chunk)))\n        imp = imp[imp.index.isin(selected_feats)]\n        self.map_raw_feature_importances(imp)\n        selected_feats = list(self.mapped_importances.index)\n        self._selected_features = selected_feats\n\n    def perform_selection(self, train_valid = None):\n        if self.kind == 'backward':\n            self._backward(train_valid)\n        elif self.kind == 'forward':\n            self._forward(train_valid)","metadata":{"papermill":{"duration":0.056088,"end_time":"2021-06-09T14:26:50.737314","exception":false,"start_time":"2021-06-09T14:26:50.681226","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': [],\n         'drop': ['PassengerId', 'Name', 'Embarked', 'Sex', 'Ticket'],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpCrossValPermutationImportanceEstimator(n_permut=1)\nselector1 = IterativeFeatureSelector(EmptyFeaturePipeline(), model1, pie1, feature_group_size=1, fit_on_holdout=True, kind='forward')\n\npipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=3, top_numeric=1))\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\n\nprint(pie1.get_features_score())\nprint(len(model.features))","metadata":{"papermill":{"duration":18.320803,"end_time":"2021-06-09T14:27:09.096951","exception":false,"start_time":"2021-06-09T14:26:50.776148","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['forward, 1 iter imp, holdout', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.053033,"end_time":"2021-06-09T14:27:09.190513","exception":false,"start_time":"2021-06-09T14:27:09.13748","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': [],\n         'drop': ['PassengerId', 'Name', 'Embarked', 'Sex', 'Ticket'],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpCrossValPermutationImportanceEstimator(n_permut=20)\nselector1 = IterativeFeatureSelector(EmptyFeaturePipeline(), model1, pie1, feature_group_size=1, fit_on_holdout=False, kind='forward')\n\npipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=3, top_numeric=1))\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\n\nprint(pie1.get_features_score())\nprint(len(model.features))","metadata":{"papermill":{"duration":68.053123,"end_time":"2021-06-09T14:28:17.283809","exception":false,"start_time":"2021-06-09T14:27:09.230686","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['final_forward', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.052394,"end_time":"2021-06-09T14:28:17.377599","exception":false,"start_time":"2021-06-09T14:28:17.325205","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roles = {'target': TARGET_NAME, 'category': ['profile_town', 'profile_district', 'engine_type', 'recommended_policy_type', 'car_color', 'car_type']}\nroles = {'target': TARGET_NAME, \n         'category': [],\n         'drop': ['PassengerId', 'Name', 'Embarked', 'Sex', 'Ticket'],\n        }\n\ntask = Task('binary', )\nreader = PandasToPandasReader(task, cv=N_FOLDS, random_state=RANDOM_STATE, advanced_roles=False)\n\nmodel0 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie = ModelBasedImportanceEstimator()\nselector = ImportanceCutoffSelector(LGBSimpleFeatures(), model0, pie, cutoff=-9999)\n\nmodel1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 64, 'seed': 42, 'num_threads': N_THREADS})\npie1 = NpCrossValPermutationImportanceEstimator(n_permut=20)\nselector1 = IterativeFeatureSelector(EmptyFeaturePipeline(), model1, pie1, feature_group_size=1, fit_on_holdout=False, kind='backward')\n\npipe = LGBSimplerFeatures(selector, top_category=4).append(GroupByPipeline(None, top_category=3, top_numeric=1))\n\nmodel = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 128, 'seed': 1, 'num_threads': N_THREADS})\npipeline = MLPipeline([(model),], pre_selection=selector, features_pipeline=pipe, post_selection=selector1)\n\nautoml = AutoML(reader, [\n    [pipeline],\n], skip_conn=False, verbose=0)\n\noof_pred = automl.fit_predict(train_data, roles = roles)\n\ntest_pred = automl.predict(test_data)\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\n\nprint(pie1.get_features_score())\nprint(len(model.features))","metadata":{"papermill":{"duration":95.263488,"end_time":"2021-06-09T14:29:52.681607","exception":false,"start_time":"2021-06-09T14:28:17.418119","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.loc['final_backward', 'TEST score'] = np.round(test_automl, 4)\nresult","metadata":{"papermill":{"duration":0.053342,"end_time":"2021-06-09T14:29:52.775303","exception":false,"start_time":"2021-06-09T14:29:52.721961","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.040428,"end_time":"2021-06-09T14:29:52.856313","exception":false,"start_time":"2021-06-09T14:29:52.815885","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}