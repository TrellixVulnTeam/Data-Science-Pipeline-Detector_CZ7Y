{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# In this particular notebook ,we are going to see 5 different techniques for feature selection.\n1 Dropping Constant Features- Variance Threshold- Unsupervised learning \n2 Feature selection with correlation\n3 Features selection Using Information Gain For Classification \n4 Features selection Using Information Gain For Regression \n5 Feature Selection Using Chi2 Statistical Analysis","metadata":{}},{"cell_type":"markdown","source":"# 1- Dropping Constant Features- Variance Threshold","metadata":{}},{"cell_type":"markdown","source":"# Variance Threshold\nVariance threshold is a function inside Feature selector.\nFeature selector that removes all low-variance features.\n\nThis feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_selection import VarianceThreshold\ndf=pd.read_csv('../input/santander-customer-satisfaction/train.csv',nrows=10000)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:09:46.423947Z","iopub.execute_input":"2021-06-02T12:09:46.424315Z","iopub.status.idle":"2021-06-02T12:09:46.733419Z","shell.execute_reply.started":"2021-06-02T12:09:46.424285Z","shell.execute_reply":"2021-06-02T12:09:46.732628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:09:48.375062Z","iopub.execute_input":"2021-06-02T12:09:48.375701Z","iopub.status.idle":"2021-06-02T12:09:48.381759Z","shell.execute_reply.started":"2021-06-02T12:09:48.375648Z","shell.execute_reply":"2021-06-02T12:09:48.38079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## top 10 data\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:09:50.114194Z","iopub.execute_input":"2021-06-02T12:09:50.114916Z","iopub.status.idle":"2021-06-02T12:09:50.155033Z","shell.execute_reply.started":"2021-06-02T12:09:50.114863Z","shell.execute_reply":"2021-06-02T12:09:50.154225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Define the dataset into dependent and independent feature\nX=df.drop(labels=['TARGET'], axis=1)\ny=df['TARGET']","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:09:51.724533Z","iopub.execute_input":"2021-06-02T12:09:51.725097Z","iopub.status.idle":"2021-06-02T12:09:51.741082Z","shell.execute_reply.started":"2021-06-02T12:09:51.725064Z","shell.execute_reply":"2021-06-02T12:09:51.739938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# separate dataset into train and test\nX_train, X_test, y_train, y_test = train_test_split(\n    df.drop(labels=['TARGET'], axis=1),\n    df['TARGET'],\n    test_size=0.3,\n    random_state=0)\n\n\n### we have 370 features as our independent features\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:09:53.813798Z","iopub.execute_input":"2021-06-02T12:09:53.814208Z","iopub.status.idle":"2021-06-02T12:09:53.855402Z","shell.execute_reply.started":"2021-06-02T12:09:53.814176Z","shell.execute_reply":"2021-06-02T12:09:53.854319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets apply the variance threshold","metadata":{}},{"cell_type":"markdown","source":"It will remove all those features which have zero threshold value or zero variance feature . It applies only on independent feature.","metadata":{}},{"cell_type":"code","source":"var_thres=VarianceThreshold(threshold=0)\nvar_thres.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:09:58.886843Z","iopub.execute_input":"2021-06-02T12:09:58.887231Z","iopub.status.idle":"2021-06-02T12:09:58.936094Z","shell.execute_reply.started":"2021-06-02T12:09:58.887199Z","shell.execute_reply":"2021-06-02T12:09:58.935032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the below code, true indicates that a particular feature is very important and false indicates that a particular feature is not so important with respect to the target feature.","metadata":{}},{"cell_type":"code","source":"var_thres.get_support()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:20:18.187654Z","iopub.execute_input":"2021-06-02T12:20:18.188017Z","iopub.status.idle":"2021-06-02T12:20:18.195353Z","shell.execute_reply.started":"2021-06-02T12:20:18.187985Z","shell.execute_reply":"2021-06-02T12:20:18.194135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# There are total 284 non constant features out of 370 features.","metadata":{}},{"cell_type":"code","source":"### lets find non constant feature\nlen(X_train.columns[var_thres.get_support()])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:21:05.163154Z","iopub.execute_input":"2021-06-02T12:21:05.163549Z","iopub.status.idle":"2021-06-02T12:21:05.169913Z","shell.execute_reply.started":"2021-06-02T12:21:05.163512Z","shell.execute_reply":"2021-06-02T12:21:05.168957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 86 features are our constant features","metadata":{}},{"cell_type":"code","source":"constant_columns = [column for column in X_train.columns\n                    if column not in X_train.columns[var_thres.get_support()]]\n\nprint(len(constant_columns))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:26:24.134764Z","iopub.execute_input":"2021-06-02T12:26:24.135163Z","iopub.status.idle":"2021-06-02T12:26:24.160277Z","shell.execute_reply.started":"2021-06-02T12:26:24.135133Z","shell.execute_reply":"2021-06-02T12:26:24.158859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Printing our constant columns","metadata":{}},{"cell_type":"code","source":"for column in constant_columns:\n    print(column)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:34:40.851866Z","iopub.execute_input":"2021-06-02T12:34:40.852286Z","iopub.status.idle":"2021-06-02T12:34:40.85967Z","shell.execute_reply.started":"2021-06-02T12:34:40.852254Z","shell.execute_reply":"2021-06-02T12:34:40.85856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here, we are dropping the constant columns.","metadata":{}},{"cell_type":"code","source":"X_train.drop(constant_columns,axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:36:23.932161Z","iopub.execute_input":"2021-06-02T12:36:23.932515Z","iopub.status.idle":"2021-06-02T12:36:24.001202Z","shell.execute_reply.started":"2021-06-02T12:36:23.932484Z","shell.execute_reply":"2021-06-02T12:36:24.000175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above function, we get all the features which are important for our dataset","metadata":{}},{"cell_type":"markdown","source":"# 2- Feature selection with correlation","metadata":{}},{"cell_type":"markdown","source":"# In this technique, we compare two features together and if both features are highly co-related with each other then we will drop anyone features fromÂ both.","metadata":{}},{"cell_type":"code","source":"#importing libraries\nfrom sklearn.datasets import load_boston\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:41:51.307846Z","iopub.execute_input":"2021-06-02T12:41:51.308257Z","iopub.status.idle":"2021-06-02T12:41:51.410074Z","shell.execute_reply.started":"2021-06-02T12:41:51.308225Z","shell.execute_reply":"2021-06-02T12:41:51.409129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset","metadata":{}},{"cell_type":"code","source":"#Loading the dataset\ndata = load_boston()\ndf = pd.DataFrame(data.data, columns = data.feature_names)\ndf[\"MEDV\"] = data.target","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:42:34.450972Z","iopub.execute_input":"2021-06-02T12:42:34.45133Z","iopub.status.idle":"2021-06-02T12:42:34.468668Z","shell.execute_reply.started":"2021-06-02T12:42:34.4513Z","shell.execute_reply":"2021-06-02T12:42:34.467888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.feature_names","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:42:55.710966Z","iopub.execute_input":"2021-06-02T12:42:55.711476Z","iopub.status.idle":"2021-06-02T12:42:55.717935Z","shell.execute_reply.started":"2021-06-02T12:42:55.711444Z","shell.execute_reply":"2021-06-02T12:42:55.716869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:43:30.317261Z","iopub.execute_input":"2021-06-02T12:43:30.317615Z","iopub.status.idle":"2021-06-02T12:43:30.342245Z","shell.execute_reply.started":"2021-06-02T12:43:30.317585Z","shell.execute_reply":"2021-06-02T12:43:30.341452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dividing our independent(x) and dependent feature (y)","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"MEDV\",axis=1)   #Feature Matrix\ny = df[\"MEDV\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:44:01.194476Z","iopub.execute_input":"2021-06-02T12:44:01.194844Z","iopub.status.idle":"2021-06-02T12:44:01.201779Z","shell.execute_reply.started":"2021-06-02T12:44:01.194803Z","shell.execute_reply":"2021-06-02T12:44:01.201005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:45:07.7842Z","iopub.execute_input":"2021-06-02T12:45:07.78469Z","iopub.status.idle":"2021-06-02T12:45:07.806053Z","shell.execute_reply.started":"2021-06-02T12:45:07.784658Z","shell.execute_reply":"2021-06-02T12:45:07.805295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:45:17.004457Z","iopub.execute_input":"2021-06-02T12:45:17.004856Z","iopub.status.idle":"2021-06-02T12:45:17.012585Z","shell.execute_reply.started":"2021-06-02T12:45:17.004822Z","shell.execute_reply":"2021-06-02T12:45:17.011409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separate dataset into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.3,\n    random_state=0)\n\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:45:33.244087Z","iopub.execute_input":"2021-06-02T12:45:33.244452Z","iopub.status.idle":"2021-06-02T12:45:33.257091Z","shell.execute_reply.started":"2021-06-02T12:45:33.244417Z","shell.execute_reply":"2021-06-02T12:45:33.255815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We perform all the operations on X_train dataset and after do the same for X_test.","metadata":{}},{"cell_type":"code","source":"X_train.corr()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:46:23.189751Z","iopub.execute_input":"2021-06-02T12:46:23.190148Z","iopub.status.idle":"2021-06-02T12:46:23.219724Z","shell.execute_reply.started":"2021-06-02T12:46:23.190114Z","shell.execute_reply":"2021-06-02T12:46:23.218739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# You can see tax and rad features both are are 91% highly co-related with each other, so we will drop one of them. threshold(90)","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = X_train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:50:15.01076Z","iopub.execute_input":"2021-06-02T12:50:15.011151Z","iopub.status.idle":"2021-06-02T12:50:16.126944Z","shell.execute_reply.started":"2021-06-02T12:50:15.011117Z","shell.execute_reply":"2021-06-02T12:50:16.125687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the following function we can select highly correlated features\nIt will remove the first feature that is correlated with anything other feature\n","metadata":{}},{"cell_type":"code","source":"# with the following function we can select highly correlated features\n# it will remove the first feature that is correlated with anything other feature\n\ndef correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:53:58.365518Z","iopub.execute_input":"2021-06-02T12:53:58.365923Z","iopub.status.idle":"2021-06-02T12:53:58.372825Z","shell.execute_reply.started":"2021-06-02T12:53:58.365873Z","shell.execute_reply":"2021-06-02T12:53:58.371579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here we are calling our fn. and passing the dataset and threshold value","metadata":{}},{"cell_type":"code","source":"corr_features = correlation(X_train, 0.7)\nlen(set(corr_features))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:56:16.19284Z","iopub.execute_input":"2021-06-02T12:56:16.193282Z","iopub.status.idle":"2021-06-02T12:56:16.206335Z","shell.execute_reply.started":"2021-06-02T12:56:16.193247Z","shell.execute_reply":"2021-06-02T12:56:16.205491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Highly co-related features","metadata":{}},{"cell_type":"code","source":"corr_features","metadata":{"execution":{"iopub.status.busy":"2021-06-02T12:57:46.490944Z","iopub.execute_input":"2021-06-02T12:57:46.491287Z","iopub.status.idle":"2021-06-02T12:57:46.497428Z","shell.execute_reply.started":"2021-06-02T12:57:46.491258Z","shell.execute_reply":"2021-06-02T12:57:46.496552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop highly co-related features","metadata":{}},{"cell_type":"code","source":"X_train.drop(corr_features,axis=1)\nX_test.drop(corr_features,axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:02:31.665806Z","iopub.execute_input":"2021-06-02T13:02:31.666306Z","iopub.status.idle":"2021-06-02T13:02:31.695824Z","shell.execute_reply.started":"2021-06-02T13:02:31.666261Z","shell.execute_reply":"2021-06-02T13:02:31.694817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We dropped highly co-related features after comparing each and every column with each other.","metadata":{}},{"cell_type":"markdown","source":"# 3- Features selection Using Information Gain For Classification","metadata":{}},{"cell_type":"markdown","source":"Before going ahead you need to have some statistical test knowledge like annova test, t test , chi square test, p value test","metadata":{}},{"cell_type":"markdown","source":"# Mutual Information\nMI Estimate mutual information for a discrete target variable.\n\nMutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n\nThe function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n\nInshort\n\nA quantity called mutual information measures the amount of information one can obtain from one random variable given another.\n\nThe mutual information between two random variables X and Y can be stated formally as follows:\n\nI(X ; Y) = H(X) â H(X | Y) Where I(X ; Y) is the mutual information for X and Y, H(X) is the entropy for X and H(X | Y) is the conditional entropy for X given Y. The result has the units of bits.","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:04:54.900663Z","iopub.execute_input":"2021-06-02T13:04:54.901047Z","iopub.status.idle":"2021-06-02T13:04:54.905416Z","shell.execute_reply.started":"2021-06-02T13:04:54.901017Z","shell.execute_reply":"2021-06-02T13:04:54.904253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('https://gist.githubusercontent.com/tijptjik/9408623/raw/b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:05:06.818884Z","iopub.execute_input":"2021-06-02T13:05:06.819254Z","iopub.status.idle":"2021-06-02T13:05:07.164421Z","shell.execute_reply.started":"2021-06-02T13:05:06.819224Z","shell.execute_reply":"2021-06-02T13:05:07.163628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# let's check how many unique value we have","metadata":{}},{"cell_type":"code","source":"df['Wine'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:05:19.668587Z","iopub.execute_input":"2021-06-02T13:05:19.669018Z","iopub.status.idle":"2021-06-02T13:05:19.677829Z","shell.execute_reply.started":"2021-06-02T13:05:19.668983Z","shell.execute_reply":"2021-06-02T13:05:19.676638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check all the values are integers or not","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:05:27.473669Z","iopub.execute_input":"2021-06-02T13:05:27.474079Z","iopub.status.idle":"2021-06-02T13:05:27.49826Z","shell.execute_reply.started":"2021-06-02T13:05:27.474045Z","shell.execute_reply":"2021-06-02T13:05:27.496473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Train test split to avoid overfitting\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(df.drop(labels=['Wine'], axis=1),\n    df['Wine'],\n    test_size=0.3,\n    random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:05:41.54737Z","iopub.execute_input":"2021-06-02T13:05:41.547719Z","iopub.status.idle":"2021-06-02T13:05:41.556458Z","shell.execute_reply.started":"2021-06-02T13:05:41.547687Z","shell.execute_reply":"2021-06-02T13:05:41.555168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:05:52.112423Z","iopub.execute_input":"2021-06-02T13:05:52.112962Z","iopub.status.idle":"2021-06-02T13:05:52.133147Z","shell.execute_reply.started":"2021-06-02T13:05:52.112927Z","shell.execute_reply":"2021-06-02T13:05:52.132347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note - Remove all the null values from train and test dataset  before applying  mutual_info_classify","metadata":{}},{"cell_type":"markdown","source":"# High value for any feature mean that particular feature is the best feature ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\n# determine the mutual information\nmutual_info = mutual_info_classif(X_train, y_train)\nmutual_info","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:06:06.883057Z","iopub.execute_input":"2021-06-02T13:06:06.883639Z","iopub.status.idle":"2021-06-02T13:06:06.938467Z","shell.execute_reply.started":"2021-06-02T13:06:06.883602Z","shell.execute_reply":"2021-06-02T13:06:06.937352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting the information of features into series","metadata":{}},{"cell_type":"code","source":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:06:19.343285Z","iopub.execute_input":"2021-06-02T13:06:19.343638Z","iopub.status.idle":"2021-06-02T13:06:19.352421Z","shell.execute_reply.started":"2021-06-02T13:06:19.343607Z","shell.execute_reply":"2021-06-02T13:06:19.351271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's plot the ordered mutual_info values per feature\nmutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:06:33.283197Z","iopub.execute_input":"2021-06-02T13:06:33.283546Z","iopub.status.idle":"2021-06-02T13:06:33.532513Z","shell.execute_reply.started":"2021-06-02T13:06:33.283519Z","shell.execute_reply":"2021-06-02T13:06:33.531487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Import selectkbest function to pick top features","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:34:58.792223Z","iopub.execute_input":"2021-06-02T13:34:58.793238Z","iopub.status.idle":"2021-06-02T13:34:58.798487Z","shell.execute_reply.started":"2021-06-02T13:34:58.793196Z","shell.execute_reply":"2021-06-02T13:34:58.797157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We will take only top 5 features as our independent features.","metadata":{}},{"cell_type":"code","source":"#No we Will select the  top 5 important features\nsel_five_cols = SelectKBest(mutual_info_classif, k=5)\nsel_five_cols.fit(X_train, y_train)\nX_train.columns[sel_five_cols.get_support()]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:06:58.861191Z","iopub.execute_input":"2021-06-02T13:06:58.861713Z","iopub.status.idle":"2021-06-02T13:06:58.913307Z","shell.execute_reply.started":"2021-06-02T13:06:58.861682Z","shell.execute_reply":"2021-06-02T13:06:58.912215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4- Features selection Using Information Gain For Regression","metadata":{}},{"cell_type":"markdown","source":"# Mutual Information\nEstimate mutual information for a continuous target variable.\n\nMutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n\nThe function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances\n\nMutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n\nInshort\n\nA quantity called mutual information measures the amount of information one can obtain from one random variable given another.\n\nThe mutual information between two random variables X and Y can be stated formally as follows:\n\nI(X ; Y) = H(X) â H(X | Y) Where I(X ; Y) is the mutual information for X and Y, H(X) is the entropy for X and H(X | Y) is the conditional entropy for X given Y. The result has the units of bits.","metadata":{}},{"cell_type":"markdown","source":"here we are trying to find out the best features based on the specific sales price. And ales price is a continuous target variable.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nhousing_df=pd.read_csv('../input/housepricesadvancedregressiontechniquestrain/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:05:21.573215Z","iopub.execute_input":"2021-06-02T15:05:21.573793Z","iopub.status.idle":"2021-06-02T15:05:21.643774Z","shell.execute_reply.started":"2021-06-02T15:05:21.573684Z","shell.execute_reply":"2021-06-02T15:05:21.642798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:05:24.971569Z","iopub.execute_input":"2021-06-02T15:05:24.972198Z","iopub.status.idle":"2021-06-02T15:05:25.030467Z","shell.execute_reply.started":"2021-06-02T15:05:24.972156Z","shell.execute_reply":"2021-06-02T15:05:25.029076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:05:28.765629Z","iopub.execute_input":"2021-06-02T15:05:28.766045Z","iopub.status.idle":"2021-06-02T15:05:28.810827Z","shell.execute_reply.started":"2021-06-02T15:05:28.765964Z","shell.execute_reply":"2021-06-02T15:05:28.809646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking for null values","metadata":{}},{"cell_type":"code","source":"housing_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:05:35.538744Z","iopub.execute_input":"2021-06-02T15:05:35.539115Z","iopub.status.idle":"2021-06-02T15:05:35.556014Z","shell.execute_reply.started":"2021-06-02T15:05:35.539086Z","shell.execute_reply":"2021-06-02T15:05:35.554802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Taking only numerical variable to apply mutual information.","metadata":{}},{"cell_type":"code","source":"\nnumeric_lst=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerical_cols = list(housing_df.select_dtypes(include=numeric_lst).columns)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:21:49.049019Z","iopub.execute_input":"2021-06-02T15:21:49.049367Z","iopub.status.idle":"2021-06-02T15:21:49.056292Z","shell.execute_reply.started":"2021-06-02T15:21:49.049339Z","shell.execute_reply":"2021-06-02T15:21:49.05541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We have to find out mutual information with respect to each and every feature along with sales price.","metadata":{}},{"cell_type":"markdown","source":"# Numericals columns","metadata":{}},{"cell_type":"code","source":"numerical_cols","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:22:03.287689Z","iopub.execute_input":"2021-06-02T15:22:03.288193Z","iopub.status.idle":"2021-06-02T15:22:03.294999Z","shell.execute_reply.started":"2021-06-02T15:22:03.288161Z","shell.execute_reply":"2021-06-02T15:22:03.29378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ceating a dataframe for all the numerical_cols","metadata":{}},{"cell_type":"code","source":"housing_df=housing_df[numerical_cols]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:22:37.176995Z","iopub.execute_input":"2021-06-02T15:22:37.177374Z","iopub.status.idle":"2021-06-02T15:22:37.182975Z","shell.execute_reply.started":"2021-06-02T15:22:37.177339Z","shell.execute_reply":"2021-06-02T15:22:37.182195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:22:39.806715Z","iopub.execute_input":"2021-06-02T15:22:39.807231Z","iopub.status.idle":"2021-06-02T15:22:39.831961Z","shell.execute_reply.started":"2021-06-02T15:22:39.8072Z","shell.execute_reply":"2021-06-02T15:22:39.831021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_df=housing_df.drop(\"Id\",axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:22:53.088816Z","iopub.execute_input":"2021-06-02T15:22:53.089343Z","iopub.status.idle":"2021-06-02T15:22:53.09577Z","shell.execute_reply.started":"2021-06-02T15:22:53.089306Z","shell.execute_reply":"2021-06-02T15:22:53.094721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### It is always a good practice to split train and test data to avoid\n#overfitting\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(housing_df.drop(labels=['SalePrice'], axis=1),\n    housing_df['SalePrice'],\n    test_size=0.3,\n    random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:23:08.009643Z","iopub.execute_input":"2021-06-02T15:23:08.010045Z","iopub.status.idle":"2021-06-02T15:23:09.202617Z","shell.execute_reply.started":"2021-06-02T15:23:08.010009Z","shell.execute_reply":"2021-06-02T15:23:09.201424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:23:19.775018Z","iopub.execute_input":"2021-06-02T15:23:19.775372Z","iopub.status.idle":"2021-06-02T15:23:19.814866Z","shell.execute_reply.started":"2021-06-02T15:23:19.775342Z","shell.execute_reply":"2021-06-02T15:23:19.813869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T19:24:20.820796Z","iopub.execute_input":"2021-06-02T19:24:20.821128Z","iopub.status.idle":"2021-06-02T19:24:20.879705Z","shell.execute_reply.started":"2021-06-02T19:24:20.821054Z","shell.execute_reply":"2021-06-02T19:24:20.878598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filling null values with zero. \nHigher the value you get for any feature ,the more better it is nd more dependent to target feature.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\n# determine the mutual information\nmutual_info = mutual_info_regression(X_train.fillna(0), y_train)\nmutual_info","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:49:54.50339Z","iopub.execute_input":"2021-06-02T15:49:54.503876Z","iopub.status.idle":"2021-06-02T15:49:54.747251Z","shell.execute_reply.started":"2021-06-02T15:49:54.503845Z","shell.execute_reply":"2021-06-02T15:49:54.7463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.As the value near to one the more dependent that particular feature is.","metadata":{}},{"cell_type":"markdown","source":"# Converting all the values into series","metadata":{}},{"cell_type":"code","source":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:49:56.008735Z","iopub.execute_input":"2021-06-02T15:49:56.00926Z","iopub.status.idle":"2021-06-02T15:49:56.019262Z","shell.execute_reply.started":"2021-06-02T15:49:56.009227Z","shell.execute_reply":"2021-06-02T15:49:56.018199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:49:57.386206Z","iopub.execute_input":"2021-06-02T15:49:57.386798Z","iopub.status.idle":"2021-06-02T15:49:58.021807Z","shell.execute_reply.started":"2021-06-02T15:49:57.386763Z","shell.execute_reply":"2021-06-02T15:49:58.021094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectPercentile","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:50:01.481964Z","iopub.execute_input":"2021-06-02T15:50:01.482515Z","iopub.status.idle":"2021-06-02T15:50:01.486332Z","shell.execute_reply.started":"2021-06-02T15:50:01.48246Z","shell.execute_reply":"2021-06-02T15:50:01.485404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will choose only top percentile fatures. SelectPercentile helps us to choose top feature out of all the features.","metadata":{}},{"cell_type":"code","source":"## Selecting the top 20 percentile\nselected_top_columns = SelectPercentile(mutual_info_regression, percentile=20)\nselected_top_columns.fit(X_train.fillna(0), y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:50:03.707782Z","iopub.execute_input":"2021-06-02T15:50:03.708405Z","iopub.status.idle":"2021-06-02T15:50:03.949141Z","shell.execute_reply.started":"2021-06-02T15:50:03.708352Z","shell.execute_reply":"2021-06-02T15:50:03.948139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In below code, false means that particular feature is not belonging to top 20 percentile. ","metadata":{}},{"cell_type":"code","source":"selected_top_columns.get_support()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:50:05.46218Z","iopub.execute_input":"2021-06-02T15:50:05.462727Z","iopub.status.idle":"2021-06-02T15:50:05.470145Z","shell.execute_reply.started":"2021-06-02T15:50:05.462676Z","shell.execute_reply":"2021-06-02T15:50:05.469126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting top most important feature","metadata":{}},{"cell_type":"code","source":"X_train.columns[selected_top_columns.get_support()]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:50:06.783008Z","iopub.execute_input":"2021-06-02T15:50:06.78348Z","iopub.status.idle":"2021-06-02T15:50:06.79001Z","shell.execute_reply.started":"2021-06-02T15:50:06.783451Z","shell.execute_reply":"2021-06-02T15:50:06.789194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5- Feature Selection Using Chi2 Statistical Analysis","metadata":{}},{"cell_type":"markdown","source":"# Fisher Score- Chisquare Test For Feature Selection\nCompute chi-squared stats between each non-negative feature and class.\n\nThis score should be used to evaluate categorical variables in a classification task.\nThis score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.\n\nRecall that the chi-square test measures dependence between stochastic variables, so using this function âweeds outâ the features that are the most likely to be independent of class and therefore irrelevant for classification. The Chi Square statistic is commonly used for testing relationships between categorical variables.\n\nIt compares the observed distribution of the different classes of target Y among the different categories of the feature, against the expected distribution of the target classes, regardless of the feature categories.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\ndf=sns.load_dataset('titanic')\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:06.452163Z","iopub.execute_input":"2021-06-02T16:42:06.452691Z","iopub.status.idle":"2021-06-02T16:42:06.465526Z","shell.execute_reply.started":"2021-06-02T16:42:06.452659Z","shell.execute_reply":"2021-06-02T16:42:06.464537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:10.086345Z","iopub.execute_input":"2021-06-02T16:42:10.086717Z","iopub.status.idle":"2021-06-02T16:42:10.109491Z","shell.execute_reply.started":"2021-06-02T16:42:10.086688Z","shell.execute_reply":"2021-06-02T16:42:10.108393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:12.340689Z","iopub.execute_input":"2021-06-02T16:42:12.341095Z","iopub.status.idle":"2021-06-02T16:42:12.364633Z","shell.execute_reply.started":"2021-06-02T16:42:12.341058Z","shell.execute_reply":"2021-06-02T16:42:12.36313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So,i am considering categorical features and will try to find out the top important features.","metadata":{}},{"cell_type":"markdown","source":"Creating a data frame for categorical features.we need to compare all the categories with the output category (Survived)","metadata":{}},{"cell_type":"code","source":"##['sex','embarked','alone','pclass','Survived']\ndf=df[['sex','embarked','alone','pclass','survived']]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:13.898115Z","iopub.execute_input":"2021-06-02T16:42:13.898652Z","iopub.status.idle":"2021-06-02T16:42:13.913255Z","shell.execute_reply.started":"2021-06-02T16:42:13.898607Z","shell.execute_reply":"2021-06-02T16:42:13.91243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sex']=np.where(df['sex']==\"male\",1,0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:15.505926Z","iopub.execute_input":"2021-06-02T16:42:15.506286Z","iopub.status.idle":"2021-06-02T16:42:15.520344Z","shell.execute_reply.started":"2021-06-02T16:42:15.506252Z","shell.execute_reply":"2021-06-02T16:42:15.51943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Let's perform label encoding on sex column\nimport numpy as np\n### let's perform label encoding on embarked\nordinal_label = {k: i for i, k in enumerate(df['embarked'].unique(), 0)}\ndf['embarked'] = df['embarked'].map(ordinal_label)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:17.158128Z","iopub.execute_input":"2021-06-02T16:42:17.158677Z","iopub.status.idle":"2021-06-02T16:42:17.165329Z","shell.execute_reply.started":"2021-06-02T16:42:17.15863Z","shell.execute_reply":"2021-06-02T16:42:17.164421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:27.214175Z","iopub.execute_input":"2021-06-02T16:42:27.214702Z","iopub.status.idle":"2021-06-02T16:42:27.227688Z","shell.execute_reply.started":"2021-06-02T16:42:27.214653Z","shell.execute_reply":"2021-06-02T16:42:27.226652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performing label encoding on each and every column.","metadata":{}},{"cell_type":"code","source":"### let's perform label encoding on alone\ndf['alone']=np.where(df['alone']==True,1,0)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:42:43.253592Z","iopub.execute_input":"2021-06-02T16:42:43.254051Z","iopub.status.idle":"2021-06-02T16:42:43.261022Z","shell.execute_reply.started":"2021-06-02T16:42:43.25401Z","shell.execute_reply":"2021-06-02T16:42:43.259789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:43:07.805537Z","iopub.execute_input":"2021-06-02T16:43:07.805938Z","iopub.status.idle":"2021-06-02T16:43:07.818204Z","shell.execute_reply.started":"2021-06-02T16:43:07.80588Z","shell.execute_reply":"2021-06-02T16:43:07.816873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### train Test split is usually done to avaoid overfitting\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(df[['sex','embarked','alone','pclass']],\n                                              df['survived'],test_size=0.3,random_state=100)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:43:22.751518Z","iopub.execute_input":"2021-06-02T16:43:22.751869Z","iopub.status.idle":"2021-06-02T16:43:22.76201Z","shell.execute_reply.started":"2021-06-02T16:43:22.751841Z","shell.execute_reply":"2021-06-02T16:43:22.760876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:43:39.028715Z","iopub.execute_input":"2021-06-02T16:43:39.029316Z","iopub.status.idle":"2021-06-02T16:43:39.041137Z","shell.execute_reply.started":"2021-06-02T16:43:39.029264Z","shell.execute_reply":"2021-06-02T16:43:39.040242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['sex'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:43:51.009388Z","iopub.execute_input":"2021-06-02T16:43:51.009736Z","iopub.status.idle":"2021-06-02T16:43:51.019817Z","shell.execute_reply.started":"2021-06-02T16:43:51.009706Z","shell.execute_reply":"2021-06-02T16:43:51.018654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:44:01.206708Z","iopub.execute_input":"2021-06-02T16:44:01.20722Z","iopub.status.idle":"2021-06-02T16:44:01.214941Z","shell.execute_reply.started":"2021-06-02T16:44:01.207187Z","shell.execute_reply":"2021-06-02T16:44:01.214126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Perform chi2 test\n### chi2 returns 2 values\n### Fscore and the pvalue\nfrom sklearn.feature_selection import chi2\nf_p_values=chi2(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:44:14.391778Z","iopub.execute_input":"2021-06-02T16:44:14.39238Z","iopub.status.idle":"2021-06-02T16:44:14.403222Z","shell.execute_reply.started":"2021-06-02T16:44:14.392346Z","shell.execute_reply":"2021-06-02T16:44:14.40207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Chi2 gives us two value-\n\nFscore - fscore needs to be higher, the more the value of fscore the more important feature is\n\nPvalue - lesser the pvalue the more important the feature is","metadata":{}},{"cell_type":"markdown","source":"1st array values is of fscore\n\n2nd array values is of pvalue","metadata":{}},{"cell_type":"code","source":"f_p_values","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:44:23.508714Z","iopub.execute_input":"2021-06-02T16:44:23.509075Z","iopub.status.idle":"2021-06-02T16:44:23.515694Z","shell.execute_reply.started":"2021-06-02T16:44:23.509045Z","shell.execute_reply":"2021-06-02T16:44:23.514632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make a series of these p_values","metadata":{}},{"cell_type":"code","source":"import pandas as pd\np_values=pd.Series(f_p_values[1])\np_values.index=X_train.columns\np_values","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:44:35.411807Z","iopub.execute_input":"2021-06-02T16:44:35.412402Z","iopub.status.idle":"2021-06-02T16:44:35.421879Z","shell.execute_reply.started":"2021-06-02T16:44:35.412351Z","shell.execute_reply":"2021-06-02T16:44:35.420457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sort the series in ascending order","metadata":{}},{"cell_type":"code","source":"p_values.sort_index(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:44:52.621413Z","iopub.execute_input":"2021-06-02T16:44:52.621973Z","iopub.status.idle":"2021-06-02T16:44:52.632309Z","shell.execute_reply.started":"2021-06-02T16:44:52.621924Z","shell.execute_reply":"2021-06-02T16:44:52.631286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation\nSex Column is the most important column when compared to the output feature Survived","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}