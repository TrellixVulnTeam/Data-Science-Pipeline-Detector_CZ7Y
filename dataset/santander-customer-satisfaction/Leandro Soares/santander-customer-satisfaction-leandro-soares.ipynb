{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d689a18-dea3-4d27-b00c-fdf209341d21"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Any results you write to the current directory are saved as output.\n\n# Carrega a matriz de treinamento para um dataset.\nmatriz_treino_original = pd.read_csv(filepath_or_buffer = \"../input/train.csv\", index_col = 0)\nmatriz_teste_original = pd.read_csv(filepath_or_buffer = \"../input/test.csv\", index_col = 0)\nprint(\"At first: \" + str(matriz_treino_original.shape))\nprint (\"Satisfied Customers: \" + str(matriz_treino_original[matriz_treino_original.TARGET == 0].shape))\nprint (\"Unhappy Customers: \" + str(matriz_treino_original[matriz_treino_original.TARGET == 1].shape))\n\n# eliminaVarianciaZero removes from the dataset columns whose variance of values\n# of rows is zero.\ndef eliminaVarianciaZero (matriz):\n    # Para cada coluna, calcula-se a vari√¢ncia.\n    variancia = matriz.var(axis = 0, numeric_only = True)\n    matriz_sem_variancia_zero = matriz.loc[:, variancia.loc[variancia != 0].index]\n    return matriz_sem_variancia_zero\n\nmatriz_treino = eliminaVarianciaZero(matriz_treino_original)\nprint(\"After eliminating zero variance: \" + str(matriz_treino.shape))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d08350d-c9ff-e3dd-5b5a-1d859fb29b29"},"outputs":[],"source":"# eliminaPercentil10IgualPercentil95 removes from the dataset the columns whose\n# 10th percentile and 95th percentile are equal to each other, considering two\n# datasets generated from the original array, one with the rows of\n# TARGET equal to zero and one with the rows of TARGET equal to 1.\ndef eliminaPercentil10IgualPercentil95 (matriz):\n    matriz_pos = matriz[matriz.TARGET == 0].describe(percentiles = [0.1, 0.95])\n    matriz_neg = matriz[matriz.TARGET == 1].describe(percentiles = [0.1, 0.95])\n    colunas = matriz.columns.drop('TARGET')\n    colunas_manter = matriz.columns.where(matriz.columns == 'TARGET').dropna()\n\n    for coluna in colunas:\n        p10_pos = matriz_pos.loc['10%', coluna]\n        p95_pos = matriz_pos.loc['95%', coluna]\n\n        p10_neg = matriz_neg.loc['10%', coluna]\n        p95_neg = matriz_neg.loc['95%', coluna]\n\n        if not(p10_pos == p95_pos == p10_neg == p95_neg):\n            colunas_manter = colunas_manter.insert(colunas_manter.size - 1, coluna)\n\n    matriz_retorno = matriz.loc[:, colunas_manter]\n    return matriz_retorno\n\nmatriz_treino = eliminaPercentil10IgualPercentil95(matriz_treino)\nprint(\"After eliminating 10 and 95 percentile equals: \" + str(matriz_treino.shape))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee6c4998-1d11-e788-08c5-1b7992d93e87"},"outputs":[],"source":"# eliminaLinhasDuplicadas deletes duplicate rows in two steps:\n# First it eliminates duplicate lines, considering TARGET, keeping only\n# one of them.\n# After this, delete all duplicate rows, except for TARGET.\ndef eliminaLinhasDuplicadas (matriz):\n    matriz_retorno = matriz.drop_duplicates()\n    matriz_retorno = matriz_retorno.drop_duplicates(subset = matriz_retorno.columns.drop('TARGET'), keep = False)\n    return matriz_retorno\n\nmatriz_treino = eliminaLinhasDuplicadas(matriz_treino)\nprint(\"After deleting duplicate rows: \" + str(matriz_treino.shape))\nprint (\"Satisfied Customers: \" + str(matriz_treino[matriz_treino.TARGET == 0].shape))\nprint (\"Unhappy Customers: \" + str(matriz_treino[matriz_treino.TARGET == 1].shape))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62140092-7bae-275f-c400-31ffe8d703d7"},"outputs":[],"source":"# Set up three datasets for training and validation of the classifier, the\n# Following way:\n# - The dataset is broken in two, depending on the classification of the sample.\n# - Randomly select 15% of samples from each of the two sets\n# To compose the validation set.\n# - The remaining samples from the set with data classified as \"Not satisfied\"\n# Composes two training sets, one balanced and one unbalanced.\n# - The remaining samples from the set with the data classified as \"Satisfied\"\n# Compose the unbalanced training set.\n# - Randomly select the remaining samples from the set with the data\n# Classified as \"Satisfied\" the number of remaining samples of the set with\n# The data classified as \"Not satisfied\" to compose the set of\n# Balanced training.\n\nimport random as rnd\n\nids_satisfeito = matriz_treino[matriz_treino.TARGET == 0].index\nids_nao_satisfeito = matriz_treino[matriz_treino.TARGET == 1].index\n\nquantidade_amostras_validacao = round(0.15 * ids_satisfeito.size)\nlista_id_aleatoria = rnd.sample(list(ids_satisfeito), quantidade_amostras_validacao)\nids_validacao = pd.Index(lista_id_aleatoria)\nids_satisfeito = ids_satisfeito.drop(lista_id_aleatoria)\n\nquantidade_amostras_validacao = round(0.15 * ids_nao_satisfeito.size)\nlista_id_aleatoria = rnd.sample(list(ids_nao_satisfeito), quantidade_amostras_validacao)\nids_validacao = ids_validacao.append(pd.Index(lista_id_aleatoria))\n\nids_treino_nao_balanceado = matriz_treino.index.drop(ids_validacao)\n\nids_treino_balanceado = ids_nao_satisfeito.drop(lista_id_aleatoria)\nlista_id_aleatoria = rnd.sample(list(ids_satisfeito), ids_treino_balanceado.size)\nids_treino_balanceado = ids_treino_balanceado.append(pd.Index(lista_id_aleatoria))\n\nmatriz_validacao = matriz_treino.loc[ids_validacao, :]\nmatriz_treino_nao_balanceado = matriz_treino.loc[ids_treino_nao_balanceado, :]\nmatriz_treino_balanceado = matriz_treino.loc[ids_treino_balanceado, :]\n\nprint(\"Validation dataset: \" + str(matriz_validacao.shape))\nprint(\"Unbalanced training dataset: \" + str(matriz_treino_nao_balanceado.shape))\nprint(\"Balanced training dataset: \" + str(matriz_treino_balanceado.shape))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c04cb200-a1a5-e346-9af4-a98b99d32d10"},"outputs":[],"source":"# It creates classifiers, using K-Nearest Neighbor with k equal to 1 and k equals 5,\n# with balanced and unbalanced data, and measures the accuracy of each of these\n# models, considering the validation data.\nimport sklearn.neighbors as sknb\nimport sklearn.metrics as skmt\n\ndef validaClassificador(matriz_treinamento, matriz_validacao, numero_vizinhos):\n    matriz_treino_atributos = matriz_treinamento.loc[:, matriz_treinamento.columns.drop(['TARGET'])]\n    matriz_treino_alvo = matriz_treinamento.loc[:, 'TARGET']\n\n    matriz_validacao_atributos = matriz_validacao.loc[:, matriz_validacao.columns.drop(['TARGET'])]\n    matriz_validacao_alvo = matriz_validacao.loc[:, 'TARGET']\n\n    classificador = sknb.KNeighborsClassifier(n_neighbors = numero_vizinhos)\n    classificador.fit(matriz_treino_atributos, matriz_treino_alvo)\n    \n    predicao = pd.DataFrame(classificador.predict(matriz_validacao_atributos))\n\n    acuracia = skmt.accuracy_score(matriz_validacao_alvo, predicao)\n\n    return acuracia\n\nacuracia_desbal_1 = validaClassificador(matriz_treino_nao_balanceado, matriz_validacao, 1)\nprint(\"Accuracy unbalanced model 1 neighbor: \" + str(acuracia_desbal_1))\n\nacuracia_desbal_5 = validaClassificador(matriz_treino_nao_balanceado, matriz_validacao, 5)\nprint(\"Accuracy unbalanced model 5 neighbors: \" + str(acuracia_desbal_5))\n\nacuracia_bal_1 = validaClassificador(matriz_treino_balanceado, matriz_validacao, 1)\nprint(\"Accuracy balanced model 1 neighbor: \" + str(acuracia_bal_1))\n\nacuracia_bal_5 = validaClassificador(matriz_treino_balanceado, matriz_validacao, 5)\nprint(\"Accuracy balanced model 5 neighbors: \" + str(acuracia_bal_5))\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}