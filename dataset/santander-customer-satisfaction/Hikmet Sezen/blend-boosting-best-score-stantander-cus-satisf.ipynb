{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Blend Boosting study on dataset of the Santander Customer Satisfaction:\n\nHere I share with you a systematic blend boosting study on dataset of the Santander Customer Satisfaction (https://www.kaggle.com/c/santander-customer-satisfactione). I just collect some submission files (15 distincts).\n\nBasically, I start to analysis of correlations, then decide to sort them according to their sum of correlation values in between. This lets me divide 15 scores into 3 subgroups. Then I make internal linear calibration in each subgroup by considering their scores on the Kaggle. Finally I make recalling between subgroups to achieve higher scores on the Kaggle by resubmission. Of course, if you spend much more time, you can always achieve betters scores, but I stop it here because it is already highest score on Kaggle ;-).  ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# loading dummy submission file\nsub_file = pd.read_csv('../input/santander-customer-satisf/submission_file.csv')\n\n# loading data including 15 (some of them are identical) best scores\ndf_sub = pd.read_csv(r'../input/santander-customer-satisf/best_blend_1.csv')\n\n# a rough correlation based visualization of 32 best scores\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sub.corr(), cmap='Spectral')\nplt.ylabel('file index numbers')\nplt.xlabel('file index numbers')\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic analysis and visualization of subgroups in different color.\nplt.figure(figsize=(12, 5))\ndf_mean_corr = pd.DataFrame({'mean_corr': df_sub.corr().mean()})\ndf_mean_corr = df_mean_corr.sort_values('mean_corr', ascending=False)\ndf_mean_corr = df_mean_corr.reset_index()\n\nplt.plot(df_mean_corr.index[:6], df_mean_corr['mean_corr'].values[:6], 'o', ms=10)\nplt.plot(df_mean_corr.index[6:14], df_mean_corr['mean_corr'].values[6:14], 'o', ms=10)\nplt.plot(df_mean_corr.index[14:15], df_mean_corr['mean_corr'].values[14:15], 'o', ms=10)\nplt.plot(df_mean_corr.index[15:16], df_mean_corr['mean_corr'].values[15:16], 'o', ms=10)\nplt.plot(df_mean_corr.index[16:], df_mean_corr['mean_corr'].values[16:], 'o', ms=10)\n\nplt.xticks([*range(len(df_mean_corr))], df_mean_corr['index'].tolist())\nplt.title('determination of sub_groups')\nplt.ylabel('a corellation ralated index')\nplt.xlabel('file index numbers')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a linear combination to achieve much better scores\ndf_sub['weighted_avg'] = abs(1 * (\n        -10 * (-10 * df_sub['7'] - 3 * df_sub['8'] - 3 * df_sub['10'] \n               - 10 * df_sub['11'] + 10 * df_sub['12'] + 200 * df_sub['14']) / 184 +\n\n        80 * (10 * df_sub['0'] + 2 * df_sub['2'] + 1 * df_sub['3'] + 3 * df_sub['4'] + \n              3 * df_sub['5'] + 1 * df_sub['6'] + 200 * df_sub['15']) / 220 +\n\n        -33 * (3 * df_sub['1'] - 1 * df_sub['9'] + 13 * df_sub['13']) / 15) / 37)\n\n\n# create the final submission file\nsubmission = pd.DataFrame({'ID': sub_file.ID, 'TARGET': df_sub['weighted_avg'].tolist()})\nsubmission.to_csv(r'best_blend_result.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## It gets a 0.84296 AUC as public score, and looks the best score on Kaggle so far ;-)","metadata":{}}]}