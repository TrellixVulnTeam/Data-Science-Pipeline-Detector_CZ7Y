{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nimport numpy as np\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ntrain = pd.read_csv(\"../input/train.csv\")\ntest  = pd.read_csv(\"../input/test.csv\")\n\nalg = xgb.XGBClassifier(learning_rate =0.02,n_estimators=700,max_depth=6,min_child_weight=1,\n                         gamma=0,subsample=0.9,colsample_bytree=0.85,objective= 'binary:logistic',nthread=7,\n                         scale_pos_weight=1,seed=27)\ntarget='TARGET'\nIDcol='ID'\n                         \npredictors= [x for x in train.columns if x not in [target, IDcol]]\ncv_folds=5\nearly_stopping_rounds=25\n\n#get parameters\nxgb_param = alg.get_xgb_params()\n#make dmatrix\nxgtrain = xgb.DMatrix(train[predictors].values, label=train[target].values)\n#do cross validation \ncvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, metrics=['auc'],\n     early_stopping_rounds=early_stopping_rounds)\nalg.set_params(n_estimators=cvresult.shape[0]) #set n_estimators to best round\n\n#Fit the algorithm on the data\nalg.fit(train[predictors], train['TARGET'],eval_metric='auc')\n\n#Predict training set:\ntrain_predictions = alg.predict(train[predictors])\ntrain_predprob = alg.predict_proba(train[predictors])[:,1]\n\n#Print model report:\nprint (\"\\nModel Report\")\nprint (\"Accuracy : %.4g\" % metrics.accuracy_score(train['TARGET'].values, train_predictions))\nprint (\"AUC Score (Train): %f\" % metrics.roc_auc_score(train['TARGET'], train_predprob))\n\nfeat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n#feat_imp.plot(kind='bar', title='Feature Importances')  ##If needed\n#plt.ylabel('Feature Importance Score') \n\n#get 64 most important features\nfeat_imp=list(feat_imp.index[:64])\nfeat_imp.append('TARGET')\n\nnewTrain = train[feat_imp] #done!\npd.to_csv(newTrain,'Satander64Features.csv')\n\n#test your new dataset\ndef testFeatureReduction(train,newtrain):\n    if sum(newTrain['TARGET']) == sum(train['TARGET']):\n        print('Number of ones in target column preserved')\n    else:\n        print('Some information lost - not all ones are present')\n    print('Columns reduced from '+str(len(train.columns)) +' to ' +str(len(newtrain.columns)))\n\ntestFeatureReduction(train,newTrain)\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}