{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nimport lightgbm as lgb\nfrom lightgbm import plot_importance\nimport xgboost as xgb\n\n\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\n\n\nplt.style.use('seaborn')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/santander-customer-satisfaction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/santander-customer-satisfaction/test.csv')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Data Shape : \",train_df.shape)\nprint(\"Test Data Shape : \",test_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train_df.drop(['ID','TARGET'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\n* Target Percent\n* Check Multicollinearity\n* Check Outlier","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(train_df['TARGET'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(10,4))\ntrain_df['TARGET'].value_counts().plot.pie(\n    explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True\n)\nsns.countplot('TARGET', data=train_df, ax=ax[1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_value = train_df.isnull().sum().sort_values(ascending=False)\nnull_percent = round(train_df.isnull().sum().sort_values(ascending=False)/len(train_df)*100,2)\npd.concat([null_value, null_percent], axis=1, keys=['Null values', 'Percent'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features[features.columns[:8]].corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(features[features.columns[:8]].corr(),annot=True,cmap='YlGnBu')\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> We Can Check Multicollinearity","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train_df[features.columns].mean(axis=1),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features.columns].mean(axis=1),color=\"red\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per rows in the train and test set\")\nsns.distplot(train_df[features.columns].std(axis=1),color=\"blue\",kde=True,bins=120, label='train')\nsns.distplot(test_df[features.columns].std(axis=1),color=\"green\", kde=True,bins=120, label='test')\nplt.legend(); plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t0 = train_df[train_df['TARGET'] == 0]\nt1 = train_df[train_df['TARGET'] == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per row in the train set\")\nsns.distplot(t0[features.columns].skew(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features.columns].skew(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> We Can Check Outlier","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.boxplot(train_df['var3'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.boxplot(train_df['var38'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n* Processing Outlier Values","metadata":{}},{"cell_type":"code","source":"train_df['var3'].replace(-999999,2,inplace=True)\ntrain_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n* Split Data to Train / Test \n* Train Data to Standard Scaler\n* Target Data to Oversampling by SMOTE","metadata":{}},{"cell_type":"code","source":"train_df.drop('ID',axis=1,inplace=True)\ntest_df.drop('ID',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train_df.drop('TARGET',axis=1)\ny = train_df['TARGET']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler().fit(x)\nx_scaler = scaler.transform(x)\ntest_df_scler = scaler.transform(test_df)\nx_scaler_df = pd.DataFrame(x_scaler, columns=x.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=0.95)\nx_scaler_pca = pca.fit_transform(x_scaler)\nx_scaler_pca_df = pd.DataFrame(x_scaler_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_scaler_pca_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(x_scaler_pca_df.loc[:, 0], x_scaler_pca_df.loc[:, 1], c=y,  cmap=\"copper_r\")\nplt.axis('off')\nplt.colorbar()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> We cant use PCA","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler_x_train, scaler_x_test, scaler_y_train, scaler_y_test = train_test_split(x_scaler, y, test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smote = SMOTE()\nx_over, y_over = smote.fit_resample(scaler_x_train,scaler_y_train)\ny_over.value_counts().plot(kind='bar',title='Count_target',color=['blue','orange'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling\n* LogisticRegression\n* LightGBM Classification","metadata":{}},{"cell_type":"code","source":"def get_clf_eval(y_test, pred = None, pred_proba = None):\n    confusion = confusion_matrix(y_test, pred)\n    accuacy = accuracy_score(y_test, pred)\n    precision = precision_score(y_test, pred)\n    recall = recall_score(y_test, pred)\n    f1 = f1_score(y_test, pred)\n    roc_auc = roc_auc_score(y_test, pred_proba)\n    \n    print('confusion')\n    print(confusion)\n    print('Accuacy : {}'.format(np.around(accuacy,4)))\n    print('Precision: {}'.format(np.around(precision,4)))\n    print('Recall : {}'.format(np.around(recall,4)))\n    print('F1 : {}'.format(np.around(f1,4)))  \n    print('ROC_AUC : {}'.format(np.around(roc_auc,4)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* LogisticRegression ","metadata":{}},{"cell_type":"code","source":"lg_reg = LogisticRegression()\n\nlg_reg.fit(x_over, y_over)\npred = lg_reg.predict(scaler_x_test)\npred_proba = lg_reg.predict_proba(scaler_x_test)[:,1]\nget_clf_eval(scaler_y_test, pred, pred_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* LightGBM Classifier","metadata":{}},{"cell_type":"code","source":"scaler_x_test, scaler_x_val, scaler_y_test, scaler_y_val = train_test_split(scaler_x_test, scaler_y_test, test_size=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = lgb.Dataset(x_over, label=y_over)\nval_data = lgb.Dataset(scaler_x_val, label=scaler_y_val)\nparams = {\n    'n_estimators': 5000,\n    'num_leaves': 20,\n    'max_depth': -1,\n    'min_data_in_leaf': 80,\n    'learning_rate': 0.001,\n    'boosting': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'n_jobs': -1\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.train(params,\n                  train_data,\n                  valid_sets=val_data, \n                  valid_names=['train','valid'],\n                  early_stopping_rounds=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/santander-customer-satisfaction/sample_submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = model.predict(test_df_scler)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['TARGET'] = target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}