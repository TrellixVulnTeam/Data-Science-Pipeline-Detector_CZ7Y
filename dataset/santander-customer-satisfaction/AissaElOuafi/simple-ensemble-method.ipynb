{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import cross_validation\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport seaborn as sns\nimport xgboost as xgb\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"id_test = test_data['ID']\ntarget = train_data['TARGET'].values\nX_train = train_data.drop(['ID','TARGET'], axis=1)\nX_test = test_data.drop(['ID'], axis=1).values\nprint (\"The number of features before the domentionality reduction approach : \",X_train.shape[1])"},{"cell_type":"markdown","metadata":{},"source":"## Dimentionality Reduction using ExtraTreesClassifier \nWe have 369 features in train data, the goal of this step is to reduce the number of features and the dimesion of data, a lot of features are duplicated or they have zero variances. Some features are higly correlated. The dimentionality redcution imporve the quality of model because it reduce noises in data and accelerates the execution time of machine learning models. I decided to use and `Extra Trees Classifier` to do the dimentionality reduction. We can also use `Principal Components Analysis (PCA)` or `Linear Discriminant Analysis (LDA)` in order to reduce the dimension of data."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"clf = ExtraTreesClassifier()\nclf = clf.fit(X_train,target)\nclf.feature_importances_\nmodel = SelectFromModel(clf,prefit=True)\nXr_Train = model.transform(X_train)\nXr_Test = model.transform(X_test)\nprint (\"The number of features after the domentionality reduction approach : \",Xr_Test.shape[1])"},{"cell_type":"markdown","metadata":{},"source":"## Random Forest Classifier"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"clf = RandomForestClassifier(n_estimators=120, max_depth=17, random_state=1)\nclf.fit(Xr_Train, target)\ny_pred = clf.predict_proba(Xr_Test)\nscores = cross_validation.cross_val_score(clf, Xr_Train, target, scoring='roc_auc', cv=5) \nprint(scores.mean())\nsubmission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred[:,1]})\nsubmission.to_csv(\"submission_rfc.csv\", index=False)"},{"cell_type":"markdown","metadata":{},"source":"## XGB Classifier"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"xgbClassifier = xgb.XGBClassifier(n_estimators=580, max_depth=5, seed=1234, missing=np.nan, learning_rate=0.02, subsample=0.7, colsample_bytree=0.7, objective='binary:logistic') \nxgbClassifier.fit(Xr_Train,target)\ny_xgb_pred = xgbClassifier.predict_proba(Xr_Test)\nscores = cross_validation.cross_val_score(xgbClassifier, Xr_Train, target, scoring='roc_auc', cv=5) \nprint(scores.mean())"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}