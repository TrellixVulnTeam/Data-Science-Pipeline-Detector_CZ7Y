{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\", color_codes=True)\n\n# Loading training and testing data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(train.drop_duplicates(subset=train.columns[1:-1]).shape)\nprint(train.drop_duplicates(subset=train.columns[1:]).shape)\n\nprint(train.drop_duplicates(subset=train.columns[1:-1], keep=False).shape)\nprint(train.drop_duplicates(subset=train.columns[1:], keep=False).shape)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(train.drop_duplicates(subset=train.columns[1:-1]).shape)\nprint(train.drop_duplicates(subset=train.columns[1:]).shape)\n\nprint(train.drop_duplicates(subset=train.columns[1:-1], keep=False).shape)\nprint(train.drop_duplicates(subset=train.columns[1:], keep=False).shape)\nlen(train.columns[1:-1])\nduplicate_ids = set(train['ID']).difference(set(train.drop_duplicates(subset=train.columns[1:-1], keep=False)['ID']))\nduplicate_ids_2 = set(train['ID']).difference(set(train.drop_duplicates(subset=train.columns[1:], keep=False)['ID']))\nprint(len(duplicate_ids))\nprint(len(duplicate_ids_2))\nto_drop = duplicate_ids.difference(duplicate_ids_2)\ntrain = train[~train['ID'].isin(to_drop)].drop_duplicates(subset=train.columns[1:])\ntrain.shape"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# replace all -999999 values with most common value(2)\ntrain = train.replace(-999999,2)\ntrain.loc[train.var3==-999999].shape\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Add features that count number of zeros in a row\nX = train.iloc[:,:-1]\ny = train.TARGET\nX['n0'] = (X==0).sum(axis=1)\ntrain['n0'] = X['n0']\n\n#train = train.drop(['TARGET'], axis=1)\n# Removing constant columns \ncolumnsToRemove = []\nfor col in train.columns:\n    if train[col].std() == 0:\n        columnsToRemove.append(col)\n\n\ntrain.drop(columnsToRemove, axis=1, inplace=True)\n\n# Remove duplicate Columns \n\ncolumnsToRemove = []\ncolumns = train.columns\nfor i in range(len(columns)-1):\n    v = train[columns[i]].values\n    for j in range(i+1, len(columns)):\n        if np.array_equal(v, train[columns[j]].values):\n            columnsToRemove.append(columns[j])\n\ntrain.drop(columnsToRemove, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# including analysis on var38 by cast42 from the below link.\n#https://www.kaggle.com/cast42/santander-customer-satisfaction/exploring-features/comments\ntrain['var38mc'] = np.isclose(train.var38, 117310.979016)\ntrain['logvar38'] = train.loc[~train['var38mc'], 'var38'].map(np.log)\ntrain.loc[train['var38mc'], 'logvar38'] = 0"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"col = [x for x in train.columns if x not in ['TARGET']]\nX = train[col]\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import f_classif,chi2\nfrom sklearn.preprocessing import Binarizer, scale\n\n# First select features based on chi2 and f_classif\np = 3\n\nX_bin = Binarizer().fit_transform(scale(X))\nselectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, y)\nselectF_classif = SelectPercentile(f_classif, percentile=p).fit(X, y)\n\nchi2_selected = selectChi2.get_support()\nchi2_selected_features = [ f for i,f in enumerate(X.columns) if chi2_selected[i]]\nprint('Chi2 selected {} features {}.'.format(chi2_selected.sum(),\n   chi2_selected_features))\nf_classif_selected = selectF_classif.get_support()\nf_classif_selected_features = [ f for i,f in enumerate(X.columns) if f_classif_selected[i]]\nprint('F_classif selected {} features {}.'.format(f_classif_selected.sum(),\n   f_classif_selected_features))\nselected = chi2_selected & f_classif_selected\nprint('Chi2 & F_classif selected {} features'.format(selected.sum()))\nfeatures = [ f for f,s in zip(X.columns, selected) if s]\nfeatures = features + ['n0', 'logvar38', 'var38mc']\nprint (features)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import cross_validation\nimport xgboost as xgb\n\n# Try a classification algorithm\nfeatures = ['var15', 'ind_var5', 'ind_var30', 'num_var5', 'num_var30', 'num_var42', \n            'var36', 'num_meses_var5_ult3', 'n0', 'logvar38', 'var38mc']\ninputData = train[features]\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(inputData, y, random_state=1301, stratify=y, test_size=0.3)\n\ndtrain = xgb.DMatrix(X_train, label=y_train, missing=9999999999)\ndtest = xgb.DMatrix(X_test, label=y_test, missing=9999999999)\n\nparam = {'bst:max_depth':2, 'bst:eta':0.01, 'silent':1, 'objective':'binary:logistic','bst:subSample':0.65 }\nparam['nthread'] = 4\nparam['eval_metric'] = 'auc'\n\nnum_round = 200\n\nevallist  = [(dtest,'eval'), (dtrain,'train')]\nbst = xgb.train( param, dtrain, num_round, evallist )"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.var36.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def var36_99(var):\n    if var == 99:\n        return 1\n    else:\n        return 0\ndef var36_0123(var):\n    if var != 99:\n        return 1\n    else:\n        return 0\ntrain['var36_99'] = train.var36.apply(var36_99)\ntrain['var36_0123'] = train.var36.apply(var36_0123)\ntrain['saldo_var30'] = train.saldo_var30.map(np.log)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import cross_validation\nimport xgboost as xgb\n\nfeatures = ['var15', 'ind_var5', 'ind_var30', 'num_var5', 'num_var30', 'num_var42', 'var36', \n            'num_meses_var5_ult3', 'n0', 'logvar38', 'var38mc','var36_99','var36_0123','saldo_var30']\n\ninputData = train[features]\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(inputData, y, random_state=1301, stratify=y, test_size=0.3)\n\ndtrain = xgb.DMatrix(X_train, label=y_train, missing=9999999999)\ndtest = xgb.DMatrix(X_test, label=y_test, missing=9999999999)\n\nparam = {'bst:max_depth':3, 'bst:eta':0.01, 'silent':1, 'objective':'binary:logistic','bst:subSample':0.7,\n        'bst:scale_pos_weight':0.96}\nparam['nthread'] = 4\nparam['eval_metric'] = 'auc'\n\nnum_round = 500\n\nevallist  = [(dtest,'eval'), (dtrain,'train')]\nbst = xgb.train( param, dtrain, num_round, evallist )"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test['n0'] = (test == 0).sum(axis=1)\ntest['var36_99'] = test.var36.apply(var36_99)\ntest['var36_0123'] = test.var36.apply(var36_0123)\ntest['var38mc'] = np.isclose(test.var38, 117310.979016)\ntest['logvar38'] = test.loc[~test['var38mc'], 'var38'].map(np.log)\ntest.loc[test['var38mc'], 'logvar38'] = 0\n\nsel_test = test[features]\nxgmat = xgb.DMatrix(sel_test)\ny_pred = bst.predict(xgmat,ntree_limit=bst.best_ntree_limit)\n\nsubmission = pd.DataFrame({\"ID\":test.index, \"TARGET\":y_pred})\nsubmission.to_csv(\"submission.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train['saldo_var30'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}