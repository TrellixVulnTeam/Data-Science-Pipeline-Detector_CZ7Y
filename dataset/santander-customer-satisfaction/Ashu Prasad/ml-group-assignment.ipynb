{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the dataframe\ndataframe = pd.read_csv(\"../input/santander-customer-satisfaction/train.csv\")\n\n# Print the first 20 rows\ndataframe.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We print the sum of NaNs in each coloumn\nnp.isnan(dataframe).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning data to the train dataframe\ntrain_data = dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping Target as we are supposed to predict that\n# Dropping ID as it is unique to all rows\ntrain_data = train_data.drop(['TARGET'], axis = 1)\ntrain_data = train_data.drop(['ID'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing redundant and low variance features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We append the coloumn names that have 0 standard deviation as we can't gather much info from these due to low variance\nremove_col_std = []\nfor i in train_data.columns:\n    if(train_data[i].std() == 0):\n        remove_col_std.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Redefining train dataframe by removing the 0 standard deviation coloumns\ntrain_data = train_data.drop(remove_col_std, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing columns that are identical to one another\nremove_col_redund = []\ncount = 0\nfor i in range(len(train_data.columns)):\n    i_values = train_data[train_data.columns[i]].values\n    for j in range(i+1, len(train_data.columns)):\n        if(np.array_equal(i_values, train_data[train_data.columns[j]].values)):\n            remove_col_redund.append(train_data.columns[j])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Redefining the train dataframe once more by dropping redundant coloumns\ntrain_data = train_data.drop(remove_col_redund, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection using Correlation-Heatmap"},{"metadata":{},"cell_type":"markdown","source":"Correlation of first 10 features with TARGET"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We select the first 20 features and the target coloumn\nfirst_df = pd.concat([train_data.iloc[:, :20], train_data.iloc[:, 305]], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We print the correlation heatmap for these 20 features with the target variable\nplt.figure(figsize = (20 ,20))\ncorrmat = first_df.corr()\ntop_corr_features = corrmat.index\nsns.heatmap(first_df[top_corr_features].corr(), annot = True, cmap = 'RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Intresting features:\n<ol>\n    <li>var15</li>\n</ol>"},{"metadata":{},"cell_type":"markdown","source":"Implementing the above strategy for the rest of the features. <br>We take the correlation boundary as 0.020. This means all features above or equal to this correlation value will be considered as an intresting feature.\n\nNOTE: Since the scale for correlation changes, evaluate by the value in each box rather than the colour."},{"metadata":{},"cell_type":"markdown","source":"Ideally, try to take features which are having either a correlation score closer to 1 or -1"},{"metadata":{},"cell_type":"markdown","source":"We may have to implement the same process for all the features to check how each feature correlates with the target variable which can be quite tedious given the number of features."},{"metadata":{"trusted":true},"cell_type":"code","source":"first_df = pd.concat([train_data.iloc[:, 296:306], train_data.iloc[:, 305]], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20 ,20))\ncorrmat = first_df.corr()\ntop_corr_features = corrmat.index\nsns.heatmap(first_df[top_corr_features].corr(), annot = True, cmap = 'RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems that ind_var2_0, ind_var2, ind_var27_0, ind_var28_0, ind_var28, ind_var27 don't have any correlation with any feature.\n\nIntresting features:\n<ol>\n    <li>var15 = 0.1</li>\n    <li>ind_var8_0 = 0.047</li>\n    <li>ind_var8 = 0.028</li>\n    <li>ind_var26_cte = 0.024</li>\n    <li>ind_var25_cte = 0.023</li>\n    <li>num_var8_0 = 0.047</li>\n    <li>num_var8 = 0.028</li>\n    <li>var36 = 0.1</li>\n    <li>num_var22_ult1 = 0.025</li>\n    <li>num_meses_var8_ult3 = 0.026</li>\n    <li>num_op_var41_efect_ult1 = 0.021</li>\n    <li>num_op_var41_efect_ult3 = 0.02</li>\n    <li>num_op_var39_efect_ult1 = 0.022</li>\n    <li>num_op_var39_efect_ult3 = 0.02</li>\n</ol>"},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection using K-Best"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We segregate the data features into 'X' dataframe and the target variable in the 'y' dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data.iloc[:, :306]\ny = dataframe.iloc[:, 370]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use the ANOVA test to determine the feature importance. This is done through the 'f_classif' method.\n\n'k' determines how many features are we going to select"},{"metadata":{"trusted":true},"cell_type":"code","source":"bestfeatures = SelectKBest(score_func = f_classif, k = 40)\nfit = bestfeatures.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create two dataframes. One containing the scores for each feature and the second dataframe, the feature itself"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScores = pd.concat([dfcolumns, dfscores], axis = 1)\nfeatureScores.columns = ['Features', 'Score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We sort the top 40 features"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(featureScores.nlargest(40, 'Score'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the top 30 features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (25, 6))\nsns.barplot(x = featureScores.nlargest(30, 'Score')['Features'], y = featureScores.nlargest(30, 'Score')['Score'])\nplt.xticks(rotation = 45)\nax = plt.gca()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection using Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ExtraTreesClassifier()\nselector = model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (60, 40))\nfeat_importances = pd.Series(model.feature_importances_, index = X.columns)\nfeat_importances.nlargest(40).plot(kind = 'barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Class distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsns.countplot(dataframe['TARGET'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly there's a lot of class imbalance"},{"metadata":{},"cell_type":"markdown","source":"This means we may have to use algorithms such as XGBoost or AdaBoost as they are known to be resilient to such class imbalance problem."},{"metadata":{},"cell_type":"markdown","source":"Satisfied customers:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe[dataframe['TARGET'] == 0].shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unsatisfied customers:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe[dataframe['TARGET'] == 1].shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting a feature set based on ExtraTreesClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of the top 40 features selected by the ExtraTreesClassifier\nlist(feat_importances.nlargest(40).index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_feat_1 = X[list(feat_importances.nlargest(40).index)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We determine the shape of the matrix and confirm if the shape of rows for the input matrix 'X' is same as that of 'y' "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X shape: \" +  str(X_feat_1.shape) + \" || y shape: \" + str(y.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we need to implement  train_test_split and feature scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_feat_1, y, test_size = 0.25, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]   \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiating the XGBClassfier\nclassifier_etc = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the 'roc_auc' scoring parameter as that is the metrics to be evaluated in the problem statement"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search = RandomizedSearchCV(classifier_etc, param_distributions = params, n_iter = 5, scoring = 'roc_auc', n_jobs = -1, cv = 5, verbose = 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We implement random search CV technique as this will search the search space randomly and will attempt to find the best set of hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once we have fit the data, we can directly get the best model parameters through the 'best_estimator_' method"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The optimal parameters can be extracted through the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_etc = random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Attempting to get the cross validation score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(classifier_etc,X,y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_etc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier_etc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Printing the confusion matrix for the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And our ROC curve score is..."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(\"Roc AUC: \", roc_auc_score(y_test, classifier_etc.predict_proba(X_test)[:,1], average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting a feature set based on K-Best"},{"metadata":{},"cell_type":"markdown","source":"We repeat the same process as before"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(featureScores.nlargest(40, 'Score')['Features'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_feat_2 = X[list(featureScores.nlargest(40, 'Score')['Features'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X shape: \" +  str(X_feat_2.shape) + \" || y shape: \" + str(y.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_feat_2, y, test_size = 0.20, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]   \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_k_best = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search = RandomizedSearchCV(classifier_k_best, param_distributions = params, n_iter = 5, scoring = 'roc_auc', n_jobs = -1, cv = 5, verbose = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_k_best = random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(classifier_k_best,X,y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_k_best.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier_k_best.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(\"Roc AUC: \", roc_auc_score(y_test, classifier_k_best.predict_proba(X_test)[:,1], average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finalizing"},{"metadata":{},"cell_type":"markdown","source":"Performing the final steps for result submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the test dataframe\ntest_df = pd.read_csv(\"../input/santander-customer-satisfaction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_X = test_df[list(feat_importances.nlargest(40).index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_X = sc.fit_transform(test_df_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ID = test_df.ID","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = classifier_etc.predict_proba(test_df_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"ID\":test_ID, \"TARGET\": probs[:,1]})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}