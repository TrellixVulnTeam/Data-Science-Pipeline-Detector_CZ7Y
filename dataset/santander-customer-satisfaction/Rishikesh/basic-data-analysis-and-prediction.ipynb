{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom pandas import Series,DataFrame\nfrom sklearn import preprocessing\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import cross_validation\nimport xgboost as xgb\n\ntrain_df   = pd.read_csv('../input/train.csv')\ntest_df  = pd.read_csv('../input/test.csv')\nsns.countplot(x=\"TARGET\", data=train_df)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for feat in train_df.columns:\n    if train_df[feat].dtype == 'float64':\n        train_df[feat][np.isnan(train_df[feat])] = train_df[feat].mean()\n        test_df[feat][np.isnan(test_df[feat])] = test_df[feat].mean()\n      \n    elif train_df[feat].dtype == 'object':\n        train_df[feat][train_df[feat] != train_df[feat]] = train_df[feat].value_counts().index[0]\n        test_df[feat][test_df[feat] != test_df[feat]] = test_df[feat].value_counts().index[0]\nfor feat in train_df.columns:\n    if train_df[feat].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(np.unique(list(train_df[feat].values) + list(test_df[feat].values)))\n        train_df[feat]   = lbl.transform(list(train_df[feat].values))\n        test_df[feat]  = lbl.transform(list(test_df[feat].values))\nX_train = train_df.drop([\"ID\",\"TARGET\"],axis=1)\nY_train = train_df[\"TARGET\"]\nX_test  = test_df.drop(\"ID\",axis=1).copy()\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.decomposition import PCA\n# Save a nice dark grey as a variable\nalmost_black = '#262626'\n# Instanciate a PCA object for the sake of easy visualisation\npca = PCA(n_components = 2)\n\n# Fit and transform x to visualise inside a 2D feature space\nx_vis = pca.fit_transform(X_train)\n\n# Plot the original data\n# Plot the two classes\npalette = sns.color_palette()\nplt.scatter(x_vis[Y_train==0, 0], x_vis[Y_train==0, 1], label=\"Class #0\", alpha=0.5, \n            edgecolor=almost_black, facecolor=palette[0], linewidth=0.15)\nplt.scatter(x_vis[Y_train==1, 0], x_vis[Y_train==1, 1], label=\"Class #1\", alpha=0.5, \n            edgecolor=almost_black, facecolor=palette[2], linewidth=0.15)\n\nplt.legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Logistic Regression\n\nlogreg = LogisticRegression(class_weight={0:0.2, 1:0.8})\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict_proba(X_test)[:,1]\n\nlogreg.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"svmreg=svm.SVC(kernel='linear', class_weight={1: 10})\nsvmreg.fit(X_train, Y_train)\nY_pred = svmreg.predict_proba(X_test)[:,1]\n\nsvmreg.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Create submission\n\nsubmission = pd.DataFrame()\nsubmission[\"ID\"] = test_df[\"ID\"]\nsubmission[\"TARGET\"] = Y_pred\n\nsubmission.to_csv('santander.csv', index=False)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}