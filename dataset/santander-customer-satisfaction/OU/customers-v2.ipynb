{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#import libraries\nimport time\nfrom functools import wraps\n\n#import data analytics libraries installed\nimport pandas as pd \nimport numpy as np\n\nfrom sklearn import cross_validation\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectFromModel\n\nimport xgboost as xgb\n\n#import data visualization libraries\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n\n\n#show run time of a function\n'''\ndef fn_timer(function):\n    @wraps(function)\n    def function_timer(*args, **kwargs):\n        t0 = time.time()\n        result=function(*args, **kwargs)\n        t1 = time.time()\n        print(\"Total running time %s: %s secconds\" % (function.func_name, str(t1-t0)))\n        return result\n    return function_timer\n'''\n\n#----------------------------------------load data-----------------------------------\nstart=time.clock()\n\n\n#@fn_timer\ndef readFile(fileName):\n    return pd.read_csv(fileName)\n    \ndf_train = readFile(\"../input/train.csv\")#load data into a dataframe\ndf_test = readFile(\"../input/test.csv\")\n\n\n\n#loading time\nend=time.clock()\nprint (\"loading time: %f seconds\" %(end -start ))\n#------------------------------------------------------------------------------------\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#preview \ndf_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_test.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n#------------------------------Data Preparation-----------------------------------------------------------\n#Clean data\n\n\n#@fn_timer \ndef removeDuplicatedRowsAndColumns():\n    #remove duplicated rows\n    df_train.drop_duplicates()\n    df_test.drop_duplicates()\n\n    #remove duplicated columns\n    remove = []\n    cols = df_train.columns\n    for i in range(len(cols)-1):\n        v = df_train[cols[i]].values\n        for j in range(i+1,len(cols)):\n            if np.array_equal(v,df_train[cols[j]].values):\n                remove.append(cols[j])\n\n    df_train.drop(remove, axis=1, inplace=True)\n    df_test.drop(remove, axis=1, inplace=True)\n    \n   \nremoveDuplicatedRowsAndColumns()\n\n\n#@fn_timer\ndef removeConstantColumns():\n    remove = []\n    for col in df_train.columns:\n        if df_train[col].std() == 0:\n            remove.append(col)\n\n    df_train.drop(remove, axis=1, inplace=True)\n    df_test.drop(remove, axis=1, inplace=True)\n\n    \nremoveConstantColumns()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_train.describe()\n#var3 contains -999999, outlier?\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_train.var3.replace(-999999,2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#-----------------------------------------Explore Data------------------------------------------\n#line number\nNb_clients=df_train.TARGET.count()\nprint (Nb_clients)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#In TARGET column: 0 means happy, 1 means unhappy\n#Distribution of Customer Satisfaction\ndf = df_train.TARGET.value_counts(1)\ndf"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#show distribution in Pie chart (just for fun)\nrate=[df[0],df[1]]\nlabels = ['happy', 'unhappy']\ncolors = ['blue','orange']\n\nplt.pie(rate, labels=labels, autopct='%1.2f%%', colors=colors)\nplt.show()\n#unbalanced positive and negative samples"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_train.var15.describe()\n#var15 is suspected to be the age of the customer\n#show distribution in histogram chart\ndf_train.var15.hist(bins=100) \nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#remove ID and TARGET\nY = df_train.TARGET.values\nX = df_train.drop([\"ID\",\"TARGET\"], axis=1) \n\ntest_id = df_test.ID\ndf_test = df_test.drop([\"ID\"], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Add PCA components as features\n#@fn_timer \ndef addPCAfeatures():\n    X_normalized = normalize(X, axis=0)\n    test_normalized= normalize(df_test, axis=0)\n    pca = PCA(n_components=3)\n    X_pca = pca.fit_transform(X_normalized)\n    test_pca=pca.fit_transform(test_normalized)\n    \n    X['PCA1'] = X_pca[:,0]\n    X['PCA2'] = X_pca[:,1]\n    X['PCA3'] = X_pca[:,2]\n\n    df_test['PCA1'] = test_pca[:,0]\n    df_test['PCA2'] = test_pca[:,1]\n    df_test['PCA3'] = test_pca[:,2]\n\n    \naddPCAfeatures()    \nX.ix[0:5, 306:309]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n#split data\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=0.30, random_state=1000)\nprint(X_train.shape, X_test.shape, df_test.shape)\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Feature selection\nclf = ExtraTreesClassifier(random_state=1000)\nselector = clf.fit(X_train, y_train)\n\n\n#FeatureName = X_train.columns.values\nimpScore = pd.Series(clf.feature_importances_)\n#c = pd.DataFrame({'FeatureName':X_train.columns.values,'b':impScore})\nc = pd.DataFrame({'impScore':impScore})\nc.index=X_train.columns.values\n\n# plot most important features\n#feat_imp = c.sort_values(ascending=False)\nc.sort_index(axis=0, by='impScore', ascending=False)[0:40].plot(kind='bar', title='Feature Importances according to ExtraTreesClassifier', figsize=(12, 8))\nplt.ylabel('Feature Importance Score')\nplt.subplots_adjust(bottom=0.3)\n#plt.savefig('1.png')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"fs = SelectFromModel(selector, prefit=True)\n\nX_train = fs.transform(X_train)\nX_test = fs.transform(X_test)\ndf_test = fs.transform(df_test)\n\nprint(X_train.shape, X_test.shape, df_test.shape)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#--------------------Train Model-------------------------------------------\n#xgboost\n#@fn_timer \ndef trainModel(i):\n    m2_xgb = xgb.XGBClassifier(n_estimators=110, nthread=-1, max_depth = i, \\\n    seed=1000)\n    m2_xgb.fit(X_train, y_train, eval_metric=\"auc\", verbose = False,\n               eval_set=[(X_test, y_test)])\n    return m2_xgb\n\n    \n   \n# calculate the auc score\nfor i in range(8):\n    print(\"max_depth =%s\" ,i+1 )\n    print(\"Roc AUC: \", roc_auc_score(y_test, trainModel(i).predict_proba(X_test)[:,1]))\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#max_depth=6 is the best \n# Submission\nprobs = trainModel(6).predict_proba(df_test)\n\nsubmission = pd.DataFrame({\"ID\":test_id, \"TARGET\": probs[:,1]})\nsubmission.to_csv(\"submission.csv\", index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}