{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom lasagne.layers import DenseLayer\nfrom lasagne.layers import InputLayer\nfrom lasagne.layers import DropoutLayer\nfrom lasagne.nonlinearities import softmax\nfrom lasagne.updates import nesterov_momentum\nfrom nolearn.lasagne import NeuralNet\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def load_data():\n    print('Loading data...')\n    # load train data    \n    df_train = pd.read_csv(\"../input/train.csv\")\n    df_test = pd.read_csv(\"../input/test.csv\")\n    \n    remove = []\n    for col in df_train.columns:\n        if df_train[col].std() == 0:\n            remove.append(col)\n\n    df_train.drop(remove, axis=1, inplace=True)\n    df_test.drop(remove, axis=1, inplace=True)\n\n    remove = []\n    c = df_train.columns\n    for i in range(len(c)-1):\n        v = df_train[c[i]].values\n        for j in range(i+1,len(c)):\n            if np.array_equal(v,df_train[c[j]].values):\n                remove.append(c[j])\n\n    df_train.drop(remove, axis=1, inplace=True)\n    df_test.drop(remove, axis=1, inplace=True)\n\n    target = df_train['TARGET'].values\n    df_train =df_train.drop(['TARGET'],axis=1)\n    id_test = df_test['ID'].values\n\n    categoricalVariables = []\n    for var in df_train.columns:\n        vector=pd.concat([df_train[var],df_test[var]], axis=0)\n        typ=str(df_train[var].dtype)\n        if (typ=='object'):\n            categoricalVariables.append(var)\n    \n    for col in categoricalVariables:\n        df_train[col] = pd.factorize(df_train[col])[0] \n        df_test[col] = pd.factorize(df_test[col])[0]   \n                                  \n    list_train=df_train.columns.tolist()\n    list_test =df_test.columns.tolist()\n    \n    #Remove sparse columns\n    sparse_col=[]\n    for col in df_train.columns:\n        cls=df_train[col].values\n        if sum(cls)<30:\n            sparse_col.append(col) \n           \n    df_train.drop(sparse_col, axis=1,inplace=True)\n    df_test.drop(sparse_col, axis=1,inplace=True)\n\n    df_train=df_train.fillna(-1)        \n    df_test=df_test.fillna(-1)   \n        \n    feature_names=df_train.columns.values.tolist()\n\n    X_train =df_train.values\n    X_test = df_test.values\n\n    scaler=StandardScaler()    \n    X_train = scaler.fit_transform(X_train)    \n    X_test=scaler.fit_transform(X_test)    \n    X_fit, X_eval, y_fit, y_eval= train_test_split(X_train, target, test_size=0.3,random_state=123)   \n    num_features=len(feature_names) \n    \n    return X_fit, X_eval, y_fit, y_eval,X_test,id_test,num_features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X_fit, X_eval, y_fit, y_eval,X_test,id_test,num_features=load_data()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X_fit.shape"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"## create layer of nn\nlayers = [('input', InputLayer),\n           ('dense0', DenseLayer),\n           ('dropout0', DropoutLayer),\n           ('dense1', DenseLayer),\n           ('dropout1', DropoutLayer),\n           ('output', DenseLayer)]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from lasagne.nonlinearities import sigmoid\n#lasagne.updates.adagrad\nfrom lasagne.updates import adagrad\nnet1 = NeuralNet(layers=layers,\n                 input_shape=(None, num_features),\n                 dense0_num_units=512,\n                 dropout0_p=0.1,\n                 dense1_num_units=256,\n                 dropout1_p=0.1,\n                 output_nonlinearity=sigmoid,\n                 update=adagrad,\n                 update_learning_rate=0.04,\n                 eval_size=0.2,\n                 verbose=1,\n                 max_epochs=15)\nnet1.fit(X_fit, y_fit)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}