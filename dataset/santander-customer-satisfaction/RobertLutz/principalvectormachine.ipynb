{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport matplotlib as plt\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"training_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"id_col = training_data.columns[0]\nfeature_cols = list(training_data.columns[1:-1])\ntarget_col = training_data.columns[-1]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.decomposition import PCA\npca = PCA(n_components=14).fit(training_data[feature_cols]) # 14 PCs explain virtually all the variance\n\n# Print the components and the amount of variance in the data contained in each dimension\nprint ('\\n', pca.explained_variance_ratio_)\nprint(sum(pca.explained_variance_ratio_))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X_train = pca.transform(balanced_data[feature_cols])\ny_train = balanced_data[target_col]\n\nX_test = pca.transform(test_data[feature_cols])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.svm import SVC\nfrom sklearn.cross_validation import cross_val_score\nclf = SVC()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.cross_validation import KFold\nfrom sklearn.grid_search import GridSearchCV\n\ndef best(classifier, paramdict, X_train, y_train):\n    kfcv = KFold(n=len(y_train), n_folds=10, shuffle=True)\n    gs = GridSearchCV(classifier, paramdict, cv=kfcv)\n    gs.fit(X_train, y_train)\n    return gs.best_estimator_, gs.best_params_\n\nparams = {'C': [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\nclf = SVC()\nbest_model, best_hyperparams = best(clf, params, X_train, y_train)\n\nprint(best_hyperparams)\nclf = best_model"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"scores = cross_val_score(clf, X_train, y_train, cv=10)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"clf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"results = pd.DataFrame({'TARGET':predictions}, index=test_data[id_col])\nprint(results[results['TARGET']==1].shape)\nprint(results)\nresults.to_csv('submission.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}