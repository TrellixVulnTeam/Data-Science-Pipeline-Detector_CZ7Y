{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom math import log, exp\nimport pylab as pl\nfrom random import random\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"training_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv', index_col='ID')\n\nfeature_cols = list(training_data.columns[1:-1])\ntarget_col = training_data.columns[-1]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#from sklearn.decomposition import PCA\n#pca = PCA(n_components=100, whiten=True).fit(training_data[feature_cols]) # 14 PCs explain virtually all the variance\n\n# Print the components and the amount of variance in the data contained in each dimension\n#print ('\\n', pca.explained_variance_ratio_)\n#print(sum(pca.explained_variance_ratio_))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"group_size = training_data[training_data['TARGET']==1].shape[0]\n\ntraining_data = training_data.reindex(np.random.permutation(training_data.index))\n\nbalanced_data = pd.concat([training_data[training_data['TARGET']==1][:group_size], \n                           training_data[training_data['TARGET']==0][:group_size]])\n\ny_train = balanced_data[target_col]\nX_train = balanced_data[feature_cols]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#y_train = pd.DataFrame(balanced_data[target_col])\n#X_train = pd.DataFrame(pca.transform(balanced_data[feature_cols]), index=y_train.index)\n\n#X_test = pd.DataFrame(pca.transform(test_data[feature_cols]), index=test_data.index)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import cross_val_score\n\nbooster = AdaBoostClassifier(n_estimators=151)\nbooster.fit(X_train,y_train)\n\nresults = pd.DataFrame({'TARGET':booster.predict(test_data)}, index=test_data.index)\nprint(results)\n\nresults.to_csv('submission.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}