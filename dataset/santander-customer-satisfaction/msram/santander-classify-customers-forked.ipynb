{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import division\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import OneClassSVM\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# load data\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\n\nignored_columns = ['ID', 'TARGET']\nC = df_train.columns\n\n# remove constant columns\neps = 1e-10\ndropped_columns = set()\nprint('Identifing low-variance columns...', end=' ')\nfor c in C:\n    if df_train[c].var() < eps:\n        # print('.. %-30s: too low variance ... column ignored'%(c))\n        dropped_columns.add(c)\nprint('done!')\nC = list(set(C) - dropped_columns - set(ignored_columns))\n\n# remove duplicate columns\nprint('Identifying duplicate columns...', end=' ')\nfor i, c1 in enumerate(C):\n    f1 = df_train[c1].values\n    for j, c2 in enumerate(C[i+1:]):\n        f2 = df_train[c2].values\n        if np.all(f1 == f2):\n            dropped_columns.add(c2)\nprint('done!')\n\nC = list(set(C) - dropped_columns - set(ignored_columns))\nprint('# columns dropped: %d'%(len(dropped_columns)))\nprint('# columns retained: %d'%(len(C)))\n\ndf_train.drop(dropped_columns, axis=1, inplace=True)\ndf_test.drop(dropped_columns, axis=1, inplace=True)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"y_train_valid_ltest = df_train['TARGET'].values\nX_train_valid_ltest = df_train.drop(['ID','TARGET'], axis=1).values\n\nid_test = df_test['ID']\nX_test = df_test.drop(['ID'], axis=1).values\n\n# length of dataset\nlen_train = len(X_train_valid_ltest)\nlen_test  = len(X_test)\n\nX_train_valid, X_local_test, y_train_valid, y_local_test = train_test_split(X_train_valid_ltest, y_train, test_size=0.2)\nX_fit, X_eval, y_fit, y_eval= train_test_split(X_train_valid, y_train_valid, test_size=0.3)\n\nprint('# train: %5d (0s: %5d, 1s: %4d)'%(len(y_fit), sum(y_fit==0), sum(y_fit==1)))\nprint('# valid: %5d (0s: %5d, 1s: %4d)'%(len(y_eval), sum(y_eval==0), sum(y_eval==1)))\nprint('# test:  %5d (0s: %5d, 1s: %4d)'%((len(y_local_test), sum(y_local_test==0), sum(y_local_test==1))))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# classifier\nclf = xgb.XGBClassifier(missing=np.nan, max_depth=5,\n                        n_estimators=1000, learning_rate=0.01,\n                        subsample=0.5, colsample_bytree=0.9, seed=4242)\n\n# fitting\nclf.fit(X_fit, y_fit, early_stopping_rounds=50, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n\n\nauc_train = roc_auc_score(y_fit, clf.predict_proba(X_fit)[:,1])\nauc_valid = roc_auc_score(y_eval, clf.predict_proba(X_eval)[:,1])\nauc_test  = roc_auc_score(y_local_test, clf.predict_proba(X_local_test)[:,1])\n\nprint('\\n----------------------------')\nprint('  AUC train: %.5f'%auc_train)\nprint('  AUC valid: %.5f'%auc_valid)\nprint('  AUC test : %.5f'%auc_test)\nprint('----------------------------')\n\nprint('\\nModel parameters...')\nprint(clf.get_params())\nprint('\\n----------------------------\\n')\n\n# predicting\ny_pred= clf.predict_proba(X_test)[:,1]\n\nsubmission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint('Completed!')"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}