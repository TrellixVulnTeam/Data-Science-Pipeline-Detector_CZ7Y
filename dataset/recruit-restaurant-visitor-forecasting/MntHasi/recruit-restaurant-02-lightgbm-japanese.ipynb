{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Recruit Restaurant Visitor Forecasting\n\n[前処理のコード](https://www.kaggle.com/mnthasi/210516-recruit-pre-japanese)で前処理したdata_all_motoをロードして学習だけ行う<br>\n処理時間<br>\nモデル学習2分×6\n<br>\n【モデル学習方法】\n* 週ごとにモデルを作成する\n* 2週目のモデルであれば、前週の来店者数の情報は使わないで予測する\n* validationがいい加減にならないように、lag特徴量を適宜落としている\n<br><br>\n\nLoad the preprocessed data_all_moto in [Preprocessing Code] (https://www.kaggle.com/mnthasi/210516-recruit-pre-japanese) and only learn <br>\nProcessing time <br>\nModel learning 2 minutes x 6\n<br> <br>\n[Model learning method] <br>\n* Create a model weekly\n* If it is the second week model, predict without using the information on the number of visitors in the previous week\n* The lag features are reduced as appropriate so that validation is not sloppy.\n\nコードを3つに分割しています<br>\nThe code is divided into three<br>\nhttps://www.kaggle.com/mnthasi/recruit-restaurant-01-pre\nhttps://www.kaggle.com/mnthasi/recruit-restaurant-02-lightgbm-japanese\nhttps://www.kaggle.com/mnthasi/recruit-restaurant-03-ensemble-japanese","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T09:28:56.748812Z","iopub.execute_input":"2021-06-13T09:28:56.749142Z","iopub.status.idle":"2021-06-13T09:28:56.775231Z","shell.execute_reply.started":"2021-06-13T09:28:56.749112Z","shell.execute_reply":"2021-06-13T09:28:56.774182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime as dt","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:28:56.776608Z","iopub.execute_input":"2021-06-13T09:28:56.776871Z","iopub.status.idle":"2021-06-13T09:28:56.78079Z","shell.execute_reply.started":"2021-06-13T09:28:56.776845Z","shell.execute_reply":"2021-06-13T09:28:56.779909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 前処理したデータフレームのインポート\nvisit_dateは日付情報が残っていて欲しいので、読み込みのオプションをつけている","metadata":{}},{"cell_type":"code","source":"data_all_moto = pd.read_csv(\"../input/data-all-11/data_all (11).csv\", parse_dates=['visit_date'])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:28:56.782225Z","iopub.execute_input":"2021-06-13T09:28:56.782642Z","iopub.status.idle":"2021-06-13T09:29:01.248709Z","shell.execute_reply.started":"2021-06-13T09:28:56.782609Z","shell.execute_reply":"2021-06-13T09:29:01.24774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:01.250183Z","iopub.execute_input":"2021-06-13T09:29:01.250531Z","iopub.status.idle":"2021-06-13T09:29:01.348171Z","shell.execute_reply.started":"2021-06-13T09:29:01.250492Z","shell.execute_reply":"2021-06-13T09:29:01.347276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量のdrop","metadata":{}},{"cell_type":"code","source":"data_all_moto = data_all_moto.drop([\"lag70\",\"lag63\"], axis=1)\ndata_all_moto = data_all_moto.drop([\"index\"], axis=1)\ndata_all_moto = data_all_moto.drop([\"lag_mean_7-21\",\"lag_mean_7-28\",\"lag_mean_7-14\"], axis=1)\n# data_all_moto = data_all_moto.loc[(data_all_moto['air_genre_name'] == 13)]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:01.349378Z","iopub.execute_input":"2021-06-13T09:29:01.349679Z","iopub.status.idle":"2021-06-13T09:29:01.553045Z","shell.execute_reply.started":"2021-06-13T09:29:01.34965Z","shell.execute_reply":"2021-06-13T09:29:01.552094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_all_moto.visit_date","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:01.554803Z","iopub.execute_input":"2021-06-13T09:29:01.555095Z","iopub.status.idle":"2021-06-13T09:29:01.562582Z","shell.execute_reply.started":"2021-06-13T09:29:01.555065Z","shell.execute_reply":"2021-06-13T09:29:01.561638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:01.56402Z","iopub.execute_input":"2021-06-13T09:29:01.5643Z","iopub.status.idle":"2021-06-13T09:29:01.586411Z","shell.execute_reply.started":"2021-06-13T09:29:01.564273Z","shell.execute_reply":"2021-06-13T09:29:01.585471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# validationデータの範囲を指定する関数set_vaの定義\n期間の順番に気を付けること","metadata":{}},{"cell_type":"code","source":"def set_va():\n    #とりあえず全部trainにする\n    data_all.loc[(data_all['visit_date'] <= dt.datetime(2017,4,22)), 'set'] = 'train'\n    #validationデータの期間の終わりを指定する\n    data_all.loc[(data_all['visit_date'] <= dt.datetime(2017,4,22)), 'set'] = 'va'\n    data_all.loc[(data_all['visit_date'] <= dt.datetime(2017,4,15)), 'set'] = 'train'\n    print(\"set_va done\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:01.587799Z","iopub.execute_input":"2021-06-13T09:29:01.588186Z","iopub.status.idle":"2021-06-13T09:29:01.598519Z","shell.execute_reply.started":"2021-06-13T09:29:01.588145Z","shell.execute_reply":"2021-06-13T09:29:01.597605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# --------------------ここから①週目-------------------\n4/23-4/29までを予測するためのモデルを作る<br>\n～4/1までのtrainデータを学習させて4/2-4/9までを予測するためのモデルを作り、<br>\n4/23-4/29までを予測する\n\n* ①　4/23-29 lagのdropなし\n* ②　4/30-5/6　lag7をdrop(7日前以降の情報は無い)\n* ③　5/7-5/13　lag7,14をdrop(14日前以降の情報は無い)\n* ④　5/14-5/20　lag7,14,21をdrop(21日前以降の情報は無い)\n* ⑤　5/21-5/27　lag7,14,21,28をdrop(28日前以降の情報は無い)\n* ⑥　5/28-5-31　lag7,14,21,28,35をdrop(35日前以降の情報は無い)","metadata":{}},{"cell_type":"markdown","source":"# 【重要】期間ごとにtrain/va/testに分割\nsubmission用のデータを作る時は、trainの期間を4/22までに変更する\n(そうしないと、直近の学習データが不足し不利になる)","metadata":{}},{"cell_type":"code","source":"#2017/5/31まで全部testにした後、5/28より前はnot-testにする #【YOU NEED TO CHANGE】\ndata_all.loc[(data_all['visit_date'] <= dt.datetime(2017,4,29)), 'set'] = 'test'\ndata_all.loc[(data_all['visit_date'] < dt.datetime(2017,4,23)), 'set'] = 'not-test'\n\n# バリデーションデータの範囲を指定\nset_va()\n\n# visit_dataはdrop\ndata_all = data_all.drop(columns=\"visit_date\")\n\n# trainデータから、visitors(目的変数)と、idを落とす(予測に寄与しない)\ncolumns_drop2 = [\"visitors\",\"id\"]\n\n# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=columns_drop2)\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=columns_drop2)\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n# testデータで評価しない日・店舗の組み合わせがありid=0となってしまう\n# id=0の行を削除する\ntest_fit_x = test_fit_x[test_fit_x['id'] != 0]\n\ntest_id = test_fit_x.id\ntest_fit_x = test_fit_x.drop(columns=\"id\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:01.599642Z","iopub.execute_input":"2021-06-13T09:29:01.599903Z","iopub.status.idle":"2021-06-13T09:29:02.10744Z","shell.execute_reply.started":"2021-06-13T09:29:01.599876Z","shell.execute_reply":"2021-06-13T09:29:02.106296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lightGBMの学習\n全データで学習すると1分くらい","metadata":{}},{"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\n\n# パラメータの設定\nparams = {\n    \"objective\" : \"regression\",\n    \"metric\" : \"rmse\",\n    \"num_leaves\" : 40,\n    \"learning_rate\" : 0.01,\n    \"bagging_fraction\" : 0.8,\n    \"feature_fraction\" : 0.4, #特徴量の〇％だけ利用する\n    \"bagging_frequency\" : 6,\n    \"bagging_seed\" : 42,\n    \"verbosity\" : -1, # 学習途中の経過を表示するかどうか\n    \"seed\": 42\n}\n\ntrain_lgb = lgb.Dataset(train_fit_x, label=train_fit_y)\nva_lgb = lgb.Dataset(va_fit_x, label=va_fit_y)\n\nevals_result = {}\n\nmodel_lgb1 = lgb.train(params, train_set = train_lgb,\n                  num_boost_round = 10000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000, \n                  evals_result=evals_result)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:29:02.108682Z","iopub.execute_input":"2021-06-13T09:29:02.10895Z","iopub.status.idle":"2021-06-13T09:31:03.621976Z","shell.execute_reply.started":"2021-06-13T09:29:02.108924Z","shell.execute_reply":"2021-06-13T09:31:03.620946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# validationデータの予測","metadata":{}},{"cell_type":"code","source":"va_visitors = data_all.loc[(data_all.set == \"va\"),\"visitors\"]\n\npred = model_lgb1.predict(va_fit_x, num_iteration=model_lgb1.best_iteration)\n\ncolumns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# マイナスに予測される値は絶対値を取得する\npred_d[\"pred_visitors\"] = pred_d[\"pred_visitors\"].abs()\n\n# RSMLEスコアの算出\nscore1 = np.sqrt(mean_squared_log_error(va_visitors, pred_d[\"pred_visitors\"]))\nprint(\"---------------RMSLE-score----------------\")\nscore1","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:31:03.623066Z","iopub.execute_input":"2021-06-13T09:31:03.62333Z","iopub.status.idle":"2021-06-13T09:31:04.542001Z","shell.execute_reply.started":"2021-06-13T09:31:03.623304Z","shell.execute_reply":"2021-06-13T09:31:04.540997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 可視化","metadata":{}},{"cell_type":"code","source":"columns = [\"visitors\"]\nva_fit_d = pd.DataFrame(data=va_visitors, columns = columns)\nva_fit_d = va_fit_d.reset_index(drop=True)\n\nsns.scatterplot(x=va_fit_d['visitors'], y=pred_d['pred_visitors'])\nsns.scatterplot(x=va_fit_d['visitors'], y=va_fit_d['visitors']) #perfect fitting line","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:31:04.543527Z","iopub.execute_input":"2021-06-13T09:31:04.544212Z","iopub.status.idle":"2021-06-13T09:31:04.739099Z","shell.execute_reply.started":"2021-06-13T09:31:04.54414Z","shell.execute_reply":"2021-06-13T09:31:04.73818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testデータの予測","metadata":{}},{"cell_type":"code","source":"# モデルで予測する\npred = model_lgb1.predict(test_fit_x)\n\n# 提出用データを作成する\ncolumns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)\n\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_id_df.id\nsubmission[\"visitors\"] = submission_ck.visitors\n\n# csvファイルに書き出す\nsubmission.to_csv(\"submission_week1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:31:04.740815Z","iopub.execute_input":"2021-06-13T09:31:04.741447Z","iopub.status.idle":"2021-06-13T09:31:05.649116Z","shell.execute_reply.started":"2021-06-13T09:31:04.741404Z","shell.execute_reply":"2021-06-13T09:31:05.648393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_allを元に戻す\ndata_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:31:05.652563Z","iopub.execute_input":"2021-06-13T09:31:05.653131Z","iopub.status.idle":"2021-06-13T09:31:05.6599Z","shell.execute_reply.started":"2021-06-13T09:31:05.653087Z","shell.execute_reply":"2021-06-13T09:31:05.659041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ------------------ここから②週目-----------------------\n変更箇所は以下の通りで、　#【YOU NEED TO CHANGE】で注記あり\n* 特徴量のドロップ\n* test_setの期間の変更\n* lgb1モデルの名前を変更\n* submission.csvの名前を変更","metadata":{}},{"cell_type":"code","source":"%%time\n#特徴量をドロップする\ndrops = [\"lag7\"]                                                              #【YOU NEED TO CHANGE】\ndata_all = data_all.drop(columns = drops)\n\n#2017/5/31まで全部testにした後、5/28より前はnot-testにする #【YOU NEED TO CHANGE】\ndata_all.loc[(data_all['visit_date'] <= dt.datetime(2017,5,6)), 'set'] = 'test'\ndata_all.loc[(data_all['visit_date'] < dt.datetime(2017,4,30)), 'set'] = 'not-test'\n\n# バリデーションデータの範囲を指定\nset_va()\n\n# visit_dataはdrop\ndata_all = data_all.drop(columns=\"visit_date\")\n\n# trainデータから、visitors(目的変数)と、idを落とす(予測に寄与しない)\ncolumns_drop2 = [\"visitors\",\"id\"]\n\n# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=columns_drop2)\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=columns_drop2)\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n# testデータで評価しない日・店舗の組み合わせがありid=0となってしまう\n# id=0の行を削除する\ntest_fit_x = test_fit_x[test_fit_x['id'] != 0]\n\ntest_id = test_fit_x.id\ntest_fit_x = test_fit_x.drop(columns=\"id\")\n\n# LightGBMモデルで学習\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\n\n\ntrain_lgb = lgb.Dataset(train_fit_x, label=train_fit_y)\nva_lgb = lgb.Dataset(va_fit_x, label=va_fit_y)\n\nevals_result = {}\n\nmodel_lgb2 = lgb.train(params, train_set = train_lgb,                          #【YOU NEED TO CHANGE】\n                  num_boost_round = 10000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000, \n                  evals_result=evals_result)\n\nva_visitors = data_all.loc[(data_all.set == \"va\"),\"visitors\"]\n\npred = model_lgb2.predict(va_fit_x, num_iteration=model_lgb2.best_iteration)  #【YOU NEED TO CHANGE】*2\n\ncolumns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# マイナスに予測される値は絶対値を取得する\npred_d[\"pred_visitors\"] = pred_d[\"pred_visitors\"].abs()\n\n# RSMLEスコアの算出\nscore2 = np.sqrt(mean_squared_log_error(va_visitors, pred_d[\"pred_visitors\"])) #【YOU NEED TO CHANGE】\nprint(\"---------------RMSLE-score----------------\")\nprint(score2)                                                                #【YOU NEED TO CHANGE】\n\n# モデルで予測する\npred = model_lgb2.predict(test_fit_x)                                   #【YOU NEED TO CHANGE】\n\n# 提出用データを作成する\ncolumns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)\n\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_id_df.id\nsubmission[\"visitors\"] = submission_ck.visitors\n\n# csvファイルに書き出す\nsubmission.to_csv(\"submission_week2.csv\", index=False)                #【YOU NEED TO CHANGE】\n\n# data_allを元に戻す\ndata_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:31:05.661455Z","iopub.execute_input":"2021-06-13T09:31:05.661734Z","iopub.status.idle":"2021-06-13T09:34:29.27291Z","shell.execute_reply.started":"2021-06-13T09:31:05.661707Z","shell.execute_reply":"2021-06-13T09:34:29.271952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ------------------ここから③週目-----------------------","metadata":{}},{"cell_type":"code","source":"data_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:34:29.274047Z","iopub.execute_input":"2021-06-13T09:34:29.274309Z","iopub.status.idle":"2021-06-13T09:34:29.279494Z","shell.execute_reply.started":"2021-06-13T09:34:29.274282Z","shell.execute_reply":"2021-06-13T09:34:29.27859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#特徴量をドロップする\ndrops = [\"lag7\",\"lag14\"]                                                  #【YOU NEED TO CHANGE】\ndata_all = data_all.drop(columns = drops)\n\n#2017/5/31まで全部testにした後、5/28より前はnot-testにする #【YOU NEED TO CHANGE】\ndata_all.loc[(data_all['visit_date'] <= dt.datetime(2017,5,13)), 'set'] = 'test'\ndata_all.loc[(data_all['visit_date'] < dt.datetime(2017,5,7)), 'set'] = 'not-test'\n\n# バリデーションデータの範囲を指定\nset_va()\n\n# visit_dataはdrop\ndata_all = data_all.drop(columns=\"visit_date\")\n\n# trainデータから、visitors(目的変数)と、idを落とす(予測に寄与しない)\ncolumns_drop2 = [\"visitors\",\"id\"]\n\n# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=columns_drop2)\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=columns_drop2)\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n# testデータで評価しない日・店舗の組み合わせがありid=0となってしまう\n# id=0の行を削除する\ntest_fit_x = test_fit_x[test_fit_x['id'] != 0]\n\ntest_id = test_fit_x.id\ntest_fit_x = test_fit_x.drop(columns=\"id\")\n\n# LightGBMモデルで学習\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\n\ntrain_lgb = lgb.Dataset(train_fit_x, label=train_fit_y)\nva_lgb = lgb.Dataset(va_fit_x, label=va_fit_y)\n\nevals_result = {}\n\nmodel_lgb3 = lgb.train(params, train_set = train_lgb,                          #【YOU NEED TO CHANGE】\n                  num_boost_round = 10000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000, \n                  evals_result=evals_result)\n\nva_visitors = data_all.loc[(data_all.set == \"va\"),\"visitors\"]\n\npred = model_lgb3.predict(va_fit_x, num_iteration=model_lgb3.best_iteration)  #【YOU NEED TO CHANGE】*2\n\ncolumns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# マイナスに予測される値は絶対値を取得する\npred_d[\"pred_visitors\"] = pred_d[\"pred_visitors\"].abs()\n\n# RSMLEスコアの算出\nscore3 = np.sqrt(mean_squared_log_error(va_visitors, pred_d[\"pred_visitors\"]))  #【YOU NEED TO CHANGE】\nprint(\"---------------RMSLE-score----------------\")\nprint(score3)                                                                #【YOU NEED TO CHANGE】\nprint()\n\n# モデルで予測する\npred = model_lgb3.predict(test_fit_x)                                   #【YOU NEED TO CHANGE】\n\n# 提出用データを作成する\ncolumns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)\n\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_id_df.id\nsubmission[\"visitors\"] = submission_ck.visitors\n\n# csvファイルに書き出す\nsubmission.to_csv(\"submission_week3.csv\", index=False)                #【YOU NEED TO CHANGE】\n\n# data_allを元に戻す\ndata_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:34:29.280748Z","iopub.execute_input":"2021-06-13T09:34:29.281278Z","iopub.status.idle":"2021-06-13T09:37:36.491857Z","shell.execute_reply.started":"2021-06-13T09:34:29.281237Z","shell.execute_reply":"2021-06-13T09:37:36.490938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ------------------ここから④週目-----------------------","metadata":{}},{"cell_type":"code","source":"data_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:37:36.493147Z","iopub.execute_input":"2021-06-13T09:37:36.493507Z","iopub.status.idle":"2021-06-13T09:37:36.501051Z","shell.execute_reply.started":"2021-06-13T09:37:36.493473Z","shell.execute_reply":"2021-06-13T09:37:36.500164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#特徴量をドロップする\ndrops = [\"lag7\",\"lag14\",\"lag21\"]                                 #【YOU NEED TO CHANGE】\ndata_all = data_all.drop(columns = drops)\n\n#2017/5/31まで全部testにした後、5/28より前はnot-testにする #【YOU NEED TO CHANGE】\ndata_all.loc[(data_all['visit_date'] <= dt.datetime(2017,5,20)), 'set'] = 'test'\ndata_all.loc[(data_all['visit_date'] < dt.datetime(2017,5,14)), 'set'] = 'not-test'\n\n# バリデーションデータの範囲を指定\nset_va()\n\n# visit_dataはdrop\ndata_all = data_all.drop(columns=\"visit_date\")\n\n# trainデータから、visitors(目的変数)と、idを落とす(予測に寄与しない)\ncolumns_drop2 = [\"visitors\",\"id\"]\n\n# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=columns_drop2)\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=columns_drop2)\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n# testデータで評価しない日・店舗の組み合わせがありid=0となってしまう\n# id=0の行を削除する\ntest_fit_x = test_fit_x[test_fit_x['id'] != 0]\n\ntest_id = test_fit_x.id\ntest_fit_x = test_fit_x.drop(columns=\"id\")\n\n# LightGBMモデルで学習\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\n\ntrain_lgb = lgb.Dataset(train_fit_x, label=train_fit_y)\nva_lgb = lgb.Dataset(va_fit_x, label=va_fit_y)\n\nevals_result = {}\n\nmodel_lgb4 = lgb.train(params, train_set = train_lgb,                          #【YOU NEED TO CHANGE】\n                  num_boost_round = 100000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000, \n                  evals_result=evals_result)\n\nva_visitors = data_all.loc[(data_all.set == \"va\"),\"visitors\"]\n\npred = model_lgb4.predict(va_fit_x, num_iteration=model_lgb4.best_iteration) #【YOU NEED TO CHANGE】*2\n\ncolumns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# マイナスに予測される値は絶対値を取得する\npred_d[\"pred_visitors\"] = pred_d[\"pred_visitors\"].abs()\n\n# RSMLEスコアの算出\nscore4 = np.sqrt(mean_squared_log_error(va_visitors, pred_d[\"pred_visitors\"]))  #【YOU NEED TO CHANGE】\nprint(\"---------------RMSLE-score----------------\")\nprint(score4)                                                                #【YOU NEED TO CHANGE】\n\n# モデルで予測する\npred = model_lgb4.predict(test_fit_x)                                   #【YOU NEED TO CHANGE】\n\n# 提出用データを作成する\ncolumns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)\n\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_id_df.id\nsubmission[\"visitors\"] = submission_ck.visitors\n\n# csvファイルに書き出す\nsubmission.to_csv(\"submission_week4.csv\", index=False)                #【YOU NEED TO CHANGE】\n\n# data_allを元に戻す\ndata_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:37:36.502481Z","iopub.execute_input":"2021-06-13T09:37:36.502873Z","iopub.status.idle":"2021-06-13T09:40:45.635308Z","shell.execute_reply.started":"2021-06-13T09:37:36.502834Z","shell.execute_reply":"2021-06-13T09:40:45.634278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ------------------ここから⑤週目-----------------------","metadata":{}},{"cell_type":"code","source":"%%time\n#特徴量をドロップする\ndrops = [\"lag7\",\"lag14\",\"lag21\",\"lag28\"]                #【YOU NEED TO CHANGE】\ndata_all = data_all.drop(columns = drops)\n\n#2017/5/31まで全部testにした後、5/28より前はnot-testにする #【YOU NEED TO CHANGE】\ndata_all.loc[(data_all['visit_date'] <= dt.datetime(2017,5,27)), 'set'] = 'test'\ndata_all.loc[(data_all['visit_date'] < dt.datetime(2017,5,21)), 'set'] = 'not-test'\n\n# バリデーションデータの範囲を指定\nset_va()\n\n# visit_dataはdrop\ndata_all = data_all.drop(columns=\"visit_date\")\n\n# trainデータから、visitors(目的変数)と、idを落とす(予測に寄与しない)\ncolumns_drop2 = [\"visitors\",\"id\"]\n\n# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=columns_drop2)\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=columns_drop2)\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n# testデータで評価しない日・店舗の組み合わせがありid=0となってしまう\n# id=0の行を削除する\ntest_fit_x = test_fit_x[test_fit_x['id'] != 0]\n\ntest_id = test_fit_x.id\ntest_fit_x = test_fit_x.drop(columns=\"id\")\n\n# LightGBMモデルで学習\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\n\ntrain_lgb = lgb.Dataset(train_fit_x, label=train_fit_y)\nva_lgb = lgb.Dataset(va_fit_x, label=va_fit_y)\n\nevals_result = {}\n\nmodel_lgb5 = lgb.train(params, train_set = train_lgb,                          #【YOU NEED TO CHANGE】\n                  num_boost_round = 100000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000, \n                  evals_result=evals_result)\n\nva_visitors = data_all.loc[(data_all.set == \"va\"),\"visitors\"]\n\npred = model_lgb5.predict(va_fit_x, num_iteration=model_lgb5.best_iteration) #【YOU NEED TO CHANGE】*2\n\ncolumns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# マイナスに予測される値は絶対値を取得する\npred_d[\"pred_visitors\"] = pred_d[\"pred_visitors\"].abs()\n\n# RSMLEスコアの算出\nscore5 = np.sqrt(mean_squared_log_error(va_visitors, pred_d[\"pred_visitors\"]))  #【YOU NEED TO CHANGE】\nprint(\"---------------RMSLE-score----------------\")\nprint(score5)                                                                #【YOU NEED TO CHANGE】\n\n# モデルで予測する\npred = model_lgb5.predict(test_fit_x)                                   #【YOU NEED TO CHANGE】\n\n# 提出用データを作成する\ncolumns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)\n\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_id_df.id\nsubmission[\"visitors\"] = submission_ck.visitors\n\n# csvファイルに書き出す\nsubmission.to_csv(\"submission_week5.csv\", index=False)                #【YOU NEED TO CHANGE】\n\n# data_allを元に戻す\ndata_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:40:45.636673Z","iopub.execute_input":"2021-06-13T09:40:45.637191Z","iopub.status.idle":"2021-06-13T09:44:20.126333Z","shell.execute_reply.started":"2021-06-13T09:40:45.63715Z","shell.execute_reply":"2021-06-13T09:44:20.125432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ------------------ここから⑥週目-----------------------","metadata":{}},{"cell_type":"code","source":"%%time\n#特徴量をドロップする\ndrops = [\"lag7\",\"lag14\",\"lag21\",\"lag28\",\"lag35\"]                #【YOU NEED TO CHANGE】\ndata_all = data_all.drop(columns = drops)\n\n#2017/5/31まで全部testにした後、5/28より前はnot-testにする #【YOU NEED TO CHANGE】\ndata_all.loc[(data_all['visit_date'] <= dt.datetime(2017,5,31)), 'set'] = 'test'\ndata_all.loc[(data_all['visit_date'] < dt.datetime(2017,5,28)), 'set'] = 'not-test'\n\n# バリデーションデータの範囲を指定\nset_va()\n\n# visit_dataはdrop\ndata_all = data_all.drop(columns=\"visit_date\")\n\n# trainデータから、visitors(目的変数)と、idを落とす(予測に寄与しない)\ncolumns_drop2 = [\"visitors\",\"id\"]\n\n# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=columns_drop2)\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=columns_drop2)\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n# testデータで評価しない日・店舗の組み合わせがありid=0となってしまう\n# id=0の行を削除する\ntest_fit_x = test_fit_x[test_fit_x['id'] != 0]\n\ntest_id = test_fit_x.id\ntest_fit_x = test_fit_x.drop(columns=\"id\")\n\n# LightGBMモデルで学習\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\n\ntrain_lgb = lgb.Dataset(train_fit_x, label=train_fit_y)\nva_lgb = lgb.Dataset(va_fit_x, label=va_fit_y)\n\nevals_result = {}\n\nmodel_lgb6 = lgb.train(params, train_set = train_lgb,                          #【YOU NEED TO CHANGE】\n                  num_boost_round = 100000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000, \n                  evals_result=evals_result)\n\nva_visitors = data_all.loc[(data_all.set == \"va\"),\"visitors\"]\n\npred = model_lgb6.predict(va_fit_x, num_iteration=model_lgb6.best_iteration) #【YOU NEED TO CHANGE】*2\n\ncolumns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# マイナスに予測される値は絶対値を取得する\npred_d[\"pred_visitors\"] = pred_d[\"pred_visitors\"].abs()\n\n# RSMLEスコアの算出\nscore6 = np.sqrt(mean_squared_log_error(va_visitors, pred_d[\"pred_visitors\"]))  #【YOU NEED TO CHANGE】\nprint(\"---------------RMSLE-score----------------\")\nprint(score6)                                                                #【YOU NEED TO CHANGE】\n\n# モデルで予測する\npred = model_lgb6.predict(test_fit_x)                                   #【YOU NEED TO CHANGE】\n\n# 提出用データを作成する\ncolumns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)\n\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_id_df.id\nsubmission[\"visitors\"] = submission_ck.visitors\n\n# csvファイルに書き出す\nsubmission.to_csv(\"submission_week6.csv\", index=False)                #【YOU NEED TO CHANGE】\n\n# data_allを元に戻す\ndata_all = data_all_moto","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:44:20.127672Z","iopub.execute_input":"2021-06-13T09:44:20.127999Z","iopub.status.idle":"2021-06-13T09:47:22.171679Z","shell.execute_reply.started":"2021-06-13T09:44:20.127969Z","shell.execute_reply":"2021-06-13T09:47:22.170952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.read_csv(\"./submission_week1.csv\")\nsubmission2 = pd.read_csv(\"./submission_week2.csv\")\nsubmission3 = pd.read_csv(\"./submission_week3.csv\")\nsubmission4 = pd.read_csv(\"./submission_week4.csv\")\nsubmission5 = pd.read_csv(\"./submission_week5.csv\")\nsubmission6 = pd.read_csv(\"./submission_week6.csv\")\n\nsubmission_all = pd.concat([submission1, submission2,submission3,submission4,submission5,submission6])\n# submission_all = submission1","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.172772Z","iopub.execute_input":"2021-06-13T09:47:22.173047Z","iopub.status.idle":"2021-06-13T09:47:22.217803Z","shell.execute_reply.started":"2021-06-13T09:47:22.17302Z","shell.execute_reply":"2021-06-13T09:47:22.216892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_all","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.219Z","iopub.execute_input":"2021-06-13T09:47:22.219267Z","iopub.status.idle":"2021-06-13T09:47:22.231936Z","shell.execute_reply.started":"2021-06-13T09:47:22.21924Z","shell.execute_reply":"2021-06-13T09:47:22.230936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_all.sort_values(by='id', ascending=True).head(315)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.23309Z","iopub.execute_input":"2021-06-13T09:47:22.233404Z","iopub.status.idle":"2021-06-13T09:47:22.280315Z","shell.execute_reply.started":"2021-06-13T09:47:22.233374Z","shell.execute_reply":"2021-06-13T09:47:22.279418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zeros = submission_all.loc[submission_all['id'] == \"0\"]\nsubmission_all = submission_all.loc[submission_all[\"id\"] != \"0\"]\nsubmission_all","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.281411Z","iopub.execute_input":"2021-06-13T09:47:22.281682Z","iopub.status.idle":"2021-06-13T09:47:22.300981Z","shell.execute_reply.started":"2021-06-13T09:47:22.281654Z","shell.execute_reply":"2021-06-13T09:47:22.299657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zeros.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.302088Z","iopub.execute_input":"2021-06-13T09:47:22.302471Z","iopub.status.idle":"2021-06-13T09:47:22.317063Z","shell.execute_reply.started":"2021-06-13T09:47:22.302437Z","shell.execute_reply":"2021-06-13T09:47:22.31574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_all.sort_values(by='id', ascending=True).head(315)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.318612Z","iopub.execute_input":"2021-06-13T09:47:22.318896Z","iopub.status.idle":"2021-06-13T09:47:22.364027Z","shell.execute_reply.started":"2021-06-13T09:47:22.318867Z","shell.execute_reply":"2021-06-13T09:47:22.363083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_all.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.365147Z","iopub.execute_input":"2021-06-13T09:47:22.365429Z","iopub.status.idle":"2021-06-13T09:47:22.383744Z","shell.execute_reply.started":"2021-06-13T09:47:22.365402Z","shell.execute_reply":"2021-06-13T09:47:22.382798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_all","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.384805Z","iopub.execute_input":"2021-06-13T09:47:22.385058Z","iopub.status.idle":"2021-06-13T09:47:22.396433Z","shell.execute_reply.started":"2021-06-13T09:47:22.385032Z","shell.execute_reply":"2021-06-13T09:47:22.395489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_test = submission_all.sort_values(by='id', ascending=True)\n# 重複した行を削除\n# submission_test = submission_test[~submission_test.duplicated()]\nsubmission_test = submission_test.drop_duplicates(subset=[\"id\"],keep=\"first\")\nsubmission_test","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.397541Z","iopub.execute_input":"2021-06-13T09:47:22.397921Z","iopub.status.idle":"2021-06-13T09:47:22.457992Z","shell.execute_reply.started":"2021-06-13T09:47:22.39789Z","shell.execute_reply":"2021-06-13T09:47:22.457013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# サブミッション用データを追加","metadata":{}},{"cell_type":"code","source":"submission_test.to_csv(\"F_submission_week_all.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.459009Z","iopub.execute_input":"2021-06-13T09:47:22.459247Z","iopub.status.idle":"2021-06-13T09:47:22.555789Z","shell.execute_reply.started":"2021-06-13T09:47:22.459222Z","shell.execute_reply":"2021-06-13T09:47:22.554816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(score1)\nprint(score2)\nprint(score3)\nprint(score4)\nprint(score5)\nprint(score6)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.556884Z","iopub.execute_input":"2021-06-13T09:47:22.557159Z","iopub.status.idle":"2021-06-13T09:47:22.562622Z","shell.execute_reply.started":"2021-06-13T09:47:22.557131Z","shell.execute_reply":"2021-06-13T09:47:22.56164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量の寄与度を算出\n各モデルで、影響のある特徴量を表示する\nmodel_lgb〇の部分を変えると、期間ごとにそれぞれ作成したモデルごとに見れる","metadata":{}},{"cell_type":"code","source":"# 特徴量重要度の算出 (データフレームで取得)\n\n# 特徴量名のリスト(目的変数CRIM以外)\n# 特徴量重要度の算出方法 'gain'(推奨) : トレーニングデータの損失の減少量を評価\ncols = list(train_fit_x.columns)\ncols_df = pd.DataFrame(cols)\n\n# 特徴量重要度の算出 //\nf_importance = np.array(model_lgb6.feature_importance(importance_type='gain'))\n# 正規化(必要ない場合はコメントアウト)\nf_importance = f_importance / np.sum(f_importance)\nf_importance_df = pd.DataFrame(f_importance)\ndf_importance = cols_df.join(f_importance_df,lsuffix='_features', rsuffix='_importance')\n# 降順ソート\ndf_importance = df_importance.sort_values('0_importance', ascending=False)\ndf_importance","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:47:22.56366Z","iopub.execute_input":"2021-06-13T09:47:22.563895Z","iopub.status.idle":"2021-06-13T09:47:22.585899Z","shell.execute_reply.started":"2021-06-13T09:47:22.563871Z","shell.execute_reply":"2021-06-13T09:47:22.584966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}