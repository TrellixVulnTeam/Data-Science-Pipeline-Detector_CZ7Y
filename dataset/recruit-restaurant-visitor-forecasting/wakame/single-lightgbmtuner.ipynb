{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install optuna==0.18.1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import optuna \noptuna.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls ../input/recruit-restaurant-visitor-forecasting/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb_origin\nimport optuna.integration.lightgbm as lgb\nfrom pathlib import Path\n# from sklearn.model_selection import KFold\n# from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom ml_metrics import rmsle\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nlb = preprocessing.LabelBinarizer()\n\ninput_path = Path(\"../input/recruit-restaurant-visitor-forecasting/\")\nair_reserve_path = input_path / \"air_reserve.csv\"\nair_store_info_path = input_path / \"air_store_info.csv\"\nair_visit_data_path = input_path / \"air_visit_data.csv\"\nhpg_reserve_path = input_path / \"hpg_reserve.csv\"\nhpg_store_info_path = input_path / \"hpg_store_info.csv\"\ndate_info_path = input_path / \"date_info.csv\"\nsample_submission_path = input_path / \"sample_submission.csv\"\nstore_id_relation_path = input_path / \"store_id_relation.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ar = pd.read_csv(air_reserve_path)\ndf_as = pd.read_csv(air_store_info_path)\ndf_av = pd.read_csv(air_visit_data_path)\ndf_hr = pd.read_csv(hpg_reserve_path)\ndf_hs = pd.read_csv(hpg_store_info_path)\ndf_di = pd.read_csv(date_info_path)\ndf_ss = pd.read_csv(sample_submission_path)\ndf_si = pd.read_csv(store_id_relation_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(sample_submission_path)\ndf_test['air_store_id'] = df_test['id'].apply(lambda x: '_'.join(x.split('_')[:2]))\ndf_test['visit_date'] = df_test['id'].apply(lambda x: x.split('_')[-1])\nindex_test = df_test['id']\ndel df_test['id'], df_test['visitors']\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# remove outliers\n# =============================================================================\ndef remove_outliers(data):\n    df_0 = data.loc[data.visitors == 0]   \n    q1 = np.percentile(data.visitors, 25, axis=0)\n    q3 = np.percentile(data.visitors, 75, axis=0)\n#    k = 5\n#    k = 2.5\n    k = 2.8\n#    k = 2\n#    k = 1.5\n    iqr = q3 - q1\n    df_temp = data.loc[data.visitors > q1 - k*iqr]\n    df_temp = data.loc[data.visitors < q3 + k*iqr]\n    frames = [df_0, df_temp]\n    result = pd.concat(frames)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_av = remove_outliers(df_av)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# df to dict for mapping and dropping\n# =============================================================================\nprint('mapping and dropping useless information in df_hr ...')\ns_1 = df_si['air_store_id']\ns_2 = df_si['hpg_store_id']\na_h_map = dict(zip(s_2.values, s_1.values))\ndel s_1, s_2\n\ndf_hr['air_store_id'] = df_hr['hpg_store_id'].map(a_h_map)\ndf_hr = df_hr.drop('hpg_store_id', axis=1).dropna()\n\n\nprint('mapping and dropping useless information in df_hr Done!')\nprint(\"-----------------------------------------------------------------------------------------\")\n\nprint('mapping and dropping useless information in df_hr ...')\n\ndf_hs['air_store_id'] = df_hs['hpg_store_id'].map(a_h_map)\ndf_hs = df_hs.drop('hpg_store_id', axis=1).dropna()\nprint('mapping and dropping useless information in df_hs Done!')\ngc.collect()\nprint(\"=========================================================================================\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# handle datetime (no clock info)\n# =============================================================================\nprint('seperating date time features ...')\n\ntime_format = '%Y-%m-%d'\ndef seperate_date(data):     \n    # split date feature in real visit datetime\n    data_time = pd.to_datetime(data.visit_date, format=time_format)\n    data['Year_visit']= data_time.dt.year\n    data['Month_visit'] = data_time.dt.month\n    data['DayOfYear_visit'] = data_time.dt.dayofyear\n    # data['DayOfMonth_visit'] = data_time.dt.day\n#    data['WeekOfYear_visit'] = data_time.dt.week\n    data['DayOfWeek_visit'] = data_time.dt.dayofweek\n#    del data['visit_date']\n    return data\n\nseperate_date(df_av)\nseperate_date(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------------------------------------------------------------------\ntime_format = \"%Y-%m-%d %H:%M:%S\"\ndef seperate_date(data):\n    # split date feature in reservation datetime\n    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n    data['Year_re']= data_time.dt.year\n    data['Month_re'] = data_time.dt.month\n    data['DayOfYear_re'] = data_time.dt.dayofyear\n    # data['DayOfMonth_re'] = data_time.dt.day\n#    data['WeekOfYear_re'] = data_time.dt.week\n    data['DayOfWeek_re'] = data_time.dt.dayofweek\n    data['Hour_re'] = data_time.dt.hour\n#    del data['reserve_datetime']\n    return data\n\nseperate_date(df_ar)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seperate_date(data):\n    # split date feature in reservation datetime\n    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n    data['Year_re_h']= data_time.dt.year\n    data['Month_re_h'] = data_time.dt.month\n    data['DayOfYear_re_h'] = data_time.dt.dayofyear\n    # data['DayOfMonth_re_h'] = data_time.dt.day\n#    data['WeekOfYear_re_h'] = data_time.dt.week\n    data['DayOfWeek_re_h'] = data_time.dt.dayofweek\n    data['Hour_re_h'] = data_time.dt.hour\n#    del data['reserve_datetime']\n    return data\n\nseperate_date(df_hr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_format = \"%Y-%m-%d %H:%M:%S\"\ndef seperate_date(data):\n    # split date feature in reserved visiting datetime\n    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n    data['Year_re_visit']= data_time.dt.year\n    data['Month_re_visit'] = data_time.dt.month\n    data['DayOfYear_re_visit'] = data_time.dt.dayofyear\n    # data['DayOfMonth_re_visit'] = data_time.dt.day\n#    data['WeekOfYear_re_visit'] = data_time.dt.week\n    data['DayOfWeek_re_visit'] = data_time.dt.dayofweek\n    data['Hour_re_visit'] = data_time.dt.hour\n#    del data['visit_datetime']\n    return data\n\nseperate_date(df_ar)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seperate_date(data):\n    # split date feature in reserved visiting datetime\n    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n    data['Year_re_visit_h']= data_time.dt.year\n    data['Month_re_visit_h'] = data_time.dt.month\n    data['DayOfYear_re_visit_h'] = data_time.dt.dayofyear\n    # data['DayOfMonth_re_visit_h'] = data_time.dt.day\n    data['WeekOfYear_re_visit_h'] = data_time.dt.week\n    data['DayOfWeek_re_visit_h'] = data_time.dt.dayofweek\n    data['Hour_re_visit_h'] = data_time.dt.hour\n#    del data['visit_datetime']\n    return data\n\nseperate_date(df_hr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('seperating date time features done! ...')\ngc.collect()\nprint(\"=========================================================================================\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# label encoding\n# =============================================================================\nprint('label encoding ...')\n\nle.fit(df_as['air_genre_name'])\ndf_as['air_genre_name'] = le.fit_transform(df_as['air_genre_name'])\n\nle.fit(df_as['air_area_name'])\ndf_as['air_area_name'] = le.fit_transform(df_as['air_area_name'])\n\nle.fit(df_hs['hpg_genre_name'])\ndf_hs['hpg_genre_name'] = le.fit_transform(df_hs['hpg_genre_name'])\n\nle.fit(df_hs['hpg_area_name'])\ndf_hs['hpg_area_name'] = le.fit_transform(df_hs['hpg_area_name'])\n\n\n\nle.fit(df_as['air_store_id'])\n\n\ndf_ar['air_store_id'] = le.transform(df_ar['air_store_id'])\ndf_as['air_store_id'] = le.transform(df_as['air_store_id'])\ndf_av['air_store_id'] = le.transform(df_av['air_store_id'])\ndf_hr['air_store_id'] = le.transform(df_hr['air_store_id'])\ndf_hs['air_store_id'] = le.transform(df_hs['air_store_id'])\n\ndf_test['air_store_id'] = le.transform(df_test['air_store_id'])\n\n\nprint('label encoding done !')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# Merge dataset\n# =============================================================================\nfeatures_to_drop = [\n        'air_store_id__'\n        ]\n\ndef merge_df(data, data_to_join):\n    # merge dataframes        \n    data = data.join(data_to_join, on='air_store_id', rsuffix='__', how='left')   \n    return data\n\ndef fix_data(data):\n    # drop __ data    \n    for feature in features_to_drop:\n        del data[feature]\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge to df_train\nprint('merging dataframes ...')\ndf_train = merge_df(df_av, df_ar)\ndf_train = merge_df(df_train, df_as)\n\ndf_hr['reserve_visitors_hr'] = df_hr['reserve_visitors'] \ndel df_hr['reserve_visitors'] \n\ndf_hs['latitude_hr'] = df_hs['latitude'] \ndel df_hs['latitude'] \n\ndf_hs['longitude_hr'] = df_hs['longitude'] \ndel df_hs['longitude'] \n\ndf_train = merge_df(df_train, df_hs)\ndf_train = merge_df(df_train, df_hr)\ngc.collect()\nfix_data(df_train)\n\n# Merge to df_test\n\ndf_test = merge_df(df_test, df_ar)\ndf_test = merge_df(df_test, df_as)\n\ndf_test = merge_df(df_test, df_hs)\ndf_test = merge_df(df_test, df_hr)\ngc.collect()\nfix_data(df_test)\n\n\nprint('merging dataframes done!')\ngc.collect()\nprint(\"=========================================================================================\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# add holiday feature (for the visiting day)\n# =============================================================================\ndf_di['visit_date'] = df_di['calendar_date']\ndel df_di['calendar_date'] \n\ndef add_is_holiday(data):\n    # merge dataframes        \n    data = data.merge(df_di, on='visit_date', how='left')\n    del data['day_of_week']\n    return data\n\ndf_train = add_is_holiday(df_train)\ndf_test = add_is_holiday(df_test)\n\n# =============================================================================\n# drop date-time-hour info\n# =============================================================================\ndef drop_datetime_info(data):\n    del data['visit_date'], data['visit_datetime'], data['reserve_datetime'], data['visit_datetime__'], data['reserve_datetime__']\n#    del data['visit_date'], data['visit_datetime'], data['reserve_datetime']\n    return data\ndf_train = drop_datetime_info(df_train)\n\ndef drop_datetime_info(data):\n    del data['visit_date'], data['visit_datetime'], data['reserve_datetime'], data['visit_datetime__'], data['reserve_datetime__']\n#    del data['visit_date'], data['visit_datetime'], data['reserve_datetime']\n    return data\ndf_test = drop_datetime_info(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# autoclean\n# =============================================================================\n#df_train_clean = autoclean(df_train)\n#df_test_clean = autoclean(df_test)\n#\ntrain = df_train.fillna(-1)\ntest = df_test.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# shuffle dataset\n# =============================================================================\nfrom sklearn.utils import shuffle\ntrain =  shuffle(train, random_state=21)\n\n\nX_train, X_valid = train_test_split(train, test_size=0.05, random_state=42, shuffle=False)\n\nX = X_train.drop(['visitors'], axis=1)\ny = np.log1p(X_train['visitors'].values)\nd_train = lgb.Dataset(X, y)\n\nX = X_valid.drop(['visitors'], axis=1)\ny = np.log1p(X_valid['visitors'].values)\nd_valid = lgb.Dataset(X, y)\n\nwatchlist = [d_train, d_valid]\n\nprint('Training LGBM model...')\n# LightGBMTuner\n# Reference: https://gist.github.com/smly/367c53e855cdaeea35736f32876b7416\nbest_params = {}\ntuning_history = []\n\nparams = {\n            'objective': 'regression',\n            'metric': 'rmse',\n        }\n\nlgb.train(\n        params,\n        d_train,\n        num_boost_round=10000,\n        valid_sets=watchlist,\n        early_stopping_rounds=100,\n        verbose_eval=200,\n        best_params=best_params,\n        tuning_history=tuning_history)\n    \npd.DataFrame(tuning_history).to_csv('./tuning_history.csv')\n\nbest_params['learning_rate'] = 0.05\n\nlgb_model1 = lgb_origin.train(\n            best_params,\n            d_train,\n            num_boost_round=50000,\n            valid_names=['train', 'valid'],\n            valid_sets=watchlist,\n            early_stopping_rounds=1000,\n            verbose_eval=1000)\n\ntest_probs = lgb_model1.predict(test)\ntest_probs = np.expm1(test_probs)\n\nresult = pd.DataFrame({\"id\": index_test, \"visitors\": test_probs})\n    \nresult.to_csv('LGB_sub.csv', index=False)\n    \n# gbm.save_model(r\"..\\output\\models\\LGB_\"+str(file_name)+'.model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}