{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"code","execution_count":null,"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom subprocess import check_output","metadata":{"_uuid":"0a3131f5b1e272426033b62d82d40be37bf52e65","_cell_guid":"eb7eb04d-42c7-4971-a6d2-79f482ce0f25"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"data = {\n    'tra': pd.read_csv('../input/air_visit_data.csv'),\n    'as': pd.read_csv('../input/air_store_info.csv'),\n    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n    'ar': pd.read_csv('../input/air_reserve.csv'),\n    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n    'id': pd.read_csv('../input/store_id_relation.csv'),\n    'tes': pd.read_csv('../input/sample_submission.csv'),\n    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n    }\ndata['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\ndata['hr'].drop('hpg_store_id',  axis=1, inplace=True)\ndata['ar'] = data['ar'].append(data['hr'])\ndata['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\ndata['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\ndata['tes'].drop('id', axis=1, inplace=True)\nprint ('Data loaded')","metadata":{"_uuid":"df069fc9a7396acba16d2cbb5c8742ca9941adc5","_cell_guid":"750dab05-4563-4f05-874f-53eda6e9d6b0"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# Create single data set with all relevant base data:\ndata['tra']['visit_datetime'] = pd.to_datetime(data['tra']['visit_date'])\ndata['tra']['visit_date']     = data['tra']['visit_datetime'].dt.date\ndata['ar']['res_visit_datetime'] = pd.to_datetime(data['ar']['visit_datetime'])\ndata['ar']['reserve_datetime']   = pd.to_datetime(data['ar']['reserve_datetime'])\ndata['ar']['visit_date']         = data['ar']['res_visit_datetime'].dt.date\ndata['ar']['reserve_diff'] = data['ar'].apply(lambda r: (r['res_visit_datetime']\n                                                         - r['reserve_datetime']).days, \n                                        axis=1)\ndata['ar'].drop('visit_datetime',  axis=1, inplace=True)\ndata['ar'].drop('reserve_datetime',  axis=1, inplace=True)\ndata['ar'].drop('res_visit_datetime',  axis=1, inplace=True)\navg_reserv = data['ar'].groupby(['air_store_id','visit_date'], \n                                as_index=False).mean().reset_index()\ndata['ar'] = data['ar'].groupby(['air_store_id','visit_date'], \n                                as_index=False).sum().reset_index()\ndata['ar'] = data['ar'].drop(['reserve_diff'],axis=1)\ndata['ar'] = data['ar'].drop(['index'],axis=1)\ndata['ar']['reserve_diff'] = avg_reserv['reserve_diff']                            \n    \ndata['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\ndata['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n\ndata['tes']['visit_datetime'] = pd.to_datetime(data['tes']['visit_date'])\ndata['tes']['visit_date'] = data['tes']['visit_datetime'].dt.date\n\nprep_df = pd.merge(data['tra'], data['ar'],  how='left', on=['air_store_id', 'visit_date'])\nprep_df = pd.merge(prep_df,     data['as'],  how='inner', on='air_store_id')\nprep_df = pd.merge(prep_df,     data['hol'], how='left',  on='visit_date')\n\npredict_data = pd.merge(data['tes'],  data['ar'],   how='left', on=['air_store_id', 'visit_date'])\npredict_data = pd.merge(predict_data, data['as'],   how='inner', on='air_store_id')\npredict_data = pd.merge(predict_data, data['hol'],  how='left', on='visit_date')\n\n#print(len(prep_df[prep_df.air_store_id == \"air_35512c42db0868da\"]))\n#print(len(data['tra'][data['tra'].air_store_id == \"air_35512c42db0868da\"]))","metadata":{"_uuid":"492e59e2738e1c5db6a7fa81371daa1fdcc01753","collapsed":true,"_cell_guid":"13033c0f-d4fc-4e43-8126-efc11a71e0f6"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# Encode fields:\nprep_df['month'] = prep_df['visit_datetime'].dt.month\nprep_df['day']   = prep_df['visit_datetime'].dt.day\nprep_df.drop('visit_datetime',      axis=1, inplace=True)   \npredict_data['month'] = predict_data['visit_datetime'].dt.month\npredict_data['day']   = predict_data['visit_datetime'].dt.day\npredict_data.drop('visit_datetime', axis=1, inplace=True)\n\n# Encode labels of categorical columns:\ncat_features = [col for col in ['air_genre_name', 'air_area_name', 'day_of_week']]\nfor column in cat_features:\n    temp_prep = pd.get_dummies(pd.Series(prep_df[column]))\n    prep_df = pd.concat([prep_df,temp_prep],axis=1)\n    prep_df = prep_df.drop([column],axis=1)\n    temp_predict = pd.get_dummies(pd.Series(predict_data[column]))\n    predict_data = pd.concat([predict_data,temp_predict],axis=1)\n    predict_data = predict_data.drop([column],axis=1)\n    for missing_col in temp_prep:     # Make sure the columns of train and test are identical\n        if missing_col not in predict_data.columns:\n            predict_data[missing_col] = 0\n    \nprep_df['visitors'] = np.log1p(prep_df['visitors'])\nprep_df.fillna(0, inplace=True)\npredict_data.fillna(0, inplace=True)\nprint('Done')","metadata":{"_uuid":"8251d594c4d3a507bdb36c5429bf08648721ad57","_cell_guid":"75456b4f-afe0-41d3-9576-088871eb2b80"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"air_ids = [air for air in prep_df['air_store_id'].unique()]\nmult_series = dict()\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nstore_key = prep_df[['air_store_id', 'visit_date']]\nstore_key_predict = predict_data[['air_store_id', 'visit_date']]\nprep_df.drop(['air_store_id', 'visit_date'], axis=1, inplace=True)  \npredict_data.drop(['air_store_id', 'visit_date'], axis=1, inplace=True) \ncols = prep_df.columns\ncols_predict = predict_data.columns\nscaler.fit(prep_df)\nscaled_prep_df      = pd.DataFrame(scaler.transform(prep_df), columns=cols)\nscaled_predict_data = pd.DataFrame(scaler.transform(predict_data), columns=cols_predict)\nscaled_prep_df['air_store_id'] = store_key['air_store_id']\nscaled_prep_df['visit_date']   = store_key['visit_date']\nscaled_predict_data['air_store_id'] = store_key_predict['air_store_id']\nscaled_predict_data['visit_date']   = store_key_predict['visit_date']\nscaled_predict_data['visitors'] = 0\n\nfor air_id in air_ids:\n    tmp = pd.DataFrame(scaled_prep_df[scaled_prep_df['air_store_id'] == air_id]).sort_values('visit_date')\n    tmp.drop('air_store_id', axis=1, inplace=True)  \n    tmp.set_index('visit_date', inplace=True)\n    mult_series[str(air_id)] = tmp.astype('float32')\n\nmult_series['air_ee3a01f0c71a769f'].head(10)  # Print data for sample restaurant\n#list(mult_series.keys())\n# Target:  y = prep_df['visitors'].values","metadata":{"_uuid":"0110301907bfea1240e6093d489c348f1535ecd2","_cell_guid":"a59a6680-18a5-4109-a008-14cb976595d4"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# From https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    \"\"\"\n    Frame a time series as a supervised learning dataset.\n    Arguments:\n        data: Sequence of observations as a list or NumPy array.\n        n_in: Number of lag observations as input (X).\n        n_out: Number of observations as output (y).\n        dropnan: Boolean whether or not to drop rows with NaN values.\n    Returns:\n        Pandas DataFrame of series framed for supervised learning.\n    \"\"\"\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # Input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # Forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # Put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # Drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg\n\n# Submissions are evaluated using RMSLE:\ndef RMSLE(y, pred):\n    return mean_squared_error(y, pred)**0.5","metadata":{"_uuid":"fcae5885004264bbc541d2891195f9d300e76e4b","collapsed":true,"_cell_guid":"185c0363-bfca-471a-94fe-e44bed734c63"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# Convert data series for supervised learning:\ntmp = pd.DataFrame(series_to_supervised(mult_series['air_ee3a01f0c71a769f'], 1, 1))\ntmp.drop(tmp.columns[[i for i in range(133,264)]], axis=1, inplace=True)\nsuper_data = tmp\nfor air_id in air_ids:\n    tmp = series_to_supervised(mult_series[str(air_id)], 1, 1)\n    # Drop columns that should not be predicted (column #103 is number of visitors:\n    tmp.drop(tmp.columns[[i for i in range(133,264)]], axis=1, inplace=True)\n    super_data = super_data.append(tmp)\nsuper_data.head(10)","metadata":{"_uuid":"a0e51933fad965a99850bbe126270d5e854b227d","_cell_guid":"7f154d13-2ed9-4f9a-91d9-be8f9eddba79"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# Prepare LSTM training, split up records into training and test data:\ntrain_size = int(len(super_data) * 0.7)\ntest_size = len(super_data) - train_size\n\ntrain = super_data[:train_size].values\ntest  = super_data[train_size:].values\n\n# Split into input and outputs\ntrain_X, train_y = train[:,:-1], train[:,-1]\ntest_X, test_y = test[:, :-1], test[:, -1]\n\n# LSTM requires 3D data sets: [samples, timesteps, features]\ntrain_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\ntest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","metadata":{"_uuid":"cddfbecbd3f530e0226d4c107543dd85b27c2fd0","_cell_guid":"cd3af536-c427-4af2-ba3c-9b4d3cc2ef85"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# Train model:\nmulti_model = Sequential()\nbtc_size = 50\n#multi_model.add(LSTM(4, input_shape=(train_X.shape[1], train_X.shape[2])))\nmulti_model.add(LSTM(4, batch_input_shape=(btc_size, train_X.shape[1], train_X.shape[2]), \n                     stateful=True))\nmulti_model.add(Dense(1))\nmulti_model.compile(loss='mse', optimizer='adam')\nfor i in range(int(train_X.shape[0] / btc_size)):\n    this_X = train_X[(i * btc_size):((i + 1) * btc_size)][:][:]\n    this_y = train_y[(i * btc_size):((i + 1) * btc_size)]\n    multi_history = multi_model.fit(this_X, this_y, epochs=10, \n                                batch_size=btc_size, \n                                verbose=0, shuffle=False)\n    multi_model.reset_states()\n  ","metadata":{"_uuid":"65dbec7eb6305636a7abf1ccfb74ed9570ade2cd","collapsed":true,"_cell_guid":"8bd9ed1a-225b-45aa-9650-c1447fad54ae"},"outputs":[]},{"cell_type":"code","execution_count":null,"source":"# Make predictions:\ny_pred = [test_X.shape[0]]\nfor i in range(int(test_X.shape[0] / btc_size)):\n    this_X = test_X[(i * btc_size):((i + 1) * btc_size)][:][:]\n    this_pred = multi_model.predict(this_X, batch_size=btc_size)    \n    y_pred[(i * btc_size):((i + 1) * btc_size)] = this_pred\n\ntest_X_nn = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n# Invert scaling for forecast\ninv_y_pred = np.concatenate((y_pred, test_X_nn[:, 1:]), axis=1)\ninv_y_pred = scaler.inverse_transform(inv_y_pred)\ninv_y_pred = inv_y_pred[:,0]\n# Invert scaling for actual\ntest_y_nn = test_y.reshape((len(test_y), 1))\ninv_y = np.concatenate((test_y_nn, test_X_nn[:, 1:]), axis=1)\ninv_y = scaler.inverse_transform(inv_y)\ninv_y = inv_y[:,0]\n\nprint(inv_y_pred[:10])\nprint(inv_y[:10])\nrmsle = RMSLE(inv_y, inv_y_pred)\nprint('Test RMSLE: %.3f' % rmsle)","metadata":{"_uuid":"22b05d3d0b0a0c2279750562dc74f540df33451b","_cell_guid":"5bab96fe-ab28-4f66-9016-6bd402f4dc3d"},"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","file_extension":".py","version":"3.6.3","pygments_lexer":"ipython3"}}}