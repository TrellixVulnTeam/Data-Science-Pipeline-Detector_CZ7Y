{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.4","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3"}},"cells":[{"outputs":[],"cell_type":"code","execution_count":null,"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import shuffle\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\n\nfrom subprocess import check_output\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn import preprocessing","metadata":{"_cell_guid":"eb7eb04d-42c7-4971-a6d2-79f482ce0f25","_uuid":"0a3131f5b1e272426033b62d82d40be37bf52e65","collapsed":true}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"data = {\n    'tra': pd.read_csv('../input/air_visit_data.csv'),\n    'as': pd.read_csv('../input/air_store_info.csv'),\n    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n    'ar': pd.read_csv('../input/air_reserve.csv'),\n    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n    'id': pd.read_csv('../input/store_id_relation.csv'),\n    'tes': pd.read_csv('../input/sample_submission.csv'),\n    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n    }\ndata['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\ndata['hr'].drop('hpg_store_id',  axis=1, inplace=True)\ndata['ar'] = data['ar'].append(data['hr'])\ndata['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\ndata['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\ntest_id = data['tes']['id']\ndata['tes'].drop('id', axis=1, inplace=True)\nprint ('Data loaded - number visits: ' + str(data['tra'].shape[0]))","metadata":{"_cell_guid":"750dab05-4563-4f05-874f-53eda6e9d6b0","_uuid":"df069fc9a7396acba16d2cbb5c8742ca9941adc5"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"# Create single data set with all relevant base data:\ndata['tra']['visit_datetime'] = pd.to_datetime(data['tra']['visit_date'])\ndata['tra']['dow']     = data['tra']['visit_datetime'].dt.dayofweek\ndata['ar']['res_visit_datetime'] = pd.to_datetime(data['ar']['visit_datetime'])\ndata['ar']['reserve_datetime']   = pd.to_datetime(data['ar']['reserve_datetime'])\ndata['ar']['visit_date']         = data['ar']['res_visit_datetime'].dt.date\ndata['ar']['reserve_diff'] = data['ar'].apply(lambda r: (r['res_visit_datetime']\n                                                         - r['reserve_datetime']).days, \n                                        axis=1)\ndata['ar'].drop('visit_datetime',  axis=1, inplace=True)\ndata['ar'].drop('reserve_datetime',  axis=1, inplace=True)\ndata['ar'].drop('res_visit_datetime',  axis=1, inplace=True)\navg_reserv = data['ar'].groupby(['air_store_id','visit_date'], \n                                as_index=False).mean().reset_index()\ndata['ar'] = data['ar'].groupby(['air_store_id','visit_date'], \n                                as_index=False).sum().reset_index()\ndata['ar'] = data['ar'].drop(['reserve_diff'],axis=1)\ndata['ar'] = data['ar'].drop(['index'],axis=1)\ndata['ar']['reserve_diff'] = avg_reserv['reserve_diff']  \ndata['ar']['visit_date'] = data['ar']['visit_date'].astype(str)    \n\ndata['tes']['visit_datetime'] = pd.to_datetime(data['tes']['visit_date'])\ndata['tes']['dow']     = data['tes']['visit_datetime'].dt.dayofweek\n\nprep_df = pd.merge(data['tra'], data['ar'],  how='left', on=['air_store_id', 'visit_date'])\nprep_df = pd.merge(prep_df,     data['as'],  how='inner', on='air_store_id')\nprep_df = pd.merge(prep_df,     data['hol'], how='left',  on='visit_date')\nprint ('Data merged - number visits in train: ' + str(prep_df.shape[0]))\npredict_data = pd.merge(data['tes'],  data['ar'],   how='left', on=['air_store_id', 'visit_date'])\npredict_data = pd.merge(predict_data, data['as'],   how='inner', on='air_store_id')\npredict_data = pd.merge(predict_data, data['hol'],  how='left', on='visit_date')\nprint ('Data merged - number visits in test: ' + str(predict_data.shape[0]))","metadata":{"_cell_guid":"13033c0f-d4fc-4e43-8126-efc11a71e0f6","_uuid":"492e59e2738e1c5db6a7fa81371daa1fdcc01753"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].min().rename(\n    columns={'visitors': 'min_visitors'})\nprep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\npredict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].mean().rename(\n    columns={'visitors': 'mean_visitors'})\nprep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\npredict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].median().rename(\n    columns={'visitors': 'median_visitors'})\nprep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\npredict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].max().rename(\n    columns={'visitors': 'max_visitors'})\nprep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\npredict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].count().rename(\n    columns={'visitors': 'count_observations'})\nprep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\npredict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n\nprep_df.drop('dow',  axis=1, inplace=True)\npredict_data.drop('dow',  axis=1, inplace=True)\nprint(predict_data.shape)\nprint(prep_df.shape)","metadata":{"_cell_guid":"74bf4d7d-8b9d-4d40-af81-0458339cbf8b","_uuid":"e4e009dc9b75ab7d9ab20f158319e418005b0f44"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"# Encode fields:\nprep_df['month'] = prep_df['visit_datetime'].dt.month\nprep_df['day']   = prep_df['visit_datetime'].dt.day\nprep_df.drop('visit_datetime',      axis=1, inplace=True)   \npredict_data['month'] = predict_data['visit_datetime'].dt.month\npredict_data['day']   = predict_data['visit_datetime'].dt.day\npredict_data.drop('visit_datetime', axis=1, inplace=True)\nprep_df.fillna(-1, inplace=True)\npredict_data.fillna(-1, inplace=True)\n\n# Encode labels of categorical columns:\ncat_features = [col for col in ['air_genre_name', 'air_area_name', 'day_of_week']]\nfor column in cat_features:\n    temp_prep = pd.get_dummies(pd.Series(prep_df[column]))\n    prep_df = pd.concat([prep_df,temp_prep],axis=1)\n    prep_df = prep_df.drop([column],axis=1)\n    temp_predict = pd.get_dummies(pd.Series(predict_data[column]))\n    predict_data = pd.concat([predict_data,temp_predict],axis=1)\n    predict_data = predict_data.drop([column],axis=1)\n    for missing_col in temp_prep:     # Make sure the columns of train and test are identical\n        if missing_col not in predict_data.columns:\n            predict_data[missing_col] = 0\n    for missing_col in temp_predict:     # Make sure the columns of train and test are identical\n        if missing_col not in prep_df.columns:\n            prep_df[missing_col] = 0        \n    \nprep_df['visitors'] = np.log1p(prep_df['visitors'])\nprint('Done')","metadata":{"_cell_guid":"75456b4f-afe0-41d3-9576-088871eb2b80","_uuid":"8251d594c4d3a507bdb36c5429bf08648721ad57"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"#prep_df = prep_df[prep_df['visit_date'] >= '2016-06-29']\n#prep_df = prep_df.drop(['reserve_visitors'],axis=1)\n#prep_df = prep_df.drop(['reserve_diff'],axis=1)\n#prep_df = prep_df.drop(['latitude'],axis=1)\n#prep_df = prep_df.drop(['longitude'],axis=1)\n#predict_data = predict_data.drop(['reserve_visitors'],axis=1)\n#predict_data = predict_data.drop(['reserve_diff'],axis=1)\n#predict_data = predict_data.drop(['latitude'],axis=1)\n#predict_data = predict_data.drop(['longitude'],axis=1)                        \n#prep_df.head()","metadata":{"_cell_guid":"bf7fcff5-a20e-4ffc-8f68-93f7bfdd2c47","_uuid":"cdf9509f4cad4b1b759d77376d7e9e78b60a6275","collapsed":true}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"prep_df.drop(['visit_date'], axis=1, inplace=True)\nlabel_enc = preprocessing.LabelEncoder()\nlabel_enc.fit(prep_df['air_store_id'])\nprep_df['air_store_id'] = label_enc.transform(prep_df['air_store_id'])\nprep_cols = prep_df.columns\n\npredict_data.drop(['visit_date'], axis=1, inplace=True)  \npredict_data['air_store_id'] = label_enc.transform(predict_data['air_store_id'])\n \nX_train = prep_df.drop(['visitors'], axis=1)\ny_train = prep_df['visitors'].values    \nX_test = predict_data.drop(['visitors'], axis=1)\n# Submissions are evaluated using RMSLE:\ndef RMSLE(y, pred):\n    return mean_squared_error(y, pred)**0.5","metadata":{"_cell_guid":"a59a6680-18a5-4109-a008-14cb976595d4","_uuid":"0110301907bfea1240e6093d489c348f1535ecd2","collapsed":true}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)","metadata":{"_cell_guid":"d045d27a-1650-4e87-bf68-25b345cb5e2d","_uuid":"42c743c969af57b449ad4b56d88cb6b140eed5e4"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"lgb_params1 = {}\nlgb_params1['application'] = 'regression'\nlgb_params1['boosting'] = 'gbdt'\nlgb_params1['learning_rate'] = 0.015\nlgb_params1['num_leaves'] = 32\nlgb_params1['min_sum_hessian_in_leaf'] = 2e-2\nlgb_params1['min_gain_to_split'] = 0\nlgb_params1['bagging_fraction'] = 0.9\nlgb_params1['feature_fraction'] = 0.9\nlgb_params1['num_threads'] = 8\nlgb_params1['metric'] = 'rmse'\n\nlgb_params2 = {}\nlgb_params2['application'] = 'regression'\nlgb_params2['boosting'] = 'gbdt'\nlgb_params2['learning_rate'] = 0.02\nlgb_params2['lambda_l1'] = 0.2\nlgb_params2['num_leaves'] = 16\nlgb_params2['min_gain_to_split'] = 0\nlgb_params2['bagging_fraction'] = 0.8\nlgb_params2['feature_fraction'] = 0.8\nlgb_params2['num_threads'] = 4\nlgb_params2['metric'] = 'rmse'\n\nlgb_params3 = {}\nlgb_params3['application'] = 'regression'\nlgb_params3['boosting'] = 'gbdt'\nlgb_params3['learning_rate'] = 0.022\nlgb_params3['num_leaves'] = 32\nlgb_params2['lambda_l2'] = 0.3\nlgb_params3['bagging_freq'] = 8\nlgb_params3['min_gain_to_split'] = 0\nlgb_params3['bagging_fraction'] = 0.8\nlgb_params3['feature_fraction'] = 0.8\nlgb_params3['num_threads'] = 4\nlgb_params3['metric'] = 'rmse'\n\ndef do_train(X_train, X_valid, lgb_params):\n    X_t = X_train.drop(['visitors'], axis=1)\n    y_t = X_train['visitors'].values\n    d_train = lgb.Dataset(X_t, y_t)\n    X_v = X_valid.drop(['visitors'], axis=1)\n    y_v = X_valid['visitors'].values\n    d_valid = lgb.Dataset(X_v, y_v)\n    watchlist = [d_train, d_valid]\n    lgb_model = lgb.train(lgb_params, train_set=d_train, num_boost_round=15000, \n                          valid_sets=watchlist, verbose_eval=100)\n    test_pred = lgb_model.predict(X_v)\n    rmsle = RMSLE(y_v, test_pred)\n    return rmsle, lgb_model\n\nX_train, X_valid = train_test_split(prep_df, test_size=0.2, random_state=74, shuffle=True)\nrmsle, lgb_model1 = do_train(X_train, X_valid, lgb_params1)\ntest_pred1 = np.expm1(lgb_model1.predict(X_test))\nprint('Test RMSLE: %.3f' % rmsle)\n    \nX_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=2121, shuffle=True)\nrmsle, lgb_model2 = do_train(X_train, X_valid, lgb_params2)\ntest_pred2 = np.expm1(lgb_model2.predict(X_test))\nprint('Test RMSLE: %.3f' % rmsle)   \n\nX_train, X_valid = train_test_split(prep_df, test_size=0.2, random_state=4, shuffle=True)\nrmsle, lgb_model3 = do_train(X_train, X_valid, lgb_params3)\ntest_pred3 = np.expm1(lgb_model3.predict(X_test))\nprint('Test RMSLE: %.3f' % rmsle)   \n\nX_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=19, shuffle=True)\nrmsle, lgb_model4 = do_train(X_train, X_valid, lgb_params1)\ntest_pred4 = np.expm1(lgb_model4.predict(X_test))\nprint('Test RMSLE: %.3f' % rmsle)  \n\ntest_pred = (test_pred1 + test_pred2 + test_pred3 + test_pred4) / 4\nresult = pd.DataFrame({\"id\": test_id, \"visitors\": test_pred})   \nresult.to_csv('LGB_sub.csv', index=False)\nprint('Done')","metadata":{"_cell_guid":"4bae1e9b-63e1-4533-b12f-473b53598d99","_uuid":"e1da1944b9aa89094124bd24ac0a3403891f1b2f"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"#prep_df = shuffle(prep_df, random_state=74)\n#X_train, X_valid = train_test_split(prep_df, test_size=0.2, random_state=74, shuffle=False)\n#\n#X_t = X_train.drop(['visitors'], axis=1)\n#y_t = X_train['visitors'].values\n#d_train = lgb.Dataset(X_t, y_t)\n#\n#X_v = X_valid.drop(['visitors'], axis=1)\n#y_v = X_valid['visitors'].values\n#d_valid = lgb.Dataset(X_v, y_v)\n#watchlist = [d_train, d_valid]\n#\n#params = {}\n#params['application'] = 'regression'\n#params['boosting'] = 'gbdt'\n#params['learning_rate'] = 0.015\n#params['num_leaves'] = 32\n#params['min_sum_hessian_in_leaf'] = 2e-2\n#params['min_gain_to_split'] = 0\n#params['bagging_fraction'] = 0.9\n#params['feature_fraction'] = 0.9\n#params['num_threads'] = 8\n#params['metric'] = 'rmse'\n#\n#lgb_model = lgb.train(params, train_set=d_train, num_boost_round=50000, \n#                       valid_sets=watchlist, verbose_eval=100)\n#\n#test_pred = lgb_model.predict(X_v)\n#rmsle = RMSLE(y_v, test_pred)\n#print('Test RMSLE: %.3f' % rmsle)","metadata":{"_cell_guid":"cd3af536-c427-4af2-ba3c-9b4d3cc2ef85","_uuid":"cddfbecbd3f530e0226d4c107543dd85b27c2fd0","collapsed":true}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"#predict_data.drop(['visitors'], axis=1, inplace=True)\n#test_pred = np.expm1(lgb_model.predict(predict_data))\n#result = pd.DataFrame({\"id\": test_id, \"visitors\": test_pred})\n#    \n#result.to_csv('LGB_sub.csv', index=False)\n#print('Done')","metadata":{"_cell_guid":"a43137ed-a9d5-449a-8460-7c31014e8354","_uuid":"4f1b01e0431437a2691137212a45b86232da5d01","collapsed":true}}],"nbformat":4,"nbformat_minor":1}