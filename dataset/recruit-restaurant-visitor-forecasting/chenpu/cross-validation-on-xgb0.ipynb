{"nbformat_minor":1,"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"cell_type":"code","metadata":{"_uuid":"92c0fc8c4608dd4dbcf97e33fd5c356700ee60ef","_cell_guid":"1ea46683-90fb-4ccf-8375-c95c4cf4eeb7"},"execution_count":1},{"source":"\"\"\"\nRef: https://www.kaggle.com/the1owl/surprise-me\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n\n# Data wrangling brought to you by the1owl\n# https://www.kaggle.com/the1owl/surprise-me\n\ndata = {\n    'tra':\n    pd.read_csv('../input/air_visit_data.csv'),\n    'as':\n    pd.read_csv('../input/air_store_info.csv'),\n    'hs':\n    pd.read_csv('../input/hpg_store_info.csv'),\n    'ar':\n    pd.read_csv('../input/air_reserve.csv'),\n    'hr':\n    pd.read_csv('../input/hpg_reserve.csv'),\n    'id':\n    pd.read_csv('../input/store_id_relation.csv'),\n    'tes':\n    pd.read_csv('../input/sample_submission.csv'),\n    'hol':\n    pd.read_csv('../input/date_info.csv').rename(columns={\n        'calendar_date': 'visit_date'\n    })\n}\n\ndata['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n\nfor df in ['ar', 'hr']:\n    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n    data[df]['reserve_datetime_diff'] = data[df].apply(\n        lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n    data[df] = data[df].groupby(\n        ['air_store_id', 'visit_datetime'], as_index=False)[[\n            'reserve_datetime_diff', 'reserve_visitors'\n        ]].sum().rename(columns={\n            'visit_datetime': 'visit_date'\n        })\n    print(data[df].head())\n\ndata['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\ndata['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\ndata['tra']['year'] = data['tra']['visit_date'].dt.year\ndata['tra']['month'] = data['tra']['visit_date'].dt.month\ndata['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n\ndata['tes']['visit_date'] = data['tes']['id'].map(\n    lambda x: str(x).split('_')[2])\ndata['tes']['air_store_id'] = data['tes']['id'].map(\n    lambda x: '_'.join(x.split('_')[:2]))\ndata['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\ndata['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\ndata['tes']['year'] = data['tes']['visit_date'].dt.year\ndata['tes']['month'] = data['tes']['visit_date'].dt.month\ndata['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n\nunique_stores = data['tes']['air_store_id'].unique()\nstores = pd.concat(\n    [\n        pd.DataFrame({\n            'air_store_id': unique_stores,\n            'dow': [i] * len(unique_stores)\n        }) for i in range(7)\n    ],\n    axis=0,\n    ignore_index=True).reset_index(drop=True)\n\n#sure it can be compressed...\ntmp = data['tra'].groupby(\n    ['air_store_id', 'dow'],\n    as_index=False)['visitors'].min().rename(columns={\n        'visitors': 'min_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(\n    ['air_store_id', 'dow'],\n    as_index=False)['visitors'].mean().rename(columns={\n        'visitors': 'mean_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(\n    ['air_store_id', 'dow'],\n    as_index=False)['visitors'].median().rename(columns={\n        'visitors': 'median_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(\n    ['air_store_id', 'dow'],\n    as_index=False)['visitors'].max().rename(columns={\n        'visitors': 'max_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\ntmp = data['tra'].groupby(\n    ['air_store_id', 'dow'],\n    as_index=False)['visitors'].count().rename(columns={\n        'visitors': 'count_observations'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n\nstores = pd.merge(stores, data['as'], how='left', on=['air_store_id'])\nlbl = preprocessing.LabelEncoder()\nstores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\nstores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n\ndata['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\ndata['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\ndata['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n\ntrain = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date'])\ntest = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date'])\n\ntrain = pd.merge(data['tra'], stores, how='left', on=['air_store_id', 'dow'])\ntest = pd.merge(data['tes'], stores, how='left', on=['air_store_id', 'dow'])\n\nfor df in ['ar', 'hr']:\n    train = pd.merge(\n        train, data[df], how='left', on=['air_store_id', 'visit_date'])\n    test = pd.merge(\n        test, data[df], how='left', on=['air_store_id', 'visit_date'])\n\ncol = [\n    c for c in train\n    if c not in ['id', 'air_store_id', 'visit_date', 'visitors']\n]\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\n# XGB starter template borrowed from @anokas\n# https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n\nprint('Binding to float32')\n\nfor c, dtype in zip(train.columns, train.dtypes):\n    if dtype == np.float64:\n        train[c] = train[c].astype(np.float32)\n\nfor c, dtype in zip(test.columns, test.dtypes):\n    if dtype == np.float64:\n        test[c] = test[c].astype(np.float32)","outputs":[],"cell_type":"code","metadata":{"_uuid":"9f76f0746af8615cfd5bce97633076cdfbb8d6a3","_cell_guid":"4a8d9fec-78c4-4db7-bbea-5ffa1d077681"},"execution_count":2},{"source":"train_x = train.drop(['air_store_id', 'visit_date', 'visitors'], axis=1)\ntrain_y = np.log1p(train['visitors'].values)\nprint(train_x.shape, train_y.shape)\ntest_x = test.drop(['id', 'air_store_id', 'visit_date', 'visitors'], axis=1)","outputs":[],"cell_type":"code","metadata":{"_uuid":"8020e3bb9d82fb932a408febcd0d0c3114d5f0b6","_cell_guid":"311223da-3ad5-439e-8933-79c6c4887927"},"execution_count":3},{"source":"# parameter tuning of xgboost\n# start from default setting\nboost_params = {'eval_metric': 'rmse'}\nxgb0 = xgb.XGBRegressor(\n    max_depth=8,\n    learning_rate=0.01,\n    n_estimators=10000,\n    objective='reg:linear',\n    gamma=0,\n    min_child_weight=1,\n    subsample=1,\n    colsample_bytree=1,\n    scale_pos_weight=1,\n    seed=27,\n    **boost_params)","outputs":[],"cell_type":"code","metadata":{"_uuid":"fc2f8fd8d641b43cba059f915d867f3c2fead688","collapsed":true,"_cell_guid":"b49f6b02-d389-4635-a736-7daa179ece1f"},"execution_count":4},{"source":"xgb0.fit(train_x, train_y)","outputs":[],"cell_type":"code","metadata":{"_uuid":"1ac68b702d77d8ef324d5a37adc4c0fbcf1e1055","scrolled":true,"_cell_guid":"83c298d9-d53a-4687-804f-c9ff48c2b1f7"},"execution_count":7},{"source":"predict_train_y = xgb0.predict(train_x)","outputs":[],"cell_type":"code","metadata":{"_uuid":"741012d2d33b25a1be211737486ee753cefc8eab","collapsed":true,"_cell_guid":"c1c5faad-b244-4e72-a5fd-ea2ffefd8ef2"},"execution_count":8},{"source":"predict_y = xgb0.predict(test_x)\ntest['visitors'] = np.expm1(predict_y)\ntest[['id', 'visitors']].to_csv(\n    'xgb0_submission.csv', index=False, float_format='%.3f')  # LB0.495","outputs":[],"cell_type":"code","metadata":{"_uuid":"369ae9ed4f87e03b925c6a3210cafa648f0bf786","collapsed":true,"_cell_guid":"a15c6c30-a766-4cbd-b922-234c959639c6"},"execution_count":9},{"source":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn import metrics","outputs":[],"cell_type":"code","metadata":{"_uuid":"94287e20eda3e13afc364395dd5e3b270bdd4b12","collapsed":true,"_cell_guid":"7b0b9158-f006-4c41-8bfa-2b31fa84cde0"},"execution_count":10},{"source":"def RMSLE(y, pred):\n    return metrics.mean_squared_error(y, pred)**0.5\nn_folds=5\ndef rmse_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_x)\n    rmse = np.sqrt(-cross_val_score(model, train_x, train_y, scoring='neg_mean_squared_error', cv=kf))\n    return(rmse)","outputs":[],"cell_type":"code","metadata":{"_uuid":"33a1db4f4c8092fb6d88d801f93c8ad23566cb43","collapsed":true,"_cell_guid":"a3351b3a-0a00-4da2-8057-31486fac57ea"},"execution_count":11},{"source":"RMSLE(train_y,predict_train_y)","outputs":[],"cell_type":"code","metadata":{"_uuid":"a0d5ac414d5d179c14ec357b3ccd7cf137d4f37b","scrolled":true,"_cell_guid":"deae1e72-9d54-4a48-9a53-b3c77971a36f"},"execution_count":12},{"source":"rmse_cv(xgb0)","outputs":[],"cell_type":"code","metadata":{"_uuid":"154538b5ca654ac901ad9811c624f5b96374ea68","scrolled":true,"collapsed":true,"_cell_guid":"aba6064c-58fc-4d8e-93db-6185d897b2d8"},"execution_count":null},{"source":"","outputs":[],"cell_type":"code","metadata":{"_uuid":"a8c60077f47e588fd24a8b025a574565f0b2ce35","collapsed":true,"_cell_guid":"f99fb234-d33d-432a-b1bb-b28e45b7185f"},"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","version":"3.6.4","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat":4}