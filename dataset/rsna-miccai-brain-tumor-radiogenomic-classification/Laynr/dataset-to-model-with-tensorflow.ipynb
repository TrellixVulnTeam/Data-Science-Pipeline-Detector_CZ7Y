{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This kernel uses Tensorflow to define, train, and evaluate a model.\n\nThis is part of a larger solution found at: https://www.kaggle.com/ohbewise/a-rsna-mri-solution-from-dicom-to-submission","metadata":{}},{"cell_type":"code","source":"import pickle\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nscan_types    = ['FLAIR','T1w','T1wCE','T2w']","metadata":{"execution":{"iopub.status.busy":"2021-09-27T23:07:56.169071Z","iopub.execute_input":"2021-09-27T23:07:56.169398Z","iopub.status.idle":"2021-09-27T23:08:00.603925Z","shell.execute_reply.started":"2021-09-27T23:07:56.169314Z","shell.execute_reply":"2021-09-27T23:08:00.603016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define, train, and evaluate model\n# source: https://keras.io/examples/vision/3D_image_classification/\ndef get_model(width=128, height=128, depth=64, name='3dcnn'):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = tf.keras.Input((width, height, depth, 1))\n\n    x = tf.keras.layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n    x = tf.keras.layers.Dense(units=512, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n\n    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = tf.keras.Model(inputs, outputs, name=name)\n    \n    # Compile model.\n    initial_learning_rate = 0.0001\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n    )\n    model.compile(\n        loss=\"binary_crossentropy\",\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        metrics=[\"acc\"],\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-27T23:08:00.605494Z","iopub.execute_input":"2021-09-27T23:08:00.606141Z","iopub.status.idle":"2021-09-27T23:08:00.62371Z","shell.execute_reply.started":"2021-09-27T23:08:00.606099Z","shell.execute_reply":"2021-09-27T23:08:00.622641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for scan_type in scan_types:\n    # load train_dataset dataset\n    tf_data_path = f'../input/nifti-to-split-dataset-with-nibabel/datasets/{scan_type}_train_dataset'\n    with open(tf_data_path + '/element_spec', 'rb') as in_:\n        es = pickle.load(in_)\n    train_dataset = tf.data.experimental.load(tf_data_path, es, compression='GZIP')\n    \n    # load validation_dataset\n    tf_data_path = f'../input/nifti-to-split-dataset-with-nibabel/datasets/{scan_type}_validation_dataset'\n    with open(tf_data_path + '/element_spec', 'rb') as in_:\n        es = pickle.load(in_)\n    validation_dataset = tf.data.experimental.load(tf_data_path, es, compression='GZIP')\n\n    # Get Model\n    model = get_model(width=128, height=128, depth=64,name=scan_type)\n    \n    # Define callbacks.\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n        f'{scan_type}_3d_image_classification.h5', save_best_only=True\n    )\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n\n    epochs = 100\n    model.fit(\n        train_dataset,\n        validation_data=validation_dataset,\n        epochs=epochs,\n        shuffle=True,\n        verbose=2,\n        callbacks=[checkpoint_cb, early_stopping_cb],\n    )\n    \n    #save model\n    model.save(f'./models/{scan_type}')\n    \n    # show metrics\n    fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n    ax = ax.ravel()\n\n    for i, metric in enumerate([\"acc\", \"loss\"]):\n        ax[i].plot(model.history.history[metric])\n        ax[i].plot(model.history.history[\"val_\" + metric])\n        ax[i].set_title(\"{} Model {}\".format(scan_type, metric))\n        ax[i].set_xlabel(\"epochs\")\n        ax[i].set_ylabel(metric)\n        ax[i].legend([\"train\", \"val\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-27T23:08:00.630122Z","iopub.execute_input":"2021-09-27T23:08:00.631367Z","iopub.status.idle":"2021-09-27T23:08:05.118593Z","shell.execute_reply.started":"2021-09-27T23:08:00.631336Z","shell.execute_reply":"2021-09-27T23:08:05.116052Z"},"trusted":true},"execution_count":null,"outputs":[]}]}