{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchio","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":13.691324,"end_time":"2021-08-21T17:40:14.233867","exception":false,"start_time":"2021-08-21T17:40:00.542543","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-04T16:56:10.315119Z","iopub.execute_input":"2021-09-04T16:56:10.315704Z","iopub.status.idle":"2021-09-04T16:56:24.271034Z","shell.execute_reply.started":"2021-09-04T16:56:10.315618Z","shell.execute_reply":"2021-09-04T16:56:24.269823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchio as tio\n\nimport os\nimport torch\ntorch.set_grad_enabled(False)\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader","metadata":{"papermill":{"duration":2.036577,"end_time":"2021-08-21T17:40:16.301205","exception":false,"start_time":"2021-08-21T17:40:14.264628","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-04T16:56:24.272797Z","iopub.execute_input":"2021-09-04T16:56:24.273117Z","iopub.status.idle":"2021-09-04T16:56:26.342296Z","shell.execute_reply.started":"2021-09-04T16:56:24.273086Z","shell.execute_reply":"2021-09-04T16:56:26.341184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set paths\ndata_dir   = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/'\ntrain_dir  = data_dir+'train/'\n\n# get labels and patients\nlabels_df = pd.read_csv(data_dir+'train_labels.csv', index_col=0)\npatients = os.listdir(train_dir)\n\n# Remove cases the competion host said to exclude \n# https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/discussion/262046\npatients.remove('00109')\npatients.remove('00123')\npatients.remove('00709')\n\npatients = patients[:42]\n\nprint(f'Total patients: {len(patients)}\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T16:56:26.343974Z","iopub.execute_input":"2021-09-04T16:56:26.344282Z","iopub.status.idle":"2021-09-04T16:56:26.444749Z","shell.execute_reply.started":"2021-09-04T16:56:26.344253Z","shell.execute_reply":"2021-09-04T16:56:26.444007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of scan types... but just use T1wCE for now\nscan_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n#scan_types = ['T1wCE']\n\n# decare variables\nsubjects_list = []\ncases = {}\ndataset_types ={}\ndataset_cases ={}\n\n# loop thru scan types\nfor scan_type in scan_types:\n    # loop thru patients\n    for patient in patients:\n        # get label for patient \n        label = labels_df._get_value(int(patient), 'MGMT_value')\n        \n        # create subject object for each patient and save to cases dictionary\n        cases[patient] = tio.Subject(\n             image=tio.ScalarImage(f'{train_dir}{patient}/{scan_type}',),\n             label=label,\n         )\n        # add subject object to subjects_list\n        subjects_list.append(cases[patient])\n    \n    # normalize and resize scans\n    transforms = [\n        tio.ToCanonical(),\n        tio.Resample(1),\n        tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n        tio.CropOrPad((128,128,64)),\n    ]\n    transform = tio.Compose(transforms)\n    \n    # create subject datasets\n    subjects_dataset = tio.SubjectsDataset(subjects_list, transform=transform)\n    \n    # add dataset and list to dictionary of types and cases\n    dataset_types[scan_type] = subjects_dataset\n    dataset_cases[scan_type] = subjects_list\n            ","metadata":{"papermill":{"duration":0.082097,"end_time":"2021-08-21T17:40:16.413317","exception":false,"start_time":"2021-08-21T17:40:16.33122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-04T16:56:26.44617Z","iopub.execute_input":"2021-09-04T16:56:26.446441Z","iopub.status.idle":"2021-09-04T16:56:26.457862Z","shell.execute_reply.started":"2021-09-04T16:56:26.446415Z","shell.execute_reply":"2021-09-04T16:56:26.456912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train a model\n# https://torchio.readthedocs.io/data/patch_training.html\n\n# loop thru scan types\nfor scan_type in scan_types:\n    print(f'{scan_type}')\n    \n    # train a model\n    patch_size = (128, 128, 64)\n    queue_length = 300\n    samples_per_volume = 2\n    sampler = tio.data.UniformSampler(patch_size)\n    patches_queue = tio.Queue(\n        dataset_types[scan_type],\n        queue_length,\n        samples_per_volume,\n        sampler,\n        num_workers=4,\n    )\n    patches_loader = DataLoader(patches_queue, batch_size=16)    \n    \n    \n    num_epochs = 2\n    model = torch.nn.Identity()\n    #model = torch.hub.load('fepegar/highresnet', 'highres3dnet', pretrained=True)\n    for epoch_index in range(num_epochs):\n        for patches_batch in patches_loader:\n            inputs = patches_batch['image'][tio.DATA]  # key 'image' is in subject\n            targets = patches_batch['label']#[tio.DATA]  # key 'label' is in subject\n            logits = model(inputs)  # model being an instance of torch.nn.Module\n    \n    #save model: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n    print(model)\n    torch.save(model.state_dict(), f'./{scan_type}_state_dict')\n    torch.save(model, f'./{scan_type}_model')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T16:56:26.460224Z","iopub.execute_input":"2021-09-04T16:56:26.460564Z","iopub.status.idle":"2021-09-04T16:58:18.778366Z","shell.execute_reply.started":"2021-09-04T16:56:26.460527Z","shell.execute_reply":"2021-09-04T16:58:18.777066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the goal here is to train an exisiting model with the new dataset... but I think this is just doing Inference\n# https://torchio.readthedocs.io/data/patch_inference.html\n'''\n# pull a pre trained model\nrepo = 'fepegar/highresnet'\nmodel_name = 'highres3dnet'\nmodel = torch.hub.load(repo, model_name, pretrained=True)\ndevice = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\nprint('Device:', device)\nmodel.to(device).eval();\n\n# loop thru scan types\nfor scan_type in scan_types:\n    print(f'{scan_type}')\n    # to cut down on processing power we use a GridSampler and GridAggregator\n    for preprocessed in dataset_types[scan_type]:\n        patch_overlap = 4\n        patch_size = (128, 128, 64)\n        grid_sampler = tio.inference.GridSampler(\n            preprocessed,\n            patch_size,\n            patch_overlap,\n        )\n        patch_loader = torch.utils.data.DataLoader(grid_sampler)\n        aggregator = tio.inference.GridAggregator(grid_sampler)\n        preprocessed.clear_history()\n\n        for patches_batch in tqdm(patch_loader, unit='batch'):\n            input_tensor = patches_batch['image'][tio.DATA].to(device)\n            locations = patches_batch[tio.LOCATION]\n            with torch.cuda.amp.autocast():\n                logits = model(input_tensor)\n            labels = logits.argmax(dim=tio.CHANNELS_DIMENSION, keepdim=True)\n            aggregator.add_batch(labels, locations)\n        output_tensor = aggregator.get_output_tensor()\n'''","metadata":{"papermill":{"duration":2.750331,"end_time":"2021-08-21T17:40:49.219867","exception":false,"start_time":"2021-08-21T17:40:46.469536","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-04T16:58:18.780428Z","iopub.execute_input":"2021-09-04T16:58:18.780762Z","iopub.status.idle":"2021-09-04T16:58:18.792788Z","shell.execute_reply.started":"2021-09-04T16:58:18.780725Z","shell.execute_reply":"2021-09-04T16:58:18.791755Z"},"trusted":true},"execution_count":null,"outputs":[]}]}