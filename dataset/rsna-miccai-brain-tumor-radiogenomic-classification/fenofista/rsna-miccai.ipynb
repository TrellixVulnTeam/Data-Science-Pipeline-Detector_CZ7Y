{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nimport time\nfrom random import randint\nfrom keras.callbacks import CSVLogger\nimport numpy as np\nfrom scipy import stats\nimport pandas as pd\nfrom keras.utils import np_utils\n\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import KFold\n\nimport nibabel as nib\nimport pydicom as pdm\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport h5py\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport matplotlib.animation as anim\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\n\nimport seaborn as sns\nimport imageio\nfrom skimage.transform import resize\nfrom skimage.util import montage\n\nfrom IPython.display import Image as show_gif\nfrom IPython.display import clear_output\nfrom IPython.display import YouTubeVideo\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.nn import MSELoss\n\n\nimport albumentations as A\nfrom albumentations import Compose, HorizontalFlip\nimport SimpleITK as sitk\nimport sys\nimport os\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport pydicom\nimport matplotlib.pyplot as plt\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport glob\nimport cv2\nimport torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\nimport keras\nimport warnings\nimport os\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnp.seterr(divide='ignore', invalid='ignore')\nfrom keras.layers import Conv3D, MaxPool3D, Flatten, Dense\nfrom keras.layers import Dropout, Input, BatchNormalization\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom plotly.offline import iplot, init_notebook_mode\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adadelta\nimport plotly.graph_objs as go\nfrom matplotlib.pyplot import cm\nfrom keras.models import Model\nimport numpy as np\nimport keras\nimport h5py\nimport SimpleITK as sitk\ninit_notebook_mode(connected=True)\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:14.512623Z","iopub.execute_input":"2021-10-26T03:48:14.512976Z","iopub.status.idle":"2021-10-26T03:48:23.132514Z","shell.execute_reply.started":"2021-10-26T03:48:14.512901Z","shell.execute_reply":"2021-10-26T03:48:23.131597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\nlabels.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:23.134068Z","iopub.execute_input":"2021-10-26T03:48:23.13443Z","iopub.status.idle":"2021-10-26T03:48:23.164735Z","shell.execute_reply.started":"2021-10-26T03:48:23.13439Z","shell.execute_reply":"2021-10-26T03:48:23.164043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_len = 1000;\nlabels[\"imfolder\"] = ['{0:05d}'.format(s) for s in labels[\"BraTS21ID\"]]\npath = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/\"\nlabels['path'] = [os.path.join(path ,f) for f in labels[\"imfolder\"]]\ntrain = labels[:data_len]\nval_len = int(data_len*0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:23.166964Z","iopub.execute_input":"2021-10-26T03:48:23.167814Z","iopub.status.idle":"2021-10-26T03:48:23.178315Z","shell.execute_reply.started":"2021-10-26T03:48:23.167772Z","shell.execute_reply":"2021-10-26T03:48:23.17748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = labels[:0]\npath = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/\"\np = []\nd = []\nfor i in range(1010):\n    id_ = '{0:05d}'.format(i)\n    if(os.path.exists(path+id_)):\n        p.append(path+id_)\n        d.append(id_)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:23.180067Z","iopub.execute_input":"2021-10-26T03:48:23.180659Z","iopub.status.idle":"2021-10-26T03:48:23.629916Z","shell.execute_reply.started":"2021-10-26T03:48:23.18062Z","shell.execute_reply":"2021-10-26T03:48:23.628856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['path'] = p\ntrain['imfolder'] = d\ntrain.to_csv('test_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:23.631343Z","iopub.execute_input":"2021-10-26T03:48:23.631748Z","iopub.status.idle":"2021-10-26T03:48:23.644069Z","shell.execute_reply.started":"2021-10-26T03:48:23.631705Z","shell.execute_reply":"2021-10-26T03:48:23.643153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load(path, kind , image_size = 128 , depth =64):\n    directory = path +'/'+ kind\n#     print(directory)\n    reader = sitk.ImageSeriesReader()\n    dicom_names = reader.GetGDCMSeriesFileNames(directory)\n    reader.SetFileNames(dicom_names)\n    image = reader.Execute()\n    \n    image = sitk.GetArrayFromImage(image)\n\n    mid = int(image.shape[0]/2)    \n    if image.shape[0]>=64:\n        image = image[mid-32:mid+32,:,:]\n\n    image = resize(image, (64, 128, 128), preserve_range=True)    \n    image = torch.tensor(image)    \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:23.646419Z","iopub.execute_input":"2021-10-26T03:48:23.647062Z","iopub.status.idle":"2021-10-26T03:48:23.654855Z","shell.execute_reply.started":"2021-10-26T03:48:23.647023Z","shell.execute_reply":"2021-10-26T03:48:23.653803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = load(path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/01006/',kind = 'FLAIR' )","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:23.656615Z","iopub.execute_input":"2021-10-26T03:48:23.657008Z","iopub.status.idle":"2021-10-26T03:48:24.985194Z","shell.execute_reply.started":"2021-10-26T03:48:23.65697Z","shell.execute_reply":"2021-10-26T03:48:24.984327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:24.987875Z","iopub.execute_input":"2021-10-26T03:48:24.988233Z","iopub.status.idle":"2021-10-26T03:48:24.993956Z","shell.execute_reply.started":"2021-10-26T03:48:24.988197Z","shell.execute_reply":"2021-10-26T03:48:24.992867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(64): \n    plt.subplot(8, 8, i+1)\n    plt.imshow(image[i])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:24.996487Z","iopub.execute_input":"2021-10-26T03:48:24.997253Z","iopub.status.idle":"2021-10-26T03:48:28.124296Z","shell.execute_reply.started":"2021-10-26T03:48:24.99721Z","shell.execute_reply":"2021-10-26T03:48:28.123466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BratsDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, phase: str=\"test\", is_resize: bool=False):\n        self.df = df\n        self.phase = phase\n        self.augmentations = get_augmentations(phase)\n        self.data_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n        self.is_resize = is_resize\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        \n        id_ = self.df['imfolder'][idx];\n        path = self.df['path'][idx];\n#         path = 'task2_data_in_nii/00730/'\n        id_ = str(id_)\n        \n        images = []\n        for data_type in self.data_types:\n            img_path = path\n            img = self.load_img(img_path, data_type)#.transpose(2, 0, 1)\n            img = img.reshape(64,128,128)   \n            img = img.numpy()\n#             print(type(img))\n            img = self.normalize(img)\n            images.append(img)\n        img = np.stack(images)\n        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n        \n        if self.phase != \"test\":\n            augmented = self.augmentations(image=img.astype(np.float32), \n                                           )\n            \n            img = augmented['image']\n    \n        \n            return {\n                \"Id\": id_,\n                \"image\": img,\n            }\n        \n        return {\n            \"Id\": id_,\n            \"image\": img,\n        }\n    \n    def load_img(self, file_path, data_type):\n        data = load(file_path , data_type)\n#         print(file_path)\n#         data = np.asarray(data.dataobj)\n        return data\n    \n    def normalize(self, data: np.ndarray):\n        data_min = 0\n        \n        return (data - data_min) / (np.amax(data) - data_min)\n    \n    \n    \n   ","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:28.125561Z","iopub.execute_input":"2021-10-26T03:48:28.125928Z","iopub.status.idle":"2021-10-26T03:48:28.152632Z","shell.execute_reply.started":"2021-10-26T03:48:28.125891Z","shell.execute_reply":"2021-10-26T03:48:28.151841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_augmentations(phase):\n    list_transforms = []\n    \n    list_trfms = Compose(list_transforms)\n    return list_trfms\ndef get_dataloader(\n    dataset: torch.utils.data.Dataset,\n    path_to_csv: str,\n    phase: str,\n    fold: int = 0,\n    batch_size: int = 1,\n    num_workers: int = 0,\n):\n    '''Returns: dataloader for the model training'''\n    df = pd.read_csv(path_to_csv)\n    dataset = dataset(df, phase)\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=False,\n        shuffle=True,   \n    )\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:28.156612Z","iopub.execute_input":"2021-10-26T03:48:28.157905Z","iopub.status.idle":"2021-10-26T03:48:28.169207Z","shell.execute_reply.started":"2021-10-26T03:48:28.157866Z","shell.execute_reply":"2021-10-26T03:48:28.16823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('test_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:28.173321Z","iopub.execute_input":"2021-10-26T03:48:28.175936Z","iopub.status.idle":"2021-10-26T03:48:28.185592Z","shell.execute_reply.started":"2021-10-26T03:48:28.175877Z","shell.execute_reply":"2021-10-26T03:48:28.184749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:28.189691Z","iopub.execute_input":"2021-10-26T03:48:28.191637Z","iopub.status.idle":"2021-10-26T03:48:28.216413Z","shell.execute_reply.started":"2021-10-26T03:48:28.191599Z","shell.execute_reply":"2021-10-26T03:48:28.215612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='test_data.csv', phase='train', fold=0)\nlen(dataloader)\n\ndata = next(iter(dataloader))\ndata['Id'], data['image'].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:28.217595Z","iopub.execute_input":"2021-10-26T03:48:28.218073Z","iopub.status.idle":"2021-10-26T03:48:31.696215Z","shell.execute_reply.started":"2021-10-26T03:48:28.21804Z","shell.execute_reply":"2021-10-26T03:48:31.695382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(64): \n    plt.subplot(8, 8, i+1)\n    plt.imshow(data['image'][0][0][i])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:31.697547Z","iopub.execute_input":"2021-10-26T03:48:31.697904Z","iopub.status.idle":"2021-10-26T03:48:34.594164Z","shell.execute_reply.started":"2021-10-26T03:48:31.697867Z","shell.execute_reply":"2021-10-26T03:48:34.593241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n    def __init__(self, in_channels, out_channels, num_groups=8):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n            #nn.BatchNorm3d(out_channels),\n            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n            nn.ReLU(inplace=True),\n\n            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n            #nn.BatchNorm3d(out_channels),\n            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n            \n            nn.ReLU(inplace=True),\n            \n          )\n\n    def forward(self,x):\n        return self.double_conv(x)\n\n    \nclass Down(nn.Module):\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.MaxPool3d(2, 2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        return self.encoder(x)\n\n    \nclass Up(nn.Module):\n\n    def __init__(self, in_channels, out_channels, trilinear=False):\n        super().__init__()\n        \n        if trilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        else:\n            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n            \n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n\n        diffZ = x2.size()[2] - x1.size()[2]\n        diffY = x2.size()[3] - x1.size()[3]\n        diffX = x2.size()[4] - x1.size()[4]\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n    \nclass Out(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size = 1)\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass UNet3d(nn.Module):\n    def __init__(self, in_channels, n_classes, n_channels):\n        super().__init__()\n        self.in_channels = in_channels\n        self.n_classes = n_classes\n        self.n_channels = n_channels\n\n        self.conv = DoubleConv(in_channels, n_channels)\n        self.enc1 = Down(n_channels, 2 * n_channels)\n        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n\n        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n        self.dec3 = Up(4 * n_channels, n_channels)\n        self.dec4 = Up(2 * n_channels, n_channels)\n        self.out = Out(n_channels, n_classes)\n\n    def forward(self, x):\n        x1 = self.conv(x)\n        x2 = self.enc1(x1)\n        x3 = self.enc2(x2)\n        x4 = self.enc3(x3)\n        x5 = self.enc4(x4)\n\n        mask = self.dec1(x5, x4)\n        mask = self.dec2(mask, x3)\n        mask = self.dec3(mask, x2)\n        mask = self.dec4(mask, x1)\n        mask = self.out(mask)\n        return mask","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:48:34.595397Z","iopub.execute_input":"2021-10-26T03:48:34.595838Z","iopub.status.idle":"2021-10-26T03:48:34.616988Z","shell.execute_reply.started":"2021-10-26T03:48:34.595804Z","shell.execute_reply":"2021-10-26T03:48:34.616179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet3d(in_channels=4, n_classes=3, n_channels=24)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:58:34.208683Z","iopub.execute_input":"2021-10-26T03:58:34.209051Z","iopub.status.idle":"2021-10-26T03:58:34.260452Z","shell.execute_reply.started":"2021-10-26T03:58:34.209015Z","shell.execute_reply":"2021-10-26T03:58:34.259581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/seg-model/best_model_0.17.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:58:34.600445Z","iopub.execute_input":"2021-10-26T03:58:34.60087Z","iopub.status.idle":"2021-10-26T03:58:34.639686Z","shell.execute_reply.started":"2021-10-26T03:58:34.600829Z","shell.execute_reply":"2021-10-26T03:58:34.638813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval();","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:58:35.296851Z","iopub.execute_input":"2021-10-26T03:58:35.297189Z","iopub.status.idle":"2021-10-26T03:58:35.301415Z","shell.execute_reply.started":"2021-10-26T03:58:35.297158Z","shell.execute_reply":"2021-10-26T03:58:35.300576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShowResult:\n  \n    def mask_preprocessing(self, mask):\n        \"\"\"\n        Test.\n        \"\"\"\n        mask = mask.squeeze().cpu().detach().numpy()\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n\n        mask_WT = np.rot90(montage(mask[0]))\n        mask_TC = np.rot90(montage(mask[1]))\n        mask_ET = np.rot90(montage(mask[2]))\n\n        return mask_WT, mask_TC, mask_ET\n\n    def image_preprocessing(self, image):\n        \"\"\"\n        Returns image flair as mask for overlaping gt and predictions.\n        \"\"\"\n        image = image.squeeze().cpu().detach().numpy()\n        image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))\n        flair_img = np.rot90(montage(image[0]))\n        return flair_img\n    \n    def plot(self, image,   prediction):\n        image = self.image_preprocessing(image)\n#         gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n        \n        fig, axes = plt.subplots(1, 2, figsize = (35, 30))\n    \n        [ax.axis(\"off\") for ax in axes]\n#         axes[0].set_title(\"Ground Truth\", fontsize=35, weight='bold')\n#         axes[0].imshow(image, cmap ='bone')\n#         axes[0].imshow(np.ma.masked_where(gt_mask_WT == False, gt_mask_WT),\n#                   cmap='cool_r', alpha=0.6)\n#         axes[0].imshow(np.ma.masked_where(gt_mask_TC == False, gt_mask_TC),\n#                   cmap='autumn_r', alpha=0.6)\n#         axes[0].imshow(np.ma.masked_where(gt_mask_ET == False, gt_mask_ET),\n#                   cmap='autumn', alpha=0.6)\n\n        axes[1].set_title(\"Prediction\", fontsize=35, weight='bold')\n        axes[1].imshow(image, cmap ='bone')\n        axes[1].imshow(np.ma.masked_where(pr_mask_WT == False, pr_mask_WT),\n                  cmap='cool_r', alpha=0.6)\n        axes[1].imshow(np.ma.masked_where(pr_mask_TC == False, pr_mask_TC),\n                  cmap='autumn_r', alpha=0.6)\n        axes[1].imshow(np.ma.masked_where(pr_mask_ET == False, pr_mask_ET),\n                  cmap='autumn', alpha=0.6)\n\n        plt.tight_layout()\n        \n        plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:58:36.145061Z","iopub.execute_input":"2021-10-26T03:58:36.14541Z","iopub.status.idle":"2021-10-26T03:58:36.157654Z","shell.execute_reply.started":"2021-10-26T03:58:36.145356Z","shell.execute_reply":"2021-10-26T03:58:36.15642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = []\ntumor = []\nID=[]\npos=[]\nfor itr, data in enumerate(dataloader):\n    print(itr)\n    treshold = 0.3\n    id_ = int(data['Id'][0]);\n    id_ = '{0:05d}'.format(id_)\n    print(id_)\n    img = data['image']\n    logits = model(img)\n    test = img.numpy();\n    test = test.reshape(4, 128, 128, 64);\n    test = np.moveaxis(test, (0, 1, 2, 3), (0, 3, 2, 1))\n    tumor.append(test);\n    probs = torch.sigmoid(logits)\n    show = (probs >= treshold).float()\n    predictions = show.numpy()\n    predictions = predictions.reshape(3,128,128,64)\n    predictions = np.moveaxis(predictions, (0, 1, 2, 3), (0, 3, 2, 1))\n#     show_result = ShowResult()\n#     show_result.plot(img, show)\n    train_data.append(predictions)\n    ID.append(id_)\n    pos.append(itr)\n    if itr==2:\n        break;","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:08:45.840344Z","iopub.execute_input":"2021-10-26T04:08:45.840719Z","iopub.status.idle":"2021-10-26T04:09:26.416218Z","shell.execute_reply.started":"2021-10-26T04:08:45.840688Z","shell.execute_reply":"2021-10-26T04:09:26.41534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"long = len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:26.417741Z","iopub.execute_input":"2021-10-26T04:09:26.418081Z","iopub.status.idle":"2021-10-26T04:09:26.422245Z","shell.execute_reply.started":"2021-10-26T04:09:26.418043Z","shell.execute_reply":"2021-10-26T04:09:26.421386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:26.424061Z","iopub.execute_input":"2021-10-26T04:09:26.424609Z","iopub.status.idle":"2021-10-26T04:09:26.436227Z","shell.execute_reply.started":"2021-10-26T04:09:26.424571Z","shell.execute_reply":"2021-10-26T04:09:26.43542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(64): \n    plt.subplot(8, 8, i+1)\n    plt.imshow(train_data[0][0][i])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:26.438044Z","iopub.execute_input":"2021-10-26T04:09:26.438399Z","iopub.status.idle":"2021-10-26T04:09:29.631333Z","shell.execute_reply.started":"2021-10-26T04:09:26.438351Z","shell.execute_reply":"2021-10-26T04:09:29.630479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big = np.array([0]*len(train_data))\nfor e in range(len(train_data)):\n    print(e)\n    data = train_data[e]\n    area = [0]*64\n    print(data[0].shape)\n    for i in range (64):\n        area[i] = data[0][i].sum()\n    max = 0;\n    index = 0\n    for i in range(64):\n        if(area[i]>max):\n            max = area[i]\n            index = i\n    big[e] = index\n#     print(area)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:29.632566Z","iopub.execute_input":"2021-10-26T04:09:29.633063Z","iopub.status.idle":"2021-10-26T04:09:29.658119Z","shell.execute_reply.started":"2021-10-26T04:09:29.633022Z","shell.execute_reply":"2021-10-26T04:09:29.657334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:29.659426Z","iopub.execute_input":"2021-10-26T04:09:29.659791Z","iopub.status.idle":"2021-10-26T04:09:29.666495Z","shell.execute_reply.started":"2021-10-26T04:09:29.659753Z","shell.execute_reply":"2021-10-26T04:09:29.66549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:29.667844Z","iopub.execute_input":"2021-10-26T04:09:29.668399Z","iopub.status.idle":"2021-10-26T04:09:29.676774Z","shell.execute_reply.started":"2021-10-26T04:09:29.668323Z","shell.execute_reply":"2021-10-26T04:09:29.675434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gaussian_noise(img, mean=0, sigma=0.1):\n\n    # int -> float (標準化)\n#     img = img / 255\n    # 隨機生成高斯 noise (float + float)\n    noise = np.random.rand(img.shape[0], img.shape[1])\n#     noise = ;\n    # noise + 原圖\n#     print(noise)\n    for i in range(img.shape[0]):\n        for j in range(img.shape[1]):\n            if(img[i][j]==0 and noise[i][j]>0.9):\n                img[i][j] = img[i][j]+0.8\n                \n                \n    gaussian_out = img\n    # 所有值必須介於 0~1 之間，超過1 = 1，小於0 = 0\n#     gaussian_out = np.clip(gaussian_out, 0, 1)\n\n    # 原圖: float -> int (0~1 -> 0~255)\n#     gaussian_out = np.uint8(gaussian_out*255)\n    # noise: float -> int (0~1 -> 0~255)\n    noise = np.uint8(noise*255)\n    \n    return gaussian_out","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:29.679566Z","iopub.execute_input":"2021-10-26T04:09:29.680105Z","iopub.status.idle":"2021-10-26T04:09:29.687048Z","shell.execute_reply.started":"2021-10-26T04:09:29.680069Z","shell.execute_reply":"2021-10-26T04:09:29.685915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(tumor[0][0][42])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:29.688643Z","iopub.execute_input":"2021-10-26T04:09:29.689425Z","iopub.status.idle":"2021-10-26T04:09:29.852192Z","shell.execute_reply.started":"2021-10-26T04:09:29.689373Z","shell.execute_reply":"2021-10-26T04:09:29.851404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain = np.array([])\nfor i in range(len(train_data)):\n# for i in range(0,1):\n    data = train_data[i]\n    tumor_data = tumor[i]\n#     plt.imshow(tumor_data[0][43])\n    id_ = ID[i]\n    tumor_data1 = tumor_data[:,:,20:115,20:115]\n#     plt.imshow(tumor_data[0][42])\n    data1 = data[:,:,20:115,20:115]\n    index = big[i]\n    \n    print(index)\n    \n    image1 = data1[0][index-3]\n    \n    tumor_image1 = tumor_data1[0][index-3];\n    plt.imshow(tumor_image1)\n#     image1 = gaussian_noise(image1)\n    image2 = data1[0][index]\n    tumor_image2 = tumor_data1[0][index];\n    image2 = gaussian_noise(image2)\n    for i in range(0, 95):\n        for j in range(0,95):\n            if image1[i][j] == 1:\n                tumor_image1[i][j]+=2;\n#             else:\n#                 tumor_image1[i][j]-=150\n            if(image2[i][j]==1):\n                tumor_image2[i][j]+=2;\n#             else:\n#                 tumor_image2[i][j]-=150\n                \n                \n                \n    tumor_image1 = tumor_image1.reshape(1,95,95)\n    tumor_image2 = tumor_image2.reshape(1,95,95)\n    \n    \n    data = np.concatenate((tumor_image1, tumor_image2))\n    print(data.shape)\n    data = data.reshape(1, data.shape[0], data.shape[1], data.shape[2])\n    if xtrain.size:\n        xtrain = np.concatenate((xtrain, data))\n       \n    else:\n        print(\"first X\")\n        xtrain = data\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:29.853429Z","iopub.execute_input":"2021-10-26T04:09:29.853901Z","iopub.status.idle":"2021-10-26T04:09:30.431413Z","shell.execute_reply.started":"2021-10-26T04:09:29.853864Z","shell.execute_reply":"2021-10-26T04:09:30.430569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:30.432759Z","iopub.execute_input":"2021-10-26T04:09:30.433103Z","iopub.status.idle":"2021-10-26T04:09:30.439221Z","shell.execute_reply.started":"2021-10-26T04:09:30.433066Z","shell.execute_reply":"2021-10-26T04:09:30.438335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = xtrain[1]\nprint(p.shape)\nplt.imshow(p[0])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:09:44.608596Z","iopub.execute_input":"2021-10-26T04:09:44.608911Z","iopub.status.idle":"2021-10-26T04:09:44.761178Z","shell.execute_reply.started":"2021-10-26T04:09:44.608881Z","shell.execute_reply":"2021-10-26T04:09:44.760261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain = xtrain.reshape(xtrain.shape[0], 95, 95, xtrain.shape[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:59:45.272292Z","iopub.execute_input":"2021-10-26T03:59:45.272765Z","iopub.status.idle":"2021-10-26T03:59:45.277475Z","shell.execute_reply.started":"2021-10-26T03:59:45.272722Z","shell.execute_reply":"2021-10-26T03:59:45.276349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(xtrain)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:49:44.597933Z","iopub.execute_input":"2021-10-26T03:49:44.598245Z","iopub.status.idle":"2021-10-26T03:49:44.603583Z","shell.execute_reply.started":"2021-10-26T03:49:44.598215Z","shell.execute_reply":"2021-10-26T03:49:44.602675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model = keras.models.load_model(\"../input/model4/great_model_0.7068965435028076\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:49:47.808286Z","iopub.execute_input":"2021-10-26T03:49:47.808649Z","iopub.status.idle":"2021-10-26T03:49:47.979664Z","shell.execute_reply.started":"2021-10-26T03:49:47.808607Z","shell.execute_reply":"2021-10-26T03:49:47.978807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(xtrain)\npred = np.argmax(pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:49:48.844145Z","iopub.execute_input":"2021-10-26T03:49:48.844496Z","iopub.status.idle":"2021-10-26T03:49:48.970042Z","shell.execute_reply.started":"2021-10-26T03:49:48.844466Z","shell.execute_reply":"2021-10-26T03:49:48.969144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:49:49.89834Z","iopub.execute_input":"2021-10-26T03:49:49.898715Z","iopub.status.idle":"2021-10-26T03:49:49.905399Z","shell.execute_reply.started":"2021-10-26T03:49:49.898684Z","shell.execute_reply":"2021-10-26T03:49:49.904557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(columns=['BraTS21ID', 'MGMT_value'])\nsub['BraTS21ID'] = ID\nsub['MGMT_value'] = pred","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:49:53.212686Z","iopub.execute_input":"2021-10-26T03:49:53.213032Z","iopub.status.idle":"2021-10-26T03:49:53.222261Z","shell.execute_reply.started":"2021-10-26T03:49:53.212999Z","shell.execute_reply":"2021-10-26T03:49:53.221163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:49:54.19788Z","iopub.execute_input":"2021-10-26T03:49:54.198204Z","iopub.status.idle":"2021-10-26T03:49:54.203915Z","shell.execute_reply.started":"2021-10-26T03:49:54.198172Z","shell.execute_reply":"2021-10-26T03:49:54.202816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:50:08.141715Z","iopub.execute_input":"2021-10-26T03:50:08.142175Z","iopub.status.idle":"2021-10-26T03:50:08.153503Z","shell.execute_reply.started":"2021-10-26T03:50:08.142131Z","shell.execute_reply":"2021-10-26T03:50:08.152442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}