{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"timm_path = \"../input/timm-pytorch-image-models/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport os\nfrom tqdm.notebook import tqdm\nimport pydicom\nimport matplotlib.pyplot as plt\nimport glob\nimport sklearn\nimport random\n\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\n\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.seterr(divide='ignore', invalid='ignore')\n\nimport nibabel as nib\nimport SimpleITK as sitk\nimport shutil\nfrom PIL import Image\nfrom IPython.display import clear_output\nimport glob\nimport time\nfrom shutil import copyfile\nfrom statistics import mean\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:06.440123Z","iopub.execute_input":"2021-10-19T16:43:06.440431Z","iopub.status.idle":"2021-10-19T16:43:16.121058Z","shell.execute_reply.started":"2021-10-19T16:43:06.440352Z","shell.execute_reply":"2021-10-19T16:43:16.120321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('/kaggle/working/yolov5'):\n    shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.122809Z","iopub.execute_input":"2021-10-19T16:43:16.123557Z","iopub.status.idle":"2021-10-19T16:43:16.926147Z","shell.execute_reply.started":"2021-10-19T16:43:16.123518Z","shell.execute_reply":"2021-10-19T16:43:16.92539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/train'\ntest_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test'\nlabel_dir = '/kaggle/working/runs/detect/exp/labels'\nimage_predict_dir = '/kaggle/working/predict'\nprediction_results_dir = '/kaggle/working/runs/detect/exp/'\ntest_dir = '/kaggle/working/test'\n\nseries = 'T1wCE'\nplane = 'axial'\n\npredictions = []\npreds = []\nstudy_count = 0\nstudies_without_preds = []\nref_plane = ''\n\nreader = sitk.ImageSeriesReader()\nreader.LoadPrivateTagsOn()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.929313Z","iopub.execute_input":"2021-10-19T16:43:16.929618Z","iopub.status.idle":"2021-10-19T16:43:16.94078Z","shell.execute_reply.started":"2021-10-19T16:43:16.929587Z","shell.execute_reply":"2021-10-19T16:43:16.940121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect():    \n    !python yolov5/detect.py --source '{image_predict_dir}' --weights '../input/rsna-winning-models/brain_tumor_axial_t1wce.pt' --img 512 --exist-ok --save-txt\n","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.94241Z","iopub.execute_input":"2021-10-19T16:43:16.943172Z","iopub.status.idle":"2021-10-19T16:43:16.949606Z","shell.execute_reply.started":"2021-10-19T16:43:16.943135Z","shell.execute_reply":"2021-10-19T16:43:16.948442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dirs(study, series):\n    if not os.path.exists(test_dir):\n        os.mkdir(test_dir)\n    if not os.path.exists(f'{test_dir}/{study}'):\n        os.mkdir(f'{test_dir}/{study}')\n    if not os.path.exists(f'{test_dir}/{study}/{series}'):\n        os.mkdir(f'{test_dir}/{study}/{series}')\n\n    if not os.path.exists(image_predict_dir):\n        os.mkdir(image_predict_dir)\n        \ndef get_image_plane(loc):\n    row_x = round(loc[0])\n    row_y = round(loc[1])\n    row_z = round(loc[2])\n    col_x = round(loc[3])\n    col_y = round(loc[4])\n    col_z = round(loc[5])\n    if row_x == 1 and row_y == 0 and col_x == 0 and col_y == 0:\n        return \"Coronal\"\n    if row_x == 0 and row_y == 0 and col_x == 1 and col_y == 0:\n        return \"Sagittal\"\n    if row_x == 1 and row_y == 0 and col_x == 0 and col_y == 1:\n        return \"Axial\"\n    return \"Unknown\"\n\n# This function does all the voxel resampling and orienting\ndef resample(image, ref_image):\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear) \n    resampler.SetTransform(sitk.AffineTransform(image.GetDimension()))\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n    resampler.SetSize(ref_image.GetSize())\n    resampler.SetOutputDirection(ref_image.GetDirection())\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n    resamped_image = resampler.Execute(image)\n    return resamped_image\n\ndef normalize_pixels(pixels):\n    pixels = pixels - np.min(pixels)\n    pixels = pixels / np.max(pixels)\n    pixels = (pixels * 255).astype(np.uint8)\n    return pixels\ndef detect_on_image_set(study, series):\n    \n    global plane\n    images = []\n    list = os.listdir(f'{test_dir}/{study}/{series}')\n\n    if len(list) > 5:\n        df = pd.DataFrame({'filename':list})\n        df['filename'] = pd.to_numeric(df['filename'].astype(str).str[:-4])\n        df = df.sort_values(by=['filename'])\n\n        center_image = int(df.shape[0] / 2)\n        if plane == 'sagittal':\n            images.append(df.iloc[int(center_image / 7 * 2)]['filename'])\n            \n        images.append(df.iloc[int(center_image / 7 * 3)]['filename'])\n        images.append(df.iloc[int(center_image / 7 * 4)]['filename'])\n        images.append(df.iloc[center_image]['filename'])\n        images.append(df.iloc[center_image + int(center_image / 7)]['filename'])\n        images.append(df.iloc[center_image + int(center_image / 7 * 2)]['filename'])\n        images.append(df.iloc[center_image + int(center_image / 7 * 3)]['filename'])\n\n        if plane == 'axial':\n            images.append(df.iloc[center_image + int(center_image / 7 * 4)]['filename'])\n            \n        for img in images:\n            copyfile(f'{test_dir}/{study}/{series}/{img}.jpg',f'/{image_predict_dir}/{img}.jpg')\n            \n        clear_output()\n        print(\"PREDICTING -> \", study_count)\n        detect()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.95218Z","iopub.execute_input":"2021-10-19T16:43:16.952456Z","iopub.status.idle":"2021-10-19T16:43:16.971893Z","shell.execute_reply.started":"2021-10-19T16:43:16.952424Z","shell.execute_reply":"2021-10-19T16:43:16.971244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanup(study):\n\n    filelist = [ f for f in os.listdir(label_dir) if f.endswith(\".txt\") ]\n    for f in filelist:\n        os.remove(os.path.join(label_dir, f))\n\n    filelist = [ f for f in os.listdir(prediction_results_dir) if f.endswith(\".jpg\") ]\n    for f in filelist:\n        copyfile(f'{prediction_results_dir}/{f}',f'/{test_dir}/{study}/{series}/pred_{f}')\n        os.remove(os.path.join(prediction_results_dir, f))\n    \n    for f in os.listdir(image_predict_dir):\n        os.remove(os.path.join(image_predict_dir, f))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.973173Z","iopub.execute_input":"2021-10-19T16:43:16.973645Z","iopub.status.idle":"2021-10-19T16:43:16.984014Z","shell.execute_reply.started":"2021-10-19T16:43:16.973609Z","shell.execute_reply":"2021-10-19T16:43:16.983244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_study(study):\n    \n    global study_count\n    counter = 0\n\n    make_dirs(study, series)\n    target_array = get_target_array(study)\n    for i in range(0,target_array.shape[0]):\n        if counter == 0:\n            if len(target_array) > 0:\n                pixels = normalize_pixels(target_array[i,:,:])\n                w = target_array.shape[0] - 50\n                h = target_array.shape[1] - 50\n                pix_mean = np.mean(target_array[i,50:w,50:h])\n                if pix_mean > 40.0:\n                    filename = f'{test_dir}/{study}/{series}/{i}.jpg'\n                    cv2.imwrite(filename, pixels)             \n        counter += 1\n        if counter == 3:\n            counter = 0\n\n    detect_on_image_set(study, series)\n\n    filelist = [ f for f in os.listdir(label_dir) if f.endswith(\".txt\") ]\n    \n    if len(filelist) < 1:\n        studies_without_preds.append(study)\n\n    for f in filelist:\n        file = f.split('.')\n        p =  f'{test_dir}/{study}/{series}/{file[0]}.jpg'\n        preds.append(p)     \n\n    cleanup(study)\n    study_count += 1","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.985224Z","iopub.execute_input":"2021-10-19T16:43:16.985702Z","iopub.status.idle":"2021-10-19T16:43:16.995833Z","shell.execute_reply.started":"2021-10-19T16:43:16.985667Z","shell.execute_reply":"2021-10-19T16:43:16.995106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_target_array(study):\n\n    target_files = reader.GetGDCMSeriesFileNames(f'{test_path}/{study}/{series}')\n    reader.SetFileNames(target_files)\n    target_set = reader.Execute()\n\n    target_plane = get_image_plane(target_set.GetDirection())\n\n    # Only resample images that aren't already in the reference plane, otherwise just export as-is.\n    if ref_plane != target_plane:\n        target_new = resample(target_set, ref_set)\n    else:\n        target_new = target_set\n\n    return sitk.GetArrayFromImage(target_new)\n\n    target_files = reader.GetGDCMSeriesFileNames(f'{test_path}/{study}/{series}')\n    reader.SetFileNames(target_files)\n    target_set = reader.Execute()\n    target_plane = get_image_plane(target_set.GetDirection())\n    if ref_plane != target_plane:\n        target_new = resample(target_set, ref_array)\n    else:\n        target_new = target_set\n    return sitk.GetArrayFromImage(target_new)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:16.99746Z","iopub.execute_input":"2021-10-19T16:43:16.998076Z","iopub.status.idle":"2021-10-19T16:43:17.008304Z","shell.execute_reply.started":"2021-10-19T16:43:16.998041Z","shell.execute_reply":"2021-10-19T16:43:17.007488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if plane == 'axial':\n    reference_series = '00000/T1w'\nif plane == 'sagittal':\n    reference_series = '00000/T2w'\n\nref_files = reader.GetGDCMSeriesFileNames(f'{train_path}/{reference_series}')\nreader.SetFileNames(ref_files)\nref_set = reader.Execute()\n\nref_plane = get_image_plane(ref_set.GetDirection())\nref_array = sitk.GetArrayFromImage(ref_set)\n    \n\nprint(\"Reference Image Plane: \" + ref_plane)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:17.009654Z","iopub.execute_input":"2021-10-19T16:43:17.010173Z","iopub.status.idle":"2021-10-19T16:43:17.477944Z","shell.execute_reply.started":"2021-10-19T16:43:17.010091Z","shell.execute_reply":"2021-10-19T16:43:17.477178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\ntest_studies = [ f for f in os.listdir(test_path) ]\nlen(test_studies)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:17.479277Z","iopub.execute_input":"2021-10-19T16:43:17.4797Z","iopub.status.idle":"2021-10-19T16:43:17.501655Z","shell.execute_reply.started":"2021-10-19T16:43:17.479663Z","shell.execute_reply":"2021-10-19T16:43:17.50102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\ntest_studies = [ f for f in os.listdir(test_path) ]\n\nif( len(test_studies) > 87):\n    for study in test_studies:\n        test_study(study)\nelse:\n    test_studies = test_studies[:3]\n    for study in test_studies:\n        test_study(study)\n     \nclear_output()\nend_time = time.time()\n\ntotal_time = round((end_time - start_time) / 60, 2)\nprint(\"TOTAL TIME: \", total_time, \" min\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:17.502819Z","iopub.execute_input":"2021-10-19T16:43:17.503155Z","iopub.status.idle":"2021-10-19T16:43:46.989697Z","shell.execute_reply.started":"2021-10-19T16:43:17.503118Z","shell.execute_reply":"2021-10-19T16:43:46.988963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = sorted(preds)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:46.991936Z","iopub.execute_input":"2021-10-19T16:43:46.99248Z","iopub.status.idle":"2021-10-19T16:43:46.996646Z","shell.execute_reply.started":"2021-10-19T16:43:46.992429Z","shell.execute_reply":"2021-10-19T16:43:46.995912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 384\naug = A.Compose(\n    [  A.Resize(image_size,image_size,p=1.0),      \n        A.CenterCrop(height = 270 ,width = 270,p=1.0), \n         A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n     A.Transpose(p=0.5),   \n        A.RandomContrast(limit=0.2, p=0.5),\n        A.Resize(image_size,image_size,p=1.0),      \n        ToTensorV2(p=1.0)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:46.998398Z","iopub.execute_input":"2021-10-19T16:43:46.999024Z","iopub.status.idle":"2021-10-19T16:43:47.007897Z","shell.execute_reply.started":"2021-10-19T16:43:46.998984Z","shell.execute_reply":"2021-10-19T16:43:47.007094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Brain(Dataset):\n    def __init__(self , path , augs=aug):\n        self.p = path\n        self.augs = augs\n        \n    def __len__(self):\n        return(len(self.p))\n    \n    def __getitem__(self , idx):\n        img_src = self.p[idx]\n        image = cv2.imread(img_src)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n\n        if (self.augs):\n            transformed = self.augs(image=image)\n            image = transformed['image']\n            image = (image)/255.\n            image = torch.tensor(image,dtype = torch.float32) \n       \n    \n        return image","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:47.012692Z","iopub.execute_input":"2021-10-19T16:43:47.013103Z","iopub.status.idle":"2021-10-19T16:43:47.021048Z","shell.execute_reply.started":"2021-10-19T16:43:47.013073Z","shell.execute_reply":"2021-10-19T16:43:47.020007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = Brain(preds)\nload = DataLoader(data,batch_size = 1 , shuffle = True)\nimg = next(iter(load))\nplt.imshow(img.squeeze(0).permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:47.022202Z","iopub.execute_input":"2021-10-19T16:43:47.022529Z","iopub.status.idle":"2021-10-19T16:43:47.298481Z","shell.execute_reply.started":"2021-10-19T16:43:47.02248Z","shell.execute_reply":"2021-10-19T16:43:47.297829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = timm.create_model('efficientnet_b3', pretrained=False,  num_classes=0, global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        #n_in = self.net.classifier.in_features\n        self.fc = nn.Linear(1536 , 128)\n        self.fc2 =  nn.Linear(128 , 1)\n        self.dp = nn.Dropout(p=0.25)\n    \n    def forward(self, x):\n        x = self.net(x)\n        x = self.pool(x)\n        x = x.view(x.shape[0],-1)\n        x = F.relu(self.fc(x))\n        x = self.dp(x)\n        x= self.fc2(x)\n        \n        return x    ","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:43:47.29957Z","iopub.execute_input":"2021-10-19T16:43:47.29994Z","iopub.status.idle":"2021-10-19T16:43:47.30905Z","shell.execute_reply.started":"2021-10-19T16:43:47.299903Z","shell.execute_reply":"2021-10-19T16:43:47.30837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = \"../input/rsna-winning-models/2D_Fold model with val_auc 0.6829104010025063 and train auc 0.7496031746031746.pth\"\nmpath = [x]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:44.690034Z","iopub.execute_input":"2021-10-19T16:44:44.690287Z","iopub.status.idle":"2021-10-19T16:44:44.693803Z","shell.execute_reply.started":"2021-10-19T16:44:44.690259Z","shell.execute_reply":"2021-10-19T16:44:44.693125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Brain(preds)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False,  num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:44.878953Z","iopub.execute_input":"2021-10-19T16:44:44.88071Z","iopub.status.idle":"2021-10-19T16:44:44.88522Z","shell.execute_reply.started":"2021-10-19T16:44:44.880678Z","shell.execute_reply":"2021-10-19T16:44:44.88447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_func(test_loader , Model):\n    Model.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output = Model(x)\n            PREDS += [F.sigmoid(output).detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:45.119238Z","iopub.execute_input":"2021-10-19T16:44:45.119784Z","iopub.status.idle":"2021-10-19T16:44:45.125457Z","shell.execute_reply.started":"2021-10-19T16:44:45.119743Z","shell.execute_reply":"2021-10-19T16:44:45.124712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predx1 = []\npredx2 = []\npredx3 = []\npredx4 = []\nfor m in mpath:\n    mod = Model()\n    mod = mod.to(device)\n    mod.load_state_dict(torch.load(m))\n    predx1 += [inference_func(test_loader , mod)]\nfor m in mpath:\n    mod = Model()\n    mod = mod.to(device)\n    mod.load_state_dict(torch.load(m))\n    predx2 += [inference_func(test_loader , mod)]\nfor m in mpath:\n    mod = Model()\n    mod = mod.to(device)\n    mod.load_state_dict(torch.load(m))\n    predx3 += [inference_func(test_loader , mod)]\nfor m in mpath:\n    mod = Model()\n    mod = mod.to(device)\n    mod.load_state_dict(torch.load(m))\n    predx4 += [inference_func(test_loader , mod)]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:45.469079Z","iopub.execute_input":"2021-10-19T16:44:45.46958Z","iopub.status.idle":"2021-10-19T16:44:51.185624Z","shell.execute_reply.started":"2021-10-19T16:44:45.469545Z","shell.execute_reply":"2021-10-19T16:44:51.184826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pa = torch.from_numpy(np.mean(predx1, axis=0)).numpy()\ncata = np.concatenate((np.expand_dims(np.array(preds), axis=1), y_pa), axis = 1)\n\ny_pb = torch.from_numpy(np.mean(predx2, axis=0)).numpy()\ncatb = np.concatenate((np.expand_dims(np.array(preds), axis=1), y_pb), axis = 1)\n\ny_pc = torch.from_numpy(np.mean(predx3, axis=0)).numpy()\ncatc = np.concatenate((np.expand_dims(np.array(preds), axis=1), y_pc), axis = 1)\n\ny_pd = torch.from_numpy(np.mean(predx4, axis=0)).numpy()\ncatd = np.concatenate((np.expand_dims(np.array(preds), axis=1), y_pd), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:51.187842Z","iopub.execute_input":"2021-10-19T16:44:51.188132Z","iopub.status.idle":"2021-10-19T16:44:51.196474Z","shell.execute_reply.started":"2021-10-19T16:44:51.188093Z","shell.execute_reply":"2021-10-19T16:44:51.195773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub=pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\nsub[\"imfolder\"] = ['{0:05d}'.format(s) for s in sub[\"BraTS21ID\"]]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:51.197952Z","iopub.execute_input":"2021-10-19T16:44:51.198447Z","iopub.status.idle":"2021-10-19T16:44:51.222939Z","shell.execute_reply.started":"2021-10-19T16:44:51.198404Z","shell.execute_reply":"2021-10-19T16:44:51.222345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['t1'] = 0.5\nsub['t2'] = 0.5\nsub['t3'] = 0.5\nsub['t4'] = 0.5\nsub['t5'] = 0.5\nsub['t6'] = 0.5\nsub['t7'] = 0.5\nsub['t8'] = 0.5","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:55.869245Z","iopub.execute_input":"2021-10-19T16:44:55.869524Z","iopub.status.idle":"2021-10-19T16:44:55.879472Z","shell.execute_reply.started":"2021-10-19T16:44:55.869475Z","shell.execute_reply":"2021-10-19T16:44:55.878677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in sub[\"imfolder\"]:\n    r = 0\n    for j in range(len(cata)):\n        if(r == 0):\n            if(i == cata[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t1'] = np.float(cata[j][1])\n                r = r+1\nfor i in sub[\"imfolder\"]:\n    for j in range(len(cata)):\n        if(r == 0):\n            if(i == cata[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t2'] = np.float(cata[j][1])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:56.130384Z","iopub.execute_input":"2021-10-19T16:44:56.131081Z","iopub.status.idle":"2021-10-19T16:44:56.143163Z","shell.execute_reply.started":"2021-10-19T16:44:56.131044Z","shell.execute_reply":"2021-10-19T16:44:56.14216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in sub[\"imfolder\"]:\n    r = 0\n    for j in range(len(catb)):\n        if(r == 0):\n            if(i == catb[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t3'] = np.float(catb[j][1])\n                r = r+1\nfor i in sub[\"imfolder\"]:\n    for j in range(len(catb)):\n        if(r == 0):\n            if(i == catb[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t4'] = np.float(catb[j][1])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:56.969297Z","iopub.execute_input":"2021-10-19T16:44:56.969856Z","iopub.status.idle":"2021-10-19T16:44:56.981338Z","shell.execute_reply.started":"2021-10-19T16:44:56.969812Z","shell.execute_reply":"2021-10-19T16:44:56.980332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in sub[\"imfolder\"]:\n    r = 0\n    for j in range(len(catc)):\n        if(r == 0):\n            if(i == catc[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t5'] = np.float(catc[j][1])\n                r = r+1\nfor i in sub[\"imfolder\"]:\n    for j in range(len(catc)):\n        if(r == 0):\n            if(i == catc[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t6'] = np.float(catc[j][1])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:44:58.309362Z","iopub.execute_input":"2021-10-19T16:44:58.310086Z","iopub.status.idle":"2021-10-19T16:44:58.321782Z","shell.execute_reply.started":"2021-10-19T16:44:58.310048Z","shell.execute_reply":"2021-10-19T16:44:58.320916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in sub[\"imfolder\"]:\n    r = 0\n    for j in range(len(catd)):\n        if(r == 0):\n            if(i == catd[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t7'] = np.float(catd[j][1])\n                r = r+1\nfor i in sub[\"imfolder\"]:\n    for j in range(len(catc)):\n        if(r == 0):\n            if(i == catd[j][0][21:26]):\n                sub.loc[sub['imfolder'] == i,'t8'] = np.float(catd[j][1])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:00.76985Z","iopub.execute_input":"2021-10-19T16:45:00.770267Z","iopub.status.idle":"2021-10-19T16:45:00.790466Z","shell.execute_reply.started":"2021-10-19T16:45:00.770226Z","shell.execute_reply":"2021-10-19T16:45:00.789788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['MGMT_value'] = (sub['t1']**2 + sub['t2']**2 + sub['t3']**2 + sub['t4']**2 + sub['t5']**2 + sub['t6']**2 + sub['t7']**2 + sub['t8']**2)/8","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:03.359252Z","iopub.execute_input":"2021-10-19T16:45:03.359533Z","iopub.status.idle":"2021-10-19T16:45:03.367223Z","shell.execute_reply.started":"2021-10-19T16:45:03.359483Z","shell.execute_reply":"2021-10-19T16:45:03.366137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pathh = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test'\ntes = [os.path.join(pathh,x) for x in studies_without_preds]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:30.190103Z","iopub.execute_input":"2021-10-19T16:45:30.190896Z","iopub.status.idle":"2021-10-19T16:45:30.197044Z","shell.execute_reply.started":"2021-10-19T16:45:30.190852Z","shell.execute_reply":"2021-10-19T16:45:30.196067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pydicom.pixel_data_handlers.util import apply_voi_lut\ndef load_dicom(path , image_size,voi_lut=True, fix_monochrome=True  ):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    data = cv2.resize(data, (image_size, image_size))\n    return data\n\ndef load_3d(path , image_size  , depth =48):\n    flair = sorted(glob.glob(f\"{path}/FLAIR/*.dcm\"))\n    t1w = sorted(glob.glob(f\"{path}/T1w/*.dcm\"))\n    t1wce = sorted(glob.glob(f\"{path}/T1wCE/*.dcm\"))\n    t2w = sorted(glob.glob(f\"{path}/T2w/*.dcm\"))\n    \n    depth_per_source = depth // 4\n    s = 0\n    flair_img = np.array([load_dicom(a , image_size) for a in flair[s::depth_per_source]]).T\n\n    if flair_img.shape[-1] < depth_per_source:\n        n_zero = depth_per_source - flair_img.shape[-1]\n        flair_img = np.concatenate((flair_img, np.zeros((image_size, image_size, n_zero))), axis = -1)\n    elif (flair_img.shape[-1] > depth_per_source):\n        n = flair_img.shape[-1] - depth_per_source\n        flair_img = flair_img[:,:,:-n]\n        \n    t1w_img = np.array([load_dicom(a , image_size) for a in t1w[s::depth_per_source]]).T\n\n    if t1w_img.shape[-1] < depth_per_source:\n        n_zero = depth_per_source - t1w_img.shape[-1]\n        t1w_img = np.concatenate((t1w_img, np.zeros((image_size, image_size, n_zero))), axis = -1)\n    elif (t1w_img.shape[-1] > depth_per_source):\n        n = t1w_img.shape[-1] - depth_per_source\n        t1w_img = t1w_img[:,:,:-n]\n        \n    t1wce_img = np.array([load_dicom(a , image_size) for a in t1wce[s::depth_per_source]]).T\n\n    if t1wce_img.shape[-1] < depth_per_source:\n        n_zero = depth_per_source - t1wce_img.shape[-1]\n        t1wce_img = np.concatenate((t1wce_img, np.zeros((image_size, image_size, n_zero))), axis = -1)\n    elif (t1wce_img.shape[-1] > depth_per_source):\n        n = t1wce_img.shape[-1] - depth_per_source\n        t1wce_img = t1wce_img[:,:,:-n]\n    \n    t2w_img = np.array([load_dicom(a , image_size) for a in  t2w[s::depth_per_source]]).T\n\n    if t2w_img.shape[-1] < depth_per_source:\n        n_zero = depth_per_source - t2w_img.shape[-1]\n        t2w_img = np.concatenate((t2w_img, np.zeros((image_size, image_size, n_zero))), axis = -1)\n    elif (t2w_img.shape[-1] > depth_per_source):\n        n = t2w_img.shape[-1] - depth_per_source\n        t2w_img = t2w_img[:,:,:-n]\n    \n   \n    \n    image_3d =  np.concatenate((flair_img, t1w_img, t1wce_img, t2w_img), axis = -1) #shpe= height x width x depth\n    image_3d = torch.tensor(image_3d , dtype = torch.float32 ).permute(2 , 1 ,0)\n    \n    return image_3d","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:30.365884Z","iopub.execute_input":"2021-10-19T16:45:30.366221Z","iopub.status.idle":"2021-10-19T16:45:30.384478Z","shell.execute_reply.started":"2021-10-19T16:45:30.366189Z","shell.execute_reply":"2021-10-19T16:45:30.383766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BrainX(Dataset):\n    def __init__(self , pre , image_size = 256 , depth = 48):\n        self.pre = pre\n        self.img_size =image_size\n        self.d = depth\n    \n    def __len__(self):\n        return(len(self.pre))\n    \n    def __getitem__(self , idx):\n        img_path = self.pre[idx]\n        img_3d = load_3d(img_path , self.img_size , self.d)\n        img_3d = img_3d/255.\n        \n        img_3d = img_3d - 0.5\n        img_3d = (img_3d)/(0.5)\n        \n        img_3d = img_3d.unsqueeze(0) # channel_length , deth , width , height\n       \n        return img_3d ","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:30.579241Z","iopub.execute_input":"2021-10-19T16:45:30.580004Z","iopub.status.idle":"2021-10-19T16:45:30.586963Z","shell.execute_reply.started":"2021-10-19T16:45:30.579956Z","shell.execute_reply":"2021-10-19T16:45:30.586277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=timm.create_model('efficientnet_b1', pretrained=False) # set pretrained=True to use the pretrained weights\nnum_features = model.classifier.in_features\nmodel.classifier = nn.Linear(num_features, 1)\nclass Model_3d_2_2d(nn.Module):\n    def __init__(self, model , input_channels = 1):\n        super().__init__()\n        self.model = model\n        self.cnn3d = nn.Conv3d( input_channels , 1 ,kernel_size = (8,3,3) , stride=(2, 1, 1))\n        self.pool1 = nn.AdaptiveMaxPool3d((8 , 224,224))\n        self.cnn2d = nn.Conv2d(8, 3 , 3 , stride = 1 , padding = 1 , bias = False)\n        self.pool2 = nn.AdaptiveMaxPool2d((224))\n        self.norm = nn.BatchNorm2d(3)\n \n    def forward(self , x):\n        x = F.relu(self.cnn3d(x))\n        x = x.squeeze(1)\n        x = self.pool1(x) \n        \n        x = self.cnn2d(x)\n        x = self.norm(x)\n        x = F.relu(x)\n        #print(x.shape)\n        x = self.pool2(x)\n        x = self.model(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:30.819356Z","iopub.execute_input":"2021-10-19T16:45:30.819997Z","iopub.status.idle":"2021-10-19T16:45:30.965879Z","shell.execute_reply.started":"2021-10-19T16:45:30.819962Z","shell.execute_reply":"2021-10-19T16:45:30.965198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = \"../input/rsna-winning-models/3D_Fold 1 model with val_acc 0.6936425264550264 and train auc 0.6745247688135619.pth\"\n#y = \"../input/best-cv/Fold 1 model with val_acc 0.7113839285714286 and train auc 0.8488540780207449.pth\"\nmpath = [x]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:31.099033Z","iopub.execute_input":"2021-10-19T16:45:31.099352Z","iopub.status.idle":"2021-10-19T16:45:31.102864Z","shell.execute_reply.started":"2021-10-19T16:45:31.099322Z","shell.execute_reply":"2021-10-19T16:45:31.102103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = BrainX(tes,  depth = 48 )\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False,  num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:31.414034Z","iopub.execute_input":"2021-10-19T16:45:31.414593Z","iopub.status.idle":"2021-10-19T16:45:31.419746Z","shell.execute_reply.started":"2021-10-19T16:45:31.414559Z","shell.execute_reply":"2021-10-19T16:45:31.41873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_func(test_loader , Model):\n    Model.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output = Model(x)\n            PREDS += [F.sigmoid(output).detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:32.109454Z","iopub.execute_input":"2021-10-19T16:45:32.110047Z","iopub.status.idle":"2021-10-19T16:45:32.115959Z","shell.execute_reply.started":"2021-10-19T16:45:32.110007Z","shell.execute_reply":"2021-10-19T16:45:32.115177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor m in mpath:\n    mod = Model_3d_2_2d(model)\n    mod = mod.to(device)\n    mod.load_state_dict(torch.load(m))\n    preds += [inference_func(test_loader , mod)]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:32.68941Z","iopub.execute_input":"2021-10-19T16:45:32.690152Z","iopub.status.idle":"2021-10-19T16:45:34.249076Z","shell.execute_reply.started":"2021-10-19T16:45:32.690099Z","shell.execute_reply":"2021-10-19T16:45:34.248285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_p = torch.from_numpy(np.mean(preds, axis=0)).numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:34.251349Z","iopub.execute_input":"2021-10-19T16:45:34.251657Z","iopub.status.idle":"2021-10-19T16:45:34.256196Z","shell.execute_reply.started":"2021-10-19T16:45:34.251617Z","shell.execute_reply":"2021-10-19T16:45:34.255479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat2 = np.concatenate((np.expand_dims(np.array(studies_without_preds), axis=1), y_p), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:34.257564Z","iopub.execute_input":"2021-10-19T16:45:34.258084Z","iopub.status.idle":"2021-10-19T16:45:34.267188Z","shell.execute_reply.started":"2021-10-19T16:45:34.258047Z","shell.execute_reply":"2021-10-19T16:45:34.266471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in sub[\"imfolder\"]:\n    r = 0\n    for j in range(len(cat2)):\n        if(r == 0):\n            if(i == cat2[j][0]):\n                sub.loc[sub['imfolder'] == i,'MGMT_value'] = np.float(cat2[j][1])**2\n                r = r+1","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:34.994436Z","iopub.execute_input":"2021-10-19T16:45:34.995013Z","iopub.status.idle":"2021-10-19T16:45:35.002273Z","shell.execute_reply.started":"2021-10-19T16:45:34.994974Z","shell.execute_reply":"2021-10-19T16:45:35.001198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub.drop(['imfolder' , 't1' , 't2','t3' , 't4', 't5', 't6', 't7' , 't8'], axis = 1)\nsub.to_csv('/kaggle/working/submission.csv', index = False)\nsub","metadata":{"execution":{"iopub.status.busy":"2021-10-19T16:45:35.489336Z","iopub.execute_input":"2021-10-19T16:45:35.490029Z","iopub.status.idle":"2021-10-19T16:45:35.511201Z","shell.execute_reply.started":"2021-10-19T16:45:35.48999Z","shell.execute_reply":"2021-10-19T16:45:35.510435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}