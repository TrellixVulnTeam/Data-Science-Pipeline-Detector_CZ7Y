{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-23T08:44:57.982993Z","iopub.execute_input":"2021-10-23T08:44:57.98333Z","iopub.status.idle":"2021-10-23T08:44:57.987876Z","shell.execute_reply.started":"2021-10-23T08:44:57.983299Z","shell.execute_reply":"2021-10-23T08:44:57.987026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing required libraries ","metadata":{}},{"cell_type":"code","source":"eff_b0_path = \"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\"\npackage_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\nimport sys \nsys.path.append(package_path)\nimport sys \nimport os \nimport glob \nimport time \nimport random \nimport numpy as np \nimport pandas as pd \nimport pydicom \nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2 \n\nimport torch \nfrom torch import nn \nfrom torch.utils import data as torch_data \nfrom torch.nn import functional as F \n\nimport efficientnet_pytorch\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom tqdm import tqdm ","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:44:57.996717Z","iopub.execute_input":"2021-10-23T08:44:57.997211Z","iopub.status.idle":"2021-10-23T08:44:59.672413Z","shell.execute_reply.started":"2021-10-23T08:44:57.997182Z","shell.execute_reply":"2021-10-23T08:44:59.671644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# device selection ","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:44:59.674346Z","iopub.execute_input":"2021-10-23T08:44:59.674773Z","iopub.status.idle":"2021-10-23T08:44:59.723559Z","shell.execute_reply.started":"2021-10-23T08:44:59.674736Z","shell.execute_reply":"2021-10-23T08:44:59.722717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 256 \nn_frames = 10 \ncnn_features = 256 \nlstm_hidden = 32 \nn_fold = 5 \nn_epochs = 10 ","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:44:59.725367Z","iopub.execute_input":"2021-10-23T08:44:59.725878Z","iopub.status.idle":"2021-10-23T08:44:59.734227Z","shell.execute_reply.started":"2021-10-23T08:44:59.725807Z","shell.execute_reply":"2021-10-23T08:44:59.733401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# creating the model ","metadata":{}},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:44:59.73577Z","iopub.execute_input":"2021-10-23T08:44:59.738795Z","iopub.status.idle":"2021-10-23T08:44:59.74857Z","shell.execute_reply.started":"2021-10-23T08:44:59.738762Z","shell.execute_reply":"2021-10-23T08:44:59.74739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.map = nn.Conv2d(in_channels = 4 , out_channels = 3 , kernel_size = 1 )\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n        checkpoint = torch.load('../input/efficientnet-pytorch/efficientnet-b0-08094119.pth')\n        self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features \n        self.net._fc = nn.Linear(in_features = n_features , out_features = cnn_features)\n    \n    def forward(self, x ):\n        x = F.relu(self.map(x))\n        out = self.net(x)\n        return out \n\n    \nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.cnn = CNN()\n        self.rnn = nn.LSTM(cnn_features , lstm_hidden , 2, batch_first = True)\n        self.fc = nn.Linear(lstm_hidden, 1, bias = True)\n        \n    def forward(self, x):\n        batch_size , timesteps, C, H, W = x.size() \n        c_in = x.view(batch_size* timesteps , C, H, W)\n        c_out = self.cnn(c_in)\n        r_in = c_out.view(batch_size, timesteps, -1)\n        output , (hn,cn) = self.rnn(r_in)\n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:00.052749Z","iopub.execute_input":"2021-10-23T08:45:00.053534Z","iopub.status.idle":"2021-10-23T08:45:00.064447Z","shell.execute_reply.started":"2021-10-23T08:45:00.053494Z","shell.execute_reply":"2021-10-23T08:45:00.063373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n        \n    data = np.float32(cv2.resize(data, (CFG.img_size, CFG.img_size)))\n    return torch.tensor(data)\n\ndef load_dicom_line(path):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    images = []\n    for filename in t_paths:\n        data = load_dicom(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:02.943465Z","iopub.execute_input":"2021-10-23T08:45:02.944102Z","iopub.status.idle":"2021-10-23T08:45:02.951859Z","shell.execute_reply.started":"2021-10-23T08:45:02.944063Z","shell.execute_reply":"2021-10-23T08:45:02.950796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetrival(Dataset):\n    def __init__(self, paths,targets , transform = None):\n        self.paths = paths \n        self.transform = transform\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.paths)\n    \n    def read_in(self,image_paths):\n        total_img = [load_dicom(path) for path in image_paths]\n        \n        if len(total_img) == 0 :\n            total_img = torch.zeros(n_frames , img_size , img_size)\n        \n        else: \n            total_img = torch.stack(total_img)\n        \n        return total_img\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{str(_id).zfill(5)}/\"\n        channels = [] \n        for t in [\"FLAIR\",\"T1w\", \"T1wCE\", \"T2w\"]:\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n            \n            num_samples = n_frames \n            if len(t_paths) < num_samples:\n                in_frames_path = t_paths \n            else:\n                in_frames_paths = uniform_temporal_subsample(t_paths , num_samples)\n            \n            channel = self.read_in(in_frames_path)\n            if channel.shape[0] == 0 :\n                print('1 channel empty')\n                channel = torch.zeros(num_samples , img_size, img_size)\n            \n            channels.append(channel)\n        channels = torch.stack(channels).transpose(0,1)\n        \n        y = torch.tensor(self.targets[index] , dtype = torch.float)\n        return {\"X\" : channels.float(), \"y\": y}","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:03.147103Z","iopub.execute_input":"2021-10-23T08:45:03.147811Z","iopub.status.idle":"2021-10-23T08:45:03.159981Z","shell.execute_reply.started":"2021-10-23T08:45:03.147778Z","shell.execute_reply":"2021-10-23T08:45:03.159033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:03.306747Z","iopub.execute_input":"2021-10-23T08:45:03.307238Z","iopub.status.idle":"2021-10-23T08:45:03.321174Z","shell.execute_reply.started":"2021-10-23T08:45:03.307202Z","shell.execute_reply":"2021-10-23T08:45:03.32046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:03.49437Z","iopub.execute_input":"2021-10-23T08:45:03.495258Z","iopub.status.idle":"2021-10-23T08:45:03.519098Z","shell.execute_reply.started":"2021-10-23T08:45:03.495216Z","shell.execute_reply":"2021-10-23T08:45:03.517068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch_data.DataLoader(\n    DataRetrival(df['BraTS21ID'].values,\n                df['MGMT_value'].values\n                ),\n    batch_size = 8 , \n    num_workers = 4, \n    shuffle= True\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:03.605833Z","iopub.execute_input":"2021-10-23T08:45:03.608155Z","iopub.status.idle":"2021-10-23T08:45:03.622804Z","shell.execute_reply.started":"2021-10-23T08:45:03.608114Z","shell.execute_reply":"2021-10-23T08:45:03.621899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# creating the training loop \n","metadata":{}},{"cell_type":"code","source":"def train_loop(epochs , model , optimizer , dataloader , loss):\n    model = model.to(device)\n    if optimizer == \"adam\":\n        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n    model.train()\n    \n    for epoch in tqdm(range(epochs)):\n        for step, data in enumerate(dataloader):\n            X = data['X'].to(device)\n            targets = data['y'].to(device)\n            optimizer.zero_grad()\n            outputs = model(X).squeeze(1)\n            data_loss = loss(outputs, targets)\n            data_loss.backward()\n            \n            optimizer.step()\n        \n        if (epoch%3 == 0):\n            print(f'epoch no {epoch+1} completed at {time.time()}')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:04.129251Z","iopub.execute_input":"2021-10-23T08:45:04.129505Z","iopub.status.idle":"2021-10-23T08:45:04.140037Z","shell.execute_reply.started":"2021-10-23T08:45:04.129477Z","shell.execute_reply":"2021-10-23T08:45:04.139186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()\ntrain_loop(epochs = n_epochs ,\n           model = model ,\n           optimizer = \"adam\" ,\n           dataloader = train_loader,\n           loss = F.binary_cross_entropy_with_logits)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:45:04.710109Z","iopub.execute_input":"2021-10-23T08:45:04.71091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,\"./efficient_net_b0_model.pth\" )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}