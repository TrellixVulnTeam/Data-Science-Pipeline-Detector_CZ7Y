{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tf-explain","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:21.267347Z","iopub.execute_input":"2021-12-19T14:34:21.267973Z","iopub.status.idle":"2021-12-19T14:34:30.811864Z","shell.execute_reply.started":"2021-12-19T14:34:21.267873Z","shell.execute_reply":"2021-12-19T14:34:30.811041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tf_explain\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport random\nfrom sklearn import model_selection as sk_model_selection\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras_preprocessing.image.dataframe_iterator import DataFrameIterator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-19T14:34:30.815644Z","iopub.execute_input":"2021-12-19T14:34:30.815876Z","iopub.status.idle":"2021-12-19T14:34:36.081301Z","shell.execute_reply.started":"2021-12-19T14:34:30.81585Z","shell.execute_reply":"2021-12-19T14:34:36.080444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    INPUT_PATH_DCM = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/'\n    INPUT_PATH_PNG = '../input/rsna-miccai-png/'\n    TENSORBOARD_LOG_DIR = '../working/log_tensorboard/'\n    SEED = 42\n    #These should be removed from the dataset\n    EXCLUDED_STR = ['00109', '00123', '00709']\n    EXCLUDED_INT = [109, 123, 709]\n\n    #Defining target size of image\n    IMG_SIZE = 224\n    NUM_SLICES_3D = 64\n    MIN_SLICES = 12\n    \n    BATCH_SIZE = 64\n    \n    CLASS_MODE = 'binary'\n    COLOR_MODE = 'rgb'\n    TARGET_SIZE = (224, 224)\n    def __self__():\n        pass\n    @staticmethod\n    def set_seed(seed_val):\n        tf.random.set_seed(seed_val)\n        random.seed(seed_val)\n        os.environ['PYTHONHASHSEED'] = str(seed_val)\n        np.random.seed(seed_val)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.082415Z","iopub.execute_input":"2021-12-19T14:34:36.082659Z","iopub.status.idle":"2021-12-19T14:34:36.091453Z","shell.execute_reply.started":"2021-12-19T14:34:36.082623Z","shell.execute_reply":"2021-12-19T14:34:36.090661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Config.set_seed(Config.SEED)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.094587Z","iopub.execute_input":"2021-12-19T14:34:36.095135Z","iopub.status.idle":"2021-12-19T14:34:36.101038Z","shell.execute_reply.started":"2021-12-19T14:34:36.095098Z","shell.execute_reply":"2021-12-19T14:34:36.100315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Getting to know the data","metadata":{}},{"cell_type":"code","source":"!ls ../input/rsna-miccai-brain-tumor-radiogenomic-classification/\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.102496Z","iopub.execute_input":"2021-12-19T14:34:36.102929Z","iopub.status.idle":"2021-12-19T14:34:36.77287Z","shell.execute_reply.started":"2021-12-19T14:34:36.102894Z","shell.execute_reply":"2021-12-19T14:34:36.771897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(Config.INPUT_PATH_DCM+'train_labels.csv', dtype={\n    'BraTS21ID': str, 'MGMT_value':int\n})\n\ndf_test = pd.read_csv(Config.INPUT_PATH_DCM+'sample_submission.csv', dtype={\n    'BraTS21ID': str, 'MGMT_value':float\n})\n\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.775915Z","iopub.execute_input":"2021-12-19T14:34:36.776158Z","iopub.status.idle":"2021-12-19T14:34:36.814345Z","shell.execute_reply.started":"2021-12-19T14:34:36.776127Z","shell.execute_reply":"2021-12-19T14:34:36.813647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lendo dataset \ndf = df[~df['BraTS21ID'].isin(Config.EXCLUDED_STR)]\n\n#Para testes, usando 1/3 do dataset\n# df = df[:int(len(df)/3)]\n\n\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.815667Z","iopub.execute_input":"2021-12-19T14:34:36.81595Z","iopub.status.idle":"2021-12-19T14:34:36.82949Z","shell.execute_reply.started":"2021-12-19T14:34:36.815915Z","shell.execute_reply":"2021-12-19T14:34:36.82878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adapted from: https://www.kaggle.com/leandronidas/tf-efficientnet-transfer-learning-strat-split/edit\n\ndf['flair'] = df['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'train/'+file_id+'/FLAIR/')\ndf['t1w'] = df['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'train/'+file_id+'/T1w/')\ndf['t1wce'] = df['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'train/'+file_id+'/T1wCE/')\ndf['t2w'] = df['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'train/'+file_id+'/T2w/')\n\ndf['brats21idInt'] = df['BraTS21ID'].astype(int)\n\ndf_test['flair'] = df_test['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'test/'+file_id+'/FLAIR/')\ndf_test['t1w'] = df_test['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'test/'+file_id+'/T1w/')\ndf_test['t1wce'] = df_test['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'test/'+file_id+'/T1wCE/')\ndf_test['t2w'] = df_test['BraTS21ID'].apply(lambda file_id : Config.INPUT_PATH_PNG+'test/'+file_id+'/T2w/')\n\ndf_test['brats21idInt'] = df_test['BraTS21ID'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.830891Z","iopub.execute_input":"2021-12-19T14:34:36.831337Z","iopub.status.idle":"2021-12-19T14:34:36.851384Z","shell.execute_reply.started":"2021-12-19T14:34:36.831299Z","shell.execute_reply":"2021-12-19T14:34:36.850663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_y = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\npred = sample_y\npred['BraTS21ID5'] = [format(x, '05d') for x in pred.BraTS21ID]\npred.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.852764Z","iopub.execute_input":"2021-12-19T14:34:36.854654Z","iopub.status.idle":"2021-12-19T14:34:36.870227Z","shell.execute_reply.started":"2021-12-19T14:34:36.854624Z","shell.execute_reply":"2021-12-19T14:34:36.869415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Divisao estratificada em treino, teste e validação\ndf_trainval, df_test = sk_model_selection.train_test_split(\n    df, \n    test_size=0.15, \n    random_state=Config.SEED, \n    stratify=df[\"MGMT_value\"],\n)\ndf_train, df_val = sk_model_selection.train_test_split(\n    df_trainval, \n    test_size=0.2, \n    random_state=Config.SEED, \n    stratify=df_trainval[\"MGMT_value\"],\n)\n\nprint(df_train.shape)\nprint(df_val.shape)\nprint(df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.873632Z","iopub.execute_input":"2021-12-19T14:34:36.873998Z","iopub.status.idle":"2021-12-19T14:34:36.88895Z","shell.execute_reply.started":"2021-12-19T14:34:36.873971Z","shell.execute_reply":"2021-12-19T14:34:36.888201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.890173Z","iopub.execute_input":"2021-12-19T14:34:36.890947Z","iopub.status.idle":"2021-12-19T14:34:36.909194Z","shell.execute_reply.started":"2021-12-19T14:34:36.890909Z","shell.execute_reply":"2021-12-19T14:34:36.908487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_val[df_val['brats21idInt'] == 109].any())\n\nprint(df_train[df_train['brats21idInt'] == 109].any())","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.910389Z","iopub.execute_input":"2021-12-19T14:34:36.911169Z","iopub.status.idle":"2021-12-19T14:34:36.92195Z","shell.execute_reply.started":"2021-12-19T14:34:36.911132Z","shell.execute_reply":"2021-12-19T14:34:36.920978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    \ndef get_iterating_dataframe(df, mri_type):\n    \n    all_test_img_files = []\n    all_test_img_labels = []\n    all_test_img_patient_ids = []\n    for row in df.iterrows():\n\n        img_dir = row[1][mri_type]\n        img_files = os.listdir(img_dir)\n        img_nums = sorted([int(ele.replace('Image-', '').replace('.png', '')) for ele in img_files])\n        totalnum_images = len(img_nums)\n        mid_point = int(totalnum_images//2)\n        start_point = mid_point - max(int(mid_point*0.1), Config.MIN_SLICES//2)\n        end_point = mid_point + max(int(mid_point*0.1), Config.MIN_SLICES//2)\n#         print(type(img_nums[0]))\n#         break\n        img_names = [f'Image-{img_nums[i]}.png' for i in range(start_point, end_point+1)]\n\n        img_paths = [img_dir+ele for ele in img_names]\n        img_labels = [row[1]['MGMT_value']]*len(img_paths)\n        img_patient_ids = [row[1]['brats21idInt']]*len(img_paths)\n        all_test_img_files.extend(img_paths)\n        all_test_img_labels.extend(img_labels)\n        all_test_img_patient_ids.extend(img_patient_ids)\n\n    new_df = pd.DataFrame({'patient_ids': all_test_img_patient_ids,\n                  'labels': all_test_img_labels,\n                  'file_paths': all_test_img_files})\n            \n    return new_df","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.923612Z","iopub.execute_input":"2021-12-19T14:34:36.924652Z","iopub.status.idle":"2021-12-19T14:34:36.935112Z","shell.execute_reply.started":"2021-12-19T14:34:36.924619Z","shell.execute_reply":"2021-12-19T14:34:36.934351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PNGDataFrameIterator(DataFrameIterator):\n    def __init__(self, *arg, **kwargs):\n        self.white_list_formats = ('png')\n        super(PNGDataFrameIterator, self).__init__(*arg, **kwargs)\n        self.dataframe = kwargs['dataframe']\n        self.x = self.dataframe[kwargs['x_col']]\n        self.y = self.dataframe[kwargs['y_col']]\n        self.color_mode = kwargs['color_mode']\n        self.target_size = kwargs['target_size']\n\n    def _get_batches_of_transformed_samples(self, indices_array):\n        # get batch of images\n        batch_x = np.array([self.read_png_as_array(path, self.target_size, \n                                                   color_mode=self.color_mode)\n                            for path in self.x.iloc[indices_array]])\n\n        batch_y = np.array(self.y.iloc[indices_array].astype(np.uint8))  # astype because y was passed as str\n\n        # transform images\n        if self.image_data_generator is not None:\n            for i, (x, y) in enumerate(zip(batch_x, batch_y)):\n                transform_params = self.image_data_generator.get_random_transform(x.shape)\n                batch_x[i] = self.image_data_generator.apply_transform(x, transform_params)\n      \n\n        return batch_x, batch_y\n\n    \n    @staticmethod\n    def read_png_as_array(path, target_size=(Config.IMG_SIZE, Config.IMG_SIZE),\n                          color_mode='rgb'):\n        im_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        pixels = im_gray - np.min(im_gray)\n        pixels = pixels / np.max(pixels)\n        image_manual_norm = (pixels * 255).astype(np.uint8)\n        image_array = cv2.resize(image_manual_norm, target_size, interpolation=cv2.INTER_CUBIC) \n        \n        if color_mode == 'rgb':\n            image_array = np.dstack((image_array, np.zeros_like(image_array), np.zeros_like(image_array)))\n        return image_array\n\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.936294Z","iopub.execute_input":"2021-12-19T14:34:36.936765Z","iopub.status.idle":"2021-12-19T14:34:36.950501Z","shell.execute_reply.started":"2021-12-19T14:34:36.936708Z","shell.execute_reply":"2021-12-19T14:34:36.949807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exam_list = ['flair','t1w','t1wce','t2w']\n# exam_list = ['flair']\n\ndftrainIter_dict = {}\ndfvalIter_dict = {}\ndftestIter_dict = {}\ntrain_gen_dict = {}\nval_gen_dict = {}\ntest_gen_dict = {}\nmodel_check_dict = {}\nmodel_dict = {}\n\nfor exam in exam_list:\n    dftrainIter = get_iterating_dataframe(df_train, exam)\n    dftrainIter['labels_str'] = dftrainIter['labels'].astype(str)\n\n    dfvalIter = get_iterating_dataframe(df_val, exam)\n    dfvalIter['labels_str'] = dfvalIter['labels'].astype(str)\n\n    dftestIter = get_iterating_dataframe(df_test, exam)\n    dftestIter['labels_str'] = dftestIter['labels'].astype(str)\n\n    datagen = ImageDataGenerator(\n            preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n            zoom_range=0.2,\n            rotation_range=45,\n            fill_mode='nearest',\n            height_shift_range= 0.15,\n            width_shift_range=0.15,\n            horizontal_flip=True,\n            vertical_flip=True,\n            brightness_range = [0.8, 1.2],\n            rescale=1.0/255,\n    )\n    test_datagen = ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n        rescale=1.0/255,\n    )\n\n    train_generator = PNGDataFrameIterator(dataframe=dftrainIter,\n                                     x_col='file_paths',\n                                     y_col='labels_str',\n                                     image_data_generator=datagen,\n                                     seed=Config.SEED,\n                                     batch_size=Config.BATCH_SIZE,\n                                     class_mode=Config.CLASS_MODE,\n                                     color_mode=Config.COLOR_MODE,\n                                     target_size=Config.TARGET_SIZE,  \n                                    )\n\n    val_generator = PNGDataFrameIterator(dataframe=dfvalIter,\n                                     x_col='file_paths',\n                                     y_col='labels_str',\n                                     image_data_generator=test_datagen,\n                                     seed=Config.SEED,\n                                     batch_size=Config.BATCH_SIZE,\n                                     class_mode=Config.CLASS_MODE,\n                                     color_mode=Config.COLOR_MODE,\n                                     target_size=Config.TARGET_SIZE,  \n                                    )\n\n    test_generator = PNGDataFrameIterator(dataframe=dftestIter,\n                                     x_col='file_paths',\n                                     y_col='labels_str',\n                                     image_data_generator=test_datagen,\n                                     seed=Config.SEED,\n                                     batch_size=Config.BATCH_SIZE,\n                                     class_mode=Config.CLASS_MODE,\n                                     color_mode=Config.COLOR_MODE,\n                                     target_size=Config.TARGET_SIZE,  \n                                    )\n    model_resnet = tf.keras.applications.ResNet50(weights='imagenet',\n                                              input_shape=(Config.IMG_SIZE, Config.IMG_SIZE, 3),\n                                              include_top=False)\n    model_effnetb0 = tf.keras.applications.EfficientNetB0(\n                                                    weights='imagenet',\n                                                  input_shape=(Config.IMG_SIZE, Config.IMG_SIZE, 3),\n                                                  include_top=False)\n\n    model_deep = model_resnet\n    \n    \n    # Congela camadas pré-treinadas\n#     for layer in model_deep.layers:\n#         layer.trainable = False\n        \n    # Congela todas as camadas exceto as ultimas\n    for layer in model_deep.layers[:143]:\n#     for layer in model_deep.layers[:165]:\n        layer.trainable = False\n\n    # Debug - checa qual layer está congelado    \n#     for i, layer in enumerate(model_deep.layers):\n#         print( i, layer.name, \"-\" ,layer.trainable)\n        \n        \n    x = layers.GlobalMaxPooling2D()(model_deep.output)\n#     x = layers.Flatten()(model_deep.output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(32, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dense(32, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.BatchNormalization()(x)\n#     x = layers.Dense(128, activation='relu')(x)\n#     x = layers.Dropout(0.5)(x)\n#     x = layers.BatchNormalization()(x)\n    out = layers.Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=model_deep.input, outputs=out)\n\n    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n\n#     model.summary()\n    \n    model_checkpoint = ModelCheckpoint('../working/resnet2d_congelada_' + exam + '.hdf5', \n                                       monitor='val_loss',verbose=1, \n                                       save_best_only=True)\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                      patience=10,\n                                                      restore_best_weights=True)\n    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=Config.TENSORBOARD_LOG_DIR,\n                                                histogram_freq=1,\n                                                )\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                                       patience=2, min_lr=1e-7,\n                                      verbose=1)\n    #model_ResNet50_2d.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    model.compile(loss='binary_crossentropy', optimizer=opt, \n                              metrics=[tf.keras.metrics.BinaryAccuracy(),\n                                       tf.keras.metrics.AUC(from_logits=False)] )\n    \n\n    dftrainIter_dict[exam] = dftrainIter\n    dfvalIter_dict[exam] = dfvalIter\n    dftestIter_dict[exam] = dftestIter \n    train_gen_dict[exam] = train_generator\n    val_gen_dict[exam] = val_generator\n    test_gen_dict[exam] = test_generator\n    model_check_dict[exam] = model_checkpoint\n    model_dict[exam] = model","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:34:36.951924Z","iopub.execute_input":"2021-12-19T14:34:36.952346Z","iopub.status.idle":"2021-12-19T14:36:25.145224Z","shell.execute_reply.started":"2021-12-19T14:34:36.952311Z","shell.execute_reply":"2021-12-19T14:36:25.143654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dict","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:36:25.146563Z","iopub.execute_input":"2021-12-19T14:36:25.146845Z","iopub.status.idle":"2021-12-19T14:36:25.153355Z","shell.execute_reply.started":"2021-12-19T14:36:25.146807Z","shell.execute_reply":"2021-12-19T14:36:25.152544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NUM_EPOCHS = 6 * 5 #Should take ~1hr to run for each 5 epochs\n# history_dict = {}\n# for exam in exam_list:\n#     history_dict[exam] = model_dict[exam].fit(train_gen_dict[exam],\n#                                     validation_data=val_gen_dict[exam],\n#                                     epochs = NUM_EPOCHS,\n#                                     verbose = 1,\n#                                     callbacks=[\n#                                         early_stopping, \n#                                         model_check_dict[exam],\n#                                         reduce_lr,\n#                                               ]\n#                                     )","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:36:25.154729Z","iopub.execute_input":"2021-12-19T14:36:25.155249Z","iopub.status.idle":"2021-12-19T14:36:25.162653Z","shell.execute_reply.started":"2021-12-19T14:36:25.15521Z","shell.execute_reply":"2021-12-19T14:36:25.161877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for exam in exam_list:\n#     history = history_dict[exam]\n#     plt.plot(history.history['loss'])\n#     plt.plot(history.history['val_loss'])\n#     plt.title('model loss')\n#     plt.ylabel('loss')\n#     plt.xlabel('epoch')\n#     plt.legend(['train', 'val'], loc='upper left')\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:36:25.164082Z","iopub.execute_input":"2021-12-19T14:36:25.164453Z","iopub.status.idle":"2021-12-19T14:36:25.171706Z","shell.execute_reply.started":"2021-12-19T14:36:25.164415Z","shell.execute_reply":"2021-12-19T14:36:25.170912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Loading previously trained resnets (5 epochs for now)\n!ls ../input/rsna-miccai-resnet50-4exams-5epochs/resnet2d_congelada_' + exam + '.hdf5'\nfor exam in exam_list:\n    model_dict[exam].load_weights('../input/rsna-miccai-resnet50-4exams-5epochs/resnet2d_congelada_' + exam + '.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:36:25.173258Z","iopub.execute_input":"2021-12-19T14:36:25.173549Z","iopub.status.idle":"2021-12-19T14:36:32.884226Z","shell.execute_reply.started":"2021-12-19T14:36:25.173512Z","shell.execute_reply":"2021-12-19T14:36:32.883371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_dict = {}\nfor exam in exam_list:\n    print('Computing prediction for ' + exam + '...')\n    test_pred = model_dict[exam].predict(test_gen_dict[exam], steps=len(test_gen_dict[exam]))\n    dftestIter_dict[exam]['pred_y'] = test_pred\n    mean_pred = test_pred.mean()\n    test_pred_agg = dftestIter_dict[exam].groupby('patient_ids').apply(\n        lambda x: x['pred_y'].max()\n        if (x['pred_y'].max() - mean_pred) > (mean_pred - x['pred_y'].min()) \n        else x['pred_y'].min()\n    )\n    test_pred_dict[exam] = test_pred_agg\nprint('done!')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:36:32.885845Z","iopub.execute_input":"2021-12-19T14:36:32.886119Z","iopub.status.idle":"2021-12-19T14:37:38.581547Z","shell.execute_reply.started":"2021-12-19T14:36:32.886082Z","shell.execute_reply":"2021-12-19T14:37:38.580014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_dict","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:37:38.583083Z","iopub.execute_input":"2021-12-19T14:37:38.583334Z","iopub.status.idle":"2021-12-19T14:37:38.593411Z","shell.execute_reply.started":"2021-12-19T14:37:38.5833Z","shell.execute_reply":"2021-12-19T14:37:38.592639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nns_probs = [0 for _ in range(len(df_test.MGMT_value))]\nprint(exam_list)\nfor exam in exam_list:\n    ns_probs = [0 for _ in range(len(df_test.MGMT_value))]\n    y_label = df_test.MGMT_value\n    y_pred  = test_pred_dict[exam]\n    ns_auc = roc_auc_score(y_label, ns_probs)\n    lr_auc = roc_auc_score(y_label, y_pred)\n    print('No skill: ROC AUC=%.3f' % (ns_auc))\n    print('CNN: ROC AUC=%.3f' % (lr_auc))\n    lr_fpr, lr_tpr, _ = roc_curve(y_label, y_pred)\n    plt.plot(lr_fpr, lr_tpr, marker='.', label='CNN')\n\n    ns_fpr, ns_tpr, _ = roc_curve(y_label, ns_probs)\n    plt.plot(ns_fpr, ns_tpr, marker='.', label='No Skill')\n\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:37:38.594942Z","iopub.execute_input":"2021-12-19T14:37:38.595392Z","iopub.status.idle":"2021-12-19T14:37:39.310507Z","shell.execute_reply.started":"2021-12-19T14:37:38.595342Z","shell.execute_reply":"2021-12-19T14:37:39.309805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Combining predictions\ntest_pred_exam_agg = np.zeros(len(df_test.MGMT_value))\nfor exam in exam_list:\n#     if exam is 'flair' or exam is 't2w':\n#         pass\n#     else:\n# #         test_pred_exam_agg = test_pred_exam_agg + test_pred_dict[exam]\n#         test_pred_exam_agg = np.maximum( test_pred_exam_agg , test_pred_dict[exam] )\n     test_pred_exam_agg = np.maximum( test_pred_exam_agg , test_pred_dict[exam] )\n# test_pred_exam_agg = test_pred_exam_agg / 4\ntest_pred_exam_agg\n\nns_probs = [0 for _ in range(len(df_test.MGMT_value))]\ny_label = df_test.MGMT_value\ny_pred  = test_pred_exam_agg\nns_auc = roc_auc_score(y_label, ns_probs)\nlr_auc = roc_auc_score(y_label, y_pred)\nprint('No skill: ROC AUC=%.3f' % (ns_auc))\nprint('CNN: ROC AUC=%.3f' % (lr_auc))\nlr_fpr, lr_tpr, _ = roc_curve(y_label, y_pred)\nplt.plot(lr_fpr, lr_tpr, marker='.', label='CNN')\n\nns_fpr, ns_tpr, _ = roc_curve(y_label, ns_probs)\nplt.plot(ns_fpr, ns_tpr, marker='.', label='No Skill')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:37:39.311676Z","iopub.execute_input":"2021-12-19T14:37:39.312499Z","iopub.status.idle":"2021-12-19T14:37:39.496604Z","shell.execute_reply.started":"2021-12-19T14:37:39.312458Z","shell.execute_reply":"2021-12-19T14:37:39.495902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred_dict = {}\nfor exam in exam_list:\n    print('Computing prediction for ' + exam + '...')\n    val_pred = model_dict[exam].predict(val_gen_dict[exam], steps=len(val_gen_dict[exam]))\n    dfvalIter_dict[exam]['pred_y'] = val_pred\n    mean_pred = val_pred.mean()\n    val_pred_agg = dfvalIter_dict[exam].groupby('patient_ids').apply(\n        lambda x: x['pred_y'].max()\n        if (x['pred_y'].max() - mean_pred) > (mean_pred - x['pred_y'].min()) \n        else x['pred_y'].min()\n    )\n    val_pred_dict[exam] = val_pred_agg\nprint('done!')\n\nval_pred_dict\n\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nns_probs = [0 for _ in range(len(df_val.MGMT_value))]\nprint(exam_list)\nfor exam in exam_list:\n    ns_probs = [0 for _ in range(len(df_val.MGMT_value))]\n    y_label = df_val.MGMT_value\n    y_pred  = val_pred_dict[exam]\n    ns_auc = roc_auc_score(y_label, ns_probs)\n    lr_auc = roc_auc_score(y_label, y_pred)\n    print('No skill: ROC AUC=%.3f' % (ns_auc))\n    print('CNN: ROC AUC=%.3f' % (lr_auc))\n    lr_fpr, lr_tpr, _ = roc_curve(y_label, y_pred)\n    plt.plot(lr_fpr, lr_tpr, marker='.', label='CNN')\n\n    ns_fpr, ns_tpr, _ = roc_curve(y_label, ns_probs)\n    plt.plot(ns_fpr, ns_tpr, marker='.', label='No Skill')\n\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.show()\n\n#Combining predictions\nval_pred_exam_agg = np.zeros(len(df_val.MGMT_value))\nfor exam in exam_list:\n#     if exam is 'flair' or exam is 't2w':\n#         pass\n#     else:\n# #         val_pred_exam_agg = val_pred_exam_agg + val_pred_dict[exam]\n#         val_pred_exam_agg = np.maximum( val_pred_exam_agg , val_pred_dict[exam] )\n     val_pred_exam_agg = np.maximum( val_pred_exam_agg , val_pred_dict[exam] )\n# val_pred_exam_agg = val_pred_exam_agg / 4\nval_pred_exam_agg\n\nns_probs = [0 for _ in range(len(df_val.MGMT_value))]\ny_label = df_val.MGMT_value\ny_pred  = val_pred_exam_agg\nns_auc = roc_auc_score(y_label, ns_probs)\nlr_auc = roc_auc_score(y_label, y_pred)\nprint('No skill: ROC AUC=%.3f' % (ns_auc))\nprint('CNN: ROC AUC=%.3f' % (lr_auc))\nlr_fpr, lr_tpr, _ = roc_curve(y_label, y_pred)\nplt.plot(lr_fpr, lr_tpr, marker='.', label='CNN')\n\nns_fpr, ns_tpr, _ = roc_curve(y_label, ns_probs)\nplt.plot(ns_fpr, ns_tpr, marker='.', label='No Skill')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:37:39.497966Z","iopub.execute_input":"2021-12-19T14:37:39.498409Z","iopub.status.idle":"2021-12-19T14:38:45.388325Z","shell.execute_reply.started":"2021-12-19T14:37:39.498369Z","shell.execute_reply":"2021-12-19T14:38:45.387597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\ndef get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\n\ndef save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.5):\n    # Load the original image\n#     img = keras.preprocessing.image.load_img(img_path)\n#     img = keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n#     display(Image(cam_path))\n\n\n\n\ndef gradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=None,\n           last_conv_layer_name='conv5_block3_3_conv',\n           output_prefix = None):\n\n    # Prepare image\n    if model is None:\n        model_builder = keras.applications.ResNet50\n        model = model_builder(weights=\"imagenet\")\n    \n    \n    img_size = (Config.IMG_SIZE, Config.IMG_SIZE)\n\n    for i, img_path in enumerate(files_paths):\n        # The local path to our target image\n        img_array = preprocess_input(get_img_array(img_path, size=img_size))\n\n        model.layers[-1].activation = None\n\n        # Generate class activation heatmap\n        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n        \n\n        output_path = '../working/gradCam_out_' + output_prefix + '_' + str(i) +'.png'\n        \n        save_and_display_gradcam(img_array[0], heatmap, output_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:45.389528Z","iopub.execute_input":"2021-12-19T14:38:45.389784Z","iopub.status.idle":"2021-12-19T14:38:45.409216Z","shell.execute_reply.started":"2021-12-19T14:38:45.38975Z","shell.execute_reply":"2021-12-19T14:38:45.408404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_paths = [\n    '../input/rsna-miccai-png/train/00000/FLAIR/Image-242.png',\n    '../input/rsna-miccai-png/train/00045/FLAIR/Image-116.png',\n     '../input/rsna-miccai-png/train/00133/FLAIR/Image-35.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['flair'],\n            output_prefix = 'flair'\n           )","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:45.410636Z","iopub.execute_input":"2021-12-19T14:38:45.410918Z","iopub.status.idle":"2021-12-19T14:38:46.242856Z","shell.execute_reply.started":"2021-12-19T14:38:45.410885Z","shell.execute_reply":"2021-12-19T14:38:46.24208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_paths = [\n    '../input/rsna-miccai-png/train/00000/T2w/Image-126.png',\n    '../input/rsna-miccai-png/train/00045/T2w/Image-323.png',\n     '../input/rsna-miccai-png/train/00133/T2w//Image-19.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t2w'],\n            output_prefix = 't2w'\n           )","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:46.24417Z","iopub.execute_input":"2021-12-19T14:38:46.244413Z","iopub.status.idle":"2021-12-19T14:38:46.622699Z","shell.execute_reply.started":"2021-12-19T14:38:46.244379Z","shell.execute_reply":"2021-12-19T14:38:46.621935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_paths = [\n    '../input/rsna-miccai-png/train/00000/T1wCE/Image-78.png',\n    '../input/rsna-miccai-png/train/00045/T1wCE/Image-77.png',\n     '../input/rsna-miccai-png/train/00133/T1wCE//Image-35.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1wce'],\n            output_prefix = 't1wce'\n           )","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:46.626771Z","iopub.execute_input":"2021-12-19T14:38:46.626971Z","iopub.status.idle":"2021-12-19T14:38:47.016322Z","shell.execute_reply.started":"2021-12-19T14:38:46.626946Z","shell.execute_reply":"2021-12-19T14:38:47.015603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_paths = [\n    '../input/rsna-miccai-png/train/00478/FLAIR/Image-100.png',\n    '../input/rsna-miccai-png/train/00478/FLAIR/Image-105.png',\n     '../input/rsna-miccai-png/train/00478/FLAIR/Image-113.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['flair'],\n            output_prefix = 'flair_00478'\n           )","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:47.017627Z","iopub.execute_input":"2021-12-19T14:38:47.017891Z","iopub.status.idle":"2021-12-19T14:38:47.378614Z","shell.execute_reply.started":"2021-12-19T14:38:47.017856Z","shell.execute_reply":"2021-12-19T14:38:47.377873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_paths = [\n    '../input/rsna-miccai-png/train/00197/T1wCE/Image-105.png',\n    '../input/rsna-miccai-png/train/00197/T1wCE/Image-110.png',\n     '../input/rsna-miccai-png/train/00197/T1wCE/Image-118.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1wce'],\n            output_prefix = 't1wce_00197'\n           )\n\n#!rm -f \nfiles_paths = [\n    '../input/rsna-miccai-png/train/00011/T1wCE/Image-48.png',\n    '../input/rsna-miccai-png/train/00011/T1wCE/Image-55.png',\n     '../input/rsna-miccai-png/train/00011/T1wCE/Image-66.png',\n     '../input/rsna-miccai-png/train/00011/T1wCE/Image-86.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1wce'],\n            output_prefix = 't1wce_00011'\n           )\n\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00500/T1wCE/Image-196.png',\n    '../input/rsna-miccai-png/train/00500/T1wCE/Image-216.png',\n     '../input/rsna-miccai-png/train/00500/T1wCE/Image-232.png',\n     '../input/rsna-miccai-png/train/00500/T1wCE/Image-252.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1wce'],\n            output_prefix = 't1wce_00500'\n           )\n\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00011/T1wCE/Image-48.png',\n    '../input/rsna-miccai-png/train/00011/T1wCE/Image-55.png',\n     '../input/rsna-miccai-png/train/00011/T1wCE/Image-66.png',\n     '../input/rsna-miccai-png/train/00011/T1wCE/Image-86.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['flair'],\n            output_prefix = 's_t1wce_m_flair_00011'\n           )\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:47.379977Z","iopub.execute_input":"2021-12-19T14:38:47.380217Z","iopub.status.idle":"2021-12-19T14:38:49.256291Z","shell.execute_reply.started":"2021-12-19T14:38:47.380184Z","shell.execute_reply":"2021-12-19T14:38:49.255575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ruim\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00500/FLAIR/Image-84.png',\n    '../input/rsna-miccai-png/train/00500/FLAIR/Image-104.png',\n     '../input/rsna-miccai-png/train/00500/FLAIR/Image-146.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['flair'],\n            output_prefix = 'flair_00500'\n           )\n\n#bom\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00201/FLAIR/Image-22.png',\n    '../input/rsna-miccai-png/train/00201/FLAIR/Image-26.png',\n     '../input/rsna-miccai-png/train/00201/FLAIR/Image-36.png',\n     '../input/rsna-miccai-png/train/00201/FLAIR/Image-42.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['flair'],\n            output_prefix = 'flair_00201'\n           )\n\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00201/FLAIR/Image-22.png',\n    '../input/rsna-miccai-png/train/00201/FLAIR/Image-26.png',\n     '../input/rsna-miccai-png/train/00201/FLAIR/Image-36.png',\n     '../input/rsna-miccai-png/train/00201/FLAIR/Image-42.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1wce'],\n            output_prefix = 's_flair_m_t1wce_00201'\n           )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:49.257657Z","iopub.execute_input":"2021-12-19T14:38:49.257923Z","iopub.status.idle":"2021-12-19T14:38:50.598886Z","shell.execute_reply.started":"2021-12-19T14:38:49.257889Z","shell.execute_reply":"2021-12-19T14:38:50.597954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls\n# !rm *.png","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:50.60032Z","iopub.execute_input":"2021-12-19T14:38:50.600847Z","iopub.status.idle":"2021-12-19T14:38:50.606868Z","shell.execute_reply.started":"2021-12-19T14:38:50.600807Z","shell.execute_reply":"2021-12-19T14:38:50.606167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bem ruim\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00066/T1w/Image-11.png',\n    '../input/rsna-miccai-png/train/00066/T1w/Image-18.png',\n     '../input/rsna-miccai-png/train/00066/T1w/Image-20.png',\n     '../input/rsna-miccai-png/train/00066/T1w/Image-24.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1w'],\n            output_prefix = 't1w_00066'\n           )\n\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00414/T1w/Image-102.png',\n    '../input/rsna-miccai-png/train/00414/T1w/Image-115.png',\n     '../input/rsna-miccai-png/train/00414/T1w/Image-94.png',\n     '../input/rsna-miccai-png/train/00414/T1w/Image-89.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t1w'],\n            output_prefix = 't1w_00414'\n           )\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:50.609785Z","iopub.execute_input":"2021-12-19T14:38:50.611861Z","iopub.status.idle":"2021-12-19T14:38:51.751722Z","shell.execute_reply.started":"2021-12-19T14:38:50.611823Z","shell.execute_reply":"2021-12-19T14:38:51.750977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_paths = [\n    '../input/rsna-miccai-png/train/00094/T2w/Image-128.png',\n    '../input/rsna-miccai-png/train/00094/T2w/Image-224.png',\n     '../input/rsna-miccai-png/train/00094/T2w/Image-281.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t2w'],\n            output_prefix = 't2w_00094'\n           )\n\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00191/T2w/Image-48.png',\n    '../input/rsna-miccai-png/train/00191/T2w/Image-38.png',\n     '../input/rsna-miccai-png/train/00191/T2w/Image-32.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t2w'],\n            output_prefix = 't2w_00191'\n           )\n\nfiles_paths = [\n    '../input/rsna-miccai-png/train/00298/T2w/Image-31.png',\n    '../input/rsna-miccai-png/train/00298/T2w/Image-35.png',\n     '../input/rsna-miccai-png/train/00298/T2w/Image-40.png',\n     '../input/rsna-miccai-png/train/00298/T2w/Image-47.png',\n    \n]\ngradCAM(files_paths, \n            preprocess_input=keras.applications.resnet50.preprocess_input,\n            model=model_dict['t2w'],\n            output_prefix = 't2w_00298'\n           )\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:51.752933Z","iopub.execute_input":"2021-12-19T14:38:51.754996Z","iopub.status.idle":"2021-12-19T14:38:53.131314Z","shell.execute_reply.started":"2021-12-19T14:38:51.754963Z","shell.execute_reply":"2021-12-19T14:38:53.13053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_dict['t1w'].head(50)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:53.132495Z","iopub.execute_input":"2021-12-19T14:38:53.133188Z","iopub.status.idle":"2021-12-19T14:38:53.14612Z","shell.execute_reply.started":"2021-12-19T14:38:53.133149Z","shell.execute_reply":"2021-12-19T14:38:53.144034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r gradcam_pngs.zip *png","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:53.148262Z","iopub.execute_input":"2021-12-19T14:38:53.148571Z","iopub.status.idle":"2021-12-19T14:38:54.178592Z","shell.execute_reply.started":"2021-12-19T14:38:53.148531Z","shell.execute_reply":"2021-12-19T14:38:54.177697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'gradcam_pngs.zip')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T14:38:54.180536Z","iopub.execute_input":"2021-12-19T14:38:54.180826Z","iopub.status.idle":"2021-12-19T14:38:54.187147Z","shell.execute_reply.started":"2021-12-19T14:38:54.180779Z","shell.execute_reply":"2021-12-19T14:38:54.18632Z"},"trusted":true},"execution_count":null,"outputs":[]}]}