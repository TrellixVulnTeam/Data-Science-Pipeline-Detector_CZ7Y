{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\n'''\n================================================\n加载模型\n================================================\n'''\ngpu = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\nnet = torch.load('../input/trainedmodel/res.pt', map_location=gpu)\n\n# print(next(net.parameters()).device)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:22:31.678714Z","iopub.execute_input":"2021-07-27T14:22:31.679074Z","iopub.status.idle":"2021-07-27T14:22:31.793062Z","shell.execute_reply.started":"2021-07-27T14:22:31.679041Z","shell.execute_reply":"2021-07-27T14:22:31.792186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport random\nimport numpy as np\nimport cv2\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\nfrom matplotlib import pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\npath = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n\n'''\n================================================\n加载数据：读取dicom数据->数据增强->每个个人的四种数据合成一个样本->Dataset->DataLoader\n================================================\n'''\n'''1-1, 数据增强'''\nsometimes = lambda aug: iaa.Sometimes(0.2, aug)\nseq = iaa.Sequential(\n    [\n        iaa.Fliplr(0.5),    #水平翻转\n        iaa.Flipud(0.2),    #竖直翻转\n        sometimes(iaa.CropAndPad(\n            percent=(-0.05, 0.05),  # crop images by -5% to 10% of their height/width\n            pad_mode=ia.ALL,\n            pad_cval=(0, 255)\n        )),\n        sometimes(iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},   # scale images to 80-120% of their size, individually per axis\n            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n            rotate=(-45, 45),   # rotate by -45 to +45 degrees\n            shear=(-16, 16),    # shear by -16 to +16 degrees\n            order=[0, 1],   # use nearest neighbour or bilinear interpolation (fast)\n            cval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n            mode=ia.ALL     #use any of scikit-image's warping modes (see 2nd image from the top for examples)\n        )),\n        # execute 0 to 5 of the following (less important) augmenters per image\n        # don't execute all of them, as that would often be way too strong\n        iaa.SomeOf((0, 5),\n                   [\n                       sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))),\n                       # convert images into their superpixel representation\n                       iaa.OneOf([\n                           iaa.GaussianBlur((0, 3.0)),  # blur images with a sigma between 0 and 3.0\n                           iaa.AverageBlur(k=(2, 7)),  # blur image using local means with kernel sizes between 2 and 7\n                           iaa.MedianBlur(k=(3, 11)),\n                           # blur image using local medians with kernel sizes between 2 and 7\n                       ]),\n                       iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),  # sharpen images\n                       iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),  # emboss images\n                       # search either for all edges or for directed edges,\n                       # blend the result with the original image using a blobby mask\n                       iaa.SimplexNoiseAlpha(iaa.OneOf([\n                           iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                           iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n                       ])),\n                       iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05 * 255), per_channel=0.5),\n                       # add gaussian noise to images\n                       iaa.OneOf([\n                           iaa.Dropout((0.01, 0.1), per_channel=0.5),  # randomly remove up to 10% of the pixels\n                           iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n                       ]),\n                       iaa.Invert(0.05, per_channel=True),  # invert color channels\n                       iaa.Add((-10, 10), per_channel=0.5),\n                       # change brightness of images (by -10 to 10 of original value)\n\n                       # either change the brightness of the whole image (sometimes\n                       # per channel) or change the brightness of subareas\n                       iaa.OneOf([\n                           iaa.Multiply((0.5, 1.5), per_channel=0.5),\n                           iaa.FrequencyNoiseAlpha(\n                               exponent=(-4, 0),\n                               first=iaa.Multiply((0.5, 1.5), per_channel=True),\n                               second=iaa.LinearContrast((0.5, 2.0))\n                           )\n                       ]),\n                       iaa.LinearContrast((0.5, 2.0), per_channel=0.5),  # improve or worsen the contrast\n                       sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)),\n                       # move pixels locally around (with random strengths)\n                       sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),  # sometimes move parts of the image around\n                       sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n                   ],\n                   random_order=True\n                   )\n    ],\n    random_order=True\n)\n\n'''1-2, 将dcm数据转换为numpy.array，利用seq并进行数据增强'''\ndef dicom2array(paths, voi_lut=True, fix_monochrome=True, remove_black_boundary=True, aug=False):\n    for path in paths:\n        dicom = pydicom.read_file(path)\n        # VOI LUT (if available by DICOM device) is used to\n        # transform raw DICOM data to \"human-friendly\" view\n        if voi_lut:\n            data = apply_voi_lut(dicom.pixel_array, dicom)\n        else:\n            data = dicom.pixel_array\n        if data.max() > 0.0:  # avoiding black images (if possible)\n            break\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    if remove_black_boundary:  # we get slightly more details\n        (x, y) = np.where(data > 0)\n        if len(x) > 0 and len(y) > 0:\n            x_mn = np.min(x)\n            x_mx = np.max(x)\n            y_mn = np.min(y)\n            y_mx = np.max(y)\n            if (x_mx - x_mn) > 10 and (y_mx - y_mn) > 10:\n                data = data[:, np.min(y):np.max(y)]\n    data = cv2.resize(data, (512, 512))\n    if aug:\n        data = seq(images=data)\n    return data\n\n'''1-3, 借助于dicom2array加载数据，并且将每一个病患的四类数据合成一个样本'''\ndef load_rand_dicom_images(scan_id, split=\"train\", aug=False):\n    \"\"\"\n    send 4 random slices of each modality\n    \"\"\"\n    if split != \"train\" and split != \"test\":\n        split = \"train\"\n    flair = sorted(glob.glob(f\"{path}/{split}/{scan_id}/FLAIR/*.dcm\"))\n    flair_img = dicom2array(random.sample(flair, max(len(flair) // 2, 1)), aug=aug)\n    t1w = sorted(glob.glob(f\"{path}/{split}/{scan_id}/T1w/*.dcm\"))\n    t1w_img = dicom2array(random.sample(t1w, max(len(t1w) // 2, 1)), aug=aug)\n    t1wce = sorted(glob.glob(f\"{path}/{split}/{scan_id}/T1wCE/*.dcm\"))\n    t1wce_img = dicom2array(random.sample(t1wce, max(len(t1wce) // 2, 1)), aug=aug)\n    t2w = sorted(glob.glob(f\"{path}/{split}/{scan_id}/T2w/*.dcm\"))\n    t2w_img = dicom2array(random.sample(t2w, max(len(t2w) // 2, 1)), aug=aug)\n\n    return np.array((flair_img, t1w_img, t1wce_img, t2w_img)).T\n\n# '''测试'''\n# data = load_rand_dicom_images(\"00001\", split='test')\n# print(data.shape)\n# for i in range(4):\n#     plt.imshow(data[:, :, i])\n#     plt.pause(0.01)\n# plt.show()\n\n'''1-4,Dataset'''\nclass BrainTumor(Dataset):\n    def __init__(self):\n        super().__init__()\n        self.ids = [a.split(\"/\")[-1] for a in sorted(glob.glob(path + f\"/test/\" + \"/*\"))]\n    def __len__(self):\n        return len(self.ids)\n    def __getitem__(self, idx):\n        imgs = load_rand_dicom_images(self.ids[idx], 'test', aug=False)\n        transform = transforms.Compose(\n            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5, 0.5), (0.5, 0.5, 0.5, 0.5))])\n        imgs = transform(imgs)\n        return torch.tensor(imgs, dtype=torch.float32)\n    \n'''1-5, dataloader'''\ntest_bs = 16\ntest_dataset = BrainTumor()\ntest_loader = DataLoader(test_dataset, batch_size=test_bs, num_workers=4)\n\n# '''测试'''\n# for img in test_loader:\n#     print(img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:22:31.79489Z","iopub.execute_input":"2021-07-27T14:22:31.795233Z","iopub.status.idle":"2021-07-27T14:22:31.834058Z","shell.execute_reply.started":"2021-07-27T14:22:31.795197Z","shell.execute_reply":"2021-07-27T14:22:31.833162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n'''\n================================================\n获取结果\n================================================\n'''\n'''加载样例'''\ndf = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv',dtype=\"string\")\n# print(df)\n# assert None\n\n'''使用训练好的网络填充结果'''\nn = 0\nfor data in test_loader:\n    res = net(data.to(gpu))\n#     print(res)\n#     print((res[:, 0] / res.sum(dim=1)).detach().numpy())\n    df['MGMT_value'][n*test_bs: (n+1)*test_bs] = [f'{i}' for i in (res[:, 0] / res.sum(dim=1)).detach().cpu().numpy()]\n    n+=1\n#     print(df)\n\n'''保存'''\ndf.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:22:31.835858Z","iopub.execute_input":"2021-07-27T14:22:31.836488Z","iopub.status.idle":"2021-07-27T14:22:41.864981Z","shell.execute_reply.started":"2021-07-27T14:22:31.836452Z","shell.execute_reply":"2021-07-27T14:22:41.864063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pd.read_csv('submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:22:41.866603Z","iopub.execute_input":"2021-07-27T14:22:41.866968Z","iopub.status.idle":"2021-07-27T14:22:41.880488Z","shell.execute_reply.started":"2021-07-27T14:22:41.866922Z","shell.execute_reply":"2021-07-27T14:22:41.879485Z"},"trusted":true},"execution_count":null,"outputs":[]}]}