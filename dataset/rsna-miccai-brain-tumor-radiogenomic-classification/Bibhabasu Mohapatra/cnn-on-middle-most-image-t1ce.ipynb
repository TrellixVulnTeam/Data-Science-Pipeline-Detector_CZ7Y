{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-03-22T16:45:55.354345Z","iopub.execute_input":"2022-03-22T16:45:55.354775Z","iopub.status.idle":"2022-03-22T16:46:07.770076Z","shell.execute_reply.started":"2022-03-22T16:45:55.354676Z","shell.execute_reply":"2022-03-22T16:46:07.768872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport timm\nimport albumentations\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom torch.utils.data import Dataset, DataLoader\nfrom skimage import io, color","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-22T16:46:07.773842Z","iopub.execute_input":"2022-03-22T16:46:07.774147Z","iopub.status.idle":"2022-03-22T16:46:12.990466Z","shell.execute_reply.started":"2022-03-22T16:46:07.774102Z","shell.execute_reply":"2022-03-22T16:46:12.989407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BratsDataset(Dataset):\n    def __init__(self, image_path, MGMT_value, transforms=None):\n        self.image_path = image_path\n        self.MGMT_value = MGMT_value\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_path)\n    \n    def __getitem__(self, item):\n        image = io.imread(self.image_path[item])\n        MGMT_value = self.MGMT_value[item]\n        \n        image = color.gray2rgb(image)\n\n        if self.transforms is not None:\n            augmented = self.transforms(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            'image': torch.tensor(image, dtype=torch.float),\n            'targets': torch.tensor(MGMT_value, dtype=torch.float)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T16:46:12.99262Z","iopub.execute_input":"2022-03-22T16:46:12.992966Z","iopub.status.idle":"2022-03-22T16:46:13.004591Z","shell.execute_reply.started":"2022-03-22T16:46:12.992913Z","shell.execute_reply":"2022-03-22T16:46:13.002814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,train_loader,device,optimizer):\n    model.train()\n    running_train_loss = 0.0\n    for data in train_loader:\n        inputs = data['image']\n        targets = data['targets']\n\n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        running_train_loss +=loss.item()\n        \n    train_loss_value = running_train_loss/len(train_loader)\n    print(f'train BCE loss is {train_loss_value}')\n    \ndef eval(model,valid_loader,device,optimizer):\n    model.eval()\n    final_targets = []\n    final_outputs = []\n    running_val_loss = 0.0\n    with torch.no_grad():\n        for data in valid_loader:\n            inputs = data['image']\n            targets = data['targets']\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n\n            output = model(inputs)\n            running_val_loss += nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            targets = (targets.detach().cpu().numpy()).tolist()\n            output = (torch.sigmoid(output).detach().cpu().numpy()).tolist()\n            final_outputs.extend(output)\n            final_targets.extend(targets)\n        val_loss = running_val_loss/len(valid_loader)    \n        print(f'valid BCE loss is {val_loss}')\n    return final_outputs,final_targets","metadata":{"execution":{"iopub.status.busy":"2022-03-22T16:46:13.00778Z","iopub.execute_input":"2022-03-22T16:46:13.008443Z","iopub.status.idle":"2022-03-22T16:46:13.022608Z","shell.execute_reply.started":"2022-03-22T16:46:13.008397Z","shell.execute_reply":"2022-03-22T16:46:13.021442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nmodel_name = 'swin_base_patch4_window7_224'\n\nout_dim    = 1\n\nclass get_model(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=True)\n        self.model.head = nn.Sequential(nn.Linear(self.model.head.in_features,768),\n                                              nn.Linear(768,256))\n        self.last = nn.Linear(256, 128)\n        self.depth1 = nn.Linear(128,64)\n        self.depth2 = nn.Linear(64,1)\n    def forward(self, image):\n        x = self.model(image)\n        x = self.last(x)\n        x = self.depth1(x)\n        x = self.depth2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-22T16:46:13.024414Z","iopub.execute_input":"2022-03-22T16:46:13.025171Z","iopub.status.idle":"2022-03-22T16:46:13.037474Z","shell.execute_reply.started":"2022-03-22T16:46:13.025114Z","shell.execute_reply":"2022-03-22T16:46:13.036431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloaders","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/train-png-middlecsv/train_rsna_png_T1wCE.csv')\n\ndf_train, df_valid = train_test_split(df, test_size = 0.3, stratify=df.MGMT_value)\n\nimage_path_train = df_train.path.values.tolist()\nimage_path_valid = df_valid.path.values.tolist()\n\naug = albumentations.Compose(\n[   albumentations.Resize(224, 224, p=1),\n    albumentations.Normalize(\n    (0.485, 0.456, 0.406),(0.229, 0.224, 0.225),max_pixel_value=255.0,always_apply=True)\n])\ntrain_dataset = BratsDataset(image_path_train, df_train.MGMT_value.values, transforms=aug )\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n\nvalid_dataset = BratsDataset(image_path_valid, df_valid.MGMT_value.values, transforms=aug )\nvalid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T16:46:13.039451Z","iopub.execute_input":"2022-03-22T16:46:13.039946Z","iopub.status.idle":"2022-03-22T16:46:13.075009Z","shell.execute_reply.started":"2022-03-22T16:46:13.039904Z","shell.execute_reply":"2022-03-22T16:46:13.074149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\ndevice = 'cuda'\n\nmodel = get_model()\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-6)\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=1, eta_min=1e-4, last_epoch=- 1, verbose=True)\n\nfor epoch in range(18):\n    print(f'==================== Epoch -- {epoch} ====================')\n    train(model=model,train_loader=train_loader,device=device,optimizer=optimizer)\n\n    final_outputs,final_targets = eval(model=model,valid_loader=valid_loader,device=device,optimizer=optimizer)\n    \n    final_outputs = list(chain.from_iterable(final_outputs))     \n    \n    ROC = np.sqrt(metrics.roc_auc_score(final_targets,final_outputs))\n#     scheduler.step()\n\n    print(f'valid ROC={ROC}')\n    \ntorch.save(model.state_dict(),'model-epoch'+'.pth')","metadata":{"execution":{"iopub.status.busy":"2022-03-22T16:53:31.229581Z","iopub.execute_input":"2022-03-22T16:53:31.229946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}