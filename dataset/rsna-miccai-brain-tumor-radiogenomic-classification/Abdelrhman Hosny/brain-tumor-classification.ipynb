{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# basics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom os.path import join\nimport sys\nfrom sklearn.model_selection import train_test_split\n# pytorch model\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\n\n# pyTorch Lightning\n\nimport pytorch_lightning as pl\nfrom torchmetrics import Accuracy\n\n# image processing\n\nfrom skimage.io import imread\nfrom scipy.ndimage import zoom # image resizing 3D\nfrom skimage.transform import resize\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-09T19:53:15.17498Z","iopub.status.idle":"2022-06-09T19:53:15.17566Z","shell.execute_reply.started":"2022-06-09T19:53:15.175385Z","shell.execute_reply":"2022-06-09T19:53:15.175418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Data","metadata":{}},{"cell_type":"code","source":"! mkdir my-train-data\nimport zipfile\nwith zipfile.ZipFile('../input/rsnabraintumorclassification-64-256-256/1MS8S5qFadxAqPCrd0MtKts4ciGH5W1L-', 'r') as zip_ref:\n    zip_ref.extractall('my-train-data')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:54:11.530269Z","iopub.execute_input":"2022-06-09T19:54:11.530631Z","iopub.status.idle":"2022-06-09T19:54:18.55689Z","shell.execute_reply.started":"2022-06-09T19:54:11.530598Z","shell.execute_reply":"2022-06-09T19:54:18.555385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm ./my-train-data/00109.pt ./my-train-data/00123.pt ./my-train-data/00709.pt","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:41.361499Z","iopub.execute_input":"2022-06-09T15:53:41.361795Z","iopub.status.idle":"2022-06-09T15:53:42.114241Z","shell.execute_reply.started":"2022-06-09T15:53:41.361758Z","shell.execute_reply":"2022-06-09T15:53:42.113423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Reading filenames**","metadata":{}},{"cell_type":"code","source":"INPUT_FOLDER = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\nINPUT_FOLDER_PNG = '../input/rsna-miccai-png'\n\nlabels_df = pd.read_csv(join(INPUT_FOLDER, 'train_labels.csv'))\nlabels_df = labels_df.sort_values('BraTS21ID')\npatients_train = os.listdir('my-train-data')\npatients_test = os.listdir(join(INPUT_FOLDER, 'test'))\n# removing examples with errors mentioned in discussion\n# erronous examples\nerror_examples = ['00109', '00123', '00709']\n\n# remove from directory list\n# for error in error_examples: patients_train.remove(error)\nlabels_df = labels_df[[ x not in [int(y) for y in error_examples ] for x in labels_df.BraTS21ID ]]\npatients_train.sort()\n\nprint(f'Number of train data : {len(patients_train)}\\nNumber of test data : {len(patients_test)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.117482Z","iopub.execute_input":"2022-06-09T15:53:42.117841Z","iopub.status.idle":"2022-06-09T15:53:42.191294Z","shell.execute_reply.started":"2022-06-09T15:53:42.117798Z","shell.execute_reply":"2022-06-09T15:53:42.190524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df['patient_folder'] = patients_train","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.193308Z","iopub.execute_input":"2022-06-09T15:53:42.193539Z","iopub.status.idle":"2022-06-09T15:53:42.201044Z","shell.execute_reply.started":"2022-06-09T15:53:42.193508Z","shell.execute_reply":"2022-06-09T15:53:42.200216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.202488Z","iopub.execute_input":"2022-06-09T15:53:42.202947Z","iopub.status.idle":"2022-06-09T15:53:42.227804Z","shell.execute_reply.started":"2022-06-09T15:53:42.202913Z","shell.execute_reply":"2022-06-09T15:53:42.22697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split Data to train and validation**","metadata":{}},{"cell_type":"code","source":"train_info = pd.DataFrame({'patient_id': patients_train, 'patient_label': labels_df.MGMT_value})\n\ntrain_info, val_info = train_test_split(train_info, test_size=0.18,\n                                        stratify=train_info.patient_label,\n                                        random_state=42\n                                       )\nprint(train_info.head())\nprint('------')\nprint(val_info.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.229188Z","iopub.execute_input":"2022-06-09T15:53:42.229437Z","iopub.status.idle":"2022-06-09T15:53:42.253179Z","shell.execute_reply.started":"2022-06-09T15:53:42.229403Z","shell.execute_reply":"2022-06-09T15:53:42.252365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Constant & Enums**","metadata":{}},{"cell_type":"code","source":"IMAGE_DEPTH = 64\nIMAGE_SIZE = [256, 256]\nIMAGE_DIMS = [IMAGE_DEPTH, *IMAGE_SIZE]\nBATCH_SIZE = 4\nGET_ITEM_ACCESS = 0\nPRETRAINED_PATH = '../input/medicalnet-pretrained-weights/resnet_34.pth'\nclass MRITypes:\n    flair = 'FLAIR'\n    tw1ce = 'T1wCE'\n    t1w = 'T1w'\n    t2w = 'T2w'\n    \ndef get_types():\n    return [ MRITypes.tw1ce]\n    \ndef get_index(mri_type : MRITypes):\n    return get_types().index(mri_type)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.254568Z","iopub.execute_input":"2022-06-09T15:53:42.25485Z","iopub.status.idle":"2022-06-09T15:53:42.260741Z","shell.execute_reply.started":"2022-06-09T15:53:42.254817Z","shell.execute_reply":"2022-06-09T15:53:42.259956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load image functions**","metadata":{}},{"cell_type":"code","source":"# load scans in a folder\ndef load_scan(path):\n    slices = [ pydicom.read_file(join(path, slice_file))\n                    for slice_file in os.listdir(path)]\n    \n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    \n    return slices\n\ndef load_scan_png(path):\n    sorted_filenames = sorted(os.listdir(path), key=lambda x: int(x[:-4][6:]))\n    slices = [ imread(join(path, slice_file), as_gray=True) for slice_file in sorted_filenames]\n    \n    return slices","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.262271Z","iopub.execute_input":"2022-06-09T15:53:42.26279Z","iopub.status.idle":"2022-06-09T15:53:42.270931Z","shell.execute_reply.started":"2022-06-09T15:53:42.262754Z","shell.execute_reply":"2022-06-09T15:53:42.270188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making the train dataset class","metadata":{}},{"cell_type":"markdown","source":"The following are my preprocessing for images of different types.\n","metadata":{}},{"cell_type":"code","source":"#-------------------------------------------------------------------------------------------------------------------------\n# preprocessing png\ndef preprocess_png_image(image):\n    # resize to IMAGE_SHAPE\n    trans_image = np.array([ resize(x, IMAGE_SIZE) for x in image ])\n    \n    # set image depth to IMAGE_DEPTH\n    current_depth = trans_image.shape[0]\n    trans_image = zoom(trans_image, (IMAGE_DEPTH/current_depth, 1, 1))\n    \n    # turn image to pytorch tensor\n    trans_image = torch.tensor(trans_image, dtype=torch.float32)\n    \n    # normalize images to values between [0, 1]\n    trans_image /= 255\n    \n    return trans_image\n#-------------------------------------------------------------------------------------------------------------------------\n# preprocessing function\n\ndef preprocess_dicom_image(image):\n    \n    # remove all black images\n    trans_image = [ x for x in image if np.any(x.pixel_array != 0)]\n    \n    # apply voi lut (which is a filter that makes it easier to spot things)\n    trans_image = [ apply_voi_lut(x.pixel_array, x) for x in trans_image]\n    \n    # reverse image if monochrome (some images are inverted)\n    trans_image = [ np.amax(x) - x if dicom.PhotometricInterpretation == \"MONOCHROME1\" else x\n                       for x, dicom in zip(trans_image, image) ]\n  \n\n    # resize images to IMAGE_SIZE and discard images that are all black\n    trans_image = np.array([ resize(x, IMAGE_SIZE) for x in trans_image ])\n    \n    \n    # set image depth to IMAGE_DEPTH\n    current_depth = trans_image.shape[0]\n    trans_image = zoom(trans_image, (IMAGE_DEPTH/current_depth, 1, 1))\n    \n    \n    # normalize images using the min max approach to make in range [0, 1]\n    \n    trans_image = [ x - np.min(x) for x in trans_image]\n    trans_image = [ x / np.max(x) for x in trans_image]\n    \n    \n    trans_image = torch.tensor(trans_image, dtype=torch.float32)\n    return trans_image\n#-------------------------------------------------------------------------------------------------------------------------\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.272401Z","iopub.execute_input":"2022-06-09T15:53:42.272744Z","iopub.status.idle":"2022-06-09T15:53:42.284622Z","shell.execute_reply.started":"2022-06-09T15:53:42.272712Z","shell.execute_reply":"2022-06-09T15:53:42.283728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Dataset for my already preprocessed data**","metadata":{}},{"cell_type":"markdown","source":"As preprocessing took a long time, I preprocessed all the data, and uploaded it as a Kaggle Dataset to train faster.","metadata":{}},{"cell_type":"code","source":"# dataset definition\nclass TumorDataset(Dataset):\n    def __init__(self, patient_ids, patient_labels, transform, load_function, input_folder, split):\n        super().__init__()\n        self.patient_ids = patient_ids\n        self.patient_labels = patient_labels if not (split == 'test') else None\n        self.transform = transform\n        self.load_function = load_function\n        self.input_folder = input_folder\n        self.split = split   \n    \n    def __len__(self):\n        return len(self.patient_ids)\n    \n    def __getitem__(self, idx):\n        current_label = self.patient_labels[idx] if self.split == 'train' else None\n        # get folder of patient\n        patient_folder = join(self.input_folder, self.split, self.patient_ids[idx])\n        # read each of T1, Tw1ce, T2w, FLAIR\n        # add them in patient_scans.\n        patient_scans = []\n        \n        for scan_type in get_types():\n            # read image\n            current_scan = self.load_function(join(patient_folder, scan_type))\n            \n            # apply preprocessing\n            current_scan = self.transform(current_scan)\n            \n            # add color channel to 3D image\n            current_scan = current_scan.unsqueeze(0)\n            \n            # add image to array\n            patient_scans.append(current_scan)\n        \n        if self.split == 'train':\n            return (\n                 torch.stack(patient_scans),\n                 torch.tensor(current_label, dtype=torch.float32)\n                )\n        else:\n            return (\n                torch.stack(patient_scans)\n                )\n\n#---------------------------------------------------------------------\nclass PTDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        filename = join('my-train-data', self.x[idx])\n        patient_scans = torch.load(filename)\n        patient_scans = patient_scans.type(torch.FloatTensor)\n        patient_scans /= 255\n        return (\n            patient_scans,\n            torch.tensor(self.y[idx], dtype=torch.float32)\n        )","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.288444Z","iopub.execute_input":"2022-06-09T15:53:42.28911Z","iopub.status.idle":"2022-06-09T15:53:42.302829Z","shell.execute_reply.started":"2022-06-09T15:53:42.289072Z","shell.execute_reply":"2022-06-09T15:53:42.302181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(patient_ids, patient_labels, image_type, split):\n    transform, load_fn, input_folder = None, None, None\n    if (image_type.lower() == 'png'):\n        transform = preprocess_png_image\n        load_fn = load_scan_png\n        input_folder = INPUT_FOLDER_PNG\n    if (image_type.lower() == 'dicom' or image_type.lower() == 'dcm'):\n        transform = preprocess_dicom_image\n        load_fn = load_scan\n        input_folder = INPUT_FOLDER\n        \n    return TumorDataset(patient_ids, patient_labels, transform, load_fn, input_folder, split)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.305866Z","iopub.execute_input":"2022-06-09T15:53:42.30613Z","iopub.status.idle":"2022-06-09T15:53:42.315219Z","shell.execute_reply.started":"2022-06-09T15:53:42.306084Z","shell.execute_reply":"2022-06-09T15:53:42.314483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Data\ntrain_dataset = PTDataset(train_info.patient_id.values,\n                             train_info.patient_label.values)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, num_workers=1)\n\n# Validation Data\nval_dataset = PTDataset(val_info.patient_id.values,\n                           val_info.patient_label.values)\n\nval_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=1)\n\n# Test Data\ntest_dataset = load_dataset(patients_test,\n                           None,\n                           image_type='dcm', \n                           split='test')\n\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.318431Z","iopub.execute_input":"2022-06-09T15:53:42.31872Z","iopub.status.idle":"2022-06-09T15:53:42.327127Z","shell.execute_reply.started":"2022-06-09T15:53:42.318684Z","shell.execute_reply":"2022-06-09T15:53:42.326344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_slices(image):\n    \n    fig, axes = plt.subplots(8, 8, figsize=(50,50))\n    i = 0\n    for row in axes:\n        for col in row:\n            col.imshow(image[i, :, :], cmap='gray')\n            i += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:53:42.328625Z","iopub.execute_input":"2022-06-09T15:53:42.329201Z","iopub.status.idle":"2022-06-09T15:53:42.337408Z","shell.execute_reply.started":"2022-06-09T15:53:42.329163Z","shell.execute_reply":"2022-06-09T15:53:42.336767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Trying out dataloaders**","metadata":{}},{"cell_type":"code","source":"x = next(iter(test_dataloader))\nprint(f'size of x : {x.size()}')\nprint(f'size of x[:,0] : {x[:,0].size()}')\nx_show = x[:, 0][0].squeeze().numpy()\nt = plot_slices(x_show)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:55:30.258515Z","iopub.execute_input":"2022-06-09T15:55:30.259225Z","iopub.status.idle":"2022-06-09T15:55:39.65087Z","shell.execute_reply.started":"2022-06-09T15:55:30.259188Z","shell.execute_reply":"2022-06-09T15:55:39.648755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = next(iter(train_dataloader))\nprint(f'size of x : {x.size()}')\nprint(f'size of x[:,0] : {x[:,0].size()}')\nx_show = x[:, 0][1].squeeze()\nt = plot_slices(x_show.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:55:50.96251Z","iopub.execute_input":"2022-06-09T15:55:50.963353Z","iopub.status.idle":"2022-06-09T15:56:01.400536Z","shell.execute_reply.started":"2022-06-09T15:55:50.963317Z","shell.execute_reply":"2022-06-09T15:56:01.399592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding Libraries to download 3D Models","metadata":{}},{"cell_type":"code","source":"input_monaipath = '../input/monai-v060-deep-learning-in-healthcare-imaging'\nmonaipath = '/kaggle/monai'\ninput_medicalnet_path = '../input/medicalnet'\nmedicalnet_path = '/kaggle/medicalnet'","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:23.355401Z","iopub.execute_input":"2022-06-09T15:56:23.355709Z","iopub.status.idle":"2022-06-09T15:56:23.362442Z","shell.execute_reply.started":"2022-06-09T15:56:23.355675Z","shell.execute_reply":"2022-06-09T15:56:23.361725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir -p {monaipath}\n! cp -r {input_monaipath}/* {monaipath}\n! mkdir -p {medicalnet_path}\n! cp -r {input_medicalnet_path}/* {medicalnet_path}","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:24.182957Z","iopub.execute_input":"2022-06-09T15:56:24.183232Z","iopub.status.idle":"2022-06-09T15:56:52.167097Z","shell.execute_reply.started":"2022-06-09T15:56:24.183203Z","shell.execute_reply":"2022-06-09T15:56:52.166062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append(monaipath)\n# sys.path.append(medicalnet_path)\n\n\nfrom monai.networks.nets.efficientnet import EfficientNetBN\n# from models.resnet import resnet18 , resnet34","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:52.169215Z","iopub.execute_input":"2022-06-09T15:56:52.169517Z","iopub.status.idle":"2022-06-09T15:56:59.576978Z","shell.execute_reply.started":"2022-06-09T15:56:52.169478Z","shell.execute_reply":"2022-06-09T15:56:59.576238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_last_n_layers(model, n):\n    # removes last 2 layer from model and\n    # returns the dimension of last layer\n    \n    components_list = list(model.children())\n    \n    return nn.Sequential(*(components_list[:-n]))\n\ndef remove_last_2_layers(model):\n    return remove_last_n_layers(model, 2)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:59.578325Z","iopub.execute_input":"2022-06-09T15:56:59.578595Z","iopub.status.idle":"2022-06-09T15:56:59.585023Z","shell.execute_reply.started":"2022-06-09T15:56:59.57856Z","shell.execute_reply":"2022-06-09T15:56:59.5835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n#     model = resnet34(sample_input_D=1, sample_input_H=256,\n#                      sample_input_W=256, num_seg_classes=1)\n#     net_dict = model.state_dict()\n#     pretrained_weights = torch.load(PRETRAINED_PATH)\n#     pretrained_weights = { \n#                             k.replace(\"module.\", \"\"): v \n#                             for k, v in pretrained_weights['state_dict'].items() \n#                             if k.replace(\"module.\", \"\") in net_dict.keys()\n#               }\n#     net_dict.update(pretrained_weights)\n#     model.load_state_dict(net_dict)\n#     model.conv_seg = nn.Sequential(\n#                             nn.AdaptiveAvgPool3d(output_size=1),\n#                             nn.Dropout(p=0.2, inplace=False)\n#                             )\n    model = EfficientNetBN('efficientnet-b1', spatial_dims=3, in_channels=1,\n                           num_classes=1, pretrained=False)\n    \n    model = remove_last_2_layers(model)\n    return model\n\nclass AllTypesNet(pl.LightningModule):\n    def __init__(self, num_features, lr=0.001):\n        super().__init__()\n        \n        self.lr = lr\n        self.train_acc = Accuracy()\n        self.val_acc = Accuracy()\n        \n        self.classifiers = nn.ModuleList([build_model()\n                                                for _ in get_types()])\n        \n        self.fc = nn.Linear(in_features=len(get_types())*num_features, out_features=1)\n        \n        \n        \n    def forward(self, x):\n#         print(f'size of 1 element of x : {x[:,0].size()}')\n#         print(f'size of x : {x.size()}')\n        pred_list = [ classifier(x[:, i]).squeeze() for i, classifier in enumerate(self.classifiers)]\n#         print(f'size of cat output : {torch.cat(pred_list, -1).size()}')\n#         print(f'pred_list[0] size : {pred_list[0].size()}')\n        pred = self.fc(torch.cat(pred_list, -1))\n        \n        \n        return pred\n    \n    def training_step(self, batch, batch_idx):\n        \n        x, y = batch\n        \n        \n        y_pred = self(x).view(-1)\n        \n        assert not bool(torch.any(torch.isnan(y_pred)).item()), f'Model outputs nan on Epoch {self.current_epoch}, batch {batch_idx}' # assert error msg\n    \n        loss = F.binary_cross_entropy_with_logits(y_pred, y)\n#         print(f'Y : {y}')\n#         print(f'Y pred: {y_pred}')\n        self.train_acc(torch.sigmoid(y_pred), y.type(torch.cuda.LongTensor))\n\n        return {'loss': loss, 'predictions': None }\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        \n        y_pred = self(x).view(-1)\n        \n        loss = F.binary_cross_entropy_with_logits(y_pred, y)\n        \n        self.val_acc(torch.sigmoid(y_pred), y.type(torch.cuda.LongTensor))\n        \n        \n        return {'loss': loss, 'predictions': None }\n    \n    def training_epoch_end(self, training_step_outputs):\n        print(f'Epoch {self.current_epoch} train accuracy : {round(self.train_acc.compute().item() * 100, 2)}%')\n        self.train_acc.reset()\n        \n    \n    def validation_epoch_end(self, validation_step_outputs):\n        print(f'Epoch {self.current_epoch} val accuracy : {round(self.val_acc.compute().item() * 100, 2)}%')\n        self.val_acc.reset()\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n        return optimizer\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:59.587317Z","iopub.execute_input":"2022-06-09T15:56:59.58781Z","iopub.status.idle":"2022-06-09T15:56:59.603594Z","shell.execute_reply.started":"2022-06-09T15:56:59.587775Z","shell.execute_reply":"2022-06-09T15:56:59.602913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Check Model size to make sure there's enough memory in GPU**","metadata":{}},{"cell_type":"code","source":"model = build_model()\nmem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\nmem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\nmem = (mem_params + mem_bufs) / 2**20 # in Megabytes\nmem * len(get_types())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:59.605631Z","iopub.execute_input":"2022-06-09T15:56:59.60615Z","iopub.status.idle":"2022-06-09T15:56:59.895187Z","shell.execute_reply.started":"2022-06-09T15:56:59.606116Z","shell.execute_reply":"2022-06-09T15:56:59.894514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check that there are no nan in train dataloader","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfor data in tqdm(train_dataloader):\n    x , y = data\n    \n    assert not bool(torch.any(torch.isnan(x)).item())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:56:59.896473Z","iopub.execute_input":"2022-06-09T15:56:59.896754Z","iopub.status.idle":"2022-06-09T15:57:03.503986Z","shell.execute_reply.started":"2022-06-09T15:56:59.896721Z","shell.execute_reply":"2022-06-09T15:57:03.501941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = EfficientNetBN('efficientnet-b1', spatial_dims=3, in_channels=1,\n                           num_classes=1, pretrained=False)._fc.in_features\nnum_features","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:57:16.804911Z","iopub.execute_input":"2022-06-09T15:57:16.8052Z","iopub.status.idle":"2022-06-09T15:57:17.088314Z","shell.execute_reply.started":"2022-06-09T15:57:16.805166Z","shell.execute_reply":"2022-06-09T15:57:17.087582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AllTypesNet(num_features, 0.0003)\n\ntrainer = pl.Trainer(gpus=1,\n                     max_epochs=3, log_every_n_steps=75)\ntrainer.fit(model,\n            train_dataloaders=train_dataloader,\n            val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T16:32:50.267849Z","iopub.execute_input":"2022-06-09T16:32:50.268462Z","iopub.status.idle":"2022-06-09T17:16:41.259404Z","shell.execute_reply.started":"2022-06-09T16:32:50.268423Z","shell.execute_reply":"2022-06-09T17:16:41.258292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.lr = 0.0003 / 3\ntrainer = pl.Trainer(gpus=1,\n                     max_epochs=5, log_every_n_steps=75)\ntrainer.fit(model,\n            train_dataloaders=train_dataloader,\n            val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T17:16:41.26413Z","iopub.execute_input":"2022-06-09T17:16:41.264368Z","iopub.status.idle":"2022-06-09T17:25:26.955102Z","shell.execute_reply.started":"2022-06-09T17:16:41.264338Z","shell.execute_reply":"2022-06-09T17:25:26.954004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.lr = 0.0003 / 5\ntrainer = pl.Trainer(gpus=1,\n                     max_epochs=10, log_every_n_steps=75)\ntrainer.fit(model,\n            train_dataloaders=train_dataloader,\n            val_dataloaders=val_dataloader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = trainer.predict(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T17:25:26.956724Z","iopub.execute_input":"2022-06-09T17:25:26.957009Z","iopub.status.idle":"2022-06-09T17:25:33.623694Z","shell.execute_reply.started":"2022-06-09T17:25:26.956965Z","shell.execute_reply":"2022-06-09T17:25:33.621678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor pred_list in y_pred:\n    for element in pred_list:\n        preds.append(element.item())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T17:25:33.625103Z","iopub.status.idle":"2022-06-09T17:25:33.625892Z","shell.execute_reply.started":"2022-06-09T17:25:33.625616Z","shell.execute_reply":"2022-06-09T17:25:33.625658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying sigmoid\npreds = 1 / ( 1 + np.exp(-1 * np.array(preds)))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T17:25:33.629278Z","iopub.status.idle":"2022-06-09T17:25:33.629804Z","shell.execute_reply.started":"2022-06-09T17:25:33.629519Z","shell.execute_reply":"2022-06-09T17:25:33.629543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm ./* -rf","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:54:26.901219Z","iopub.execute_input":"2022-06-09T19:54:26.901521Z","iopub.status.idle":"2022-06-09T19:54:28.141415Z","shell.execute_reply.started":"2022-06-09T19:54:26.901489Z","shell.execute_reply":"2022-06-09T19:54:28.140224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'BraTS21ID': patients_test,\n                           'MGMT_value': preds})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T17:25:33.632418Z","iopub.status.idle":"2022-06-09T17:25:33.632996Z","shell.execute_reply.started":"2022-06-09T17:25:33.632754Z","shell.execute_reply":"2022-06-09T17:25:33.63278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:53:19.895444Z","iopub.execute_input":"2022-06-09T19:53:19.896338Z","iopub.status.idle":"2022-06-09T19:53:20.880224Z","shell.execute_reply.started":"2022-06-09T19:53:19.89628Z","shell.execute_reply":"2022-06-09T19:53:20.879333Z"},"trusted":true},"execution_count":null,"outputs":[]}]}