{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport os, math, glob, re\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom tensorflow.keras import layers\nimport tensorflow as tf","metadata":{"papermill":{"duration":4.149817,"end_time":"2021-08-16T15:34:59.871984","exception":false,"start_time":"2021-08-16T15:34:55.722167","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-05T20:28:03.446498Z","iopub.execute_input":"2021-10-05T20:28:03.446952Z","iopub.status.idle":"2021-10-05T20:28:03.452062Z","shell.execute_reply.started":"2021-10-05T20:28:03.446921Z","shell.execute_reply":"2021-10-05T20:28:03.451377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:28:03.468755Z","iopub.execute_input":"2021-10-05T20:28:03.469184Z","iopub.status.idle":"2021-10-05T20:28:09.239886Z","shell.execute_reply.started":"2021-10-05T20:28:03.469149Z","shell.execute_reply":"2021-10-05T20:28:09.238925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Constants","metadata":{"papermill":{"duration":0.013824,"end_time":"2021-08-16T15:34:59.900221","exception":false,"start_time":"2021-08-16T15:34:59.886397","status":"completed"},"tags":[]}},{"cell_type":"code","source":"mri_types = ['FLAIR','T1w','T1wCE','T2w']\nIMAGE_SIZE  = 128\nIMAGE_DEPTH = 32\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nCHANNELS  = len(mri_types)\n\nAUTO = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:28:09.241402Z","iopub.execute_input":"2021-10-05T20:28:09.24163Z","iopub.status.idle":"2021-10-05T20:28:09.24572Z","shell.execute_reply.started":"2021-10-05T20:28:09.241603Z","shell.execute_reply":"2021-10-05T20:28:09.245027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path(\"rsna-brain-tumor-classification-tfrecords\")\ntf_train_path = GCS_PATH + \"/tfrecords/train\"\ntf_valid_path = GCS_PATH + \"/tfrecords/valid\"","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:28:09.246843Z","iopub.execute_input":"2021-10-05T20:28:09.247209Z","iopub.status.idle":"2021-10-05T20:28:09.69209Z","shell.execute_reply.started":"2021-10-05T20:28:09.247182Z","shell.execute_reply":"2021-10-05T20:28:09.691263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read TFRecords and Create Dataset","metadata":{}},{"cell_type":"markdown","source":"I have converted Original dataset with [this](https://www.kaggle.com/kavehshahhosseini/rsna-brain-tumor-convert-dicom-to-tfrecord) notebook to TFRecords and I have created a new dataset, which you can find it [here](https://www.kaggle.com/kavehshahhosseini/rsna-brain-tumor-classification-tfrecords). You should add the converted dataset, to the notebook to go further. I have splitted the data to train with 465 samples and each of them with shape `(128,128,32,4)` and validation data with 117 samples and the same shape.  ","metadata":{}},{"cell_type":"code","source":"def deserialize_example(serialized_string):\n    image_feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'MGMT_value': tf.io.FixedLenFeature([], tf.float32)\n    }\n    parsed_record = tf.io.parse_single_example(serialized_string, image_feature_description)\n    image = tf.io.decode_raw(parsed_record['image'], tf.float64)\n    image = tf.reshape(image,[IMAGE_SIZE,IMAGE_SIZE,IMAGE_DEPTH,CHANNELS])\n    \n    label = parsed_record['MGMT_value']\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:28:09.694425Z","iopub.execute_input":"2021-10-05T20:28:09.695079Z","iopub.status.idle":"2021-10-05T20:28:09.702051Z","shell.execute_reply.started":"2021-10-05T20:28:09.695029Z","shell.execute_reply":"2021-10-05T20:28:09.701023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = tf.data.TFRecordDataset(str(tf_train_path + os.sep + \"brain_train.tfrec\"),\n                                   compression_type=\"GZIP\", num_parallel_reads=AUTO).map(deserialize_example).batch(BATCH_SIZE).prefetch(AUTO)\nvalid_set = tf.data.TFRecordDataset(str(tf_valid_path + os.sep + \"brain_val.tfrec\"),\n                                   compression_type=\"GZIP\", num_parallel_reads=AUTO).map(deserialize_example).batch(BATCH_SIZE).prefetch(AUTO)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:28:09.703367Z","iopub.execute_input":"2021-10-05T20:28:09.703675Z","iopub.status.idle":"2021-10-05T20:28:09.751712Z","shell.execute_reply.started":"2021-10-05T20:28:09.703637Z","shell.execute_reply":"2021-10-05T20:28:09.750925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Image","metadata":{}},{"cell_type":"code","source":"d = train_set.take(1)\nfor i, j in d:\n    image = i\n    label = j\n\n\nimg_id = np.random.randint(0, BATCH_SIZE)\nchannel = np.random.randint(0,CHANNELS)\n\nplt.figure(figsize=(20,10),facecolor=(0,0,0))\ncols = IMAGE_DEPTH//4\nrows = 4\n\nplt.axis(\"off\")\nfor layer_idx in range(IMAGE_DEPTH):\n    ax = plt.subplot(rows,cols,layer_idx+1)\n    ax.imshow(np.squeeze(image[img_id,:,:,layer_idx,channel]), cmap=\"gray\")\n    ax.axis(\"off\")\n    ax.set_title(str(layer_idx+1),color='r',y=-0.01)\n    \nplt.suptitle(f\"Batch Image NO.: {img_id}, MRI Type: {mri_types[channel]}, Shape: {image[img_id].shape}\", color=\"w\")\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:28:09.753422Z","iopub.execute_input":"2021-10-05T20:28:09.753738Z","iopub.status.idle":"2021-10-05T20:28:26.45797Z","shell.execute_reply.started":"2021-10-05T20:28:09.753695Z","shell.execute_reply":"2021-10-05T20:28:26.45697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{"papermill":{"duration":0.021365,"end_time":"2021-08-16T15:35:04.496539","exception":false,"start_time":"2021-08-16T15:35:04.475174","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_model(width=128, height=128, depth=32):\n\n    act = \"swish\"\n    ki = tf.keras.initializers.HeUniform(42)\n    kr = 'l1_l2'\n    inputs = tf.keras.Input((width, height, depth, 4))\n\n    x = layers.Conv3D(filters=32, kernel_size=2, activation=\"swish\", padding=\"same\", kernel_regularizer=kr, kernel_initializer=ki)(inputs)\n    x = layers.MaxPool3D(2)(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=2, activation=\"swish\", padding=\"same\", kernel_regularizer=kr, kernel_initializer=ki)(x)\n    x = layers.MaxPool3D(2)(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=2, activation=\"swish\", padding=\"same\", kernel_regularizer=kr, kernel_initializer=ki)(x)\n    x = layers.MaxPool3D(2)(x)\n    \n    x = layers.Conv3D(filters=256, kernel_size=2, activation=\"swish\", padding=\"same\", kernel_regularizer=kr, kernel_initializer=ki)(x)\n    x = layers.MaxPool3D(2)(x)\n    \n    x = layers.Conv3D(filters=512, kernel_size=2, activation=\"swish\", padding=\"same\", kernel_regularizer=kr, kernel_initializer=ki)(x)\n    x = layers.MaxPool3D(2)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(units=128, activation=\"swish\")(x)\n    x = layers.Dense(units=128, activation=\"swish\")(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    model = tf.keras.Model(inputs, outputs)\n\n    return model\n\n\nwith strategy.scope():\n    model = get_model(width=IMAGE_SIZE, height=IMAGE_SIZE, depth=IMAGE_DEPTH)\n    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\", \"AUC\"])\n\nmodel.summary()","metadata":{"papermill":{"duration":1.72889,"end_time":"2021-08-16T15:35:06.246658","exception":false,"start_time":"2021-08-16T15:35:04.517768","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-05T20:28:26.459412Z","iopub.execute_input":"2021-10-05T20:28:26.459715Z","iopub.status.idle":"2021-10-05T20:28:26.821847Z","shell.execute_reply.started":"2021-10-05T20:28:26.459678Z","shell.execute_reply":"2021-10-05T20:28:26.82093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{"papermill":{"duration":0.022634,"end_time":"2021-08-16T15:35:06.292186","exception":false,"start_time":"2021-08-16T15:35:06.269552","status":"completed"},"tags":[]}},{"cell_type":"code","source":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=4, mode=\"max\")\nhistory = model.fit(train_set, validation_data=valid_set, epochs=20, callbacks=[early_stopping_cb])","metadata":{"papermill":{"duration":3152.839897,"end_time":"2021-08-16T16:27:39.15389","exception":false,"start_time":"2021-08-16T15:35:06.313993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-05T20:36:57.951957Z","iopub.execute_input":"2021-10-05T20:36:57.952349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Model Metrics","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')\n\nplt.figure(figsize=(16,7))\nacc=history.history['auc']\nval_acc=history.history['val_auc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(1,len(acc)+1)\nax1 = plt.subplot(1,2,1)\nax1.plot(epochs, acc, 'r')\nax1.plot(epochs, val_acc, 'b')\nax1.set_xticks([i for i in epochs])\nax1.set_title('Training and validation AUC')\nax1.legend([\"Training\", \"Validation\" ])\nax1.set_xlabel(\"epochs\")\nax1.set_ylabel(\"Accuracy\")\n\nax2 = plt.subplot(1,2,2)\nax2.plot(epochs, loss, 'r')\nax2.plot(epochs, val_loss, 'b')\nax2.set_xticks([i for i in epochs])\nax2.legend([\"Training\", \"Validation\" ])\nax2.set_xlabel(\"Epochs\")\nax2.set_ylabel(\"Loss\")\nax2.set_title('Training and validation loss')\n\nplt.show()","metadata":{"papermill":{"duration":0.442421,"end_time":"2021-08-16T16:27:39.691795","exception":false,"start_time":"2021-08-16T16:27:39.249374","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-05T20:31:47.941306Z","iopub.execute_input":"2021-10-05T20:31:47.941528Z","iopub.status.idle":"2021-10-05T20:31:48.268398Z","shell.execute_reply.started":"2021-10-05T20:31:47.941502Z","shell.execute_reply":"2021-10-05T20:31:48.267705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"my_simple_model_v3.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-10-05T20:31:48.270873Z","iopub.execute_input":"2021-10-05T20:31:48.271739Z","iopub.status.idle":"2021-10-05T20:31:48.55272Z","shell.execute_reply.started":"2021-10-05T20:31:48.271691Z","shell.execute_reply":"2021-10-05T20:31:48.551862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction and Submission","metadata":{}},{"cell_type":"markdown","source":"I have created another kernel [here](https://www.kaggle.com/kavehshahhosseini/rsna-brain-tumor-tensorflow-tpu-tfrecord-inference) for prediction ","metadata":{}}]}