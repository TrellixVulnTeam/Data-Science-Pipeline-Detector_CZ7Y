{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image\nfrom tqdm import tqdm\nimport os\nimport glob\nimport numpy as np\nimport random\nimport math\nimport time\nimport cv2\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-03T15:21:02.410246Z","iopub.execute_input":"2021-09-03T15:21:02.410762Z","iopub.status.idle":"2021-09-03T15:21:08.636526Z","shell.execute_reply.started":"2021-09-03T15:21:02.41066Z","shell.execute_reply":"2021-09-03T15:21:08.635419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataLoader(keras.utils.Sequence):\n    def __init__(self,base_dir='/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/test',\\\n                mods=['FLAIR']):\n        self.batch_size = 1 \n        self.base_dir = base_dir\n        self.pat_ids = sorted(glob.glob(os.path.join(base_dir, '*')))\n        self.modalities = mods\n        print('PAT IDS:',len(self.pat_ids),' | Modalities:',self.modalities)\n\n    def load_dicom_image(self,path):\n        dicom = pydicom.read_file(path)\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            data = np.amax(data) - data\n        data = data - np.min(data)\n        data = data / np.max(data)\n        data = (data * 255).astype(np.uint8)[:,:,np.newaxis]\n        data = np.repeat(data,3,2)\n        return data\n        \n    def __getitem__(self,index):\n        batch_patids = self.pat_ids[index:index+self.batch_size]\n        all_images = {}\n        for K in self.modalities:\n            all_images[K] = {'images':[],'ids':[]}\n        for patid in batch_patids:\n            for MOD in all_images.keys():\n                dicom_pngs = []\n                dicom_files = glob.glob(os.path.join(patid, MOD, '*.dcm'))\n                dset = tqdm(enumerate(dicom_files), total=len(dicom_files),position=0, leave=True)\n                dset.set_description(f'{patid}|{MOD}')\n                for i,dicom_path in dset:\n                    try:\n                        png = self.load_dicom_image(dicom_path)\n                        dicom_pngs.append(png)\n                    except:\n                        continue\n                if len(dicom_pngs)!=0:\n                    all_images[MOD]['images'].append(dicom_pngs)\n                    all_images[MOD]['ids'].append(patid.replace('\\\\','/').split('/')[-1])\n                    \n                dicom_pngs = None\n                \n        return all_images\n   \n    def __len__(self):\n        return int(len(self.pat_ids)/self.batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T15:21:11.633459Z","iopub.execute_input":"2021-09-03T15:21:11.633853Z","iopub.status.idle":"2021-09-03T15:21:11.648982Z","shell.execute_reply.started":"2021-09-03T15:21:11.633822Z","shell.execute_reply":"2021-09-03T15:21:11.647793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StageOne:\n    def __init__(self,modelpath='',height=256,width=256,score_min_thresh=0.5):\n        self.model = load_model(modelpath)\n        self.score_min_thresh = score_min_thresh\n        self.height = height\n        self.width = width\n        self.offset_perc = 0.1\n    \n    def infer(self,image_batch,filter_batchsize=16):\n        filtered_images = {}\n        for K in image_batch.keys():\n            filtered_images[K] = {'images':[],'ids':[]}\n            for imagesbatch, patid in zip(image_batch[K]['images'],image_batch[K]['ids']):\n                div,mod = divmod(len(imagesbatch),filter_batchsize)\n                if mod!=0:\n                    div+=1\n                dset = tqdm(range(0,len(imagesbatch),filter_batchsize),total=div,position=0, leave=True)\n                dset.set_description(f'{patid}|Filtering')\n                filtered_batch_images = []\n                for i in dset:\n                    org_batchimgs = imagesbatch[i:i+filter_batchsize]\n                    batchimgs = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in org_batchimgs]\n                    batchimgs = np.array([cv2.resize(img,(self.width,self.height))/255. for img in batchimgs])\n                    out = self.model.predict(batchimgs)\n                    maxindexes = np.argmax(out,axis=1)\n                    for j in range(len(maxindexes)):\n                        if maxindexes[j] == 1 and out[j][maxindexes[j]] >= self.score_min_thresh:\n                            filtered_batch_images.append(org_batchimgs[j])\n                            \n                if len(filtered_batch_images)==0:\n                    offset = math.ceil(len(imagesbatch)*self.offset_perc)\n                    filtered_batch_images = imagesbatch[offset:-offset]\n                    \n                    \n                filtered_images[K]['images'].append(filtered_batch_images)\n                filtered_images[K]['ids'].append(patid)\n                filtered_batch_images = None\n                dset = None\n                \n            return filtered_images\n              ","metadata":{"execution":{"iopub.status.busy":"2021-09-03T15:21:15.125522Z","iopub.execute_input":"2021-09-03T15:21:15.125922Z","iopub.status.idle":"2021-09-03T15:21:15.140484Z","shell.execute_reply.started":"2021-09-03T15:21:15.125891Z","shell.execute_reply":"2021-09-03T15:21:15.139106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StageTwo:\n    def __init__(self,modelpath='',height=224,width=224):\n        self.model = load_model(modelpath)\n        self.height = height\n        self.width = width\n    \n    def preprocess(self,image):\n        image = cv2.resize(image,(self.width,self.height))\n        return image\n    \n    def infer(self,imagebatch):\n        out = self.model.predict(imagebatch)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-03T15:21:17.647385Z","iopub.execute_input":"2021-09-03T15:21:17.647766Z","iopub.status.idle":"2021-09-03T15:21:17.655995Z","shell.execute_reply.started":"2021-09-03T15:21:17.647734Z","shell.execute_reply":"2021-09-03T15:21:17.654757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mods = ['FLAIR']\ngenerator = DataLoader(base_dir='/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train')\nstage_one = StageOne(modelpath='/kaggle/input/models/FINAL_MODELALL_acc0.9825_ep26.h5')\nstage_two = StageTwo(modelpath='/kaggle/input/models/3d_image_classification.hdf5')\ndset = tqdm(enumerate(generator),total=len(generator),position=0, leave=True)\ndset.set_description('Loading_test')\nall_results = {}\nfor i,sample in dset:\n    #if i > 2:\n    #    break\n    filtered_images = stage_one.infer(sample)\n    for K in filtered_images.keys():\n        for batchimg,patid in zip(filtered_images[K]['images'],filtered_images[K]['ids']):\n            batchimg = [stage_two.preprocess(img) for img in batchimg]\n            batchimg = np.transpose(batchimg, (1,2,0,3))[None,:,:,:,:]\n\n            out = stage_two.infer(batchimg)\n            maxindexes = int(np.argmax(out,axis=1)[0])\n\n            patidkey = str(patid).zfill(5)\n            if patidkey not in all_results.keys():\n                all_results[patidkey] = [maxindexes]\n            else:\n                all_results[patidkey].append(maxindexes)\n\nallpatids = []\nallpreds = []\nfor K in all_results.keys():\n    one_count = all_results[K].count(1)\n    zero_count = all_results[K].count(0)\n    allpatids.append(K)\n    if one_count > zero_count:\n        allpreds.append(1)\n    else:\n        allpreds.append(0)\n    \n        \n    \noutcsv = 'submission_train.csv'\ndf = pd.DataFrame({'BraTS21ID':allpatids,'MGMT_value':allpreds})\n#df = pd.DataFrame([allpatids,allpreds], columns=['BraTS21ID','MGMT_value'])\ndf.to_csv(outcsv,index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T15:21:33.438642Z","iopub.execute_input":"2021-09-03T15:21:33.43899Z","iopub.status.idle":"2021-09-03T15:49:11.333705Z","shell.execute_reply.started":"2021-09-03T15:21:33.438959Z","shell.execute_reply":"2021-09-03T15:49:11.331906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:49:57.634288Z","iopub.status.idle":"2021-09-03T14:49:57.636293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}