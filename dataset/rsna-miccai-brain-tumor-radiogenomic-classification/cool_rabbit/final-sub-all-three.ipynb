{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"CV: 0.6327","metadata":{}},{"cell_type":"code","source":"from brain_inference import generate_prediction\n\nsams_sub = generate_prediction()\nsams_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T16:51:25.933306Z","iopub.execute_input":"2021-10-15T16:51:25.933713Z","iopub.status.idle":"2021-10-15T17:03:52.420519Z","shell.execute_reply.started":"2021-10-15T16:51:25.933634Z","shell.execute_reply":"2021-10-15T17:03:52.419283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sams_sub['MGMT_value'].hist(bins=50);","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:03:52.422749Z","iopub.execute_input":"2021-10-15T17:03:52.423113Z","iopub.status.idle":"2021-10-15T17:03:52.706994Z","shell.execute_reply.started":"2021-10-15T17:03:52.423071Z","shell.execute_reply":"2021-10-15T17:03:52.706055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"! python ../input/brats21-bestcv-infer/brats21_yyama_cvbest_infer.py\n! rm -r ./test","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:03:52.729234Z","iopub.execute_input":"2021-10-15T17:03:52.729636Z","iopub.status.idle":"2021-10-15T17:09:29.247921Z","shell.execute_reply.started":"2021-10-15T17:03:52.729593Z","shell.execute_reply":"2021-10-15T17:09:29.246806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nyyama_sub = pd.read_csv('sub_yyama_cvbest.csv')\nyyama_sub['BraTS21ID'] = yyama_sub['BraTS21ID'].astype(str).apply(lambda s: s.zfill(5))\n\nyyama_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:09:29.249473Z","iopub.execute_input":"2021-10-15T17:09:29.249843Z","iopub.status.idle":"2021-10-15T17:09:29.272612Z","shell.execute_reply.started":"2021-10-15T17:09:29.249799Z","shell.execute_reply":"2021-10-15T17:09:29.27179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yyama_sub['MGMT_value'].hist(bins=50);","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:09:29.274043Z","iopub.execute_input":"2021-10-15T17:09:29.274742Z","iopub.status.idle":"2021-10-15T17:09:29.510852Z","shell.execute_reply.started":"2021-10-15T17:09:29.274704Z","shell.execute_reply":"2021-10-15T17:09:29.50991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:09:29.512325Z","iopub.execute_input":"2021-10-15T17:09:29.512683Z","iopub.status.idle":"2021-10-15T17:09:29.77599Z","shell.execute_reply.started":"2021-10-15T17:09:29.512647Z","shell.execute_reply":"2021-10-15T17:09:29.774852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{"execution":{"iopub.status.busy":"2021-10-15T00:29:05.954111Z","iopub.execute_input":"2021-10-15T00:29:05.954518Z","iopub.status.idle":"2021-10-15T00:29:05.968035Z","shell.execute_reply.started":"2021-10-15T00:29:05.954412Z","shell.execute_reply":"2021-10-15T00:29:05.966461Z"}}},{"cell_type":"markdown","source":"# Image processing -> 256 voxel","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport cv2\nimport pydicom\nimport matplotlib.pyplot as plt\nimport os, gc\n\nDATASET = 'test'\nscan_types = 'FLAIR'\ndata_root = Path(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification\")\n\n\n# https://www.kaggle.com/arnabs007/part-1-rsna-miccai-btrc-understanding-the-data\n# https://www.kaggle.com/davidbroberts/determining-mr-image-planes\ndef get_image_plane(data):\n    x1, y1, _, x2, y2, _ = [round(j) for j in data.ImageOrientationPatient]\n    cords = [x1, y1, x2, y2]\n\n    if cords == [1, 0, 0, 0]:\n        return 'Coronal'\n    elif cords == [1, 0, 0, 1]:\n        return 'Axial'\n    elif cords == [0, 1, 0, 0]:\n        return 'Sagittal'\n    else:\n        return 'Unknown'\n    \n    \ndef get_voxel(study_id, scan_type):\n    imgs = []\n    dcm_dir = data_root.joinpath(DATASET, study_id, scan_type)\n    dcm_paths = sorted(dcm_dir.glob(\"*.dcm\"), key=lambda x: int(x.stem.split(\"-\")[-1]))\n    positions = []\n    \n    for dcm_path in dcm_paths:\n        img = pydicom.dcmread(str(dcm_path))\n        imgs.append(img.pixel_array)\n        positions.append(img.ImagePositionPatient)\n        \n    plane = get_image_plane(img)\n    voxel = np.stack(imgs)\n    \n    # reorder planes if needed and rotate voxel\n    if plane == \"Coronal\":\n        if positions[0][1] < positions[-1][1]:\n            voxel = voxel[::-1]\n            print(f\"{study_id} {scan_type} {plane} reordered\")\n        voxel = voxel.transpose((1, 0, 2))\n    elif plane == \"Sagittal\":\n        if positions[0][0] < positions[-1][0]:\n            voxel = voxel[::-1]\n            print(f\"{study_id} {scan_type} {plane} reordered\")\n        voxel = voxel.transpose((1, 2, 0))\n        voxel = np.rot90(voxel, 2, axes=(1, 2))\n    elif plane == \"Axial\":\n        if positions[0][2] > positions[-1][2]:\n            voxel = voxel[::-1]\n            print(f\"{study_id} {scan_type} {plane} reordered\")\n        voxel = np.rot90(voxel, 2)\n    else:\n        raise ValueError(f\"Unknown plane {plane}\")\n    return voxel, plane\n\n\ndef normalize_contrast(voxel):\n    if voxel.sum() == 0:\n        return voxel\n    voxel = voxel - np.min(voxel)\n    voxel = voxel / np.max(voxel)\n    voxel = (voxel * 255).astype(np.uint8)\n    return voxel\n\n\ndef crop_voxel(voxel):\n    if voxel.sum() == 0:\n        return voxel\n    keep = (voxel.mean(axis=(0, 1)) > 0)\n    voxel = voxel[:, :, keep]\n    keep = (voxel.mean(axis=(0, 2)) > 0)\n    voxel = voxel[:, keep]\n    keep = (voxel.mean(axis=(1, 2)) > 0)\n    voxel = voxel[keep]\n    return voxel\n\n\ndef resize_voxel(voxel, sz=256):\n    output = np.zeros((sz, sz, sz), dtype=np.uint8)\n\n    if np.argmax(voxel.shape) == 0:\n        for i, s in enumerate(np.linspace(0, voxel.shape[0] - 1, sz)):\n            output[i] = cv2.resize(voxel[int(s)], (sz, sz))\n    elif np.argmax(voxel.shape) == 1:\n        for i, s in enumerate(np.linspace(0, voxel.shape[1] - 1, sz)):\n            output[:, i] = cv2.resize(voxel[:, int(s)], (sz, sz))\n    elif np.argmax(voxel.shape) == 2:\n        for i, s in enumerate(np.linspace(0, voxel.shape[2] - 1, sz)):\n            output[:, :, i] = cv2.resize(voxel[:, :, int(s)], (sz, sz))\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:09:29.777681Z","iopub.execute_input":"2021-10-15T17:09:29.778048Z","iopub.status.idle":"2021-10-15T17:09:29.807778Z","shell.execute_reply.started":"2021-10-15T17:09:29.778012Z","shell.execute_reply":"2021-10-15T17:09:29.806898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lists = list(data_root.joinpath(DATASET).glob(\"*\"))\n\nfor n, study_path in enumerate(list(data_root.joinpath(DATASET).glob(\"*\"))):\n    study_id = study_path.name\n    \n    if not study_path.is_dir():\n        continue\n\n    voxel, plane = get_voxel(study_id, scan_types)\n    voxel = normalize_contrast(voxel)\n    voxel = crop_voxel(voxel)\n    voxel = resize_voxel(voxel)\n    save_dir = f'/kaggle/working/test/{study_id}'\n    os.makedirs(save_dir, exist_ok=True)\n    np.save(f'{save_dir}/{scan_types}', voxel)\n        \n    del voxel, plane\n    gc.collect()\n    \n    print(f'{n}/{len(lists)} DONE!!')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-15T17:09:29.809231Z","iopub.execute_input":"2021-10-15T17:09:29.80992Z","iopub.status.idle":"2021-10-15T17:11:07.586431Z","shell.execute_reply.started":"2021-10-15T17:09:29.809881Z","shell.execute_reply":"2021-10-15T17:11:07.585579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation","metadata":{}},{"cell_type":"code","source":"# Installing segmentation_models_pytorch\n!mkdir -p /tmp/pip/cache/\n!cp ../input/segmentationmodelspytorch/segmentation_models/efficientnet_pytorch-0.6.3.xyz /tmp/pip/cache/efficientnet_pytorch-0.6.3.tar.gz\n!cp ../input/segmentationmodelspytorch/segmentation_models/pretrainedmodels-0.7.4.xyz /tmp/pip/cache/pretrainedmodels-0.7.4.tar.gz\n!cp ../input/segmentationmodelspytorch/segmentation_models/segmentation-models-pytorch-0.1.2.xyz /tmp/pip/cache/segmentation_models_pytorch-0.1.2.tar.gz\n!cp ../input/segmentationmodelspytorch/segmentation_models/timm-0.1.20-py3-none-any.whl /tmp/pip/cache/\n!cp ../input/segmentationmodelspytorch/segmentation_models/timm-0.2.1-py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ efficientnet-pytorch\n!pip install --no-index --find-links /tmp/pip/cache/ segmentation-models-pytorch","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-15T17:11:07.587871Z","iopub.execute_input":"2021-10-15T17:11:07.588231Z","iopub.status.idle":"2021-10-15T17:11:31.114952Z","shell.execute_reply.started":"2021-10-15T17:11:07.588191Z","shell.execute_reply":"2021-10-15T17:11:31.113816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\n\nfrom tqdm import tqdm\nimport os, gc\nimport random\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport zipfile\nimport collections\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage import exposure\nfrom bokeh.plotting import figure as bokeh_figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs\nfrom PIL import Image\nfrom sklearn import preprocessing\nfrom random import randint\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\n\nfrom segmentation_models_pytorch.unet import Unet\nfrom segmentation_models_pytorch.encoders import get_preprocessing_fn\n\nimport torchvision\nfrom torchvision import transforms\nfrom albumentations import *\nimport albumentations as A\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \n    \ndef transform(array, size=256, keep_ratio=False, resample=Image.LANCZOS):\n    im = Image.fromarray(array)\n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    return im\n    \n    \nseed = 2020\nseed_everything(seed)\nsz = 256\nNFOLDS = 5\nroot = '/kaggle/working/test'\n\n#ImageNet\nmean = np.array([[[0.485, 0.456, 0.406]]])\nstd = np.array([[[0.229, 0.224, 0.225]]])","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:11:31.116642Z","iopub.execute_input":"2021-10-15T17:11:31.116948Z","iopub.status.idle":"2021-10-15T17:11:33.140645Z","shell.execute_reply.started":"2021-10-15T17:11:31.116915Z","shell.execute_reply":"2021-10-15T17:11:33.139752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\ntest_df['BraTS21ID'] = test_df['BraTS21ID'].apply(lambda x: str(x).zfill(5))\ntest_df['type'] = 'FLAIR'\ntest_df['img_idx'] = 0\n\ntest_df_ = test_df.copy()\nfor i in range(1, 256):\n    test_df_['img_idx'] = i\n    test_df = test_df.append(test_df_, ignore_index=True)\n\ntest_df = test_df.sort_values(['BraTS21ID', 'img_idx']).reset_index(drop=True)\ntest_df['seg_area'] = 0\ntest_df['brain_area'] = 0\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:11:33.141937Z","iopub.execute_input":"2021-10-15T17:11:33.142284Z","iopub.status.idle":"2021-10-15T17:11:33.616614Z","shell.execute_reply.started":"2021-10-15T17:11:33.142248Z","shell.execute_reply":"2021-10-15T17:11:33.615614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform1 = A.Compose([\n    A.Transpose(p=1.0),\n    A.HorizontalFlip(p=1.0),\n    ])\n\ntransform2 = A.Compose([\n    A.HorizontalFlip(p=1.0),\n    A.Transpose(p=1.0),\n    ])\n\n\nclass Dataset(Dataset):\n    def __init__(self, df, preprocess_input=None, transform=None):\n        self.df = df\n        self.preprocess_input = preprocess_input\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        patient_id = self.df.iloc[idx, 0]\n        img_idx = self.df.iloc[idx, 3]\n        one_img = np.load(f'{root}/{patient_id}/FLAIR.npy')[img_idx, :, :].astype(np.float32)\n        img = np.array([one_img, one_img, one_img])\n        img = np.transpose(img, (1, 2, 0))\n        \n        if self.transform:\n            sample = self.transform(image=img)\n            img = sample['image']\n            \n        if self.preprocess_input:\n            img = self.preprocess_input(image=img)['image']\n            \n        img = img.transpose((2, 0, 1))\n        img = torch.from_numpy(img)\n        one_img = torch.from_numpy(one_img)\n            \n        return img, one_img, patient_id, img_idx\n    \n    \nENCODER_NAME = 'efficientnet-b0'\npreprocessing_fn = Lambda(image=get_preprocessing_fn(encoder_name=ENCODER_NAME, pretrained='imagenet'))\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.model = Unet(\n            encoder_name='efficientnet-b0', \n            encoder_weights=None, \n            classes=1, \n            activation=None\n        )\n\n    def forward(self, images):\n        img_masks = self.model(images)\n        return img_masks","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:11:33.618318Z","iopub.execute_input":"2021-10-15T17:11:33.618695Z","iopub.status.idle":"2021-10-15T17:11:33.632932Z","shell.execute_reply.started":"2021-10-15T17:11:33.618656Z","shell.execute_reply":"2021-10-15T17:11:33.632116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TH = 0.45\ntest_ds = Dataset(df=test_df, preprocess_input=preprocessing_fn, transform=transform1)\ntest_dl = DataLoader(dataset=test_ds, batch_size=256, shuffle=False, num_workers=2)\n\nmodel0 = Model()\nmodel0.load_state_dict(torch.load('../input/miccai-flair-efnetb0-unet-weight2/fold_0.pth'))\nmodel0.to(device)\nmodel0.eval()\nmodel1 = Model()\nmodel1.load_state_dict(torch.load('../input/miccai-flair-efnetb0-unet-weight2/fold_1.pth'))\nmodel1.to(device)\nmodel1.eval()\nmodel2 = Model()\nmodel2.load_state_dict(torch.load('../input/miccai-flair-efnetb0-unet-weight2/fold_2.pth'))\nmodel2.to(device)\nmodel2.eval()\nmodel3 = Model()\nmodel3.load_state_dict(torch.load('../input/miccai-flair-efnetb0-unet-weight2/fold_3.pth'))\nmodel3.to(device)\nmodel3.eval()\nmodel4 = Model()\nmodel4.load_state_dict(torch.load('../input/miccai-flair-efnetb0-unet-weight2/fold_4.pth'))\nmodel4.to(device)\nmodel4.eval()\n\npreds1 = []\npreds2 = []\n\nprint('=====segmentation=====')\nfor i, (img, one_img, id, idx) in tqdm(enumerate(test_dl)):\n    img = img.to(device, dtype=torch.float)\n    \n    with torch.no_grad():\n        pred0 = nn.Sigmoid()(model0(img))\n        pred1 = nn.Sigmoid()(model1(img))\n        pred2 = nn.Sigmoid()(model2(img))\n        pred3 = nn.Sigmoid()(model3(img))\n        pred4 = nn.Sigmoid()(model4(img))\n        pred = (pred0 + pred1 + pred2 + pred3 + pred4) / 5\n        pred = pred.detach().cpu().numpy().astype(np.float32)\n        pred = np.squeeze(pred)\n        pred = (pred >= TH).astype(np.uint8)\n        \n        for p in range(pred.shape[0]):\n            area = np.count_nonzero(pred[p])\n            area_ = np.count_nonzero(one_img[p])\n            id_ = id[p]\n            idx_ = idx[p]\n            pred_ = pred[p]\n            pred_ = transform2(image=pred_)['image']\n            pred_ = transform(pred_)\n            preds1.append(area)\n            preds2.append(area_)\n            #save_dir = f'/kaggle/tmp/test/' + f'{id_}/' + f'Image-{idx_}'\n            #os.makedirs(save_dir, exist_ok=True)\n            #pred_.save(save_dir + '.png')\n            \n    del img, one_img, pred, pred_, area, area_\n    gc.collect()\n        \npredictions1 = np.array(preds1).reshape(-1, 1)\npredictions2 = np.array(preds2).reshape(-1, 1)\n                \ntest_df['seg_area'] = predictions1\ntest_df['brain_area'] = predictions2\ntest_df['seg_brain_ratio'] = test_df['seg_area'] / test_df['brain_area']\n\ndel preds1, preds2, predictions1, predictions2, model0, model1, model2, model3, model4 \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:11:33.634238Z","iopub.execute_input":"2021-10-15T17:11:33.634851Z","iopub.status.idle":"2021-10-15T17:14:49.658437Z","shell.execute_reply.started":"2021-10-15T17:11:33.634802Z","shell.execute_reply":"2021-10-15T17:14:49.655844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('test_segmentation.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.659731Z","iopub.status.idle":"2021-10-15T17:14:49.660519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MGMT status inference","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm.notebook import tqdm\nimport os, gc\nimport random\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport zipfile\nimport collections\nfrom PIL import Image\nfrom sklearn import preprocessing\nfrom random import randint\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms\nimport albumentations as A\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \n    \ndef slice_selection_all(df, TH):\n    df2 = pd.DataFrame(columns=df.columns)\n    id_list = df['BraTS21ID'].unique()\n\n    for i in tqdm(range(len(id_list))):\n        tmp = df[df['BraTS21ID'] == id_list[i]].reset_index(drop=True)\n        tmp = tmp.sort_values('seg_area').reset_index(drop=True)\n        tmp['index'] = tmp.index\n        idx = tmp['index'].quantile(TH).astype(np.int32)\n        tmp_ = tmp[tmp['index'] >= idx].reset_index(drop=True)\n        df2 = df2.append(tmp_, ignore_index=True)\n        \n    return df2\n\n\ndef slice_selection_partial(df, TH, num):\n    df2 = pd.DataFrame(columns=df.columns)\n    id_list = df['BraTS21ID'].unique()\n\n    for i in tqdm(range(len(id_list))):\n        tmp = df[df['BraTS21ID'] == id_list[i]]\n        tmp = tmp.sort_values('seg_area').reset_index(drop=True)\n        tmp['index'] = tmp.index\n        idxs = list(set(tmp['index'].quantile(np.linspace(TH, 1.0, num)).astype(np.int32).to_list()))\n        tmp_ = tmp.iloc[idxs]\n        df2 = df2.append(tmp_, ignore_index=True)\n\n    return df2\n\n\ndef slice_selection_top(df, num):\n    df2 = pd.DataFrame(columns=df.columns)\n    id_list = df['BraTS21ID'].unique()\n\n    for i in tqdm(range(len(id_list))):\n        tmp = df[df['BraTS21ID'] == id_list[i]].reset_index(drop=True)\n        tmp = tmp.sort_values('seg_area', ascending=False).reset_index(drop=True)\n        tmp_ = tmp.head(num)\n        df2 = df2.append(tmp_, ignore_index=True)\n\n    return df2\n    \n\nseed = 2020\nseed_everything(seed)\nsz = 256\nroot = '/kaggle/working/test'\n\n\n#ImageNet\nmean = np.array([[[0.485, 0.456, 0.406]]])\nstd = np.array([[[0.229, 0.224, 0.225]]])","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.66182Z","iopub.status.idle":"2021-10-15T17:14:49.662392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['BraTS21ID'] = test_df['BraTS21ID'].apply(lambda x: str(x).zfill(5))\ntest_df = test_df.drop('type', axis=1)\nmax_brain_area = test_df.groupby('BraTS21ID').max().reset_index().rename(columns={'brain_area':'max_brain_area'})[['BraTS21ID', 'max_brain_area']]\ntest_df = test_df.merge(max_brain_area, on='BraTS21ID', how='left')\ntest_df = test_df[(test_df['img_idx'] >= 10) & (test_df['img_idx'] <= 245)].reset_index(drop=True)\ntest_df = test_df[(test_df['seg_brain_ratio'] > 0.01) & (test_df['seg_brain_ratio'] < 0.45)].reset_index(drop=True)\ntest_df2 = slice_selection_all(test_df, 0.3)\ntest_df2","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.6636Z","iopub.status.idle":"2021-10-15T17:14:49.664242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        brain_id = self.df.iloc[idx, 0]\n        img_idx = self.df.iloc[idx, 2]\n        img = np.load(f'{root}/{brain_id}/FLAIR.npy')[img_idx, :, :].astype(np.float32)\n        img = np.transpose(np.array([img, img, img]), (1, 2, 0))\n        if self.transform:\n            sample = self.transform(image=img)\n            img = sample['image']\n        img = (img/255.0 - mean) / std\n        img = np.transpose(img, (2, 0, 1))\n        img = torch.from_numpy(img)\n        return img\n    \n    \nclass Model(nn.Module):\n    def __init__(self, model_name='efficientnet_b0', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(\n            model_name, \n            in_chans=3, \n            pretrained=pretrained\n        )\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, 1)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \n\ndef inference_fn(data_loader, model, device):\n    model.eval()    \n    val_preds = []\n    \n    for i, x in enumerate(data_loader):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred = model(img)\n            val_preds.append(nn.Sigmoid()(pred).detach().cpu().numpy())\n            \n    val_preds = np.concatenate(val_preds)\n                \n    return val_preds","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.665307Z","iopub.status.idle":"2021-10-15T17:14:49.666047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = 0\nnum_models = 4\nNFOLDS1 = 3\nNFOLDS2 = 4\nNFOLDS3 = 5\n\nfor i in range(NFOLDS1):\n    print(f'=====FOLD:{i}=====')\n    test_ds = Dataset(df=test_df2, transform=None)\n    test_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\n    model = Model(model_name='efficientnet_b0')\n    model.load_state_dict(torch.load(f'../input/miccai-efnetb0-weight010/fold_{i}.pth'))\n    model.to(device)\n    predictions += inference_fn(test_dl, model, device) / (NFOLDS1 * num_models)\n    #rank_preds = sp.stats.rankdata(inference_fn(test_dl, model, device), method='average')\n    #predictions += rank_preds / (NFOLDS * len(test_df2) * num_models)\n    del model\n    gc.collect()\n    \nfor i in range(NFOLDS2):\n    print(f'=====FOLD:{i}=====')\n    test_ds = Dataset(df=test_df2, transform=None)\n    test_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\n    model = Model(model_name='efficientnet_b0')\n    model.load_state_dict(torch.load(f'../input/miccai-efnetb0-weight011/fold_{i}.pth'))\n    model.to(device)\n    predictions += inference_fn(test_dl, model, device) / (NFOLDS2 * num_models)\n    #rank_preds = sp.stats.rankdata(inference_fn(test_dl, model, device), method='average')\n    #predictions += rank_preds / (NFOLDS * len(test_df2) * num_models)\n    del model\n    gc.collect()\n    \nfor i in range(NFOLDS3):\n    print(f'=====FOLD:{i}=====')\n    test_ds = Dataset(df=test_df2, transform=None)\n    test_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\n    model = Model(model_name='efficientnet_b0')\n    model.load_state_dict(torch.load(f'../input/miccai-efnetb0-weight012-dup/fold_{i}.pth'))\n    model.to(device)\n    predictions += inference_fn(test_dl, model, device) / (NFOLDS3 * num_models)\n    #rank_preds = sp.stats.rankdata(inference_fn(test_dl, model, device), method='average')\n    #predictions += rank_preds / (NFOLDS * len(test_df2) * num_models)\n    del model\n    gc.collect()\n    \nfor i in range(NFOLDS3):\n    print(f'=====FOLD:{i}=====')\n    test_ds = Dataset(df=test_df2, transform=None)\n    test_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\n    model = Model(model_name='efficientnet_b1')\n    model.load_state_dict(torch.load(f'../input/miccai-efnetb1-weight001/fold_{i}.pth'))\n    model.to(device)\n    predictions += inference_fn(test_dl, model, device) / (NFOLDS3 * num_models)\n    #rank_preds = sp.stats.rankdata(inference_fn(test_dl, model, device), method='average')\n    #predictions += rank_preds / (NFOLDS * len(test_df2) * num_models)\n    del model\n    gc.collect()\n    \ntest_df2['MGMT_value'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.6672Z","iopub.status.idle":"2021-10-15T17:14:49.66785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_df2.groupby('BraTS21ID').median()['MGMT_value'].reset_index()\ntest['BraTS21ID'] = test['BraTS21ID'].apply(lambda x: int(x))","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.668861Z","iopub.status.idle":"2021-10-15T17:14:49.669584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\nsample = sample.iloc[:, :1].merge(test[['BraTS21ID', 'MGMT_value']], on='BraTS21ID', how='left').fillna(0.5)\nsample['BraTS21ID'] = sample['BraTS21ID'].astype(str).apply(lambda s: s.zfill(5))\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.670617Z","iopub.status.idle":"2021-10-15T17:14:49.671235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['MGMT_value'].hist(bins=50);","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.672247Z","iopub.status.idle":"2021-10-15T17:14:49.672874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\nall three","metadata":{}},{"cell_type":"code","source":"# simple average\ncombined = pd.concat([sample, sams_sub, yyama_sub], axis=0)\n\ncombined = combined.groupby('BraTS21ID', sort=False)['MGMT_value'].mean().reset_index()\n    \ncombined.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.673893Z","iopub.status.idle":"2021-10-15T17:14:49.674471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # weighted\n# sample['MGMT_value'] = sample['MGMT_value'] * 0.36\n# sams_sub['MGMT_value'] = sams_sub['MGMT_value'] * 0.44\n# yyama_sub['MGMT_value'] = yyama_sub['MGMT_value'] * 0.2\n\n# combined = pd.concat([sample , sams_sub , yyama_sub], axis=0)\n\n# combined = combined.groupby('BraTS21ID', sort=False)['MGMT_value'].sum().reset_index()\n    \n# combined.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.675564Z","iopub.status.idle":"2021-10-15T17:14:49.676271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.677336Z","iopub.status.idle":"2021-10-15T17:14:49.677982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined['MGMT_value'].hist(bins=50);","metadata":{"execution":{"iopub.status.busy":"2021-10-15T17:14:49.678955Z","iopub.status.idle":"2021-10-15T17:14:49.679589Z"},"trusted":true},"execution_count":null,"outputs":[]}]}