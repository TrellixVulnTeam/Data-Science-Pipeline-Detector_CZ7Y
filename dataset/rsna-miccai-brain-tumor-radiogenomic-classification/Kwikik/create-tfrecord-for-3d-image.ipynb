{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport os\nfrom pydicom import dcmread\nimport pydicom\nimport re\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport tensorflow as tf\nimport sys\nimport time\nfrom functools import partial\n\n\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-10T14:49:54.835365Z","iopub.execute_input":"2021-10-10T14:49:54.836841Z","iopub.status.idle":"2021-10-10T14:49:54.843214Z","shell.execute_reply.started":"2021-10-10T14:49:54.836765Z","shell.execute_reply":"2021-10-10T14:49:54.842161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sorted_alphanumeric(data):  #find this in stackoverflow \n    \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    \n    return sorted(data, key=alphanum_key)\n    #sort list \n\n\ndef search(Path , dir , mri_type): \n    \n    lstFilesDCM = []  \n    for root, dirs, files in os.walk(f\"{Path}/{dir}/{mri_type}\", topdown=False):\n        for name in files:\n            lstFilesDCM.append(os.path.join(root, name))\n\n    return (lstFilesDCM) #return list of the image in a dir","metadata":{"execution":{"iopub.status.busy":"2021-10-10T14:49:54.846053Z","iopub.execute_input":"2021-10-10T14:49:54.846978Z","iopub.status.idle":"2021-10-10T14:49:54.860369Z","shell.execute_reply.started":"2021-10-10T14:49:54.846917Z","shell.execute_reply":"2021-10-10T14:49:54.859596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):         # THX tensorflow doc\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2021-10-10T14:49:54.862406Z","iopub.execute_input":"2021-10-10T14:49:54.86326Z","iopub.status.idle":"2021-10-10T14:49:54.877998Z","shell.execute_reply.started":"2021-10-10T14:49:54.863103Z","shell.execute_reply":"2021-10-10T14:49:54.877182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_image(path):\n    img_size = (256, 256)\n    data = pydicom.read_file(path).pixel_array.astype(dtype = 'float32', copy = False)\n    image = cv2.resize(data , img_size , interpolation=cv2.INTER_LANCZOS4) \n    \n    return image\n\n\ndef Build_entire_train_dataset_V3(Mri_type, Path):\n    Csv  = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n\n    \n    Csv = Csv.set_index(\"BraTS21ID\")\n    unwanted = [109, 123,709]\n    Csv = Csv.drop(labels = [e for e in unwanted] , axis = 0)\n    \n    df = Csv[\"MGMT_value\"]\n    \n    \n\n    img_size = (256,256)\n    depth = 400\n    start = time.time()\n\n\n    train_dir = os.listdir(Path)    \n    \n    unwanted = ['00109', '00123', '00709']\n    train_dir = [e for e in train_dir if e not in unwanted]\n\n    \n    train_dir = sorted_alphanumeric(train_dir)\n    print(len(train_dir))     # 582 \n    \n    option = tf.io.TFRecordOptions(compression_level=2, compression_type=\"ZLIB\")\n\n    with tf.io.TFRecordWriter(f\"Train_{Mri_type}.tfrec\", options=option) as writer:\n        for dir,y in zip(train_dir,df):\n\n            Path_list = search(Path, dir , Mri_type)\n\n            sorted_path = sorted_alphanumeric(Path_list)\n\n            image3d = np.stack([load_dicom_image( f) for f in sorted_path], axis=0)\n\n            if image3d.shape[0] < depth:\n                n_zero = np.zeros((depth-image3d.shape[0], 256 , 256 )) \n                image3d = np.concatenate((image3d, n_zero), axis=0 ).astype(dtype='float32')\n                image3d = np.expand_dims(image3d , axis=-1)\n                image3d = image3d/4096\n\n            data = {'image': _bytes_feature(image3d.tobytes()),\n                    'label': _int64_feature(y)\n                    }\n\n            Data = tf.train.Example(features=tf.train.Features(feature=data))\n            Data = Data.SerializeToString()\n\n            writer.write(Data)\n            print(dir)\n            print(y)\n\n    elapsed = time.time()\n    elapsed = elapsed - start\n    print(\"Time spent: \", elapsed)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T14:49:54.880216Z","iopub.execute_input":"2021-10-10T14:49:54.880986Z","iopub.status.idle":"2021-10-10T14:49:54.896705Z","shell.execute_reply.started":"2021-10-10T14:49:54.88094Z","shell.execute_reply":"2021-10-10T14:49:54.895705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    Path = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train\"\n    Build_entire_train_dataset_V3(\"FLAIR\", Path)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-10T14:49:54.898265Z","iopub.execute_input":"2021-10-10T14:49:54.899222Z","iopub.status.idle":"2021-10-10T14:50:01.324897Z","shell.execute_reply.started":"2021-10-10T14:49:54.899086Z","shell.execute_reply":"2021-10-10T14:50:01.323788Z"},"trusted":true},"execution_count":null,"outputs":[]}]}