{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The base code of this notebook was taken from https://www.kaggle.com/piantic/no-tta-cassava-resnext50-32x4d-inference-lb0-903\n\nThe idea for dataset class was derived from https://www.kaggle.com/ihelon/brain-tumor-eda-with-animations-and-modeling","metadata":{}},{"cell_type":"markdown","source":"# Directory settings","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nTRAIN_PATH = '../input/rsna-miccai-png/train'\nTEST_PATH = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test'","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:37.666147Z","iopub.execute_input":"2021-10-22T16:19:37.666454Z","iopub.status.idle":"2021-10-22T16:19:37.672127Z","shell.execute_reply.started":"2021-10-22T16:19:37.666424Z","shell.execute_reply":"2021-10-22T16:19:37.671285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='efficientnet_b3'\n    size=512\n    batch_size=4\n    seed=42\n    target_size=2\n    target_col='MGMT_value'\n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    inference=True","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:37.701275Z","iopub.execute_input":"2021-10-22T16:19:37.701511Z","iopub.status.idle":"2021-10-22T16:19:37.706937Z","shell.execute_reply.started":"2021-10-22T16:19:37.701487Z","shell.execute_reply":"2021-10-22T16:19:37.706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Imports\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:37.743604Z","iopub.execute_input":"2021-10-22T16:19:37.743863Z","iopub.status.idle":"2021-10-22T16:19:42.446234Z","shell.execute_reply.started":"2021-10-22T16:19:37.743839Z","shell.execute_reply":"2021-10-22T16:19:42.445202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reproducibility","metadata":{}},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.448337Z","iopub.execute_input":"2021-10-22T16:19:42.448737Z","iopub.status.idle":"2021-10-22T16:19:42.458792Z","shell.execute_reply.started":"2021-10-22T16:19:42.448697Z","shell.execute_reply":"2021-10-22T16:19:42.457876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"test = os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test')\ntest = pd.DataFrame({'BraTS21ID' : test})\ntest['BraTS21ID'] = test['BraTS21ID'].astype(int)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.460123Z","iopub.execute_input":"2021-10-22T16:19:42.460601Z","iopub.status.idle":"2021-10-22T16:19:42.492273Z","shell.execute_reply.started":"2021-10-22T16:19:42.460559Z","shell.execute_reply":"2021-10-22T16:19:42.491451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['BraTS21ID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        root = f'{TEST_PATH}/{str(self.file_names[idx]).zfill(5)}/'\n        com = []\n        for typ in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n            paths = os.listdir(root + typ)\n            rnd = random.sample(paths, min(10, len(paths)))\n            typ_imgs = []\n            for f in rnd:\n                file_path = f'{root}{typ}/{f}'\n                dicom = pydicom.read_file(file_path)\n                data = apply_voi_lut(dicom.pixel_array, dicom)\n                if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n                    data = np.amax(data) - data\n                data = data - np.min(data)\n                data = data / np.max(data)\n                image = (data * 255).astype(np.uint8)\n                typ_imgs.append(cv2.resize(image, (CFG.size, CFG.size)))\n            com.append(np.mean(typ_imgs, axis = 0))\n        image = np.array(com).transpose((1,2,0)) / 255\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            image = image.float()\n        return image","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.493862Z","iopub.execute_input":"2021-10-22T16:19:42.494418Z","iopub.status.idle":"2021-10-22T16:19:42.508206Z","shell.execute_reply.started":"2021-10-22T16:19:42.49438Z","shell.execute_reply":"2021-10-22T16:19:42.507494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.511357Z","iopub.execute_input":"2021-10-22T16:19:42.511875Z","iopub.status.idle":"2021-10-22T16:19:42.51741Z","shell.execute_reply.started":"2021-10-22T16:19:42.511829Z","shell.execute_reply":"2021-10-22T16:19:42.516408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.conv = nn.Conv2d(4,3,1)\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.518651Z","iopub.execute_input":"2021-10-22T16:19:42.519141Z","iopub.status.idle":"2021-10-22T16:19:42.528736Z","shell.execute_reply.started":"2021-10-22T16:19:42.519102Z","shell.execute_reply":"2021-10-22T16:19:42.527763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\ndef load_state_eff(model_path):\n    state_dict = torch.load(model_path)['model']\n    return state_dict\n\ndef inference(model_eff, states, test_loader, device):\n    model_eff.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        x=1\n        for state in states:\n            model_eff.load_state_dict(state)\n            model_eff.eval()\n            with torch.no_grad():\n                y_preds = model_eff(images)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n            x+=1\n            \n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.530277Z","iopub.execute_input":"2021-10-22T16:19:42.530704Z","iopub.status.idle":"2021-10-22T16:19:42.541355Z","shell.execute_reply.started":"2021-10-22T16:19:42.530665Z","shell.execute_reply":"2021-10-22T16:19:42.540454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"model_eff = CustomEfficientNet(CFG.model_name, pretrained=False)\n\nstates = [load_state_eff('../input/rsna-training/efficientnet_b3_fold0_best.pth'),\n          load_state_eff('../input/rsna-training/efficientnet_b3_fold1_best.pth'),\n          load_state_eff('../input/rsna-training/efficientnet_b3_fold2_best.pth'),\n          load_state_eff('../input/rsna-training/efficientnet_b3_fold3_best.pth'),\n          load_state_eff('../input/rsna-training/efficientnet_b3_fold4_best.pth'),\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:42.542628Z","iopub.execute_input":"2021-10-22T16:19:42.543106Z","iopub.status.idle":"2021-10-22T16:19:55.809603Z","shell.execute_reply.started":"2021-10-22T16:19:42.543067Z","shell.execute_reply":"2021-10-22T16:19:55.808707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\n\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model_eff, states, test_loader, device)\n\n# submission\ntest['MGMT_value'] = predictions[:,1]\ntest[['BraTS21ID', 'MGMT_value']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-22T16:19:55.813134Z","iopub.execute_input":"2021-10-22T16:19:55.8134Z","iopub.status.idle":"2021-10-22T16:20:23.298978Z","shell.execute_reply.started":"2021-10-22T16:19:55.813373Z","shell.execute_reply":"2021-10-22T16:20:23.298084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}