{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\nfrom tqdm import tqdm_notebook as tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load train labels\ntrain_labels = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\ntrain_labels = train_labels.rename(columns={'BraTS21ID':'id', 'MGMT_value':'mgmt'}) # rename columns for simplicity\ntrain_labels.drop(train_labels[train_labels['id'].isin([109, 123, 709])].index, inplace=True) # Remove problematic/corrupted samples\ntrain_labels.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, math, glob, re\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport pydicom\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom sklearn.model_selection import train_test_split\n\n\nfrom random import shuffle\nimport tensorflow as tf\n\n# x_train, x_val, y_train, y_val = train_test_split(train_labels.id, \n#                                                   train_labels.mgmt, \n#                                                   test_size=0.2, \n#                                                   random_state=42,\n#                                                   stratify=train_labels.mgmt)\n\nx_train = train_labels.id\ny_train = train_labels.mgmt\n\nprint(x_train.shape)\nprint(y_train.shape)\n# print(x_val.shape)\n# print(y_val.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() \n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(subject_id, image, label):\n    feature = {\n        'subject_id': _int64_feature(subject_id),\n        'image': _bytes_feature(image.tobytes()),\n        'mgmt': _float_feature(label)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\ndef serialize_test_example(subject_id, image):\n    feature = {\n        'subject_id': _int64_feature(subject_id),\n        'image': _bytes_feature(image.tobytes())\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_3D_images(subject_id, dataset_path = '../input/rsna-processed-voxels-64x256x256-clahe/voxels/', contrasts = ['FLAIR', 'T1w', 'T1wCE', 'T2w']):\n    subject_volume = []\n    for contrast in contrasts:\n        subject_volume.append(np.load(os.path.join(dataset_path, contrast, str(subject_id).zfill(5) +'.npy')))\n    return tf.stack(subject_volume, axis=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir -p ./tfrecords/train/\nwith tf.io.TFRecordWriter(str(\"./tfrecords/train\" + os.sep + 'data_train.tfrec'),\n                          options=tf.io.TFRecordOptions(compression_type=\"GZIP\")) as writer:\n    for x,y in tqdm(zip(x_train,y_train), total=len(x_train)):\n        img = load_3D_images(x).numpy()\n        example = serialize_example(int(x), img, y)\n        writer.write(example)\n\n# ! mkdir -p ./tfrecords/valid/\n# with tf.io.TFRecordWriter(str(\"./tfrecords/valid\" + os.sep + 'data_val.tfrec'),\n#                           options=tf.io.TFRecordOptions(compression_type=\"GZIP\")) as writer:\n#     for x,y in tqdm(zip(x_val,y_val), total = len(x_val)):\n#         img = load_3D_images(x).numpy()\n#         example = serialize_example(int(x), img, y)\n#         writer.write(example)\n        \n# Get test subject id's\ntest_path = '../input/rsna-processed-test-voxels-clahe/voxels'\ntest_ids = [file.split('.')[0] for file in os.listdir(test_path + '/FLAIR') if os.path.isfile(os.path.join(test_path + '/FLAIR', file))]\n! mkdir -p ./tfrecords/test/\nwith tf.io.TFRecordWriter(str(\"./tfrecords/test\" + os.sep + 'data_test.tfrec'),\n                          options=tf.io.TFRecordOptions(compression_type=\"GZIP\")) as writer:\n    for x in tqdm(test_ids):\n        img = load_3D_images(x, dataset_path=test_path).numpy()\n        example = serialize_test_example(int(x), img)\n        writer.write(example)","metadata":{},"execution_count":null,"outputs":[]}]}