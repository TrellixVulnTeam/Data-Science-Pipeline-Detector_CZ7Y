{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RSNA-MICCAI Brain Tumor Radiogenomic Classification - Exploratory Data Analysis and Modeling\n\n\n### Predict the status of a genetic biomarker important for brain cancer treatment\n\nQuick Exploratory Data Analysis for [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification) challenge    \n\n\n","metadata":{}},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-competitions/kaggle/29653/logos/header.png)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:darkviolet; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation</center></h3>\n\n* [Overview](#1)\n* [Data Visualization](#2)\n    \n\n* [Competition Metric](#10)\n* [Sample Submission](#20)\n    \n\n* [Modeling](#100)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Overview<center><h2>","metadata":{}},{"cell_type":"markdown","source":"The work uses some ideas from next great works:\n- https://www.kaggle.com/avloss/eda-with-animation - animation technique\n- https://www.kaggle.com/victorfernandezalbor/brats-20-win-nnunet-segment-with-brats-21-rsna - nnUnet","metadata":{}},{"cell_type":"markdown","source":"Research papers to try out: \n<https://link.springer.com/article/10.1007/s40998-021-00426-9>","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/MIC-DKFZ/nnUNet.git\n!git clone https://github.com/NVIDIA/apex\n!pip install -e ./nnUNet\n!pip install --upgrade git+https://github.com/nanohanno/hiddenlayer.git@bugfix/get_trace_graph#egg=hiddenlayer","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:36:31.436772Z","iopub.execute_input":"2021-10-14T22:36:31.43736Z","iopub.status.idle":"2021-10-14T22:37:11.583694Z","shell.execute_reply.started":"2021-10-14T22:36:31.437273Z","shell.execute_reply":"2021-10-14T22:37:11.582835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/shijianjian/EfficientNet-PyTorch-3D\n!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:37:11.587356Z","iopub.execute_input":"2021-10-14T22:37:11.587574Z","iopub.status.idle":"2021-10-14T22:37:30.505257Z","shell.execute_reply.started":"2021-10-14T22:37:11.587546Z","shell.execute_reply":"2021-10-14T22:37:30.504297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D')\nfrom efficientnet_pytorch_3d import EfficientNet3D\npackage_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\nsys.path.append(package_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:37:30.508778Z","iopub.execute_input":"2021-10-14T22:37:30.509025Z","iopub.status.idle":"2021-10-14T22:37:34.995249Z","shell.execute_reply.started":"2021-10-14T22:37:30.508994Z","shell.execute_reply":"2021-10-14T22:37:34.994529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport json\nimport glob\nimport random\nimport collections\nimport re\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport time\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport efficientnet_pytorch\nfrom sklearn.model_selection import StratifiedKFold\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom matplotlib import pyplot\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\nfrom sklearn import metrics\nimport optuna\n# from boostaroota import BoostARoota\nfrom sklearn.metrics import log_loss\nfrom optuna.samplers import TPESampler\nimport functools\nfrom functools import partial\nimport xgboost as xgb\nfrom sklearn.metrics import confusion_matrix, average_precision_score, recall_score, accuracy_score, f1_score\nimport pylab as pl\nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport torch.nn as nn\nimport tensorflow\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import Sequence\nfrom random import shuffle\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC\nimport math\nimport joblib\nDEVICE = \"GPU\"","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:37:34.997328Z","iopub.execute_input":"2021-10-14T22:37:34.997602Z","iopub.status.idle":"2021-10-14T22:37:40.965348Z","shell.execute_reply.started":"2021-10-14T22:37:34.997568Z","shell.execute_reply":"2021-10-14T22:37:40.964589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download pretrained Task001_BrainTumour, and setting up the nnUnet environment.\nos.mkdir('./nnUNet_raw_data_base')\nos.mkdir('./nnUNet_raw_data_base/nnUNet_raw_data')\nos.mkdir('./RESULTS_FOLDER')\nos.environ['nnUNet_raw_data_base'] = './nnUNet_raw_data_base/nnUNet_raw_data'\nos.environ['RESULTS_FOLDER'] = './RESULTS_FOLDER'\nos.environ['nnUNet_preprocessed'] = './nnUNet_preprocessed'\n!nnUNet_download_pretrained_model Task001_BrainTumour","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:37:40.966437Z","iopub.execute_input":"2021-10-14T22:37:40.966676Z","iopub.status.idle":"2021-10-14T22:38:19.760425Z","shell.execute_reply.started":"2021-10-14T22:37:40.966646Z","shell.execute_reply":"2021-10-14T22:38:19.759495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '/media/roland/data/kaggle/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:19.762151Z","iopub.execute_input":"2021-10-14T22:38:19.762446Z","iopub.status.idle":"2021-10-14T22:38:19.768977Z","shell.execute_reply.started":"2021-10-14T22:38:19.762407Z","shell.execute_reply":"2021-10-14T22:38:19.768162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train/** - folder containing the training files, with each top-level folder representing a subject  \n**train_labels.csv** - file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation)   \n**test/** - the test files, which use the same structure as train/; your task is to predict the MGMT_value for each subject in the test data. NOTE: the total size of the rerun test set (Public and Private) is ~5x the size of the Public test set   \n**sample_submission.csv** - a sample submission file in the correct format","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Data Visualization<center><h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-14T06:41:32.077425Z","iopub.execute_input":"2021-07-14T06:41:32.077767Z","iopub.status.idle":"2021-07-14T06:41:32.0845Z","shell.execute_reply.started":"2021-07-14T06:41:32.077737Z","shell.execute_reply":"2021-07-14T06:41:32.082683Z"}}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:19.770341Z","iopub.execute_input":"2021-10-14T22:38:19.771129Z","iopub.status.idle":"2021-10-14T22:38:25.217483Z","shell.execute_reply.started":"2021-10-14T22:38:19.771095Z","shell.execute_reply":"2021-10-14T22:38:25.216654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nsns.countplot(data=train_df, x=\"MGMT_value\");","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:25.218906Z","iopub.execute_input":"2021-10-14T22:38:25.219188Z","iopub.status.idle":"2021-10-14T22:38:27.805749Z","shell.execute_reply.started":"2021-10-14T22:38:25.219152Z","shell.execute_reply":"2021-10-14T22:38:27.804999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image_pixel_array(arr, margin = 5, crop = True):\n\n    arr_formatted = arr.copy()\n    arr_formatted = arr_formatted - np.min(arr_formatted)\n    if np.max(arr_formatted) != 0:\n        arr_formatted = arr_formatted / np.max(arr_formatted)\n\n    percent_pixels = ((arr_formatted>0).sum()/(arr_formatted.shape[0]*arr_formatted.shape[1])) * 100\n    \n    if (crop) & (percent_pixels>5):\n        # Get rows containing brain portion\n        first_row_index = list([arr_formatted.sum(axis = 1)>0][0])\n        first_row_index = first_row_index.index(True) - margin\n        if first_row_index<0:\n            first_row_index = 0\n\n        last_row_index = list([arr_formatted.sum(axis = 1)>0][0])\n        last_row_index.reverse()\n        last_row_index = (len(last_row_index) - last_row_index.index(True)) + margin\n        if last_row_index>arr_formatted.shape[0]:\n            last_row_index = arr_formatted.shape[0]\n\n        # Get columns containing brain portion\n        first_column_index = list([arr_formatted.sum(axis = 0)>0][0])\n        first_column_index = first_column_index.index(True) - margin\n        if first_column_index<0:\n            first_column_index = 0\n\n        last_column_index = list([arr_formatted.sum(axis = 0)>0][0])\n        last_column_index.reverse()\n        last_column_index = (len(last_column_index) - last_column_index.index(True)) + margin\n        if last_column_index>arr_formatted.shape[1]:\n            last_column_index = arr_formatted.shape[1]\n\n        num_rows = last_row_index - first_row_index\n        num_columns = last_column_index - first_column_index\n        \n        if ((num_rows<arr_formatted.shape[0]) & (num_rows<arr_formatted.shape[1])) & ((num_columns<arr_formatted.shape[0]) & (num_columns<arr_formatted.shape[1])):\n            if (num_columns > num_rows):\n                if arr_formatted.shape[0] < (last_row_index+(num_columns-num_rows)):\n                    last_row_index = arr_formatted.shape[0]\n                    first_row_index = (last_row_index - num_columns)\n                else:\n                    last_row_index = last_row_index+(num_columns-num_rows)\n            elif (num_columns < num_rows):\n                if arr_formatted.shape[1] < (last_column_index+(num_rows-num_columns)):\n                    last_column_index = arr_formatted.shape[1]\n                    first_column_index = (last_column_index - num_rows)\n                else:\n                    last_column_index = last_column_index+(num_rows-num_columns)\n\n            arr_crop = arr[first_row_index:last_row_index,:]\n            arr_crop = arr_crop[:,first_column_index:last_column_index]   \n        else:\n            first_row_index = np.NaN\n            last_row_index = np.NaN\n            first_column_index = np.NaN\n            last_column_index = np.NaN\n            arr_crop = arr.copy()\n    \n    else:\n        first_row_index = np.NaN\n        last_row_index = np.NaN\n        first_column_index = np.NaN\n        last_column_index = np.NaN\n        arr_crop = arr.copy()\n    return arr_crop, [first_row_index,last_row_index,first_column_index,last_column_index]","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:27.810216Z","iopub.execute_input":"2021-10-14T22:38:27.812543Z","iopub.status.idle":"2021-10-14T22:38:28.735317Z","shell.execute_reply.started":"2021-10-14T22:38:27.812503Z","shell.execute_reply":"2021-10-14T22:38:28.734442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_plane(data):\n    x1, y1, _, x2, y2, _ = [round(j) for j in data.ImageOrientationPatient]\n    cords = [x1, y1, x2, y2]\n\n    if cords == [1, 0, 0, 0]:\n        return 'Coronal'\n    elif cords == [1, 0, 0, 1]:\n        return 'Axial'\n    elif cords == [0, 1, 0, 0]:\n        return 'Sagittal'\n    else:\n        return 'Unknown'","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:28.744739Z","iopub.execute_input":"2021-10-14T22:38:28.74702Z","iopub.status.idle":"2021-10-14T22:38:28.756206Z","shell.execute_reply.started":"2021-10-14T22:38:28.746972Z","shell.execute_reply":"2021-10-14T22:38:28.755459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_voxel(dcm_path):\n    imgs = []\n    positions = []\n    \n    img = pydicom.dcmread(str(dcm_path))\n    imgs.append(img.pixel_array)\n    positions.append(img.ImagePositionPatient)\n\n    plane = get_image_plane(img)\n    voxel = np.stack(imgs)\n    \n    # reorder planes if needed and rotate voxel\n    if plane == \"Coronal\":\n        if positions[0][1] < positions[-1][1]:\n            voxel = voxel[::-1]\n        voxel = voxel.transpose((1, 0, 2))\n    elif plane == \"Sagittal\":\n        if positions[0][0] < positions[-1][0]:\n            voxel = voxel[::-1]\n        voxel = voxel.transpose((1, 2, 0))\n        voxel = np.rot90(voxel, 2, axes=(1, 2))\n    elif plane == \"Axial\":\n        if positions[0][2] > positions[-1][2]:\n            voxel = voxel[::-1]\n        voxel = np.rot90(voxel, 2)\n        \n    min_index = np.argmin(voxel.shape)\n    \n    if min_index == 0:\n        voxel = voxel[0,:,:]\n    elif min_index == 1:\n        voxel = voxel[:,0,:]\n    elif min_index == 2:\n        voxel = voxel[:,:,0]\n    \n    return voxel, plane","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:28.760499Z","iopub.execute_input":"2021-10-14T22:38:28.761156Z","iopub.status.idle":"2021-10-14T22:38:28.780047Z","shell.execute_reply.started":"2021-10-14T22:38:28.761116Z","shell.execute_reply":"2021-10-14T22:38:28.778995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_for_saving_into_png(path, voi_lut = False, fix_monochrome = True, rotate = 0):\n    dicom = pydicom.read_file(path)\n    data, plane = get_voxel(path)\n    \n    if voi_lut:\n        data = apply_voi_lut(data, dicom)\n    \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n    \n    # MONOCHROME1 indicates that the greyscale ranges from bright to dark with ascending pixel values, whereas MONOCHROME2 ranges from dark to bright with ascending pixel values\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n        \n    data = (data * 255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:28.784429Z","iopub.execute_input":"2021-10-14T22:38:28.785961Z","iopub.status.idle":"2021-10-14T22:38:28.798741Z","shell.execute_reply.started":"2021-10-14T22:38:28.785921Z","shell.execute_reply":"2021-10-14T22:38:28.797816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\ndef create_animation(ims):\n    fig = plt.figure()\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap=\"gray\")\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//24)\n\ndef get_gray(org_img):\n    gray_img=cv2.cvtColor(org_img.copy(),cv2.COLOR_RGB2GRAY)\n    return gray_img\n\ndef get_RGB(gray_img):\n    rgb_img=cv2.cvtColor(gray_img.copy(),cv2.COLOR_GRAY2RGB)\n    return rgb_img\n\ndef get_threshold(org_img,blur=False,erode=False,dilate=False):\n    gray_img=get_gray(org_img.copy())\n    if blur:\n        img=cv2.GaussianBlur(gray_img.copy(), (5, 5), 0)\n    img=cv2.threshold(img,5,255,cv2.THRESH_BINARY)[1]\n    if erode:\n        img=cv2.erode(img, None, iterations=2)\n    if dilate:\n        img=cv2.dilate(img, None, iterations=2)\n    return img\n\ndef get_contours(th_img):\n    cnts,_ = cv2.findContours(th_img.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n    return cnts\n   \ndef edge_smoothing(org_img,cnts):\n    gray_img=get_gray(org_img.copy())\n    if len(cnts)==0:  \n        return gray_img\n    c = max(cnts, key=cv2.contourArea)\n    black_img=np.zeros_like(gray_img)\n    black_cnt=cv2.drawContours(black_img.copy(),c,-1, (255, 255, 255), 2)\n    black_cnt=cv2.dilate(black_cnt.copy(), None, iterations=10)\n    white_cnt=cv2.bitwise_not(black_cnt.copy())\n    white_cnt=get_RGB(white_cnt)\n    smooth_img=cv2.bitwise_and(white_cnt.copy(),org_img.copy())\n    return smooth_img\n\ndef get_iou(bb1, bb2):\n    assert bb1[0] < bb1[2]\n    assert bb1[1] < bb1[3]\n    assert bb2[0] < bb2[2]\n    assert bb2[1] < bb2[3]\n    x_left = max(bb1[0], bb2[0])\n    y_top = max(bb1[1], bb2[1])\n    x_right = min(bb1[2], bb2[2])\n    y_bottom = min(bb1[3], bb2[3])\n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n    assert iou >= 0.0\n    assert iou <= 1.0\n    return iou\n\ndef check_overlapping(prev_cnt,curr_cnt):\n    x,y,w,h=cv2.boundingRect(prev_cnt)\n    bb1=[x,y,x+w,y+h]\n    x,y,w,h=cv2.boundingRect(curr_cnt)\n    bb2=[x,y,x+w,y+h]\n    iou=get_iou(bb1,bb2)\n    return iou\n    \n\ndef load_patient_images(path,threshold=False,roi_threshold=False,matchpattern=False,template_path=None):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    templates=[]\n    if not template_path is None:\n        for t_path in template_path:\n            templates.append(cv2.imread(t_path))\n    \n    images = []\n    for filename in t_paths:\n        imageio.imsave('temp_png.png',load_dicom_for_saving_into_png(filename))\n        data = cv2.imread('temp_png.png')\n        if data.max() == 0:\n            continue\n        images.append(data)\n    \n    mid_idx=len(images)//2\n    th_middle_image=get_threshold(images[mid_idx].copy(),blur=True,erode=True,dilate=True)\n    x1,y1,w1,h1=cv2.boundingRect(th_middle_image)\n    print('-->',x1,y1,w1,h1)\n    max_area=w1*h1\n    \n    images=np.array(images)\n    new_images=[]\n    if images[0].shape[0]<=256 or images[1].shape[0]<=256:\n        t_size=1\n    elif images[0].shape[0]>=500 or images[1].shape[0]>=500:\n        t_size=3\n    else:\n        t_size=2\n    print('text size: ',t_size)\n     \n    prev_cnt=0\n    initialize_prev_cnt=False\n    for i,data in enumerate(images):\n        th_data=get_threshold(data.copy(),blur=True,erode=True,dilate=True)\n        x,y,w,h=cv2.boundingRect(th_data)\n        area=w*h\n        ratio=area/max_area\n        if ratio<0.4:\n            continue\n            \n        org_cnts=get_contours(th_data.copy())\n        if org_cnts:\n            org_max = max(org_cnts, key=cv2.contourArea)\n            org_cnts_area=cv2.contourArea(org_max)\n        \n        if matchpattern:\n            image=data.copy()\n            comm_image=image.copy()\n            result=cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n            (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(result)\n            (startX, startY) = maxLoc\n            endX = startX + template.shape[1]\n            endY = startY + template.shape[0]\n        \n        if roi_threshold:\n            image=data.copy()\n            g_image=cv2.cvtColor(image.copy(),cv2.COLOR_BGR2GRAY)\n            thresh=g_image.mean()+((g_image.max()-g_image.mean())//3)\n            th_data=cv2.threshold(g_image,thresh,g_image.max(),cv2.THRESH_BINARY)[1]\n            g_image=cv2.putText(g_image,f\"{i}\",(20,25),3,1,(255,255,0),2) \n            data=np.hstack([g_image,th_data])   \n        \n        if threshold:\n            image=data.copy()  \n            \n            g_image=cv2.cvtColor(image.copy(),cv2.COLOR_BGR2GRAY)\n            mean_values=g_image[np.nonzero(g_image)]\n            thresh=mean_values.mean()+((mean_values.max()-mean_values.mean())//2)\n            smooth_image=edge_smoothing(image,org_cnts)\n            smooth_image=cv2.putText(smooth_image,f\"{i}\",(20,25),t_size,1,(thresh+1,thresh+1,thresh+1),2)\n            gray_smooth_image=get_gray(smooth_image)\n            \n            th_image=cv2.threshold(gray_smooth_image.copy(),thresh,g_image.max(),cv2.THRESH_BINARY)[1]\n            cnts,_ = cv2.findContours(th_image.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n            c = max(cnts, key=cv2.contourArea)\n            data=cv2.drawContours(image.copy(),c,-1, (0, 255, 255), 2)\n\n        new_images.append(data)        \n               \n    return new_images\n\ndef get_images(i,mri_type,threshold=False,roi_threshold=False,matchpattern=False,template_path=None):\n    patient_id=str(train_df['BraTS21ID'][i]).zfill(5)\n    mgmt=train_df['MGMT_value'][i]\n    path=f'{data_directory}/train/{patient_id}/{mri_type}'\n    print('Path: ',path)\n    print('# Images: ',len(os.listdir(path)))\n    print('MGMT: ',mgmt)\n    images=load_patient_images(path,threshold,roi_threshold,matchpattern,template_path)\n    print(np.array(images).shape)\n    return images","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:28.804053Z","iopub.execute_input":"2021-10-14T22:38:28.806647Z","iopub.status.idle":"2021-10-14T22:38:28.854888Z","shell.execute_reply.started":"2021-10-14T22:38:28.806603Z","shell.execute_reply":"2021-10-14T22:38:28.854236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio \ni=80\nmri_type='FLAIR'\nimages=get_images(i,mri_type,threshold=True)\ncreate_animation(images)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:28.856502Z","iopub.execute_input":"2021-10-14T22:38:28.856751Z","iopub.status.idle":"2021-10-14T22:38:30.074033Z","shell.execute_reply.started":"2021-10-14T22:38:28.856721Z","shell.execute_reply":"2021-10-14T22:38:30.073218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path, voi_lut = False, fix_monochrome = True, rotate = 0):\n    dicom = pydicom.read_file(path)\n#     data, plane = get_voxel(path)\n    data = dicom.pixel_array\n    \n    if voi_lut:\n        data = apply_voi_lut(data, dicom)\n    \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n    \n    # MONOCHROME1 indicates that the greyscale ranges from bright to dark with ascending pixel values, whereas MONOCHROME2 ranges from dark to bright with ascending pixel values\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n#     data = data - np.min(data)\n#     if np.max(data) != 0:\n#         data = data / np.max(data)\n        \n#     data = (data * 255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:30.078103Z","iopub.execute_input":"2021-10-14T22:38:30.078614Z","iopub.status.idle":"2021-10-14T22:38:30.09154Z","shell.execute_reply.started":"2021-10-14T22:38:30.078571Z","shell.execute_reply":"2021-10-14T22:38:30.090747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_sample(\n    brats21id, \n    slice_i,\n    mgmt_value,\n    types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"), \n    rotate = 0\n):\n    plt.figure(figsize=(16, 5))\n    patient_path = os.path.join(\n        \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/\", \n        str(brats21id).zfill(5),\n    )\n    for i, t in enumerate(types, 1):\n        t_paths = sorted(\n            glob.glob(os.path.join(patient_path, t, \"*\")), \n            key=lambda x: int(x[:-4].split(\"-\")[-1]),\n        )\n        data = load_dicom(t_paths[int(len(t_paths) * slice_i)], rotate = rotate)\n#         if data.sum()!=0:\n#             data = crop_image_pixel_array(data, crop = False)\n        data = cv2.resize(data, (256, 256)) / 255\n        plt.subplot(1, 4, i)\n        plt.imshow(data, cmap=\"gray\")\n        plt.title(f\"{t}\", fontsize=16)\n        plt.axis(\"off\")\n\n    plt.suptitle(f\"MGMT_value: {mgmt_value}\", fontsize=16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:30.09414Z","iopub.execute_input":"2021-10-14T22:38:30.094459Z","iopub.status.idle":"2021-10-14T22:38:30.114114Z","shell.execute_reply.started":"2021-10-14T22:38:30.094424Z","shell.execute_reply":"2021-10-14T22:38:30.113221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Before cropping')\ndata = load_dicom('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/FLAIR/Image-101.dcm', rotate = 0)\nprint(data.shape)\nplt.imshow(data, cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:30.118157Z","iopub.execute_input":"2021-10-14T22:38:30.118695Z","iopub.status.idle":"2021-10-14T22:38:30.367341Z","shell.execute_reply.started":"2021-10-14T22:38:30.118659Z","shell.execute_reply":"2021-10-14T22:38:30.366693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('After cropping')\ndata = load_dicom('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/FLAIR/Image-101.dcm', rotate = 0)\ndata,_ = crop_image_pixel_array(data, crop = True)\nprint(data.shape)\nplt.imshow(data, cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:30.369841Z","iopub.execute_input":"2021-10-14T22:38:30.370036Z","iopub.status.idle":"2021-10-14T22:38:30.576072Z","shell.execute_reply.started":"2021-10-14T22:38:30.370013Z","shell.execute_reply":"2021-10-14T22:38:30.57542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES = 64\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=256, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    sum_pixels_across_files = [load_dicom(x).sum() for x in files]\n    files_with_pixels = [files[x] for x in range(0, len(sum_pixels_across_files)) if sum_pixels_across_files[x]>0]\n    middle = len(files_with_pixels)//2\n    num_imgs2 = num_imgs//2\n\n    if len(files_with_pixels)>=num_imgs:\n#         best_interval = int(len(files_with_pixels)/num_imgs)\n        best_interval = 1\n        p1 = max(0, middle - best_interval*num_imgs2)\n        p2 = min(len(files), middle + best_interval*num_imgs2)    \n        selected_files = files_with_pixels[p1:p2:best_interval]\n    else:\n        p1 = max(0, middle - num_imgs2)\n        p2 = min(len(files), middle + num_imgs2)  \n        selected_files = files_with_pixels[p1:p2]\n    \n    images_list_array = [load_dicom(f, rotate=rotate) for f in selected_files]\n    \n    #Cropping\n    mean_image_for_cropping = np.array(images_list_array).mean(axis = 0)\n    img_cropped,dim_for_cropping = crop_image_pixel_array(mean_image_for_cropping)\n    first_row_index = dim_for_cropping[0]\n    last_row_index = dim_for_cropping[1]\n    first_column_index = dim_for_cropping[2]\n    last_column_index = dim_for_cropping[3]\n    if ((not pd.isnull(first_row_index)) & (not pd.isnull(last_row_index)) & (not pd.isnull(first_column_index)) & (not pd.isnull(last_column_index))):\n        images_list_array = [f[first_row_index:last_row_index,first_column_index:last_column_index] for f in images_list_array]\n\n    images_list_array = [cv2.resize(f, (img_size, img_size)) for f in images_list_array]\n    img3d = np.stack(images_list_array).T\n\n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d / np.max(img3d)\n\n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00012\",mri_type = 'FLAIR')\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))\nprint(a.shape)\nplt.imshow(a[0,:,:,10], cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:30.577272Z","iopub.execute_input":"2021-10-14T22:38:30.577518Z","iopub.status.idle":"2021-10-14T22:38:34.832Z","shell.execute_reply.started":"2021-10-14T22:38:30.577484Z","shell.execute_reply":"2021-10-14T22:38:34.831313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in random.sample(range(train_df.shape[0]), 10):\n    _brats21id = train_df.iloc[i][\"BraTS21ID\"]\n    _mgmt_value = train_df.iloc[i][\"MGMT_value\"]\n    visualize_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:34.833161Z","iopub.execute_input":"2021-10-14T22:38:34.833417Z","iopub.status.idle":"2021-10-14T22:38:39.065451Z","shell.execute_reply.started":"2021-10-14T22:38:34.833383Z","shell.execute_reply":"2021-10-14T22:38:39.064774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(6, 6))\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap=\"gray\")\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//24)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.066826Z","iopub.execute_input":"2021-10-14T22:38:39.067273Z","iopub.status.idle":"2021-10-14T22:38:39.074005Z","shell.execute_reply.started":"2021-10-14T22:38:39.067236Z","shell.execute_reply":"2021-10-14T22:38:39.07322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_line(path, crop = False):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    images = []\n    for filename in t_paths:\n        data = load_dicom(filename)\n        \n        data = data - np.min(data)\n        if np.max(data) != 0:\n            data = data / np.max(data)\n        \n        if crop:\n            if data.sum()!=0:\n                data = crop_image_pixel_array(data, crop = False)\n        \n        data = cv2.resize(data, (256, 256))\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.075538Z","iopub.execute_input":"2021-10-14T22:38:39.075802Z","iopub.status.idle":"2021-10-14T22:38:39.087556Z","shell.execute_reply.started":"2021-10-14T22:38:39.075768Z","shell.execute_reply":"2021-10-14T22:38:39.086868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/FLAIR\")\ncreate_animation(images)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:03:28.539176Z","iopub.execute_input":"2021-10-14T01:03:28.539426Z","iopub.status.idle":"2021-10-14T01:03:42.657037Z","shell.execute_reply.started":"2021-10-14T01:03:28.539396Z","shell.execute_reply":"2021-10-14T01:03:42.656295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T1w\")\ncreate_animation(images)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T11:54:45.602853Z","iopub.execute_input":"2021-10-13T11:54:45.603354Z","iopub.status.idle":"2021-10-13T11:54:47.171897Z","shell.execute_reply.started":"2021-10-13T11:54:45.603317Z","shell.execute_reply":"2021-10-13T11:54:47.170924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T1wCE\")\ncreate_animation(images)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:02.203034Z","iopub.execute_input":"2021-10-04T05:08:02.203301Z","iopub.status.idle":"2021-10-04T05:08:06.807948Z","shell.execute_reply.started":"2021-10-04T05:08:02.203266Z","shell.execute_reply":"2021-10-04T05:08:06.807091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T2w\")\ncreate_animation(images)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:06.809461Z","iopub.execute_input":"2021-10-04T05:08:06.809713Z","iopub.status.idle":"2021-10-04T05:08:20.845312Z","shell.execute_reply.started":"2021-10-04T05:08:06.80968Z","shell.execute_reply":"2021-10-04T05:08:20.844486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Competition Metric<center><h2>","metadata":{}},{"cell_type":"markdown","source":"Submissions are evaluated on [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) between the predicted probability and the observed target.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, auc\n\nlist_y_true = [\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\nlist_y_pred = [\n    [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n    [0.9, 0.9, 0.9, 0.9, 0.1, 0.9, 0.9, 0.1, 0.9, 0.1, 0.1, 0.5],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], #  IMBALANCE\n]\n\nfor y_true, y_pred in zip(list_y_true, list_y_pred):\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(5, 5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.090035Z","iopub.execute_input":"2021-10-14T22:38:39.09062Z","iopub.status.idle":"2021-10-14T22:38:39.65489Z","shell.execute_reply.started":"2021-10-14T22:38:39.090585Z","shell.execute_reply":"2021-10-14T22:38:39.65423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"20\"></a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Sample Submission<center><h2>","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.656195Z","iopub.execute_input":"2021-10-14T22:38:39.656441Z","iopub.status.idle":"2021-10-14T22:38:39.677735Z","shell.execute_reply.started":"2021-10-14T22:38:39.656408Z","shell.execute_reply":"2021-10-14T22:38:39.677088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"100\"></a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Modeling<center><h2>","metadata":{}},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n# set_seed(42)\nset_seed(3407)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.678894Z","iopub.execute_input":"2021-10-14T22:38:39.679225Z","iopub.status.idle":"2021-10-14T22:38:39.733282Z","shell.execute_reply.started":"2021-10-14T22:38:39.679182Z","shell.execute_reply":"2021-10-14T22:38:39.732604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ndf = df[~(df['BraTS21ID'].isin([109, 123, 709]))].reset_index(drop = True)\ndf_train, df_valid = sk_model_selection.train_test_split(\n    df, \n    test_size=0.2, \n    random_state=42, \n    stratify=df[\"MGMT_value\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.734614Z","iopub.execute_input":"2021-10-14T22:38:39.734875Z","iopub.status.idle":"2021-10-14T22:38:39.748477Z","shell.execute_reply.started":"2021-10-14T22:38:39.734842Z","shell.execute_reply":"2021-10-14T22:38:39.747817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.749641Z","iopub.execute_input":"2021-10-14T22:38:39.749909Z","iopub.status.idle":"2021-10-14T22:38:39.758646Z","shell.execute_reply.started":"2021-10-14T22:38:39.749876Z","shell.execute_reply":"2021-10-14T22:38:39.757658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ratio 'T1w/T2w' : <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6465519/>","metadata":{}},{"cell_type":"markdown","source":"# nnUnet","metadata":{}},{"cell_type":"code","source":"!mkdir -p ./RESULTS_FOLDER/nnUNet/2d/image_raw\n!cp ../input/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/Task101_BrainTumour/imagesTs/BRATS_188_0000.nii ./RESULTS_FOLDER/nnUNet/2d/image_raw/BRATS_188_0000.nii.gz\n!cp ../input/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/Task101_BrainTumour/imagesTs/BRATS_188_0001.nii ./RESULTS_FOLDER/nnUNet/2d/image_raw/BRATS_188_0001.nii.gz\n!cp ../input/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/Task101_BrainTumour/imagesTs/BRATS_188_0002.nii ./RESULTS_FOLDER/nnUNet/2d/image_raw/BRATS_188_0002.nii.gz\n!cp ../input/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/Task101_BrainTumour/imagesTs/BRATS_188_0003.nii ./RESULTS_FOLDER/nnUNet/2d/image_raw/BRATS_188_0003.nii.gz\n!nnUNet_predict -i ./RESULTS_FOLDER/nnUNet/2d/image_raw -o ./RESULTS_FOLDER/nnUNet/2d/ -t \"001\" -tr nnUNetTrainerV2 -m 2d","metadata":{"execution":{"iopub.status.busy":"2021-10-14T21:07:46.797626Z","iopub.execute_input":"2021-10-14T21:07:46.797956Z","iopub.status.idle":"2021-10-14T21:08:26.574707Z","shell.execute_reply.started":"2021-10-14T21:07:46.797917Z","shell.execute_reply":"2021-10-14T21:08:26.573582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ./RESULTS_FOLDER/nnUNet/2d/image_raw/","metadata":{"execution":{"iopub.status.busy":"2021-10-14T21:08:26.578098Z","iopub.execute_input":"2021-10-14T21:08:26.578336Z","iopub.status.idle":"2021-10-14T21:08:27.273215Z","shell.execute_reply.started":"2021-10-14T21:08:26.578307Z","shell.execute_reply":"2021-10-14T21:08:27.272243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_raw=\"../input/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/Task101_BrainTumour/imagesTs/BRATS_188_0000.nii\"\npath=\"./RESULTS_FOLDER/nnUNet/2d/\"\n\nimport nibabel as nib\nplt.figure(figsize=(12,6))\nplt.subplot(121)\nflair_nib = nib.load(path_raw)\nflair_nib_array = flair_nib.get_fdata()\nplt.imshow(flair_nib_array[:,:,flair_nib_array.shape[2]//2], cmap = 'gray')\nplt.subplot(122)\nflair_nib = nib.load(path+\"BRATS_188.nii.gz\")\nflair_nib_array = flair_nib.get_fdata()\nplt.imshow(flair_nib_array[:,:,flair_nib_array.shape[2]//2], cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T21:08:27.276435Z","iopub.execute_input":"2021-10-14T21:08:27.276686Z","iopub.status.idle":"2021-10-14T21:08:27.821447Z","shell.execute_reply.started":"2021-10-14T21:08:27.276657Z","shell.execute_reply":"2021-10-14T21:08:27.820715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import SimpleITK as sitk\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nfrom os.path import join\nfrom fastai.vision.all import *\nimport nibabel as nib","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:39.76376Z","iopub.execute_input":"2021-10-14T22:38:39.764009Z","iopub.status.idle":"2021-10-14T22:38:40.942966Z","shell.execute_reply.started":"2021-10-14T22:38:39.763977Z","shell.execute_reply":"2021-10-14T22:38:40.942153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./test/post/\nreader = sitk.ImageSeriesReader()\nreader.LoadPrivateTagsOn()\ntrain_path=\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/\"\n# studi_id=[\"00000\",\"00002\",\"00003\"]\nstudi_id = [str(x).zfill(5) for x in df[df['BraTS21ID'].isin([840])]['BraTS21ID'].unique().tolist()]\nmri_types = [\"FLAIR\",\"T1w\",\"T1wCE\",\"T2w\"]\npixel_size_h=240\npixel_size_w=240\ninner_count=0\n\ndef dicom2nifti(image_dir, out_dir, save=True):\n    \"given a dicom directory, loads them into single file and can save it as .nii file\"\n    reader = sitk.ImageSeriesReader()\n    reader.LoadPrivateTagsOn()\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(str(image_dir))\n    reader.SetFileNames(filenamesDICOM)\n    img = reader.Execute()\n    img = sitk.Cast(img, sitk.sitkFloat32)\n    \n    if save:\n        sitk.WriteImage(img, f'{out_dir}/{image_dir.parent.name}.nii')\n    else:\n        return img\n\ndef resample_nifti(image_dir, ref_image, fn, save=True):\n    \"resample using a reference image\"\n\n    image = sitk.ReadImage(str(image_dir), sitk.sitkFloat32)\n    \n    initial_transform = sitk.CenteredTransformInitializer(ref_image, \n                                                          image, \n                                                          sitk.Euler3DTransform(), \n                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear)\n    resampler.SetTransform(initial_transform)\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n    resampler.SetSize((ref_image.GetSize()))\n    resampler.SetOutputDirection(ref_image.GetDirection())\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n    resamped_image = resampler.Execute(image)\n    \n    if save:\n        sitk.WriteImage(resamped_image, fn)\n\n    return resamped_image\n\nref_image = sitk.ReadImage('../input/sri24-dataset/sri24/spgr.nii', sitk.sitkFloat32)\n!mkdir -p ./tmp/T1w\n!mkdir -p ./tmp/T1wCE\n!mkdir -p ./tmp/T2w\n!mkdir -p ./tmp/FLAIR\n\nfor c in tqdm(studi_id):\n    path=join(train_path,c)\n    samples = [Path(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/\"+c)]\n    path_train_t2w, path_train_t1wce,path_train_t1w,path_train_flair = [],[],[],[]\n    for each in samples:\n        path_train_t2w.append(each.ls()[0])\n        path_train_t1wce.append(each.ls()[1])\n        path_train_t1w.append(each.ls()[2])\n        path_train_flair.append(each.ls()[3])\n    for fn in path_train_t1w: dicom2nifti(fn, \"./tmp/T1w/\")\n    for fn in path_train_t1wce: dicom2nifti(fn, \"./tmp/T1wCE/\")\n    for fn in path_train_t1w: dicom2nifti(fn, \"./tmp/T2w/\")\n    for fn in path_train_flair: dicom2nifti(fn, \"./tmp/FLAIR/\")      \n    for b in tqdm(mri_types):\n        path=join(train_path,c)\n        file=[]\n        for each in  [Path(join('./tmp/',b))]:\n            file.append(each.ls()[0])        \n        for fn2 in file:\n            pat_id = str(fn2).split('/')[-1].split('.')[0]\n            if b==\"FLAIR\":\n                final_fn = f\"./test/post/\"+pat_id+\"_0000.nii.gz\"\n            if b==\"T1w\":\n                final_fn = f\"./test/post/\"+pat_id+\"_0001.nii.gz\"\n            if b==\"T1wCE\":\n                final_fn = f\"./test/post/\"+pat_id+\"_0002.nii.gz\"    \n            if b==\"T2w\":\n                final_fn = f\"./test/post/\"+pat_id+\"_0003.nii.gz\"\n            resample_nifti(fn2, ref_image, final_fn, True)\n            os.remove(str(fn2))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:05:52.198991Z","iopub.execute_input":"2021-10-14T01:05:52.199499Z","iopub.status.idle":"2021-10-14T01:06:07.982837Z","shell.execute_reply.started":"2021-10-14T01:05:52.19946Z","shell.execute_reply":"2021-10-14T01:06:07.981654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"./RESULTS_FOLDER\")\n# shutil.rmtree(\"./tmp\")\n# shutil.rmtree(\"./apex\")\n# shutil.rmtree(\"./nnUNet\")\n# shutil.rmtree(\"./nnUNet_preprocessed\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:31.187022Z","iopub.execute_input":"2021-10-14T01:06:31.187565Z","iopub.status.idle":"2021-10-14T01:06:31.439092Z","shell.execute_reply.started":"2021-10-14T01:06:31.187523Z","shell.execute_reply":"2021-10-14T01:06:31.438359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nnUNet_predict -i ./test/post/ -o ./RESULTS_FOLDER/nnUNet/2d/ -t 001 -tr nnUNetTrainerV2 -m 3d_fullres --disable_tta","metadata":{"execution":{"iopub.status.busy":"2021-10-13T13:24:43.536186Z","iopub.execute_input":"2021-10-13T13:24:43.53643Z","iopub.status.idle":"2021-10-13T19:20:36.682718Z","shell.execute_reply.started":"2021-10-13T13:24:43.5364Z","shell.execute_reply":"2021-10-13T19:20:36.668829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls ./RESULTS_FOLDER/nnUNet/2d/","metadata":{"execution":{"iopub.status.busy":"2021-10-13T19:26:56.566005Z","iopub.execute_input":"2021-10-13T19:26:56.566312Z","iopub.status.idle":"2021-10-13T19:26:56.57248Z","shell.execute_reply.started":"2021-10-13T19:26:56.566278Z","shell.execute_reply":"2021-10-13T19:26:56.571424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls ./test/post/","metadata":{"execution":{"iopub.status.busy":"2021-10-13T19:27:01.536003Z","iopub.execute_input":"2021-10-13T19:27:01.536291Z","iopub.status.idle":"2021-10-13T19:27:01.540526Z","shell.execute_reply.started":"2021-10-13T19:27:01.536262Z","shell.execute_reply":"2021-10-13T19:27:01.539407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_array(fn):\n    \"opens .nii file and return the array\"\n    img = sitk.ReadImage(str(fn))\n    imgd = sitk.GetArrayFromImage(img)\n    return imgd\n\ndef plot_slice(imgd, sli):\n    \"given an image of shape slices x height x width, plots a slice\"\n    plt.imshow(imgd[sli], cmap='gray')\n    plt.axis('off')\n    \ndef get_array_plot(fn, sli):\n    imgd = get_array(fn)\n    plot_slice(imgd, sli)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:38:40.944397Z","iopub.execute_input":"2021-10-14T22:38:40.944662Z","iopub.status.idle":"2021-10-14T22:38:40.950536Z","shell.execute_reply.started":"2021-10-14T22:38:40.944627Z","shell.execute_reply":"2021-10-14T22:38:40.949838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_array_plot(f'./RESULTS_FOLDER/nnUNet/2d/00003.nii.gz', 125)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_array_plot(f'./test/post/00003_0000.nii.gz', 125)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T19:20:38.400123Z","iopub.execute_input":"2021-10-13T19:20:38.402563Z","iopub.status.idle":"2021-10-13T19:20:38.765264Z","shell.execute_reply.started":"2021-10-13T19:20:38.402518Z","shell.execute_reply":"2021-10-13T19:20:38.764447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_array_plot(f'./test/post/00003_0001.nii.gz', 125)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T19:20:38.770168Z","iopub.execute_input":"2021-10-13T19:20:38.770832Z","iopub.status.idle":"2021-10-13T19:20:39.119623Z","shell.execute_reply.started":"2021-10-13T19:20:38.770778Z","shell.execute_reply":"2021-10-13T19:20:39.118875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_array_plot(f'./test/post/00003_0002.nii.gz', 125)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T19:20:39.123767Z","iopub.execute_input":"2021-10-13T19:20:39.126189Z","iopub.status.idle":"2021-10-13T19:20:39.471504Z","shell.execute_reply.started":"2021-10-13T19:20:39.126132Z","shell.execute_reply":"2021-10-13T19:20:39.470741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_array_plot(f'./test/post/00003_0003.nii.gz', 125)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T19:20:39.475768Z","iopub.execute_input":"2021-10-13T19:20:39.478219Z","iopub.status.idle":"2021-10-13T19:20:39.819387Z","shell.execute_reply.started":"2021-10-13T19:20:39.478147Z","shell.execute_reply":"2021-10-13T19:20:39.818718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = 0\nslice_num = 70\ndisplay(df[df['BraTS21ID']==x])\nplt.figure(figsize=(30, 5))\nplt.subplot(1, 5,1)\nget_array_plot(f'./RESULTS_FOLDER/nnUNet/2d/{str(x).zfill(5)}.nii.gz', slice_num)\nplt.subplot(1, 5,2)\nget_array_plot(f'./test/post/{str(x).zfill(5)}_0000.nii.gz', slice_num) \nplt.subplot(1, 5,3)\nget_array_plot(f'./test/post/{str(x).zfill(5)}_0001.nii.gz', slice_num)\nplt.subplot(1, 5,4)\nget_array_plot(f'./test/post/{str(x).zfill(5)}_0002.nii.gz', slice_num)\nplt.subplot(1, 5,5)\nget_array_plot(f'./test/post/{str(x).zfill(5)}_0003.nii.gz', slice_num)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T20:36:39.888981Z","iopub.execute_input":"2021-10-13T20:36:39.88977Z","iopub.status.idle":"2021-10-13T20:36:41.407628Z","shell.execute_reply.started":"2021-10-13T20:36:39.889715Z","shell.execute_reply":"2021-10-13T20:36:41.406917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgd = get_array(f'./RESULTS_FOLDER/nnUNet/2d/{str(x).zfill(5)}.nii.gz')\nplt.figure(figsize=(30, 5))\nimg_slice = imgd[slice_num]\nimg_slice = imgd[slice_num]\nimg_slice[img_slice > 0] = 1\n\nplt.figure(figsize=(30, 5))\n\nplt.subplot(1, 4,1)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0000.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,2)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0001.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,3)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0002.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,4)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0003.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T20:36:50.752004Z","iopub.execute_input":"2021-10-13T20:36:50.752284Z","iopub.status.idle":"2021-10-13T20:36:52.332239Z","shell.execute_reply.started":"2021-10-13T20:36:50.752255Z","shell.execute_reply":"2021-10-13T20:36:52.33147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgd = get_array(f'./RESULTS_FOLDER/nnUNet/2d/{str(x).zfill(5)}.nii.gz')\nplt.figure(figsize=(30, 5))\nimg_slice = imgd[slice_num]\nimg_slice = imgd[slice_num]\n# img_slice[img_slice > 0] = 1\n\nplt.figure(figsize=(30, 5))\n\nplt.subplot(1, 4,1)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0000.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,2)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0001.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,3)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0002.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,4)\ntemp = get_array(f'./test/post/{str(x).zfill(5)}_0003.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T20:37:01.611129Z","iopub.execute_input":"2021-10-13T20:37:01.61181Z","iopub.status.idle":"2021-10-13T20:37:03.155083Z","shell.execute_reply.started":"2021-10-13T20:37:01.611766Z","shell.execute_reply":"2021-10-13T20:37:03.154366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Brain tumor identification model","metadata":{}},{"cell_type":"code","source":"image_data = cv2.imread('../input/ct-head-scans/Necrosis/Necrosis14.jpg')\nprint(image_data.shape)\nplt.imshow(image_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:21.64974Z","iopub.execute_input":"2021-10-04T05:08:21.650512Z","iopub.status.idle":"2021-10-04T05:08:21.87944Z","shell.execute_reply.started":"2021-10-04T05:08:21.650471Z","shell.execute_reply":"2021-10-04T05:08:21.878575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.resize(image_data,(256,256)))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:21.880825Z","iopub.execute_input":"2021-10-04T05:08:21.881069Z","iopub.status.idle":"2021-10-04T05:08:22.101437Z","shell.execute_reply.started":"2021-10-04T05:08:21.881037Z","shell.execute_reply":"2021-10-04T05:08:22.100733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data.shape, image_data.mean(), image_data.min(), image_data.max()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.102769Z","iopub.execute_input":"2021-10-04T05:08:22.103026Z","iopub.status.idle":"2021-10-04T05:08:22.112573Z","shell.execute_reply.started":"2021-10-04T05:08:22.10299Z","shell.execute_reply":"2021-10-04T05:08:22.11188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data[:,:,0].sum(), image_data[:,:,1].sum(), image_data[:,:,2].sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.115503Z","iopub.execute_input":"2021-10-04T05:08:22.115969Z","iopub.status.idle":"2021-10-04T05:08:22.123121Z","shell.execute_reply.started":"2021-10-04T05:08:22.115916Z","shell.execute_reply":"2021-10-04T05:08:22.122194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_tumor_identification = pd.DataFrame(data=None, columns = ['ID','Tumor flag'])\ndata_tumor_identification['ID'] = ['Tumor/' + x for x in os.listdir('../input/ct-head-scans/Tumor')]\ndata_tumor_identification['Tumor flag'] = 1\ndata = pd.DataFrame(data=None, columns = ['ID','Tumor flag'])\ndata['ID'] = ['Control/' + x for x in os.listdir('../input/ct-head-scans/Control')]\ndata['Tumor flag'] = 0\ndata_tumor_identification = pd.concat([data_tumor_identification, data], axis = 0).reset_index(drop = True)\ndata = pd.DataFrame(data=None, columns = ['ID','Tumor flag'])\ndata['ID'] = ['Necrosis/' + x for x in os.listdir('../input/ct-head-scans/Necrosis')]\ndata['Tumor flag'] = 0\ndata_tumor_identification = pd.concat([data_tumor_identification, data], axis = 0).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.124645Z","iopub.execute_input":"2021-10-04T05:08:22.125071Z","iopub.status.idle":"2021-10-04T05:08:22.457703Z","shell.execute_reply.started":"2021-10-04T05:08:22.125034Z","shell.execute_reply":"2021-10-04T05:08:22.456989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_tumor_identification.shape)\ndata_tumor_identification.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.460908Z","iopub.execute_input":"2021-10-04T05:08:22.461121Z","iopub.status.idle":"2021-10-04T05:08:22.474512Z","shell.execute_reply.started":"2021-10-04T05:08:22.461087Z","shell.execute_reply":"2021-10-04T05:08:22.473834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_tumor_identification = data_tumor_identification.sample(frac=1).reset_index(drop=True)\ndata_tumor_identification.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.476323Z","iopub.execute_input":"2021-10-04T05:08:22.476584Z","iopub.status.idle":"2021-10-04T05:08:22.486206Z","shell.execute_reply.started":"2021-10-04T05:08:22.476552Z","shell.execute_reply":"2021-10-04T05:08:22.485194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nsns.countplot(data=data_tumor_identification, x=\"Tumor flag\");","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.487882Z","iopub.execute_input":"2021-10-04T05:08:22.488333Z","iopub.status.idle":"2021-10-04T05:08:22.646247Z","shell.execute_reply.started":"2021-10-04T05:08:22.488299Z","shell.execute_reply":"2021-10-04T05:08:22.645408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_tumor_identification, valid_data_tumor_identification = sk_model_selection.train_test_split(\n    data_tumor_identification, \n    test_size=0.2, \n    random_state=42, \n    stratify=data_tumor_identification[\"Tumor flag\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.647673Z","iopub.execute_input":"2021-10-04T05:08:22.647912Z","iopub.status.idle":"2021-10-04T05:08:22.656161Z","shell.execute_reply.started":"2021-10-04T05:08:22.64788Z","shell.execute_reply":"2021-10-04T05:08:22.655196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training data')\nplt.figure(figsize=(5, 5))\nsns.countplot(data=train_data_tumor_identification, x=\"Tumor flag\");","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.658034Z","iopub.execute_input":"2021-10-04T05:08:22.658422Z","iopub.status.idle":"2021-10-04T05:08:22.843061Z","shell.execute_reply.started":"2021-10-04T05:08:22.658383Z","shell.execute_reply":"2021-10-04T05:08:22.842384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Validation data')\nplt.figure(figsize=(5, 5))\nsns.countplot(data=valid_data_tumor_identification, x=\"Tumor flag\");","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:22.844302Z","iopub.execute_input":"2021-10-04T05:08:22.844579Z","iopub.status.idle":"2021-10-04T05:08:23.007455Z","shell.execute_reply.started":"2021-10-04T05:08:22.84455Z","shell.execute_reply":"2021-10-04T05:08:23.006636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_brain_tumor_identification(data):\n    paths = ['../input/ct-head-scans/'+x for x in data['ID']]\n    image_data_list = []\n    for path in paths:\n        image_data = cv2.imread(path)[:,:,0].astype('float32')\n        image_data = cv2.resize(image_data,(256,256))/255\n        image_data_list.append(image_data.reshape((256,256,1)))\n    return image_data_list, data['Tumor flag']\n\ntrain_batches_tumor_identification = load_data_brain_tumor_identification(train_data_tumor_identification)\nvalid_batches_tumor_identification = load_data_brain_tumor_identification(valid_data_tumor_identification)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.008775Z","iopub.execute_input":"2021-10-04T05:08:23.009255Z","iopub.status.idle":"2021-10-04T05:08:23.605408Z","shell.execute_reply.started":"2021-10-04T05:08:23.009188Z","shell.execute_reply":"2021-10-04T05:08:23.604609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_batches_tumor_identification[0]))\ntrain_batches_tumor_identification[0][0].shape, train_batches_tumor_identification[1].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.606673Z","iopub.execute_input":"2021-10-04T05:08:23.607615Z","iopub.status.idle":"2021-10-04T05:08:23.614964Z","shell.execute_reply.started":"2021-10-04T05:08:23.607577Z","shell.execute_reply":"2021-10-04T05:08:23.614201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(train_batches_tumor_identification[0]).shape, np.array(train_batches_tumor_identification[1]).shape","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.616508Z","iopub.execute_input":"2021-10-04T05:08:23.617057Z","iopub.status.idle":"2021-10-04T05:08:23.633687Z","shell.execute_reply.started":"2021-10-04T05:08:23.617022Z","shell.execute_reply":"2021-10-04T05:08:23.633006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ##model building\n# model = Sequential()\n# #convolutional layer with rectified linear unit activation\n# model.add(layers.Conv2D(32, kernel_size=(3, 3),\n#                  activation='relu',\n#                  input_shape=(256,256,1)))\n# #32 convolution filters used each of size 3x3\n# #choose the best features via pooling\n# model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n# #randomly turn neurons on and off to improve convergence\n# model.add(layers.Dropout(0.25))\n# #flatten since too many dimensions, we only want a classification output\n# model.add(layers.Flatten())\n# #fully connected to get all relevant data\n# model.add(layers.Dense(128, activation='relu'))\n# #one more dropout for convergence' sake :) \n# model.add(layers.Dropout(0.5))\n# #output a softmax to squash the matrix into output probabilities\n# model.add(layers.Dense(1, activation='sigmoid'))\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.636488Z","iopub.execute_input":"2021-10-04T05:08:23.636688Z","iopub.status.idle":"2021-10-04T05:08:23.64165Z","shell.execute_reply.started":"2021-10-04T05:08:23.636665Z","shell.execute_reply":"2021-10-04T05:08:23.640835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_batches_tumor_identification[0]), len(train_batches_tumor_identification[1]), train_batches_tumor_identification[1].min(), train_batches_tumor_identification[1].max()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.642968Z","iopub.execute_input":"2021-10-04T05:08:23.643436Z","iopub.status.idle":"2021-10-04T05:08:23.652484Z","shell.execute_reply.started":"2021-10-04T05:08:23.6434Z","shell.execute_reply":"2021-10-04T05:08:23.651597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model, doing validation at the end of each epoch\nepochs = 500\n\ninitial_learning_rate = 0.001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\n\n# model.compile(\n#     loss=\"binary_crossentropy\",\n#     optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n#     metrics=[AUC(name='auc'),\"acc\"])\n    \n# model_save = ModelCheckpoint(f'brain_tumor_identification_model.h5', \n#                              save_best_only = True, \n#                              monitor = 'val_auc', \n#                              mode = 'max', verbose = 1)\n# early_stop = EarlyStopping(monitor = 'val_auc', \n#                            patience = 50, mode = 'max', verbose = 1,\n#                            restore_best_weights = True)\n# model.fit(\n#     np.array(train_batches_tumor_identification[0]),np.array(train_batches_tumor_identification[1]),\n#     validation_data=(np.array(valid_batches_tumor_identification[0]),np.array(valid_batches_tumor_identification[1])),\n#     batch_size=10,\n#     epochs=epochs,\n#     shuffle=True,\n#     verbose=1,\n#     callbacks = [model_save, early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.653794Z","iopub.execute_input":"2021-10-04T05:08:23.654144Z","iopub.status.idle":"2021-10-04T05:08:23.660333Z","shell.execute_reply.started":"2021-10-04T05:08:23.654081Z","shell.execute_reply":"2021-10-04T05:08:23.659469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model_2D_CNN_brain_tumor_identification(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n#         checkpoint = torch.load('../input/efficientnet-pytorch/efficientnet-b7-dcc49843.pth')\n#         self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n\n    def forward(self, x):\n        out = self.net(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.661989Z","iopub.execute_input":"2021-10-04T05:08:23.662319Z","iopub.status.idle":"2021-10-04T05:08:23.671908Z","shell.execute_reply.started":"2021-10-04T05:08:23.662288Z","shell.execute_reply":"2021-10-04T05:08:23.671262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever_2D_CNN_brain_tumor_identification(torch_data.Dataset):\n    def __init__(self, paths, targets, label_smoothing=0.01, rotate= 0):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.rotate = rotate\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = '../input/ct-head-scans/' + _id\n        channels = []\n        \n        image_data = cv2.imread(patient_path).astype('float32')\n        image_data = cv2.resize(image_data,(256,256))/255\n\n        image_data = image_data - np.min(image_data)\n        if np.max(image_data) != 0:\n            image_data = image_data / np.max(image_data)\n\n        channels.append(image_data[:,:,0])\n        channels.append(image_data[:,:,0])\n        channels.append(image_data[:,:,0])\n                    \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(channels).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(channels).float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.673386Z","iopub.execute_input":"2021-10-04T05:08:23.673642Z","iopub.status.idle":"2021-10-04T05:08:23.686301Z","shell.execute_reply.started":"2021-10-04T05:08:23.673611Z","shell.execute_reply":"2021-10-04T05:08:23.685612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data_retriever = DataRetriever_2D_CNN_brain_tumor_identification(\n#     data_tumor_identification[\"ID\"].values, \n#     data_tumor_identification[\"Tumor flag\"].values, rotate = 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.687672Z","iopub.execute_input":"2021-10-04T05:08:23.687954Z","iopub.status.idle":"2021-10-04T05:08:23.697121Z","shell.execute_reply.started":"2021-10-04T05:08:23.687919Z","shell.execute_reply":"2021-10-04T05:08:23.696411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data_retriever[0]['X'].shape, train_data_retriever[0]['y']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.698443Z","iopub.execute_input":"2021-10-04T05:08:23.69876Z","iopub.status.idle":"2021-10-04T05:08:23.705512Z","shell.execute_reply.started":"2021-10-04T05:08:23.698726Z","shell.execute_reply":"2021-10-04T05:08:23.704589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Trainer_brain_tumor_identification:\n#     def __init__(\n#         self, \n#         model, \n#         device, \n#         optimizer, \n#         criterion,\n#         best_valid_score\n#     ):\n#         self.model = model\n#         self.device = device\n#         self.optimizer = optimizer\n#         self.criterion = criterion\n        \n#         self.best_valid_score = best_valid_score\n#         self.n_patience = 0\n        \n#         self.messages = {\n#             \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n#             \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n#             \"patience\": \"\\nValid loss didn't improve last {} epochs.\"\n#         }\n    \n#     def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n#         for n_epoch in range(1, epochs + 1):\n#             self.info_message(\"EPOCH: {}\", n_epoch)\n            \n#             train_loss, train_score, train_time = self.train_epoch(train_loader)\n#             valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n#             )\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n#             )\n\n#             if (self.best_valid_score < valid_score):\n#                 self.info_message(\n#                     self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n#                 )\n#                 self.best_valid_score = valid_score\n#                 self.save_model(n_epoch, save_path)\n#                 self.n_patience = 0\n#             else:\n#                 self.n_patience += 1\n            \n#             if self.n_patience >= patience:\n#                 self.info_message(self.messages[\"patience\"], patience)\n#                 break\n            \n#     def train_epoch(self, train_loader):\n#         self.model.train()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n        \n#         for step, batch in enumerate(train_loader, 1):\n#             X = batch[\"X\"].to(self.device)\n#             targets = batch[\"y\"].to(self.device)\n#             self.optimizer.zero_grad()\n#             outputs = self.model(X).squeeze(1)\n            \n#             loss = self.criterion(outputs, targets)\n#             loss.backward()\n\n#             sum_loss += loss.detach().item()\n#             y_all.extend(batch[\"y\"].tolist())\n#             outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss/step, auc\n#         message = 'Train Step {}/{}, train_loss: {:.5f}, train_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n#         return _loss, _score, int(time.time() - t)\n    \n#     def valid_epoch(self, valid_loader):\n#         self.model.eval()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n\n#         for step, batch in enumerate(valid_loader, 1):\n#             with torch.no_grad():\n#                 X = batch[\"X\"].to(self.device)\n#                 targets = batch[\"y\"].to(self.device)\n\n#                 outputs = self.model(X).squeeze(1)\n#                 loss = self.criterion(outputs, targets)\n\n#                 sum_loss += loss.detach().item()\n#                 y_all.extend(batch[\"y\"].tolist())\n#                 outputs_all.extend(torch.sigmoid(outputs).tolist())\n            \n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss/step, auc\n#         message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n\n#         return _loss, _score, int(time.time() - t)\n    \n#     def save_model(self, n_epoch, save_path):\n#         torch.save(\n#             {\n#                 \"model_state_dict\": self.model.state_dict(),\n#                 \"optimizer_state_dict\": self.optimizer.state_dict(),\n#                 \"best_valid_score\": self.best_valid_score,\n#                 \"n_epoch\": n_epoch,\n#             },\n#             save_path,\n#         )\n    \n#     @staticmethod\n#     def info_message(message, *args, end=\"\\n\"):\n#         print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.707051Z","iopub.execute_input":"2021-10-04T05:08:23.707434Z","iopub.status.idle":"2021-10-04T05:08:23.716454Z","shell.execute_reply.started":"2021-10-04T05:08:23.707399Z","shell.execute_reply":"2021-10-04T05:08:23.715431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# gc.collect()\n# torch.cuda.empty_cache()\n# model = Model_2D_CNN_brain_tumor_identification()\n# model.to(device)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# criterion = torch_functional.binary_cross_entropy_with_logits\n\n# best_valid_score = -np.inf\n\n# trainer = Trainer_brain_tumor_identification(\n#     model, \n#     device, \n#     optimizer, \n#     criterion,\n#     best_valid_score\n# )\n\n# train_data_retriever = DataRetriever_2D_CNN_brain_tumor_identification(\n#     train_data_tumor_identification[\"ID\"].values, \n#     train_data_tumor_identification[\"Tumor flag\"].values, rotate = 0)\n\n# valid_data_retriever = DataRetriever_2D_CNN_brain_tumor_identification(\n#     valid_data_tumor_identification[\"ID\"].values, \n#     valid_data_tumor_identification[\"Tumor flag\"].values, rotate = 0)\n\n# train_loader = torch_data.DataLoader(\n#     train_data_retriever,\n#     batch_size=2,\n#     shuffle=True,\n#     num_workers=8,\n# )\n\n# valid_loader = torch_data.DataLoader(\n#     valid_data_retriever, \n#     batch_size=2,\n#     shuffle=False,\n#     num_workers=8,\n# )\n\n# history = trainer.fit(\n#     30, \n#     train_loader,\n#     valid_loader, \n#     f\"effnet-best-model-brain-tumor-identification.pth\",\n#     10,\n# )","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.71741Z","iopub.execute_input":"2021-10-04T05:08:23.717592Z","iopub.status.idle":"2021-10-04T05:08:23.730165Z","shell.execute_reply.started":"2021-10-04T05:08:23.717571Z","shell.execute_reply":"2021-10-04T05:08:23.72951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_data_tumor_identification, valid_data_tumor_identification, data_tumor_identification","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.731749Z","iopub.execute_input":"2021-10-04T05:08:23.732226Z","iopub.status.idle":"2021-10-04T05:08:23.738597Z","shell.execute_reply.started":"2021-10-04T05:08:23.73219Z","shell.execute_reply":"2021-10-04T05:08:23.73792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Identify images with tumor","metadata":{}},{"cell_type":"code","source":"##brain_tumor_identification_model building\nbrain_tumor_identification_model = Sequential()\n#convolutional layer with rectified linear unit activation\nbrain_tumor_identification_model.add(layers.Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(256,256,1)))\n#32 convolution filters used each of size 3x3\n#choose the best features via pooling\nbrain_tumor_identification_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n#randomly turn neurons on and off to improve convergence\nbrain_tumor_identification_model.add(layers.Dropout(0.25))\n#flatten since too many dimensions, we only want a classification output\nbrain_tumor_identification_model.add(layers.Flatten())\n#fully connected to get all relevant data\nbrain_tumor_identification_model.add(layers.Dense(128, activation='relu'))\n#one more dropout for convergence' sake :) \nbrain_tumor_identification_model.add(layers.Dropout(0.5))\n#output a softmax to squash the matrix into output probabilities\nbrain_tumor_identification_model.add(layers.Dense(1, activation='sigmoid'))\nbrain_tumor_identification_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:23.739893Z","iopub.execute_input":"2021-10-04T05:08:23.740432Z","iopub.status.idle":"2021-10-04T05:08:30.933697Z","shell.execute_reply.started":"2021-10-04T05:08:23.740398Z","shell.execute_reply":"2021-10-04T05:08:30.932979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_tumor_identification_model.load_weights('../input/brain-tumor-identification-model/brain_tumor_identification_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:30.93645Z","iopub.execute_input":"2021-10-04T05:08:30.936647Z","iopub.status.idle":"2021-10-04T05:08:35.615251Z","shell.execute_reply.started":"2021-10-04T05:08:30.936625Z","shell.execute_reply":"2021-10-04T05:08:35.614461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = 63\na = load_dicom_images_3d(\"00012\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==12]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:35.616416Z","iopub.execute_input":"2021-10-04T05:08:35.616677Z","iopub.status.idle":"2021-10-04T05:08:43.104729Z","shell.execute_reply.started":"2021-10-04T05:08:35.616643Z","shell.execute_reply":"2021-10-04T05:08:43.103949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = 10\na = load_dicom_images_3d(\"00012\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==12]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:43.106694Z","iopub.execute_input":"2021-10-04T05:08:43.107001Z","iopub.status.idle":"2021-10-04T05:08:44.77018Z","shell.execute_reply.started":"2021-10-04T05:08:43.106961Z","shell.execute_reply":"2021-10-04T05:08:44.769383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = 0\na = load_dicom_images_3d(\"00002\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==2]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:44.771756Z","iopub.execute_input":"2021-10-04T05:08:44.772012Z","iopub.status.idle":"2021-10-04T05:08:46.277476Z","shell.execute_reply.started":"2021-10-04T05:08:44.771979Z","shell.execute_reply":"2021-10-04T05:08:46.276782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num = 56\na = load_dicom_images_3d(\"00002\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==2]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:46.278732Z","iopub.execute_input":"2021-10-04T05:08:46.27927Z","iopub.status.idle":"2021-10-04T05:08:46.97973Z","shell.execute_reply.started":"2021-10-04T05:08:46.279235Z","shell.execute_reply":"2021-10-04T05:08:46.979059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm\n\n# all_files_list = []\n# for i in tqdm(os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train')):\n#     for j in os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/'+i):\n#         for f in os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/'+i+'/'+j):\n#             all_files_list.append('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/' + i + '/' + j + '/' + f)\n            \n# for i in tqdm(os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test')):\n#     for j in os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/'+i):\n#         for f in os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/'+i+'/'+j):\n#             all_files_list.append('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/' + i + '/' + j + '/' + f)\n            \n# print(len(all_files_list))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:46.980986Z","iopub.execute_input":"2021-10-04T05:08:46.981273Z","iopub.status.idle":"2021-10-04T05:08:46.986326Z","shell.execute_reply.started":"2021-10-04T05:08:46.981235Z","shell.execute_reply":"2021-10-04T05:08:46.985449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_data(f):\n    image_data = load_dicom(f, rotate=0)\n    image_data = cv2.resize(image_data, (256, 256))\n    image_data = image_data - np.min(image_data)\n    if np.max(image_data) != 0:\n        image_data = image_data / np.max(image_data)\n    return image_data","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:46.9878Z","iopub.execute_input":"2021-10-04T05:08:46.988062Z","iopub.status.idle":"2021-10-04T05:08:46.997435Z","shell.execute_reply.started":"2021-10-04T05:08:46.988029Z","shell.execute_reply":"2021-10-04T05:08:46.996757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# brain_tumor_identification_model_pred_df = pd.DataFrame(data = None, columns = ['Filename','Brain tumor pred'])\n# tqdm.pandas()\n# brain_tumor_identification_model_pred_df['Filename'] = all_files_list\n# brain_tumor_identification_model_pred_df['Brain tumor pred'] = brain_tumor_identification_model_pred_df['Filename'].progress_apply(lambda x: brain_tumor_identification_model.predict(get_img_data(x).reshape((1,256,256,1)))[0][0])\n# joblib.dump(brain_tumor_identification_model_pred_df,'brain_tumor_identification_model_pred_df.pkl')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:46.998674Z","iopub.execute_input":"2021-10-04T05:08:46.998989Z","iopub.status.idle":"2021-10-04T05:08:47.006026Z","shell.execute_reply.started":"2021-10-04T05:08:46.998949Z","shell.execute_reply":"2021-10-04T05:08:47.005288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nall_files_list = []\nfor i in tqdm(os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test')):\n    for j in os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/'+i):\n        for f in os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/'+i+'/'+j):\n            all_files_list.append('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/' + i + '/' + j + '/' + f)\n            \nprint(len(all_files_list))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:47.00752Z","iopub.execute_input":"2021-10-04T05:08:47.007785Z","iopub.status.idle":"2021-10-04T05:08:57.379837Z","shell.execute_reply.started":"2021-10-04T05:08:47.007752Z","shell.execute_reply":"2021-10-04T05:08:57.3788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_tumor_identification_model_pred_df = joblib.load('../input/brain-tumor-predictions/brain_tumor_identification_model_pred_df.pkl')\nprint(brain_tumor_identification_model_pred_df.shape)\nbrain_tumor_identification_model_pred_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:57.381265Z","iopub.execute_input":"2021-10-04T05:08:57.381528Z","iopub.status.idle":"2021-10-04T05:08:58.148159Z","shell.execute_reply.started":"2021-10-04T05:08:57.381495Z","shell.execute_reply":"2021-10-04T05:08:58.147424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intersection_files = set.intersection(set(all_files_list), set(brain_tumor_identification_model_pred_df['Filename'].tolist()))\nall_files_list = list(set(all_files_list) - intersection_files)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.149558Z","iopub.execute_input":"2021-10-04T05:08:58.149834Z","iopub.status.idle":"2021-10-04T05:08:58.260258Z","shell.execute_reply.started":"2021-10-04T05:08:58.149797Z","shell.execute_reply":"2021-10-04T05:08:58.259479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_files_list)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.261459Z","iopub.execute_input":"2021-10-04T05:08:58.26182Z","iopub.status.idle":"2021-10-04T05:08:58.267955Z","shell.execute_reply.started":"2021-10-04T05:08:58.261781Z","shell.execute_reply":"2021-10-04T05:08:58.26713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(brain_tumor_identification_model_pred_df.shape)\nfor i in range(0, len(all_files_list)):\n    brain_tumor_identification_model_pred_df.loc[brain_tumor_identification_model_pred_df.shape[0]] = all_files_list[i], brain_tumor_identification_model.predict(get_img_data(all_files_list[i]).reshape((1,256,256,1)))[0][0]\nprint(brain_tumor_identification_model_pred_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.269407Z","iopub.execute_input":"2021-10-04T05:08:58.269784Z","iopub.status.idle":"2021-10-04T05:08:58.280566Z","shell.execute_reply.started":"2021-10-04T05:08:58.269747Z","shell.execute_reply":"2021-10-04T05:08:58.279814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del brain_tumor_identification_model, get_img_data","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.28184Z","iopub.execute_input":"2021-10-04T05:08:58.28235Z","iopub.status.idle":"2021-10-04T05:08:58.289778Z","shell.execute_reply.started":"2021-10-04T05:08:58.282316Z","shell.execute_reply":"2021-10-04T05:08:58.289013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def select_best_images(files,img_size,num_imgs):\n#     model_pred_df = pd.DataFrame(data = None, columns = ['Order','Filename','Brain tumor pred'])\n#     count = 0\n\n#     for f in files:\n#         image_data = load_dicom(f, rotate=0)\n#         image_data = cv2.resize(image_data, (img_size, img_size))\n#         image_data = image_data - np.min(image_data)\n#         if np.max(image_data) != 0:\n#             image_data = image_data / np.max(image_data)\n#         model_pred_df.loc[count] = (count+1), f, brain_tumor_identification_model.predict(image_data.reshape((1,256,256,1)))[0][0]\n#         count += 1\n    \n#     selected_image_paths = model_pred_df.sort_values(by = ['Brain tumor pred'], ascending = False).head(num_imgs)\n#     selected_image_paths = selected_image_paths.sort_values(by = 'Order', ascending = True).reset_index(drop = True)\n    \n#     return selected_image_paths['Filename'].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.290971Z","iopub.execute_input":"2021-10-04T05:08:58.291281Z","iopub.status.idle":"2021-10-04T05:08:58.298502Z","shell.execute_reply.started":"2021-10-04T05:08:58.291246Z","shell.execute_reply":"2021-10-04T05:08:58.297771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_num = 20\n# a = load_dicom_images_3d(\"00002\")\n# print('MGMT_value:',train_df[train_df['BraTS21ID']==2]['MGMT_value'].iloc[0])\n# plt.imshow(a[0,:,:,img_num], cmap=\"gray\")\n# print('Model result on brain tumor identification:',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.299456Z","iopub.execute_input":"2021-10-04T05:08:58.3026Z","iopub.status.idle":"2021-10-04T05:08:58.311057Z","shell.execute_reply.started":"2021-10-04T05:08:58.302572Z","shell.execute_reply":"2021-10-04T05:08:58.310382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update function to include top images containing tumor\n\nNUM_IMAGES = 64\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=256, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    files = [x for x in files if load_dicom(x).sum()!=0]\n    \n    #----Selecting best images START----    \n\n#     selected_files = select_best_images(files,img_size,num_imgs)\n\n    files_df = pd.DataFrame(files)\n    files_df.columns = ['Filename']\n    files_df['Order'] = files_df.index + 1\n    \n    selected_image_paths = brain_tumor_identification_model_pred_df[brain_tumor_identification_model_pred_df['Filename'].isin(files)].sort_values(by = ['Brain tumor pred'], ascending = False).head(num_imgs)\n    selected_image_paths = selected_image_paths.merge(files_df, on = 'Filename', how = 'left')\n    selected_image_paths = selected_image_paths.sort_values(by = 'Order', ascending = True).reset_index(drop = True)\n    selected_files = selected_image_paths['Filename'].tolist()\n    \n    #----Selecting best images END----    \n\n    # crop_image_pixel_array()\n    images_list_array = [load_dicom(f, rotate=rotate) for f in selected_files]\n    \n    #Cropping\n    mean_image_for_cropping = np.array(images_list_array).mean(axis = 0)\n    img_cropped,dim_for_cropping = crop_image_pixel_array(mean_image_for_cropping)\n    first_row_index = dim_for_cropping[0]\n    last_row_index = dim_for_cropping[1]\n    first_column_index = dim_for_cropping[2]\n    last_column_index = dim_for_cropping[3]\n    if ((not pd.isnull(first_row_index)) & (not pd.isnull(last_row_index)) & (not pd.isnull(first_column_index)) & (not pd.isnull(last_column_index))):\n        images_list_array = [f[first_row_index:last_row_index,first_column_index:last_column_index] for f in images_list_array]\n\n    images_list_array = [cv2.resize(f, (img_size, img_size)) for f in images_list_array]\n    img3d = np.stack(images_list_array).T\n\n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d / np.max(img3d)\n\n    return np.expand_dims(img3d,0)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.313935Z","iopub.execute_input":"2021-10-04T05:08:58.314215Z","iopub.status.idle":"2021-10-04T05:08:58.328376Z","shell.execute_reply.started":"2021-10-04T05:08:58.31418Z","shell.execute_reply":"2021-10-04T05:08:58.327564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2D CNN","metadata":{}},{"cell_type":"code","source":"valid_combinations = [['T2w', 'T1wCE', 'T1w'], ['FLAIR', 'T2w', 'T1w'], ['FLAIR', 'T2w', 'T1wCE'], ['FLAIR', 'T1wCE', 'T1w']]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.331136Z","iopub.execute_input":"2021-10-04T05:08:58.331361Z","iopub.status.idle":"2021-10-04T05:08:58.339945Z","shell.execute_reply.started":"2021-10-04T05:08:58.33133Z","shell.execute_reply":"2021-10-04T05:08:58.339142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever_2D_CNN(torch_data.Dataset):\n    def __init__(self, paths, targets, list_combinations, label_smoothing=0.001, rotate= 0):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.list_combinations = list_combinations\n        self.rotate = rotate\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/{self.train_flag}/{str(_id).zfill(5)}/\"\n        channels = []\n        for t in list(self.list_combinations):\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n\n            x = len(t_paths)\n            num_images = 5\n                \n            if x < num_images:\n                r = range(x)\n            else:\n                d = x // num_images\n                r = range(d, x - d, d)\n\n            channel = []\n\n            for i in r:\n                pixel_array_processed = load_dicom(t_paths[i], rotate = self.rotate)\n                pixel_array_processed = pixel_array_processed - np.min(pixel_array_processed)\n                if np.max(pixel_array_processed) != 0:\n                    pixel_array_processed = pixel_array_processed / np.max(pixel_array_processed)\n                #Crop image\n                if pixel_array_processed.sum() != 0:\n                    pixel_array_processed,_ = crop_image_pixel_array(pixel_array_processed)\n                pixel_array_processed = (pixel_array_processed * 255).astype(np.uint8)\n                pixel_array_processed = cv2.resize(pixel_array_processed, (256, 256)) / 255\n                channel.append(pixel_array_processed)\n            channel = np.mean(channel, axis=0)\n            channels.append(channel)\n                    \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(channels).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(channels).float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.341517Z","iopub.execute_input":"2021-10-04T05:08:58.341812Z","iopub.status.idle":"2021-10-04T05:08:58.357894Z","shell.execute_reply.started":"2021-10-04T05:08:58.341735Z","shell.execute_reply":"2021-10-04T05:08:58.357191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_retriever_comb_1 = DataRetriever_2D_CNN(\n    df_train[\"BraTS21ID\"].values,\n    df_train[\"MGMT_value\"].values, \n    list(valid_combinations[0]), rotate = 0)\n\nvalid_data_retriever_comb_1 = DataRetriever_2D_CNN(\n    df_valid[\"BraTS21ID\"].values, \n    df_valid[\"MGMT_value\"].values,\n    list(valid_combinations[0]), rotate = 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.359034Z","iopub.execute_input":"2021-10-04T05:08:58.359462Z","iopub.status.idle":"2021-10-04T05:08:58.369484Z","shell.execute_reply.started":"2021-10-04T05:08:58.359428Z","shell.execute_reply":"2021-10-04T05:08:58.368821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = train_data_retriever_comb_1[0]['X']\nprint(img.shape)\nplt.imshow(img[1], cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.370475Z","iopub.execute_input":"2021-10-04T05:08:58.370657Z","iopub.status.idle":"2021-10-04T05:08:58.815459Z","shell.execute_reply.started":"2021-10-04T05:08:58.370636Z","shell.execute_reply":"2021-10-04T05:08:58.814763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 230\nplt.figure(figsize=(16, 6))\nif (df_train.iloc[num]['MGMT_value'])==0:\n    print('Patient without tumor')\nelse:\n    print('Patient with tumor')\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    plt.imshow(train_data_retriever_comb_1[num][\"X\"].numpy()[i], cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:58.816643Z","iopub.execute_input":"2021-10-04T05:08:58.816979Z","iopub.status.idle":"2021-10-04T05:08:59.653779Z","shell.execute_reply.started":"2021-10-04T05:08:58.81694Z","shell.execute_reply":"2021-10-04T05:08:59.653076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nif (df_train.iloc[101]['MGMT_value'])==0:\n    print('Patient without tumor')\nelse:\n    print('Patient with tumor')\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    plt.imshow(train_data_retriever_comb_1[101][\"X\"].numpy()[i], cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:08:59.655208Z","iopub.execute_input":"2021-10-04T05:08:59.655631Z","iopub.status.idle":"2021-10-04T05:09:00.935541Z","shell.execute_reply.started":"2021-10-04T05:08:59.655596Z","shell.execute_reply":"2021-10-04T05:09:00.934831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_data_retriever_comb_1, valid_data_retriever_comb_1","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:00.936666Z","iopub.execute_input":"2021-10-04T05:09:00.937182Z","iopub.status.idle":"2021-10-04T05:09:00.941721Z","shell.execute_reply.started":"2021-10-04T05:09:00.937146Z","shell.execute_reply":"2021-10-04T05:09:00.941055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model_2D_CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b7\")\n#         checkpoint = torch.load('../input/efficientnet-pytorch/efficientnet-b7-dcc49843.pth')\n#         self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n\n    def forward(self, x):\n        out = self.net(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:00.943171Z","iopub.execute_input":"2021-10-04T05:09:00.944009Z","iopub.status.idle":"2021-10-04T05:09:00.952234Z","shell.execute_reply.started":"2021-10-04T05:09:00.943972Z","shell.execute_reply":"2021-10-04T05:09:00.951515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class LossMeter:\n#     def __init__(self):\n#         self.avg = 0\n#         self.n = 0\n\n#     def update(self, val):\n#         self.n += 1\n#         # incremental update\n#         self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n\n        \n# class AccMeter:\n#     def __init__(self):\n#         self.true_count = 0\n#         self.n = 0\n#         self.avg = 0\n        \n#     def update(self, y_true, y_pred):\n#         y_true = y_true.cpu().numpy() >= 0.5\n#         y_pred = y_pred.cpu().numpy() >= 0\n#         self.n += len(y_true)\n#         self.true_count += np.sum(y_true == y_pred)\n#         # incremental update\n#         if self.n != 0:\n#             self.avg = self.true_count / self.n\n#         else:\n#             self.avg = 0","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:00.953429Z","iopub.execute_input":"2021-10-04T05:09:00.954116Z","iopub.status.idle":"2021-10-04T05:09:00.960452Z","shell.execute_reply.started":"2021-10-04T05:09:00.954062Z","shell.execute_reply":"2021-10-04T05:09:00.959608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Trainer:\n#     def __init__(\n#         self, \n#         model, \n#         device, \n#         optimizer, \n#         criterion,\n#         best_valid_score\n#     ):\n#         self.model = model\n#         self.device = device\n#         self.optimizer = optimizer\n#         self.criterion = criterion\n        \n#         self.best_valid_score = best_valid_score\n#         self.n_patience = 0\n        \n#         self.messages = {\n#             \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n#             \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n#             \"patience\": \"\\nValid loss didn't improve last {} epochs.\"\n#         }\n    \n#     def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n#         for n_epoch in range(1, epochs + 1):\n#             self.info_message(\"EPOCH: {}\", n_epoch)\n            \n#             train_loss, train_score, train_time = self.train_epoch(train_loader)\n#             valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n#             )\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n#             )\n\n#             if (self.best_valid_score < valid_score):\n#                 self.info_message(\n#                     self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n#                 )\n#                 self.best_valid_score = valid_score\n#                 self.save_model(n_epoch, save_path)\n#                 self.n_patience = 0\n#             else:\n#                 self.n_patience += 1\n            \n#             if self.n_patience >= patience:\n#                 self.info_message(self.messages[\"patience\"], patience)\n#                 break\n            \n#     def train_epoch(self, train_loader):\n#         self.model.train()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n        \n#         for step, batch in enumerate(train_loader, 1):\n#             X = batch[\"X\"].to(self.device)\n#             targets = batch[\"y\"].to(self.device)\n#             self.optimizer.zero_grad()\n#             outputs = self.model(X).squeeze(1)\n            \n#             loss = self.criterion(outputs, targets)\n#             loss.backward()\n\n#             sum_loss += loss.detach().item()\n#             y_all.extend(batch[\"y\"].tolist())\n#             outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss/step, auc\n#         message = 'Train Step {}/{}, train_loss: {:.5f}, train_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n#         return _loss, _score, int(time.time() - t)\n    \n#     def valid_epoch(self, valid_loader):\n#         self.model.eval()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n\n#         for step, batch in enumerate(valid_loader, 1):\n#             with torch.no_grad():\n#                 X = batch[\"X\"].to(self.device)\n#                 targets = batch[\"y\"].to(self.device)\n\n#                 outputs = self.model(X).squeeze(1)\n#                 loss = self.criterion(outputs, targets)\n\n#                 sum_loss += loss.detach().item()\n#                 y_all.extend(batch[\"y\"].tolist())\n#                 outputs_all.extend(torch.sigmoid(outputs).tolist())\n            \n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss/step, auc\n#         message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n\n#         return _loss, _score, int(time.time() - t)\n    \n#     def save_model(self, n_epoch, save_path):\n#         torch.save(\n#             {\n#                 \"model_state_dict\": self.model.state_dict(),\n#                 \"optimizer_state_dict\": self.optimizer.state_dict(),\n#                 \"best_valid_score\": self.best_valid_score,\n#                 \"n_epoch\": n_epoch,\n#             },\n#             save_path,\n#         )\n    \n#     @staticmethod\n#     def info_message(message, *args, end=\"\\n\"):\n#         print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:00.972047Z","iopub.execute_input":"2021-10-04T05:09:00.9723Z","iopub.status.idle":"2021-10-04T05:09:00.979506Z","shell.execute_reply.started":"2021-10-04T05:09:00.972272Z","shell.execute_reply":"2021-10-04T05:09:00.978447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_combinations","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:00.980962Z","iopub.execute_input":"2021-10-04T05:09:00.981598Z","iopub.status.idle":"2021-10-04T05:09:00.992264Z","shell.execute_reply.started":"2021-10-04T05:09:00.981561Z","shell.execute_reply":"2021-10-04T05:09:00.991403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# for i in range(0,len(valid_combinations)):\n#     print('Combination :', list(valid_combinations[i]))\n    \n#     gc.collect()\n#     torch.cuda.empty_cache()\n#     model = Model_2D_CNN()\n#     model.to(device)\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n#     criterion = torch_functional.binary_cross_entropy_with_logits\n\n#     best_valid_score = -np.inf\n\n#     trainer = Trainer(\n#         model, \n#         device, \n#         optimizer, \n#         criterion,\n#         best_valid_score\n#     )\n    \n#     for rotate_dir in [0,2]:\n#         train_data_retriever = DataRetriever_2D_CNN(\n#             df_train[\"BraTS21ID\"].values, \n#             df_train[\"MGMT_value\"].values, \n#             list(valid_combinations[i]), rotate = rotate_dir)\n\n#         valid_data_retriever = DataRetriever_2D_CNN(\n#             df_valid[\"BraTS21ID\"].values, \n#             df_valid[\"MGMT_value\"].values,\n#             list(valid_combinations[i]), rotate = rotate_dir)\n\n#         train_loader = torch_data.DataLoader(\n#             train_data_retriever,\n#             batch_size=4,\n#             shuffle=True,\n#             num_workers=8,\n#         )\n\n#         valid_loader = torch_data.DataLoader(\n#             valid_data_retriever, \n#             batch_size=4,\n#             shuffle=False,\n#             num_workers=8,\n#         )\n\n#         history = trainer.fit(\n#             30, \n#             train_loader,\n#             valid_loader, \n#             f\"best-model-{i}.pth\",\n#             10,\n#         )","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:00.993779Z","iopub.execute_input":"2021-10-04T05:09:00.994343Z","iopub.status.idle":"2021-10-04T05:09:01.001741Z","shell.execute_reply.started":"2021-10-04T05:09:00.994305Z","shell.execute_reply":"2021-10-04T05:09:01.001083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from __future__ import print_function  # for Python2\n\n# local_vars = list(locals().items())\n# for var, obj in local_vars:\n#     print(var, sys.getsizeof(obj))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.003128Z","iopub.execute_input":"2021-10-04T05:09:01.003408Z","iopub.status.idle":"2021-10-04T05:09:01.012089Z","shell.execute_reply.started":"2021-10-04T05:09:01.003375Z","shell.execute_reply":"2021-10-04T05:09:01.011407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del image_data, intersection_files, brain_tumor_identification_model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.013623Z","iopub.execute_input":"2021-10-04T05:09:01.013903Z","iopub.status.idle":"2021-10-04T05:09:01.021426Z","shell.execute_reply.started":"2021-10-04T05:09:01.013866Z","shell.execute_reply":"2021-10-04T05:09:01.020645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### User defined 3D CNN","metadata":{}},{"cell_type":"code","source":"def get_model(width=128, height=128, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = tensorflow.keras.Input((width, height, depth, 1))\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=512, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = tensorflow.keras.Model(inputs, outputs, name=\"3dcnn\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.024172Z","iopub.execute_input":"2021-10-04T05:09:01.024438Z","iopub.status.idle":"2021-10-04T05:09:01.038571Z","shell.execute_reply.started":"2021-10-04T05:09:01.024412Z","shell.execute_reply":"2021-10-04T05:09:01.037663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['BraTS21ID5'] = df_train['BraTS21ID'].apply(lambda x: format(x, '05d'))\ndf_valid['BraTS21ID5'] = df_valid['BraTS21ID'].apply(lambda x: format(x, '05d'))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.040077Z","iopub.execute_input":"2021-10-04T05:09:01.04038Z","iopub.status.idle":"2021-10-04T05:09:01.05596Z","shell.execute_reply.started":"2021-10-04T05:09:01.040341Z","shell.execute_reply":"2021-10-04T05:09:01.054204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(Sequence):\n    def __init__(self,df,mri_type,is_train=True,batch_size=4,shuffle=True):\n        self.idx = df[\"BraTS21ID\"].values\n        self.paths = df[\"BraTS21ID5\"].values\n        self.y =  df[\"MGMT_value\"].values\n        self.is_train = is_train\n        self.batch_size = batch_size\n        self.mri_type = mri_type\n        self.shuffle = shuffle\n    def __len__(self):\n        return math.ceil(len(self.idx)/self.batch_size)\n   \n    def __getitem__(self,ids):\n        id_path= self.paths[ids]\n        batch_paths = self.paths[ids * self.batch_size:(ids + 1) * self.batch_size]\n        \n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n        \n        if self.is_train:\n            list_x =  [load_dicom_images_3d(x,split=\"train\") for x in batch_paths]\n            batch_X = np.stack(list_x, axis=4)\n            return batch_X,batch_y\n        else:\n            list_x =  load_dicom_images_3d(id_path,split=\"test\", mri_type = self.mri_type)#str(scan_id).zfill(5)\n            batch_X = np.stack(list_x)\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.057413Z","iopub.execute_input":"2021-10-04T05:09:01.057781Z","iopub.status.idle":"2021-10-04T05:09:01.071117Z","shell.execute_reply.started":"2021-10-04T05:09:01.057748Z","shell.execute_reply":"2021-10-04T05:09:01.070258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.072826Z","iopub.execute_input":"2021-10-04T05:09:01.073115Z","iopub.status.idle":"2021-10-04T05:09:01.081987Z","shell.execute_reply.started":"2021-10-04T05:09:01.073067Z","shell.execute_reply":"2021-10-04T05:09:01.081259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_learning_rate = 0.0001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\n\n# for i in range(0, len(mri_types)):\n#     train_dataset = Dataset(df_train,mri_type = mri_types[i], batch_size=4)\n#     valid_dataset = Dataset(df_valid,mri_type = mri_types[i], batch_size=4)\n\n#     # Define callbacks\n#     model_save = ModelCheckpoint(f'{mri_types[i]}.h5', \n#                                  save_best_only = True, \n#                                  monitor = 'val_auc', \n#                                  mode = 'max', verbose = 1)\n#     early_stop = EarlyStopping(monitor = 'val_auc', \n#                                patience = 10, mode = 'max', verbose = 1,\n#                                restore_best_weights = True)\n\n#     # Train the model, doing validation at the end of each epoch\n#     epochs = 1\n\n#     # Build model.\n#     model = get_model(width=256, height=256, depth=64)\n#     model.summary()\n\n#     model.compile(\n#         loss=\"binary_crossentropy\",\n#         optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n#         metrics=[AUC(name='auc'),\"acc\"],\n#     )\n\n#     model.fit(\n#         train_dataset,\n#         validation_data=valid_dataset,\n#         epochs=epochs,\n#         shuffle=True,\n#         verbose=1,\n#         callbacks = [model_save, early_stop],\n#     )","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:09:01.083593Z","iopub.execute_input":"2021-10-04T05:09:01.083938Z","iopub.status.idle":"2021-10-04T05:09:01.091565Z","shell.execute_reply.started":"2021-10-04T05:09:01.083904Z","shell.execute_reply":"2021-10-04T05:09:01.090708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer learning - 3D CNN","metadata":{}},{"cell_type":"code","source":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets, mri_type, label_smoothing=0.01, augment = True):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.augment = augment\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n\n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        if self.augment:\n            rotation = np.random.randint(0,4)\n        else:\n            rotation = 0\n        data = load_dicom_images_3d(str(_id).zfill(5), mri_type=self.mri_type, split=self.train_flag, rotate=rotation)        \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(data).float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2021-10-13T11:39:13.944389Z","iopub.execute_input":"2021-10-13T11:39:13.944744Z","iopub.status.idle":"2021-10-13T11:39:13.955155Z","shell.execute_reply.started":"2021-10-13T11:39:13.944709Z","shell.execute_reply":"2021-10-13T11:39:13.954416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model_3D_effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-13T11:39:15.651675Z","iopub.execute_input":"2021-10-13T11:39:15.652252Z","iopub.status.idle":"2021-10-13T11:39:15.658245Z","shell.execute_reply.started":"2021-10-13T11:39:15.652215Z","shell.execute_reply":"2021-10-13T11:39:15.657256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s            \",\n                n_epoch, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_loss, valid_auc, valid_time\n            )\n\n            # if True:\n            #if self.best_valid_score < valid_auc: \n            if self.best_valid_score > valid_loss: \n                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n                self.info_message(\n                     \"Valid loss improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            message = 'Train Step {}/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n        \n        return sum_loss/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n            \n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss, auc):\n        self.lastmodel = f\"{save_path}\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T11:39:19.465129Z","iopub.execute_input":"2021-10-13T11:39:19.465627Z","iopub.status.idle":"2021-10-13T11:39:19.486475Z","shell.execute_reply.started":"2021-10-13T11:39:19.465591Z","shell.execute_reply":"2021-10-13T11:39:19.48538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n\nfor i in tqdm(range(0,len(mri_types))):\n    print('MRI type :', mri_types[i])\n    \n    gc.collect()\n    torch.cuda.empty_cache()\n    model = Model_3D_effnet()\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n    \n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion\n    )\n    \n    train_data_retriever = DataRetriever(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        mri_types[i], \n        augment = True)\n\n\n    valid_data_retriever = DataRetriever(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        mri_types[i], \n        augment = False)\n\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=4,\n        shuffle=True,\n        num_workers=8, pin_memory = True\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=4,\n        shuffle=False,\n        num_workers=8, pin_memory = True\n    )\n\n    history = trainer.fit(\n        30, \n        train_loader,\n        valid_loader, \n        f\"best-model-{mri_types[i]}.pth\",\n        10,\n    )","metadata":{"execution":{"iopub.status.busy":"2021-10-13T20:38:42.648575Z","iopub.execute_input":"2021-10-13T20:38:42.648856Z","iopub.status.idle":"2021-10-13T20:38:42.654588Z","shell.execute_reply.started":"2021-10-13T20:38:42.648828Z","shell.execute_reply":"2021-10-13T20:38:42.653588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer learning - nnUnet + CNN","metadata":{}},{"cell_type":"code","source":"class DataRetriever_unet(torch_data.Dataset):\n    def __init__(self, paths, targets, label_smoothing=0.01, augment = True, num_imgs = 64, mri_type = 'FLAIR'):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.augment = augment\n        self.num_imgs = num_imgs\n        self.mri_type = mri_type\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        if self.augment:\n            rotation = np.random.randint(0,4)\n        else:\n            rotation = 0\n            \n        unet_mask = get_array(f'../input/nnunet-masks/{str(_id).zfill(5)}.nii.gz')\n            \n        if self.mri_type == 'FLAIR':\n            temp = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0000.nii.gz')\n        elif self.mri_type == 'T1w':\n            temp = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0001.nii.gz')\n        elif self.mri_type == 'T1wCE':\n            temp = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0002.nii.gz')\n        elif self.mri_type == 'T2w':\n            temp = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0003.nii.gz')\n        \n        sum_pixels_in_unet_mask = [unet_mask[i,:,:].sum() for i in range(0, unet_mask.shape[0])]\n        sum_pixels_in_unet_mask_df = pd.DataFrame(sum_pixels_in_unet_mask)\n        sum_pixels_in_unet_mask_df.columns = ['Sum of pixels in unet mask']\n        sum_pixels_in_unet_mask_df['ID'] = sum_pixels_in_unet_mask_df.index\n        selected_slices = sum_pixels_in_unet_mask_df.sort_values(by = 'Sum of pixels in unet mask', ascending = False).head(int(self.num_imgs)).sort_values(by = 'ID', ascending = True)['ID'].tolist()\n\n        data = []\n        for slice_num in selected_slices:\n            img_slice = unet_mask[slice_num,:,:]\n            img_data = img_slice * temp[slice_num,:,:]\n            if (img_data.sum() != 0):\n                data.append(img_data)\n\n        data = np.stack(data, axis = 2)\n#         data = data[:,:,:64]\n        \n        if data.shape[-1] < self.num_imgs:\n            n_zero = np.zeros((240, 240, self.num_imgs - data.shape[-1]))\n            data = np.concatenate((data,  n_zero), axis = -1)\n\n        data = np.expand_dims(data,0)\n        \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(data).float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:34:59.939521Z","iopub.execute_input":"2021-10-14T23:34:59.939809Z","iopub.status.idle":"2021-10-14T23:34:59.958719Z","shell.execute_reply.started":"2021-10-14T23:34:59.93978Z","shell.execute_reply":"2021-10-14T23:34:59.95793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever_unet_all_modalities(torch_data.Dataset):\n    def __init__(self, paths, targets, label_smoothing=0.01, augment = True, num_imgs = 64):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.augment = augment\n        self.num_imgs = num_imgs\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        if self.augment:\n            rotation = np.random.randint(0,4)\n        else:\n            rotation = 0\n            \n        unet_mask = get_array(f'../input/nnunet-masks/{str(_id).zfill(5)}.nii.gz')\n            \n        temp_flair = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0000.nii.gz')\n        temp_t1w = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0001.nii.gz')\n        temp_t1wce = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0002.nii.gz')\n        temp_t2w = get_array(f'../input/preprocessed-train-images/{str(_id).zfill(5)}_0003.nii.gz')\n\n        sum_pixels_in_unet_mask = [unet_mask[i,:,:].sum() for i in range(0, unet_mask.shape[0])]\n        sum_pixels_in_unet_mask_df = pd.DataFrame(sum_pixels_in_unet_mask)\n        sum_pixels_in_unet_mask_df.columns = ['Sum of pixels in unet mask']\n        sum_pixels_in_unet_mask_df['ID'] = sum_pixels_in_unet_mask_df.index\n        selected_slices = sum_pixels_in_unet_mask_df.sort_values(by = 'Sum of pixels in unet mask', ascending = False).head(int(self.num_imgs/4)).sort_values(by = 'ID', ascending = True)['ID'].tolist()\n\n        data = []\n        for slice_num in selected_slices:\n            img_slice = unet_mask[slice_num,:,:]\n            img_data = img_slice * temp_flair[slice_num,:,:]\n            data.append(img_data)\n            img_data = img_slice * temp_t1w[slice_num,:,:]\n            data.append(img_data)\n            img_data = img_slice * temp_t1wce[slice_num,:,:]\n            data.append(img_data)\n            img_data = img_slice * temp_t2w[slice_num,:,:]\n            data.append(img_data)\n            \n        data = np.stack(data, axis = 2)\n        \n        if data.shape[-1] < self.num_imgs:\n            n_zero = np.zeros((240, 240, self.num_imgs - data.shape[-1]))\n            data = np.concatenate((data,  n_zero), axis = -1)\n\n        data = np.expand_dims(data,0)\n        \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(data).float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:53:37.138478Z","iopub.execute_input":"2021-10-14T22:53:37.138841Z","iopub.status.idle":"2021-10-14T22:53:37.158106Z","shell.execute_reply.started":"2021-10-14T22:53:37.138806Z","shell.execute_reply":"2021-10-14T22:53:37.157258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model_3D_effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:35:05.990535Z","iopub.execute_input":"2021-10-14T23:35:05.990803Z","iopub.status.idle":"2021-10-14T23:35:05.999118Z","shell.execute_reply.started":"2021-10-14T23:35:05.990775Z","shell.execute_reply":"2021-10-14T23:35:05.998361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.-inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s            \",\n                n_epoch, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_loss, valid_auc, valid_time\n            )\n\n            # if True:\n            #if self.best_valid_score < valid_auc: \n            if (self.best_valid_score < valid_auc) & (np.abs(train_loss - valid_loss)<0.05): \n                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n                self.info_message(\n                     \"Valid AUC improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_auc, self.lastmodel\n                )\n                self.best_valid_score = valid_auc\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            message = 'Train Step {}/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n        \n        return sum_loss/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n            \n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss, auc):\n        self.lastmodel = f\"{save_path}\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:35:09.898138Z","iopub.execute_input":"2021-10-14T23:35:09.898475Z","iopub.status.idle":"2021-10-14T23:35:09.918834Z","shell.execute_reply.started":"2021-10-14T23:35:09.89844Z","shell.execute_reply":"2021-10-14T23:35:09.91763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n\nfor i in tqdm(range(0,len(mri_types))):\n    print('MRI type :', mri_types[i])\n    gc.collect()\n    torch.cuda.empty_cache()\n    model = Model_3D_effnet()\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion\n    )\n\n    train_data_retriever = DataRetriever_unet(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        augment = True,\n        mri_type = mri_types[i],\n        num_imgs = 64)\n\n\n    valid_data_retriever = DataRetriever_unet(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        augment = False,\n        mri_type = mri_types[i],\n        num_imgs = 64)\n\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=4,\n        shuffle=True,\n        num_workers=8, pin_memory = True\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=4,\n        shuffle=False,\n        num_workers=8, pin_memory = True\n    )\n\n    history = trainer.fit(\n        50, \n        train_loader,\n        valid_loader, \n        f\"unet_images_3d_cnn_best-model_{mri_types[i]}.pth\",\n        15,\n    )","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:50:48.709035Z","iopub.execute_input":"2021-10-14T23:50:48.7094Z","iopub.status.idle":"2021-10-14T23:50:48.720273Z","shell.execute_reply.started":"2021-10-14T23:50:48.709357Z","shell.execute_reply":"2021-10-14T23:50:48.719541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"# Train Model Class\nclass nn_model():\n    def __init__(self, loader,criterion,num_epochs=25,embed_size=4096, num_classes=2,device='cpu',debug=False):\n        \n        torch.cuda.empty_cache()\n        \n        self.embed_size = embed_size\n        self.device = device\n        self.debug = debug\n        \n        vgg = torchvision.models.vgg19(pretrained = True)\n        \n        self.vgg_feat  = nn.Sequential(vgg.features)\n        self.vgg_pool = nn.Sequential(vgg.avgpool)\n        self.vgg_class = nn.Sequential(vgg.classifier[0])  \n        \n        self.criterion = criterion\n        self.num_epochs = num_epochs\n        del vgg\n        \n    def encoder(self,imgs):\n        features = np.zeros((imgs.shape[0],imgs.shape[1],4096))\n        for i in range(0,imgs.shape[0]):\n            for j in range(0,imgs.shape[1]):\n                A = imgs[i,j:j+1,:,:]\n                B = A.repeat(3,1,1).type(torch.FloatTensor).unsqueeze(0)\n\n                emb_ = self.vgg_class.forward(\n                                               self.vgg_pool.forward(\n                                                                       self.vgg_feat.forward(B)\n                                                                      ).view(-1)\n                                             )\n                \n                features[i,j,:] = emb_.detach().numpy()\n        \n        self.embed = torch.from_numpy(features)\n#         pdb.set_trace()\n#         self.embed = self.embed.permute(1,0,2).flatten(start_dim=1,end_dim=2)\n#         print(\"Check:\", self.embed.shape)\n        return self.embed\n    \n    def model_arch(self):\n        self.model = LSTM_RSNA()\n        \n    def train_model(self):\n        since = time.time()\n        self.optimizer = optim.SGD(self.model.parameters(), lr=0.005, momentum=0.9)\n        # Decay LR by a factor of 0.1 every 7 epochs\n        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=3, gamma=0.1)\n        \n        best_model_wts = copy.deepcopy(self.model.state_dict())\n        best_acc = 0.0\n        self.model.to(self.device)\n        self.track = []\n        for epoch in tqdm(range(self.num_epochs)):\n            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1))\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    self.model.train()  # Set model to training mode\n                else:\n                    self.model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                i=0                    \n                for inputs, labels in dataloaders[phase]:\n                    if self.debug and i>3:\n                        break\n                    else:\n                        inputs = inputs.to(self.device)\n                        labels = labels.to(self.device)[:,0,:]\n                        \n\n                        # zero the parameter gradients\n                        self.optimizer.zero_grad()\n\n                        # forward\n                        # track history if only in train\n                        with torch.set_grad_enabled(phase == 'train'):\n                            outputs,states = self.model(self.encoder(inputs).float())\n                            _, preds = torch.max(outputs, 1)                            \n                            loss = self.criterion(outputs, labels)\n\n                            # backward + optimize only if in training phase\n                            if phase == 'train':\n                                loss.backward()\n                                self.optimizer.step()\n\n                        # statistics\n                        running_loss += loss.item() * inputs.size(0)\n                        running_corrects += torch.sum(preds == labels.data[:,1])\n                        i+=1\n                    \n                if phase == 'train':\n                    self.scheduler.step()\n#                 pdb.set_trace()\n                epoch_loss = running_loss / len(dataloaders[phase])\n                epoch_acc = running_corrects.double() / len(dataloaders[phase])\n                \n                \n                if self.device=='cuda':\n                    labels = labels.to('cpu')\n                    preds = preds.to('cpu')\n                \n                epoch_metrics = np.asarray(precision_recall_fscore_support(labels.data[:,1],preds))\n#                 pdb.set_trace()\n                epoch_roc = roc_auc_score(labels.data[:,1],preds)\n                self.track.append([phase, epoch_loss, epoch_acc, \n                                   epoch_metrics[0,1],epoch_metrics[1,1], epoch_metrics[2,1],\n                                   epoch_roc])\n                \n                print('{} Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f} F1 Score: {:.4f} F1 AUC: {:.4f}'.format(\n                    phase, epoch_loss, epoch_acc, epoch_metrics[0,1],\n                    epoch_metrics[1,1], epoch_metrics[2,1],epoch_roc))\n\n                # deep copy the model\n                if phase == 'val' and epoch_roc > best_acc:\n                    best_acc = epoch_roc\n                    print('Current Best Model Epoch: ', epoch,'\\n')\n                    best_model_wts = copy.deepcopy(self.model.state_dict())\n                    torch.save({'lstm': self.model.state_dict(),'optimizer': self.optimizer.state_dict()}, 'model1.path')\n\n            print()\n\n        time_elapsed = time.time() - since\n        print('Training complete in {:.0f}m {:.0f}s'.format(\n            time_elapsed // 60, time_elapsed % 60))\n        \n        print('Best val Acc: {:4f}'.format(best_acc))\n        \n        # load best model weights\n        self.model.load_state_dict(best_model_wts)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pyradiomics","metadata":{}},{"cell_type":"code","source":"!pip install pyradiomics","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:07:13.484242Z","iopub.execute_input":"2021-10-14T22:07:13.4846Z","iopub.status.idle":"2021-10-14T22:07:13.491833Z","shell.execute_reply.started":"2021-10-14T22:07:13.484564Z","shell.execute_reply":"2021-10-14T22:07:13.491063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import radiomics","metadata":{"execution":{"iopub.status.busy":"2021-10-14T22:07:17.607876Z","iopub.execute_input":"2021-10-14T22:07:17.608619Z","iopub.status.idle":"2021-10-14T22:07:17.733181Z","shell.execute_reply.started":"2021-10-14T22:07:17.608584Z","shell.execute_reply":"2021-10-14T22:07:17.732308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"100\"></a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Stacking models<center><h2>","metadata":{}},{"cell_type":"code","source":"# models_2D_CNN = []\n# for i in range(4):\n#     gc.collect()\n#     torch.cuda.empty_cache()\n#     model = Model_2D_CNN()\n#     model.to(device)\n    \n#     checkpoint = torch.load(f\"../input/brain-tumor-classification-model/best-model-{i}.pth\")\n# #     checkpoint = torch.load(f\"best-model-{i}.pth\")\n#     print(checkpoint['best_valid_score'])\n#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n#     model.eval()\n    \n#     models_2D_CNN.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.1885Z","iopub.status.idle":"2021-10-04T05:36:31.189323Z","shell.execute_reply.started":"2021-10-04T05:36:31.189067Z","shell.execute_reply":"2021-10-04T05:36:31.189105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# models_3D_user_defined_CNN = []\n# for i in range(4):\n#     model = get_model(width=256, height=256, depth=64)\n\n#     model.load_weights(f'../input/brain-tumor-classification-model-3d-simple-cnn/{mri_types[i]}.h5')\n    \n#     models_3D_user_defined_CNN.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.190368Z","iopub.status.idle":"2021-10-04T05:36:31.191192Z","shell.execute_reply.started":"2021-10-04T05:36:31.190923Z","shell.execute_reply":"2021-10-04T05:36:31.190947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.192361Z","iopub.status.idle":"2021-10-04T05:36:31.193045Z","shell.execute_reply.started":"2021-10-04T05:36:31.192806Z","shell.execute_reply":"2021-10-04T05:36:31.19283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_3D_CNN_effnet = []\nfor i in range(4):\n    model = Model_3D_effnet()\n    model.to(device)\n    \n    checkpoint = torch.load(f\"../input/brain-tumor-classification-model-efficientnet-v1/best-model-{mri_types[i]} v1.pth\")\n#     checkpoint = torch.load(f\"best-model-{mri_types[i]}.pth\")\n    \n    print(checkpoint['best_valid_score'])\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models_3D_CNN_effnet.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.194176Z","iopub.status.idle":"2021-10-04T05:36:31.19495Z","shell.execute_reply.started":"2021-10-04T05:36:31.194696Z","shell.execute_reply":"2021-10-04T05:36:31.19472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(valid_combinations)):\n    print('Combination :', list(valid_combinations[i]))\n\n    train_data_retriever = DataRetriever_2D_CNN(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values,\n        list(valid_combinations[i]), rotate = 0)\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(train_loader):\n        print(f\"{e}/{len(train_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_2D_CNN[i]\n            tmp_res =torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.196079Z","iopub.status.idle":"2021-10-04T05:36:31.196876Z","shell.execute_reply.started":"2021-10-04T05:36:31.196627Z","shell.execute_reply":"2021-10-04T05:36:31.196651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred_df = pd.concat([pd.DataFrame(df_train[\"BraTS21ID\"].values).reset_index(drop = True), pd.DataFrame(df_train[\"MGMT_value\"].values).reset_index(drop = True), pd.DataFrame(master_y_pred[0]).reset_index(drop = True), pd.DataFrame(master_y_pred[1]).reset_index(drop = True), pd.DataFrame(master_y_pred[2]), pd.DataFrame(master_y_pred[3]).reset_index(drop = True)], axis = 1).reset_index(drop = True)\ntrain_pred_df.columns = ['BraTS21ID', 'MGMT_value', 'T2w + T1wCE + T1w pred', 'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred', 'FLAIR + T1wCE + T1w pred']\ntrain_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.198013Z","iopub.status.idle":"2021-10-04T05:36:31.198635Z","shell.execute_reply.started":"2021-10-04T05:36:31.198371Z","shell.execute_reply":"2021-10-04T05:36:31.198394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(valid_combinations)):\n    print('Combination :', list(valid_combinations[i]))\n\n    valid_data_retriever = DataRetriever_2D_CNN(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        list(valid_combinations[i]), rotate = 0)\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(valid_loader):\n        print(f\"{e}/{len(valid_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_2D_CNN[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.199778Z","iopub.status.idle":"2021-10-04T05:36:31.200496Z","shell.execute_reply.started":"2021-10-04T05:36:31.200257Z","shell.execute_reply":"2021-10-04T05:36:31.20028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_pred_df = pd.concat([pd.DataFrame(df_valid[\"BraTS21ID\"].values).reset_index(drop = True), pd.DataFrame(df_valid[\"MGMT_value\"].values).reset_index(drop = True), pd.DataFrame(master_y_pred[0]).reset_index(drop = True), pd.DataFrame(master_y_pred[1]).reset_index(drop = True), pd.DataFrame(master_y_pred[2]), pd.DataFrame(master_y_pred[3]).reset_index(drop = True)], axis = 1).reset_index(drop = True)\nvalid_pred_df.columns = ['BraTS21ID', 'MGMT_value', 'T2w + T1wCE + T1w pred', 'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred', 'FLAIR + T1wCE + T1w pred']\nvalid_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.201569Z","iopub.status.idle":"2021-10-04T05:36:31.202333Z","shell.execute_reply.started":"2021-10-04T05:36:31.202107Z","shell.execute_reply":"2021-10-04T05:36:31.20213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, len(mri_types)):\n    data = Dataset(df_train,mri_type = mri_types[i], batch_size=1)\n    model = models_3D_user_defined_CNN[i]\n    y_pred = model.predict(data)\n    y_pred = y_pred.reshape(-1)\n    train_pred_df[f'{mri_types[i]}_3D_user_defined_CNN_pred'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.203414Z","iopub.status.idle":"2021-10-04T05:36:31.204198Z","shell.execute_reply.started":"2021-10-04T05:36:31.20394Z","shell.execute_reply":"2021-10-04T05:36:31.203967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, len(mri_types)):\n    data = Dataset(df_valid,mri_type = mri_types[i], batch_size=1)\n    model = models_3D_user_defined_CNN[i]\n    y_pred = model.predict(data)\n    y_pred = y_pred.reshape(-1)\n    valid_pred_df[f'{mri_types[i]}_3D_user_defined_CNN_pred'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.205292Z","iopub.status.idle":"2021-10-04T05:36:31.206083Z","shell.execute_reply.started":"2021-10-04T05:36:31.205833Z","shell.execute_reply":"2021-10-04T05:36:31.205857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(mri_types)):\n    print('MRI type :', mri_types[i])\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    train_data_retriever = DataRetriever(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values,\n        mri_types[i],\n        augment = False)\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=2,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(train_loader):\n        print(f\"{e}/{len(train_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_3D_CNN_effnet[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.207175Z","iopub.status.idle":"2021-10-04T05:36:31.207945Z","shell.execute_reply.started":"2021-10-04T05:36:31.207699Z","shell.execute_reply":"2021-10-04T05:36:31.207723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_pred_df = pd.DataFrame(data = None)\n# train_pred_df[\"BraTS21ID\"] = df_train[\"BraTS21ID\"]\ntrain_pred_df['FLAIR pred - 3D effnet'] = master_y_pred[0]\ntrain_pred_df['T1w pred - 3D effnet'] = master_y_pred[1]\ntrain_pred_df['T1wCE pred - 3D effnet'] = master_y_pred[2]\ntrain_pred_df['T2w pred - 3D effnet'] = master_y_pred[3]\ntrain_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.209146Z","iopub.status.idle":"2021-10-04T05:36:31.209922Z","shell.execute_reply.started":"2021-10-04T05:36:31.209675Z","shell.execute_reply":"2021-10-04T05:36:31.209699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(mri_types)):\n    print('MRI type :', mri_types[i])\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    valid_data_retriever = DataRetriever(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        mri_types[i],\n        augment = False)\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever,\n        batch_size=2,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(valid_loader):\n        print(f\"{e}/{len(valid_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_3D_CNN_effnet[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.211123Z","iopub.status.idle":"2021-10-04T05:36:31.211657Z","shell.execute_reply.started":"2021-10-04T05:36:31.211421Z","shell.execute_reply":"2021-10-04T05:36:31.211445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_pred_df = pd.DataFrame(data = None)\nvalid_pred_df[\"BraTS21ID\"] = df_valid[\"BraTS21ID\"]\nvalid_pred_df['FLAIR pred - 3D effnet'] = master_y_pred[0]\nvalid_pred_df['T1w pred - 3D effnet'] = master_y_pred[1]\nvalid_pred_df['T1wCE pred - 3D effnet'] = master_y_pred[2]\nvalid_pred_df['T2w pred - 3D effnet'] = master_y_pred[3]\nvalid_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.212968Z","iopub.status.idle":"2021-10-04T05:36:31.213794Z","shell.execute_reply.started":"2021-10-04T05:36:31.213534Z","shell.execute_reply":"2021-10-04T05:36:31.213558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flair_pred = train_pred_df['FLAIR pred - 3D effnet']\nt1w_pred = train_pred_df['T1w pred - 3D effnet']\nt1wce_pred = train_pred_df['T1wCE pred - 3D effnet']\nt2w_pred = train_pred_df['T2w pred - 3D effnet']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.21485Z","iopub.status.idle":"2021-10-04T05:36:31.215669Z","shell.execute_reply.started":"2021-10-04T05:36:31.215415Z","shell.execute_reply":"2021-10-04T05:36:31.21544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combinations\ny_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\ny_true = df_train['MGMT_value']\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - mean')\n\ny_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].median(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - median')\n\ny_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].max(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - max')\n\ny_pred = flair_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - flair')\n\ny_pred = t1w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1w')\n\ny_pred = t1wce_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1wce')\n\ny_pred = t2w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t2w')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.216745Z","iopub.status.idle":"2021-10-04T05:36:31.21752Z","shell.execute_reply.started":"2021-10-04T05:36:31.217278Z","shell.execute_reply":"2021-10-04T05:36:31.217304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flair_pred = valid_pred_df['FLAIR pred - 3D effnet']\nt1w_pred = valid_pred_df['T1w pred - 3D effnet']\nt1wce_pred = valid_pred_df['T1wCE pred - 3D effnet']\nt2w_pred = valid_pred_df['T2w pred - 3D effnet']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.218576Z","iopub.status.idle":"2021-10-04T05:36:31.219353Z","shell.execute_reply.started":"2021-10-04T05:36:31.219122Z","shell.execute_reply":"2021-10-04T05:36:31.219145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combinations\ny_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\ny_true = df_valid['MGMT_value']\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - mean')\n\ny_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].median(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - median')\n\ny_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].max(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - max')\n\ny_pred = flair_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - flair')\n\ny_pred = t1w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1w')\n\ny_pred = t1wce_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1wce')\n\ny_pred = t2w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t2w')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.220516Z","iopub.status.idle":"2021-10-04T05:36:31.221301Z","shell.execute_reply.started":"2021-10-04T05:36:31.22104Z","shell.execute_reply":"2021-10-04T05:36:31.221064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classification_metrics(y_true, y_prob):\n    '''\n     Calculates classification metrics\n    :param y_true: true label\n    :param y_prob: probabilitites of true label\n    :param thrshold: threshold\n    :return: metrics\n    '''\n    \n    # calculating auroc values\n    fpr_rf, tpr_rf,thresholds = roc_curve(y_true, y_prob)\n    roc_auc_rf = auc(fpr_rf, tpr_rf)\n    optimal_idx = np.argmax(tpr_rf - fpr_rf)\n    optimal_threshold = thresholds[optimal_idx]\n        \n#         print(optimal_threshold)\n#         print(\"=====\"*20) \n#     if optimal_cal==False:\n#         optimal_threshold = thrshold   \n     \n    # generating prediction on the basis of certain threshold\n    y_pred = np.where(y_prob >= optimal_threshold, 1, 0)\n\n    # calculating tp,tn,fp,fn from confusion metrics\n    tn, fp, fn, tp = (confusion_matrix(y_true, y_pred)).ravel()\n\n    # calculating auprc\n    average_precision = average_precision_score(y_true, y_prob)\n\n    # calculating precision,recall and f1 sscore and accuracy\n    precision = (precision_score(y_true, y_pred))\n    recall = (recall_score(y_true, y_pred))\n    accuracy = (accuracy_score(y_true, y_pred))\n    f1_accuracy = (f1_score(y_true, y_pred))\n    from sklearn.metrics import cohen_kappa_score\n    kappa_score = cohen_kappa_score(y_true, y_pred, labels=None, weights=None)\n    binary_cross_entropy=log_loss(y_true, y_prob)\n    # creating dictionary of classification metric\n    target_mean=np.mean(y_true)\n    classification_metric_dict = {\"True_negatives\": tn,\n                                  \"False_positives\": fp,\n                                  \"False_negatives\": fn,\n                                  \"True_positives\": tp,\n                                  \"Accuracy\": accuracy,\n                                  \"Recall\": recall,\n                                  \"Precision\": precision,\n                                  \"f1_score\": f1_accuracy,\n                                  \"PR_AUC\": average_precision,\n                                  \"ROC_AUC\": roc_auc_rf,\n                                  \"Kappa Score\": kappa_score,\n                                  \"binary_cross_etropy\":binary_cross_entropy,\n                                  \"target_imbalance\":target_mean,\n                                  \"target_size\":len(y_true)\n                                  }\n\n    return classification_metric_dict, optimal_threshold\n\ndef classification_metrics_train(y_true, y_prob,threshold):\n    '''\n     Calculates classification metrics\n    :param y_true: true label\n    :param y_prob: probabilitites of true label\n    :param thrshold: threshold\n    :return: metrics\n    '''\n    \n    # calculating auroc values\n    fpr_rf, tpr_rf,thresholds = roc_curve(y_true, y_prob)\n    roc_auc_rf = auc(fpr_rf, tpr_rf)\n#     optimal_idx = np.argmax(tpr_rf - fpr_rf)\n    optimal_threshold = threshold\n        \n#         print(optimal_threshold)\n#         print(\"=====\"*20) \n#     if optimal_cal==False:\n#         optimal_threshold = thrshold   \n     \n    # generating prediction on the basis of certain threshold\n    y_pred = np.where(y_prob >= optimal_threshold, 1, 0)\n\n    # calculating tp,tn,fp,fn from confusion metrics\n    tn, fp, fn, tp = (confusion_matrix(y_true, y_pred)).ravel()\n\n    # calculating auprc\n    average_precision = average_precision_score(y_true, y_prob)\n\n    # calculating precision,recall and f1 sscore and accuracy\n    precision = (precision_score(y_true, y_pred))\n    recall = (recall_score(y_true, y_pred))\n    accuracy = (accuracy_score(y_true, y_pred))\n    f1_accuracy = (f1_score(y_true, y_pred))\n    from sklearn.metrics import cohen_kappa_score\n    kappa_score = cohen_kappa_score(y_true, y_pred, labels=None, weights=None)\n    binary_cross_entropy=log_loss(y_true, y_prob)\n    # creating dictionary of classification metric\n    target_mean=np.mean(y_true)\n    classification_metric_dict = {\"True_negatives\": tn,\n                                  \"False_positives\": fp,\n                                  \"False_negatives\": fn,\n                                  \"True_positives\": tp,\n                                  \"Accuracy\": accuracy,\n                                  \"Recall\": recall,\n                                  \"Precision\": precision,\n                                  \"f1_score\": f1_accuracy,\n                                  \"PR_AUC\": average_precision,\n                                  \"ROC_AUC\": roc_auc_rf,\n                                  \"Kappa Score\": kappa_score,\n                                  \"binary_cross_etropy\":binary_cross_entropy,\n                                  \"target_imbalance\":target_mean,\n                                  \"target_size\":len(y_true)\n                                  }\n\n    return classification_metric_dict, optimal_threshold","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.222568Z","iopub.status.idle":"2021-10-04T05:36:31.223152Z","shell.execute_reply.started":"2021-10-04T05:36:31.222891Z","shell.execute_reply":"2021-10-04T05:36:31.222914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective_classification(X_train, y_train, X_val, y_val, target_value, trial):\n    \"\"\"It tries to find the best hyper-parameters for XGBOOST model for given task\n\n        Details:\n            It uses OPTUNA library which is based on Baseian-optimization to tune the hyper-params.\n\n        Args:\n            X_train: training data\n            X_test: testing data\n            y_tain: training label\n            y_val: validation label\n            trail: object of optuna for optimizing the task in hand\n\n        Returns:\n            best score till now\n\n    \"\"\"\n    if ((target_value)):\n        tree_methods = ['approx', 'hist', 'exact']\n        boosting_lists = ['gbtree', 'gblinear']\n        objective_list_reg = ['binary:logistic']  # 'reg:gamma', 'reg:tweedie'\n        boosting = trial.suggest_categorical('boosting', boosting_lists),\n        tree_method = trial.suggest_categorical('tree_method', tree_methods),\n        n_estimator = trial.suggest_int('n_estimators',20, 120, 10),\n        max_depth = trial.suggest_int('max_depth', 1, 10),\n        reg_alpha = trial.suggest_int('reg_alpha', 2,7),\n        reg_lambda = trial.suggest_int('reg_lambda', 2,7),\n        min_child_weight = trial.suggest_int('min_child_weight', 0,5),\n        gamma = trial.suggest_int('gamma', 0, 5),\n        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n        objective = trial.suggest_categorical('objective', objective_list_reg),\n        colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.8, 1, 0.05),\n        colsample_bynode = trial.suggest_discrete_uniform('colsample_bynode', 0.8, 1, 0.05),\n        colsample_bylevel = trial.suggest_discrete_uniform('colsample_bylevel', 0.8, 1, 0.05),\n        subsample = trial.suggest_discrete_uniform('subsample', 0.8, 1, 0.05),\n#         scale_pos_weight = trial.suggest_discrete_uniform('scale_pos_weight', 0, 3, 0.1)\n        nthread = -1\n        \n        \n    xgboost_tune = xgb.XGBClassifier(\n        tree_method=tree_method[0],\n#         boosting=boosting[0],\n        reg_alpha=reg_alpha[0],\n        reg_lambda=reg_lambda[0],\n        gamma=gamma[0],\n        objective=objective[0],\n        colsample_bynode=colsample_bynode[0],\n        colsample_bylevel=colsample_bylevel[0],\n        n_estimators=n_estimator[0],\n        max_depth=max_depth[0],\n        min_child_weight=min_child_weight[0],\n        learning_rate=learning_rate[0],\n        subsample=subsample[0],\n        colsample_bytree=colsample_bytree[0],\n#         scale_pos_weight=scale_pos_weight,\n        eval_metric='logloss',\n        num_class=1,\n        n_jobs=nthread,\n        random_state=SEED)\n    xgboost_tune.fit(X_train, y_train)\n    pred_val = xgboost_tune.predict(X_val)\n    \n    return roc_auc_score(y_val,pred_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.224362Z","iopub.status.idle":"2021-10-04T05:36:31.22511Z","shell.execute_reply.started":"2021-10-04T05:36:31.224854Z","shell.execute_reply":"2021-10-04T05:36:31.224881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [x for x in train_pred_df.columns.tolist() if 'pred' in x.lower()]\n# get a list of models to evaluate\ndef get_models():\n\tmodels = dict()\n\tmodels['lr'] = LogisticRegression()\n\tmodels['knn'] = KNeighborsClassifier()\n\tmodels['cart'] = DecisionTreeClassifier()\n\tmodels['svm'] = SVC()\n\tmodels['bayes'] = GaussianNB()\n\treturn models\n \n# evaluate a given model using cross-validation\ndef evaluate_model(model, X, y):\n\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n\treturn scores\n \n# define dataset\nX = pd.concat([train_pred_df[cols],valid_pred_df[cols]], axis = 0).reset_index(drop = True)\ny = pd.concat([train_pred_df[['MGMT_value']],valid_pred_df[['MGMT_value']]], axis = 0).reset_index(drop = True)\ny = y['MGMT_value']\n# get the models to evaluate\nclassifier_models = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in classifier_models.items():\n\tscores = evaluate_model(model, X, y)\n\tresults.append(scores)\n\tnames.append(name)\n\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\npyplot.boxplot(results, labels=names, showmeans=True)\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.226294Z","iopub.status.idle":"2021-10-04T05:36:31.226864Z","shell.execute_reply.started":"2021-10-04T05:36:31.226617Z","shell.execute_reply":"2021-10-04T05:36:31.22664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(train_pred_df[cols], train_pred_df['MGMT_value'])\ntrain_pred = model.predict_proba(train_pred_df[cols])\ntrain_pred = [x[1] for x in train_pred]\nvalid_pred = model.predict_proba(valid_pred_df[cols])\nvalid_pred = [x[1] for x in valid_pred]\nmodel_performance_results = classification_metrics(train_pred_df['MGMT_value'], train_pred)\nprint('\\nTrain data performance:')\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\nprint('\\nValidation data performance:')\nmodel_performance_results = classification_metrics(valid_pred_df['MGMT_value'], valid_pred)\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\njoblib.dump(model, 'lr_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.22797Z","iopub.status.idle":"2021-10-04T05:36:31.228761Z","shell.execute_reply.started":"2021-10-04T05:36:31.228508Z","shell.execute_reply":"2021-10-04T05:36:31.228532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\nvalid_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\nmodel_performance_results = classification_metrics(train_pred_df['MGMT_value'], train_pred)\nprint('\\nTrain data performance:')\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\nprint('\\nValidation data performance:')\nmodel_performance_results = classification_metrics(valid_pred_df['MGMT_value'], valid_pred)\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.229911Z","iopub.status.idle":"2021-10-04T05:36:31.23077Z","shell.execute_reply.started":"2021-10-04T05:36:31.230515Z","shell.execute_reply":"2021-10-04T05:36:31.230539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nX_train = train_pred_df[cols]\ny_train = train_pred_df[['MGMT_value']]\nX_valid = valid_pred_df[cols]\ny_valid = valid_pred_df[['MGMT_value']]\n\n# # br = BoostARoota(metric='logloss')\n# # br.fit(X_train,y_train)\n# # X_train=X_train[br.keep_vars_.tolist()]\n# # X_valid=X_valid[br.keep_vars_.tolist()]\n\nstudy = optuna.create_study(direction='maximize', sampler=TPESampler(seed=SEED))\nstudy.optimize(\n    functools.partial(objective_classification, X_train, y_train, X_valid, y_valid,'trial'),\n            timeout=20)\n\nmodel_xgb = xgb.XGBClassifier(**study.best_params, random_state=SEED)\nmodel_xgb.fit(X_train,y_train)\n\ntrain_pred = model_xgb.predict_proba(train_pred_df[cols])\ntrain_pred = [x[1] for x in train_pred]\nvalid_pred = model_xgb.predict_proba(valid_pred_df[cols])\nvalid_pred = [x[1] for x in valid_pred]\n\nmodel_performance_results = classification_metrics(train_pred_df['MGMT_value'], train_pred)\nprint('\\nTrain data performance:')\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\nprint('\\nValidation data performance:')\nmodel_performance_results = classification_metrics(valid_pred_df['MGMT_value'], valid_pred)\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\n\nimport joblib\nprint(\"Saving model .. \",end=\" \")\njoblib.dump(model,r\"XGBoost_model.pkl\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.231707Z","iopub.status.idle":"2021-10-04T05:36:31.232506Z","shell.execute_reply.started":"2021-10-04T05:36:31.232261Z","shell.execute_reply":"2021-10-04T05:36:31.232286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selecting best model","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:26:01.386074Z","iopub.status.idle":"2021-09-25T13:26:01.386675Z","shell.execute_reply.started":"2021-09-25T13:26:01.386448Z","shell.execute_reply":"2021-09-25T13:26:01.38647Z"}}},{"cell_type":"code","source":"valid_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.233659Z","iopub.status.idle":"2021-10-04T05:36:31.234484Z","shell.execute_reply.started":"2021-10-04T05:36:31.234233Z","shell.execute_reply":"2021-10-04T05:36:31.234256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_pred_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.235515Z","iopub.status.idle":"2021-10-04T05:36:31.236338Z","shell.execute_reply.started":"2021-10-04T05:36:31.236064Z","shell.execute_reply":"2021-10-04T05:36:31.236089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = list(valid_pred_df[['T2w + T1wCE + T1w pred',\n       'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred',\n       'FLAIR + T1wCE + T1w pred']].mean(axis = 1))\ny_true = list(valid_pred_df['MGMT_value'])\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.237395Z","iopub.status.idle":"2021-10-04T05:36:31.238188Z","shell.execute_reply.started":"2021-10-04T05:36:31.237925Z","shell.execute_reply":"2021-10-04T05:36:31.237949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = list(valid_pred_df[['FLAIR_3D_user_defined_CNN_pred',\n       'T1w_3D_user_defined_CNN_pred', 'T1wCE_3D_user_defined_CNN_pred',\n       'T2w_3D_user_defined_CNN_pred']].mean(axis = 1))\ny_true = list(valid_pred_df['MGMT_value'])\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.239354Z","iopub.status.idle":"2021-10-04T05:36:31.240145Z","shell.execute_reply.started":"2021-10-04T05:36:31.239883Z","shell.execute_reply":"2021-10-04T05:36:31.239907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = list(valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1))\ny_true = list(valid_pred_df['MGMT_value'])\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc)\n\n####################################\n# The optimal cut off would be where tpr is high and fpr is low\n# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n####################################\ni = np.arange(len(tpr)) # index for df\nroc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\nroc.iloc[(roc.tf-0).abs().argsort()[:1]]\n\n# Plot tpr vs 1-fpr\nfig, ax = pl.subplots()\npl.plot(roc['tpr'])\npl.plot(roc['1-fpr'], color = 'red')\npl.xlabel('Index')\npl.ylabel('TPR/(1-FPR)')\npl.title('Receiver operating characteristic')\noptimal_threshold = roc.iloc[(roc.tf-0).abs().argsort()[:1]]['thresholds'].iloc[0]\nprint('Optimal threshold:', optimal_threshold*100,'%')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.241319Z","iopub.status.idle":"2021-10-04T05:36:31.242127Z","shell.execute_reply.started":"2021-10-04T05:36:31.241861Z","shell.execute_reply":"2021-10-04T05:36:31.241885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC curve\nfpr, tpr, _ = roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(5, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.plot([roc.iloc[(roc.tf-0).abs().argsort()[:1]]['fpr'].iloc[0], roc.iloc[(roc.tf-0).abs().argsort()[:1]]['fpr'].iloc[0]], [0, 1], color='green', lw=2, linestyle='--') # Performance metrics at optimal threshold\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.243181Z","iopub.status.idle":"2021-10-04T05:36:31.244029Z","shell.execute_reply.started":"2021-10-04T05:36:31.243789Z","shell.execute_reply":"2021-10-04T05:36:31.243812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Error analysis","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:26:01.393244Z","iopub.status.idle":"2021-09-25T13:26:01.393852Z","shell.execute_reply.started":"2021-09-25T13:26:01.393623Z","shell.execute_reply":"2021-09-25T13:26:01.393646Z"}}},{"cell_type":"code","source":"valid_pred_df['Final pred'] = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(valid_pred_df['MGMT_value'], valid_pred_df['Final pred'])\nroc_auc = auc(fpr, tpr)\nprint(\"\\nArea under the ROC curve : %f\" % roc_auc)\n\nprint('\\n','# False positives:',valid_pred_df[(valid_pred_df['Final pred']>0.5) & (valid_pred_df['MGMT_value']==0)].shape[0],'\\n')\nvalid_pred_df[(valid_pred_df['Final pred']>0.5) & (valid_pred_df['MGMT_value']==0)]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.244972Z","iopub.status.idle":"2021-10-04T05:36:31.245787Z","shell.execute_reply.started":"2021-10-04T05:36:31.24553Z","shell.execute_reply":"2021-10-04T05:36:31.245554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n','# False negatives:',valid_pred_df[(valid_pred_df['Final pred']<0.5) & (valid_pred_df['MGMT_value']==1)].shape[0],'\\n')\nvalid_pred_df[(valid_pred_df['Final pred']<0.5) & (valid_pred_df['MGMT_value']==1)]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.246817Z","iopub.status.idle":"2021-10-04T05:36:31.247625Z","shell.execute_reply.started":"2021-10-04T05:36:31.247381Z","shell.execute_reply":"2021-10-04T05:36:31.247406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = load_dicom_images_3d(scan_id = '00819')\n# plt.imshow(a[0,:,:,49], cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.248672Z","iopub.status.idle":"2021-10-04T05:36:31.249501Z","shell.execute_reply.started":"2021-10-04T05:36:31.24925Z","shell.execute_reply":"2021-10-04T05:36:31.249274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# master_y_pred = []\n# for i in range(0,len(mri_types)):\n#     print('MRI type :', mri_types[i])\n\n#     train_data_retriever = DataRetriever(\n#         df_train[\"BraTS21ID\"].values, \n#         df_train[\"MGMT_value\"].values,\n#         mri_types[i],\n#         augment = False)\n\n#     train_loader = torch_data.DataLoader(\n#         train_data_retriever,\n#         batch_size=4,\n#         shuffle=False,\n#         num_workers=8,\n#     )\n\n#     y_pred = []\n    \n#     for e, batch in enumerate(train_loader):\n#         print(f\"{e}/{len(train_loader)}\", end=\"\\r\")\n#         with torch.no_grad():\n#             tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n#             model = models[i]\n#             embeddings_df = model.base_model(batch[\"X\"].to(device))\n#             y_pred.extend(embeddings_df)\n            \n#     master_y_pred.append(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.250548Z","iopub.status.idle":"2021-10-04T05:36:31.251312Z","shell.execute_reply.started":"2021-10-04T05:36:31.251066Z","shell.execute_reply":"2021-10-04T05:36:31.251091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# neurons_num = 1000\n\n# for i in tqdm(range(0, len(mri_types))):\n#     for j in range(0, neurons_num):\n#         train_pred_df[mri_types[i]+'_'+str(j+1)] = [master_y_pred[i][m][0].cpu().numpy().tolist() for m in range(0, len(train_pred_df))]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.252462Z","iopub.status.idle":"2021-10-04T05:36:31.253541Z","shell.execute_reply.started":"2021-10-04T05:36:31.253293Z","shell.execute_reply":"2021-10-04T05:36:31.253319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# master_y_pred = []\n# for i in range(0,len(mri_types)):\n#     print('MRI type :', mri_types[i])\n\n#     valid_data_retriever = DataRetriever(\n#         df_valid[\"BraTS21ID\"].values, \n#         df_valid[\"MGMT_value\"].values,\n#         mri_types[i],\n#         augment = False)\n\n#     valid_loader = torch_data.DataLoader(\n#         valid_data_retriever,\n#         batch_size=4,\n#         shuffle=False,\n#         num_workers=8,\n#     )\n\n#     y_pred = []\n    \n#     for e, batch in enumerate(valid_loader):\n#         print(f\"{e}/{len(valid_loader)}\", end=\"\\r\")\n#         with torch.no_grad():\n#             tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n#             model = models[i]\n#             embeddings_df = model.base_model(batch[\"X\"].to(device))\n#             y_pred.extend(embeddings_df)\n            \n#     master_y_pred.append(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.254531Z","iopub.status.idle":"2021-10-04T05:36:31.255198Z","shell.execute_reply.started":"2021-10-04T05:36:31.25494Z","shell.execute_reply":"2021-10-04T05:36:31.254964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in tqdm(range(0, len(mri_types))):\n#     for j in range(0, neurons_num):\n#         valid_pred_df[mri_types[i]+'_'+str(j+1)] = [master_y_pred[i][m][0].cpu().numpy().tolist() for m in range(0, len(valid_pred_df))]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.256306Z","iopub.status.idle":"2021-10-04T05:36:31.256862Z","shell.execute_reply.started":"2021-10-04T05:36:31.256609Z","shell.execute_reply":"2021-10-04T05:36:31.256632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Neural network\n\nX_train = train_pred_df[cols]\ny_train = train_pred_df['MGMT_value']\n\nsimple_nn_model = Sequential()\nsimple_nn_model.add(Dense(100, input_dim=12, activation='relu'))\nsimple_nn_model.add(Dense(50, activation='relu'))\nsimple_nn_model.add(Dense(10, activation='relu'))\nsimple_nn_model.add(Dense(1, activation='sigmoid'))\nsimple_nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC(name = 'auc'),'accuracy'])\n\n# Define callbacks\nmodel_save = ModelCheckpoint('simple_nn_model.h5', \n                             save_best_only = True, \n                             monitor = 'val_auc', \n                             mode = 'max', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_auc', \n                           patience = 40, mode = 'max', verbose = 1,\n                           restore_best_weights = True)\n\nsimple_nn_model.fit(X_train, y_train, validation_data=(valid_pred_df[cols], valid_pred_df['MGMT_value']), epochs=500, batch_size=10,\n        shuffle=True,\n        verbose=1,\n        callbacks = [model_save, early_stop],\n    )","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.257997Z","iopub.status.idle":"2021-10-04T05:36:31.258524Z","shell.execute_reply.started":"2021-10-04T05:36:31.258286Z","shell.execute_reply":"2021-10-04T05:36:31.258309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = [x[0] for x in simple_nn_model.predict(train_pred_df[cols]).tolist()]\nfpr, tpr, thresholds =roc_curve(train_pred_df['MGMT_value'], y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"\\n Training data: Area under the ROC curve - %f\" % roc_auc)\n\ny_pred = [x[0] for x in simple_nn_model.predict(valid_pred_df[cols])]\nfpr, tpr, thresholds =roc_curve(valid_pred_df['MGMT_value'], y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"\\n Validation data: Area under the ROC curve - %f\" % roc_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.259881Z","iopub.status.idle":"2021-10-04T05:36:31.260682Z","shell.execute_reply.started":"2021-10-04T05:36:31.260434Z","shell.execute_reply":"2021-10-04T05:36:31.260458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions on test data","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:26:01.417656Z","iopub.status.idle":"2021-09-25T13:26:01.418232Z","shell.execute_reply.started":"2021-09-25T13:26:01.418005Z","shell.execute_reply":"2021-09-25T13:26:01.418027Z"}}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\nsubmission['BraTS21ID5'] = submission['BraTS21ID'].apply(lambda x: format(x, '05d'))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.261717Z","iopub.status.idle":"2021-10-04T05:36:31.262506Z","shell.execute_reply.started":"2021-10-04T05:36:31.262265Z","shell.execute_reply":"2021-10-04T05:36:31.262291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(valid_combinations)):\n    print('Combination :', list(valid_combinations[i]))\n\n    test_data_retriever = DataRetriever_2D_CNN(\n        submission[\"BraTS21ID\"].values, \n        np.array([]),\n        list(valid_combinations[i]), rotate = 0)\n\n    test_loader = torch_data.DataLoader(\n        test_data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(test_loader):\n        print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_2D_CNN[i]\n            tmp_res =torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n    \n    master_y_pred.append(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.263656Z","iopub.status.idle":"2021-10-04T05:36:31.264221Z","shell.execute_reply.started":"2021-10-04T05:36:31.263966Z","shell.execute_reply":"2021-10-04T05:36:31.26399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_df = pd.concat([pd.DataFrame(submission[\"BraTS21ID\"].values).reset_index(drop = True), pd.DataFrame(master_y_pred[0]).reset_index(drop = True), pd.DataFrame(master_y_pred[1]).reset_index(drop = True), pd.DataFrame(master_y_pred[2]), pd.DataFrame(master_y_pred[3]).reset_index(drop = True)], axis = 1).reset_index(drop = True)\ntest_pred_df.columns = ['BraTS21ID', 'T2w + T1wCE + T1w pred', 'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred', 'FLAIR + T1wCE + T1w pred']\ntest_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.265517Z","iopub.status.idle":"2021-10-04T05:36:31.266413Z","shell.execute_reply.started":"2021-10-04T05:36:31.26615Z","shell.execute_reply":"2021-10-04T05:36:31.266177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, len(mri_types)):\n    data = Dataset(submission,mri_type = mri_types[i], batch_size=1, is_train = False)\n    model = models_3D_user_defined_CNN[i]\n    y_pred = model.predict(data)\n    y_pred = y_pred.reshape(-1)\n    test_pred_df[f'{mri_types[i]}_3D_user_defined_CNN_pred'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.267685Z","iopub.status.idle":"2021-10-04T05:36:31.268444Z","shell.execute_reply.started":"2021-10-04T05:36:31.268202Z","shell.execute_reply":"2021-10-04T05:36:31.268225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(mri_types)):\n    print('MRI type :', mri_types[i])\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    test_data_retriever = DataRetriever(\n        submission[\"BraTS21ID\"].values, \n        np.array([]),\n        mri_types[i],\n        augment = False)\n\n    test_loader = torch_data.DataLoader(\n        test_data_retriever,\n        batch_size=2,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(test_loader):\n        print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_3D_CNN_effnet[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n    \n    master_y_pred.append(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.269521Z","iopub.status.idle":"2021-10-04T05:36:31.270057Z","shell.execute_reply.started":"2021-10-04T05:36:31.269817Z","shell.execute_reply":"2021-10-04T05:36:31.26984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_df['FLAIR pred - 3D effnet'] = master_y_pred[0]\ntest_pred_df['T1w pred - 3D effnet'] = master_y_pred[1]\ntest_pred_df['T1wCE pred - 3D effnet'] = master_y_pred[2]\ntest_pred_df['T2w pred - 3D effnet'] = master_y_pred[3]\ntest_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.271433Z","iopub.status.idle":"2021-10-04T05:36:31.272254Z","shell.execute_reply.started":"2021-10-04T05:36:31.271978Z","shell.execute_reply":"2021-10-04T05:36:31.272004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgb = joblib.load(r\"./XGBoost_model.pkl\")\ntest_pred_df['XGBoost pred'] = model_xgb.predict_proba(test_pred_df[cols])[:,1]\nsimple_nn_model = Sequential()\nsimple_nn_model.add(Dense(100, input_dim=12, activation='relu'))\nsimple_nn_model.add(Dense(50, activation='relu'))\nsimple_nn_model.add(Dense(10, activation='relu'))\nsimple_nn_model.add(Dense(1, activation='sigmoid'))\n\ntest_pred_df['Simple NN pred'] = simple_nn_model.predict(test_pred_df[cols])\nmodel = joblib.load('./lr_model.pkl')\ntest_pred_df['lr pred'] = model.predict_proba(test_pred_df[cols])[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.273511Z","iopub.status.idle":"2021-10-04T05:36:31.274417Z","shell.execute_reply.started":"2021-10-04T05:36:31.274168Z","shell.execute_reply":"2021-10-04T05:36:31.274192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.275415Z","iopub.status.idle":"2021-10-04T05:36:31.276271Z","shell.execute_reply.started":"2021-10-04T05:36:31.275994Z","shell.execute_reply":"2021-10-04T05:36:31.27602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = test_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\nids = test_pred_df['BraTS21ID']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.277361Z","iopub.status.idle":"2021-10-04T05:36:31.27815Z","shell.execute_reply.started":"2021-10-04T05:36:31.277887Z","shell.execute_reply":"2021-10-04T05:36:31.277911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.279408Z","iopub.status.idle":"2021-10-04T05:36:31.280197Z","shell.execute_reply.started":"2021-10-04T05:36:31.279936Z","shell.execute_reply":"2021-10-04T05:36:31.27996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission.shape)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.281419Z","iopub.status.idle":"2021-10-04T05:36:31.282226Z","shell.execute_reply.started":"2021-10-04T05:36:31.281967Z","shell.execute_reply":"2021-10-04T05:36:31.281992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nplt.hist(submission[\"MGMT_value\"]);","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:31.283371Z","iopub.status.idle":"2021-10-04T05:36:31.284245Z","shell.execute_reply.started":"2021-10-04T05:36:31.283969Z","shell.execute_reply":"2021-10-04T05:36:31.283993Z"},"trusted":true},"execution_count":null,"outputs":[]}]}