{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport glob\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom tqdm.notebook import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n    Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import add, Flatten\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.metrics import top_k_categorical_accuracy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\nfrom sklearn import model_selection as sk_model_selection\nimport os\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:38.018552Z","iopub.execute_input":"2021-10-13T03:22:38.019228Z","iopub.status.idle":"2021-10-13T03:22:43.35199Z","shell.execute_reply.started":"2021-10-13T03:22:38.019113Z","shell.execute_reply":"2021-10-13T03:22:43.351297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nTYPES = [\"FLAIR\", \"T1w\", \"T2w\", \"T1wCE\"]\n#WHITE_THRESHOLD = 10 # out of 255\nEXCLUDE = [109, 123, 709]\n\n\ntrain_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ntest_df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\ntrain_df = train_df[~train_df.BraTS21ID.isin(EXCLUDE)]\n\n\ntrain_df, val_df = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.1, \n    random_state = 404, \n    stratify=train_df[\"MGMT_value\"],\n)\n\ndef load_dicom(path, size = 224):\n    ''' \n    Reads a DICOM image, standardizes so that the pixel values are between 0 and 1, then rescales to 0 and 255\n    \n    Note super sure if this kind of scaling is appropriate, but everyone seems to do it. \n    '''\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return cv2.resize(data, (size, size))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:43.353468Z","iopub.execute_input":"2021-10-13T03:22:43.35498Z","iopub.status.idle":"2021-10-13T03:22:43.39168Z","shell.execute_reply.started":"2021-10-13T03:22:43.354951Z","shell.execute_reply":"2021-10-13T03:22:43.390976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(val_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:43.392971Z","iopub.execute_input":"2021-10-13T03:22:43.393234Z","iopub.status.idle":"2021-10-13T03:22:43.402171Z","shell.execute_reply.started":"2021-10-13T03:22:43.393208Z","shell.execute_reply":"2021-10-13T03:22:43.4Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_all_image_paths(brats21id, image_type, folder='train'): \n    '''\n    Returns an array of all the images of a particular type for a particular patient ID\n    '''\n    assert(image_type in TYPES)\n    \n    patient_path = os.path.join(\n        \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/%s/\" % folder, \n        str(brats21id).zfill(5),\n    )\n\n    paths = sorted(\n        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    \n    num_images = len(paths)\n    if num_images <= 20: \n        start = int(num_images * 0)\n        end = int(num_images * 1)\n    elif num_images <= 40:\n        start = int(num_images * 0.15)\n        end = int(num_images * 0.85)\n\n    elif num_images > 40:\n        start = int(num_images * 0.3)\n        end = int(num_images * 0.7)\n\n    \n\n    interval = 1\n    \n    return np.array(paths[start:end:interval])\n\ndef get_all_images(brats21id, image_type, folder='train', size=225):\n    return [load_dicom(path, size) for path in get_all_image_paths(brats21id, image_type, folder)]\nIMAGE_SIZE = 224\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:43.404622Z","iopub.execute_input":"2021-10-13T03:22:43.409395Z","iopub.status.idle":"2021-10-13T03:22:43.418259Z","shell.execute_reply.started":"2021-10-13T03:22:43.409348Z","shell.execute_reply":"2021-10-13T03:22:43.417579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df.index","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:43.419508Z","iopub.execute_input":"2021-10-13T03:22:43.41998Z","iopub.status.idle":"2021-10-13T03:22:43.431667Z","shell.execute_reply.started":"2021-10-13T03:22:43.419945Z","shell.execute_reply":"2021-10-13T03:22:43.430692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.index","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:43.43297Z","iopub.execute_input":"2021-10-13T03:22:43.433403Z","iopub.status.idle":"2021-10-13T03:22:43.442032Z","shell.execute_reply.started":"2021-10-13T03:22:43.433344Z","shell.execute_reply":"2021-10-13T03:22:43.441136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_all_data_for_train(image_type):\n    global train_df\n    \n    X_train = []\n    y_train = []\n    train_ids = []\n\n    for i in tqdm(train_df.index):\n        x = train_df.loc[i]\n        images = get_all_images(int(x['BraTS21ID']), image_type, 'train', IMAGE_SIZE)\n        label = x['MGMT_value']\n\n        X_train += images\n        y_train += [label] * len(images)\n        train_ids += [int(x['BraTS21ID'])] * len(images)\n        assert(len(X_train) == len(y_train))\n    return np.array(X_train), np.array(y_train), np.array(train_ids)\n\n\ndef get_all_data_for_val(image_type):\n    global val_df\n    \n    X_val = []\n    y_val = []\n    val_ids = []\n\n    for i in tqdm(val_df.index):\n        x = val_df.loc[i]\n        images = get_all_images(int(x['BraTS21ID']), image_type, 'train', IMAGE_SIZE)\n        label = x['MGMT_value']\n\n        X_val += images\n        y_val += [label] * len(images)\n        val_ids += [int(x['BraTS21ID'])] * len(images)\n        assert(len(X_val) == len(y_val))\n    return np.array(X_val), np.array(y_val), np.array(val_ids)\n\n\n\n# def get_all_data_for_test(image_type):\n#     global test_df\n    \n#     X_test = []\n#     test_ids = []\n\n#     for i in tqdm(test_df.index):\n#         x = test_df.loc[i]\n#         images = get_all_images(int(x['BraTS21ID']), image_type, 'test', IMAGE_SIZE)\n#         X_test += images\n#         test_ids += [int(x['BraTS21ID'])] * len(images)\n\n#     return np.array(X), np.array(test_ids)\nX_train, y_train, trainidt = get_all_data_for_train('T1wCE')\nX_val, y_val, validt = get_all_data_for_val('T1wCE')\n# X_test, testidt = get_all_data_for_test('T1wCE')\n#X.shape, y.shape, trainidt.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:22:43.44378Z","iopub.execute_input":"2021-10-13T03:22:43.444059Z","iopub.status.idle":"2021-10-13T03:27:38.199639Z","shell.execute_reply.started":"2021-10-13T03:22:43.444026Z","shell.execute_reply":"2021-10-13T03:27:38.198387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train, X_valid, y_train, y_valid, trainidt_train, trainidt_valid = train_test_split(X, y, trainidt, test_size=0.2, random_state=40)\n\n#split = int(X.shape[0] * 0.8)\n\n# X_train = X[:split]\n# X_valid = X[split:]\n\n# y_train = y[:split]\n# y_valid = y[split:]\n\n# trainidt_train = trainidt[:split]\n# trainidt_valid = trainidt[split:]\n\n# add one dim to fit the model\nX_train = tf.expand_dims(X_train, axis=-1)\nX_val = tf.expand_dims(X_val, axis=-1)\n\ny_train = to_categorical(y_train)\ny_val = to_categorical(y_val)\n\nX_train.shape, y_train.shape, X_val.shape, y_val.shape, trainidt.shape, validt.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:36:16.343017Z","iopub.execute_input":"2021-10-13T03:36:16.34329Z","iopub.status.idle":"2021-10-13T03:36:20.35515Z","shell.execute_reply.started":"2021-10-13T03:36:16.343261Z","shell.execute_reply":"2021-10-13T03:36:20.354406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:27:38.20261Z","iopub.status.idle":"2021-10-13T03:27:38.203405Z","shell.execute_reply.started":"2021-10-13T03:27:38.203145Z","shell.execute_reply":"2021-10-13T03:27:38.203169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\ndata_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:36:23.353893Z","iopub.execute_input":"2021-10-13T03:36:23.354281Z","iopub.status.idle":"2021-10-13T03:36:23.389076Z","shell.execute_reply.started":"2021-10-13T03:36:23.354245Z","shell.execute_reply":"2021-10-13T03:36:23.388434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n    if name is not None:\n        bn_name = name + '_bn'\n        conv_name = name + '_conv'\n    else:\n        bn_name = None\n        conv_name = None\n\n    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n    x = BatchNormalization(axis=3, name=bn_name)(x)\n    return x\n\n\n\ndef bottleneck_Block(inpt,nb_filters,strides=(1,1),with_conv_shortcut=False):\n    k1,k2,k3=nb_filters\n    x = Conv2d_BN(inpt, nb_filter=k1, kernel_size=1, strides=strides, padding='same')\n    x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n    x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')\n    if with_conv_shortcut:\n        shortcut = Conv2d_BN(inpt, nb_filter=k3, strides=strides, kernel_size=1)\n        x = add([x, shortcut])\n        return x\n    else:\n        x = add([x, inpt])\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:44:15.489123Z","iopub.execute_input":"2021-10-13T03:44:15.489414Z","iopub.status.idle":"2021-10-13T03:44:15.497829Z","shell.execute_reply.started":"2021-10-13T03:44:15.489365Z","shell.execute_reply":"2021-10-13T03:44:15.497157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.random.seed(0)\n# random.seed(12)\n# tf.random.set_seed(12)\nIM_WIDTH=224 #图片宽度\nIM_HEIGHT=224 #图片高度\nbatch_size=32 #批的大小\n\ninpt = keras.Input(shape=(224, 224, 1))\nx = ZeroPadding2D((3, 3))(inpt)\n\nh = keras.layers.experimental.preprocessing.Rescaling(1./255)(inpt)\n# h = data_augmentation(h)\n\n\n# # convolutional layer!\n\nx = Conv2d_BN(x,nb_filter=64, kernel_size=(4, 4), strides=(2, 2), padding='valid')\nx = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n#conv2_x\nx = bottleneck_Block(x, nb_filters=[64,64,256],strides=(1,1),with_conv_shortcut=True)\nx = bottleneck_Block(x, nb_filters=[64,64,256])\nx = bottleneck_Block(x, nb_filters=[64,64,256])\n\n#conv3_x\nx = bottleneck_Block(x, nb_filters=[128, 128, 512],strides=(2,2),with_conv_shortcut=True)\nx = bottleneck_Block(x, nb_filters=[128, 128, 512])\nx = bottleneck_Block(x, nb_filters=[128, 128, 512])\nx = bottleneck_Block(x, nb_filters=[128, 128, 512])\n\n#conv4_x\nx = bottleneck_Block(x, nb_filters=[256, 256, 1024],strides=(2,2),with_conv_shortcut=True)\nx = bottleneck_Block(x, nb_filters=[256, 256, 1024])\nx = bottleneck_Block(x, nb_filters=[256, 256, 1024])\nx = bottleneck_Block(x, nb_filters=[256, 256, 1024])\nx = bottleneck_Block(x, nb_filters=[256, 256, 1024])\nx = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n\n#conv5_x\nx = bottleneck_Block(x, nb_filters=[512, 512, 2048], strides=(2, 2), with_conv_shortcut=True)\nx = bottleneck_Block(x, nb_filters=[512, 512, 2048])\nx = bottleneck_Block(x, nb_filters=[512, 512, 2048])\n\nx = AveragePooling2D(pool_size=(4, 4))(x)\n\nh = tf.keras.layers.BatchNormalization(axis=-1)(h)\nh = keras.layers.Dropout(0.3)(h)   \n\nh = keras.layers.Flatten()(h) \n# h = global_average_layer(h)\nh = keras.layers.Dense(128, activation='relu')(h)   \n\noutput = keras.layers.Dense(2, activation=\"softmax\")(h)\n\nmodel = keras.Model(inpt, output)\n\nfrom tensorflow.keras.optimizers import SGD\n# opt = SGD(lr=0.1)\n\ncheckpoint_filepath = 'best_model.h5'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\nfilepath=checkpoint_filepath,\nsave_weights_only=False,\nmonitor='val_auc',\nmode='max',\nsave_best_only=True,\nsave_freq='epoch')\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer=tf.keras.optimizers.SGD(learning_rate =0.0001),\n             metrics=[tf.keras.metrics.AUC()])\n\nhistory = model.fit(x=X_train, y = y_train, epochs=100, callbacks=[model_checkpoint_callback], validation_data= (X_val, y_val))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:44:19.081158Z","iopub.execute_input":"2021-10-13T03:44:19.081548Z","iopub.status.idle":"2021-10-13T03:44:35.665152Z","shell.execute_reply.started":"2021-10-13T03:44:19.081513Z","shell.execute_reply":"2021-10-13T03:44:35.661288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"_uuid":"976f1ae4-82dc-4b48-adf6-0a3032768ae1","_cell_guid":"502632f6-f153-41a1-86a3-28e9696ee782","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-13T03:27:38.210149Z","iopub.status.idle":"2021-10-13T03:27:38.210915Z","shell.execute_reply.started":"2021-10-13T03:27:38.21067Z","shell.execute_reply":"2021-10-13T03:27:38.210695Z"},"trusted":true},"execution_count":null,"outputs":[]}]}