{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Use stacked images (3D) and Efficientnet3D model\n\nAcknowledgements:\n\n- https://www.kaggle.com/ihelon/brain-tumor-eda-with-animations-and-modeling\n- https://www.kaggle.com/furcifer/torch-efficientnet3d-for-mri-no-train\n- https://github.com/shijianjian/EfficientNet-PyTorch-3D\n    \n    \nUse models with only one MRI type, then ensemble the 4 models \n","metadata":{"papermill":{"duration":0.026582,"end_time":"2021-07-29T16:51:17.665332","exception":false,"start_time":"2021-07-29T16:51:17.63875","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","metadata":{"papermill":{"duration":2.647228,"end_time":"2021-07-29T16:51:20.335552","exception":false,"start_time":"2021-07-29T16:51:17.688324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T10:57:45.571898Z","iopub.execute_input":"2021-08-11T10:57:45.572415Z","iopub.status.idle":"2021-08-11T10:57:48.273188Z","shell.execute_reply.started":"2021-08-11T10:57:45.572308Z","shell.execute_reply":"2021-08-11T10:57:48.272261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\npytorch3dpath = \"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\"\n\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 256\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nfrom efficientnet_pytorch_3d import EfficientNet3D","metadata":{"lines_to_end_of_cell_marker":2,"lines_to_next_cell":2,"papermill":{"duration":0.078634,"end_time":"2021-07-29T16:51:20.440356","exception":false,"start_time":"2021-07-29T16:51:20.361722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T10:57:48.276785Z","iopub.execute_input":"2021-08-11T10:57:48.277077Z","iopub.status.idle":"2021-08-11T10:57:48.323185Z","shell.execute_reply.started":"2021-08-11T10:57:48.27705Z","shell.execute_reply":"2021-08-11T10:57:48.322371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions to load images","metadata":{"papermill":{"duration":0.024402,"end_time":"2021-07-29T16:51:20.490356","exception":false,"start_time":"2021-07-29T16:51:20.465954","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if np.min(data)==np.max(data):\n        data = np.zeros((img_size,img_size))\n        return data\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    \n    #data = (data * 255).astype(np.uint8)\n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n\n    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"))\n    \n    middle = len(files)//2\n    num_imgs2 = num_imgs//2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n            \n    return np.expand_dims(img3d,0)\n\n#load_dicom_images_3d(\"00000\").shape","metadata":{"papermill":{"duration":0.882191,"end_time":"2021-07-29T16:51:21.3971","exception":false,"start_time":"2021-07-29T16:51:20.514909","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T10:57:48.326522Z","iopub.execute_input":"2021-08-11T10:57:48.326765Z","iopub.status.idle":"2021-08-11T10:57:48.33786Z","shell.execute_reply.started":"2021-08-11T10:57:48.326742Z","shell.execute_reply":"2021-08-11T10:57:48.337039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","metadata":{"papermill":{"duration":0.073706,"end_time":"2021-07-29T16:51:21.487775","exception":false,"start_time":"2021-07-29T16:51:21.414069","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T10:57:48.340857Z","iopub.execute_input":"2021-08-11T10:57:48.341149Z","iopub.status.idle":"2021-08-11T10:57:48.404679Z","shell.execute_reply.started":"2021-08-11T10:57:48.341125Z","shell.execute_reply":"2021-08-11T10:57:48.403836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and training classes","metadata":{"papermill":{"duration":0.01522,"end_time":"2021-07-29T16:51:21.651038","exception":false,"start_time":"2021-07-29T16:51:21.635818","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n\n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n","metadata":{"papermill":{"duration":0.026485,"end_time":"2021-07-29T16:51:21.692746","exception":false,"start_time":"2021-07-29T16:51:21.666261","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T10:57:48.405984Z","iopub.execute_input":"2021-08-11T10:57:48.406344Z","iopub.status.idle":"2021-08-11T10:57:48.415688Z","shell.execute_reply.started":"2021-08-11T10:57:48.406308Z","shell.execute_reply":"2021-08-11T10:57:48.414455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out\n    ","metadata":{"papermill":{"duration":0.023627,"end_time":"2021-07-29T16:51:21.731691","exception":false,"start_time":"2021-07-29T16:51:21.708064","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T10:57:48.417334Z","iopub.execute_input":"2021-08-11T10:57:48.417751Z","iopub.status.idle":"2021-08-11T10:57:48.42498Z","shell.execute_reply.started":"2021-08-11T10:57:48.417718Z","shell.execute_reply":"2021-08-11T10:57:48.424066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n\n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:57:48.426381Z","iopub.execute_input":"2021-08-11T10:57:48.426784Z","iopub.status.idle":"2021-08-11T10:57:48.43787Z","shell.execute_reply.started":"2021-08-11T10:57:48.426684Z","shell.execute_reply":"2021-08-11T10:57:48.436893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train models","metadata":{"papermill":{"duration":0.015239,"end_time":"2021-07-29T16:51:21.814813","exception":false,"start_time":"2021-07-29T16:51:21.799574","status":"completed"},"tags":[]}},{"cell_type":"code","source":"modelfiles=['../input/3deffmodels/FLAIR-e2-loss0.696-auc0.605.pth','../input/3deffmodels/T1w-e2-loss0.718-auc0.579.pth','../input/3deffmodels/T1wCE-e6-loss0.683-auc0.633.pth','../input/3deffmodels/T2w-e8-loss0.658-auc0.677.pth']","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:21:40.011176Z","iopub.execute_input":"2021-08-11T11:21:40.01158Z","iopub.status.idle":"2021-08-11T11:21:40.015545Z","shell.execute_reply.started":"2021-08-11T11:21:40.011546Z","shell.execute_reply":"2021-08-11T11:21:40.014515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict function","metadata":{"papermill":{"duration":1.537928,"end_time":"2021-07-29T20:33:06.667139","exception":false,"start_time":"2021-07-29T20:33:05.129211","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=1,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(modelfile)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","metadata":{"papermill":{"duration":1.511836,"end_time":"2021-07-29T20:33:09.682017","exception":false,"start_time":"2021-07-29T20:33:08.170181","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T11:36:41.795147Z","iopub.execute_input":"2021-08-11T11:36:41.795541Z","iopub.status.idle":"2021-08-11T11:36:41.806085Z","shell.execute_reply.started":"2021-08-11T11:36:41.795498Z","shell.execute_reply":"2021-08-11T11:36:41.805126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble for submission","metadata":{"papermill":{"duration":1.52003,"end_time":"2021-07-29T20:35:36.319581","exception":false,"start_time":"2021-07-29T20:35:34.799551","status":"completed"},"tags":[]}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nsubmission = pd.read_csv(f\"{data_directory}/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\n#submission[\"MGMT_value\"] /= len(modelfiles)\n#submission[\"MGMT_value\"].to_csv(\"submission.csv\")","metadata":{"papermill":{"duration":107.567647,"end_time":"2021-07-29T20:37:25.522274","exception":false,"start_time":"2021-07-29T20:35:37.954627","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T11:36:43.261583Z","iopub.execute_input":"2021-08-11T11:36:43.261941Z","iopub.status.idle":"2021-08-11T11:38:39.504264Z","shell.execute_reply.started":"2021-08-11T11:36:43.261908Z","shell.execute_reply":"2021-08-11T11:38:39.503338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"papermill":{"duration":1.724359,"end_time":"2021-07-29T20:37:28.914677","exception":false,"start_time":"2021-07-29T20:37:27.190318","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T11:38:39.506163Z","iopub.execute_input":"2021-08-11T11:38:39.506579Z","iopub.status.idle":"2021-08-11T11:38:39.522543Z","shell.execute_reply.started":"2021-08-11T11:38:39.506534Z","shell.execute_reply":"2021-08-11T11:38:39.521712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt=np.array(submission[\"MGMT_value\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:38:39.524458Z","iopub.execute_input":"2021-08-11T11:38:39.52486Z","iopub.status.idle":"2021-08-11T11:38:39.529727Z","shell.execute_reply.started":"2021-08-11T11:38:39.524823Z","shell.execute_reply":"2021-08-11T11:38:39.528696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(submission[\"MGMT_value\"])","metadata":{"papermill":{"duration":2.23551,"end_time":"2021-07-29T20:37:32.833316","exception":false,"start_time":"2021-07-29T20:37:30.597806","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-11T11:38:39.531456Z","iopub.execute_input":"2021-08-11T11:38:39.531885Z","iopub.status.idle":"2021-08-11T11:38:39.805456Z","shell.execute_reply.started":"2021-08-11T11:38:39.531852Z","shell.execute_reply":"2021-08-11T11:38:39.804654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":1.631031,"end_time":"2021-07-29T20:37:36.319842","exception":false,"start_time":"2021-07-29T20:37:34.688811","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom tensorflow import keras\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-08-11T11:38:39.806794Z","iopub.execute_input":"2021-08-11T11:38:39.807127Z","iopub.status.idle":"2021-08-11T11:38:39.815833Z","shell.execute_reply.started":"2021-08-11T11:38:39.807092Z","shell.execute_reply":"2021-08-11T11:38:39.814998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameters","metadata":{}},{"cell_type":"code","source":"IM_SIZE = 256","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:59:53.157985Z","iopub.execute_input":"2021-08-11T10:59:53.158518Z","iopub.status.idle":"2021-08-11T10:59:53.163019Z","shell.execute_reply.started":"2021-08-11T10:59:53.158477Z","shell.execute_reply":"2021-08-11T10:59:53.161729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = keras.models.load_model('../input/emodels/model (7).h5 (1)/model (7).h5')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:59:53.164535Z","iopub.execute_input":"2021-08-11T10:59:53.164969Z","iopub.status.idle":"2021-08-11T10:59:58.631454Z","shell.execute_reply.started":"2021-08-11T10:59:53.164933Z","shell.execute_reply":"2021-08-11T10:59:58.630525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:59:58.636382Z","iopub.execute_input":"2021-08-11T10:59:58.638467Z","iopub.status.idle":"2021-08-11T10:59:58.757606Z","shell.execute_reply.started":"2021-08-11T10:59:58.638425Z","shell.execute_reply":"2021-08-11T10:59:58.756776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some function","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mid_crop(img,c=25,c2=30):\n    c21=int(img.shape[0]//2)\n    c22=int(img.shape[1]//2)\n    return img[c22-c2:c22+c2,c21-c:c21+c]\ndef read_xray(path, voi_lut = False, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    #data = (data * 255).astype(np.uint8)\n        \n    return mid_crop(cv2.resize(data*255,(100,100)))\ndef pad_images(imgs,img_shape=(28,28)):\n    padded=np.zeros((imgs.shape[0],max([len(x) for x in imgs]+[356]),img_shape[0],img_shape[1]))\n    for i in range(imgs.shape[0]):\n        for j in range(len(imgs[i])):\n            try:\n                padded[i,j]=imgs[i][j]\n            except:\n                break\n    return padded[:,:356,...,np.newaxis]\ndef get_prediction_per_case(patient):\n    \n    path = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{patient}/FLAIR/'\n\n    list_subfolders_with_paths = [f for f in os.listdir(path)]\n    \n    prediction = []\n    \n    imagess=[]\n    \n    for images in list_subfolders_with_paths:\n        \n       \n        img = read_xray(path+images)\n        if np.max(img) > 0 and np.mean(img)>= 0.015:\n             \n             \n       \n             img=mid_crop(cv2.resize(img,(100,100)))\n        \n             img=cv2.resize(img,(50,50))\n             img=cv2.merge((img, img, img)) \n             imagess.append(img/255)\n    \n    #print(pad_images(np.array([imagess]),(28,28)).shape)\n  \n    \n    return float(np.mean(model.predict(np.array(imagess)), axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:59:58.76148Z","iopub.execute_input":"2021-08-11T10:59:58.763475Z","iopub.status.idle":"2021-08-11T10:59:58.782674Z","shell.execute_reply.started":"2021-08-11T10:59:58.763435Z","shell.execute_reply":"2021-08-11T10:59:58.781836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_prediction_per_case('00047')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:59:58.786647Z","iopub.execute_input":"2021-08-11T10:59:58.78917Z","iopub.status.idle":"2021-08-11T11:00:07.628731Z","shell.execute_reply.started":"2021-08-11T10:59:58.789131Z","shell.execute_reply":"2021-08-11T11:00:07.627827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv',dtype=\"string\")","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:00:07.63194Z","iopub.execute_input":"2021-08-11T11:00:07.632228Z","iopub.status.idle":"2021-08-11T11:00:07.644095Z","shell.execute_reply.started":"2021-08-11T11:00:07.632186Z","shell.execute_reply":"2021-08-11T11:00:07.643152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt = (mgmt+df['BraTS21ID'].apply(get_prediction_per_case))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:00:07.645651Z","iopub.execute_input":"2021-08-11T11:00:07.646049Z","iopub.status.idle":"2021-08-11T11:01:41.835445Z","shell.execute_reply.started":"2021-08-11T11:00:07.645972Z","shell.execute_reply":"2021-08-11T11:01:41.83451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt=np.array(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:41.838946Z","iopub.execute_input":"2021-08-11T11:01:41.839249Z","iopub.status.idle":"2021-08-11T11:01:41.845095Z","shell.execute_reply.started":"2021-08-11T11:01:41.839221Z","shell.execute_reply":"2021-08-11T11:01:41.844369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:41.850902Z","iopub.execute_input":"2021-08-11T11:01:41.851279Z","iopub.status.idle":"2021-08-11T11:01:41.860499Z","shell.execute_reply.started":"2021-08-11T11:01:41.851252Z","shell.execute_reply":"2021-08-11T11:01:41.859111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:41.863472Z","iopub.execute_input":"2021-08-11T11:01:41.863909Z","iopub.status.idle":"2021-08-11T11:01:42.066514Z","shell.execute_reply.started":"2021-08-11T11:01:41.863864Z","shell.execute_reply":"2021-08-11T11:01:42.06573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('../input/emodels/T1w - model.h5') ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:42.067806Z","iopub.execute_input":"2021-08-11T11:01:42.068153Z","iopub.status.idle":"2021-08-11T11:01:45.790591Z","shell.execute_reply.started":"2021-08-11T11:01:42.068116Z","shell.execute_reply":"2021-08-11T11:01:45.788244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mid_crop(img,c=25,c2=30):\n    c21=int(img.shape[0]//2)\n    c22=int(img.shape[1]//2)\n    return img[c22-c2:c22+c2,c21-c:c21+c]\ndef read_xray(path, voi_lut = False, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    #data = (data * 255).astype(np.uint8)\n        \n    return mid_crop(cv2.resize(data*255,(100,100)))\ndef pad_images(imgs,img_shape=(28,28)):\n    padded=np.zeros((imgs.shape[0],max([len(x) for x in imgs]+[356]),img_shape[0],img_shape[1]))\n    for i in range(imgs.shape[0]):\n        for j in range(len(imgs[i])):\n            try:\n                padded[i,j]=imgs[i][j]\n            except:\n                break\n    return padded[:,:356,...,np.newaxis]\ndef get_prediction_per_case(patient):\n    \n    path = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{patient}/T1w/'\n\n    list_subfolders_with_paths = [f for f in os.listdir(path)]\n    \n    prediction = []\n    \n    imagess=[]\n    \n    for images in list_subfolders_with_paths:\n        \n       \n        img = read_xray(path+images)\n        if np.max(img) > 0 and np.mean(img)>= 0.015:\n             \n             \n       \n             img=mid_crop(cv2.resize(img,(100,100)))\n        \n             img=cv2.resize(img,(50,50))\n             img=cv2.merge((img, img, img)) \n             imagess.append(img/255)\n    \n    #print(pad_images(np.array([imagess]),(28,28)).shape)\n  \n    \n    return float(np.mean(model.predict(np.array(imagess)), axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:45.796597Z","iopub.execute_input":"2021-08-11T11:01:45.79902Z","iopub.status.idle":"2021-08-11T11:01:45.823151Z","shell.execute_reply.started":"2021-08-11T11:01:45.798971Z","shell.execute_reply":"2021-08-11T11:01:45.822177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_prediction_per_case('00047')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:45.82702Z","iopub.execute_input":"2021-08-11T11:01:45.829398Z","iopub.status.idle":"2021-08-11T11:01:47.733099Z","shell.execute_reply.started":"2021-08-11T11:01:45.829356Z","shell.execute_reply":"2021-08-11T11:01:47.732139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt = (mgmt+df['BraTS21ID'].apply(get_prediction_per_case))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:01:47.734539Z","iopub.execute_input":"2021-08-11T11:01:47.734927Z","iopub.status.idle":"2021-08-11T11:03:20.23543Z","shell.execute_reply.started":"2021-08-11T11:01:47.734883Z","shell.execute_reply":"2021-08-11T11:03:20.234548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt=np.array(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:03:20.236716Z","iopub.execute_input":"2021-08-11T11:03:20.237116Z","iopub.status.idle":"2021-08-11T11:03:20.243063Z","shell.execute_reply.started":"2021-08-11T11:03:20.237076Z","shell.execute_reply":"2021-08-11T11:03:20.241147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('../input/emodels/T1wCE - model.h5') ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:03:20.2447Z","iopub.execute_input":"2021-08-11T11:03:20.245128Z","iopub.status.idle":"2021-08-11T11:03:23.749808Z","shell.execute_reply.started":"2021-08-11T11:03:20.245091Z","shell.execute_reply":"2021-08-11T11:03:23.748827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mid_crop(img,c=25,c2=30):\n    c21=int(img.shape[0]//2)\n    c22=int(img.shape[1]//2)\n    return img[c22-c2:c22+c2,c21-c:c21+c]\ndef read_xray(path, voi_lut = False, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    #data = (data * 255).astype(np.uint8)\n        \n    return mid_crop(cv2.resize(data*255,(100,100)))\ndef pad_images(imgs,img_shape=(28,28)):\n    padded=np.zeros((imgs.shape[0],max([len(x) for x in imgs]+[356]),img_shape[0],img_shape[1]))\n    for i in range(imgs.shape[0]):\n        for j in range(len(imgs[i])):\n            try:\n                padded[i,j]=imgs[i][j]\n            except:\n                break\n    return padded[:,:356,...,np.newaxis]\ndef get_prediction_per_case(patient):\n    \n    path = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{patient}/T1wCE/'\n\n    list_subfolders_with_paths = [f for f in os.listdir(path)]\n    \n    prediction = []\n    \n    imagess=[]\n    \n    for images in list_subfolders_with_paths:\n        \n       \n        img = read_xray(path+images)\n        if np.max(img) > 0 and np.mean(img)>= 0.015:\n             \n             \n       \n             img=mid_crop(cv2.resize(img,(100,100)))\n        \n             img=cv2.resize(img,(50,50))\n             img=cv2.merge((img, img, img)) \n             imagess.append(img/255)\n    \n    #print(pad_images(np.array([imagess]),(28,28)).shape)\n  \n    \n    return float(np.mean(model.predict(np.array(imagess)), axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:03:23.751877Z","iopub.execute_input":"2021-08-11T11:03:23.752257Z","iopub.status.idle":"2021-08-11T11:03:23.767482Z","shell.execute_reply.started":"2021-08-11T11:03:23.752216Z","shell.execute_reply":"2021-08-11T11:03:23.766452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_prediction_per_case('00047')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:03:23.769074Z","iopub.execute_input":"2021-08-11T11:03:23.769635Z","iopub.status.idle":"2021-08-11T11:03:26.343961Z","shell.execute_reply.started":"2021-08-11T11:03:23.769593Z","shell.execute_reply":"2021-08-11T11:03:26.343158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt = (mgmt+df['BraTS21ID'].apply(get_prediction_per_case))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:03:26.345267Z","iopub.execute_input":"2021-08-11T11:03:26.345615Z","iopub.status.idle":"2021-08-11T11:05:10.314245Z","shell.execute_reply.started":"2021-08-11T11:03:26.345576Z","shell.execute_reply":"2021-08-11T11:05:10.313411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt=np.array(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:05:10.315531Z","iopub.execute_input":"2021-08-11T11:05:10.315887Z","iopub.status.idle":"2021-08-11T11:05:10.322941Z","shell.execute_reply.started":"2021-08-11T11:05:10.315849Z","shell.execute_reply":"2021-08-11T11:05:10.322158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('../input/emodels/T2w - model.h5') ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:05:10.326607Z","iopub.execute_input":"2021-08-11T11:05:10.326949Z","iopub.status.idle":"2021-08-11T11:05:13.881684Z","shell.execute_reply.started":"2021-08-11T11:05:10.32692Z","shell.execute_reply":"2021-08-11T11:05:13.880735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mid_crop(img,c=25,c2=30):\n    c21=int(img.shape[0]//2)\n    c22=int(img.shape[1]//2)\n    return img[c22-c2:c22+c2,c21-c:c21+c]\ndef read_xray(path, voi_lut = False, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    #data = (data * 255).astype(np.uint8)\n        \n    return mid_crop(cv2.resize(data*255,(100,100)))\ndef pad_images(imgs,img_shape=(28,28)):\n    padded=np.zeros((imgs.shape[0],max([len(x) for x in imgs]+[356]),img_shape[0],img_shape[1]))\n    for i in range(imgs.shape[0]):\n        for j in range(len(imgs[i])):\n            try:\n                padded[i,j]=imgs[i][j]\n            except:\n                break\n    return padded[:,:356,...,np.newaxis]\ndef get_prediction_per_case(patient):\n    \n    path = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{patient}/T2w/'\n\n    list_subfolders_with_paths = [f for f in os.listdir(path)]\n    \n    prediction = []\n    \n    imagess=[]\n    \n    for images in list_subfolders_with_paths:\n        \n       \n        img = read_xray(path+images)\n        if np.max(img) > 0 and np.mean(img)>= 0.015:\n             \n             \n       \n             img=mid_crop(cv2.resize(img,(100,100)))\n        \n             img=cv2.resize(img,(50,50))\n             img=cv2.merge((img, img, img)) \n             imagess.append(img/255)\n    \n    #print(pad_images(np.array([imagess]),(28,28)).shape)\n  \n    \n    return float(np.mean(model.predict(np.array(imagess)), axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:05:13.883444Z","iopub.execute_input":"2021-08-11T11:05:13.883781Z","iopub.status.idle":"2021-08-11T11:05:13.896651Z","shell.execute_reply.started":"2021-08-11T11:05:13.883745Z","shell.execute_reply":"2021-08-11T11:05:13.895617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_prediction_per_case('00047')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:05:13.898217Z","iopub.execute_input":"2021-08-11T11:05:13.898805Z","iopub.status.idle":"2021-08-11T11:05:18.880053Z","shell.execute_reply.started":"2021-08-11T11:05:13.898766Z","shell.execute_reply":"2021-08-11T11:05:18.879181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmgmt = (mgmt+df['BraTS21ID'].apply(get_prediction_per_case))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:05:18.881598Z","iopub.execute_input":"2021-08-11T11:05:18.881996Z","iopub.status.idle":"2021-08-11T11:07:21.639153Z","shell.execute_reply.started":"2021-08-11T11:05:18.881954Z","shell.execute_reply":"2021-08-11T11:07:21.638269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt=np.array(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:07:21.64048Z","iopub.execute_input":"2021-08-11T11:07:21.640849Z","iopub.status.idle":"2021-08-11T11:07:21.646503Z","shell.execute_reply.started":"2021-08-11T11:07:21.64081Z","shell.execute_reply":"2021-08-11T11:07:21.644945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:07:21.648145Z","iopub.execute_input":"2021-08-11T11:07:21.64862Z","iopub.status.idle":"2021-08-11T11:07:21.937411Z","shell.execute_reply.started":"2021-08-11T11:07:21.648511Z","shell.execute_reply":"2021-08-11T11:07:21.936583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('../input/effect0-brain/Brain_flair_model_effect.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    #data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef get_prediction_per_case(patient):\n    \n    path = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{patient}/FLAIR/'\n\n    list_subfolders_with_paths = [f for f in os.listdir(path)]\n    \n    prediction = []\n    \n    for images in list_subfolders_with_paths:\n        \n            \n        img = read_xray(path+images)\n                       \n        if np.max(img) > 0 and np.mean(img)>= 0.015:\n                \n                \n            img =  cv2.resize(img,(IM_SIZE,IM_SIZE))\n            \n            img = cv2.merge((img,img,img))\n            img = tf.reshape(img, (-1, IM_SIZE, IM_SIZE, 3))\n            \n            pred = model.predict(img)\n            \n            prediction.append(pred)\n    \n    return np.mean(prediction,axis=0)[0][0]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:07:21.938752Z","iopub.execute_input":"2021-08-11T11:07:21.939089Z","iopub.status.idle":"2021-08-11T11:07:24.384685Z","shell.execute_reply.started":"2021-08-11T11:07:21.939052Z","shell.execute_reply":"2021-08-11T11:07:24.383803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_prediction_per_case('00047')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:07:24.386053Z","iopub.execute_input":"2021-08-11T11:07:24.386403Z","iopub.status.idle":"2021-08-11T11:07:34.67878Z","shell.execute_reply.started":"2021-08-11T11:07:24.386364Z","shell.execute_reply":"2021-08-11T11:07:34.677885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmgmt = (mgmt+df['BraTS21ID'].apply(get_prediction_per_case))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:07:34.680173Z","iopub.execute_input":"2021-08-11T11:07:34.680576Z","iopub.status.idle":"2021-08-11T11:15:14.605567Z","shell.execute_reply.started":"2021-08-11T11:07:34.680537Z","shell.execute_reply":"2021-08-11T11:15:14.604566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mgmt=np.array(mgmt)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:15:14.606948Z","iopub.execute_input":"2021-08-11T11:15:14.60735Z","iopub.status.idle":"2021-08-11T11:15:14.615231Z","shell.execute_reply.started":"2021-08-11T11:15:14.607308Z","shell.execute_reply":"2021-08-11T11:15:14.61425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['MGMT_value']=mgmt/(5+len(modelfiles))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:15:14.629538Z","iopub.execute_input":"2021-08-11T11:15:14.629883Z","iopub.status.idle":"2021-08-11T11:15:14.637294Z","shell.execute_reply.started":"2021-08-11T11:15:14.629846Z","shell.execute_reply":"2021-08-11T11:15:14.636416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.histplot([x[0:4] for x in submission['MGMT_value'].astype(str)])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:15:14.659157Z","iopub.execute_input":"2021-08-11T11:15:14.659535Z","iopub.status.idle":"2021-08-11T11:15:14.86792Z","shell.execute_reply.started":"2021-08-11T11:15:14.659497Z","shell.execute_reply":"2021-08-11T11:15:14.86697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(submission['MGMT_value'])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:15:14.869231Z","iopub.execute_input":"2021-08-11T11:15:14.869579Z","iopub.status.idle":"2021-08-11T11:15:15.067236Z","shell.execute_reply.started":"2021-08-11T11:15:14.869543Z","shell.execute_reply":"2021-08-11T11:15:15.066233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:15:15.068566Z","iopub.execute_input":"2021-08-11T11:15:15.068925Z","iopub.status.idle":"2021-08-11T11:15:15.083457Z","shell.execute_reply.started":"2021-08-11T11:15:15.068886Z","shell.execute_reply":"2021-08-11T11:15:15.082415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['MGMT_value'].to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T11:15:15.084851Z","iopub.execute_input":"2021-08-11T11:15:15.085242Z","iopub.status.idle":"2021-08-11T11:15:15.092845Z","shell.execute_reply.started":"2021-08-11T11:15:15.085181Z","shell.execute_reply":"2021-08-11T11:15:15.091733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}