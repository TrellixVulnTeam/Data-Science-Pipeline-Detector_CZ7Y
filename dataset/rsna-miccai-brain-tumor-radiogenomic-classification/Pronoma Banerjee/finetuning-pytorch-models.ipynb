{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview of the competition:\nhttps://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/overview","metadata":{}},{"cell_type":"markdown","source":"# Dataset\nThe dataset consists of 4 types of mpMRI scans: \n* Fluid Attenuated Inversion Recovery\n* T1-weighted pre-contrast (T1w)\n* T1-weighted post-contrast (T1Gd)\n* T2-weighted (T2)\n\nThe 'train' folder contains the training images. This is accompanied by 'train-labels.csv' file which file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation). The 'test' folder contains the test images. \n\nFurther details on the original dataset have been provided in the following **paper**:\nU.Baid, et al., “The RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor Segmentation and Radiogenomic Classification”, arXiv:2107.02314, 2021. https://arxiv.org/abs/2107.02314","metadata":{}},{"cell_type":"markdown","source":"# Task\n\nTo predict the MGMT value of each subject in the test dataset.","metadata":{}},{"cell_type":"markdown","source":"Here I have attempted to fine tune the pre-trained Resnet, Alexnet, Densenet and all versions of VGG networks on the dataset obtained from the RSNA-MICCAI Brain Tumor Radiogenic Classification Challenge.","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport pydicom\nimport numpy as np\nimport shutil\nfrom PIL import Image\nimport scipy\nimport torch \nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models , datasets\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\nimport copy\n\nprint(\"All modules have been imported\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the train folder into subfolders\nHere I separated the subjects having the MGMT biomarker (category 1) from the ones who don't have it (category 0) within the training folder. ","metadata":{}},{"cell_type":"code","source":"!mkdir \"data\"\n!mkdir \"data/0\"\n!mkdir \"data/1\"\nlabels = pd.read_csv(\"../input/png-dataset-for-rsna-mgmt-detection/png_data/png_voxel_converted_ds/train_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:36:25.056103Z","iopub.execute_input":"2021-09-23T16:36:25.056374Z","iopub.status.idle":"2021-09-23T16:36:27.025495Z","shell.execute_reply.started":"2021-09-23T16:36:25.056346Z","shell.execute_reply":"2021-09-23T16:36:27.024615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New sorted folder with the data","metadata":{}},{"cell_type":"code","source":"main_folder_path = \"../input/png-dataset-for-rsna-mgmt-detection/png_data/png_voxel_converted_ds\"\nmain_train_folder_path = os.path.join(main_folder_path  , \"train\")\nfor subject in tqdm(os.listdir(main_train_folder_path)):\n    subject_folder = os.path.join(main_train_folder_path , subject)\n    for mri_type in os.listdir(subject_folder):\n        mri_type_folder = os.path.join(subject_folder , mri_type)\n        for mri_image in os.listdir(mri_type_folder):\n            original_image_path = os.path.join(mri_type_folder , mri_image)\n            mri_image = subject +\"_\"+ mri_type +\"_\"+ mri_image\n            subject_num = int(subject)\n            idx = np.where(labels['BraTS21ID'] == subject_num)[0][0]\n            label = str(labels.loc[idx , 'MGMT_value'])\n            new_image_folder_path =os.path.join(\"data\" , label)\n            new_image_path = os.path.join(new_image_folder_path , mri_image)\n            if (Image.open(original_image_path).getcolors()==1): continue\n            shutil.copy(original_image_path , new_image_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:36:30.993871Z","iopub.execute_input":"2021-09-23T16:36:30.994575Z","iopub.status.idle":"2021-09-23T16:43:16.389116Z","shell.execute_reply.started":"2021-09-23T16:36:30.994533Z","shell.execute_reply":"2021-09-23T16:43:16.388467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Images with label 0 = \" , len(os.listdir(\"data/0\")) , \"Images with label 1 = \" , len(os.listdir(\"data/1\")))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:46:47.594579Z","iopub.execute_input":"2021-09-23T16:46:47.595145Z","iopub.status.idle":"2021-09-23T16:46:47.649131Z","shell.execute_reply.started":"2021-09-23T16:46:47.595106Z","shell.execute_reply":"2021-09-23T16:46:47.648368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-validation-test split","metadata":{}},{"cell_type":"code","source":"!mkdir \"data/TRAIN\"\n!mkdir \"data/TRAIN/1\"\n!mkdir \"data/TRAIN/0\"\n!mkdir \"data/VAL\"\n!mkdir \"data/VAL/0\"\n!mkdir \"data/VAL/1\"\n!mkdir \"data/TEST\"\n!mkdir \"data/TEST/0\"\n!mkdir \"data/TEST/1\"","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:46:49.919496Z","iopub.execute_input":"2021-09-23T16:46:49.922084Z","iopub.status.idle":"2021-09-23T16:46:55.850448Z","shell.execute_reply.started":"2021-09-23T16:46:49.922037Z","shell.execute_reply":"2021-09-23T16:46:55.849517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = \"./data\"\n\n#split the data into train/test/val\nfor CLASS in tqdm([\"0\" , \"1\"]):\n    IMG_NUM = len(os.listdir(IMG_PATH +\"/\"+ CLASS))\n    for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH +\"/\"+ CLASS)):\n            img = IMG_PATH+ '/' +  CLASS + '/' + FILE_NAME\n            if n <4000 :\n                shutil.copy(img, 'data/TEST/' + str(CLASS) + '/' + FILE_NAME)\n            elif n < 0.9*IMG_NUM:\n                shutil.copy(img, 'data/TRAIN/'+ str(CLASS) + '/' + FILE_NAME)\n            else:\n                shutil.copy(img, 'data/VAL/'+ str(CLASS) + '/' + FILE_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:47:02.243519Z","iopub.execute_input":"2021-09-23T16:47:02.243838Z","iopub.status.idle":"2021-09-23T16:47:08.954253Z","shell.execute_reply.started":"2021-09-23T16:47:02.243804Z","shell.execute_reply":"2021-09-23T16:47:08.949799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir(\"data/TRAIN/1\")))\nprint(len(os.listdir(\"data/TRAIN/0\")))\nprint(len(os.listdir(\"data/VAL/1\")))\nprint(len(os.listdir(\"data/VAL/0\")))\nprint(len(os.listdir(\"data/TEST/1\"))) \nprint(len(os.listdir(\"data/TEST/0\")))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:47:12.112211Z","iopub.execute_input":"2021-09-23T16:47:12.112827Z","iopub.status.idle":"2021-09-23T16:47:12.170193Z","shell.execute_reply.started":"2021-09-23T16:47:12.112788Z","shell.execute_reply":"2021-09-23T16:47:12.169327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation and normalization","metadata":{}},{"cell_type":"code","source":"# Data augmentation and normalization for training\n# Just normalization for validation and testing\ndata_transforms = {\n    'TRAIN': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'VAL': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'TEST': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['TRAIN', 'VAL', 'TEST']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['TRAIN', 'VAL', 'TEST']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['TRAIN', 'VAL', 'TEST']}\nclass_names = image_datasets['TRAIN'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:47:14.842211Z","iopub.execute_input":"2021-09-23T16:47:14.842789Z","iopub.status.idle":"2021-09-23T16:47:15.359519Z","shell.execute_reply.started":"2021-09-23T16:47:14.842748Z","shell.execute_reply":"2021-09-23T16:47:15.358548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Viewing training images","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['TRAIN']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:47:19.868956Z","iopub.execute_input":"2021-09-23T16:47:19.869539Z","iopub.status.idle":"2021-09-23T16:47:21.571381Z","shell.execute_reply.started":"2021-09-23T16:47:19.8695Z","shell.execute_reply":"2021-09-23T16:47:21.570651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function for Training model","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['TRAIN', 'VAL']:\n            if phase == 'TRAIN':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'TRAIN'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    if is_inception and phase == 'TRAIN':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'TRAIN':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'TRAIN':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'VAL' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:47:21.574592Z","iopub.execute_input":"2021-09-23T16:47:21.574817Z","iopub.status.idle":"2021-09-23T16:47:21.588539Z","shell.execute_reply.started":"2021-09-23T16:47:21.574791Z","shell.execute_reply":"2021-09-23T16:47:21.587872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning Resnet18","metadata":{}},{"cell_type":"code","source":"#RESNET\nresnet = models.resnet18(pretrained=True)\nnum_ftrs = resnet.fc.in_features\n\nresnet.fc = nn.Linear(num_ftrs, 2)\n\nresnet = resnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(resnet.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(resnet, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T11:45:37.1125Z","iopub.execute_input":"2021-09-22T11:45:37.112811Z","iopub.status.idle":"2021-09-22T11:45:50.08737Z","shell.execute_reply.started":"2021-09-22T11:45:37.112771Z","shell.execute_reply":"2021-09-22T11:45:50.085512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning Alexnet","metadata":{}},{"cell_type":"code","source":"#ALEXNET\nalexnet = models.alexnet(pretrained=True)\nnum_ftrs = alexnet.classifier[6].in_features\n\nalexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n\nalexnet = alexnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(alexnet.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(alexnet, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:52:58.40083Z","iopub.execute_input":"2021-09-20T14:52:58.401108Z","iopub.status.idle":"2021-09-20T14:52:59.343363Z","shell.execute_reply.started":"2021-09-20T14:52:58.40108Z","shell.execute_reply":"2021-09-20T14:52:59.342654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finetuning Densenet121","metadata":{}},{"cell_type":"code","source":"#DENSENET\ndensenet = models.densenet121(pretrained=True)\nnum_ftrs = densenet.classifier.in_features\n\ndensenet.classifier = nn.Linear(num_ftrs,2)\n\ndensenet = densenet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(densenet.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(densenet, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T11:53:37.490821Z","iopub.execute_input":"2021-09-21T11:53:37.491087Z","iopub.status.idle":"2021-09-21T11:53:37.752498Z","shell.execute_reply.started":"2021-09-21T11:53:37.491061Z","shell.execute_reply":"2021-09-21T11:53:37.751821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning VGGnet","metadata":{}},{"cell_type":"markdown","source":"Now we will finetune all the versions of VGG models.","metadata":{}},{"cell_type":"code","source":"#VGG11\nvgg11 = models.vgg11(pretrained=True)\nnum_ftrs = vgg11.classifier[6].in_features\n\nvgg11.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg11 = vgg11.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg11.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg11, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:42:58.183974Z","iopub.execute_input":"2021-09-23T06:42:58.184343Z","iopub.status.idle":"2021-09-23T06:43:39.680694Z","shell.execute_reply.started":"2021-09-23T06:42:58.184314Z","shell.execute_reply":"2021-09-23T06:43:39.677346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG11_bn\nvgg11_bn = models.vgg11_bn(pretrained=True)\nnum_ftrs = vgg11_bn.classifier[6].in_features\n\nvgg11_bn.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg11_bn = vgg11_bn.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg11_bn.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg11_bn, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG13\nvgg13 = models.vgg13(pretrained=True)\nnum_ftrs = vgg13.classifier[6].in_features\n\nvgg13.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg13 = vgg13.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg13.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg13, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:45:45.972752Z","iopub.execute_input":"2021-09-23T06:45:45.973493Z","iopub.status.idle":"2021-09-23T07:02:20.005204Z","shell.execute_reply.started":"2021-09-23T06:45:45.97345Z","shell.execute_reply":"2021-09-23T07:02:20.004224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG13_bn\nvgg13_bn = models.vgg13_bn(pretrained=True)\nnum_ftrs = vgg13_bn.classifier[6].in_features\n\nvgg13_bn.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg13_bn = vgg13_bn.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg13_bn.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg13_bn, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:04:12.807149Z","iopub.execute_input":"2021-09-23T07:04:12.807673Z","iopub.status.idle":"2021-09-23T07:04:52.381292Z","shell.execute_reply.started":"2021-09-23T07:04:12.80764Z","shell.execute_reply":"2021-09-23T07:04:52.379027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG16\nvgg16 = models.vgg16(pretrained=True)\nnum_ftrs = vgg16.classifier[6].in_features\n\nvgg16.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg16 = vgg16.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg16.parameters(), lr=0.1)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nmodel = train_model(vgg16, criterion, optimizer, step_lr_scheduler, num_epochs=15, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:48:31.966538Z","iopub.execute_input":"2021-09-23T17:48:31.967496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG16_bn\nvgg16_bn = models.vgg16_bn(pretrained=True)\nnum_ftrs = vgg16_bn.classifier[6].in_features\n\nvgg16_bn.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg16_bn = vgg16_bn.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg16_bn.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg16_bn, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG19\nvgg19 = models.vgg19(pretrained=True)\nnum_ftrs = vgg19.classifier[6].in_features\n\nvgg19.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg19 = vgg19.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg19.parameters(), lr=0.1)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg19, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:18:40.378798Z","iopub.execute_input":"2021-09-23T17:18:40.379067Z","iopub.status.idle":"2021-09-23T17:41:14.10802Z","shell.execute_reply.started":"2021-09-23T17:18:40.379037Z","shell.execute_reply":"2021-09-23T17:41:14.107145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG19_bn\nvgg19_bn = models.vgg19_bn(pretrained=True)\nnum_ftrs = vgg19_bn.classifier[6].in_features\n\nvgg19_bn.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg19_bn = vgg19_bn.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg19_bn.parameters(), lr=0.001)\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg19_bn, criterion, optimizer, step_lr_scheduler, num_epochs=1, is_inception=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samp_subm = pd.read_csv(\"../input/png-dataset-for-rsna-mgmt-detection/png_data/png_voxel_converted_ds/sample_submission.csv\")\nprint('Samples test:', len(samp_subm))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samp_subm.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samp_subm.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I have given an outline on how to finetune some pytorch models. Please reach out if there is any doubt or feel free to comment if anything seems incorrect. Thanks!","metadata":{}}]}