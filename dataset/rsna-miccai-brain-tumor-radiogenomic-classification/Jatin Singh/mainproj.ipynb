{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"package_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\nimport sys \nsys.path.append(package_path)\n\nimport os\nimport glob\nimport time\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom torch.nn import functional as F\n\nimport efficientnet_pytorch\n\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:11.017473Z","iopub.execute_input":"2022-02-02T08:26:11.01802Z","iopub.status.idle":"2022-02-02T08:26:12.951482Z","shell.execute_reply.started":"2022-02-02T08:26:11.017928Z","shell.execute_reply":"2022-02-02T08:26:12.950085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nseed = 123\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed)\n\nclass X3D:\n    XS=0\n    S=1\n    M=2\n    L=3\n    \nx3d_config = {\n    'input_clip_length': [4, 13, 16, 16],\n    'depth_factor': [2.2, 2.2, 2.2, 5.0],\n    'width_factor': [1, 1, 1, 2.9]\n}\n\nclass CFG:\n    img_size = 256\n    n_frames = 10\n    \n    cnn_features = 256\n    lstm_hidden = 32\n    \n    n_fold = 5\n    n_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:14.160619Z","iopub.execute_input":"2022-02-02T08:26:14.16117Z","iopub.status.idle":"2022-02-02T08:26:14.212778Z","shell.execute_reply.started":"2022-02-02T08:26:14.161131Z","shell.execute_reply":"2022-02-02T08:26:14.21196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.map = nn.Conv2d(in_channels=4, out_channels=3, kernel_size=1)\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n#         checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\")\n#         self.net.load_state_dict(checkpoint)\n        \n        n_features = self.net._fc.in_features\n        \n#         print(n_features)\n        \n        self.net._fc = nn.Linear(in_features=n_features, out_features=CFG.cnn_features, bias=True)\n    \n    def forward(self, x):\n        x = F.relu(self.map(x))\n        out = self.net(x)\n        return out\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.cnn = CNN()\n        self.rnn = nn.LSTM(CFG.cnn_features, CFG.lstm_hidden, 2, batch_first=True)\n        self.fc = nn.Linear(CFG.lstm_hidden, 1, bias=True)\n\n    def forward(self, x):\n        # x shape: BxTxCxHxW\n        batch_size, timesteps, C, H, W = x.size()\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.cnn(c_in)\n        r_in = c_out.view(batch_size, timesteps, -1)\n        output, (hn, cn) = self.rnn(r_in)\n        \n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:14.665101Z","iopub.execute_input":"2022-02-02T08:26:14.665832Z","iopub.status.idle":"2022-02-02T08:26:14.685826Z","shell.execute_reply.started":"2022-02-02T08:26:14.665772Z","shell.execute_reply":"2022-02-02T08:26:14.684679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n        \n    data = np.float32(cv2.resize(data, (CFG.img_size, CFG.img_size)))\n    return torch.tensor(data)\n\n# def load_dicom_line(path):\n#     t_paths = sorted(\n#         glob.glob(os.path.join(path, \"*\")), \n#         key=lambda x: int(x[:-4].split(\"-\")[-1]),\n#     )\n#     images = []\n#     for filename in t_paths:\n#         data = load_dicom(filename)\n#         if data.max() == 0:\n#             continue\n#         images.append(data)\n        \n#     return images\n\n# def load_image(path):\n#     image = cv2.imread(path, 0)\n#     if image is None:\n#         return np.zeros((CFG.img_size, CFG.img_size))\n    \n#     image = cv2.resize(image, (CFG.img_size, CFG.img_size)) / 255\n#     return torch.tensor(image)\n\n# def get_valid_frames(t_paths):\n#     res = []\n#     for path in t_paths:\n#         img = load_dicom(path)\n#         if img.view(-1).mean(0) != 0:\n#             res.append(path)\n#     return res\n    \n\ndef uniform_temporal_subsample(x, num_samples):\n    '''\n        Moddified from https://github.com/facebookresearch/pytorchvideo/blob/d7874f788bc00a7badfb4310a912f6e531ffd6d3/pytorchvideo/transforms/functional.py#L19\n        Args:\n            x: input list\n            num_samples: The number of equispaced samples to be selected\n        Returns:\n            Output list     \n    '''\n    t = len(x)\n    indices = torch.linspace(0, t - 1, num_samples)\n    indices = torch.clamp(indices, 0, t - 1).long()\n    return [x[i] for i in indices]","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:15.24818Z","iopub.execute_input":"2022-02-02T08:26:15.24846Z","iopub.status.idle":"2022-02-02T08:26:15.257117Z","shell.execute_reply.started":"2022-02-02T08:26:15.248423Z","shell.execute_reply":"2022-02-02T08:26:15.256374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataRetriever(Dataset):\n    def __init__(self, paths, transform=None):\n        self.paths = paths\n        self.transform = transform\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def read_video(self, vid_paths):\n        video = [load_dicom(path) for path in vid_paths]\n        if len(video)==0:\n            video = torch.zeros(CFG.n_frames, CFG.img_size, CFG.img_size)\n        else:\n            video = torch.stack(video) # T * C * H * W\n#         video = torch.transpose(video, 0, 1) # C * T * H * W\n        return video\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{str(_id).zfill(5)}/\"\n        channels = []\n        for t in [\"FLAIR\",\"T1w\", \"T1wCE\", \"T2w\"]:\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n            num_samples = CFG.n_frames\n#             t_paths = get_valid_frames(t_paths)\n            if len(t_paths) < num_samples:\n                in_frames_path = t_paths\n            else:\n                in_frames_path = uniform_temporal_subsample(t_paths, num_samples)\n            \n            channel = self.read_video(in_frames_path)\n            if channel.shape[0] == 0:\n                print(\"1 channel empty\")\n                channel = torch.zeros(num_samples, CFG.img_size, CFG.img_size)\n            channels.append(channel)\n        \n        channels = torch.stack(channels).transpose(0,1)\n        return {\"X\": channels.float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:15.648143Z","iopub.execute_input":"2022-02-02T08:26:15.648632Z","iopub.status.idle":"2022-02-02T08:26:15.659661Z","shell.execute_reply.started":"2022-02-02T08:26:15.648596Z","shell.execute_reply":"2022-02-02T08:26:15.65879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ndf.head(10)\n# df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:15.947308Z","iopub.execute_input":"2022-02-02T08:26:15.947743Z","iopub.status.idle":"2022-02-02T08:26:15.973244Z","shell.execute_reply.started":"2022-02-02T08:26:15.947708Z","shell.execute_reply":"2022-02-02T08:26:15.9726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(1, CFG.n_fold+1):\n    model = Model()\n    model.to(device)\n    checkpoint = torch.load(f\"../input/rnsa21-best-weights/best-model-{i}.pth\")\n#     print(checkpoint[\"model_state_dict\"])\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:16.258886Z","iopub.execute_input":"2022-02-02T08:26:16.259121Z","iopub.status.idle":"2022-02-02T08:26:26.125089Z","shell.execute_reply.started":"2022-02-02T08:26:16.259095Z","shell.execute_reply":"2022-02-02T08:26:26.123958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\ntest_data_retriever = TestDataRetriever(\n    submission[\"BraTS21ID\"].values # ids in test data\n)\nprint(test_data_retriever.read_video)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=4,\n    shuffle=False,\n    num_workers=8,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:26.129689Z","iopub.execute_input":"2022-02-02T08:26:26.129916Z","iopub.status.idle":"2022-02-02T08:26:26.159748Z","shell.execute_reply.started":"2022-02-02T08:26:26.129887Z","shell.execute_reply":"2022-02-02T08:26:26.156474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_data_retriever))\nprint(test_data_retriever[85]['X'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:26.161041Z","iopub.execute_input":"2022-02-02T08:26:26.161353Z","iopub.status.idle":"2022-02-02T08:26:26.810677Z","shell.execute_reply.started":"2022-02-02T08:26:26.161315Z","shell.execute_reply":"2022-02-02T08:26:26.809027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader.batch_size\nlen(test_loader) # no. of batches","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:26.8127Z","iopub.execute_input":"2022-02-02T08:26:26.812945Z","iopub.status.idle":"2022-02-02T08:26:26.819096Z","shell.execute_reply.started":"2022-02-02T08:26:26.81291Z","shell.execute_reply":"2022-02-02T08:26:26.818199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        print(batch[\"X\"].shape)\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n#             print(tmp_pred)\n            tmp_pred += tmp_res\n            \n        tmp_pred = tmp_pred/len(models)\n        y_pred.extend(tmp_pred)\n#         print(len(y_pred))\n        ids.extend(batch[\"id\"].numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:26.820676Z","iopub.execute_input":"2022-02-02T08:26:26.821049Z","iopub.status.idle":"2022-02-02T08:26:46.232856Z","shell.execute_reply.started":"2022-02-02T08:26:26.821012Z","shell.execute_reply":"2022-02-02T08:26:46.231996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:46.234978Z","iopub.execute_input":"2022-02-02T08:26:46.235283Z","iopub.status.idle":"2022-02-02T08:26:46.24045Z","shell.execute_reply.started":"2022-02-02T08:26:46.235246Z","shell.execute_reply":"2022-02-02T08:26:46.239781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:46.241724Z","iopub.execute_input":"2022-02-02T08:26:46.24222Z","iopub.status.idle":"2022-02-02T08:26:46.26005Z","shell.execute_reply.started":"2022-02-02T08:26:46.242182Z","shell.execute_reply":"2022-02-02T08:26:46.259096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model2 Fire Baba","metadata":{"execution":{"iopub.status.busy":"2022-01-25T12:03:56.753412Z","iopub.execute_input":"2022-01-25T12:03:56.754121Z","iopub.status.idle":"2022-01-25T12:03:56.818898Z","shell.execute_reply.started":"2022-01-25T12:03:56.754083Z","shell.execute_reply":"2022-01-25T12:03:56.81747Z"}}},{"cell_type":"code","source":"pip install '../input/rsna-monai-packages/monai-0.6.0-202107081903-py3-none-any.whl'","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:26:55.192722Z","iopub.execute_input":"2022-02-02T08:26:55.19323Z","iopub.status.idle":"2022-02-02T08:27:23.134988Z","shell.execute_reply.started":"2022-02-02T08:26:55.193192Z","shell.execute_reply":"2022-02-02T08:27:23.133918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:23.136998Z","iopub.execute_input":"2022-02-02T08:27:23.137359Z","iopub.status.idle":"2022-02-02T08:27:23.916799Z","shell.execute_reply.started":"2022-02-02T08:27:23.137318Z","shell.execute_reply":"2022-02-02T08:27:23.916083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import roc_auc_score\nfrom torch.optim import lr_scheduler\nfrom tqdm import tqdm\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:23.91808Z","iopub.execute_input":"2022-02-02T08:27:23.918354Z","iopub.status.idle":"2022-02-02T08:27:25.33365Z","shell.execute_reply.started":"2022-02-02T08:27:23.918319Z","shell.execute_reply":"2022-02-02T08:27:25.332597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES_3D = 64\nTRAINING_BATCH_SIZE = 8\nTEST_BATCH_SIZE = 8\nIMAGE_SIZE = 256\nN_EPOCHS = 15\ndo_valid = True\nn_workers = 4\ntype_ = \"T1wCE\"","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:25.336104Z","iopub.execute_input":"2022-02-02T08:27:25.336366Z","iopub.status.idle":"2022-02-02T08:27:25.342375Z","shell.execute_reply.started":"2022-02-02T08:27:25.336329Z","shell.execute_reply":"2022-02-02T08:27:25.34045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n\n    if rotate > 0:\n        rot_choices = [\n            0,\n            cv2.ROTATE_90_CLOCKWISE,\n            cv2.ROTATE_90_COUNTERCLOCKWISE,\n            cv2.ROTATE_180,\n        ]\n        data = cv2.rotate(data, rot_choices[rotate])\n\n    data = cv2.resize(data, (img_size, img_size))\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:25.343909Z","iopub.execute_input":"2022-02-02T08:27:25.344171Z","iopub.status.idle":"2022-02-02T08:27:25.354146Z","shell.execute_reply.started":"2022-02-02T08:27:25.344135Z","shell.execute_reply":"2022-02-02T08:27:25.353354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nimport cv2\nfrom torch.utils.data import Dataset\n\n\nclass BrainRSNADataset(Dataset):\n    def __init__(\n        self, data, transform=None, target=\"MGMT_value\", mri_type=\"FLAIR\", is_train=True\n    ):\n        self.target = target\n        self.data = data\n        self.type = mri_type\n\n        self.transform = transform\n        self.is_train = is_train\n        self.folder = \"train\" if self.is_train else \"test\"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        row = self.data.loc[index]\n        case_id = int(row.BraTS21ID)\n        target = int(row[self.target])\n        _3d_images = self.load_dicom_images_3d(case_id)\n        _3d_images = torch.tensor(_3d_images).float()\n        if self.is_train:\n            return {\"image\": _3d_images, \"target\": target}\n        else:\n            return {\"image\": _3d_images, \"case_id\": case_id}\n\n    def load_dicom_images_3d(\n        self,\n        case_id,\n        num_imgs=NUM_IMAGES_3D,\n        img_size=IMAGE_SIZE,\n        rotate=0,\n    ):\n        case_id = str(case_id).zfill(5)\n\n        path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/{self.folder}/{case_id}/{self.type}/*.dcm\"\n#         path = f\"../input/brain-tumor-test/test1/test1/{case_id}/{self.type}/*.dcm\"\n        \n        files = sorted(\n            glob.glob(path),\n            key=lambda var: [\n                int(x) if x.isdigit() else x for x in re.findall(r\"[^0-9]|[0-9]+\", var)\n            ],\n        )\n\n        middle = len(files) // 2\n        num_imgs2 = num_imgs // 2\n        p1 = max(0, middle - num_imgs2)\n        p2 = min(len(files), middle + num_imgs2)\n        image_stack = [load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]\n        \n        img3d = np.stack(image_stack).T\n        if img3d.shape[-1] < num_imgs:\n            n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n            img3d = np.concatenate((img3d, n_zero), axis=-1)\n#         print(img3d.shape)\n        if np.min(img3d) < np.max(img3d):\n            img3d = img3d - np.min(img3d)\n            img3d = img3d / np.max(img3d)\n\n        return np.expand_dims(img3d, 0)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:25.355972Z","iopub.execute_input":"2022-02-02T08:27:25.356479Z","iopub.status.idle":"2022-02-02T08:27:25.37212Z","shell.execute_reply.started":"2022-02-02T08:27:25.356444Z","shell.execute_reply":"2022-02-02T08:27:25.371318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ../input/","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:25.375526Z","iopub.execute_input":"2022-02-02T08:27:25.377167Z","iopub.status.idle":"2022-02-02T08:27:26.104031Z","shell.execute_reply.started":"2022-02-02T08:27:25.377137Z","shell.execute_reply":"2022-02-02T08:27:26.103021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import monai\n\n# model \nmodel = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\ndevice = torch.device(\"cuda\")\nmodel.to(device);\nall_weights = os.listdir(\"../input/resnet10rsna\")\nfold_files = [f for f in all_weights if type_ in f]\n# print(np.array(fold_files).shape)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:26.105846Z","iopub.execute_input":"2022-02-02T08:27:26.106147Z","iopub.status.idle":"2022-02-02T08:27:28.318503Z","shell.execute_reply.started":"2022-02-02T08:27:26.106107Z","shell.execute_reply":"2022-02-02T08:27:28.317704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_files","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:28.320048Z","iopub.execute_input":"2022-02-02T08:27:28.320294Z","iopub.status.idle":"2022-02-02T08:27:28.325869Z","shell.execute_reply.started":"2022-02-02T08:27:28.320258Z","shell.execute_reply":"2022-02-02T08:27:28.324924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:27:28.329159Z","iopub.execute_input":"2022-02-02T08:27:28.32965Z","iopub.status.idle":"2022-02-02T08:27:28.339033Z","shell.execute_reply.started":"2022-02-02T08:27:28.329615Z","shell.execute_reply":"2022-02-02T08:27:28.338381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tta_true_labels = []\ntta_preds = []\ntest_dataset = BrainRSNADataset(data=sample, mri_type=type_, is_train=False)\ntest_dl = torch.utils.data.DataLoader(\n        test_dataset, batch_size=8, shuffle=False, num_workers=4\n    )\n\npreds_f = np.zeros(len(sample))\nfor fold in range(5):\n    image_ids = []\n    model.load_state_dict(torch.load(f\"../input/resnet10rsna/{fold_files[fold]}\"))\n    preds = []\n    epoch_iterator_test = tqdm(test_dl)\n    with torch.no_grad():\n        for  step, batch in enumerate(epoch_iterator_test):\n            model.eval()\n            images = batch[\"image\"].to(device)\n            print(batch[\"image\"].shape)\n            outputs = model(images)\n            preds.append(outputs.sigmoid().detach().cpu().numpy())\n            image_ids.append(batch[\"case_id\"].detach().cpu().numpy())\n    \n\n    preds_f += np.vstack(preds).T[0]/5\n\n    ids_f = np.hstack(image_ids)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:28:18.477104Z","iopub.execute_input":"2022-02-02T08:28:18.47738Z","iopub.status.idle":"2022-02-02T08:30:20.312124Z","shell.execute_reply.started":"2022-02-02T08:28:18.477349Z","shell.execute_reply":"2022-02-02T08:30:20.311276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(np.array(test_dataset).shape)\ntest_dataset[40]['image'].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.31456Z","iopub.execute_input":"2022-02-02T08:30:20.314879Z","iopub.status.idle":"2022-02-02T08:30:20.58391Z","shell.execute_reply.started":"2022-02-02T08:30:20.314835Z","shell.execute_reply":"2022-02-02T08:30:20.583219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample[\"BraTS21ID\"] = ids_f\nsample[\"MGMT_value\"] = preds_f","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.58505Z","iopub.execute_input":"2022-02-02T08:30:20.585299Z","iopub.status.idle":"2022-02-02T08:30:20.592655Z","shell.execute_reply.started":"2022-02-02T08:30:20.585263Z","shell.execute_reply":"2022-02-02T08:30:20.59183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = sample.sort_values(by=\"BraTS21ID\").reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.595327Z","iopub.execute_input":"2022-02-02T08:30:20.595717Z","iopub.status.idle":"2022-02-02T08:30:20.602597Z","shell.execute_reply.started":"2022-02-02T08:30:20.595678Z","shell.execute_reply":"2022-02-02T08:30:20.601866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission2.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.603845Z","iopub.execute_input":"2022-02-02T08:30:20.605353Z","iopub.status.idle":"2022-02-02T08:30:20.610257Z","shell.execute_reply.started":"2022-02-02T08:30:20.605321Z","shell.execute_reply":"2022-02-02T08:30:20.608272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.61167Z","iopub.execute_input":"2022-02-02T08:30:20.61231Z","iopub.status.idle":"2022-02-02T08:30:20.627286Z","shell.execute_reply.started":"2022-02-02T08:30:20.612275Z","shell.execute_reply":"2022-02-02T08:30:20.626511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model3 random","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \n# TRAIN_PATH = '../input/rsna-miccai-png/train'\nTEST_PATH = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test'","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.628752Z","iopub.execute_input":"2022-02-02T08:30:20.629471Z","iopub.status.idle":"2022-02-02T08:30:20.63664Z","shell.execute_reply.started":"2022-02-02T08:30:20.629407Z","shell.execute_reply":"2022-02-02T08:30:20.635977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='efficientnet_b3'\n    size=512\n    batch_size=4\n    seed=42\n    target_size=2\n    target_col='MGMT_value'\n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    inference=True","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.638307Z","iopub.execute_input":"2022-02-02T08:30:20.638742Z","iopub.status.idle":"2022-02-02T08:30:20.646226Z","shell.execute_reply.started":"2022-02-02T08:30:20.638702Z","shell.execute_reply":"2022-02-02T08:30:20.645532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Imports\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:20.647125Z","iopub.execute_input":"2022-02-02T08:30:20.647315Z","iopub.status.idle":"2022-02-02T08:30:22.724236Z","shell.execute_reply.started":"2022-02-02T08:30:20.647292Z","shell.execute_reply":"2022-02-02T08:30:22.723391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.728894Z","iopub.execute_input":"2022-02-02T08:30:22.729107Z","iopub.status.idle":"2022-02-02T08:30:22.736086Z","shell.execute_reply.started":"2022-02-02T08:30:22.729078Z","shell.execute_reply":"2022-02-02T08:30:22.735357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test')\n# print(np.array(test).shape)\ntest = pd.DataFrame({'BraTS21ID' : test})\n# print(test)\ntest['BraTS21ID'] = test['BraTS21ID'].astype(int)\ntest","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.737425Z","iopub.execute_input":"2022-02-02T08:30:22.737842Z","iopub.status.idle":"2022-02-02T08:30:22.76376Z","shell.execute_reply.started":"2022-02-02T08:30:22.737804Z","shell.execute_reply":"2022-02-02T08:30:22.763118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['BraTS21ID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        root = f'{TEST_PATH}/{str(self.file_names[idx]).zfill(5)}/'\n        com = []\n        for typ in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n            paths = os.listdir(root + typ)\n            rnd = random.sample(paths, min(10, len(paths)))\n            typ_imgs = []\n            for f in rnd:\n                file_path = f'{root}{typ}/{f}'\n                dicom = pydicom.read_file(file_path)\n                data = apply_voi_lut(dicom.pixel_array, dicom)\n                if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n                    data = np.amax(data) - data\n                data = data - np.min(data)\n                data = data / np.max(data)\n                image = (data * 255).astype(np.uint8)\n                typ_imgs.append(cv2.resize(image, (CFG.size, CFG.size)))\n            com.append(np.mean(typ_imgs, axis = 0))\n        image = np.array(com).transpose((1,2,0)) / 255\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            image = image.float()\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.76525Z","iopub.execute_input":"2022-02-02T08:30:22.765717Z","iopub.status.idle":"2022-02-02T08:30:22.777215Z","shell.execute_reply.started":"2022-02-02T08:30:22.765681Z","shell.execute_reply":"2022-02-02T08:30:22.776439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.780225Z","iopub.execute_input":"2022-02-02T08:30:22.780464Z","iopub.status.idle":"2022-02-02T08:30:22.790169Z","shell.execute_reply.started":"2022-02-02T08:30:22.78043Z","shell.execute_reply":"2022-02-02T08:30:22.789445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.conv = nn.Conv2d(4,3,1)\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n#         print(n_features)\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.791828Z","iopub.execute_input":"2022-02-02T08:30:22.792213Z","iopub.status.idle":"2022-02-02T08:30:22.801532Z","shell.execute_reply.started":"2022-02-02T08:30:22.792174Z","shell.execute_reply":"2022-02-02T08:30:22.80068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\ndef load_state_eff(model_path):\n    state_dict = torch.load(model_path)['model']\n    return state_dict\n\ndef inference(model_eff, states, test_loader, device):\n    model_eff.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        x=1\n        for state in states:\n            model_eff.load_state_dict(state)\n            model_eff.eval()\n            with torch.no_grad():\n                y_preds = model_eff(images)\n#                 print(images.shape) # (4, 4, 512, 512)\n                print(y_preds.shape) # (4, 2)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy()) # append (4, 2) 5 times \n            x+=1\n#         print(np.array(avg_preds).shape)    # (5, 4, 2) -> 5 folds \n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.802828Z","iopub.execute_input":"2022-02-02T08:30:22.80451Z","iopub.status.idle":"2022-02-02T08:30:22.815183Z","shell.execute_reply.started":"2022-02-02T08:30:22.804469Z","shell.execute_reply":"2022-02-02T08:30:22.81419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eff = CustomEfficientNet(CFG.model_name, pretrained=False)\n\nstates = [load_state_eff('../input/rsnatraining/efficientnet_b3_fold0_best.pth'),\n          load_state_eff('../input/rsnatraining/efficientnet_b3_fold1_best.pth'),\n          load_state_eff('../input/rsnatraining/efficientnet_b3_fold2_best.pth'),\n          load_state_eff('../input/rsnatraining/efficientnet_b3_fold3_best.pth'),\n          load_state_eff('../input/rsnatraining/efficientnet_b3_fold4_best.pth'),\n]\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:22.816362Z","iopub.execute_input":"2022-02-02T08:30:22.816788Z","iopub.status.idle":"2022-02-02T08:30:33.546012Z","shell.execute_reply.started":"2022-02-02T08:30:22.816748Z","shell.execute_reply":"2022-02-02T08:30:33.545138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\n\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model_eff, states, test_loader, device)\n\n# submission\ntest['MGMT_value'] = predictions[:,1]\n# test[['BraTS21ID', 'MGMT_value']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()\nsubmission3 = test[['BraTS21ID', 'MGMT_value']]\n# submission3.to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# submission3.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:30:33.547749Z","iopub.execute_input":"2022-02-02T08:30:33.548057Z","iopub.status.idle":"2022-02-02T08:30:59.28433Z","shell.execute_reply.started":"2022-02-02T08:30:33.548013Z","shell.execute_reply":"2022-02-02T08:30:59.283492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission3 = submission3.sort_values(by=\"BraTS21ID\").reset_index(drop=True)\nsubmission3","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:32:14.702253Z","iopub.execute_input":"2022-02-02T08:32:14.703054Z","iopub.status.idle":"2022-02-02T08:32:14.718254Z","shell.execute_reply.started":"2022-02-02T08:32:14.703015Z","shell.execute_reply":"2022-02-02T08:32:14.717456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model4 [MUEN]funkyboy","metadata":{}},{"cell_type":"code","source":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:52.758143Z","iopub.execute_input":"2022-02-02T08:34:52.758463Z","iopub.status.idle":"2022-02-02T08:34:52.764918Z","shell.execute_reply.started":"2022-02-02T08:34:52.758408Z","shell.execute_reply":"2022-02-02T08:34:52.764169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '/media/roland/data/kaggle/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 256\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nfrom efficientnet_pytorch_3d import EfficientNet3D","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:52.930663Z","iopub.execute_input":"2022-02-02T08:34:52.930938Z","iopub.status.idle":"2022-02-02T08:34:52.938984Z","shell.execute_reply.started":"2022-02-02T08:34:52.930905Z","shell.execute_reply":"2022-02-02T08:34:52.938058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_image(path, img_size=SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n        \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    middle = len(files)//2\n    num_imgs2 = num_imgs//2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d / np.max(img3d)\n            \n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00000\")\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:53.095938Z","iopub.execute_input":"2022-02-02T08:34:53.096499Z","iopub.status.idle":"2022-02-02T08:34:53.553987Z","shell.execute_reply.started":"2022-02-02T08:34:53.096466Z","shell.execute_reply":"2022-02-02T08:34:53.553205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(12)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:53.555863Z","iopub.execute_input":"2022-02-02T08:34:53.556102Z","iopub.status.idle":"2022-02-02T08:34:53.563545Z","shell.execute_reply.started":"2022-02-02T08:34:53.556067Z","shell.execute_reply":"2022-02-02T08:34:53.561914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{data_directory}/train_labels.csv\")\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=12, \n    stratify=train_df[\"MGMT_value\"],\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:53.56509Z","iopub.execute_input":"2022-02-02T08:34:53.565482Z","iopub.status.idle":"2022-02-02T08:34:53.586235Z","shell.execute_reply.started":"2022-02-02T08:34:53.565442Z","shell.execute_reply":"2022-02-02T08:34:53.585456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.tail()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:53.588084Z","iopub.execute_input":"2022-02-02T08:34:53.588498Z","iopub.status.idle":"2022-02-02T08:34:53.597595Z","shell.execute_reply.started":"2022-02-02T08:34:53.588453Z","shell.execute_reply":"2022-02-02T08:34:53.596575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\", augment=False):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n        self.augment = augment\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            if self.augment:\n                rotation = np.random.randint(0,4)\n            else:\n                rotation = 0\n\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\", rotate=rotation)\n\n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:53.725402Z","iopub.execute_input":"2022-02-02T08:34:53.72617Z","iopub.status.idle":"2022-02-02T08:34:53.73646Z","shell.execute_reply.started":"2022-02-02T08:34:53.726121Z","shell.execute_reply":"2022-02-02T08:34:53.735667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/einops-030/einops-0.3.0-py2.py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:34:53.862432Z","iopub.execute_input":"2022-02-02T08:34:53.862686Z","iopub.status.idle":"2022-02-02T08:35:21.595891Z","shell.execute_reply.started":"2022-02-02T08:34:53.862655Z","shell.execute_reply":"2022-02-02T08:35:21.594975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\n\n# helpers\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)\n\n# classes\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n        super().__init__()\n        inner_dim = dim_head *  heads\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.attend = nn.Softmax(dim = -1)\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x):\n        qkv = self.to_qkv(x).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        attn = self.attend(dots)\n\n        out = torch.matmul(attn, v)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        return self.to_out(out)\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n        mlp_dim = 2048\n        for _ in range(depth):\n            #print (dim, mlp_dim)\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n            ]))\n    def forward(self, x):\n        for attn, ff in self.layers:\n            x = attn(x) + x\n            x = ff(x) + x\n        return x\n\n# class ViT(nn.Module):\n#     def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n#         super().__init__()\n#         image_height, image_width = pair(image_size)\n#         patch_height, patch_width = pair(patch_size)\n\n#         assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n#         num_patches = (image_height // patch_height) * (image_width // patch_width)\n#         patch_dim = channels * patch_height * patch_width\n#         assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n#         self.to_patch_embedding = nn.Sequential(\n#             Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n#             nn.Linear(patch_dim, dim),\n#         )\n\n#         self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n#         self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n#         self.dropout = nn.Dropout(emb_dropout)\n\n#         self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n#         self.pool = pool\n#         self.to_latent = nn.Identity()\n\n#         self.mlp_head = nn.Sequential(\n#             nn.LayerNorm(dim),\n#             nn.Linear(dim, num_classes)\n#         )\n\n#     def forward(self, img):\n#         x = self.to_patch_embedding(img)\n#         b, n, _ = x.shape\n\n#         cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n#         x = torch.cat((cls_tokens, x), dim=1)\n#         x += self.pos_embedding[:, :(n + 1)]\n#         x = self.dropout(x)\n\n#         x = self.transformer(x)\n\n#         x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n\n#         x = self.to_latent(x)\n#         return self.mlp_head(x)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.600062Z","iopub.execute_input":"2022-02-02T08:35:21.600305Z","iopub.status.idle":"2022-02-02T08:35:21.622504Z","shell.execute_reply.started":"2022-02-02T08:35:21.600276Z","shell.execute_reply":"2022-02-02T08:35:21.621588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels = 3, dropout = 0., emb_dropout = 0.):\n        super().__init__()\n        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n        num_patches = (image_size // patch_size) *(image_size // patch_size)* 2\n        patch_dim = channels * patch_size ** 3\n\n        self.patch_size = patch_size\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n        #print (mlp_dim)\n        self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)\n        #print (dim)\n        self.to_cls_token = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, mlp_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(mlp_dim, num_classes),\n            nn.Dropout(dropout)\n        )\n\n    def forward(self, img, mask = None):\n        p = self.patch_size\n        #print (img.shape)\n        x = rearrange(img, 'b c (h p1) (w p2) (d p3) -> b (h w d) (p1 p2 p3 c)', p1 = p, p2 = p, p3 = p)\n        #print (x.shape)\n        x = self.patch_to_embedding(x)\n        #print (x.shape)\n        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\n        #print (cls_tokens.shape)\n        x = torch.cat((cls_tokens, x), dim=1)\n        #print (x.shape)\n        #print (self.pos_embedding.shape)\n        x += self.pos_embedding\n        x = self.dropout(x)\n\n        x = self.transformer(x)\n\n        x = self.to_cls_token(x[:, 0])\n        return self.mlp_head(x)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.624317Z","iopub.execute_input":"2022-02-02T08:35:21.625009Z","iopub.status.idle":"2022-02-02T08:35:21.639219Z","shell.execute_reply.started":"2022-02-02T08:35:21.624964Z","shell.execute_reply":"2022-02-02T08:35:21.63842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s            \",\n                n_epoch, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_loss, valid_auc, valid_time\n            )\n\n            # if True:\n            #if self.best_valid_score < valid_auc: \n            if self.best_valid_score > valid_loss: \n                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n                self.info_message(\n                     \"auc improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            message = 'Train Step {}/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n        \n        return sum_loss/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n            \n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss, auc):\n        self.lastmodel = f\"{save_path}-best.pth\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.643151Z","iopub.execute_input":"2022-02-02T08:35:21.643395Z","iopub.status.idle":"2022-02-02T08:35:21.666945Z","shell.execute_reply.started":"2022-02-02T08:35:21.643358Z","shell.execute_reply":"2022-02-02T08:35:21.665856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# def train_mri_type(df_train, df_valid, mri_type):\n#     if mri_type==\"all\":\n#         train_list = []\n#         valid_list = []\n#         for mri_type in mri_types:\n#             df_train.loc[:,\"MRI_Type\"] = mri_type\n#             train_list.append(df_train.copy())\n#             df_valid.loc[:,\"MRI_Type\"] = mri_type\n#             valid_list.append(df_valid.copy())\n\n#         df_train = pd.concat(train_list)\n#         df_valid = pd.concat(valid_list)\n#     else:\n#         df_train.loc[:,\"MRI_Type\"] = mri_type\n#         df_valid.loc[:,\"MRI_Type\"] = mri_type\n\n#     print(df_train.shape, df_valid.shape)\n#     display(df_train.head())\n    \n#     train_data_retriever = Dataset(\n#         df_train[\"BraTS21ID\"].values, \n#         df_train[\"MGMT_value\"].values, \n#         df_train[\"MRI_Type\"].values,\n#         augment=True\n#     )\n\n#     valid_data_retriever = Dataset(\n#         df_valid[\"BraTS21ID\"].values, \n#         df_valid[\"MGMT_value\"].values,\n#         df_valid[\"MRI_Type\"].values\n#     )\n\n#     train_loader = torch_data.DataLoader(\n#         train_data_retriever,\n#         batch_size=4,\n#         shuffle=True,\n#         num_workers=8,pin_memory = True\n#     )\n\n#     valid_loader = torch_data.DataLoader(\n#         valid_data_retriever, \n#         batch_size=4,\n#         shuffle=False,\n#         num_workers=8,pin_memory = True\n#     )\n\n#     model = Model(\n#         image_size = 256,\n#         patch_size = 32,\n#         num_classes = 1,\n#         dim = 1024,\n#         depth = 2,\n#         heads = 16,\n#         mlp_dim = 2048,\n#         channels = 1,\n#         dropout = 0.1,\n#         emb_dropout = 0.1\n#     )\n#     model.to(device)\n\n#     #checkpoint = torch.load(\"best-model-all-auc0.555.pth\")\n#     #model.load_state_dict(checkpoint[\"model_state_dict\"])\n\n#     #print(model)\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n#     #optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n#     criterion = torch_functional.binary_cross_entropy_with_logits\n\n#     trainer = Trainer(\n#         model, \n#         device, \n#         optimizer, \n#         criterion\n#     )\n\n#     history = trainer.fit(\n#         10, \n#         train_loader, \n#         valid_loader, \n#         f\"{mri_type}\", \n#         10,\n#     )\n    \n#     return trainer.lastmodel\n\n# modelfiles = None\n\n# if not modelfiles:\n#     modelfiles = [train_mri_type(df_train, df_valid, m) for m in mri_types]\n#     print(modelfiles)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.668716Z","iopub.execute_input":"2022-02-02T08:35:21.669069Z","iopub.status.idle":"2022-02-02T08:35:21.680719Z","shell.execute_reply.started":"2022-02-02T08:35:21.669028Z","shell.execute_reply":"2022-02-02T08:35:21.679751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = Model(\n        image_size = 256,\n        patch_size = 32,\n        num_classes = 1,\n        dim = 1024,\n        depth = 2,\n        heads = 16,\n        mlp_dim = 2048,\n        channels = 1,\n        dropout = 0.1,\n        emb_dropout = 0.1\n    )\n    model.to(device)\n    \n    checkpoint = torch.load(modelfile)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.682199Z","iopub.execute_input":"2022-02-02T08:35:21.683201Z","iopub.status.idle":"2022-02-02T08:35:21.696849Z","shell.execute_reply.started":"2022-02-02T08:35:21.683111Z","shell.execute_reply":"2022-02-02T08:35:21.696113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_valid = df_valid.set_index(\"BraTS21ID\")\n# df_valid[\"MGMT_pred\"] = 0\n# for m, mtype in zip(modelfiles,  mri_types):\n#     pred = predict(m, df_valid, mtype, \"train\")\n#     df_valid[\"MGMT_pred\"] += pred[\"MGMT_value\"]\n# df_valid[\"MGMT_pred\"] /= len(modelfiles)\n# auc = roc_auc_score(df_valid[\"MGMT_value\"], df_valid[\"MGMT_pred\"])\n# print(f\"Validation ensemble AUC: {auc:.4f}\")\n# sns.displot(df_valid[\"MGMT_pred\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.698372Z","iopub.execute_input":"2022-02-02T08:35:21.699284Z","iopub.status.idle":"2022-02-02T08:35:21.706718Z","shell.execute_reply.started":"2022-02-02T08:35:21.699245Z","shell.execute_reply":"2022-02-02T08:35:21.705946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission4 = pd.read_csv(f\"{data_directory}/sample_submission.csv\", index_col=\"BraTS21ID\")\n\n# submission4[\"MGMT_value\"] = 0\n# for m, mtype in zip(modelfiles, mri_types):\n#     pred = predict(m, submission4, mtype, split=\"test\")\n#     submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\n# submission4[\"MGMT_value\"] /= len(modelfiles)\n# submission4[\"MGMT_value\"].to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.708319Z","iopub.execute_input":"2022-02-02T08:35:21.708884Z","iopub.status.idle":"2022-02-02T08:35:21.719039Z","shell.execute_reply.started":"2022-02-02T08:35:21.708843Z","shell.execute_reply":"2022-02-02T08:35:21.718213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission4","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.720796Z","iopub.execute_input":"2022-02-02T08:35:21.721458Z","iopub.status.idle":"2022-02-02T08:35:21.728957Z","shell.execute_reply.started":"2022-02-02T08:35:21.721355Z","shell.execute_reply":"2022-02-02T08:35:21.728105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.displot(submissio4n[\"MGMT_value\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.732056Z","iopub.execute_input":"2022-02-02T08:35:21.732698Z","iopub.status.idle":"2022-02-02T08:35:21.737955Z","shell.execute_reply.started":"2022-02-02T08:35:21.732637Z","shell.execute_reply":"2022-02-02T08:35:21.737211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Submission","metadata":{}},{"cell_type":"code","source":"final = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\nfinal.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.739622Z","iopub.execute_input":"2022-02-02T08:35:21.740249Z","iopub.status.idle":"2022-02-02T08:35:21.760035Z","shell.execute_reply.started":"2022-02-02T08:35:21.740203Z","shell.execute_reply":"2022-02-02T08:35:21.759264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final[\"MGMT_value\"] = (submission1[\"MGMT_value\"] + submission2[\"MGMT_value\"] + submission3[\"MGMT_value\"])/3","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.761696Z","iopub.execute_input":"2022-02-02T08:35:21.762228Z","iopub.status.idle":"2022-02-02T08:35:21.768065Z","shell.execute_reply.started":"2022-02-02T08:35:21.762188Z","shell.execute_reply":"2022-02-02T08:35:21.767268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.770856Z","iopub.execute_input":"2022-02-02T08:35:21.771745Z","iopub.status.idle":"2022-02-02T08:35:21.78424Z","shell.execute_reply.started":"2022-02-02T08:35:21.771697Z","shell.execute_reply":"2022-02-02T08:35:21.783172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.to_csv(\"submission.csv\", index=False)\nfinal","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:35:21.786164Z","iopub.execute_input":"2022-02-02T08:35:21.786496Z","iopub.status.idle":"2022-02-02T08:35:21.802471Z","shell.execute_reply.started":"2022-02-02T08:35:21.786444Z","shell.execute_reply":"2022-02-02T08:35:21.801358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = pd.read_csv(\"../input/brain-tumor-test/train1_actual_labels.csv\")\n# actual_labels = temp[\"MGMT_value\"].values\n# predicted_labels = final[\"MGMT_value\"].values\n# temp","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:24.789368Z","iopub.execute_input":"2022-02-01T15:30:24.789962Z","iopub.status.idle":"2022-02-01T15:30:24.807246Z","shell.execute_reply.started":"2022-02-01T15:30:24.789923Z","shell.execute_reply":"2022-02-01T15:30:24.806601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred = []\n# for i in predicted_labels:\n#     if i<0.5:\n#         pred.append(0)\n#     else:\n#         pred.append(1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:25:40.82644Z","iopub.execute_input":"2022-02-01T15:25:40.827008Z","iopub.status.idle":"2022-02-01T15:25:40.831469Z","shell.execute_reply.started":"2022-02-01T15:25:40.826976Z","shell.execute_reply":"2022-02-01T15:25:40.830727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import precision_score\n# precision_score(actual_labels, pred, average=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:25:57.030525Z","iopub.execute_input":"2022-02-01T15:25:57.031402Z","iopub.status.idle":"2022-02-01T15:25:57.040396Z","shell.execute_reply.started":"2022-02-01T15:25:57.031347Z","shell.execute_reply":"2022-02-01T15:25:57.039587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission1","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:11.975779Z","iopub.execute_input":"2022-02-01T15:26:11.976616Z","iopub.status.idle":"2022-02-01T15:26:11.988928Z","shell.execute_reply.started":"2022-02-01T15:26:11.976552Z","shell.execute_reply":"2022-02-01T15:26:11.98799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission2","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:16.213915Z","iopub.execute_input":"2022-02-01T15:26:16.214186Z","iopub.status.idle":"2022-02-01T15:26:16.225307Z","shell.execute_reply.started":"2022-02-01T15:26:16.214155Z","shell.execute_reply":"2022-02-01T15:26:16.224559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission3","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:28:48.401421Z","iopub.execute_input":"2022-02-01T15:28:48.401731Z","iopub.status.idle":"2022-02-01T15:28:48.407901Z","shell.execute_reply.started":"2022-02-01T15:28:48.401697Z","shell.execute_reply":"2022-02-01T15:28:48.406999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission3 = submission3.sort_values(by = 'BraTS21ID')\n# submission3","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:49.168443Z","iopub.execute_input":"2022-02-01T15:30:49.168713Z","iopub.status.idle":"2022-02-01T15:30:49.182552Z","shell.execute_reply.started":"2022-02-01T15:30:49.168683Z","shell.execute_reply":"2022-02-01T15:30:49.181719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final[\"MGMT_value\"] = (submission1[\"MGMT_value\"] + submission2[\"MGMT_value\"] + submission3[\"MGMT_value\"])/3","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:58.179226Z","iopub.execute_input":"2022-02-01T15:30:58.179599Z","iopub.status.idle":"2022-02-01T15:30:58.188928Z","shell.execute_reply.started":"2022-02-01T15:30:58.179556Z","shell.execute_reply":"2022-02-01T15:30:58.186875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# precision_score(actual_labels, pred, average=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:31:15.14068Z","iopub.execute_input":"2022-02-01T15:31:15.141275Z","iopub.status.idle":"2022-02-01T15:31:15.14935Z","shell.execute_reply.started":"2022-02-01T15:31:15.141237Z","shell.execute_reply":"2022-02-01T15:31:15.1486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}