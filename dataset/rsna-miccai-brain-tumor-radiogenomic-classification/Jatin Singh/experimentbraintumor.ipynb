{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pipeline 3","metadata":{}},{"cell_type":"code","source":"package_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\nimport sys \nsys.path.append(package_path)\n\nimport os\nimport glob\nimport time\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom torch.nn import functional as F\n\nimport efficientnet_pytorch\n\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:13:57.825346Z","iopub.execute_input":"2022-04-26T09:13:57.826254Z","iopub.status.idle":"2022-04-26T09:13:57.832721Z","shell.execute_reply.started":"2022-04-26T09:13:57.826217Z","shell.execute_reply":"2022-04-26T09:13:57.831934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nseed = 123\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed)\n\nclass X3D:\n    XS=0\n    S=1\n    M=2\n    L=3\n    \nx3d_config = {\n    'input_clip_length': [4, 13, 16, 16],\n    'depth_factor': [2.2, 2.2, 2.2, 5.0],\n    'width_factor': [1, 1, 1, 2.9]\n}\n\nclass CFG:\n    img_size = 256\n    n_frames = 10\n    \n    cnn_features = 256\n    lstm_hidden = 32\n    \n    n_fold = 5\n    n_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:13:58.252008Z","iopub.execute_input":"2022-04-26T09:13:58.252464Z","iopub.status.idle":"2022-04-26T09:13:58.261687Z","shell.execute_reply.started":"2022-04-26T09:13:58.252427Z","shell.execute_reply":"2022-04-26T09:13:58.260838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.map = nn.Conv2d(in_channels=4, out_channels=3, kernel_size=1)\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b2\")\n#         checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\")\n#         checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth\")\n#         self.net.load_state_dict(checkpoint)\n        \n        n_features = self.net._fc.in_features\n        \n#         print(n_features)\n        \n        self.net._fc = nn.Linear(in_features=n_features, out_features=CFG.cnn_features, bias=True)\n    \n    def forward(self, x):\n        x = F.relu(self.map(x))\n        out = self.net(x)\n        return out\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.cnn = CNN()\n        self.rnn = nn.LSTM(CFG.cnn_features, CFG.lstm_hidden, 2, batch_first=True)\n        self.fc = nn.Linear(CFG.lstm_hidden, 1, bias=True)\n\n    def forward(self, x):\n        # x shape: BxTxCxHxW\n        batch_size, timesteps, C, H, W = x.size()\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.cnn(c_in)\n        r_in = c_out.view(batch_size, timesteps, -1)\n        output, (hn, cn) = self.rnn(r_in)\n        \n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:13:58.737603Z","iopub.execute_input":"2022-04-26T09:13:58.737867Z","iopub.status.idle":"2022-04-26T09:13:58.74949Z","shell.execute_reply.started":"2022-04-26T09:13:58.737837Z","shell.execute_reply":"2022-04-26T09:13:58.74867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n        \n    data = np.float32(cv2.resize(data, (CFG.img_size, CFG.img_size)))\n    return torch.tensor(data)\n\n# def load_dicom_line(path):\n#     t_paths = sorted(\n#         glob.glob(os.path.join(path, \"*\")), \n#         key=lambda x: int(x[:-4].split(\"-\")[-1]),\n#     )\n#     images = []\n#     for filename in t_paths:\n#         data = load_dicom(filename)\n#         if data.max() == 0:\n#             continue\n#         images.append(data)\n        \n#     return images\n\n# def load_image(path):\n#     image = cv2.imread(path, 0)\n#     if image is None:\n#         return np.zeros((CFG.img_size, CFG.img_size))\n    \n#     image = cv2.resize(image, (CFG.img_size, CFG.img_size)) / 255\n#     return torch.tensor(image)\n\n# def get_valid_frames(t_paths):\n#     res = []\n#     for path in t_paths:\n#         img = load_dicom(path)\n#         if img.view(-1).mean(0) != 0:\n#             res.append(path)\n#     return res\n    \n\ndef uniform_temporal_subsample(x, num_samples):\n    '''\n        Moddified from https://github.com/facebookresearch/pytorchvideo/blob/d7874f788bc00a7badfb4310a912f6e531ffd6d3/pytorchvideo/transforms/functional.py#L19\n        Args:\n            x: input list\n            num_samples: The number of equispaced samples to be selected\n        Returns:\n            Output list     \n    '''\n    t = len(x)\n    indices = torch.linspace(0, t - 1, num_samples)\n    indices = torch.clamp(indices, 0, t - 1).long()\n    return [x[i] for i in indices]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:13:59.172125Z","iopub.execute_input":"2022-04-26T09:13:59.172377Z","iopub.status.idle":"2022-04-26T09:13:59.180059Z","shell.execute_reply.started":"2022-04-26T09:13:59.172348Z","shell.execute_reply":"2022-04-26T09:13:59.179286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataRetriever(Dataset):\n    def __init__(self, paths, transform=None):\n        self.paths = paths\n        self.transform = transform\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def read_video(self, vid_paths):\n        video = [load_dicom(path) for path in vid_paths]\n        if len(video)==0:\n            video = torch.zeros(CFG.n_frames, CFG.img_size, CFG.img_size)\n        else:\n            video = torch.stack(video) # T * C * H * W\n#         video = torch.transpose(video, 0, 1) # C * T * H * W\n        return video\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{str(_id).zfill(5)}/\"\n        channels = []\n        for t in [\"FLAIR\",\"T1w\", \"T1wCE\", \"T2w\"]:\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n            num_samples = CFG.n_frames\n#             t_paths = get_valid_frames(t_paths)\n            if len(t_paths) < num_samples:\n                in_frames_path = t_paths\n            else:\n                in_frames_path = uniform_temporal_subsample(t_paths, num_samples)\n            \n            channel = self.read_video(in_frames_path)\n            if channel.shape[0] == 0:\n                print(\"1 channel empty\")\n                channel = torch.zeros(num_samples, CFG.img_size, CFG.img_size)\n            channels.append(channel)\n        \n        channels = torch.stack(channels).transpose(0,1)\n        return {\"X\": channels.float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:13:59.182051Z","iopub.execute_input":"2022-04-26T09:13:59.182582Z","iopub.status.idle":"2022-04-26T09:13:59.195366Z","shell.execute_reply.started":"2022-04-26T09:13:59.182544Z","shell.execute_reply":"2022-04-26T09:13:59.19468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ndf.head(10)\n# df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:13:59.532112Z","iopub.execute_input":"2022-04-26T09:13:59.532899Z","iopub.status.idle":"2022-04-26T09:13:59.553886Z","shell.execute_reply.started":"2022-04-26T09:13:59.532828Z","shell.execute_reply":"2022-04-26T09:13:59.553215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(1, CFG.n_fold+1):\n    model = Model()\n    model.to(device)\n    checkpoint = torch.load(f\"../input/modelweight34/modelweight34/best-model-{i}.pth\")\n#     print(checkpoint[\"model_state_dict\"])\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:00.303898Z","iopub.execute_input":"2022-04-26T09:14:00.304164Z","iopub.status.idle":"2022-04-26T09:14:05.193601Z","shell.execute_reply.started":"2022-04-26T09:14:00.304137Z","shell.execute_reply":"2022-04-26T09:14:05.192828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\ntest_data_retriever = TestDataRetriever(\n    submission[\"BraTS21ID\"].values # ids in test data\n)\nprint(test_data_retriever.read_video)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=4,\n    shuffle=False,\n    num_workers=8,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:05.195162Z","iopub.execute_input":"2022-04-26T09:14:05.195547Z","iopub.status.idle":"2022-04-26T09:14:05.205591Z","shell.execute_reply.started":"2022-04-26T09:14:05.195512Z","shell.execute_reply":"2022-04-26T09:14:05.204842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_data_retriever))\nprint(test_data_retriever[85]['X'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:05.207005Z","iopub.execute_input":"2022-04-26T09:14:05.207498Z","iopub.status.idle":"2022-04-26T09:14:05.439992Z","shell.execute_reply.started":"2022-04-26T09:14:05.207422Z","shell.execute_reply":"2022-04-26T09:14:05.439203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader.batch_size\nlen(test_loader) # no. of batches","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:05.441615Z","iopub.execute_input":"2022-04-26T09:14:05.4424Z","iopub.status.idle":"2022-04-26T09:14:05.44842Z","shell.execute_reply.started":"2022-04-26T09:14:05.442359Z","shell.execute_reply":"2022-04-26T09:14:05.44767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        print(batch[\"X\"].shape)\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n#             print(tmp_pred)\n            tmp_pred += tmp_res\n            \n        tmp_pred = tmp_pred/len(models)\n        y_pred.extend(tmp_pred)\n#         print(len(y_pred))\n        ids.extend(batch[\"id\"].numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:05.449741Z","iopub.execute_input":"2022-04-26T09:14:05.450011Z","iopub.status.idle":"2022-04-26T09:14:23.667879Z","shell.execute_reply.started":"2022-04-26T09:14:05.449976Z","shell.execute_reply":"2022-04-26T09:14:23.666989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:23.67006Z","iopub.execute_input":"2022-04-26T09:14:23.670331Z","iopub.status.idle":"2022-04-26T09:14:23.676162Z","shell.execute_reply.started":"2022-04-26T09:14:23.670293Z","shell.execute_reply":"2022-04-26T09:14:23.675301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:14:23.677577Z","iopub.execute_input":"2022-04-26T09:14:23.678205Z","iopub.status.idle":"2022-04-26T09:14:23.694406Z","shell.execute_reply.started":"2022-04-26T09:14:23.678166Z","shell.execute_reply":"2022-04-26T09:14:23.693663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline 2","metadata":{"execution":{"iopub.status.busy":"2022-01-25T12:03:56.753412Z","iopub.execute_input":"2022-01-25T12:03:56.754121Z","iopub.status.idle":"2022-01-25T12:03:56.818898Z","shell.execute_reply.started":"2022-01-25T12:03:56.754083Z","shell.execute_reply":"2022-01-25T12:03:56.81747Z"}}},{"cell_type":"code","source":"pip install '../input/rsna-monai-packages/monai-0.6.0-202107081903-py3-none-any.whl'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:01:25.242366Z","iopub.execute_input":"2022-04-26T08:01:25.242639Z","iopub.status.idle":"2022-04-26T08:01:53.944397Z","shell.execute_reply.started":"2022-04-26T08:01:25.242608Z","shell.execute_reply":"2022-04-26T08:01:53.943495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:10.954948Z","iopub.execute_input":"2022-04-26T08:03:10.955233Z","iopub.status.idle":"2022-04-26T08:03:11.705462Z","shell.execute_reply.started":"2022-04-26T08:03:10.955202Z","shell.execute_reply":"2022-04-26T08:03:11.704752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import roc_auc_score\nfrom torch.optim import lr_scheduler\nfrom tqdm import tqdm\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:13.066459Z","iopub.execute_input":"2022-04-26T08:03:13.067178Z","iopub.status.idle":"2022-04-26T08:03:14.364379Z","shell.execute_reply.started":"2022-04-26T08:03:13.067138Z","shell.execute_reply":"2022-04-26T08:03:14.3636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES_3D = 64\nTRAINING_BATCH_SIZE = 8\nTEST_BATCH_SIZE = 8\nIMAGE_SIZE = 256\nN_EPOCHS = 15\ndo_valid = True\nn_workers = 4\ntype_ = \"T1wCE\"","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:15.514625Z","iopub.execute_input":"2022-04-26T08:03:15.515217Z","iopub.status.idle":"2022-04-26T08:03:15.521613Z","shell.execute_reply.started":"2022-04-26T08:03:15.515176Z","shell.execute_reply":"2022-04-26T08:03:15.519565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n\n    if rotate > 0:\n        rot_choices = [\n            0,\n            cv2.ROTATE_90_CLOCKWISE,\n            cv2.ROTATE_90_COUNTERCLOCKWISE,\n            cv2.ROTATE_180,\n        ]\n        data = cv2.rotate(data, rot_choices[rotate])\n\n    data = cv2.resize(data, (img_size, img_size))\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:16.563592Z","iopub.execute_input":"2022-04-26T08:03:16.563869Z","iopub.status.idle":"2022-04-26T08:03:16.571323Z","shell.execute_reply.started":"2022-04-26T08:03:16.56384Z","shell.execute_reply":"2022-04-26T08:03:16.56966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nimport cv2\nfrom torch.utils.data import Dataset\n\n\nclass BrainRSNADataset(Dataset):\n    def __init__(\n        self, data, transform=None, target=\"MGMT_value\", mri_type=\"FLAIR\", is_train=True\n    ):\n        self.target = target\n        self.data = data\n        self.type = mri_type\n\n        self.transform = transform\n        self.is_train = is_train\n        self.folder = \"train\" if self.is_train else \"test\"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        row = self.data.loc[index]\n        case_id = int(row.BraTS21ID)\n        target = int(row[self.target])\n        _3d_images = self.load_dicom_images_3d(case_id)\n        _3d_images = torch.tensor(_3d_images).float()\n        if self.is_train:\n            return {\"image\": _3d_images, \"target\": target}\n        else:\n            return {\"image\": _3d_images, \"case_id\": case_id}\n\n    def load_dicom_images_3d(\n        self,\n        case_id,\n        num_imgs=NUM_IMAGES_3D,\n        img_size=IMAGE_SIZE,\n        rotate=0,\n    ):\n        case_id = str(case_id).zfill(5)\n\n        path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/{self.folder}/{case_id}/{self.type}/*.dcm\"\n#         path = f\"../input/brain-tumor-test/test1/test1/{case_id}/{self.type}/*.dcm\"\n        \n        files = sorted(\n            glob.glob(path),\n            key=lambda var: [\n                int(x) if x.isdigit() else x for x in re.findall(r\"[^0-9]|[0-9]+\", var)\n            ],\n        )\n\n        middle = len(files) // 2\n        num_imgs2 = num_imgs // 2\n        p1 = max(0, middle - num_imgs2)\n        p2 = min(len(files), middle + num_imgs2)\n        image_stack = [load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]\n        \n        img3d = np.stack(image_stack).T\n        if img3d.shape[-1] < num_imgs:\n            n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n            img3d = np.concatenate((img3d, n_zero), axis=-1)\n#         print(img3d.shape)\n        if np.min(img3d) < np.max(img3d):\n            img3d = img3d - np.min(img3d)\n            img3d = img3d / np.max(img3d)\n\n        return np.expand_dims(img3d, 0)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:21.157407Z","iopub.execute_input":"2022-04-26T08:03:21.157676Z","iopub.status.idle":"2022-04-26T08:03:21.173531Z","shell.execute_reply.started":"2022-04-26T08:03:21.157646Z","shell.execute_reply":"2022-04-26T08:03:21.172688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ../input/","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:27.271871Z","iopub.execute_input":"2022-04-26T08:03:27.27243Z","iopub.status.idle":"2022-04-26T08:03:27.988034Z","shell.execute_reply.started":"2022-04-26T08:03:27.272391Z","shell.execute_reply":"2022-04-26T08:03:27.987225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import monai\n\n# model \nmodel = monai.networks.nets.resnet34(spatial_dims=3, n_input_channels=1, n_classes=1)\ndevice = torch.device(\"cuda\")\nmodel.to(device);\nall_weights = os.listdir(\"../input/modelweights33/modelweights33\")\nfold_files = [f for f in all_weights if type_ in f]\n# print(np.array(fold_files).shape)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:29.296935Z","iopub.execute_input":"2022-04-26T08:03:29.297704Z","iopub.status.idle":"2022-04-26T08:03:32.559782Z","shell.execute_reply.started":"2022-04-26T08:03:29.297659Z","shell.execute_reply":"2022-04-26T08:03:32.559016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_files","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:34.646511Z","iopub.execute_input":"2022-04-26T08:03:34.64701Z","iopub.status.idle":"2022-04-26T08:03:34.654588Z","shell.execute_reply.started":"2022-04-26T08:03:34.646973Z","shell.execute_reply":"2022-04-26T08:03:34.653816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:03:37.133607Z","iopub.execute_input":"2022-04-26T08:03:37.134179Z","iopub.status.idle":"2022-04-26T08:03:37.140802Z","shell.execute_reply.started":"2022-04-26T08:03:37.134138Z","shell.execute_reply":"2022-04-26T08:03:37.139979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tta_true_labels = []\ntta_preds = []\ntest_dataset = BrainRSNADataset(data=sample, mri_type=type_, is_train=False)\ntest_dl = torch.utils.data.DataLoader(\n        test_dataset, batch_size=8, shuffle=False, num_workers=4\n    )\n\npreds_f = np.zeros(len(sample))\nfor fold in range(5):\n    image_ids = []\n    model.load_state_dict(torch.load(f\"../input/modelweights33/modelweights33/{fold_files[fold]}\"))\n    preds = []\n    epoch_iterator_test = tqdm(test_dl)\n    with torch.no_grad():\n        for  step, batch in enumerate(epoch_iterator_test):\n            model.eval()\n            images = batch[\"image\"].to(device)\n            print(batch[\"image\"].shape)\n            outputs = model(images)\n            preds.append(outputs.sigmoid().detach().cpu().numpy())\n            image_ids.append(batch[\"case_id\"].detach().cpu().numpy())\n    \n\n    preds_f += np.vstack(preds).T[0]/5\n\n    ids_f = np.hstack(image_ids)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:12:26.059407Z","iopub.execute_input":"2022-04-26T08:12:26.059665Z","iopub.status.idle":"2022-04-26T08:14:24.369786Z","shell.execute_reply.started":"2022-04-26T08:12:26.059636Z","shell.execute_reply":"2022-04-26T08:14:24.368433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(np.array(test_dataset).shape)\ntest_dataset[40]['image'].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:14:45.54176Z","iopub.execute_input":"2022-04-26T08:14:45.542304Z","iopub.status.idle":"2022-04-26T08:14:45.812709Z","shell.execute_reply.started":"2022-04-26T08:14:45.542261Z","shell.execute_reply":"2022-04-26T08:14:45.811961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample[\"BraTS21ID\"] = ids_f\nsample[\"MGMT_value\"] = preds_f","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:14:46.152316Z","iopub.execute_input":"2022-04-26T08:14:46.152588Z","iopub.status.idle":"2022-04-26T08:14:46.157383Z","shell.execute_reply.started":"2022-04-26T08:14:46.152555Z","shell.execute_reply":"2022-04-26T08:14:46.15673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = sample.sort_values(by=\"BraTS21ID\").reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:14:46.686554Z","iopub.execute_input":"2022-04-26T08:14:46.687381Z","iopub.status.idle":"2022-04-26T08:14:46.693074Z","shell.execute_reply.started":"2022-04-26T08:14:46.687335Z","shell.execute_reply":"2022-04-26T08:14:46.692338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission2.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:14:47.382995Z","iopub.execute_input":"2022-04-26T08:14:47.383686Z","iopub.status.idle":"2022-04-26T08:14:47.389884Z","shell.execute_reply.started":"2022-04-26T08:14:47.383646Z","shell.execute_reply":"2022-04-26T08:14:47.389122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:14:48.337996Z","iopub.execute_input":"2022-04-26T08:14:48.338762Z","iopub.status.idle":"2022-04-26T08:14:48.350369Z","shell.execute_reply.started":"2022-04-26T08:14:48.338711Z","shell.execute_reply":"2022-04-26T08:14:48.349663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline 1","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \n# TRAIN_PATH = '../input/rsna-miccai-png/train'\nTEST_PATH = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:15.982548Z","iopub.execute_input":"2022-04-26T08:48:15.982836Z","iopub.status.idle":"2022-04-26T08:48:15.988073Z","shell.execute_reply.started":"2022-04-26T08:48:15.982797Z","shell.execute_reply":"2022-04-26T08:48:15.987023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='efficientnet_b4'\n    size=512\n    batch_size=4\n    seed=42\n    target_size=2\n    target_col='MGMT_value'\n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    inference=True","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:16.498476Z","iopub.execute_input":"2022-04-26T08:48:16.498734Z","iopub.status.idle":"2022-04-26T08:48:16.503821Z","shell.execute_reply.started":"2022-04-26T08:48:16.498703Z","shell.execute_reply":"2022-04-26T08:48:16.502823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Imports\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:17.077988Z","iopub.execute_input":"2022-04-26T08:48:17.078489Z","iopub.status.idle":"2022-04-26T08:48:17.090404Z","shell.execute_reply.started":"2022-04-26T08:48:17.078451Z","shell.execute_reply":"2022-04-26T08:48:17.089672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:17.740391Z","iopub.execute_input":"2022-04-26T08:48:17.741084Z","iopub.status.idle":"2022-04-26T08:48:17.746804Z","shell.execute_reply.started":"2022-04-26T08:48:17.741045Z","shell.execute_reply":"2022-04-26T08:48:17.745667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test')\n# print(np.array(test).shape)\ntest = pd.DataFrame({'BraTS21ID' : test})\n# print(test)\ntest['BraTS21ID'] = test['BraTS21ID'].astype(int)\ntest","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:17.938549Z","iopub.execute_input":"2022-04-26T08:48:17.938817Z","iopub.status.idle":"2022-04-26T08:48:17.954457Z","shell.execute_reply.started":"2022-04-26T08:48:17.93878Z","shell.execute_reply":"2022-04-26T08:48:17.953792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['BraTS21ID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        root = f'{TEST_PATH}/{str(self.file_names[idx]).zfill(5)}/'\n        com = []\n        for typ in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n            paths = os.listdir(root + typ)\n            rnd = random.sample(paths, min(10, len(paths)))\n            typ_imgs = []\n            for f in rnd:\n                file_path = f'{root}{typ}/{f}'\n                dicom = pydicom.read_file(file_path)\n                data = apply_voi_lut(dicom.pixel_array, dicom)\n                if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n                    data = np.amax(data) - data\n                data = data - np.min(data)\n                data = data / np.max(data)\n                image = (data * 255).astype(np.uint8)\n                typ_imgs.append(cv2.resize(image, (CFG.size, CFG.size)))\n            com.append(np.mean(typ_imgs, axis = 0))\n        image = np.array(com).transpose((1,2,0)) / 255\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            image = image.float()\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:18.188413Z","iopub.execute_input":"2022-04-26T08:48:18.188777Z","iopub.status.idle":"2022-04-26T08:48:18.199541Z","shell.execute_reply.started":"2022-04-26T08:48:18.188733Z","shell.execute_reply":"2022-04-26T08:48:18.198844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:18.598327Z","iopub.execute_input":"2022-04-26T08:48:18.598923Z","iopub.status.idle":"2022-04-26T08:48:18.603571Z","shell.execute_reply.started":"2022-04-26T08:48:18.598879Z","shell.execute_reply":"2022-04-26T08:48:18.602658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.conv = nn.Conv2d(4,3,1)\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n#         print(n_features)\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:19.207281Z","iopub.execute_input":"2022-04-26T08:48:19.207938Z","iopub.status.idle":"2022-04-26T08:48:19.214861Z","shell.execute_reply.started":"2022-04-26T08:48:19.207895Z","shell.execute_reply":"2022-04-26T08:48:19.213958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\ndef load_state_eff(model_path):\n    state_dict = torch.load(model_path)['model']\n    return state_dict\n\ndef inference(model_eff, states, test_loader, device):\n    model_eff.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        x=1\n        for state in states:\n            model_eff.load_state_dict(state)\n            model_eff.eval()\n            with torch.no_grad():\n                y_preds = model_eff(images)\n#                 print(images.shape) # (4, 4, 512, 512)\n                print(y_preds.shape) # (4, 2)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy()) # append (4, 2) 5 times \n            x+=1\n#         print(np.array(avg_preds).shape)    # (5, 4, 2) -> 5 folds \n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:19.789652Z","iopub.execute_input":"2022-04-26T08:48:19.790359Z","iopub.status.idle":"2022-04-26T08:48:19.797914Z","shell.execute_reply.started":"2022-04-26T08:48:19.790321Z","shell.execute_reply":"2022-04-26T08:48:19.797233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eff = CustomEfficientNet(CFG.model_name, pretrained=False)\n\nstates = [load_state_eff('../input/modelweight14/modelweight14/efficientnet_b4_fold0_best.pth'),\n          load_state_eff('../input/modelweight14/modelweight14/efficientnet_b4_fold1_best.pth'),\n          load_state_eff('../input/modelweight14/modelweight14/efficientnet_b4_fold2_best.pth'),\n          load_state_eff('../input/modelweight14/modelweight14/efficientnet_b4_fold3_best.pth'),\n          load_state_eff('../input/modelweight14/modelweight14/efficientnet_b4_fold4_best.pth'),\n]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:20.357684Z","iopub.execute_input":"2022-04-26T08:48:20.358245Z","iopub.status.idle":"2022-04-26T08:48:31.765012Z","shell.execute_reply.started":"2022-04-26T08:48:20.358206Z","shell.execute_reply":"2022-04-26T08:48:31.764229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\n\n\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model_eff, states, test_loader, device)\n\n# submission\ntest['MGMT_value'] = predictions[:,1]\n# test[['BraTS21ID', 'MGMT_value']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()\nsubmission3 = test[['BraTS21ID', 'MGMT_value']]\n# submission3.to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# submission3.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:31.769057Z","iopub.execute_input":"2022-04-26T08:48:31.769675Z","iopub.status.idle":"2022-04-26T08:48:57.700426Z","shell.execute_reply.started":"2022-04-26T08:48:31.769633Z","shell.execute_reply":"2022-04-26T08:48:57.699607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission3 = submission3.sort_values(by=\"BraTS21ID\").reset_index(drop=True)\nsubmission3","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:48:57.702145Z","iopub.execute_input":"2022-04-26T08:48:57.702435Z","iopub.status.idle":"2022-04-26T08:48:57.718505Z","shell.execute_reply.started":"2022-04-26T08:48:57.702385Z","shell.execute_reply":"2022-04-26T08:48:57.71743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Submission","metadata":{}},{"cell_type":"code","source":"final = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\nfinal.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:46.04758Z","iopub.execute_input":"2022-04-26T09:18:46.048288Z","iopub.status.idle":"2022-04-26T09:18:46.062365Z","shell.execute_reply.started":"2022-04-26T09:18:46.04825Z","shell.execute_reply":"2022-04-26T09:18:46.061648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final[\"MGMT_value\"] = (0.3*submission1[\"MGMT_value\"] + 0.5*submission2[\"MGMT_value\"] + 0.2*submission3[\"MGMT_value\"])\nfinal[\"MGMT_value\"] = submission3[\"MGMT_value\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:46.224461Z","iopub.execute_input":"2022-04-26T09:18:46.224734Z","iopub.status.idle":"2022-04-26T09:18:46.230832Z","shell.execute_reply.started":"2022-04-26T09:18:46.224703Z","shell.execute_reply":"2022-04-26T09:18:46.230133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final[\"MGMT_value\"] = submission2[\"MGMT_value\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:47.21571Z","iopub.execute_input":"2022-04-26T09:18:47.216285Z","iopub.status.idle":"2022-04-26T09:18:47.22028Z","shell.execute_reply.started":"2022-04-26T09:18:47.216247Z","shell.execute_reply":"2022-04-26T09:18:47.219564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final[\"MGMT_value\"] = (submission1[\"MGMT_value\"] + submission2[\"MGMT_value\"] + submission3[\"MGMT_value\"])/3","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:48.36647Z","iopub.execute_input":"2022-04-26T09:18:48.367194Z","iopub.status.idle":"2022-04-26T09:18:48.370571Z","shell.execute_reply.started":"2022-04-26T09:18:48.367153Z","shell.execute_reply":"2022-04-26T09:18:48.369881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:48.627361Z","iopub.execute_input":"2022-04-26T09:18:48.628052Z","iopub.status.idle":"2022-04-26T09:18:48.641371Z","shell.execute_reply.started":"2022-04-26T09:18:48.628013Z","shell.execute_reply":"2022-04-26T09:18:48.640284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.to_csv(\"submission.csv\", index=False)\nfinal","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:48.917848Z","iopub.execute_input":"2022-04-26T09:18:48.918375Z","iopub.status.idle":"2022-04-26T09:18:48.93242Z","shell.execute_reply.started":"2022-04-26T09:18:48.918339Z","shell.execute_reply":"2022-04-26T09:18:48.931551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = pd.read_csv(\"../input/brain-tumor-test/train1_actual_labels.csv\")\n# actual_labels = temp[\"MGMT_value\"].values\n# predicted_labels = final[\"MGMT_value\"].values\n# temp","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:18:51.204994Z","iopub.execute_input":"2022-04-26T09:18:51.205242Z","iopub.status.idle":"2022-04-26T09:18:51.208515Z","shell.execute_reply.started":"2022-04-26T09:18:51.205214Z","shell.execute_reply":"2022-04-26T09:18:51.20782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred = []\n# for i in predicted_labels:\n#     if i<0.5:\n#         pred.append(0)\n#     else:\n#         pred.append(1)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:49.342613Z","iopub.execute_input":"2022-04-26T08:16:49.343094Z","iopub.status.idle":"2022-04-26T08:16:49.349438Z","shell.execute_reply.started":"2022-04-26T08:16:49.343056Z","shell.execute_reply":"2022-04-26T08:16:49.348647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import precision_score\n# precision_score(actual_labels, pred, average=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:49.939389Z","iopub.execute_input":"2022-04-26T08:16:49.939944Z","iopub.status.idle":"2022-04-26T08:16:49.943355Z","shell.execute_reply.started":"2022-04-26T08:16:49.939905Z","shell.execute_reply":"2022-04-26T08:16:49.942365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:50.743706Z","iopub.execute_input":"2022-04-26T08:16:50.744208Z","iopub.status.idle":"2022-04-26T08:16:50.749145Z","shell.execute_reply.started":"2022-04-26T08:16:50.744169Z","shell.execute_reply":"2022-04-26T08:16:50.748223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission2","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:51.13767Z","iopub.execute_input":"2022-04-26T08:16:51.138239Z","iopub.status.idle":"2022-04-26T08:16:51.141747Z","shell.execute_reply.started":"2022-04-26T08:16:51.138199Z","shell.execute_reply":"2022-04-26T08:16:51.141069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission3 = submission3.sort_values(by = 'BraTS21ID')\n# submission3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final[\"MGMT_value\"] = (submission1[\"MGMT_value\"] + submission2[\"MGMT_value\"] + submission3[\"MGMT_value\"])/3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# precision_score(actual_labels, pred, average=\"binary\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}