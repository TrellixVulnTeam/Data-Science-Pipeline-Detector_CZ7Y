{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pipeline 3","metadata":{}},{"cell_type":"code","source":"package_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\nimport sys \nsys.path.append(package_path)\n\nimport os\nimport glob\nimport time\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom torch.nn import functional as F\n\nimport efficientnet_pytorch\n\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:01:34.13992Z","iopub.execute_input":"2022-03-20T10:01:34.140172Z","iopub.status.idle":"2022-03-20T10:01:35.776388Z","shell.execute_reply.started":"2022-03-20T10:01:34.140144Z","shell.execute_reply":"2022-03-20T10:01:35.775651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nseed = 123\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed)\n\nclass X3D:\n    XS=0\n    S=1\n    M=2\n    L=3\n    \nx3d_config = {\n    'input_clip_length': [4, 13, 16, 16],\n    'depth_factor': [2.2, 2.2, 2.2, 5.0],\n    'width_factor': [1, 1, 1, 2.9]\n}\n\nclass CFG:\n    img_size = 256\n    n_frames = 10\n    \n    cnn_features = 256\n    lstm_hidden = 32\n    \n    n_fold = 5\n    n_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:01:35.779886Z","iopub.execute_input":"2022-03-20T10:01:35.780087Z","iopub.status.idle":"2022-03-20T10:01:35.835989Z","shell.execute_reply.started":"2022-03-20T10:01:35.780062Z","shell.execute_reply":"2022-03-20T10:01:35.835209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.map = nn.Conv2d(in_channels=4, out_channels=3, kernel_size=1)\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b2\")\n#         checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\")\n#         checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth\")\n#         self.net.load_state_dict(checkpoint)\n        \n        n_features = self.net._fc.in_features\n        \n#         print(n_features)\n        \n        self.net._fc = nn.Linear(in_features=n_features, out_features=CFG.cnn_features, bias=True)\n    \n    def forward(self, x):\n        x = F.relu(self.map(x))\n        out = self.net(x)\n        return out\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.cnn = CNN()\n        self.rnn = nn.LSTM(CFG.cnn_features, CFG.lstm_hidden, 2, batch_first=True)\n        self.fc = nn.Linear(CFG.lstm_hidden, 1, bias=True)\n\n    def forward(self, x):\n        # x shape: BxTxCxHxW\n        batch_size, timesteps, C, H, W = x.size()\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.cnn(c_in)\n        r_in = c_out.view(batch_size, timesteps, -1)\n        output, (hn, cn) = self.rnn(r_in)\n        print(hn)\n        print(cn)\n        print(output)\n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:38.111731Z","iopub.execute_input":"2022-03-20T10:02:38.112014Z","iopub.status.idle":"2022-03-20T10:02:38.124067Z","shell.execute_reply.started":"2022-03-20T10:02:38.111982Z","shell.execute_reply":"2022-03-20T10:02:38.122557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n        \n    data = np.float32(cv2.resize(data, (CFG.img_size, CFG.img_size)))\n    return torch.tensor(data)\n\ndef uniform_temporal_subsample(x, num_samples):\n    t = len(x)\n    indices = torch.linspace(0, t - 1, num_samples)\n    indices = torch.clamp(indices, 0, t - 1).long()\n    return [x[i] for i in indices]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:39.774846Z","iopub.execute_input":"2022-03-20T10:02:39.775714Z","iopub.status.idle":"2022-03-20T10:02:39.783101Z","shell.execute_reply.started":"2022-03-20T10:02:39.775663Z","shell.execute_reply":"2022-03-20T10:02:39.782239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataRetriever(Dataset):\n    def __init__(self, paths, transform=None):\n        self.paths = paths\n        self.transform = transform\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def read_video(self, vid_paths):\n        video = [load_dicom(path) for path in vid_paths]\n        if len(video)==0:\n            video = torch.zeros(CFG.n_frames, CFG.img_size, CFG.img_size)\n        else:\n            video = torch.stack(video) # T * C * H * W\n#         video = torch.transpose(video, 0, 1) # C * T * H * W\n        return video\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{str(_id).zfill(5)}/\"\n        channels = []\n        for t in [\"FLAIR\",\"T1w\", \"T1wCE\", \"T2w\"]:\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n            num_samples = CFG.n_frames\n#             t_paths = get_valid_frames(t_paths)\n            if len(t_paths) < num_samples:\n                in_frames_path = t_paths\n            else:\n                in_frames_path = uniform_temporal_subsample(t_paths, num_samples)\n            \n            channel = self.read_video(in_frames_path)\n            if channel.shape[0] == 0:\n                print(\"1 channel empty\")\n                channel = torch.zeros(num_samples, CFG.img_size, CFG.img_size)\n            channels.append(channel)\n        \n        channels = torch.stack(channels).transpose(0,1)\n        return {\"X\": channels.float(), \"id\": _id}","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:40.386447Z","iopub.execute_input":"2022-03-20T10:02:40.386847Z","iopub.status.idle":"2022-03-20T10:02:40.398126Z","shell.execute_reply.started":"2022-03-20T10:02:40.386813Z","shell.execute_reply":"2022-03-20T10:02:40.397416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ndf.head(10)\n# df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:40.56426Z","iopub.execute_input":"2022-03-20T10:02:40.56481Z","iopub.status.idle":"2022-03-20T10:02:40.577726Z","shell.execute_reply.started":"2022-03-20T10:02:40.564765Z","shell.execute_reply":"2022-03-20T10:02:40.577014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(1, CFG.n_fold+1):\n    model = Model()\n    model.to(device)\n    checkpoint = torch.load(f\"../input/modelweights1/model1_weights/best-model-{i}.pth\")\n#     print(checkpoint[\"model_state_dict\"])\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:40.72289Z","iopub.execute_input":"2022-03-20T10:02:40.723474Z","iopub.status.idle":"2022-03-20T10:02:42.242197Z","shell.execute_reply.started":"2022-03-20T10:02:40.723439Z","shell.execute_reply":"2022-03-20T10:02:42.241308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:42.243907Z","iopub.execute_input":"2022-03-20T10:02:42.244345Z","iopub.status.idle":"2022-03-20T10:02:42.267387Z","shell.execute_reply.started":"2022-03-20T10:02:42.244252Z","shell.execute_reply":"2022-03-20T10:02:42.266762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\ntest_data_retriever = TestDataRetriever(\n    submission[\"BraTS21ID\"].values # ids in test data\n)\nprint(test_data_retriever.read_video)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=4,\n    shuffle=False,\n    num_workers=8,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:42.271195Z","iopub.execute_input":"2022-03-20T10:02:42.273172Z","iopub.status.idle":"2022-03-20T10:02:42.290959Z","shell.execute_reply.started":"2022-03-20T10:02:42.273125Z","shell.execute_reply":"2022-03-20T10:02:42.290265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_data_retriever))\nprint(test_data_retriever[85]['X'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:42.665986Z","iopub.execute_input":"2022-03-20T10:02:42.666509Z","iopub.status.idle":"2022-03-20T10:02:42.823604Z","shell.execute_reply.started":"2022-03-20T10:02:42.666471Z","shell.execute_reply":"2022-03-20T10:02:42.822788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader.batch_size\nlen(test_loader) # no. of batches","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:44.922076Z","iopub.execute_input":"2022-03-20T10:02:44.922823Z","iopub.status.idle":"2022-03-20T10:02:44.929817Z","shell.execute_reply.started":"2022-03-20T10:02:44.922776Z","shell.execute_reply":"2022-03-20T10:02:44.929038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        print(batch[\"X\"].shape)\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n#             print(tmp_pred)\n            tmp_pred += tmp_res\n            \n        tmp_pred = tmp_pred/len(models)\n        y_pred.extend(tmp_pred)\n#         print(len(y_pred))\n        ids.extend(batch[\"id\"].numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:02:45.174426Z","iopub.execute_input":"2022-03-20T10:02:45.175085Z","iopub.status.idle":"2022-03-20T10:03:04.291557Z","shell.execute_reply.started":"2022-03-20T10:02:45.175047Z","shell.execute_reply":"2022-03-20T10:03:04.290716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:16.274697Z","iopub.execute_input":"2022-03-20T09:31:16.274976Z","iopub.status.idle":"2022-03-20T09:31:16.280208Z","shell.execute_reply.started":"2022-03-20T09:31:16.274946Z","shell.execute_reply":"2022-03-20T09:31:16.27957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:16.284066Z","iopub.execute_input":"2022-03-20T09:31:16.284748Z","iopub.status.idle":"2022-03-20T09:31:16.298354Z","shell.execute_reply.started":"2022-03-20T09:31:16.284646Z","shell.execute_reply":"2022-03-20T09:31:16.297549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline 2","metadata":{"execution":{"iopub.status.busy":"2022-01-25T12:03:56.753412Z","iopub.execute_input":"2022-01-25T12:03:56.754121Z","iopub.status.idle":"2022-01-25T12:03:56.818898Z","shell.execute_reply.started":"2022-01-25T12:03:56.754083Z","shell.execute_reply":"2022-01-25T12:03:56.81747Z"}}},{"cell_type":"code","source":"pip install '../input/rsna-monai-packages/monai-0.6.0-202107081903-py3-none-any.whl'","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:16.299822Z","iopub.execute_input":"2022-03-20T09:31:16.300129Z","iopub.status.idle":"2022-03-20T09:31:45.163866Z","shell.execute_reply.started":"2022-03-20T09:31:16.300033Z","shell.execute_reply":"2022-03-20T09:31:45.163014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:45.165809Z","iopub.execute_input":"2022-03-20T09:31:45.166119Z","iopub.status.idle":"2022-03-20T09:31:46.010095Z","shell.execute_reply.started":"2022-03-20T09:31:45.166066Z","shell.execute_reply":"2022-03-20T09:31:46.009305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import roc_auc_score\nfrom torch.optim import lr_scheduler\nfrom tqdm import tqdm\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:46.011417Z","iopub.execute_input":"2022-03-20T09:31:46.011701Z","iopub.status.idle":"2022-03-20T09:31:47.36188Z","shell.execute_reply.started":"2022-03-20T09:31:46.011665Z","shell.execute_reply":"2022-03-20T09:31:47.361107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES_3D = 64\nTRAINING_BATCH_SIZE = 8\nTEST_BATCH_SIZE = 8\nIMAGE_SIZE = 256\nN_EPOCHS = 15\ndo_valid = True\nn_workers = 4\ntype_ = \"T1wCE\"","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:47.363361Z","iopub.execute_input":"2022-03-20T09:31:47.36364Z","iopub.status.idle":"2022-03-20T09:31:47.368444Z","shell.execute_reply.started":"2022-03-20T09:31:47.363603Z","shell.execute_reply":"2022-03-20T09:31:47.367679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n\n    if rotate > 0:\n        rot_choices = [\n            0,\n            cv2.ROTATE_90_CLOCKWISE,\n            cv2.ROTATE_90_COUNTERCLOCKWISE,\n            cv2.ROTATE_180,\n        ]\n        data = cv2.rotate(data, rot_choices[rotate])\n\n    data = cv2.resize(data, (img_size, img_size))\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:47.370736Z","iopub.execute_input":"2022-03-20T09:31:47.370978Z","iopub.status.idle":"2022-03-20T09:31:47.380663Z","shell.execute_reply.started":"2022-03-20T09:31:47.370945Z","shell.execute_reply":"2022-03-20T09:31:47.379847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nimport cv2\nfrom torch.utils.data import Dataset\n\n\nclass BrainRSNADataset(Dataset):\n    def __init__(\n        self, data, transform=None, target=\"MGMT_value\", mri_type=\"FLAIR\", is_train=True\n    ):\n        self.target = target\n        self.data = data\n        self.type = mri_type\n\n        self.transform = transform\n        self.is_train = is_train\n        self.folder = \"train\" if self.is_train else \"test\"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        row = self.data.loc[index]\n        case_id = int(row.BraTS21ID)\n        target = int(row[self.target])\n        _3d_images = self.load_dicom_images_3d(case_id)\n        _3d_images = torch.tensor(_3d_images).float()\n        if self.is_train:\n            return {\"image\": _3d_images, \"target\": target}\n        else:\n            return {\"image\": _3d_images, \"case_id\": case_id}\n\n    def load_dicom_images_3d(\n        self,\n        case_id,\n        num_imgs=NUM_IMAGES_3D,\n        img_size=IMAGE_SIZE,\n        rotate=0,\n    ):\n        case_id = str(case_id).zfill(5)\n\n        path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/{self.folder}/{case_id}/{self.type}/*.dcm\"\n#         path = f\"../input/brain-tumor-test/test1/test1/{case_id}/{self.type}/*.dcm\"\n        \n        files = sorted(\n            glob.glob(path),\n            key=lambda var: [\n                int(x) if x.isdigit() else x for x in re.findall(r\"[^0-9]|[0-9]+\", var)\n            ],\n        )\n\n        middle = len(files) // 2\n        num_imgs2 = num_imgs // 2\n        p1 = max(0, middle - num_imgs2)\n        p2 = min(len(files), middle + num_imgs2)\n        image_stack = [load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]\n        \n        img3d = np.stack(image_stack).T\n        if img3d.shape[-1] < num_imgs:\n            n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n            img3d = np.concatenate((img3d, n_zero), axis=-1)\n#         print(img3d.shape)\n        if np.min(img3d) < np.max(img3d):\n            img3d = img3d - np.min(img3d)\n            img3d = img3d / np.max(img3d)\n\n        return np.expand_dims(img3d, 0)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:47.382377Z","iopub.execute_input":"2022-03-20T09:31:47.38267Z","iopub.status.idle":"2022-03-20T09:31:47.549061Z","shell.execute_reply.started":"2022-03-20T09:31:47.382635Z","shell.execute_reply":"2022-03-20T09:31:47.547879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ../input/","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:47.551129Z","iopub.execute_input":"2022-03-20T09:31:47.551996Z","iopub.status.idle":"2022-03-20T09:31:48.297307Z","shell.execute_reply.started":"2022-03-20T09:31:47.551731Z","shell.execute_reply":"2022-03-20T09:31:48.296414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import monai\n\n# model \nmodel = monai.networks.nets.resnet34(spatial_dims=3, n_input_channels=1, n_classes=1)\ndevice = torch.device(\"cuda\")\nmodel.to(device);\nall_weights = os.listdir(\"../input/modelweights32/modelweights32\")\nfold_files = [f for f in all_weights if type_ in f]\n# print(np.array(fold_files).shape)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:48.29934Z","iopub.execute_input":"2022-03-20T09:31:48.299689Z","iopub.status.idle":"2022-03-20T09:31:51.126033Z","shell.execute_reply.started":"2022-03-20T09:31:48.299647Z","shell.execute_reply":"2022-03-20T09:31:51.125255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:51.127328Z","iopub.execute_input":"2022-03-20T09:31:51.127618Z","iopub.status.idle":"2022-03-20T09:31:51.135435Z","shell.execute_reply.started":"2022-03-20T09:31:51.127567Z","shell.execute_reply":"2022-03-20T09:31:51.134781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_files","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:51.136709Z","iopub.execute_input":"2022-03-20T09:31:51.137118Z","iopub.status.idle":"2022-03-20T09:31:51.14666Z","shell.execute_reply.started":"2022-03-20T09:31:51.137078Z","shell.execute_reply":"2022-03-20T09:31:51.145839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:51.148335Z","iopub.execute_input":"2022-03-20T09:31:51.148717Z","iopub.status.idle":"2022-03-20T09:31:51.157191Z","shell.execute_reply.started":"2022-03-20T09:31:51.148626Z","shell.execute_reply":"2022-03-20T09:31:51.156562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tta_true_labels = []\ntta_preds = []\ntest_dataset = BrainRSNADataset(data=sample, mri_type=type_, is_train=False)\ntest_dl = torch.utils.data.DataLoader(\n        test_dataset, batch_size=8, shuffle=False, num_workers=4\n    )\n\npreds_f = np.zeros(len(sample))\nfor fold in range(5):\n    image_ids = []\n    model.load_state_dict(torch.load(f\"../input/modelweights32/modelweights32/{fold_files[fold]}\"))\n    preds = []\n    epoch_iterator_test = tqdm(test_dl)\n    with torch.no_grad():\n        for  step, batch in enumerate(epoch_iterator_test):\n            model.eval()\n            images = batch[\"image\"].to(device)\n            print(batch[\"image\"].shape)\n            outputs = model(images)\n            preds.append(outputs.sigmoid().detach().cpu().numpy())\n            image_ids.append(batch[\"case_id\"].detach().cpu().numpy())\n    \n\n    preds_f += np.vstack(preds).T[0]/5\n\n    ids_f = np.hstack(image_ids)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:31:51.158228Z","iopub.execute_input":"2022-03-20T09:31:51.161609Z","iopub.status.idle":"2022-03-20T09:34:10.598771Z","shell.execute_reply.started":"2022-03-20T09:31:51.161564Z","shell.execute_reply":"2022-03-20T09:34:10.597367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(np.array(test_dataset).shape)\ntest_dataset[40]['image'].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.600409Z","iopub.execute_input":"2022-03-20T09:34:10.600957Z","iopub.status.idle":"2022-03-20T09:34:10.863914Z","shell.execute_reply.started":"2022-03-20T09:34:10.600911Z","shell.execute_reply":"2022-03-20T09:34:10.863091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample[\"BraTS21ID\"] = ids_f\nsample[\"MGMT_value\"] = preds_f","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.865223Z","iopub.execute_input":"2022-03-20T09:34:10.866082Z","iopub.status.idle":"2022-03-20T09:34:10.871519Z","shell.execute_reply.started":"2022-03-20T09:34:10.866039Z","shell.execute_reply":"2022-03-20T09:34:10.870628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = sample.sort_values(by=\"BraTS21ID\").reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.874525Z","iopub.execute_input":"2022-03-20T09:34:10.874887Z","iopub.status.idle":"2022-03-20T09:34:10.885161Z","shell.execute_reply.started":"2022-03-20T09:34:10.874843Z","shell.execute_reply":"2022-03-20T09:34:10.88436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission2.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.88729Z","iopub.execute_input":"2022-03-20T09:34:10.888188Z","iopub.status.idle":"2022-03-20T09:34:10.892143Z","shell.execute_reply.started":"2022-03-20T09:34:10.888143Z","shell.execute_reply":"2022-03-20T09:34:10.891109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.89391Z","iopub.execute_input":"2022-03-20T09:34:10.894659Z","iopub.status.idle":"2022-03-20T09:34:10.910855Z","shell.execute_reply.started":"2022-03-20T09:34:10.894615Z","shell.execute_reply":"2022-03-20T09:34:10.909793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline 1","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \n# TRAIN_PATH = '../input/rsna-miccai-png/train'\nTEST_PATH = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test'","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.917859Z","iopub.execute_input":"2022-03-20T09:34:10.918086Z","iopub.status.idle":"2022-03-20T09:34:10.923364Z","shell.execute_reply.started":"2022-03-20T09:34:10.918045Z","shell.execute_reply":"2022-03-20T09:34:10.922302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='efficientnet_b4'\n    size=512\n    batch_size=4\n    seed=42\n    target_size=2\n    target_col='MGMT_value'\n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    inference=True","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.92516Z","iopub.execute_input":"2022-03-20T09:34:10.925576Z","iopub.status.idle":"2022-03-20T09:34:10.933423Z","shell.execute_reply.started":"2022-03-20T09:34:10.925534Z","shell.execute_reply":"2022-03-20T09:34:10.932444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Imports\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:10.935038Z","iopub.execute_input":"2022-03-20T09:34:10.935514Z","iopub.status.idle":"2022-03-20T09:34:12.728699Z","shell.execute_reply.started":"2022-03-20T09:34:10.935285Z","shell.execute_reply":"2022-03-20T09:34:12.727832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.73086Z","iopub.execute_input":"2022-03-20T09:34:12.731278Z","iopub.status.idle":"2022-03-20T09:34:12.737487Z","shell.execute_reply.started":"2022-03-20T09:34:12.731237Z","shell.execute_reply":"2022-03-20T09:34:12.736797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test')\n# print(np.array(test).shape)\ntest = pd.DataFrame({'BraTS21ID' : test})\n# print(test)\ntest['BraTS21ID'] = test['BraTS21ID'].astype(int)\ntest","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.740209Z","iopub.execute_input":"2022-03-20T09:34:12.740431Z","iopub.status.idle":"2022-03-20T09:34:12.762003Z","shell.execute_reply.started":"2022-03-20T09:34:12.740405Z","shell.execute_reply":"2022-03-20T09:34:12.761275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['BraTS21ID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        root = f'{TEST_PATH}/{str(self.file_names[idx]).zfill(5)}/'\n        com = []\n        for typ in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n            paths = os.listdir(root + typ)\n            rnd = random.sample(paths, min(10, len(paths)))\n            typ_imgs = []\n            for f in rnd:\n                file_path = f'{root}{typ}/{f}'\n                dicom = pydicom.read_file(file_path)\n                data = apply_voi_lut(dicom.pixel_array, dicom)\n                if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n                    data = np.amax(data) - data\n                data = data - np.min(data)\n                data = data / np.max(data)\n                image = (data * 255).astype(np.uint8)\n                typ_imgs.append(cv2.resize(image, (CFG.size, CFG.size)))\n            com.append(np.mean(typ_imgs, axis = 0))\n        image = np.array(com).transpose((1,2,0)) / 255\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            image = image.float()\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.763027Z","iopub.execute_input":"2022-03-20T09:34:12.763267Z","iopub.status.idle":"2022-03-20T09:34:12.774185Z","shell.execute_reply.started":"2022-03-20T09:34:12.763234Z","shell.execute_reply":"2022-03-20T09:34:12.773481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.775576Z","iopub.execute_input":"2022-03-20T09:34:12.776402Z","iopub.status.idle":"2022-03-20T09:34:12.784377Z","shell.execute_reply.started":"2022-03-20T09:34:12.776364Z","shell.execute_reply":"2022-03-20T09:34:12.783729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.conv = nn.Conv2d(4,3,1)\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n#         print(n_features)\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.786349Z","iopub.execute_input":"2022-03-20T09:34:12.786795Z","iopub.status.idle":"2022-03-20T09:34:12.794033Z","shell.execute_reply.started":"2022-03-20T09:34:12.786757Z","shell.execute_reply":"2022-03-20T09:34:12.793225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\ndef load_state_eff(model_path):\n    state_dict = torch.load(model_path)['model']\n    return state_dict\n\ndef inference(model_eff, states, test_loader, device):\n    model_eff.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        x=1\n        for state in states:\n            model_eff.load_state_dict(state)\n            model_eff.eval()\n            with torch.no_grad():\n                y_preds = model_eff(images)\n#                 print(images.shape) # (4, 4, 512, 512)\n                print(y_preds.shape) # (4, 2)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy()) # append (4, 2) 5 times \n            x+=1\n#         print(np.array(avg_preds).shape)    # (5, 4, 2) -> 5 folds \n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.79534Z","iopub.execute_input":"2022-03-20T09:34:12.795605Z","iopub.status.idle":"2022-03-20T09:34:12.805688Z","shell.execute_reply.started":"2022-03-20T09:34:12.79557Z","shell.execute_reply":"2022-03-20T09:34:12.805033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eff = CustomEfficientNet(CFG.model_name, pretrained=False)\n\nstates = [load_state_eff('../input/modelweights2/model2_weights/efficientnet_b4_fold0_best.pth'),\n          load_state_eff('../input/modelweights2/model2_weights/efficientnet_b4_fold1_best.pth'),\n          load_state_eff('../input/modelweights2/model2_weights/efficientnet_b4_fold2_best.pth'),\n          load_state_eff('../input/modelweights2/model2_weights/efficientnet_b4_fold3_best.pth'),\n          load_state_eff('../input/modelweights2/model2_weights/efficientnet_b4_fold4_best.pth'),\n]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:12.807048Z","iopub.execute_input":"2022-03-20T09:34:12.807329Z","iopub.status.idle":"2022-03-20T09:34:23.459381Z","shell.execute_reply.started":"2022-03-20T09:34:12.807294Z","shell.execute_reply":"2022-03-20T09:34:23.45863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eff","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:23.462555Z","iopub.execute_input":"2022-03-20T09:34:23.462762Z","iopub.status.idle":"2022-03-20T09:34:23.476077Z","shell.execute_reply.started":"2022-03-20T09:34:23.462737Z","shell.execute_reply":"2022-03-20T09:34:23.475261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\n\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model_eff, states, test_loader, device)\n\n# submission\ntest['MGMT_value'] = predictions[:,1]\n# test[['BraTS21ID', 'MGMT_value']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()\nsubmission3 = test[['BraTS21ID', 'MGMT_value']]\n# submission3.to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# submission3.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:23.477671Z","iopub.execute_input":"2022-03-20T09:34:23.478212Z","iopub.status.idle":"2022-03-20T09:34:53.885937Z","shell.execute_reply.started":"2022-03-20T09:34:23.478176Z","shell.execute_reply":"2022-03-20T09:34:53.885179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission3 = submission3.sort_values(by=\"BraTS21ID\").reset_index(drop=True)\nsubmission3","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:53.887743Z","iopub.execute_input":"2022-03-20T09:34:53.888003Z","iopub.status.idle":"2022-03-20T09:34:53.901283Z","shell.execute_reply.started":"2022-03-20T09:34:53.887964Z","shell.execute_reply":"2022-03-20T09:34:53.90051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Submission","metadata":{}},{"cell_type":"code","source":"final = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\nfinal.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:53.903106Z","iopub.execute_input":"2022-03-20T09:34:53.90364Z","iopub.status.idle":"2022-03-20T09:34:53.920142Z","shell.execute_reply.started":"2022-03-20T09:34:53.903597Z","shell.execute_reply":"2022-03-20T09:34:53.919424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final[\"MGMT_value\"] = (0.2*submission1[\"MGMT_value\"] + 0.5*submission2[\"MGMT_value\"] + 0.3*submission3[\"MGMT_value\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:53.921137Z","iopub.execute_input":"2022-03-20T09:34:53.921333Z","iopub.status.idle":"2022-03-20T09:34:53.92768Z","shell.execute_reply.started":"2022-03-20T09:34:53.921309Z","shell.execute_reply":"2022-03-20T09:34:53.926918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.to_csv(\"submission.csv\", index=False)\nfinal","metadata":{"execution":{"iopub.status.busy":"2022-03-20T09:34:53.929382Z","iopub.execute_input":"2022-03-20T09:34:53.930023Z","iopub.status.idle":"2022-03-20T09:34:53.94814Z","shell.execute_reply.started":"2022-03-20T09:34:53.929981Z","shell.execute_reply":"2022-03-20T09:34:53.947382Z"},"trusted":true},"execution_count":null,"outputs":[]}]}