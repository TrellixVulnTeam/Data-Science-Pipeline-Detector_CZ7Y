{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyradiomics","metadata":{"execution":{"iopub.status.busy":"2021-10-15T00:55:10.122382Z","iopub.execute_input":"2021-10-15T00:55:10.12282Z","iopub.status.idle":"2021-10-15T00:55:22.91624Z","shell.execute_reply.started":"2021-10-15T00:55:10.122718Z","shell.execute_reply":"2021-10-15T00:55:22.914952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys \nfrom tqdm import tqdm \nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport pydicom\nimport torch\nimport nibabel as nib\nimport matplotlib.pyplot as plt\nimport SimpleITK as sitk\nimport radiomics\nimport cv2\nfrom PIL import Image\nimport pydicom as dicom\nfrom pydicom.dataset import Dataset, FileDataset\nfrom pydicom.uid import ExplicitVRLittleEndian\nimport pydicom._storage_sopclass_uids\nfrom pydicom.uid import RLELossless\nimport tensorflow as tf\n\ntrain_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/'","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:05.469113Z","iopub.execute_input":"2021-10-15T01:19:05.469508Z","iopub.status.idle":"2021-10-15T01:19:05.478154Z","shell.execute_reply.started":"2021-10-15T01:19:05.469474Z","shell.execute_reply":"2021-10-15T01:19:05.476882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_dirs is a list of patient ids\ntrain_dirs = sorted(os.listdir(train_path))\n#reads series of files\nreader = sitk.ImageSeriesReader()\n#keeps the private metadata required for the files\nreader.LoadPrivateTagsOn()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:09.319447Z","iopub.execute_input":"2021-10-15T01:19:09.319864Z","iopub.status.idle":"2021-10-15T01:19:09.371014Z","shell.execute_reply.started":"2021-10-15T01:19:09.319829Z","shell.execute_reply":"2021-10-15T01:19:09.369957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dirs))","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:10.972219Z","iopub.execute_input":"2021-10-15T01:19:10.972602Z","iopub.status.idle":"2021-10-15T01:19:10.97749Z","shell.execute_reply.started":"2021-10-15T01:19:10.972571Z","shell.execute_reply":"2021-10-15T01:19:10.976356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resample(image, ref_image):\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear)\n    \n    resampler.SetTransform(sitk.AffineTransform(image.GetDimension()))\n\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n\n    resampler.SetSize(ref_image.GetSize())\n\n    resampler.SetOutputDirection(ref_image.GetDirection())\n\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n\n    resamped_image = resampler.Execute(image)\n    \n    return resamped_image","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:11.932715Z","iopub.execute_input":"2021-10-15T01:19:11.933078Z","iopub.status.idle":"2021-10-15T01:19:11.940437Z","shell.execute_reply.started":"2021-10-15T01:19:11.933046Z","shell.execute_reply":"2021-10-15T01:19:11.939553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(data):\n    return (data - np.min(data)) / (np.max(data) - np.min(data))","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:13.963531Z","iopub.execute_input":"2021-10-15T01:19:13.964101Z","iopub.status.idle":"2021-10-15T01:19:13.968995Z","shell.execute_reply.started":"2021-10-15T01:19:13.96405Z","shell.execute_reply":"2021-10-15T01:19:13.967688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef get_img(index):\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/T1w')\n    #print(\"Number of dicom files in T1w : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    t1_sitk = reader.Execute()\n    #print(t1_sitk)\n\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/FLAIR')\n    #print(\"Number of dicom files in FLAIR : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    flair_sitk = reader.Execute()\n    #print(flair_sitk)\n\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/T1wCE')\n    #print(\"Number of dicom files in T1wCE : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    t1wce_sitk = reader.Execute()\n    #print(t1wce_sitk)\n\n    flair_resampled = resample(flair_sitk, t1_sitk)\n    #print(flair_resampled)\n    t1wce_resampled = resample(t1wce_sitk, t1_sitk)\n\n    t1_sitk_array = normalize(sitk.GetArrayFromImage(t1_sitk))\n    flair_resampled_array = normalize(sitk.GetArrayFromImage(flair_resampled))\n    t1wce_resampled_array = normalize(sitk.GetArrayFromImage(t1wce_resampled))\n    \n    #print(t1_sitk_array.shape)\n    #print(flair_resampled_array.shape)\n    #print(t1wce_resampled_array.shape)\n\n    stacked = np.stack([t1_sitk_array, flair_resampled_array, t1wce_resampled_array])\n\n    to_rgb = stacked[:,t1_sitk_array.shape[0]//2,:,:].transpose(1,2,0)\n    im = Image.fromarray((to_rgb * 255).astype(np.uint8))\n    return im","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:14.319552Z","iopub.execute_input":"2021-10-15T01:19:14.319933Z","iopub.status.idle":"2021-10-15T01:19:14.329547Z","shell.execute_reply.started":"2021-10-15T01:19:14.319901Z","shell.execute_reply":"2021-10-15T01:19:14.328736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n    in_channels=3, out_channels=1, init_features=32, pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:15.979733Z","iopub.execute_input":"2021-10-15T01:19:15.980224Z","iopub.status.idle":"2021-10-15T01:19:16.205502Z","shell.execute_reply.started":"2021-10-15T01:19:15.980177Z","shell.execute_reply":"2021-10-15T01:19:16.204566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install einops","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:17.721366Z","iopub.execute_input":"2021-10-15T01:19:17.721743Z","iopub.status.idle":"2021-10-15T01:19:27.590792Z","shell.execute_reply.started":"2021-10-15T01:19:17.721711Z","shell.execute_reply":"2021-10-15T01:19:27.589221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def center_crop(img, dim):\n    \"\"\"Returns center cropped image\n    Args:\n    img: image to be center cropped\n    dim: dimensions (width, height) to be cropped\n    \"\"\"                                                                                      \n    width, height = img.shape[1], img.shape[0]\n\n    # process crop width and height for max available dimension\n    crop_width = dim[0] if dim[0]<img.shape[1] else img.shape[1]\n    crop_height = dim[1] if dim[1]<img.shape[0] else img.shape[0] \n    mid_x, mid_y = int(width/2), int(height/2)\n    cw2, ch2 = int(crop_width/2), int(crop_height/2) \n    crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n    return crop_img                                                                              \n\ndef undesired_objects (image):\n    image = image.astype('uint8')\n    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image,connectivity=8)\n    sizes = stats[:, -1]\n    \n\n\n    max_label = 1\n    max_size = sizes[1]\n    for i in range(2, nb_components):\n        if sizes[i] > max_size:\n            max_label = i\n            max_size = sizes[i]\n    \n    \n    \n    img2 = np.zeros(output.shape)\n    img2[output == max_label] = 255\n \n    \n    truncated.append(img2)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:27.592946Z","iopub.execute_input":"2021-10-15T01:19:27.593358Z","iopub.status.idle":"2021-10-15T01:19:27.605164Z","shell.execute_reply.started":"2021-10-15T01:19:27.593317Z","shell.execute_reply":"2021-10-15T01:19:27.603907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CROPPING THE IMAGE","metadata":{}},{"cell_type":"code","source":"'''\nfrom einops import rearrange, reduce, repeat\n\nfor ind in range(0,30):    \n    im = get_img(int(train_dirs[ind]))\n    print(train_dirs[int(train_dirs[ind])])\n    test_img = np.array([np.moveaxis(np.array(im.resize((256, 256))), -1, 0)])\n    test_img = (center_crop(test_img[0, 1, :, :],(160,180)))\n    test_img = cv2.resize(test_img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n    test_img = cv2.merge((test_img, test_img, test_img))\n    test_img = np.expand_dims(test_img, axis=0)\n    input_tensor = torch.Tensor(test_img)\n    input_tensor = rearrange(input_tensor, 'b h w c -> b c h w')\n    print(input_tensor.shape)\n    #test_img = np.array([np.moveaxis(np.array(im.resize((256, 256))), -1, 0)])\n    #print(test_img.shape)\n    \n    \n    test_res = model(input_tensor)\n\n    #largest connected contour\n    response_array = test_res.detach().numpy()\n    response_array = np.reshape(response_array,(256,256))\n    temp = response_array\n    truncated = []\n    undesired_objects(response_array)\n    \n    kernel = np.ones((5, 5), 'uint8')\n    truncated[0] = cv2.dilate(truncated[0],kernel,iterations = 10)\n    \n    \n    #draw bounding box on the largest contour\n    truncated[0] = truncated[0].astype('uint8')\n    bounding_boxes = []\n    contours, hierarchy = cv2.findContours(truncated[0],cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    idx =0 \n    for cnt in contours:\n        idx += 1\n        x,y,w,h = cv2.boundingRect(cnt)\n        cv2.rectangle(truncated[0],(x,y),(x+w,y+h),(200,0,0),2)\n    bounding_boxes.append(truncated[0])\n    \n    image_rectangles[int(train_dirs[ind])] = [x,y,w,h]\n    \n\n\n    f, axarr = plt.subplots(2,2, figsize=(20, 20))\n    axarr[0][0].imshow(input_tensor[0, 1, :, :].detach().cpu().numpy())\n    axarr[0][1].imshow(test_res[0][0].detach().cpu().numpy() > 0.5)\n    axarr[1][0].imshow(truncated[0])\n\n\n    #map the bounding box to the original image\n    marked_image = input_tensor.detach().cpu().numpy()\n    marked_image = np.ascontiguousarray(marked_image, dtype=np.uint8)\n    print(type(marked_image))\n    cv2.rectangle(marked_image[0, 1, :, :],(x,y),(x+w,y+h),(0,50,50),2)\n\n\n    \n    axarr[1][1].imshow(marked_image[0, 1, :, :])\n\n'''","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:27.606975Z","iopub.execute_input":"2021-10-15T01:19:27.607355Z","iopub.status.idle":"2021-10-15T01:19:27.627395Z","shell.execute_reply.started":"2021-10-15T01:19:27.607318Z","shell.execute_reply":"2021-10-15T01:19:27.626003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"NON-CROPPED IMAGE","metadata":{}},{"cell_type":"code","source":"def numpyToDicom(image2d,index,path):\n    \n    image2d = image2d.astype(np.uint16)\n\n    #print(\"Setting file meta information...\")\n    # Populate required values for file meta information\n\n    meta = pydicom.Dataset()\n    meta.MediaStorageSOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n    meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n    meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian  \n\n    ds = Dataset()\n    ds.file_meta = meta\n\n    ds.is_little_endian = True\n    ds.is_implicit_VR = False\n\n    ds.SOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n    ds.PatientName = \"Test^Firstname\"\n    ds.PatientID = \"123456\"\n\n    ds.Modality = \"MR\"\n    ds.SeriesInstanceUID = pydicom.uid.generate_uid()\n    ds.StudyInstanceUID = pydicom.uid.generate_uid()\n    ds.FrameOfReferenceUID = pydicom.uid.generate_uid()\n\n    ds.BitsStored = 16\n    ds.BitsAllocated = 16\n    ds.SamplesPerPixel = 1\n    ds.HighBit = 15\n\n    ds.ImagesInAcquisition = \"1\"\n\n    ds.Rows = image2d.shape[0]\n    ds.Columns = image2d.shape[1]\n    ds.InstanceNumber = 1\n\n    ds.ImagePositionPatient = r\"0\\0\\1\"\n    ds.ImageOrientationPatient = r\"1\\0\\0\\0\\-1\\0\"\n    ds.ImageType = r\"ORIGINAL\\PRIMARY\\AXIAL\"\n\n    ds.RescaleIntercept = \"0\"\n    ds.RescaleSlope = \"1\"\n    ds.PixelSpacing = r\"1\\1\"\n    ds.PhotometricInterpretation = \"MONOCHROME2\"\n    ds.PixelRepresentation = 1\n\n    pydicom.dataset.validate_file_meta(ds.file_meta, enforce_standard=True)\n\n    #print(\"Setting pixel data...\")\n    ds.PixelData = image2d.tobytes()\n    ds.save_as(path + str(index)+'.dcm')","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:27.629213Z","iopub.execute_input":"2021-10-15T01:19:27.629628Z","iopub.status.idle":"2021-10-15T01:19:27.643305Z","shell.execute_reply.started":"2021-10-15T01:19:27.629563Z","shell.execute_reply":"2021-10-15T01:19:27.642039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_rectangles = {}\n","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:27.645251Z","iopub.execute_input":"2021-10-15T01:19:27.645907Z","iopub.status.idle":"2021-10-15T01:19:27.657801Z","shell.execute_reply.started":"2021-10-15T01:19:27.645871Z","shell.execute_reply":"2021-10-15T01:19:27.656979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ind in range(0,585):\n    print(int(train_dirs[ind]))\n    im = get_img(ind)\n    \n    test_img = np.array([np.moveaxis(np.array(im.resize((256, 256))), -1, 0)])\n    test_res = model(torch.Tensor(test_img))\n\n    #largest connected contour\n    response_array = test_res.detach().numpy()\n    response_array = np.reshape(response_array,(256,256))\n    temp = response_array\n    truncated = []\n    undesired_objects(response_array)\n    \n    kernel = np.ones((5, 5), 'uint8')\n    truncated[0] = cv2.dilate(truncated[0],kernel,iterations = 10)\n\n    #draw bounding box on the largest contour\n    truncated[0] = truncated[0].astype('uint8')\n    bounding_boxes = []\n    contours, hierarchy = cv2.findContours(truncated[0],cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    idx =0 \n    for cnt in contours:\n        idx += 1\n        x,y,w,h = cv2.boundingRect(cnt)\n        roi=truncated[0][y:y+h,x:x+w]\n        #v2.imwrite(str(idx) + '.jpg', roi)\n        cv2.rectangle(truncated[0],(x,y),(x+w,y+h),(200,0,0),2)\n    bounding_boxes.append(truncated[0])\n    \n    image_rectangles[int(train_dirs[ind])] = [x,y,w,h]\n    \n\n\n\n    #f, axarr = plt.subplots(2,2, figsize=(20, 20))\n    #axarr[0][0].imshow(test_img[0, 1, :, :])\n    #axarr[0][1].imshow(test_res[0][0].detach().cpu().numpy() > 0.5)\n\n\n    #map the bounding box to the original image\n    #marked_image = test_img\n    #print(type(test_img))\n    #cv2.rectangle(marked_image[0, 1, :, :],(x,y),(x+w,y+h),(0,50,50),2)\n\n\n    #axarr[1][0].imshow(truncated[0])\n    #axarr[1][1].imshow(marked_image[0, 1, :, :])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:19:29.717666Z","iopub.execute_input":"2021-10-15T01:19:29.71805Z","iopub.status.idle":"2021-10-15T02:17:43.028541Z","shell.execute_reply.started":"2021-10-15T01:19:29.717993Z","shell.execute_reply":"2021-10-15T02:17:43.021777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(image_rectangles)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T02:17:55.18702Z","iopub.execute_input":"2021-10-15T02:17:55.187415Z","iopub.status.idle":"2021-10-15T02:17:55.194403Z","shell.execute_reply.started":"2021-10-15T02:17:55.187383Z","shell.execute_reply":"2021-10-15T02:17:55.193303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"st = []","metadata":{"execution":{"iopub.status.busy":"2021-10-15T02:17:58.173758Z","iopub.execute_input":"2021-10-15T02:17:58.174137Z","iopub.status.idle":"2021-10-15T02:17:58.178279Z","shell.execute_reply.started":"2021-10-15T02:17:58.174108Z","shell.execute_reply":"2021-10-15T02:17:58.177476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef load_img(index):\n    \n    '''\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/T1w')\n    \n    #print(filenamesDICOM[0])\n    \n    print(\"Patient id = \"+str(train_dirs[index]))\n    print(\"Number of dicom files in T1w : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    os.mkdir('./test_final/'+train_dirs[index]+'/T1w/')\n    path = './test_final/'+train_dirs[index]+'/T1w/'\n    \n    t1_sitk = reader.Execute()\n    \n    \n    cntr = 0\n    \n    lnn = len(filenamesDICOM)\n    \n    mid = int(lnn/2)\n    \n    j = min(mid+32,lnn)\n    i = max(mid-32,0)\n    \n\n    for k in range(i,j):\n        ds = dicom.dcmread(filenamesDICOM[k])\n        img = ds.pixel_array\n        #print(img.shape)\n        \n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        l = image_rectangles[int(train_dirs[index])]\n        x = l[0]\n        y = l[1]\n        w = l[2]\n        h = l[3]\n        img = img[x:x+w,y:y+w]\n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        #cv2.imwrite(str(cntr) + '.jpg', img)\n        #numpyToDicom(img,cntr,path)\n        #cv2.imwrite(os.path.join(path , str(cntr) + '.jpg'), img)\n        #tfrecord_writer = tf.io.TFRecordWriter('./test_final/'+train_dirs[index]+'/T1w/'+str(cntr)+'.tfrecord')\n        st.append(img)\n        #print(stk.shape)\n        #example = tf.train.Example(features=tf.train.Features(feature={'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img.tobytes()]))}))\n        \n        #tfrecord_writer.write(example.SerializeToString())\n        cntr += 1\n    \n      \n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/FLAIR')\n    print(\"Patient id = \"+str(train_dirs[index]))\n    print(\"Number of dicom files in FLAIR : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    #os.mkdir('./test_train/'+train_dirs[index]+'/T1w/')\n    #os.mkdir('./test_final/'+train_dirs[index]+'/FLAIR/')\n    #path = './test_final/'+train_dirs[index]+'/FLAIR/'\n    t1_sitk = reader.Execute()\n    \n    \n    cntr = 0\n    \n    \n    lnn = len(filenamesDICOM)\n    \n    mid = int(lnn/2)\n    \n    j = min(mid+32,lnn)\n    i = max(mid-32,0)\n    \n\n    for k in range(i,j):\n        ds = dicom.dcmread(filenamesDICOM[k])\n        img = ds.pixel_array\n        #print(img.shape)\n        \n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        l = image_rectangles[int(train_dirs[index])]\n        x = l[0]\n        y = l[1]\n        w = l[2]\n        h = l[3]\n        img = img[x:x+w,y:y+w]\n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        #cv2.imwrite(str(cntr) + '.jpg', img)\n        #cv2.imwrite(os.path.join(path , str(cntr) + '.jpg'), img)\n        #numpyToDicom(img,cntr,path)\n        st.append(img)\n        \n        cntr += 1\n\n    '''\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/T1wCE')\n    #print(\"Patient id = \"+str(train_dirs[index]))\n    #print(\"Number of dicom files in T1wCE : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    #os.mkdir('./test_train/'+train_dirs[index]+'/T1w/')\n    #os.mkdir('./test_final/'+train_dirs[index]+'/T1wCE/')\n    path = './test_final/'+train_dirs[index]+'/T1wCE/'\n    t1_sitk = reader.Execute()\n    \n    \n    cntr = 0\n    \n    lnn = len(filenamesDICOM)\n    \n    mid = int(lnn/2)\n    \n    j = min(mid+32,lnn)\n    i = max(mid-32,0)\n    \n\n    for k in range(i,j):\n        ds = dicom.dcmread(filenamesDICOM[k])\n        img = ds.pixel_array\n        #print(img.shape)\n        \n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        l = image_rectangles[int(train_dirs[index])]\n        x = l[0]\n        y = l[1]\n        w = l[2]\n        h = l[3]\n        img = img[x:x+w,y:y+w]\n        img = cv2.resize(img, dsize=(1024, 1024), interpolation=cv2.INTER_CUBIC)\n        #cv2.imwrite(str(cntr) + '.jpg', img)\n        #cv2.imwrite(os.path.join(path , str(cntr) + '.jpg'), img)\n        #numpyToDicom(img,cntr,path)\n        st.append(img)\n        cntr += 1\n\n    '''\n    \n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{train_path}/{train_dirs[index]}/T2w')\n    print(\"Patient id = \"+str(train_dirs[index]))\n    print(\"Number of dicom files in T2w : \"+ str(len(filenamesDICOM)))\n    reader.SetFileNames(filenamesDICOM)\n    #os.mkdir('./test_train/'+train_dirs[index]+'/T1w/')\n    os.mkdir('./test_final/'+train_dirs[index]+'/T2w/')\n    path = './test_final/'+train_dirs[index]+'/T2w/'\n    t1_sitk = reader.Execute()\n    \n    \n    cntr = 0\n    \n    lnn = len(filenamesDICOM)\n    \n    mid = int(lnn/2)\n    \n    j = min(mid+32,lnn)\n    i = max(mid-32,0)\n    \n\n    for k in range(i,j):\n        ds = dicom.dcmread(filenamesDICOM[k])\n        img = ds.pixel_array\n        #print(img.shape)\n        \n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        l = image_rectangles[int(train_dirs[index])]\n        x = l[0]\n        y = l[1]\n        w = l[2]\n        h = l[3]\n        img = img[x:x+w,y:y+w]\n        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n        #cv2.imwrite(str(cntr) + '.jpg', img)\n        #cv2.imwrite(os.path.join(path , str(cntr) + '.jpg'), img)\n        #numpyToDicom(img,cntr,path)\n        st.append(img)\n        cntr += 1\n\n        \n      '''","metadata":{"execution":{"iopub.status.busy":"2021-10-15T02:20:03.681765Z","iopub.execute_input":"2021-10-15T02:20:03.682274Z","iopub.status.idle":"2021-10-15T02:20:03.695192Z","shell.execute_reply.started":"2021-10-15T02:20:03.682242Z","shell.execute_reply":"2021-10-15T02:20:03.69405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\ndir_path = './test_final'\n\ntry:\n    shutil.rmtree(dir_path)\nexcept OSError as e:\n    print(\"Error: %s : %s\" % (dir_path, e.strerror))\n\nos.mkdir('./test_final/')","metadata":{"execution":{"iopub.status.busy":"2021-10-15T02:20:04.945877Z","iopub.execute_input":"2021-10-15T02:20:04.946247Z","iopub.status.idle":"2021-10-15T02:20:04.952313Z","shell.execute_reply.started":"2021-10-15T02:20:04.946214Z","shell.execute_reply":"2021-10-15T02:20:04.950968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(0,585)):\n    #os.mkdir('./test_final/'+train_dirs[i]+'/')\n    #print(i)\n    load_img(i)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T02:23:36.749357Z","iopub.execute_input":"2021-10-15T02:23:36.749861Z","iopub.status.idle":"2021-10-15T02:23:36.830088Z","shell.execute_reply.started":"2021-10-15T02:23:36.749752Z","shell.execute_reply":"2021-10-15T02:23:36.828519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('Test_Final','zip','./test_final')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:29:41.84797Z","iopub.execute_input":"2021-10-14T23:29:41.848478Z","iopub.status.idle":"2021-10-14T23:29:41.852944Z","shell.execute_reply.started":"2021-10-14T23:29:41.848446Z","shell.execute_reply":"2021-10-14T23:29:41.851832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(st)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:11:44.267321Z","iopub.execute_input":"2021-10-15T01:11:44.267963Z","iopub.status.idle":"2021-10-15T01:11:44.276576Z","shell.execute_reply.started":"2021-10-15T01:11:44.267905Z","shell.execute_reply":"2021-10-15T01:11:44.275401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-15T00:19:46.5833Z","iopub.execute_input":"2021-10-15T00:19:46.583761Z","iopub.status.idle":"2021-10-15T00:19:46.655722Z","shell.execute_reply.started":"2021-10-15T00:19:46.583724Z","shell.execute_reply":"2021-10-15T00:19:46.654222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stkk = np.array(st)\nprint(stkk[0].shape)\nplt.imshow(stkk[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:11:49.625879Z","iopub.execute_input":"2021-10-15T01:11:49.62648Z","iopub.status.idle":"2021-10-15T01:11:54.505304Z","shell.execute_reply.started":"2021-10-15T01:11:49.626444Z","shell.execute_reply":"2021-10-15T01:11:54.504145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfrecord_writer = tf.io.TFRecordWriter('./T1wce-TRAIN.tfrecord')\nfor image in tqdm(stkk):\n    example = tf.train.Example(features=tf.train.Features(feature={'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image.tobytes()]))}))\n    tfrecord_writer.write(example.SerializeToString())\ntfrecord_writer.close()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:11:58.9948Z","iopub.execute_input":"2021-10-15T01:11:58.995492Z","iopub.status.idle":"2021-10-15T01:12:05.433321Z","shell.execute_reply.started":"2021-10-15T01:11:58.995448Z","shell.execute_reply":"2021-10-15T01:12:05.432112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_fn(record_bytes):\n    return tf.io.parse_single_example(record_bytes,\n      {\"image\": tf.io.FixedLenFeature([], dtype=tf.string, default_value='')\n      })\n        #shape_h': tf.io.FixedLenFeature([], dtype=tf.int64, default_value=0),\n        #shape_w': tf.io.FixedLenFeature([], dtype=tf.int64, default_value=0)})\n        #'type': tf.io.FixedLenFeature([], dtype=tf.string, default_value='')})","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:12:09.054402Z","iopub.execute_input":"2021-10-15T01:12:09.054823Z","iopub.status.idle":"2021-10-15T01:12:09.06199Z","shell.execute_reply.started":"2021-10-15T01:12:09.054783Z","shell.execute_reply":"2021-10-15T01:12:09.060693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parsed_dataset = tf.data.TFRecordDataset(\"./T1w-FLAIR-T2w.tfrecord\").map(decode_fn)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:12:56.1723Z","iopub.execute_input":"2021-10-15T01:12:56.172716Z","iopub.status.idle":"2021-10-15T01:12:56.196999Z","shell.execute_reply.started":"2021-10-15T01:12:56.172679Z","shell.execute_reply":"2021-10-15T01:12:56.195939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for parsed_record in tqdm(parsed_dataset):\n    image = tf.io.decode_raw(parsed_record['image'], out_type=tf.float32)\n    image = tf.reshape(image, [256, 256])\n    print(image.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-10-15T01:12:57.335729Z","iopub.execute_input":"2021-10-15T01:12:57.336161Z","iopub.status.idle":"2021-10-15T01:12:57.381294Z","shell.execute_reply.started":"2021-10-15T01:12:57.336128Z","shell.execute_reply":"2021-10-15T01:12:57.380146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\ndir_path = './T1WCE.tfrecord'\n\ntry:\n    shutil.rmtree(dir_path)\nexcept OSError as e:\n    print(\"Error: %s : %s\" % (dir_path, e.strerror))","metadata":{"execution":{"iopub.status.busy":"2021-10-15T00:19:12.185239Z","iopub.execute_input":"2021-10-15T00:19:12.186028Z","iopub.status.idle":"2021-10-15T00:19:12.203003Z","shell.execute_reply.started":"2021-10-15T00:19:12.185857Z","shell.execute_reply":"2021-10-15T00:19:12.20214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove('./Test_Final.zip')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:38:52.16533Z","iopub.execute_input":"2021-10-14T23:38:52.165863Z","iopub.status.idle":"2021-10-14T23:38:52.170126Z","shell.execute_reply.started":"2021-10-14T23:38:52.165832Z","shell.execute_reply":"2021-10-14T23:38:52.168766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}