{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport sqlite3\nimport csv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom wordcloud import WordCloud\nimport re\nimport os\nfrom sqlalchemy import create_engine # database connection\nimport datetime as dt\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score,precision_score,recall_score\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom skmultilearn.adapt import mlknn\nfrom skmultilearn.problem_transform import ClassifierChain\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom sklearn.naive_bayes import GaussianNB\nfrom datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the data into a pandas dataframe\ndf = pd.read_csv(\"/kaggle/input/facebook-recruiting-iii-keyword-extraction/Train.zip\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates(['Title', 'Body', 'Tags'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"tag_count\"] = df[\"Tags\"].apply(lambda row : len(str(row).split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tag_count.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer= lambda text : text.split(\" \"))\ntag_dtm = vectorizer.fit_transform(df[\"Tags\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = vectorizer.get_feature_names()\ntags[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freqs = tag_dtm.sum(axis=0).A1\nresult = dict(zip(tags,freqs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_df = pd.DataFrame(result.items(), columns=[\"Tags\", \"Counts\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_df_sorted = tag_df.sort_values(['Counts'], ascending=False)\ntag_counts = tag_df_sorted[\"Counts\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(tag_counts[:100])\nplt.scatter(x= list(range(0,100,5)), y = tag_counts[0:100:5], c= 'orange',label = \"Quantiles with 5 % intervals\")\nplt.scatter(x= list(range(0,100,25)), y = tag_counts[0:100:25], c = \"red\", label = \"Quantiles with 25th % intervals\")\nplt.grid()\nplt.xlabel(\"Tag Number\")\nplt.ylabel(\"Number of times the tag Appear\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(result.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(background_color='black',\n         width = 1600,\n         height = 800).generate_from_frequencies(result)\nplt.figure(figsize=(30,20))\nplt.imshow(wordcloud)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations:\nA look at the word cloud shows that \"c#\", \"java\", \"php\", \"asp.net\", \"javascript\", \"c++\" are some of the most frequent tags."},{"metadata":{"trusted":true},"cell_type":"code","source":"i = np.arange(30)\ntag_df_sorted.head(30).plot(kind='bar')\nplt.xticks(i, tag_df_sorted['Tags'][:30])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def striphtml(data):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr,' ',str(data))\n    return cleantext\n\nstop_words = set(stopwords.words('english'))\nstemmer = SnowballStemmer('english')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_df = df.sample(50000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\npreprocessed_data_list=[]\nquestions_with_code=0\nlen_pre=0\nlen_post=0\nquestions_proccesed = 0\nprepared_df = pd.DataFrame(columns=['question','code','tags','words_pre','words_post','is_code'])\nfor row in random_df.iterrows():\n\n    is_code = 0\n\n    #As title seems very important feature Hence increasing title weight by adding it 3 times\n    title, question, tags = 3*(' ' +row[1][1]), row[1][2], row[1][3]\n\n    if '<code>' in question:\n        questions_with_code+=1\n        is_code = 1\n    x = len(question)+len(title)\n    len_pre+=x\n\n    code = str(re.findall(r'<code>(.*?)</code>', question, flags=re.DOTALL))\n\n    question=re.sub('<code>(.*?)</code>', '', question, flags=re.MULTILINE|re.DOTALL)\n    question=striphtml(question.encode('utf-8'))\n\n    title=title.encode('utf-8')\n\n    question=str(title)+\" \"+str(question)\n    question=re.sub(r'[^A-Za-z]+',' ',question)\n    words=word_tokenize(str(question.lower()))\n\n    #Removing all single letter and and stopwords from question exceptt for the letter 'c'\n    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n\n    len_post+=len(question)\n    processed_di = {\n        \"question\": question,\n        \"code\": code,\n        \"tags\": tags,\n        \"words_pre\": x,\n        \"words_post\": len(question),\n        \"is_code\" : is_code\n    }\n    \n    prepared_df.loc[len(prepared_df.index)] = [question,code,tags,x,len(question),is_code]\n    questions_proccesed += 1\n    if (questions_proccesed%100000==0):\n        print(\"number of questions completed=\",questions_proccesed)\n\nno_dup_avg_len_pre=(len_pre*1.0)/questions_proccesed\nno_dup_avg_len_post=(len_post*1.0)/questions_proccesed\n\nprint( \"Avg. length of questions(Title+Body) before processing: %d\"%no_dup_avg_len_pre)\nprint( \"Avg. length of questions(Title+Body) after processing: %d\"%no_dup_avg_len_post)\nprint (\"Percent of questions containing code: %d\"%((questions_with_code*100.0)/questions_proccesed))\n\nprint(\"Time taken to run this cell :\", datetime.now() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepared_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_data = prepared_df[[\"question\",\"tags\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Machine Learning Models"},{"metadata":{},"cell_type":"markdown","source":"Converting tags for multilabel problems"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer= lambda text : text.split(), binary=True)\nmultilabel_y = vectorizer.fit_transform(preprocessed_data[\"tags\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multilabel_y.get_shape()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tags_to_choose(n):\n    t = multilabel_y.sum(axis=0).tolist()[0]\n    sorted_tags_i = sorted(range(len(t)), key=lambda i: t[i], reverse=True)\n    multilabel_yn=multilabel_y[:,sorted_tags_i[:n]]\n    return multilabel_yn\n\ndef questions_explained_fn(n):\n    multilabel_yn = tags_to_choose(n)\n    x= multilabel_yn.sum(axis=1)\n    return (np.count_nonzero(x==0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_explained = []\ntotal_tags = multilabel_y.shape[1]\ntotal_qs = preprocessed_data.shape[0]\n\nfor i in range(500, total_tags, 100):\n    question_explained.append(np.round(((total_qs-questions_explained_fn(i))/total_qs)*100,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(question_explained)\nxlabel = list(500+np.array(range(-50,450,50))*50)\nax.set_xticklabels(xlabel)\nplt.xlabel(\"Number of tags\")\nplt.ylabel(\"Number Questions coverd partially\")\nplt.grid()\nplt.show()\n# you can choose any number of tags based on your computing power, minimun is 50(it covers 90% of the tags)\nprint(\"with \",5500,\"tags we are covering \",question_explained[50],\"% of questions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multilabel_yx = tags_to_choose(5500)\nprint(\"number of questions that are not covered :\", questions_explained_fn(5500),\"out of \", total_qs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multilabel_yx.get_shape()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of tags in sample :\", multilabel_y.shape[1])\nprint(\"number of tags taken :\", multilabel_yx.shape[1],\"(\",(multilabel_yx.shape[1]/multilabel_y.shape[1])*100,\"%)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into test and train (80:20)"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_size=preprocessed_data.shape[0]\ntrain_size=int(0.80*total_size)\n\nx_train=preprocessed_data.head(train_size)\nx_test=preprocessed_data.tail(total_size - train_size)\n\ny_train = multilabel_yx[0:train_size,:]\ny_test = multilabel_yx[train_size:total_size,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of data points in train data :\", y_train.shape)\nprint(\"Number of data points in test data :\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Featurizing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vect = TfidfVectorizer(min_df=0.00009,max_features=200000,smooth_idf=True,norm='l2',\\\n               tokenizer=lambda x : x.split(),sublinear_tf=False, ngram_range=(1,3) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_vectors = tfidf_vect.fit_transform(x_train['question'])\nx_test_vectors = tfidf_vect.transform(x_test['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dimensions of train data X:\",x_train_vectors.shape, \"Y :\",y_train.shape)\nprint(\"Dimensions of test data X:\",x_test_vectors.shape,\"Y:\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying Logistic Regression with OneVsRest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l1'), n_jobs=-1)\nclassifier.fit(x_train_vectors,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = classifier.predict(x_test_vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"accuracy \", metrics.accuracy_score(y_test,predictions))\nprint(\"macro f1 score \",metrics.f1_score(y_test,predictions, average='macro'))\nprint(\"micro f1 score \", metrics.f1_score(y_test, predictions, average='micro'))\nprint(\"hamming loss \", metrics.hamming_loss(y_test,predictions))\n\n# print(\"Precision classification report \\n\", metrics.classification_report(y_test,predictions))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # Applying Linear SVM with hinge loss and logistic regression in single shot with OneVsRest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cls_sgd = OneVsRestClassifier(SGDClassifier(), n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cls_sgd.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params = {\n# \"estimator__loss\" : [\"log\", \"hinge\"],\n# \"estimator__penalty\" : ['l1','l2'], \n# \"estimator__alpha\" : [0.01, 0.1]     \n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf_grid = GridSearchCV(cls_sgd,param_grid=params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf_grid.fit(x_train_vectors,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}