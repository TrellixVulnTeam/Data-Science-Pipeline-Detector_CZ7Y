{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Notebook - Table of Content\n\n1. [**Importing necessary libraries**](#1.-Importing-necessary-libraries)   \n2. [**Loading data**](#2.-Loading-data) \n3. [**Data preprocessing**](#3.-Data-preprocessing)  \n    3.1 [**Checking for duplicates**](#3.1-Checking-for-duplicates)\n4. [**Basic Data Analysis on Tags**](#4.-Basic-Data-Analysis-on-Tags)  \n    4.1 [**Frequency of tag_count**](#4.1-Frequency-of-tag_count)  \n    4.2 [**Total number of unique tags**](#4.2-Total-number-of-unique-tags)  \n    4.3 [**Frequency of each tag**](#4.3-Frequency-of-each-tag)  \n5. [**Word map for most frequent Tags**](#5.-Word-map-for-most-frequent-Tags)  \n6. [**Text preprocessing**](#6.-Text-preprocessing)   \n7. [**Machine learning models**](#7.-Machine-learning-models)  \n    7.1 [**Multilabel problem - Handling tags**](#7.1-Multilabel-problem---Handling-tags)  \n    7.2 [**Splitting into train and test set with 80:20 ratio**](#7.2-Splitting-into-train-and-test-set-with-80:20-ratio)  \n    7.3 [**Featurization of Training Data**](#7.3-Featurization-of-Training-Data)  \n    7.4 [**Fitting Logistic Regression with OneVsRest Classifier**](#7.4-Fitting-Logistic-Regression-with-OneVsRest-Classifier)  \n    7.5 [**Modelling by assigning more weightage to Title**](#7.5-Modelling-by-assigning-more-weightage-to-Title)  "},{"metadata":{},"cell_type":"markdown","source":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/"},{"metadata":{},"cell_type":"markdown","source":"### 1. Importing necessary libraries"},{"metadata":{"id":"AoKLP09VvgjD","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score,precision_score,recall_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Loading data"},{"metadata":{"id":"jT-mHsWy_Qyx","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/facebook-recruiting-iii-keyword-extraction/Train.zip\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"CSVMsK9w_X7M","outputId":"c1ab3938-076b-44bc-ff48-2e64f838b2ae","trusted":true},"cell_type":"code","source":"print(\"Dataframe shape : \", df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the number of records in the data is very large(6034195) so let's consider a small subset of data for faster computing."},{"metadata":{"id":"c6IKzAhC_Y2E","trusted":true},"cell_type":"code","source":"df = df.iloc[:10000, :]\nprint(\"Shape of Dataframe after subsetting : \", df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Data preprocessing\n\n#### 3.1 Checking for duplicates"},{"metadata":{"id":"Q6EySonONWtP","outputId":"8375a67e-99ba-42d5-a980-7d8b44d9ccea","trusted":true},"cell_type":"code","source":"duplicate_pairs = df.sort_values('Title', ascending=False).duplicated('Title')\nprint(\"Total number of duplicate questions : \", duplicate_pairs.sum())\ndf = df[~duplicate_pairs]\nprint(\"Dataframe shape after duplicate removal : \", df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"CbZi6OT8OFUC","trusted":true},"cell_type":"code","source":"df[\"tag_count\"] = df[\"Tags\"].apply(lambda x : len(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"id":"awwtIsb3Od36"},"cell_type":"markdown","source":"### 4. Basic Data Analysis on Tags \n\n#### 4.1. Frequency of tag_count"},{"metadata":{"id":"scx8z2ilOk49","outputId":"c07baf83-a8d3-465e-9790-d6908af83d06","trusted":true},"cell_type":"code","source":"df[\"tag_count\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"ouwat4wbjPSQ","outputId":"fd598443-11dc-4841-a632-fe9b4d4159a4","trusted":true},"cell_type":"code","source":"print( \"Maximum number of tags in a question: \", df[\"tag_count\"].max())\nprint( \"Minimum number of tags in a question: \", df[\"tag_count\"].min())\nprint( \"Average number of tags in a question: \", df[\"tag_count\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"id":"VqYKoyKCjn5Z","outputId":"d778908d-4900-49f9-99bf-f14632be5131","trusted":true},"cell_type":"code","source":"sns.countplot(df[\"tag_count\"])\nplt.title(\"Number of tags in questions \")\nplt.xlabel(\"Number of Tags\")\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"id":"vaGdBRjMkAbb"},"cell_type":"markdown","source":"**Observations:**\n\n1. Maximum number of tags in a question: 5\n2. Minimum number of tags in a question: 1\n3. Average number of tags per question: 2.92\n4. Most of the questions have either 2 or 3 tags"},{"metadata":{"id":"rzjID8n8WPfP"},"cell_type":"markdown","source":"#### 4.2 Total number of unique tags"},{"metadata":{"id":"a1l8hTDWVv7c","trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer = lambda x: x.split())\ntag_bow = vectorizer.fit_transform(df['Tags'])","execution_count":null,"outputs":[]},{"metadata":{"id":"-DjUF7T-WsPD","outputId":"5ced9dab-182d-4c02-b52d-0c905f55e05a","trusted":true},"cell_type":"code","source":"print(\"Number of questions :\", tag_bow.shape[0])\nprint(\"Number of unique tags :\", tag_bow.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"Pe8d3ro1Wza_","outputId":"d52c50e5-0e03-47e6-e266-b29bbd3f82fa","trusted":true},"cell_type":"code","source":"tags = vectorizer.get_feature_names()\nprint(\"Few tags :\", tags[:10])","execution_count":null,"outputs":[]},{"metadata":{"id":"GODNL0f1XMIm"},"cell_type":"markdown","source":"#### 4.3 Frequency of each tag"},{"metadata":{"id":"potfqCxoW-sy","trusted":true},"cell_type":"code","source":"freq = tag_bow.sum(axis=0).A1\ntag_to_count_map = dict(zip(tags, freq))","execution_count":null,"outputs":[]},{"metadata":{"id":"1yti3Lb2X_Ao","trusted":true},"cell_type":"code","source":"list = []\nfor key, value in tag_to_count_map.items():\n  list.append([key, value]) ","execution_count":null,"outputs":[]},{"metadata":{"id":"YAda86oaXkQg","outputId":"c6a022ed-e459-4ee3-9e7f-bcbadd973901","trusted":true},"cell_type":"code","source":"tag_df = pd.DataFrame(list, columns=['Tags', 'Counts'])\ntag_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"TFm1gr0rX3OK","outputId":"3f84919e-b4c4-4f65-990a-60cd4211cade","trusted":true},"cell_type":"code","source":"tag_df_sorted = tag_df.sort_values(['Counts'], ascending=False)\nplt.plot(tag_df_sorted['Counts'].values)\nplt.grid()\nplt.title(\"Distribution of frequency of tags based on appeareance\")\nplt.xlabel(\"Tag numbers for most frequent tags\")\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"id":"wjrw_zlxZqXI","outputId":"0ed0de67-9a65-4372-b015-e535aabc885f","trusted":true},"cell_type":"code","source":"plt.plot(tag_df_sorted['Counts'][0:100].values)\nplt.grid()\nplt.title(\"Top 100 tags : Distribution of frequency of tags based on appeareance\")\nplt.xlabel(\"Tag numbers for most frequent tags\")\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"id":"slY5PeRraHBA","outputId":"5253e68f-2d2e-4571-ee41-cf92c0989a16","trusted":true},"cell_type":"code","source":"plt.plot(tag_df_sorted['Counts'][0:100].values)\nplt.scatter(x=np.arange(0,100,5), y=tag_df_sorted['Counts'][0:100:5], c='g', label=\"quantiles with 0.05 intervals\")\nplt.scatter(x=np.arange(0,100,25), y=tag_df_sorted['Counts'][0:100:25], c='r', label = \"quantiles with 0.25 intervals\")\nfor x,y in zip(np.arange(0,100,25), tag_df_sorted['Counts'][0:100:25]):\n    plt.annotate(s=\"({} , {})\".format(x,y), xy=(x,y), xytext=(x-0.01, y+30))\n\nplt.title('first 100 tags: Distribution of frequency of tags based on appeareance')\nplt.grid()\nplt.xlabel(\"Tag numbers for most frequent tags\")\nplt.ylabel(\"Frequency\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"id":"5UJFJcCahQoS","outputId":"ade468e9-f62a-4cb8-bccd-1d14dbb40743","trusted":true},"cell_type":"code","source":"print(\"{} tags are used more than 25 times\".format(tag_df_sorted[tag_df_sorted[\"Counts\"]>25].shape[0]))\nprint(\"{} tags are used more than 50 times\".format(tag_df_sorted[tag_df_sorted[\"Counts\"]>50].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"id":"gNGhpC5tiVOu"},"cell_type":"markdown","source":"**Observations:**\n\n1. 144 tags are used more than 25 times.\n2. 59 tags are used more than 50 times.\n3. **C#** is most frequently used tag 778 times.\n4. Since some tags occur much more frequenctly than others, Micro-averaged F1-score is the appropriate metric for this probelm."},{"metadata":{"id":"oHrM2OwPkTLG"},"cell_type":"markdown","source":"### 5. Word map for most frequent Tags"},{"metadata":{"id":"Ez0QpyV2i-mY","outputId":"6f3090cc-cccf-48f9-9f94-8a8e225e8ca9","trusted":true},"cell_type":"code","source":"tag_to_count_map\ntupl = dict(tag_to_count_map.items())\nword_cloud = WordCloud(width=1600,height=800,).generate_from_frequencies(tupl)\nplt.figure(figsize = (12,8))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.tight_layout(pad=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"qc7V7yOEloMx"},"cell_type":"markdown","source":"**Observations:**\n\n\"c#\", \"java\", \"php\", \"android\", \"javascript\", \"jquery\", \"C++\" are some of the most frequent tags."},{"metadata":{"id":"asSkTygrmHpn"},"cell_type":"markdown","source":"### Bar plot of top 20 tags"},{"metadata":{"id":"ku0ttVmIlNKD","outputId":"ab41f4b6-3b3a-4a31-a638-46d3fc26ff28","trusted":true},"cell_type":"code","source":"i=np.arange(20)\ntag_df_sorted.head(20).plot(kind='bar')\nplt.title('Frequency of top 20 tags')\nplt.xticks(i, tag_df_sorted['Tags'])\nplt.xlabel('Tags')\nplt.ylabel('Counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"klC5LG3vOXOa"},"cell_type":"markdown","source":"### 6. Text preprocessing"},{"metadata":{"id":"wxph4pgfSWd0","trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nstemmer = SnowballStemmer(\"english\")","execution_count":null,"outputs":[]},{"metadata":{"id":"zSCCrYCqOkuI","outputId":"401f84f7-9a75-44e2-e168-4adec2b65563","trusted":true},"cell_type":"code","source":"qus_list=[]\nqus_with_code = 0\nlen_before_preprocessing = 0 \nlen_after_preprocessing = 0 \nfor index,row in df.iterrows():\n    title, body, tags = row[\"Title\"], row[\"Body\"], row[\"Tags\"]\n    if '<code>' in body:\n        qus_with_code+=1\n    len_before_preprocessing+=len(title) + len(body)\n    body=re.sub('<code>(.*?)</code>', '', body, flags=re.MULTILINE|re.DOTALL)\n    body = re.sub('<.*?>', ' ', str(body.encode('utf-8')))\n    title=title.encode('utf-8')\n    question=str(title)+\" \"+str(body)\n    question=re.sub(r'[^A-Za-z]+',' ',question)\n    words=word_tokenize(str(question.lower()))\n    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n    qus_list.append(question)\n    len_after_preprocessing += len(question)\ndf[\"question\"] = qus_list\navg_len_before_preprocessing=(len_before_preprocessing*1.0)/df.shape[0]\navg_len_after_preprocessing=(len_after_preprocessing*1.0)/df.shape[0]\nprint( \"Avg. length of questions(Title+Body) before preprocessing: \", avg_len_before_preprocessing)\nprint( \"Avg. length of questions(Title+Body) after preprocessing: \", avg_len_after_preprocessing)\nprint (\"% of questions containing code: \", (qus_with_code*100.0)/df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"2jYjwkCvV_9U","outputId":"13a108f7-7844-4651-e970-257606f487ab","trusted":true},"cell_type":"code","source":"preprocessed_df = df[[\"question\",\"Tags\"]]\nprint(\"Shape of preprocessed data :\", preprocessed_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"NLxDBjYVXwUv"},"cell_type":"markdown","source":"## 7. Machine learning models\n\n### 7.1 Multilabel problem - Handling tags"},{"metadata":{"id":"-CUdUCYTXPmW","trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')\ny_multilabel = vectorizer.fit_transform(preprocessed_df['Tags'])","execution_count":null,"outputs":[]},{"metadata":{"id":"UaobS626ZQqX","trusted":true},"cell_type":"code","source":"def tags_to_consider(n):\n    tag_i_sum = y_multilabel.sum(axis=0).tolist()[0]\n    sorted_tags_i = sorted(range(len(tag_i_sum)), key=lambda i: tag_i_sum[i], reverse=True)\n    yn_multilabel=y_multilabel[:,sorted_tags_i[:n]]\n    return yn_multilabel\n\ndef questions_covered_fn(numb):\n    yn_multilabel = tags_to_consider(numb)\n    x= yn_multilabel.sum(axis=1)\n    return (np.count_nonzero(x==0))","execution_count":null,"outputs":[]},{"metadata":{"id":"1LYS8Z6ikeWD","trusted":true},"cell_type":"code","source":"questions_covered = []\ntotal_tags=y_multilabel.shape[1]\ntotal_qus=preprocessed_df.shape[0]\nfor i in range(100, total_tags, 100):\n    questions_covered.append(np.round(((total_qus-questions_covered_fn(i))/total_qus)*100,3))","execution_count":null,"outputs":[]},{"metadata":{"id":"vfaOrB7ikyaN","outputId":"3172acd8-0c74-4f15-af51-52612ec78418","trusted":true},"cell_type":"code","source":"plt.plot(np.arange(100,total_tags, 100),questions_covered)\nplt.xlabel(\"Number of tags\")\nplt.ylabel(\"Number of questions covered partially\")\nplt.grid()\nplt.show()\nprint(questions_covered[9],\"% of questions covered by 1000 tags\")\nprint(\"Number of questions that are not covered by 100 tags : \", questions_covered_fn(1000),\"out of \", total_qus)","execution_count":null,"outputs":[]},{"metadata":{"id":"__MTVD9aWvog","outputId":"7071aa31-9a5a-4693-8afb-0cf1ee1a2bce","trusted":true},"cell_type":"code","source":"yx_multilabel = tags_to_consider(1000)\nprint(\"Number of tags in the subset :\", y_multilabel.shape[1])\nprint(\"Number of tags considered :\", yx_multilabel.shape[1],\"(\",(yx_multilabel.shape[1]/y_multilabel.shape[1])*100,\"%)\")","execution_count":null,"outputs":[]},{"metadata":{"id":"x0U8ZkfGXhJw"},"cell_type":"markdown","source":"### 7.2 Splitting into train and test set with 80:20 ratio"},{"metadata":{"id":"jNtyUuE3XXFS","outputId":"a63f3c08-8794-41bb-8dde-577044bb8f4f","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(preprocessed_df, yx_multilabel, test_size = 0.2,random_state = 42)\nprint(\"Number of data points in training data :\", X_train.shape[0])\nprint(\"Number of data points in test data :\", X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"7w9FmpPEdctB"},"cell_type":"markdown","source":"###  7.3 Featurization of Training Data"},{"metadata":{"id":"XY9VZCRFc03B","trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, tokenizer = lambda x: x.split(), ngram_range=(1,3))\nX_train_multilabel = vectorizer.fit_transform(X_train['question'])\nX_test_multilabel = vectorizer.transform(X_test['question'])","execution_count":null,"outputs":[]},{"metadata":{"id":"whPPHxwdfIRa","outputId":"7f3ab43f-124d-416d-8981-7c79f67e2adc","trusted":true},"cell_type":"code","source":"print(\"Training data shape X : \",X_train_multilabel.shape, \"Y :\",y_train.shape)\nprint(\"Test data shape X : \",X_test_multilabel.shape,\"Y:\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"PgySg-ylf8mG"},"cell_type":"markdown","source":"### 7.4 Fitting Logistic Regression with OneVsRest Classifier"},{"metadata":{"id":"VkbOJcoGfnkh","trusted":true},"cell_type":"code","source":"clf = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l2'))\nclf.fit(X_train_multilabel, y_train)\ny_pred = clf.predict(X_test_multilabel)","execution_count":null,"outputs":[]},{"metadata":{"id":"cjKhSIsMgsSV","outputId":"747a30ca-93bb-4684-e0cc-a4d6e318ccb4","trusted":true},"cell_type":"code","source":"print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))\nprint(\"Macro f1 score :\",metrics.f1_score(y_test, y_pred, average = 'macro'))\nprint(\"Micro f1 scoore :\",metrics.f1_score(y_test, y_pred, average = 'micro'))\nprint(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred))\n#print(\"Precision recall report :\\n\",metrics.classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"eEoRGR_5iqHa"},"cell_type":"markdown","source":"* ### 7.5 Modelling by assigning more weightage to Title"},{"metadata":{"id":"6u9MyWLJi4ji","outputId":"51f4b46a-71e6-4720-c84a-2d426571ff55","trusted":true},"cell_type":"code","source":"qus_list=[]\nqus_with_code = 0\nlen_before_preprocessing = 0 \nlen_after_preprocessing = 0 \nfor index,row in df.iterrows():\n    title, body, tags = row[\"Title\"], row[\"Body\"], row[\"Tags\"]\n    if '<code>' in body:\n        qus_with_code+=1\n    len_before_preprocessing+=len(title) + len(body)\n    body=re.sub('<code>(.*?)</code>', '', body, flags=re.MULTILINE|re.DOTALL)\n    body = re.sub('<.*?>', ' ', str(body.encode('utf-8')))\n    title=title.encode('utf-8')\n    question=str(title)+\" \"+str(title)+\" \"+str(title)+\" \"+ body\n    question=re.sub(r'[^A-Za-z]+',' ',question)\n    words=word_tokenize(str(question.lower()))\n    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n    qus_list.append(question)\n    len_after_preprocessing += len(question)\ndf[\"question_with_more_wt_title\"] = qus_list\navg_len_before_preprocessing=(len_before_preprocessing*1.0)/df.shape[0]\navg_len_after_preprocessing=(len_after_preprocessing*1.0)/df.shape[0]\nprint( \"Avg. length of questions(Title+Body) before preprocessing: \", avg_len_before_preprocessing)\nprint( \"Avg. length of questions(Title+Body) after preprocessing: \", avg_len_after_preprocessing)\nprint (\"% of questions containing code: \", (qus_with_code*100.0)/df.shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ena9APsql71X","outputId":"ff8f41a6-c915-469b-a5ac-3cd7b88e3f7f","trusted":true},"cell_type":"code","source":"preprocessed_df = df[[\"question_with_more_wt_title\",\"Tags\"]]\nprint(\"Shape of preprocessed data :\", preprocessed_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"029QWU2Bk6Qv","outputId":"7340f39f-47e6-462b-ddac-c568033e814b","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(preprocessed_df, yx_multilabel, test_size = 0.2,random_state = 42)\nprint(\"Number of data points in training data :\", X_train.shape[0])\nprint(\"Number of data points in test data :\", X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"FCKYAIV2l1Ic","trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, tokenizer = lambda x: x.split(), ngram_range=(1,3))\nX_train_multilabel = vectorizer.fit_transform(X_train['question_with_more_wt_title'])\nX_test_multilabel = vectorizer.transform(X_test['question_with_more_wt_title'])","execution_count":null,"outputs":[]},{"metadata":{"id":"VPnsuECXmwI9","outputId":"9ac1adc6-68b7-42cb-d9a5-a61d60b60b01","trusted":true},"cell_type":"code","source":"print(\"Training data shape X : \",X_train_multilabel.shape, \"Y :\",y_train.shape)\nprint(\"Test data shape X : \",X_test_multilabel.shape,\"Y:\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"dRI2XKTSnJ-2","trusted":true},"cell_type":"code","source":"clf = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l2'))\nclf.fit(X_train_multilabel, y_train)\ny_pred = clf.predict(X_test_multilabel)","execution_count":null,"outputs":[]},{"metadata":{"id":"Rt3uUYvfnLwU","outputId":"8ab1c5f9-797c-4378-9b95-689333ca4f99","trusted":true},"cell_type":"code","source":"print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))\nprint(\"Macro f1 score :\",metrics.f1_score(y_test, y_pred, average = 'macro'))\nprint(\"Micro f1 scoore :\",metrics.f1_score(y_test, y_pred, average = 'micro'))\nprint(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"w_akgLPkpMK9","trusted":true},"cell_type":"code","source":"#using direct implementation of Logistic Regression\nclf2 = OneVsRestClassifier(LogisticRegression(penalty='l1'))\nclf2.fit(X_train_multilabel, y_train)\ny_pred2 = clf2.predict(X_test_multilabel)","execution_count":null,"outputs":[]},{"metadata":{"id":"BDaRDca_plIg","outputId":"723b82ff-08de-479e-bcc3-6b9fff5aa320","trusted":true},"cell_type":"code","source":"print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred2))\nprint(\"Macro f1 score :\",metrics.f1_score(y_test, y_pred2, average = 'macro'))\nprint(\"Micro f1 scoore :\",metrics.f1_score(y_test, y_pred2, average = 'micro'))\nprint(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf2.predict()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}