{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3fd2cab5-c6cb-cc8f-daac-605ea8e4cc43"},"source":"#Planet: LBP, COLOR, SOBEL feature extraction"},{"cell_type":"markdown","metadata":{"_cell_guid":"69604230-f13e-1c04-6de1-bf7f509dee6b"},"source":"##Loading modules"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"646eb8c9-3761-2b96-d956-ffadbbab95c0"},"outputs":[],"source":"import os\nimport sys\n\nimport scipy\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom skimage import io\nfrom scipy.ndimage import convolve\nfrom skimage.transform import rotate\nfrom skimage.feature import local_binary_pattern\n\nfrom scipy import ndimage\nfrom scipy.stats import itemfreq \n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.feature_extraction.image import extract_patches_2d\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import linear_model, decomposition\nfrom sklearn.cluster import MiniBatchKMeans\n\nfrom pprint import pprint\nfrom IPython.display import display\nfrom itertools import product, chain\n\n%matplotlib inline\n\nPLANET_KAGGLE_ROOT = os.path.abspath(\"../input/\")\n\n#training sets paths\nTRAIN_JPEG_DIR  = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\nTRAIN_TIF_DIR   = os.path.join(PLANET_KAGGLE_ROOT, 'train-tif-v2')\nTRAIN_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\n\nassert os.path.exists(TRAIN_JPEG_DIR)\nassert os.path.exists(TRAIN_TIF_DIR)\nassert os.path.exists(TRAIN_LABEL_CSV)\n\n#testing sets paths\nTEST_JPEG_DIR  = os.path.join(PLANET_KAGGLE_ROOT, 'test-jpg-v2')\nTEST_TIF_DIR   = os.path.join(PLANET_KAGGLE_ROOT, 'test-tif-v2')\n\nassert os.path.exists(TEST_JPEG_DIR)\nassert os.path.exists(TEST_TIF_DIR)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3840b130-b690-916b-3435-89171fe31644"},"source":"##Load labels in one hot representation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"963f3133-41cd-10a1-6fc2-dda335b1576e"},"outputs":[],"source":"labels_df = pd.read_csv(TRAIN_LABEL_CSV)\n\n#build list with unique labels\nlabel_list = []\nfor tag_str in labels_df.tags.values:\n    labels = tag_str.split(' ')\n    for label in labels:\n        if label not in label_list:\n            label_list.append(label)\n\n#qdd onehot features for every label\nfor label in label_list:\n    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n\n#remove the tags column\nlabels_df = labels_df.drop(\"tags\", 1)\n\nlabels_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0662a30b-f3ce-e4cc-b92b-eae377dfe0fa"},"outputs":[],"source":"def load_image(filename):\n    '''Look through the directory tree to find the image you specified\n    (e.g. train_10.tif vs. train_10.jpg)'''\n    for dirname in os.listdir(PLANET_KAGGLE_ROOT):\n        path = os.path.abspath(os.path.join(PLANET_KAGGLE_ROOT, dirname, filename))\n        if os.path.exists(path):\n            #print('Found image {}'.format(path))\n            return io.imread(path)\n    #print('Load failed: could not find image {}'.format(path))\n\ndef sample_to_fname(sample_df, row_idx, suffix='tif'):\n    '''Given a dataframe of sampled images, get the\n    corresponding filename.'''\n    fname = sample_df.get_value(sample_df.index[row_idx], 'image_name')\n    return '{}.{}'.format(fname, suffix)"},{"cell_type":"markdown","metadata":{"_cell_guid":"db14e571-3cd6-35f0-dca7-f4d6de9cbe79"},"source":"##Features extraction"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e683139-e8ba-65d8-5cf9-2230c0b269bc"},"outputs":[],"source":"def extract_rgb(img): \n    return img[:,:,0], img[:,:,1], img[:,:,2]\n\ndef rgb2gray(rgb):\n    r, g, b = extract_rgb(rgb)\n    return 0.2989 * r + 0.5870 * g + 0.1140 * b\n\nLBP_RADIUS = 3\nLBP_NB_POINTS = 8 * LBP_RADIUS\nLBP_METHOD = 'uniform'\n\ndef get_lbp(img_gray_scale):\n    return local_binary_pattern(\n        img_gray_scale,\n        LBP_NB_POINTS,\n        LBP_RADIUS,\n        LBP_METHOD\n    )\n\ndef get_hist(lst):\n    x = itemfreq(lst)\n    hist = x[:, 1]/sum(x[:, 1])\n    return hist\n\ndef get_lbp_hist(img):\n    return get_hist(get_lbp(rgb2gray(img)).reshape(-1))\n\n##load and display image\n#img = load_image(\"train_1.jpg\")\n#r, g, b = extract_rgb(img)\n#plt.imshow(get_lbp(rgb2gray(img)), cmap='gray')\n#plt.show()\n\n##compute the lbp histogram of the image\n#hist = get_lbp_hist(img)\n#plt.plot(range(len(hist)), hist)\n#plt.show()\n\n##compute the lbp histogram of the image rotated by 30Â°\n#hist_r30 = get_lbp_hist(rotate(img, angle=30, resize=False))\n#plt.plot(range(len(hist_r30)), hist_r30)\n#plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2817729-6206-b4ea-ea80-cc7f37c29447"},"outputs":[],"source":"def get_sobel(img_gray_scale):\n    sx = ndimage.sobel(img_gray_scale, axis=0, mode='constant')\n    sy = ndimage.sobel(img_gray_scale, axis=1, mode='constant')\n    return np.hypot(sx, sy)[3:-3,3:-3] #3:-3 to remove the border problems...\n\ndef get_sobel_hist(img):\n    x = np.histogram(get_sobel(rgb2gray(img)).reshape(-1), bins=range(256))[0]\n    return x / sum(x)\n\n##load image\n#img = load_image(\"train_11.jpg\")\n\n##display the sobel fitered image\n#plt.imshow(get_sobel(rgb2gray(img)))\n#plt.show()\n\n##disply the sobel histogram\n#sobel_hist = get_sobel_hist(img)\n#plt.plot(range(len(sobel_hist)), sobel_hist)\n#plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ffe63cf4-f91e-24b1-e01d-85ba8102b31a"},"outputs":[],"source":"def extract_gray_scale_histogram(img_gray_scale):\n    x = np.histogram(img_gray_scale.reshape(-1), bins=range(256))[0]\n    return x / sum(x)\n\ndef get_color_histogram(img):\n    f = lambda m: list(extract_gray_scale_histogram(m))\n    r, g, b = extract_rgb(img)\n    return f(r) + f(g) + f(b)\n\n#load image\n#img = load_image(\"train_12.jpg\")\n\n#display image\n#plt.imshow(img)\n#plt.show()\n\n#display color histogram\n#plt.plot(get_color_histogram(img))\n#plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"693fbff1-c16d-5ce4-6a76-56c22e9a94e3"},"source":"##Prepare datasets"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9fa045ae-301c-a6cf-2186-f40fb503f9fd"},"outputs":[],"source":"PRC_TRAINING = .5\nPRC_TESTING  = .25\n\ndataset = shuffle(labels_df).reset_index(drop=True)\n\ntrain, test = train_test_split(dataset, test_size=1 - PRC_TRAINING)\ntest, cv = train_test_split(dataset, test_size=PRC_TESTING)\n\ntraining_set_labels = train\ntesting_set_labels  = test\ncross_validation_set_labels = cv"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"012b33db-716c-7944-d265-8b30fe9dc17e"},"outputs":[],"source":"LOAD_MAX_NB_DATA = 1000\n\n#loading the data\ntraining_set_data = []\ntesting_set_data  = []\ncross_validation_set_data = []\n\nfor r in training_set_labels[\"image_name\"][:LOAD_MAX_NB_DATA]:\n    img = load_image(r + \".jpg\")\n    training_set_data.append(img)#extract_features(img))\nprint(\"training data loaded...\")\n\nfor r in testing_set_labels[\"image_name\"][:LOAD_MAX_NB_DATA]:\n    img = load_image(r + \".jpg\")\n    testing_set_data.append(img)#extract_features(img))\nprint(\"testing data loaded...\")\n    \nfor r in cross_validation_set_labels[\"image_name\"][:LOAD_MAX_NB_DATA]:\n    img = load_image(r + \".jpg\")\n    cross_validation_set_data.append(img)#extract_features(img))\nprint(\"cross validation data loaded...\")\n    \n#removing the image name column in labels\ntraining_set_labels = training_set_labels.drop(\"image_name\", 1)\ntesting_set_labels  = testing_set_labels.drop(\"image_name\", 1)\ncross_validation_set_labels = cross_validation_set_labels.drop(\"image_name\", 1)\n\n#limit the the nb max data to load...\ntraining_set_labels = training_set_labels.head(LOAD_MAX_NB_DATA)\ntesting_set_labels  = testing_set_labels.head(LOAD_MAX_NB_DATA)\ncross_validation_set_labels = cross_validation_set_labels.head(LOAD_MAX_NB_DATA)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c0a2d86c-1d00-589f-e771-5e5b23dad16b"},"source":"##Do some BagOfWords processing stuffs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25a93b96-e0ea-ac4b-d778-1e22d4dbb402"},"outputs":[],"source":"DISPLAY_CLUSTER_MATRIX = (9, 9)\nkmeans = MiniBatchKMeans(n_clusters=DISPLAY_CLUSTER_MATRIX[0] * DISPLAY_CLUSTER_MATRIX[1], verbose=False)\npatch_size = (20, 20)\n\nbuffer = []\nindex = 1\n\nfor img in cross_validation_set_data: #using the crossvalidation dataset to train the words extractor...\n    data = extract_patches_2d(rgb2gray(img), patch_size, max_patches=500)\n    data = np.reshape(data, (len(data), -1))\n    index += 1\n    buffer.append(data)\n    data = np.concatenate(buffer, axis=0)\n\nprint(\"nb_patches : \", len(buffer))\n    \nkmeans.fit(data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8960734-f73c-a675-c66c-6f545dfc488e"},"outputs":[],"source":"#display the patches\nplt.figure(figsize=(10.2, 10))\nfor i, patch in enumerate(kmeans.cluster_centers_):\n    plt.subplot(DISPLAY_CLUSTER_MATRIX[0], DISPLAY_CLUSTER_MATRIX[1], i + 1)\n    plt.imshow(patch.reshape(patch_size), cmap=plt.cm.gray, interpolation='nearest')\n    plt.xticks(())\n    plt.yticks(())\n\nplt.suptitle('Patches trained', fontsize=16)\nplt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f30e9be5-7c6c-2957-f553-a44731fdabab"},"outputs":[],"source":"def get_words_hist_of_img(gray_scale_img):\n    #initialise the vector\n    hist = [0 for i in range(kmeans.n_clusters)]\n    #extract patches\n    data = extract_patches_2d(gray_scale_img, patch_size, max_patches=500)\n    data = np.reshape(data, (len(data), -1))\n    #comoute the predictions histogram\n    preds = kmeans.predict(data)\n    for p in preds:\n        hist[p] += 1\n    hist = np.array(hist)\n    return hist / sum(hist)\n    \n#get_words_hist_of_img(rgb2gray(img))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92b3ea29-6412-f140-9304-09722646ac61"},"outputs":[],"source":"def extract_features(img):\n    lst = list(get_lbp_hist(img)) + list(get_sobel_hist(img)) + list(get_color_histogram(img)) + list(get_words_hist_of_img(rgb2gray(img)))\n    #print(len(list(get_lbp_hist(img))), len(list(get_sobel_hist(img))), len(list(get_color_histogram(img))))\n    return lst\n\n#load image\n#img = load_image(\"train_12.jpg\")\n\n#display the global descripor\n#plt.plot(extract_features(img))\n#plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c464086-a363-40b7-c9b7-872684cc7809"},"outputs":[],"source":"training_set_img = training_set_data\ntesting_set_img  = testing_set_data\n\ntraining_set_data = []\ntesting_set_data  = []\n\nfor img in training_set_img:\n    training_set_data.append(extract_features(img))\nprint(\"training features extracted...\")\n\nfor img in testing_set_img:\n    testing_set_data.append(extract_features(img))\nprint(\"testing features extracted...\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fba8f9b0-5051-eb7b-3e8b-33a5696e2f6f"},"outputs":[],"source":"LR = lambda: linear_model.LogisticRegression(class_weight=\"balanced\", penalty=\"l2\")\nPCA = lambda: decomposition.PCA()\nPIPE_LINE = lambda: Pipeline(steps=[\n    #('pca', PCA()), \n    ('logistic', LR())\n])\n\n##TODO: configure crossvalidated logistic regression...\n#LRCV = lambda: linear_model.LogisticRegressionCV(class_weight=\"balanced\", penalty=\"l2\", cv=StratifiedKFold, scoring=precision_recall_fscore_support)\n\n#fit logistic models\npredictors = {label: PIPE_LINE() for label in list(training_set_labels)}\nfor label in predictors:\n    try:\n        predictors[label].fit(\n            np.array(training_set_data),\n            np.array(list(training_set_labels[label]))\n        )\n    except:\n        print(\"something went wrong with label : \", label)\n\n\n#compute model accuracy    \naccuracy = {}\nfor label in predictors:\n    try:\n        y_hat = predictors[label].predict(testing_set_data) == np.array(list(testing_set_labels[label]))\n        accuracy[label] = sum(y_hat) / len(y_hat)\n    except:\n        print(\"ignoring label : \", label)\n\nprint(\"accuracy : \")\npprint(accuracy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69229094-b56d-665c-0666-95de519efd0f"},"outputs":[],"source":"#####TODO build the top level classifier...\n## adapt the previous classifier set to ouput a set of labels \n## (think about uniques labels eg. wheater can't be cloudy and partialy cloudy...)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e199167-5fbb-15e4-51dd-0ca3a9b19cd2"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}