{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import required libraries\n\nThis session would import all the required packages for us to build the models."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assign training data\nThis is to import our dataset (images and labels).\n\n1. ***tags*** column described the conditions including weather and pollution as well. \n2. ***deforest*** column described the occurrence of deforestation. *False* stands for no deforestation and vice versa."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"df_train = pd.read_csv('../input/train_v2.csv')\ndf_train['deforest'] = df_train['tags'].str.contains(\"agriculture|habitation|road|cultivation|slash_burn|conventional_mine|bare_ground|artisinal_mine|selective_logging|blow_down\")\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic counting\nThis is to show the number of *forest* and *deforest* images available in dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['deforest'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To plot some figures"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l, j in df_train[:9].values:\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {} - {}'.format(f, l, j))\n    #ax[i // 4, i % 4].show()\n    i += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data frame pre-processing\nThis session is to process the images (unstructed data) to *machine learnable* format (to let the computer understands the images in its way).<br/>\n<br/>\nWe would also split the entire dataset into *training* set and *validation* set for model developement and model validation respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"## \"deforest\" need to be string\ndf_train.deforest = df_train.deforest.apply(str)\ndf_train[\"id\"] = df_train[\"image_name\"] + '.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,  \n    zoom_range=0.2,        \n    horizontal_flip=True,\n    validation_split=0.2)  \n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe = df_train,\n    x_col = 'id',\n    y_col = 'deforest',\n    directory = '../input/train-jpg',\n    target_size = (150,150),\n    batch_size=32,\n    class_mode = 'binary',\n    subset='training')\n\nval_generator = datagen.flow_from_dataframe(\n    dataframe = df_train,\n    x_col = 'id',\n    y_col = 'deforest',\n    directory = '../input/train-jpg',\n    target_size=(150,150),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building a deep learning model\n\nThis session is to build a deep learning model that can perform classification in later application."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimize the model\nThis is to instruct the model to improve its performance (accuracy) by learning from its own mistake."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_generator, \n    steps_per_epoch  = 100, \n    validation_data  = val_generator,\n    validation_steps = 50,\n    epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To visualize model's performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\nfig = plt.figure(figsize=(16,9))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('amazon_forest.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Live-demo"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n\nfor f, l, j, k in df_train.iloc[[2521]].values:\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.title(('{} - {}'.format(l, j)))\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nfrom keras.preprocessing import image\n\nmodel = load_model('amazon_forest.h5')\n\ntest_image = image.load_img('../input/train-jpg/train_1.jpg', target_size=(150, 150))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\ntest_image = test_image.reshape(1, 150, 150, 3)   \n\nresult = np.array(model.predict(test_image))\nclasses = result.item(0)\n\nif classes == 0:\n    print (\"Great! Forest is still well preserved!\") \nelif classes == 1:\n    print (\"Oh no! Send some guards there!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}