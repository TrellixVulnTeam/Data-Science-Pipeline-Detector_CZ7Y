{"metadata":{"_is_fork":false,"_change_revision":0,"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","pygments_lexer":"ipython3","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python"}},"cells":[{"outputs":[],"metadata":{"_uuid":"2b90840c73b6527ff03607c7e3c1dca709cadd0a","_cell_guid":"276ba4ef-a67f-d2ba-cc35-8d1ec8677c44"},"source":"# Saving the Rainforest with Random Forests\n### Claire Longo\n### July 2017\nKaggle Competition code\nPlanet: Understanding the Amazon from Space\n\nhttps://www.kaggle.com/c/planet-understanding-the-amazon-from-space\n\nTHIS NOTEBOOK WAS CREATED IN COLLABORATION WITH A TEAM WITH https://www.kaggle.com/acetherace\n\nThe goal of this competition is to label satellite images of the Amazon rainforest. The goal of this algorithm is to identify and understand the where, how and why of deforestation. This is a computer vision task requiring multilabel classification with large class unbalance. This approach uses .jpeg image data to train the model, and meaningful features are engineering from the raw image files.\n\nNote that this notebook only uses 100 images as an example for the feature engineering and model training. The notebook would take a long time to run the analysis for all the images, but the code can easily be edited to do so. ","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"ff3bb089cf2b094ab41b8ef0db182dcb41673ed4","_execution_state":"idle","trusted":false,"_cell_guid":"c4623ae6-4fa7-e7d5-3a5a-85332689bb90"},"source":"import pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nfrom skimage.io import imread, imshow\nfrom skimage import transform, img_as_float, filters\nfrom skimage.color import rgb2gray\nfrom skimage.feature import blob_dog, blob_log, blob_doh, canny\nfrom skimage.transform import hough_line\nimport glob\nimport math\nimport scipy\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"ace9afbeccdfa08762299fb43b18f29251190722","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"d3fb653f-1199-494b-aa86-c76f7690daf2"},"source":"# some functions\ndef load_sample_training_data(ftype='jpg', n=100):\n    \"\"\"Returns (train_imgs, labels, im_names, tagged_df)\n    train_imgs is the raw image data in the sample folder\n    n is number of images to read in\n    \"\"\"\n    #open data from current directory. Should work with any direcotry path\n    tagged_df = pd.read_csv('../input/train_v2.csv')\n\n    #split the tags into new rows\n    tagged_df = pd.DataFrame(tagged_df.tags.str.split(' ').tolist(), index=tagged_df.image_name).stack()\n    tagged_df = tagged_df.reset_index()[[0, 'image_name']] # dataframe with two columns\n    tagged_df.columns = ['tags', 'image_name'] # rename columns\n    tagged_df.set_index('image_name', inplace=True) # rest index to image_name again\n\n    #create dummy variables for each tag\n    tagged_df = pd.get_dummies(tagged_df['tags']) # creates dummy rows\n    tagged_df = tagged_df.groupby(tagged_df.index).sum() # adds dummy rows together by image_name index\n\n    train_imgs = []\n    labels = []\n    im_names = []\n    print('Loading {} image dataset'.format(ftype))\n    path = os.path.join('..', 'input','train-{}'.format(ftype),'*.'+ftype)\n\n    files = glob.glob(path)\n    for fs in files[1:n]:\n        img = imread(fs)\n        # img = transform.resize(img, output_shape=(h,w,d), preserve_range=True)  if needed\n        train_imgs.append(img)\n        \n        imname = os.path.basename(fs).split('.')[0]\n        im_names.append(imname)\n        \n        labels_temp = tagged_df.loc[imname]\n        labels.append(labels_temp)\n    train_imgs = img_as_float(np.asarray(train_imgs))\n    return train_imgs, labels, im_names, tagged_df","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"13d6492cd66e38a72d83f10d4cce4469705f7013","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"3382cc21-7567-44e6-a992-68f891eb728e"},"source":"X_sample, labels, names_train, tagged_df = load_sample_training_data(ftype='jpg', n=100)","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"ef08184e10c397a83dce4a28e9b8f5daabf28f3c","_execution_state":"idle","collapsed":false,"_cell_guid":"b001260e-a7e3-42e9-b21a-fda202d3d11d"},"source":"These example images are from the training dataset. Images are tagged with more than one label.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"c34b15ab7cb8b2c9051e48c22dde8860d6d48ebe","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"f4cdd1bf-05a6-4bb5-b50d-a649fc5bb427"},"source":"def get_labels(fname, tagged_df):\n    \"\"\"return list of labels for a given filename\"\"\"\n    return \", \".join(tagged_df.loc[fname][tagged_df.loc[fname]==1].index.tolist())  \n\ndef plot_samples(X_train, names_train, tagged_df, nrow, ncol):\n    \"\"\"Plots random sample images with their titles and tag names\"\"\"\n    sampling = np.random.randint(low=0, high=X_train.shape[0]-1, size = nrow*ncol)\n    fig, axes = plt.subplots(nrow, ncol, figsize=(15, 12))\n    for i in range(0,len(sampling)):\n        name = names_train[sampling[i]]\n        tags = get_labels(name, tagged_df)\n\n        row = math.floor(i/ncol)\n        col = i - math.floor(i/ncol)*ncol\n        if (nrow == 1 or ncol == 1):\n            ind = (max(row,col))\n        else:\n            ind = (row,col)\n        axes[ind].imshow(X_train[sampling[i]])\n        axes[ind].set_title(name+'\\n'+tags)\n        axes[ind].tick_params(left=False, right=False)\n        axes[ind].set_yticklabels([])\n        axes[ind].set_xticklabels([])\n        axes[ind].axis('off')\n    plt.tight_layout()\n\nplot_samples(X_sample, names_train, tagged_df, nrow=4, ncol=4)","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"c3fc121b5ce35855e2f85aed622d4cbd29310144","_execution_state":"idle","collapsed":false,"_cell_guid":"2d88b4c2-7672-4619-9dce-015b074a541d"},"source":"The bar plot shows the sample size for each tag in the training dataset. Notice the large class unbalance. The tags that do not occur very frequently will be difficult to train a model to identify, because there are not many cases in the training data.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"5d08eae6febd69c059ca758395dc31ad5d0a0f1d","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"bd2b0311-7ffe-419f-b11f-841f260b4bb2"},"source":"#Barplot of tag counts\ndef plot_sample_size(tagged_df):\n    plt.rcParams['figure.figsize'] = (12, 5)\n    print('There are {} unique tags in this data'.format(len(tagged_df.columns)))\n    colors = cm.rainbow(np.linspace(0, 1, len(tagged_df.columns)))\n    tagged_df.sum().sort_values(ascending=False).plot(title=\"Counts of Tags\", color=colors, kind='bar')\n    plt.show()\n\nplot_sample_size(tagged_df)","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"427013eec038eb0776fb4e5ce29a0283054325f0","_execution_state":"idle","collapsed":false,"_cell_guid":"59044c7f-f32a-41a6-aaf9-e9e06a8227b2"},"source":"## Feature Engineering\nThe images contain numeric pixel values on the red, green, and blue scale. The statistical distributions of the red, green, and blue, pixels differ for different types of tags, indicating that this may be a useful feature for classification. The patterns in these pixels will likely have useful trends for classifying the objects in the images and the image types. The image below shows the red, green, and blue image layers.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"49f605910a4ccf4dc1c92262a6efbee7c895c150","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"1f1eb5b5-b1bc-4985-8866-ac5b579f0622"},"source":"fig, axes = plt.subplots(1, 3, figsize=(10, 6))\naxes[0].imshow(X_sample[1,:,:,0], cmap='Reds')\naxes[1].imshow(X_sample[1,:,:,1], cmap='Greens')\naxes[2].imshow(X_sample[1,:,:,2], cmap='Blues')","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"76198a63034d75fa0797d442a608438d12c16dce","_execution_state":"idle","collapsed":false,"_cell_guid":"1189a027-d76c-4c7d-942f-712a7ae87b00"},"source":"The tags are based on patterns in the images, but the location of these patterns does not matter. For example a road in the bottom corner or top corner of an image is still a road, and we are only interested in tagging it as such. Therefore, the raw pixel data is not an optimal feature because it defines patterns in specific locations. Thus, we engineer features from the raw pixel data that attempt to represent generalized patterns in the images.\nMany of the red, green, and blue distributions are bimodal, which could offer interesting insight into the classification, so a feature is created to capture bimodal patterns in the r g b pixel distributions. The binned mode differences is simply the difference between the two min bounds of the two largest count bins, or the two modes. If this value is large, then the two largest modes are a large distance from each other, indicating the distribution is bimodal.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"9302ed06daa5c2cca0ac6e43e4c1c7d0e4a83a07","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"eb8f4e5d-bf22-4d82-816c-1eec813a9adf"},"source":"#Binned mode differences feature creation to detect bimodal patterns\ndef binned_mode_features_with_diagnostics(img, steps):\n    ## red ##\n    #split on mean\n    m=img[:,:,0].flatten().mean()\n    left = img[:,:,0].flatten()[img[:,:,0].flatten()<m]\n    right = img[:,:,0].flatten()[img[:,:,0].flatten()>=m]\n    #find mode in left and right\n    max_ind_left = np.histogram(left, bins=steps, density=False)[0].argsort()[-1:]\n    max_ind_right = np.histogram(right, bins=steps, density=False)[0].argsort()[-1:]\n    #calc bimodal metric\n    mo1 = np.histogram(right, bins=steps, density=False)[1][max_ind_right]\n    mo2 = np.histogram(left, bins=steps, density=False)[1][max_ind_left]\n    mods_diff_r=abs(mo1-mo2)\n    print(\"The mean of the red distribution is {}\".format(m.round(2)))\n    print(\"After splitting on the mean, the two modes are found at {} and {}\".format(mo2, mo1))\n    plt.hist(img[:,:,0].flatten(), color='red', bins=steps)\n    plt.axvline(img[:,:,0].mean(), color='black', linestyle='dashed', linewidth=2)\n    plt.axvline(mo1, color='yellow', linestyle='dashed', linewidth=2)\n    plt.axvline(mo2, color='yellow', linestyle='dashed', linewidth=2)\n    plt.show()\n    \n    ## green ##\n    m=img[:,:,1].flatten().mean()\n    left = img[:,:,1].flatten()[img[:,:,1].flatten()<m]\n    right = img[:,:,1].flatten()[img[:,:,1].flatten()>=m]\n    max_ind_left = np.histogram(left, bins=steps, density=False)[0].argsort()[-1:]\n    max_ind_right = np.histogram(right, bins=steps, density=False)[0].argsort()[-1:]\n    mo1 = np.histogram(right, bins=steps, density=False)[1][max_ind_right]\n    mo2 = np.histogram(left, bins=steps, density=False)[1][max_ind_left]\n    mods_diff_g=abs(mo1-mo2)\n    print(\"The mean of the green distribution is {}\".format(m.round(2)))\n    print(\"After splitting on the mean, the two modes are found at {} and {}\".format(mo2, mo1))\n    plt.hist(img[:,:,1].flatten(), color='green', bins=steps)\n    plt.axvline(img[:,:,1].mean(), color='black', linestyle='dashed', linewidth=2)\n    plt.axvline(mo1, color='yellow', linestyle='dashed', linewidth=2)\n    plt.axvline(mo2, color='yellow', linestyle='dashed', linewidth=2)\n    plt.show()\n    \n    ## blue ##\n    m=img[:,:,2].flatten().mean()\n    left = img[:,:,2].flatten()[img[:,:,2].flatten()<m]\n    right = img[:,:,2].flatten()[img[:,:,2].flatten()>=m]\n    max_ind_left = np.histogram(left, bins=steps, density=False)[0].argsort()[-1:]\n    max_ind_right = np.histogram(right, bins=steps, density=False)[0].argsort()[-1:]\n    mo1 = np.histogram(right, bins=steps, density=False)[1][max_ind_right]\n    mo2 = np.histogram(left, bins=steps, density=False)[1][max_ind_left]\n    mods_diff_b=abs(mo1-mo2)\n    print(\"The mean of the blue distribution is {}\".format(m.round(2)))\n    print(\"After splitting on the mean, the two modes are found at {} and {}\".format(mo2, mo1))\n    plt.hist(img[:,:,2].flatten(), color='blue', bins=steps)\n    plt.axvline(img[:,:,2].mean(), color='black', linestyle='dashed', linewidth=2)\n    plt.axvline(mo1, color='yellow', linestyle='dashed', linewidth=2)\n    plt.axvline(mo2, color='yellow', linestyle='dashed', linewidth=2)\n    plt.show()\n    \n    return mods_diff_r[0].round(2), mods_diff_g[0].round(2), mods_diff_b[0].round(2)\n\nimg=X_sample[2]\nsteps=np.arange(start=0,stop=1, step=.01)\nbinned_mode_features_with_diagnostics(img, steps)","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"828a15cd8d0ddfb6895e221e18f15b92ec82146d","_execution_state":"idle","collapsed":false,"_cell_guid":"a8dbe2ed-dd16-4048-b57e-be8243fc802b"},"source":"Features are also created from the images using sobel and canny transforms in the skimage library. The sobel and canny transformations from skimage perform edge detection of the images. An example of the Sobel transformation is plotted below.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"f477904e3d56e2db3098c4e8c7b54db0bb6d405d","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"96243042-7a6a-4574-9c11-a7ea47795cf2"},"source":"from skimage.color import rgb2gray\nfrom skimage import transform, img_as_float, filters\nX_train_g = rgb2gray(X_sample)\n\nX_train_sobel = []\nfor i in range(X_train_g.shape[0]):\n    X_train_sobel.append(filters.sobel(X_train_g[i]))\nX_train_sobel = np.asarray(X_train_sobel)\n\nplot_samples(X_train_sobel, names_train, tagged_df, 4,4)","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"9908a84777d9b725832f2cfca21372475d68dda1","_execution_state":"idle","collapsed":false,"_cell_guid":"93c9735c-47b3-47c4-a625-595a5c09ed29"},"source":"Create features from sample data...","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"bf3e3eb6f68895d8ba1d4c24370cf30c67f392c7","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"b00a41c6-0a57-4512-9c04-800251858902"},"source":"def xform_to_gray(imgs):\n    return rgb2gray(imgs)\n\ndef xform_to_sobel(imgs):\n    imgs = xform_to_gray(imgs)\n    sobels = []\n    if imgs.ndim == 2:\n        sobels.append(filters.sobel(imgs))\n    else:\n        for i in range(imgs.shape[0]):\n            sobels.append(filters.sobel(imgs[i]))\n    return np.asarray(sobels)\n\ndef xform_to_canny(imgs, sigma):\n    imgs = xform_to_gray(imgs)\n    cannys = []\n    if imgs.ndim == 2:\n        cannys.append(canny(imgs, sigma))\n    else:\n        for i in range(imgs.shape[0]):\n            cannys.append(canny(imgs[i], sigma))\n    return np.asarray(cannys)\n\ndef get_num_blobs(img):\n    return len(blob_log(rgb2gray(img)))\n\ndef binned_mode_features(img, nbins=100):\n                                          \n    steps=np.arange(start=0,stop=1, step=1/nbins)\n                                                                            \n    ## red ##\n    #split on mean\n    m=img[:,:,0].flatten().mean()\n    left = img[:,:,0].flatten()[img[:,:,0].flatten()<m]\n    right = img[:,:,0].flatten()[img[:,:,0].flatten()>=m]\n    #find mode in left and right\n    max_ind_left = np.histogram(left, bins=steps, density=False)[0].argsort()[-1:]\n    max_ind_right = np.histogram(right, bins=steps, density=False)[0].argsort()[-1:]\n    #calc bimodal metric\n    mo1 = np.histogram(right, bins=steps, density=False)[1][max_ind_right]\n    mo2 = np.histogram(left, bins=steps, density=False)[1][max_ind_left]\n    mods_diff_r=abs(mo1-mo2)\n\n    ## green ##\n    m=img[:,:,1].flatten().mean()\n    left = img[:,:,1].flatten()[img[:,:,1].flatten()<m]\n    right = img[:,:,1].flatten()[img[:,:,1].flatten()>=m]\n    max_ind_left = np.histogram(left, bins=steps, density=False)[0].argsort()[-1:]\n    max_ind_right = np.histogram(right, bins=steps, density=False)[0].argsort()[-1:]\n    mo1 = np.histogram(right, bins=steps, density=False)[1][max_ind_right]\n    mo2 = np.histogram(left, bins=steps, density=False)[1][max_ind_left]\n    mods_diff_g=abs(mo1-mo2)\n\n    ## blue ##\n    m=img[:,:,2].flatten().mean()\n    left = img[:,:,2].flatten()[img[:,:,2].flatten()<m]\n    right = img[:,:,2].flatten()[img[:,:,2].flatten()>=m]\n    max_ind_left = np.histogram(left, bins=steps, density=False)[0].argsort()[-1:]\n    max_ind_right = np.histogram(right, bins=steps, density=False)[0].argsort()[-1:]\n    mo1 = np.histogram(right, bins=steps, density=False)[1][max_ind_right]\n    mo2 = np.histogram(left, bins=steps, density=False)[1][max_ind_left]\n    mods_diff_b=abs(mo1-mo2)\n\n    return mods_diff_r[0], mods_diff_g[0], mods_diff_b[0]\ndef get_features(img):\n    \"\"\"Input is a Nx256x256x3 numpy array of images, where N is number of images\"\"\"\n        \n    # METRIC FOR BIMODALITY\n    # bin each color intensity (histogram)\n    # find 2 most populated bins\n    # subtract and abs() to quantify bimodality\n        \n    r = img[:,:,0].ravel()\n    g = img[:,:,1].ravel()\n    b = img[:,:,2].ravel()\n                \n    s = xform_to_sobel(img)\n    \n    can = xform_to_canny(img, 0.5)\n    \n    #hough, _, _ = hough_line(rgb2gray(img))\n    \n    r_mean = np.mean(r)\n    g_mean = np.mean(g)\n    b_mean = np.mean(b)\n    \n    r_std = np.std(r)\n    g_std = np.std(g)\n    b_std = np.std(b)\n    \n    r_max = np.max(r)\n    b_max = np.max(b)\n    g_max = np.max(g)\n    \n    r_min = np.min(r)\n    b_min = np.min(b)\n    g_min = np.min(g)\n    \n    r_kurtosis = scipy.stats.kurtosis(r)\n    b_kurtosis = scipy.stats.kurtosis(b)\n    g_kurtosis = scipy.stats.kurtosis(g)\n    \n    r_skew = scipy.stats.skew(r)\n    b_skew = scipy.stats.skew(b)\n    g_skew = scipy.stats.skew(g)\n    \n    sobel_mean = np.mean(s.ravel())\n    sobel_std = np.std(s.ravel())\n    sobel_max = np.max(s.ravel())\n    sobel_min = np.min(s.ravel())\n    sobel_kurtosis = scipy.stats.kurtosis(s.ravel())\n    sobel_skew = scipy.stats.skew(s.ravel())\n    sobel_rowmean_std = np.std(np.mean(s,axis=1))\n    sobel_colmean_std = np.std(np.mean(s,axis=0))\n    \n    canny_mean = np.mean(can.ravel())\n    canny_std = np.std(can.ravel())\n    canny_max = np.max(can.ravel())\n    canny_min = np.min(can.ravel())\n    canny_kurtosis = scipy.stats.kurtosis(can.ravel())\n    canny_skew = scipy.stats.skew(can.ravel())\n    canny_rowmean_std = np.std(np.mean(can,axis=1))\n    canny_colmean_std = np.std(np.mean(can,axis=0))\n    \n    r_bimodal, g_bimodal, b_bimodal = binned_mode_features(img)\n    \n    #n_blobs = get_num_blobs(img)\n    \n    #hough_mean = np.mean(hough)\n    #hough_std = np.std(hough)\n    #hough_max = np.max(hough)\n    #hough_min = np.max(hough)\n    #hough_kurtosis = scipy.stats.kurtosis(hough.ravel())\n    #hough_skew = scipy.stats.skew(hough.ravel())\n                  \n    return pd.Series(\n        {'r_mean':r_mean, 'g_mean':g_mean, 'b_mean':b_mean,\n         'r_std':r_std, 'g_std':g_std, 'b_std':b_std,\n         'r_max':r_max, 'g_max':g_max, 'b_max':b_max,\n         'r_min':r_min, 'g_min':g_min, 'b_min':b_min,\n         'r_kurtosis':r_kurtosis, 'g_kurtosis':g_kurtosis, 'b_kurtosis':b_kurtosis,\n         'r_skew':r_skew, 'g_skew':g_skew, 'b_skew':b_skew,\n         'sobel_mean':sobel_mean, 'sobel_std':sobel_std, \n         'sobel_max':sobel_max, 'sobel_min':sobel_min,\n         'sobel_kurtosis':sobel_kurtosis, 'sobel_skew':sobel_skew,\n         'sobel_rowmean_std':sobel_rowmean_std, 'sobel_colmean_std':sobel_colmean_std,\n         'canny_mean':canny_mean, 'canny_std':canny_std, \n         'canny_max':canny_max, 'canny_min':canny_min,\n         'canny_kurtosis':canny_kurtosis, 'canny_skew':canny_skew,\n         'canny_rowmean_std':canny_rowmean_std, 'canny_colmean_std':canny_colmean_std,\n         'r_bimodal':r_bimodal, 'g_bimodal':g_bimodal, 'b_bimodal':b_bimodal\n         #'n_blobs':n_blobs\n         #'hough_mean':hough_mean, 'hough_std':hough_std, 'hough_max':hough_max,\n         #'hough_min':hough_min, 'hough_kurtosis':hough_kurtosis, 'hough_skew':hough_skew\n        })","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"7e94d9a53db2b8ba150dcb24bae2e4b5538d750b","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"95c547ce-c9b3-420b-95c3-f51588591b43"},"source":"y = tagged_df\n\nX = pd.DataFrame([])\nfor i in np.arange(0,99):\n    x  = get_features(X_sample[i,])\n    X =  X.append(x, ignore_index=True)\nX","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"28f2da25ef30b5a68695efb560dfa20d54e81f28","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"4ad4d9e8-da61-400c-8484-125f4ebebb15"},"source":"#create table of each feature histograms for each label\nX.set_index(y.index[0:99], inplace=True)\nprint(X.columns) #possible features to plot\n","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"ad2c86e56d290b9b10097dc3aacd13bd5657bc44","_execution_state":"idle","collapsed":false,"_cell_guid":"c968545e-b1ae-4564-805e-c61ccbbe7796"},"source":"The list above shows all the features that have been created. To check if these features actually describe patterns in the classed, I plotted histograms of the features by each tag. If the patterns in the histograms differ, then the feature may be informative in defining the classes. The two features plotted below are for the blue bimodal feature, and the sobel column mean standard deviation.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"8fdc05a0d99954dea0f468cdd75e8ed33c23fb72","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"4b136e9d-1304-4bbc-b6f7-116f71abe90f"},"source":"plt.rcParams['figure.figsize'] = (10, 20)\n#function to plot distributions of a features by class label\ndef plot_a_feature_by_labels(feature):\n    colors = cm.rainbow(np.linspace(0, 1, len(y.columns))) #pick colors for plots by labels\n    for i in np.arange(0, len(y.columns)-1):\n        col=y.columns[i]\n        ind_list = y[y[col]==1].index.tolist()\n        X.ix[ind_list][feature].hist(bins=25, color=colors[i])\n        plt.title(col)\n        plt.grid(True)\n        plt.subplot(6,3,i+1) \n\nprint(\"Blue bimodal feauture\")\nplot_a_feature_by_labels('b_bimodal')   \nplt.show()\nprint(\"sobel column mean standard deviation\")\nplot_a_feature_by_labels('sobel_colmean_std')\nplt.show()","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"fc94604f0d27485e748a1e754c2835fe8f9879d9","_execution_state":"idle","collapsed":false,"_cell_guid":"c00d43dc-9ea3-4d1e-82a6-3b404bb54d6e"},"source":"## Random Forest Modeling\nRandom Forest with balanced sampling to account for unbalanced classes.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"8019f8325ece9c70ae58fe8d18ecac632535e0fe","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"6997b1a9-3493-405f-8e75-f546c3aaac9d"},"source":"#do a test/train split\nfrom sklearn.model_selection import train_test_split\nX_train, X_validation, y_train, y_validation = train_test_split(X, y[0:99], test_size=0.40, random_state=14113) \n\nprint('X_train is a {} object'.format(type(X_train)))\nprint('it has shape {}'.format(X_train.shape))\n\nprint('y_train is a {} object'.format(type(y_train)))\nprint('it has {} elements'.format(len(y_train)))","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"92ec1c93ca5bc5493ef88e09d60b3bc17d3f23eb","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"6cc384bd-258c-4900-a88b-bb7aa9bfe0ad"},"source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 100, \n                            max_features = 'sqrt',\n                            bootstrap = True, \n                            oob_score = True,\n                            n_jobs = -1,\n                            random_state = 14113,\n                            class_weight = 'balanced_subsample')\n\nrf.fit(X_train, y_train)\nprint('The oob error for this random forest is {}'.format(rf.oob_score_.round(2)))","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"ec9878862fed06d49dcdd13fc724fa67315c7076","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"2477fbfb-443c-447a-a338-ded0c5a148d4"},"source":"#features ranking of features. \nFeature_importance = pd.DataFrame(rf.feature_importances_, X_train.columns)\ndef plot_feature_importance(Feature_importance, n):\n    '''\n    plot top n features\n    '''\n    plt.rcParams['figure.figsize'] = (12, 5)\n    Feature_importance = pd.DataFrame(rf.feature_importances_, X_train.columns)\n    Feature_importance.columns = ['features']\n    Feature_importance = Feature_importance.sort_values(by='features', axis=0, ascending=False)\n    colors = cm.gist_heat(np.linspace(0, 1, len(tagged_df.columns)))\n    Feature_importance.head(n).plot(title=\"Counts of Tags\", color=colors, kind='bar')\n    plt.show()\n\nplot_feature_importance(Feature_importance, 15)","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"d4b4f8347e0b1da18e1e392b7353f27aba9bae1a","_execution_state":"idle","collapsed":false,"_cell_guid":"e4c61441-1b47-40c5-8629-d3900bce9563"},"source":"## F2-score and other metrics\nCompute the F2-score because this is the metric used to score the competition. The F2 score is calculated from precision and accuracy, and weights the recall higher than the precision. (Note the warning is for the classes with very small sample size.)\nROC curves visualize performance of a classifier via precision and recall tradeoff. Visualization of how predicted probabilities compare to the truth. The ROC curve and histogram look at the performance of two classes, a large class and a small (agriculture and bare ground). The model performs well for tags with large sample size, but poor recall performance come from the small classes.","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"aaf66e9f5c44c26a78b0b91f4dc8a83510c1f6af","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"53a69595-b1b9-41b1-88d7-621b02ac1405"},"source":"from sklearn.metrics import fbeta_score\nnp.asarray(y_validation)\npredictions = rf.predict(X_validation)\nfbeta_score(np.asarray(y_validation), predictions, beta=2, average='samples')","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"d35fd416a9ede3389661d0705d39b154e01d0118","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"0f23d4b2-7c9b-49ab-8254-2b4e01272ce8"},"source":"from sklearn.metrics import precision_recall_fscore_support as score\nprecision, recall, fscore, support = score(y_validation, predictions)\nMetrics = pd.DataFrame([precision, recall, support], index=['precision', 'recall', 'support'])\nMetrics.columns = y_validation.columns\nMetrics","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"359678c5929c712dad5f27ba64759855f75c1c2e","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"6ca7183f-0e6a-42fd-aae7-c147bfe0744a"},"source":"probs = rf.predict_proba(X_validation)\n\nfrom sklearn import metrics\n\ndef plot_ROC(tag):\n    '''\n    plot ROC curve for a specific tag\n    '''\n    plt.rcParams['figure.figsize'] = (6,6)\n    n = np.where(y_validation.columns==tag)[0][0]\n    fpr, tpr, threshs = metrics.roc_curve(y_validation[tag], probs[n][:,1],\n                                          pos_label=None, sample_weight=None, drop_intermediate=False)\n    plt.figure()\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=lw)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(tag+'\\nReceiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \nplot_ROC('agriculture')\nplot_ROC('bare_ground')","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"8affb99b0bc247db7cda3c00cb0189a725d5aed9","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"7a88e73f-a397-45ac-b5c0-a17afbc909dc"},"source":"def plot_decision_hist(tag):\n    '''\n    plots decision histograms with thresholds\n    '''\n    plt.rcParams['figure.figsize'] = (6,6)\n    #Less than .5 is 0. greater is 1\n    n = np.where(y_validation.columns==tag)[0][0]\n    probs_df = pd.DataFrame(probs[n][:,1]).set_index(y_validation[tag])\n    class0 =  np.array(probs_df.ix[0][0]) #0 does not have true tag\n    class1 =  np.array(probs_df.ix[1][0]) #1 does have true tag\n\n    S = class0\n    # Histogram:\n    # Bin it\n    n, bin_edges = np.histogram(S, 30)\n    # Normalize it, so that every bins value gives the probability of that bin\n    bin_probability = n/float(n.sum())\n    # Get the mid points of every bin\n    bin_middles = (bin_edges[1:]+bin_edges[:-1])/2.\n    # Compute the bin-width\n    bin_width = bin_edges[1]-bin_edges[0]\n    # Plot the histogram as a bar plot\n    plt.bar(bin_middles, bin_probability, width=bin_width, color='red', alpha=.4)\n\n    S = class1\n    n, bin_edges = np.histogram(S, 30)\n    bin_probability = n/float(n.sum())\n    bin_middles = (bin_edges[1:]+bin_edges[:-1])/2.\n    bin_width = bin_edges[1]-bin_edges[0]\n    plt.bar(bin_middles, bin_probability, width=bin_width, color='green', alpha=.8)\n\n    plt.axvline(x=0.5, color='k', linestyle='--')\n    plt.title(tag+'\\nScore distributions with splitting on a 0.5 threshold')\n    plt.xlabel('Classification model score')\n    plt.ylabel('Frequency')\n    plt.show()\n    \nplot_decision_hist('agriculture')\nplot_decision_hist('bare_ground')    ","execution_count":null,"cell_type":"code"},{"outputs":[],"metadata":{"_uuid":"c4dd2368ee07b90dcc2d5cedc38f1402c9198b23","_execution_state":"idle","collapsed":false,"_cell_guid":"e549327b-f606-4222-9e8b-ed20aa4070ce"},"source":"This model performs well on the  classes with large sample sizes, but misses the small classes. ","execution_count":null,"cell_type":"markdown"},{"outputs":[],"metadata":{"_uuid":"69a917ac800b76ddb23284364aaaaf231242427f","_execution_state":"idle","trusted":false,"collapsed":false,"_cell_guid":"30544016-d484-40ba-96be-573d60aafd1b"},"source":"","execution_count":null,"cell_type":"code"}],"nbformat_minor":0,"nbformat":4}