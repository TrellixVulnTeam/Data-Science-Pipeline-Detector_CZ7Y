{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import date\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n# Following the notes from fast.aitutorial docs - https://docs.fast.ai/tutorial.data.html\n# Adding Resnet 18 dataset\n\n#Learnt a lot from these two.. https://www.kaggle.com/hortonhearsafoo/fast-ai-lesson-2\n#From: https://nbviewer.jupyter.org/github/arunoda/fastai-courses/blob/master/dl1/lesson3-planet.ipynb#Test-Dataset\n\n# First of all, we need to find some metrics \n# Basically these are just for printing only.\n# Since this is a multi classification problem, we need to use a threshold for the \n# accuracy.\ndef p_accuracy(pred, act, **kwargs):\n    return accuracy_thresh(pred, act, thresh=0.2, **kwargs)\n#This kaggle competition uses f2 score for the final eval. So we should use that as well.\ndef f2_score(pred, act, **kwargs):\n    return fbeta(pred, act, beta=2, thresh=0.2, **kwargs)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dac0cb6fce5c63fd09ff56e02eb11338e339c68"},"cell_type":"code","source":"# This file contains all the main external libs we'll use - fastai v1\nfrom fastai import *\nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61b03f6187390691a9aad542a68db729296db165"},"cell_type":"code","source":"debug = 0\nPATH = \"/kaggle/input/planet-understanding-the-amazon-from-space/\"\n# 32 when testing variable building to 256 when for real\nif debug:\n    sz=32 \n    print(\"In low res debug mode - quick but not accurate at all\")\nelse:\n    sz=256\n    print(\"In high res mode - slow, looking for that final result\")\nTMP_PATH = \"/tmp/tmp\"\nMODEL_PATH = \"/tmp/model/\"\narch = 'resnet18' #just for naming the submission file\ncomp_name = \"planet\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e2253ce82be0ec1de612585b7dc44db9a143137"},"cell_type":"code","source":"!ls {PATH} # directory for training and test files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c942916a9d2678d8f30396998d678c1d12bf3f6"},"cell_type":"code","source":"label_df = pd.read_csv(f'{PATH}train_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d64212c32923aaea552705b70351d59f558ae875"},"cell_type":"code","source":"#what does the csv file look like id is the file name (minus .jpg), breed is the classification\nlabel_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74631fa4de65b910ef267867e760ad9a6f512832"},"cell_type":"code","source":"# What are the different tags? \nlabel_df.pivot_table(index='tags', aggfunc=len).sort_values('image_name', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d2f4dc7344c0ed7d4f5e37e85db7312d2b2d145"},"cell_type":"code","source":"# GPU required\ntorch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48dee6bc52192d033d91414359781750320e56ac"},"cell_type":"code","source":"torch.backends.cudnn.enabled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0de0042c226965eb25eeffdb84cdde3322cd4c9"},"cell_type":"code","source":"# Fix to enable Resnet to live on Kaggle - creates a writable location for the models\ncache_dir = os.path.expanduser(os.path.join('~', '.torch'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n   # print(\"directory created :\" .cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n  #  print(\"directory created :\" . cache_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faeef12764f05ba8ddbf4fbbb88d704c09f1da9b"},"cell_type":"code","source":"#copying model to writable location\n#cd /kaggle/working\nshutil.copy(\"/kaggle/input/resnet18/resnet18.pth\", \"/tmp/.torch/models/resnet18-5c106cde.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1a1f386fea11ade46c3b836fc653f4fa8f5b10e"},"cell_type":"code","source":"tfms = get_transforms(do_flip=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea65c4211c4603b031e7351707ad6db57694d0fc"},"cell_type":"code","source":"def get_data(sz):\n    tfms = get_transforms(do_flip=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n    \n    data = (\n        ImageItemList\n            .from_csv(PATH, 'train_v2.csv', folder=\"train-jpg\", suffix=\".jpg\")\n            .random_split_by_pct(0.2)\n            .label_from_df(sep=' ')\n            .transform(tfms, size=sz)\n            .add_test_folder('test-jpg-v2')\n            .databunch(num_workers=0)\n            .normalize(imagenet_stats)\n    )\n    return data\n#crashes with too many workers (remove numworkers while testing with a small image size ~ 64), keep for the bigger images for accuracy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b610a1d74a700c38c33fd5ef0ffa0b0f9d09893"},"cell_type":"code","source":"#Cause learning on 64x64\nsz=64\ndata = get_data(sz)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"270b81355fa05fa307f72e95a269d697b8fc67f0"},"cell_type":"code","source":"len(data.classes), data.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"60ff31ba162f448b90e80c897b286aa0d9051adb"},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(10,12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3721152c6f6ef269f5f2e2369dad3100a9cd6a1"},"cell_type":"code","source":"img = plt.imread(f'{PATH}train-jpg/{label_df.iloc[0,0]}.jpg')\nplt.imshow(img);\n# all images are 256 x 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3301c5813a4d6ea56025449109e24555ff7c87c3"},"cell_type":"code","source":"img.size","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be46f0ac1d112fe50b5cae41d6febbe51b001691"},"cell_type":"markdown","source":"### Intial model "},{"metadata":{"trusted":true,"_uuid":"5fd9ff5b9602a95b6d40ea5d1916b6f8080f6e57"},"cell_type":"code","source":"learn = create_cnn(data, models.resnet18, model_dir=MODEL_PATH, metrics=[p_accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6edfe597ca55e2dc7a98fdf8b07ee052e2a55fd3","scrolled":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06c1819cdba4e2aa04104525474d6e7a50b38fb0","scrolled":false},"cell_type":"code","source":"lr = 1e-1\nlearn.fit_one_cycle(5, slice(lr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fba0a030ff15974cc7785e1a410d4f5f9ec927e2"},"cell_type":"markdown","source":"### Let's add f2 as an metric"},{"metadata":{"trusted":true,"_uuid":"bbdc257605320706206cfa7cd9dfc10dde6a4ec0"},"cell_type":"code","source":"learn.metrics = [p_accuracy, f2_score]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0b3484eacf8567e4932435a62f670ec22b75512"},"cell_type":"markdown","source":"### Unfreeze"},{"metadata":{"trusted":true,"_uuid":"bced74574f567244dbee920ecf0a47f989eb4831"},"cell_type":"code","source":"learn.unfreeze() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ce05868f9602abaab7225c7a55613b369009c39"},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1005c16320ad69b297b11f49bb90e7ebd9f41cb9"},"cell_type":"code","source":"if debug:\n    learn.fit_one_cycle(1, max_lr=(1e-6, 1e-5, 1e-4))\nelse:\n    learn.fit_one_cycle(3, max_lr=(1e-6, 1e-5, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ece4734f86eaa816f8d29b8389110c1475804b3"},"cell_type":"markdown","source":"### Look at the images as 128 px resolution"},{"metadata":{"trusted":true,"_uuid":"92eb942cfc7e33525c073a5b685d9caeb835d3a1"},"cell_type":"code","source":"sz=128\nlearn.data = get_data(sz)\nlearn.freeze()\nlearn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"716ed239a90a650cd19fbea6897469f3aa86eb00"},"cell_type":"code","source":"if debug:\n    learn.fit_one_cycle(1, slice(1e-5, 1e-3))\nelse: \n    learn.fit_one_cycle(3, slice(1e-5, 1e-3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f142846519f0081f58dae9c1d0b2bc54c696aae"},"cell_type":"markdown","source":"### Unfreeze"},{"metadata":{"trusted":true,"_uuid":"c79b2bcb04eb14d2dce74d348efb0b6b387b8af8"},"cell_type":"code","source":"sz=256\nlearn.data = get_data(sz)\nlearn.freeze()\nlearn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f28c3f5fa51912848675f4920dd6794408d56b6f","scrolled":true},"cell_type":"code","source":"if debug:\n    learn.fit_one_cycle(1, slice((1e-2)/2, (1e-1)/2))\nelse:\n    learn.fit_one_cycle(3, slice((1e-2)/2, (1e-1)/2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e858e8ec091936241dcfab5cf7769936c270498f"},"cell_type":"code","source":"learn.unfreeze();\nlearn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32ca4a2595c9ec2c289d2e910ea9849db417c87d"},"cell_type":"code","source":"if debug:\n    learn.fit_one_cycle(1,  slice(1e-6, 1e-5))\nelse:\n    learn.fit_one_cycle(5,  slice(1e-6, 1e-5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9974cb606cfb411a3492f747b5b9a14c9f672dc","scrolled":true},"cell_type":"code","source":"learn.show_results(rows=3, figsize=(12,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bf9e3b6f6a996561b80053acb38669c428a825c"},"cell_type":"code","source":"# from https://nbviewer.jupyter.org/github/arunoda/fastai-courses/blob/master/dl1/lesson3-planet.ipynb#Test-Dataset\ndef get_tags(pred, thresh):\n    classes = \"\"\n    best_guess = \"\"\n    tags = 0\n    high_val = 0\n    if debug:\n        thresh = 0.2\n        print(f\"Debug - using low threshold {thresh}\")\n    for idx, val in enumerate(pred):\n        if val > thresh:\n            classes = f'{classes} {learn.data.classes[idx]}'\n            tags = tags+1\n        if val > high_val:\n            high_val = val\n            best_guess = f'{learn.data.classes[idx]}'\n    if tags == 0:\n        classes = best_guess\n    return classes.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12bbecf867c6d07d398400ac3fc1c8efda38f4b6"},"cell_type":"code","source":"def predict(idx):\n    pred_vals = predictions[0][idx]\n    tags = get_tags(pred_vals, 0.2)\n    print(tags)\n    img = learn.data.test_ds[idx][0]\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecf9744b6ced86c2aa43757f2aa8e644781a44da"},"cell_type":"code","source":"def get_row(idx):\n    pred = predictions[0][idx]\n    tags = get_tags(pred, 0.2)\n    image_path = learn.data.test_ds.x.items[idx]\n    image_name = re.search(r'([^/]+)$', f'{image_path}')[0].replace('.jpg', '') \n    return image_name, tags","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4092ba1ea6316a7ee5cc8b00666fe41aa4716486"},"cell_type":"code","source":"len(learn.data.test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29a142cacc9225988bf1afcb142e4be0edeba74c"},"cell_type":"code","source":"predictions = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e1943aed51b3a5bd90377366996427d3cff039f8"},"cell_type":"code","source":"predict(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"637358f97da4baa4ef6d081c24947c36828c7abe"},"cell_type":"code","source":"df = pd.DataFrame(columns=['image_name', 'tags'])\nfor idx in range(len(predictions[0])):\n    if idx % 5000 == 0:\n        print(f\"Completed: {idx}\")\n        \n    image_name, tags = get_row(idx)\n    df.loc[idx] = [image_name, tags]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f42419eb00393bf2520a067f92eb428d0df67671"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d42733dcba400660823ce205d365ed535aaccd8a"},"cell_type":"code","source":"dt = date.today()\ndate_str = dt.isoformat()\nsubmission_path = f'submission-256-{date_str}-size.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef22b30be3ca718656f5d03590464810ec191ba6"},"cell_type":"code","source":"df.to_csv(submission_path, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6afde65b86b21f9a167a558396a09a00c72c136b","scrolled":true},"cell_type":"code","source":"!head {submission_path}","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}