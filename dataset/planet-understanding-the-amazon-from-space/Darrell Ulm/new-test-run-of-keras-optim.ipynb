{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ead9ad26-645a-67ab-dd70-b1c11e857df0"},"source":"Thank you to @anokas for source code at https://www.kaggle.com/anokas/planet-understanding-the-amazon-from-space/simple-keras-starter/"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7d410c7-f998-dff8-7a24-2ac74cb5e0f5"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\n\nimport keras as k\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nimport cv2\nfrom tqdm import tqdm\n\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import fbeta_score\nimport time"},{"cell_type":"markdown","metadata":{"_cell_guid":"2ef20ca3-ccf0-3756-43e1-6f4eef4e4fd7"},"source":"pre-proc test/train."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ee3230e-2334-a865-76fd-4e8efcf0dade"},"outputs":[],"source":"x_train = []\nx_test = []\ny_train = []\n\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/sample_submission.csv')\n\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n\nlabels = ['blow_down',\n 'bare_ground',\n 'conventional_mine',\n 'blooming',\n 'cultivation',\n 'artisinal_mine',\n 'haze',\n 'primary',\n 'slash_burn',\n 'habitation',\n 'clear',\n 'road',\n 'selective_logging',\n 'partly_cloudy',\n 'agriculture',\n 'water',\n 'cloudy']\n\nlabel_map = {'agriculture': 14,\n 'artisinal_mine': 5,\n 'bare_ground': 1,\n 'blooming': 3,\n 'blow_down': 0,\n 'clear': 10,\n 'cloudy': 16,\n 'conventional_mine': 2,\n 'cultivation': 4,\n 'habitation': 9,\n 'haze': 6,\n 'partly_cloudy': 13,\n 'primary': 7,\n 'road': 11,\n 'selective_logging': 12,\n 'slash_burn': 8,\n 'water': 15}\n\nfor f, tags in tqdm(df_train.values[:18000], miniters=1000):\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1 \n    x_train.append(cv2.resize(img, (32, 32)))\n    y_train.append(targets)\n\nfor f, tags in tqdm(df_test.values, miniters=1000):\n    img = cv2.imread('../input/test-jpg/{}.jpg'.format(f))\n    x_test.append(cv2.resize(img, (32, 32)))\n    \ny_train = np.array(y_train, np.uint8)\nx_train = np.array(x_train, np.float32) / 255.\nx_test  = np.array(x_test, np.float32) / 255.\n\nprint(x_train.shape)\nprint(y_train.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c405653c-ad09-7f27-e6c3-46f69fa68e32"},"source":"If use Theano then transpose data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98204397-e87c-7530-9ca9-78335aba9b92"},"outputs":[],"source":"#x_train = x_train.transpose((0, 3, 1, 2))\n#x_test = x_test.transpose((0, 3, 1, 2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"9150f6db-6b97-1fe3-42af-607d640df739"},"source":"For x-validate make n-folds."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10912110-fbdb-06e0-16cc-21a4b6d9f907"},"outputs":[],"source":"# https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475\nimport numpy as np\nfrom sklearn.metrics import fbeta_score\n\ndef optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n  def mf(x):\n    p2 = np.zeros_like(p)\n    for i in range(17):\n      p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n    score = fbeta_score(y, p2, beta=2, average='samples')\n    return score\n\n  x = [0.2]*17\n  for i in range(17):\n    best_i2 = 0\n    best_score = 0\n    for i2 in range(resolution):\n      i2 /= resolution\n      x[i] = i2\n      score = mf(x)\n      if score > best_score:\n        best_i2 = i2\n        best_score = score\n    x[i] = best_i2\n    if verbose:\n      print(i, best_i2, best_score)\n\n  return x"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5b79bc1-fb26-a87b-f2ab-23c1b37a00c0"},"outputs":[],"source":"from keras.layers.normalization import BatchNormalization\n\nnfolds = 3\n\nnum_fold = 0\nsum_score = 0\n\nyfull_test = []\nyfull_train =[]\n\nkf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)\n\nfor train_index, test_index in kf:\n        start_time_model_fitting = time.time()\n        \n        X_train = x_train[train_index]\n        Y_train = y_train[train_index]\n        X_valid = x_train[test_index]\n        Y_valid = y_train[test_index]\n\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        print('Split train: ', len(X_train), len(Y_train))\n        print('Split valid: ', len(X_valid), len(Y_valid))\n        \n        kfold_weights_path = os.path.join('', 'weights_kfold_' + str(num_fold) + '.h5')\n        \n        model = Sequential()\n        model.add(BatchNormalization(input_shape=(32, 32, 3)))\n        model.add(Conv2D(8, 1, 1, activation='relu'))\n        model.add(Conv2D(16, 2, 2, activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Conv2D(32, 3, 3, activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(64, 3, 3, activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n        model.add(Flatten())\n        model.add(Dense(256, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(17, activation='sigmoid'))\n\n        model.compile(loss='binary_crossentropy', \n                      optimizer='adam',\n                      metrics=['accuracy'])\n        callbacks = [\n            EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n        \n        model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n                  batch_size=128,verbose=2, nb_epoch=10,callbacks=callbacks,\n                  shuffle=True)\n        \n        if os.path.isfile(kfold_weights_path):\n            model.load_weights(kfold_weights_path)\n        \n        p_valid = model.predict(X_valid, batch_size = 128, verbose=2)\n        print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n        print(\"Optimizing prediction threshold\")\n        print(optimise_f2_thresholds(Y_valid, p_valid))\n        \n        p_test = model.predict(x_train, batch_size = 128, verbose=2)\n        yfull_train.append(p_test)\n        \n        p_test = model.predict(x_test, batch_size = 128, verbose=2)\n        yfull_test.append(p_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"33dba992-7427-37bb-e233-d33b00c77c0b"},"source":"Avg for each fold."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56d6d764-54a1-c68e-ba16-a44f46328aef"},"outputs":[],"source":"result = np.array(yfull_test[0])\nfor i in range(1, nfolds):\n    result += np.array(yfull_test[i])\nresult /= nfolds\nresult = pd.DataFrame(result, columns = labels)\nresult"},{"cell_type":"markdown","metadata":{"_cell_guid":"237fd9e0-4ef4-2a9a-c62d-cf7ea5ecc329"},"source":"Predict."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e71169d-c19a-6e4c-eb26-e14722ccaae5"},"outputs":[],"source":"from tqdm import tqdm\nthres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\npreds = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.ix[[i]]\n    a = a.apply(lambda x: x > thres, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    preds.append(' '.join(list(a.index)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6b423b2-2432-7bd0-5f8e-ef2fe8d49bd0"},"outputs":[],"source":"df_test['tags'] = preds\ndf_test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57278b15-31ba-6800-523d-c6a63fc287f3"},"outputs":[],"source":"df_test.to_csv('submission_keras.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}