{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!ls","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"6516a789-901d-4c39-99a5-a82803b856c6","_uuid":"20e3637c962648a89e979bc3c28fb844c97c549a","collapsed":true,"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"f0bf7f79-4acf-457d-ac27-ca3f8848568d","_uuid":"b50b0f768c6c7afce16bf001f7bf06e3a050126a","collapsed":true,"trusted":true},"cell_type":"code","source":"from fastai.conv_learner import *","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"d54d54b3-6f92-4d61-a810-21054049e599","_uuid":"8a7ebc15f32f80a149b9efb1e907e1633f3d73ff","collapsed":true,"trusted":true},"cell_type":"code","source":"PATH = '../input/planet-understanding-the-amazon-from-space/'","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"dc18d216-1070-4880-97fd-f238eb18c205","_uuid":"ca537b1c066181835e93e945e8ad94fb11f3a0a2","trusted":true},"cell_type":"code","source":"ls {PATH}","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"e7c19983-a8f4-4ae5-8334-202777d88d25","_uuid":"0fadf737b2c6163185d9f3f4d50c584baac7fe66","trusted":true},"cell_type":"code","source":"# Visualizing data:\nfrom fastai.plots import *\nlist_paths = [f'{PATH}train-jpg/train_0.jpg', f'{PATH}train-jpg/train_1.jpg']\ntitles = ['haze primary', 'agriculture clear water primary']\nplots_from_files(list_paths, titles=titles, maintitle='Multi-labeled classification')","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"f4f4d621-ae17-4afd-ada0-dfff453431e3","_uuid":"20e83b6c1506ccf010816442cdd4ffb1de571c31","collapsed":true,"trusted":true},"cell_type":"code","source":"# Helper function for f2 metric evaluation\nimport warnings\nfrom sklearn.metrics import fbeta_score\ndef f2(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n                    for th in np.arange(start,end,step)])","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"c0c31ab0-2b23-4b9e-98ff-a731d4c78228","_uuid":"29e5009aadf4c868a0df5f300e2ddcf48201d087","collapsed":true,"trusted":true},"cell_type":"code","source":"metrics = [f2]\nmodel = resnet34","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"7d2c0642-78a8-42da-ab91-848d25863510","_uuid":"81ec82384eccbfb69cd8b50eed6200eb36df86ca","trusted":true},"cell_type":"code","source":"# Perparing cross validation data:\nlabel_csv = f'{PATH}train_v2.csv'\nn = len(list(open(label_csv))) - 1\nval_idxs = get_cv_idxs(n) # Automatically randomly selects 20% of validation indices\nval_idxs.shape","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"2c9ad213-fc7c-4807-9385-aeb5bed6f88a","_uuid":"56566846e599e97d99507c8b7d3f64d395d3f29d","collapsed":true,"trusted":true},"cell_type":"code","source":"def get_data(sz):\n    # Allow for top down data augmentation here as images are satellite images\n    tfms = tfms_from_model(model, sz, aug_tfms=transforms_top_down, max_zoom=1.1)\n    return ImageClassifierData.from_csv(PATH, 'train-jpg', label_csv, tfms=tfms, suffix='.jpg', val_idxs=val_idxs, test_name='test-jpg-v2')","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"1700461a-061c-47d8-8fb3-b629bb40816f","_uuid":"373d3c3d80e37585ec2bdddc4d0518051fbbb3ef","trusted":true},"cell_type":"code","source":"# Fetching data from above helper function:\ndata = get_data(256)\nx, y = next(iter(data.val_dl))\ny","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"5d8f454e-9bdb-429f-9556-466d16dc30e5","_uuid":"deb986eb0e0a0cd65be88d9d1a14e8b1390604e9","trusted":true},"cell_type":"code","source":"# View first validation's classes and labels\nlist(zip(data.classes, y[0]))","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"ec36422f-83e5-46cd-b2bd-96742ad9ea2b","_uuid":"dbfb203e0f03276b4ab2ec83c3234cfb6e0e07c6","collapsed":true,"trusted":true},"cell_type":"code","source":"sz = 64","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"8f603b9d-f34b-4847-bd4c-cd8c89a09dda","_uuid":"65f1967d33ac0ec12803f5817692335c854ad439","collapsed":true,"trusted":true},"cell_type":"code","source":"data = get_data(sz)","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"1b66d1f8-4d1a-4658-b03a-a28fa088e04e","_uuid":"d86d80d0f00793aa215c6b78843bd3685e1729e6","collapsed":true,"trusted":true},"cell_type":"code","source":"#import pathlib\n#data.path = pathlib.Path('.')\nfrom os.path import expanduser, join, exists\nfrom os import makedirs\ncache_dir = expanduser(join('~', '.torch'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"58ac6f26-260c-4806-ab6c-a947d59745d5","_uuid":"4b1d7d6e30aba5e68bb9cd249248fa865274211c","collapsed":true,"trusted":true},"cell_type":"code","source":"!cp ../input/resnet34/resnet34.pth /tmp/.torch/models/resnet34-333f7ec4.pth","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"33563c7f-f0c8-4e1b-8aa4-4f85741e5d13","_uuid":"1d080ff87db359cd465534100e44b19d048675ac","collapsed":true,"trusted":true},"cell_type":"code","source":"import pathlib\ndata.path = pathlib.Path('.')\n#data = data.resize(int(sz * 1.3), '.') # Tells to ignore training images more than sz * 1.3 to save time\nlearn = ConvLearner.pretrained(model, data, metrics=metrics)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"355a0560-85cb-4e77-a84d-47396b4f8060","_uuid":"124347d134d2fe7ac8fd29564c71a636fad29ce5","trusted":true},"cell_type":"code","source":"# Using learning rate finder to find a good initial starting learning rate\nlr = learn.lr_find()\nlearn.sched.plot()","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15051ce752d2949e8f8f498e92535ebb4c53b2af"},"cell_type":"code","source":"# Surprisingly lr is too large for this dataset, anyways we will use 0.2 as loss is clearly decreasing\nlr = 0.2\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)","execution_count":21,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"a71d0d0b92eddfdddf909200be34124e1ea2a452"},"cell_type":"code","source":"# The next step is to unfreeze the layers and use differential learning rates for training:\nlr_d = [lr/9, lr/3, lr] # The lr's are decreased by order of 3 per group towards initial layers of network\nlearn.unfreeze()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc3b8b5c785becf026a1f0c12efea71798e375f9"},"cell_type":"code","source":"learn.fit(lr_d, 3, cycle_len=1, cycle_mult=2)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"875874e5a6e8b6422a643558d8e10a1c139dfe20"},"cell_type":"code","source":"learn.sched.plot_loss()","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5be5e81dc8062c2bd8de667413b9c62af7369b7e"},"cell_type":"code","source":"# Training with images of size 128 now with layers of the model frozen and only the last f.c being trained\nsz = 128\nlearn.set_data(get_data(sz))\nlearn.freeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"20c2e9c41dfd9e905ba4f1aaa328bc46f7f1e894"},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit(lr_d, 3, cycle_len=1, cycle_mult=2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}