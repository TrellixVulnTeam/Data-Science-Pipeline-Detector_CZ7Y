{"nbformat_minor":0,"cells":[{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"b8dcc3a9-ced2-41b2-ba71-0e855626e32d","collapsed":false,"_uuid":"5247bddd63fb6bf65f65bacd7571933dc50f8057"},"source":"In this notebook I will be following this one: https://www.kaggle.com/robinkraft/getting-started-with-the-data-now-with-docs which is based on some basic image manipulation on Planet data.\nOriginal Notebook by Jesus Martinez Manso and Benjamin Goldenberg\n\n(C) Planet 2017"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"054da628-7614-46b5-a54c-49e338c1170a","_uuid":"25159899648cadafa14e0fbf6682112cd8e86a4f"},"source":"import sys\nimport os\nimport subprocess\n\nfrom six import string_types\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport scipy\nfrom skimage import io\nfrom scipy import ndimage\nfrom IPython.display import display\n%matplotlib inline\n"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"c593fbf9-9b9c-4718-b69f-d570f538cf86","collapsed":false,"_uuid":"e5d8dc75a624e5a1a82e0c2a164e3eeb6fa6d36b"},"source":"! ls -lrt ../input"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"82d3fd54-547b-46be-80b3-9af9caebaea1","collapsed":false,"_uuid":"90b40eb0b837c930246a4e5d2894cee8df56d5b0"},"source":"## Setup\n Lets set up some global variables for file locations and ensure that they exist when we run this notebook\n\n"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"5f817ea9-ecdb-4b24-9862-4823bfc777d1","collapsed":false,"_uuid":"937f0e41d5f3c5120d5c7e8ddb0c13b917c66c34"},"source":"PLANET_KAGGLE_ROOT = os.path.abspath('../input/')\nPLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\nPLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\nassert os.path.exists(PLANET_KAGGLE_ROOT)\nassert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\nassert os.path.exists(PLANET_KAGGLE_LABEL_CSV)            "},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"79dabec7-b2a3-4927-a628-1599e3ac1f59","collapsed":false,"_uuid":"ffbc6296ef595321d963e485d72d8f25cf1a2727"},"source":"## Inspect Image Labels\nImage labels are in the CSV file called train_v2.csv"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"fe74af58-4ce0-47d6-9d79-218b76611174","collapsed":false,"_uuid":"dbb9ac84189dce159fb9b1ce5bd9a13b1e11acd4"},"source":"!ls -lha /kaggle/input/train_v2.csv"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"f9bb1b89-0afc-4a92-8e7f-a6c97beadacb","collapsed":false,"_uuid":"c2b31a1b320909a4d6bca4f9d5c4b227123cde3b"},"source":"labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\nlabels_df.head()"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"f53c3dd6-0f85-462e-8d3c-65cc0102ba5c","collapsed":false,"_uuid":"672e2f9594e86dd06ed15d1db6fca7f1920fb22a"},"source":"Some of these labels contain more than one feature. Let's create a table that tells us the features that each image has more clearly. First lets extract all the possible labels seen in the labels df into a list"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"a1cb0de4-3b47-4e6e-a05a-a170d1565bfd","collapsed":false,"_uuid":"0db7ca449014e221d1c95572722da3558d0f7307"},"source":"label_list = []\nfor tag_str in labels_df.tags.values:\n    labels = tag_str.split(' ')\n    for label in labels:\n        if label not in label_list:\n            label_list.append(label)\nlabel_list\n#labels_df['tags']"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"0959aab9-aca1-4555-9df4-263c58b6f857","collapsed":false,"_uuid":"16a371a9f933487e826c8dfa8a281ccfb67f0994"},"source":"We will put the images into whats called a 'one hot' representation, where 1 represents if the image can be described by the label, with all labels as columns. We're essentially parsing the text of the csv file here."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"0e024794-2b98-4fc8-8f21-f7755b0cd924","collapsed":false,"_uuid":"991a94635c86f23e2aa4b39c596cc0bc95f77490"},"source":"for label in label_list:\n    labels_df[label] =  labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0 )\n  \nlabels_df.head()"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"61e934b7-252a-4896-b42a-515de6d8f4e5","collapsed":false,"_uuid":"848f782e580f64f856b71493d8849ad847e716e2"},"source":"Now lets visualize the frequency of each label."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"bdd6ab3c-1be9-4688-97c8-06287bac6c30","collapsed":false,"_uuid":"3de2d5b72a1a95aca0adc386134726b7049a635a"},"source":"labels_df[label_list].sum().sort_values().plot.bar()"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"2c734500-16ad-403c-8965-775fbaef3833","collapsed":false,"_uuid":"6d858f300e4141bbf42426d20a9062a936b30620"},"source":"def make_cooccurrence_matrix(labels):\n    numeric_df = labels_df[labels]\n    c_matrix = numeric_df.T.dot(numeric_df)\n    sns.heatmap(c_matrix)\n    return c_matrix\n\nmake_cooccurrence_matrix(label_list)"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"61b05da8-1e6c-4b0f-89c6-4aa0f4a93355","collapsed":false,"_uuid":"d869c4e9af91c39998b0724d34be25609241ffa5"},"source":"Check that each image has only one weather label."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"7d024f46-8430-40c9-9a0d-19529cc955fa","collapsed":false,"_uuid":"0edbffef17a1681530f2c4cb502396d5fc77f90f"},"source":"weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\nmake_cooccurrence_matrix(weather_labels)"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"f9fc6b68-39fb-4dbb-a093-05ed8d901c4e","collapsed":false,"_uuid":"032c7f4def65071a188fe1bdecc381f0ef152a59"},"source":"However for land labels, we may have more than one label"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"f349253c-57d0-4807-b2a3-a4b73a7d6c39","collapsed":false,"_uuid":"47a2cbf64f54f6d171542a96cbe8b783e2d3fb08"},"source":"land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation']\nmake_cooccurrence_matrix(land_labels)"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"7d63fd76-1b6c-4ccb-ae9d-b6656768803a","collapsed":false,"_uuid":"43cc58527b5cb7e1015bc8a5ecb5c7e4ae4e4d6e"},"source":"There is little overlap in the rarer labels."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"dee5fedf-91d1-4ff5-bfa9-2ab6e38413a5","collapsed":false,"_uuid":"12ed8599c61ddd8c7e036050141aa6d61a9765b2"},"source":"rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\nmake_cooccurrence_matrix(rare_labels)"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"ab0982d5-a31d-4c0b-ad91-544f2075753f","collapsed":false,"_uuid":"ed741e11204dbbd9c85549edb0fd74f104625b46"},"source":"## Inspect images\nNow lets display and image and plot the pixel values."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"59d3477f-49b3-43fe-bc87-f5e348aef8b7","collapsed":false,"_uuid":"5c72cd0a727ed7719fb94e89052473988e40ac62"},"source":"def sample_images(tags, n=None):\n    ''' Randomly sample n images with the specified tags.'''\n    condition = True\n    if isinstance(tags, string_types):\n        raise ValueError('Pass a list of tags, not a single tag')\n    for tag in tags:\n        condition = condition & labels_df[tag] == 1\n    if n is not None:\n        return labels_df[condition].sample(n)\n    else:\n        return labels_df[condition]\n    "},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"f545fc4f-b12b-49c9-8a92-d4a52f640073","collapsed":false,"_uuid":"61adeea3cca69f64916fc7b19f130e53ea5d2b93"},"source":"def load_image(filename):\n    '''Look through directory tree to find the image specified'''\n    for dirname in os.listdir(PLANET_KAGGLE_ROOT):\n        path = os.path.abspath(os.path.join(PLANET_KAGGLE_ROOT, dirname, filename))\n        if os.path.exists(path):\n            print('Found image {}'.format(path))\n            return io.imread(path)\n        print('Load failed: could not find image {}'.format(path))\n        \ndef sample_to_fname(sample_df, row_idx, suffix='tif'):\n    '''Given a dataframe of sampled images, get the corresponding filename'''\n    fname = sample_df.get_value(sample_df.index[row_idx], 'image_name')\n    return '{}.{}'.format(fname, suffix)"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"8ce52731-2ba8-4213-8671-ecb6b3c13ae2","collapsed":false,"_uuid":"8c64b014c8e18a35ca81da5107a1b129fc6bd7a0"},"source":"def plot_rgbn_hist(r, g, b, n):\n    for slice_, name, color in ((r, 'r', 'red'), (g, 'g', 'green'), (b, 'b', 'blue'), (n, 'n', 'magenta')):\n        plt.hist(slice_.ravel(), bins=100,\n                range=[0,rgb_image.max()],\n                label=name, color=color,histtype='step')\n    plt.legend()    "},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"55bfec04-f4c2-4889-b927-23e3d702d71a","collapsed":false,"_uuid":"5e9f8503ba8e8462b95528fa0cd2adb8580b35e5"},"source":"s = sample_images(['primary', 'water', 'road'], n=1)\nfname = sample_to_fname(s, 0)\n\nbgrn_image = load_image(fname)\n\nbgr_image = bgrn_image[:,:,:3]\nrgb_image = bgr_image[:, :, [2,1,0]]\n\n# Extract each band\n# extract the different bands\nb, g, r, nir = bgrn_image[:, :, 0], bgrn_image[:, :, 1], bgrn_image[:, :, 2], bgrn_image[:, :, 3]\n\n# plot a histogram of rgbn values\nplot_rgbn_hist(r, g, b, nir)"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"9845aa5b-acae-4bff-b0e6-3c69a6528676","collapsed":false,"_uuid":"025f1ad757a79849b584eb08c5129d6d8556c19e"},"source":"# Plot the bands\nfig = plt.figure()\nfig.set_size_inches(12, 4)\nfor i, (x, c) in enumerate(((r, 'r'), (g, 'g'), (b, 'b'), (nir, 'near-ir'))):\n    a = fig.add_subplot(1, 4, i+1)\n    a.set_title(c)\n    plt.imshow(x)                       "},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"f389ba28-960e-4381-be4c-d9bf72d6ed48","collapsed":false,"_uuid":"e480e9b0468756bcd60a84cf93b8eb9b81f1c378"},"source":"# The combined RGB image doesn't look right however..."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"17ade47c-136e-4621-a252-dc4db345052e","collapsed":false,"_uuid":"7c3a929e4c99cf30bfcb38d00f6357bc1719ea9c"},"source":"plt.imshow(rgb_image)"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"dcbb3938-9e7b-4e71-b907-fd61923f4580","collapsed":false,"_uuid":"2755017824abbb6f6c9ed2574b084e3a7907c6e3"},"source":"The image has not been colour calibrated and needs to be normalized. We need to use a reference colour curve from a image that has been normalized. Sometimes one would use a third party aerial image of a canopy, but in this case we will use JPEG images in the data set that have already been colour corrected.\n\nThe goal is to transform the (test) image such that its mean and variance match the reference image data. "},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"10fe97cf-3ab7-4169-8080-154bff210913","collapsed":false,"_uuid":"ec8052e838480ff9c8c8efaf71a52351509da6ef"},"source":"# Collect a list of 20000 image names\njpg_list = os.listdir(PLANET_KAGGLE_JPEG_DIR)[:20000]\n\n# Pick 100 at random\nnp.random.shuffle(jpg_list)\njpg_list = jpg_list[:100]\n\nprint(jpg_list)"},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"bfce41d5-d89a-4bf4-a02b-3def23f125d3","collapsed":false,"_uuid":"0bb81e1fd9b27b68c8df002339b9bc9c49ebdb39"},"source":"Read each image (8 bit RGBA) and dump the pixels values to ref_colours, which has buckets for R, G, B"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"963c3f21-2947-496f-a851-f345e786a38a","collapsed":false,"_uuid":"f84d11297e11448f35687598531e9cbb0dc27bb7"},"source":"ref_colors = [[],[],[]]\nfor _file in jpg_list:\n    #keep only rgb\n    _img = mpimg.imread(os.path.join(PLANET_KAGGLE_JPEG_DIR, _file))[:,:,:3]\n    #flatten the 2 dimensions to one\n    _data = _img.reshape((-1,3))\n    # Dump pixel values into correct buckets\n    for i in range(3):\n        ref_colors[i] = ref_colors[i] + _data[:,i].tolist()\n    \nref_colors = np.array(ref_colors)    "},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","collapsed":false,"_cell_guid":"ac4393fc-ea9a-4371-9d9d-7d804413db7f","_uuid":"3b08fdbf7d291dd435bbbac31571966e862231b5"},"source":"for i, color in enumerate(['r','g','b']):\n    plt.hist(ref_colors[i], bins=30, range=[0,255], label=color, color=color, histtype='step')\nplt.legend()\nplt.title('Reference colour histogram')\n   "},{"execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"_execution_state":"idle","collapsed":false,"_cell_guid":"70f92e72-acb1-47c0-bd96-31e082a53ba1","_uuid":"134f7ab9e9fae006449aa53b078fc181a9e7410b"},"source":"The histogram above represents the response in RGB that we would like to use for our uncorrected image. Compare this histogram to the one plotted above using our function plot_r_g_b_n_hist. While the corrected image is 8 bit and the one above is 16 bit, you can see that the uncorrected image has a different response in each band, covering different pixel value domains. This explains why we see such extreme values in the RGB image above. The dynamic range is very large and does not allow us to view the subtleties in all 3 bands."},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","collapsed":false,"_cell_guid":"f69d1a16-bb38-48ef-8881-88d3d8449468","_uuid":"cf72cbf67533f987a067c58fe0d29c8dd9b03654"},"source":"ref_means = [np.mean(ref_colors[i]) for i in range(3)]\nref_stds = [np.std(ref_colors[i]) for i in range(3)]"},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","collapsed":false,"_cell_guid":"e488aeae-c9ea-4144-847f-4e812c003c3b","_uuid":"e027e9010bf62401e045410af1b0dcf6ad4c84b9"},"source":""}],"nbformat":4,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","name":"python","version":"3.6.1"}}}