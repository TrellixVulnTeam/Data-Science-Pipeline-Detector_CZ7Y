{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"91d72583-578a-92d6-0522-be53e6241e12"},"source":"**Python based Kernel for Amazon**\n\nWe see there are various labels associated with each image / chip showing the phenomenon occurring in Amazon rain forest \n\nThese 'Class Labels'have following parts:\n\n 1. 'Atmospheric Condition' and always exist\n    --> *'clear', 'partly_cloudy', 'cloudy', and 'haze'*     \n\n 2. 'More Common Labels' that may or may not exist\n   --> *'primary', 'water', 'habitation', 'agriculture', 'road', 'cultivation', 'bare_ground'*\n\n 3. 'Less Common Labels' that rarely exist\n    --> *slash_burn, selective_logging, 'blooming', 'conventional_mining', 'artisinal_mining', 'blow_down*\n\n**We treat 'labels' as a corpus of documents. Then we convert this corpus into a feature matrix using CountVectorizer() which is then converted to a pandas dataframe.** This should give a nice manageble set of data corresponding to the images which can be analysed."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d2af56f-c620-baa4-dea2-81fad30f57af"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport plotly.plotly as py\nimport plotly.tools as tls\nimport cv2\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom operator import itemgetter\nfrom sklearn import preprocessing\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"259226a9-d734-3219-dbd8-d1f4d7011531"},"outputs":[],"source":"df = pd.read_csv('../input/train.csv')\nprint(df.head())"},{"cell_type":"markdown","metadata":{"_cell_guid":"05925de5-dfb2-6187-da9b-3ae2f97e8492"},"source":"Use CountVectorizer to transform the corpus of documents (i.e. the labels associated with the images) into matrix form. Then create bar graph of the labels vs their count."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79a3af77-e747-8e06-2c93-a3bea8997470"},"outputs":[],"source":"labels = np.array(df['tags'])\n\nvect = CountVectorizer()\nvect.fit(labels)\nvect.get_feature_names()\n\nlabels_dtm = vect.transform(labels)\ndf_labels = pd.DataFrame(labels_dtm.toarray(), columns = vect.get_feature_names())\n\n# create a dict to collect total values of each class of label\namazon_condition = {}\nfor col in df_labels.columns.values:\n    z = df_labels.groupby([col])[col].count().astype(int)\n    amazon_condition[col] = 0\n    for i, j in enumerate(z):\n        if i != 0:\n            amazon_condition[col] += j\namazon_condition_labels = [x for x in amazon_condition.keys()]\namazon_condition_values = [x for x in amazon_condition.values()]\n\nprint(amazon_condition_labels)\nprint(amazon_condition_values)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb2a02b8-242c-0f94-1ae8-fed23e7acdb9"},"outputs":[],"source":"#from sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import fbeta_score\nfrom PIL import Image\nfrom PIL import ImageStat\nimport glob\n\ndef extract_features(path):\n    features = []\n    image_stat = ImageStat.Stat(Image.open(path))\n    features += image_stat.sum\n    features += image_stat.mean\n    features += image_stat.rms\n    features += image_stat.var\n    features += image_stat.stddev\n    img = cv2.imread(path)\n    cv2img = cv2.imread(path,0)\n    features += list(cv2.calcHist([cv2img],[0],None,[256],[0,256]).flatten())\n    mean, std = cv2.meanStdDev(img)\n    features += list(mean)\n    features += list(std)\n    return features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1be1977-f191-b063-7901-5040400be6e3"},"outputs":[],"source":"from tqdm import tqdm\nfrom time import time\n\nX_train = pd.DataFrame()\ninput_path = '../input/'\ndf['path'] = df['image_name'].map(lambda x: input_path + 'train-jpg/' + x + '.jpg')\n\nf_list = []\n\nt0 = time()\nfor i in df['path']:\n    f = np.array(extract_features(i)).astype(int)\n    f_list.append(f)\n\nprint(\"done in %0.3fs\" % (time() - t0))    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ddb8a307-2abe-a4e6-2505-ee1d0738a072"},"outputs":[],"source":"f_list_arr = np.array(f_list)\nX_train = pd.DataFrame(f_list_arr)\n#normalize the X_train scale\n#X_train = preprocessing.scale(X_train)\nfor i in X_train.columns.values:\n    X_train[i] = X_train[i]/max(X_train[i])\n    \nprint(type(X_train))\nprint(X_train.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98cf9ff9-fac7-8b76-1f62-4b5a56385928"},"outputs":[],"source":"print(type(X_train))\nprint(type(df_labels))\nY_train = np.array(df_labels)\nprint(Y_train[:5])\nprint(len(X_train[0]))\npad = np.zeros((len(X_train[0]),42))\nprint(pad.shape)\nX_train = np.hstack((X_train,pad))\nprint(X_train.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da22a311-ec3d-0f57-111f-a87fd1f8e11f"},"outputs":[],"source":"print(df_labels.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"752b49c1-ecd6-94f2-6155-456bc7445bd3"},"outputs":[],"source":"#print(test_images)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9cd3082f-2b2e-ea3b-81fa-1bdf76712815"},"outputs":[],"source":"test_images = []\nX_test = []\ntest_images = glob.glob(input_path + 'test-jpg-v2/*')\nX_test = pd.DataFrame([[x.split('/')[3].replace('.jpg',''),x] for x in test_images])\nprint(X_test[:5])\n\nX_test.columns = ['image_name','path']\nprint(X_test[:5])\nprint(X_test.shape, type(X_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44c129cd-85c2-57c7-ee84-4a906c6d5381"},"outputs":[],"source":"ftr_list_arr=[]\nftr_list = []\npad=[]\n\nt0 = time()\nfor i in X_test['path']:\n    ftr = np.array(extract_features(i)).astype(int)\n    ftr_list.append(ftr)\nprint(\"done in %0.3fs\" % (time() - t0))    \n\nftr_list_arr = np.array(ftr_list)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e084c9d-6416-a169-0718-9cf8c4a2ea34"},"outputs":[],"source":"print(ftr_list_arr.shape)\nprint(len(ftr_list_arr))\nprint(type(ftr_list_arr))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0353c8b7-31af-44ce-c2c2-3694fcefd6e6"},"outputs":[],"source":"pad = np.zeros((len(ftr_list_arr),42))\nprint(pad.shape)\nftr_list_arr = np.hstack((ftr_list_arr,pad))\ntest_pred = pd.DataFrame(ftr_list_arr)\n\nprint(test_pred.shape)\n#print(test_pred.head())\n\n#normalize the test_pred scale\n#test_pred = preprocessing.scale(test_pred)\n\nfor i in test_pred.columns.values:\n    test_pred[i] = test_pred[i]/max(X_train[i])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"add25c20-98d2-02df-2f6a-dc6e04eda130"},"outputs":[],"source":"X_train_to_csv = pd.DataFrame(X_train)\nY_train_to_csv = pd.DataFrame(Y_train)\n\nX_train_to_csv.to_csv('X_train.csv')\nY_train_to_csv.to_csv('Y_train.csv')\ntest_pred.to_csv('pred.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f3a8ade-e12f-fc89-aff1-1cfa1f9370e2"},"outputs":[],"source":"print(check_output([\"ls\"]).decode(\"utf8\"))\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4d96240-cd91-b3b3-edce-684ac2cd5fbd"},"outputs":[],"source":"print(X_train.shape)\nprint(Y_train.shape)\nprint(test_pred.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"593cea49-c24a-ec26-914a-71e58815c974"},"outputs":[],"source":"X_val = X_train[32000:]\nX_train = X_train[:32000]\nY_val = Y_train[32000:]\nY_train = Y_train[:32000]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6653ad7-8af4-1363-de01-b14a1953417d"},"outputs":[],"source":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)\n\nprint(test_pred.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30ca2e06-ff2d-11ad-596d-fdde9ef9c7a3"},"outputs":[],"source":"from keras import backend as K\nimg_rows = 18 \nimg_cols = 18\n\nif K.image_dim_ordering() == 'th':\n    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n    #X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n    #X_test_k = X_test_k.reshape(X_test_k.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n    #X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n    #X_test_k = X_test_k.reshape(X_test_k.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"638d34c0-85f7-54ba-3099-28ab394cba92"},"outputs":[],"source":"print(Y_train.shape)\nprint(Y_val.shape)\nX_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\nprint(X_train.shape)\nprint(X_val.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"241e6c7b-e10b-081e-d0fe-20b009c617dc"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\n\nbatch_size = 128\nnb_classes = 17\n#nb_epoch = 5\nnb_epoch = 1\n\n# input image dimensions\nimg_rows, img_cols = 18, 18\n# number of convolutional filters to use\nnb_filters = 32\n# size of pooling area for max pooling\npool_size = (2, 2)\n# convolution kernel size\nkernel_size = (3, 3)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='valid', input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes))\n#model.add(Activation('softmax'))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',  optimizer='adam', metrics=['accuracy'])\n#model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n\n#callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n    \nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, \n          validation_data=(X_val, Y_val), shuffle=True)\n\nscore = model.evaluate(X_val, Y_val, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c6f90df-853c-bd5d-74c4-82debb8869ed"},"outputs":[],"source":"#print(score)\n#model.predict_proba(X_val[:100])\nprint(X_val[:2])\nclass_predictions = []\nclass_predictions = model.predict_classes(X_val[:2], batch_size=32, verbose=1)\nprint(class_predictions.astype(float))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35c36222-9c67-c282-a0c0-883f4c9e32e3"},"outputs":[],"source":"p_test = model.predict(X_val, verbose=1)\n#p_test [p_test >0.24] = 1\n#p_test [p_test < 1] = 0\nprint(p_test.shape)\nprint(p_test[:10])\nprint(Y_val[:10])\n\nprint"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"121e1845-857d-be5c-1e66-28460f90645d"},"outputs":[],"source":"from sklearn.metrics import fbeta_score\n\n#p_valid = model.predict(X_val, batch_size=128)\np_proba = model.predict_proba(X_val, batch_size=128)\n#print(y_valid)\n#print(p_valid)\n#print(fbeta_score(Y_val, np.array(p_valid) > 0.2, beta=2, average='samples'))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adb5ed9e-3e6f-4727-4faf-f986b855a0b1"},"outputs":[],"source":"print(X_val[:2])\nprint(p_proba[:10])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa7c94ab-4fd5-89fa-c57b-3e76e34cca8e"},"outputs":[],"source":"print(type(test_pred))\npredset = np.array(test_pred)\npredset = predset.reshape(predset.shape[0],18,18,1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a869ec50-68e7-3751-2d13-b9e44642fb93"},"outputs":[],"source":"print(predset.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25b39964-82e5-4a43-1287-4a2bd9efe30f"},"outputs":[],"source":"p_test = model.predict(predset, batch_size = 128, verbose=2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ddbcae17-172b-c139-7eb2-1b967eb9c8ec"},"outputs":[],"source":"print(p_proba[:1])\nprint(Y_val[:1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"227989c5-72d1-9c09-022a-cf0d2a81dadd"},"outputs":[],"source":"#result [result >0.24] = 1\n#result [result < 1] = 0\n#print(result[:5])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"106f0560-024b-2141-05d6-17d0d3074e7d"},"outputs":[],"source":"#print(type(result))\n#result_df = pd.DataFrame(result)\n#result_df.columns = df_labels.columns.values\n#print(result_df.head())\n#tags = []\n\n#for i,j in enumerate(np.array(result_df)):\n#    temp_tags = []\n    #print(temp_tags)\n#    for c, col in enumerate(result_df.columns.values):\n#        if j[c] == 1:\n#            temp_tags.append(col)\n#    tags.append(temp_tags)\n\n#tags1 = []    \n\n#for x in tags:\n#    st = ''    \n#    for y in x:\n#        st += y + ' '\n#    tags1.append(st[:(len(st)-1)])         "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0523a675-ee80-a3d6-a6bc-d36d46c0a00a"},"outputs":[],"source":"#print(len(tags), type(tags))\n#print(tags[:10])\n#print(len(tags1), type(tags1))\n#print(tags1[:10])\n#X_test['tags'] = tags1\n\n#X_test[:10]\n#print(X_test.columns.values)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d793561-30ba-f42f-b8dc-cd115fff03e0"},"outputs":[],"source":"#X_test[['image_name','tags']].to_csv('submission_amazon_02.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2fc57e63-dab7-aa5c-d5e4-d29159f0cf6a"},"outputs":[],"source":"#pdForCSV = pd.DataFrame()\n#pdForCSV['image_name'] = X_test.image_name.values\n#pdForCSV['tags'] = preds\n#pdForCSV.to_csv('2017_05_01_XGB_submission.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}