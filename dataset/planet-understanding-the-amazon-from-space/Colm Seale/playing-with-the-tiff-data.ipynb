{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74774026-9dfc-5ada-d204-c9650d28a113"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f471e682-222c-522d-76ea-4a6bb65d760d"},"outputs":[],"source":"# coding: utf-8\n# import data\nimport os\nimport matplotlib.image as image\nimport matplotlib.pyplot as plt\n\nPLANET_KAGGLE_ROOT = \"../input\"\nPLANET_KAGGLE_TIFF_DIR = PLANET_KAGGLE_ROOT + \"/train-tif/\"\nPLANET_KAGGLE_LABEL_CSV = PLANET_KAGGLE_ROOT + \"/train.csv\"\n\n# load label data\n# read our data and take a look at what we are dealing with\ntrain_csv = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\nprint(train_csv.head())\n\n# load tiff data\n# load files\ntrain_tiff_sample = os.listdir(PLANET_KAGGLE_TIFF_DIR)\n\n# pick just cloudy images for now\n\nAVAILABLE_LABELS = [\n    'agriculture', \n    'artisinal_mine', \n    'bare_ground', \n    'blooming', \n    'blow_down', \n    'clear', \n    'cloudy', \n    'conventional_mine', \n    'cultivation', \n    'habitation', \n    'haze', \n    'partly_cloudy', \n    'primary', \n    'road', \n    'selective_logging', \n    'slash_burn', \n    'water']\n\ntags = pd.DataFrame()\n\nfor label in AVAILABLE_LABELS:\n    tags[label] = train_csv.tags.apply(lambda x: np.where(label in x, 1, 0))\n\ntrain = pd.concat([train_csv, tags], axis=1)\nfiltered_samples = [sample[0:-4] for sample in train_tiff_sample]\n\n# get labels for these files\nsample_labels = train[train['image_name'].isin(filtered_samples)]\nsample_labels.reset_index(inplace=True)\n\nfrom glob import glob\nfrom skimage import io\nimage_paths = sorted(glob('../input/train-tif/*.tif'))[0:1000]\nimgs = [io.imread(path) for path in image_paths]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38c823a1-e9d7-44ac-15c0-15fdabc0a653"},"outputs":[],"source":"flattened_imgs = [img.flatten() for img in imgs[0:5]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaf39191-7b5f-4e31-a06d-8e5c081824a6"},"outputs":[],"source":"df = pd.DataFrame.from_records(flattened_imgs)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"39c98298-ab04-7e81-3cc5-b03b6aa29677"},"outputs":[],"source":"sample_labels = sample_labels[['cloudy']][0:5]\nsample_labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"659d3490-8418-e6b7-c8c4-0b4f0f1f3991"},"outputs":[],"source":"df = pd.concat([sample_labels[['cloudy']][0:5], df], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f2f9c7a-63fc-25db-054f-8ec538c80b85"},"outputs":[],"source":"# running out of memory, need to spin up a server for development"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"718b5cd5-2f42-9ad5-e941-0a3cb7a958c1"},"outputs":[],"source":"df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7ee2115-44f1-b0eb-df3e-8551bdb723b3"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}