{"cells":[{"outputs":[],"cell_type":"markdown","source":"**Model**: Inception_v3 pre-trained\n\n**Function**: Find Best Threshold\n\n**Output**:\n\n 1. A sample submission using simple Keras CNN 2) \n 2. Predicted probability and truth labels for use in Best Threshold finding","metadata":{"_cell_guid":"081f9e1f-3b99-29c6-917a-f8b1c902a7a3","_uuid":"c6cb8deb751313ecb0fbcfe7001df016fa2357f2"},"execution_count":null},{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pickle as pickle\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport random\n\nimport keras as k\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nimport cv2\nimport datetime as dt\nfrom tqdm import tqdm\n\nfrom multiprocessing import Pool, cpu_count\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"38875a27-ad3d-ac67-5ba8-10adc2ece94d","_uuid":"18d2f081976c80be58e669e6bcc5cbcf130bc158"}},{"source":"# Import Model Specific packages\nfrom keras.preprocessing.image import img_to_array, load_img\n\nimport keras as k\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\n# import packages for InceptionV3\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.models import Model\n\nfrom multiprocessing import Pool, cpu_count\n\n# callback for saving models, early stopping\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\n# for plotting model training history\nimport matplotlib.pyplot as plt\n\n# os.chdir('C:/deep_learning') # This is where the input dataset is stored\n# os.getcwd()\nprint(\"------Fan Fei's Imports Complete-----\")","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"c5c61fab-755f-70ed-db43-e62b3e4a819c","_uuid":"159891f5e24b5ea3513a0594ec6c14766ba8573f"}},{"source":"random_seed = 987654321\nrandom.seed(random_seed)\nnp.random.seed(random_seed)\ninput_dim = 299\n\nx_train0 = []\nx_test0 = []\ny_train0 = []\n\ndf_train = pd.read_csv('../input/train_v2.csv')[:256]        # just get the first 256 images\n\nlabels = df_train['tags'].str.get_dummies(sep=' ').columns\n\nlabel_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\n\nfor f, tags in tqdm(df_train.values, miniters=1000):\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1 \n    x_train0.append(cv2.resize(img, (input_dim, input_dim)))\n    y_train0.append(targets)\n    \ny_train0 = np.array(y_train0, np.uint8)\nx_train0 = np.array(x_train0, np.float16) / 255.\n\nprint(x_train0.shape)\nprint(y_train0.shape)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"81313a87-02c0-f95d-b430-28acd843335a","_uuid":"0cd75cb9303f6cdd4ee22d363609c45584f67555"}},{"source":"df_test = pd.read_csv('../input/sample_submission_v2.csv')[:256]        # just get the first 256 images\n\nfor f, tags in tqdm(df_test.values, miniters=1000):\n    img = cv2.imread('../input/test-jpg-v2/{}.jpg'.format(f))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1 \n    x_test0.append(cv2.resize(img, (input_dim, input_dim)))\n    \nx_test0 = np.array(x_test0, np.float16) / 255.","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"184522a5-9713-33a9-84e6-4b60d1dc4e65","_uuid":"33cc0e83bee1c982e2f59b63afe5d772ecd011ef"}},{"source":"split = 192\n# split = 35000\nx_train, x_valid, y_train, y_valid = x_train0[:split], x_train0[split:], y_train0[:split], y_train0[split:]\n\n# create the base pre-trained model\nbase_model = InceptionV3(weights=None, include_top=False, input_shape=(input_dim,input_dim,3))\n# no weight initialization because Kaggle kernel is isolated from the internet, cannot download\n# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(input_dim,input_dim))\n\n# add a new top layer\nx = base_model.output\nx = Flatten()(x)\npredictions = Dense(17, activation='sigmoid')(x)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"c04ef59b-f97d-8f87-6252-d98c493f90e6","_uuid":"ca94d8acfbc3af2d9d05d3ad85c9fecdc215b71a"}},{"source":"# let's visualize layer names and layer indices to see how many layers \n# we should freeze\nfor i, layer in enumerate(base_model.layers):\n    print(i, layer.name)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"8e669de3-3a8a-d458-9268-5bff260d8408","_uuid":"be60cb37bc2e935c4b96a2948145afdce6670e00"}},{"source":"# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 172 layers and unfreeze the rest:\nfor layer in model.layers[:172]:\n    layer.trainable = False\nfor layer in model.layers[172:]:\n    layer.trainable = True","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"9970bd26-efad-3e3f-c62f-b3e5bb853d0c","_uuid":"1bc5a22fbb8bb07fea22b5f26271d5cbf53578ae"}},{"source":"# Read in pre-trained weights - fast\n# model.load_weights(obj_save_path + \"weights_incv3.best.hdf5\")","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"edf26945-4ad6-a430-a76b-8e89d4b34233","_uuid":"4450ad269cb79ebd6d4926f9a21d9a3ed342a7d1"}},{"source":"# we need to recompile the model for these modifications to take effect\n# we use SGD with a low learning rate\nfrom keras.optimizers import SGD\nmodel.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n              optimizer=SGD(lr=0.01, momentum=0.9))","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"e52fa06a-85c1-20fa-41ec-13ce89e47524","_uuid":"3b1cb623c9dd4667f8bec4fad98c20ce500942ed"}},{"source":"# Incorporate Callback features\n# Checkpointing \nfilepath= \"weights_incv3.best.hdf5\"\n# filepath= obj_save_path + \"weights_incv3.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n\n# Early Stopping\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0.0002, patience=5, verbose=0, mode='auto') \n\ncallbacks_list = [checkpoint, earlystop]","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"f78726a9-b899-bd20-1fbb-ef184180d9f2","_uuid":"8d429e0e762edf38da8480fa105164151117e643"}},{"source":"# the explicit split approach was taken so as to allow for a local validation\n# model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, callbacks=callbacks_list, verbose=0)\n\n# Fit the model (Add history so that the history may be saved)\nhistory = model.fit(x_train, y_train,\n          batch_size=32,\n          epochs=1,\n          verbose=1,\n          callbacks=callbacks_list,\n          validation_data=(x_valid, y_valid))\n\nfrom sklearn.metrics import fbeta_score\n\np_train = model.predict(x_train0, batch_size=32,verbose=2)\np_test = model.predict(x_test0, batch_size=32,verbose=2)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"ae9174aa-11e7-c0c2-a912-2ae8d36e3f91","_uuid":"c49ad6f6158b76f91a9817ebc08857769faf9a62"}},{"source":"def f2_score(y_true, y_pred):\n    y_true, y_pred, = np.array(y_true), np.array(y_pred)\n    return fbeta_score(y_true, y_pred, beta=2, average='samples')\n\ndef find_f2score_threshold(p_valid, y_valid, try_all=False, verbose=False):\n    best = 0\n    best_score = -1\n    totry = np.arange(0.1,0.4,0.025) if try_all is False else np.unique(p_valid)\n    for t in totry:\n        score = f2_score(y_valid, p_valid > t)\n        if score > best_score:\n            best_score = score\n            best = t\n    if verbose is True: \n        print('Best score: ', round(best_score, 5), ' @ threshold =', best)\n    return best\n\nprint(fbeta_score(y_train0, np.array(p_train) > 0.2, beta=2, average='samples'))\nbest_threshold = find_f2score_threshold(p_train, y_train0, try_all=True, verbose=True)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"d081994c-2190-2b91-15d6-6bd002571584","_uuid":"be676eab3bafed1f9576a33a498659b6f7e472fd"}},{"source":"# Saving predicted probability and ground truth for Train Dataset\n# Compute the best threshold externally\nprint(labels)\nchk_output = pd.DataFrame()\nfor index in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]:\n    chk_output['class %d' % index] = p_train[:,index-1]\nchk_output.to_csv('predicted_probability.csv', index=False)\nfor index in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]:\n    chk_output['class %d' % index] = y_train0[:,index-1]\nchk_output.to_csv('true_label.csv', index=False)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"f27120c4-b6fd-0bf9-f172-264f8310aadc","_uuid":"970946764fea76af27cb839b5ef4db3b91da1d32"}},{"source":"values_test = (p_test > .222222)*1.0        # before multiplying by 1.0, this appears as an array of True and False\nvalues_test = np.array(values_test, np.uint8)\n\nprint(values_test)\n# Build Submission, using label outputted from long time ago\ntest_labels = []\nfor row in range(values_test.shape[0]):\n    test_labels.append(' '.join(labels[values_test[row,:]==1]))\nSubmission_PDFModel = df_test.copy()\nSubmission_PDFModel.drop('tags', axis = 1)\nSubmission_PDFModel['tags'] = test_labels\nSubmission_PDFModel.to_csv('sub_pretrained_inception_v3_online.csv', index = False)","execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"2c663701-cc97-9d34-b6e9-6a846ddd6ff3","_uuid":"61356a092bd9e39607586219ffab340e121aa049"}}],"nbformat_minor":0,"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"_change_revision":0,"language_info":{"file_extension":".py","name":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","version":"3.6.1","nbconvert_exporter":"python","mimetype":"text/x-python"},"_is_fork":false}}