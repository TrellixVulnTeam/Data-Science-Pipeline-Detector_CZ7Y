{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"906e02e8-7be8-fca6-ac3a-2548dfff6dd8"},"source":"# How much information can be extracted from the IR channel alone? \n\nIs this notebook we try to rebuild the RGB image purely from its IR channel with a U-convolutional architecture, and shortcut connections."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85ac474c-9589-b030-d749-2573b48fc251"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom skimage import io, transform\nfrom keras.preprocessing import image as kimage\nfrom keras.applications.imagenet_utils import preprocess_input\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd8c3815-ce4a-5c94-6ef1-c3f4a37eba27"},"outputs":[],"source":"TDATA_PATH = \"../input/train-tif/\"\nJDATA_PATH = \"../input/train-jpg/\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1350095e-dd6d-6244-17c2-c33432c08a4d"},"outputs":[],"source":"files = os.listdir(JDATA_PATH) + os.listdir(TDATA_PATH)\nfiles = sorted(set([f.split(\".\")[0] for f in files]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ede4c3f-bf65-6b07-3554-e1682f7e11c0"},"outputs":[],"source":"def open_tif_file(path, size=32):\n    path = path + \".tif\"\n    img = io.imread(path)\n    img = transform.resize(img, (32, 32))\n    img = np.expand_dims(img, 0)\n    img = img.astype(np.float16)\n    return img[:, :, :, [3]] # Only IR channel\n\n\ndef open_jpg_file(path, size=32):\n    path = path + \".jpg\"\n    img = kimage.load_img(path, target_size=(size, size))\n    img = kimage.img_to_array(img, data_format=\"channels_last\")\n    img = np.expand_dims(img, 0)\n    img = img / 255.\n    img = img.astype(np.float16)\n    return img\n\n\ndef load_data(TDATA_PATH, JDATA_PATH, files, img_size,\n              validation_size=2000, max_size=None):\n    validation_indices = np.arange(len(files))\n\n    np.random.seed(0)\n    np.random.shuffle(validation_indices)\n    validation_indices = validation_indices[:validation_size]\n\n    xtr = []\n    xva = []\n    ytr = []\n    yva = []\n\n    for ith, file in enumerate(files):\n        if (ith + 1) % 2500 == 0:\n            print(\"Files loaded:\", ith + 1)\n            \n        if max_size is not None and ith >= max_size:\n            break\n\n        try:\n            x = open_tif_file(TDATA_PATH + file, img_size)\n            y = open_jpg_file(JDATA_PATH + file, img_size)\n        except Exception as e:\n            print(e, ith)\n        else:\n            if ith in validation_indices:\n                xva.append(x)\n                yva.append(y)\n            else:\n                xtr.append(x)\n                ytr.append(y)\n\n    xtr = np.vstack(xtr)\n    xva = np.vstack(xva)\n    ytr = np.vstack(ytr)\n    yva = np.vstack(yva)\n    \n    return xtr, ytr, xva, yva"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec49455a-6320-b6aa-7903-f8ed3968d038"},"outputs":[],"source":"IMG_SIZE = 32\nVALIDATION_SIZE = 4000\nMAX_SIZE = 2500"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d0e05c8-bb45-a824-1638-62598e56be28"},"outputs":[],"source":"xtr, ytr, xva, yva = load_data(\n    TDATA_PATH, JDATA_PATH, files, img_size=IMG_SIZE,\n    validation_size=VALIDATION_SIZE, max_size=MAX_SIZE)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93a2061e-4c4b-087a-e5d6-d509142b5c0f"},"outputs":[],"source":"print(xtr.shape, ytr.shape)\nprint(xva.shape, yva.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b212efd7-39cb-2e26-98c7-250202af09f5"},"outputs":[],"source":"import tensorflow as tf\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Input, Flatten, AveragePooling2D\nfrom keras.layers import Conv2D, Activation, BatchNormalization, MaxPooling2D\nfrom keras.layers import Conv2DTranspose, ZeroPadding2D, UpSampling2D\nfrom keras.layers.merge import add, concatenate\nfrom keras.optimizers import Adam"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46cab60d-cf09-8dc5-b1f8-dca57968da8f"},"outputs":[],"source":"img_input = Input(shape=(IMG_SIZE, IMG_SIZE, 1), name=\"image\")\n\nd1 = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='dconv1')(img_input)\nx = MaxPooling2D(2)(d1)\n\nd2 = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='dconv2')(x)\nx = MaxPooling2D(2)(d2)\n\nd3 = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='dconv3')(x)\nx = MaxPooling2D(2)(d3)\n\nx = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='conv')(x)\n\nx = UpSampling2D(2)(x)\nx = add([x, d3])\nu3 = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='uconv3')(x)\n\nx = UpSampling2D(2)(u3)\nx = add([x, d2])\nu2 = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='uconv2')(x)\n\nx = UpSampling2D(2)(u2)\nx = add([x, d1])\nx = Conv2D(50, (3, 3), padding=\"same\", activation=\"relu\", name='uconv11')(x)\n\nx = add([x, img_input])\nx = Conv2D(50, (2, 2), padding=\"same\", activation=\"relu\", name='uconv12')(x)\nout = Conv2D(3, (1, 1), padding=\"same\", activation=\"sigmoid\", name=\"img_output\")(x)\n\nmodel = Model(inputs=img_input, outputs=out, name=\"u-conv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fb39fe0-8329-5f65-4bf6-3b0ac8df40a9"},"outputs":[],"source":"model.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af6841b7-55dc-c4bf-9844-cd8a78ef4979"},"outputs":[],"source":"model.compile(loss=\"mse\", optimizer=Adam(lr=5e-4))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7e17228-6865-7b90-2eff-c150184d02e9"},"outputs":[],"source":"# Loop over this cell multiple times to avoid time-out\nh = model.fit(xtr, ytr, validation_data=[xva, yva], verbose=2, epochs=10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc679fae-dfce-231d-9462-376fd7bc6990"},"outputs":[],"source":"def ir_channel(x):\n    irx = np.tile(x, 3).astype(float)\n    irx = irx - irx.min()\n    irx = irx / irx.max()\n    return irx"},{"cell_type":"markdown","metadata":{"_cell_guid":"95e240db-c959-e915-9f24-94a8f4036cc8"},"source":"Below we inspect if the model has converged yet by analyzing what sort of image it generates from training data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f57ee3da-f1e3-c279-1f9f-af69fd8f0c10"},"outputs":[],"source":"gentr = model.predict(xtr)\nfig, axis = plt.subplots(4, 3 * 2, figsize=(15, 10))\n\nfor i in range(4):\n    for j in range(0, 6, 3):\n        axis[i][j + 0].imshow(ir_channel(xtr[i*2 + j//3]) )\n        axis[i][j + 1].imshow(gentr[i*2 + j//3])\n        axis[i][j + 2].imshow(ytr[i*2 + j//3].astype(float))\n        \n        axis[i][j].axis(\"off\")\n        axis[i][j + 1].axis(\"off\")\n        axis[i][j + 2].axis(\"off\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"439378f5-352c-7143-6df9-1224c6aa9f5a"},"source":"Here we inspect what sort of RGB image is generated for validation samples."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f75c814-e77e-5c41-1c92-075ddc420fc7"},"outputs":[],"source":"gen = model.predict(xva)\nfig, axis = plt.subplots(4, 3 * 2, figsize=(15, 10))\n\nfor i in range(4):\n    for j in range(0, 6, 3):\n        axis[i][j + 0].imshow( ir_channel(xva[i*2 + j//3]) )\n        axis[i][j + 1].imshow(gen[i*2 + j//3])\n        axis[i][j + 2].imshow(yva[i*2 + j//3].astype(float))\n        \n        axis[i][j].axis(\"off\")\n        axis[i][j + 1].axis(\"off\")\n        axis[i][j + 2].axis(\"off\")\n        "},{"cell_type":"markdown","metadata":{"_cell_guid":"6efe17fd-be2f-ab46-b69e-a4460542296a"},"source":"Looks promising, however it needs to run longer and with more data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0acb2bf-fe11-5723-e1e3-080978c66f97"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}