{"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"081f9e1f-3b99-29c6-917a-f8b1c902a7a3","_uuid":"129da4ffe1e6a251ccbc3c75ec3042a5c83f4e19"},"execution_count":null,"source":"To-do: Improve efficiency with multiprocessing from Blending Code","outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"38875a27-ad3d-ac67-5ba8-10adc2ece94d","_execution_state":"idle","trusted":false,"_uuid":"6ae2c993391fb2eba78ca7caef28ce4296bdf5fa"},"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\n\nimport keras as k\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nimport cv2\nfrom tqdm import tqdm\n\nfrom multiprocessing import Pool, cpu_count\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom sklearn.metrics import fbeta_score\n\ndef f2_score(y_true, y_pred):\n    y_true, y_pred, = np.array(y_true), np.array(y_pred)\n    return fbeta_score(y_true, y_pred, beta=2)\n\ndef find_f2score_threshold(p_valid, y_valid, try_all=False, verbose=False):\n    best = 0\n    best_score = -1\n    totry = np.arange(0.1,0.4,0.005)\n    for t in totry:\n        score = f2_score(y_valid, p_valid > t)\n        if score > best_score:\n            best_score = score\n            best = t\n    if verbose is True: \n        print('Best score: ', round(best_score, 5), ' @ threshold =', best)\n    return best\n\nx_train0 = []\nx_test0 = []\ny_train0 = []\n\ndf_train = pd.read_csv('../input/train_v2.csv')\n\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n\nlabel_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\n\nfor f, tags in tqdm(df_train.values, miniters=1000):\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1 \n    x_train0.append(cv2.resize(img, (32, 32)))\n    y_train0.append(targets)\n    \ny_train0 = np.array(y_train0, np.uint8)\nx_train0 = np.array(x_train0, np.float16) / 255.\n\nprint(x_train0.shape)\nprint(y_train0.shape)\n\nsplit = 35000\nx_train, x_valid, y_train, y_valid = x_train0[:split], x_train0[split:], y_train0[:split], y_train0[split:]\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(32, 32, 3)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(17, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n              optimizer='adam',\n              metrics=['accuracy'])\n              \nmodel.fit(x_train, y_train,\n          batch_size=128,\n          epochs=1,\n          verbose=2,\n          validation_data=(x_valid, y_valid))\n\np_train = model.predict(x_train0, batch_size=128,verbose=2)\nprint(p_train.shape)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"c5ca3ac9726b29c2059c32c2f7ee408f44cf4a46","_execution_state":"idle","collapsed":false},"execution_count":null,"source":"# best_threshold = pd.Series(np.zeros(17), index=y_train0)\n\nbest_threshold = np.zeros(17)\n\nfor i in range(17):\n    best_threshold[i] = find_f2score_threshold(p_train[:,i], y_train0[:,i], verbose=False)\n\nprint(best_threshold)","outputs":[]}],"metadata":{"_is_fork":false,"language_info":{"codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python","name":"python","mimetype":"text/x-python","version":"3.6.0"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"_change_revision":0},"nbformat_minor":0}