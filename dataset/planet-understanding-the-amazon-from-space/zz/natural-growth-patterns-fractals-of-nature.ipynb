{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c7c2dbfd-f48c-38f5-56a8-c580833d4141"},"source":"Bag of Colors\n================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15d23828-4891-e24e-d267-da73195d6ecf"},"outputs":[],"source":"from multiprocessing import Pool, cpu_count\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import fbeta_score\nimport pandas as pd\nimport numpy as np\nimport glob, cv2\n\ndef get_features(path):\n    img = cv2.imread(path)\n    hist = cv2.calcHist([cv2.imread(path,0)],[0],None,[256],[0,256])\n    m, s = cv2.meanStdDev(img)\n    img = cv2.resize(img, (20, 20), cv2.INTER_LINEAR)\n    img = np.append(img.flatten(), m.flatten())\n    img = np.append(img, s.flatten())\n    img = np.append(img, hist.flatten())\n    return [path, img]\n\ndef normalize_img(paths):\n    imf_d = {}\n    p = Pool(cpu_count())\n    ret = p.map(get_features, paths)\n    for i in range(len(ret)):\n        imf_d[ret[i][0]] = ret[i][1]\n    ret = []\n    fdata = [imf_d[f] for f in paths]\n    fdata = np.array(fdata, dtype=np.uint8)\n    return fdata\n\nin_path = '../input/'\ntrain = pd.read_csv(in_path + 'train.csv')\ntrain['path'] = train['image_name'].map(lambda x: in_path + 'train-jpg/' + x + '.jpg')\ny = train['tags'].str.get_dummies(sep=' ')\nxtrain = normalize_img(train['path']); print('train...')\n\ntest_jpg = glob.glob(in_path + 'test-jpg/*')\ntest = pd.DataFrame([[p.split('/')[3].replace('.jpg',''),p] for p in test_jpg])\ntest.columns = ['image_name','path']\nxtest = normalize_img(test['path']); print('test...')\n\netr = ExtraTreesRegressor(n_estimators=18, max_depth=12, n_jobs=-1, random_state=1)\netr.fit(xtrain, y); print('fit...')\n\ntrain_pred = etr.predict(xtrain)\ntrain_pred[train_pred >0.24] = 1\ntrain_pred[train_pred < 1] = 0\nprint(fbeta_score(y,train_pred,beta=2, average='samples'))\n\npred = etr.predict(xtest); print('predict...')\n\ntags = []\nfor r in pred:\n    r = list(r)\n    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.24], reverse=True)]))\n\ntest['tags'] = tags\ntest[['image_name','tags']].to_csv('submission_boc_01.csv', index=False)\ntest.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f55cb370-966a-9acc-1458-e35e2f97c8b9"},"outputs":[],"source":"#mutualy exclusive tags from cooccurence_matrix in following script\n#https://github.com/planetlabs/planet-amazon-deforestation/blob/master/planet_chip_examples.ipynb\n\ndef me_clean(row): #\n    row = row.split(' ')\n    d = {k: i for i, k in enumerate(row)}\n    me_list = [['artisinal_mine','conventional_mine','blow_down'],['clear','partly_cloudy','cloudy','haze']]\n    for l in me_list:\n        l2 = [j for j in l if j in row]\n        if len(l2)>1:\n            l2 = [c[0] for c in sorted([[c, d[c]] for c in l2], reverse=True)] #give priority to lower bound pred\n            row = [j for j in row if j not in l2[1:]]\n    return ' '.join(row)\n\ntest['tags'] = test['tags'].apply(lambda x: me_clean(x))\ntest[['image_name','tags']].to_csv('submission_boc_02.csv', index=False)\ntest.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64a5a294-4ef7-f6db-9dac-bf65138010db"},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nth = []\ntrain_predx = etr.predict(xtrain)\nfor i in np.arange(0.0, 0.9, 0.01):\n    train_pred = train_predx.copy()\n    train_pred[train_pred >i] = 1\n    train_pred[train_pred < 1] = 0\n    th.append([i, fbeta_score(y,train_pred,beta=2, average='samples')])\n_ = pd.DataFrame(th, columns=['th','f2_score']).plot(kind='line', x='th', y='f2_score')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}