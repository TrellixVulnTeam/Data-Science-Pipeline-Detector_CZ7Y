{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c046d7cf-c6f9-16b4-31b8-ad2fe15ee36a"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7185eb4-92dd-4e17-6701-f76696bf0a50"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c028222-f230-d550-91ff-909e276aa6ff"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42f5513f-b226-61a1-69b7-e7b8627cd026"},"outputs":[],"source":"from multiprocessing import Pool, cpu_count\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import fbeta_score\nfrom PIL import Image, ImageStat\nfrom skimage import io\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport glob, cv2\nimport random\nimport scipy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"901836d5-001f-eed0-af69-310fd71242fa"},"outputs":[],"source":"def get_features(path):\n    try:\n        st = []\n        #pillow jpg\n        img = Image.open(path)\n        im_stats_ = ImageStat.Stat(img)\n        st += im_stats_.sum\n        st += im_stats_.mean\n        st += im_stats_.rms\n        st += im_stats_.var\n        st += im_stats_.stddev\n        img = np.array(img)[:,:,:3]\n        st += [scipy.stats.kurtosis(img[:,:,0].ravel())]\n        st += [scipy.stats.kurtosis(img[:,:,1].ravel())]\n        st += [scipy.stats.kurtosis(img[:,:,2].ravel())]\n        st += [scipy.stats.skew(img[:,:,0].ravel())]\n        st += [scipy.stats.skew(img[:,:,1].ravel())]\n        st += [scipy.stats.skew(img[:,:,2].ravel())]\n        #cv2 jpg\n        img = cv2.imread(path)\n        bw = cv2.imread(path,0)\n        st += list(cv2.calcHist([bw],[0],None,[256],[0,256]).flatten()) #bw \n        st += list(cv2.calcHist([img],[0],None,[256],[0,256]).flatten()) #r\n        st += list(cv2.calcHist([img],[1],None,[256],[0,256]).flatten()) #g\n        st += list(cv2.calcHist([img],[2],None,[256],[0,256]).flatten()) #b\n        try:\n            #skimage tif\n            imgr = io.imread(path.replace('jpg','tif'))\n            tf = imgr[:, :, 3]\n            st += list(cv2.calcHist([tf],[0],None,[256],[0,65536]).flatten()) #near ifrared\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 0]) / (imgr[:, :, 3] + imgr[:, :, 0])) #water ~ -1.0, barren area ~ 0.0, shrub/grass ~ 0.2-0.4, forest ~ 1.0\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 1]) / (imgr[:, :, 3] + imgr[:, :, 1]))\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 2]) / (imgr[:, :, 3] + imgr[:, :, 2]))\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n        except:\n            st += [-1 for i in range(256)]\n            st += [-2 for i in range(60)]\n            print('err', path.replace('jpg','tif'))\n        m, s = cv2.meanStdDev(img) #mean and standard deviation\n        st += list(m)\n        st += list(s)\n        st += [cv2.Laplacian(bw, cv2.CV_64F).var()] \n        st += [cv2.Laplacian(img, cv2.CV_64F).var()]\n        st += [cv2.Sobel(bw,cv2.CV_64F,1,0,ksize=5).var()]\n        st += [cv2.Sobel(bw,cv2.CV_64F,0,1,ksize=5).var()]\n        st += [cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5).var()]\n        st += [cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5).var()]\n        st += [(bw<30).sum()]\n        st += [(bw>225).sum()]\n    except:\n        print(path)\n    return [path, st]\n\ndef normalize_img(paths):\n    imf_d = {}\n    p = Pool(cpu_count())\n    ret = p.map(get_features, paths)\n    for i in range(len(ret)):\n        imf_d[ret[i][0]] = ret[i][1]\n    ret = []\n    fdata = [imf_d[f] for f in paths]\n    return fdata\n\nin_path = '../input/'\ntrain = pd.read_csv(in_path + 'train.csv')[:500]\ntrain['path'] = train['image_name'].map(lambda x: in_path + 'train-jpg/' + x + '.jpg')\ny = train['tags'].str.get_dummies(sep=' ')\nxtrain = normalize_img(train['path']); print('train...')\n\ntest_jpg = glob.glob(in_path + 'test-jpg/*')[:500]\ntest = pd.DataFrame([[p.split('/')[3].replace('.jpg',''),p] for p in test_jpg])\ntest.columns = ['image_name','path']\nxtest = normalize_img(test['path']); print('test...')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a708e7f-c034-8be1-780f-21dd9efce1aa"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ee842e2-4842-1c92-4aa5-07361a21866e"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}