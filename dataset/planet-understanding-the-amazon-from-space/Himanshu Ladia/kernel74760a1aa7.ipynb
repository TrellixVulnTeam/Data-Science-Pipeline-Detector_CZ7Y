{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom collections import Counter, defaultdict\nimport cv2\nfrom multiprocessing import cpu_count\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Input, Flatten, Dense, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom sklearn.metrics import fbeta_score\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('# File sizes')\nfor f in os.listdir('../input/planet-understanding-the-amazon-from-space/'):\n    if not os.path.isdir('../input/planet-understanding-the-amazon-from-space/' + f):\n        print(f.ljust(30) + str(round(os.path.getsize('../input/planet-understanding-the-amazon-from-space/' + f) / 1000000, 2)) + 'MB')\n    else:\n        sizes = [os.path.getsize('../input/planet-understanding-the-amazon-from-space/'+f+'/'+x)/1000000 for x in os.listdir('../input/planet-understanding-the-amazon-from-space/' + f)]\n        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/planet-understanding-the-amazon-from-space/train_v2.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = df_train['tags'].apply(lambda x : x.split(' '))\ncounts = defaultdict(int)\nfor label in labels:\n    for tag in label:\n        counts[tag] += 1\n\nx = list(counts.keys())\ny = list(counts.values())\nx_pos = [i for i,_ in enumerate(x)]\nplt.figure(figsize=(20,5))\nplt.bar(x_pos, y)\nplt.xlabel('Tags')\nplt.ylabel('Counts')\nplt.title('Distribution of tags')\nplt.xticks(x_pos, x, rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in df_train[:9].values:\n    img = cv2.imread('../input/planet-understanding-the-amazon-from-space/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n    i += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_validation_split(df_train, validation_split_size):\n    flatten = lambda l: [item for sublist in l for item in sublist]\n    labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n    y_map = {l: i for i, l in enumerate(labels)}\n    \n    y_train = []\n    \n    for file_name, tags in df_train.values:\n        targets = np.zeros(len(y_map))\n        for t in tags.split(' '):\n            targets[y_map[t]] = 1\n        y_train.append(targets)\n        \n    y_train = np.array(y_train, np.uint8)\n    \n    train_index = []\n    val_index = []\n    index = np.arange(len(df_train))\n    for i in range(len(y_map)):\n        sss = StratifiedShuffleSplit(n_splits=2, test_size=validation_split_size, random_state=i)\n        for train_idx, test_idx in sss.split(index, y_train[:,i]):\n            X_train, X_test = index[train_idx], index[test_idx]\n        train_index = train_index + list(set(X_train) - set(train_index) - set(val_index))\n        val_index = val_index + list(set(X_test) - set(train_index) - set(val_index))\n        \n    return np.array(train_index), np.array(val_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_class_mapping(data):\n    file_path, tags, y_map = data\n    targets = np.zeros(len(y_map))\n    \n    for t in tags.split(' '):\n        targets[y_map[t]] = 1\n        \n    return file_path, targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_train_data_files(df_train, train_jpeg_dir, validation_split_size, process_count):\n    train_files, train_tags = [], []\n    val_files, val_tags = [], []\n    x_train_files, y_train_files = [], []\n    x_val_files, y_val_files = [], []\n    \n    files_path = []\n    tags_list = []\n    \n    for file_name, tags in df_train.values:\n        files_path.append('{}/{}.jpg'.format(train_jpeg_dir, file_name))\n        tags_list.append(tags)\n        \n    train_index, val_index = _get_validation_split(df_train, validation_split_size)\n    for index in train_index:\n        train_files.append(files_path[index])\n        train_tags.append(tags_list[index])\n    for index in val_index:\n        val_files.append(files_path[index])\n        val_tags.append(tags_list[index])\n    \n    flatten = lambda l: [item for sublist in l for item in sublist]\n    labels = list(set(flatten([tags.split(' ') for tags in df_train['tags'].values])))\n    y_map = {l: i for i, l in enumerate(labels)}\n\n    with ThreadPoolExecutor(process_count) as pool:\n        for file_path, targets in tqdm(pool.map(_get_class_mapping, [(file_path, tags, y_map) for file_path, tags in zip(train_files, train_tags)]), total=len(train_files)):\n            x_train_files.append(file_path)\n            y_train_files.append(targets)\n            \n    with ThreadPoolExecutor(process_count) as pool:\n        for file_path, targets in tqdm(pool.map(_get_class_mapping, [(file_path, tags, y_map) for file_path, tags in zip(val_files, val_tags)]), total=len(val_files)):\n            x_val_files.append(file_path)\n            y_val_files.append(targets)\n            \n    return [x_train_files, y_train_files, x_val_files, y_val_files, {v:k for k,v in y_map.items()}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_test_data_files(test_jpeg_dir):\n    filenames = os.listdir(test_jpeg_dir)\n    X_test_file_name = filenames\n    X_test_file_path = [test_jpeg_dir+'/'+name for name in filenames]\n    return X_test_file_name, X_test_file_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _val_transform_to_matrices(data):\n    file_path, label = data\n    image = Image.open(file_path)\n    image.thumbnail((128,128))\n    image = np.asarray(image.convert('RGB'), dtype=np.float32)\n    image = image[:,:,::-1]\n    image[:, :, 0] -= 103.939\n    image[:, :, 1] -= 116.779\n    image[:, :, 2] -= 123.68\n    image = image / 255\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _preprocess_val_files(process_count, X_val, y_val):\n    X = []\n    y = []\n    with ThreadPoolExecutor(process_count) as pool:\n        for image, targets in pool.map(_val_transform_to_matrices, [(file_path, label) for file_path, label in zip(X_val, y_val)]):\n            X.append(image)\n            y.append(targets)\n    result = [np.array(X), np.array(y)]\n    print(\"Size consumed by validation matrices {} mb\".format(result[0].nbytes/1024/1024))\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_train_generator(X_train, y_train, batch_size):\n    augmentor = ImageDataGenerator(rescale=1./255,shear_range=0.2,horizontal_flip=True,vertical_flip=True)\n    loop_range = len(X_train)\n    \n    while True:\n        for i in range(loop_range):\n            start_offset = batch_size * i\n            range_offset = min(batch_size, loop_range-start_offset)\n            \n            if range_offset <= 0:\n                break\n                \n            batch_features = np.zeros((range_offset, 128, 128, 3))\n            batch_labels = np.zeros((range_offset, len(y_train[0])))\n            \n            for j in range(range_offset):\n                image = Image.open(X_train[start_offset + j])\n                image.thumbnail((128,128))\n                image = np.asarray(image.convert('RGB'), dtype=np.float32)\n                image = image[:,:,::-1]\n                image[:, :, 0] -= 103.939\n                image[:, :, 1] -= 116.779\n                image[:, :, 2] -= 123.68\n                \n                batch_features[j] = image\n                batch_labels[j] = y_train[start_offset + j]\n                \n            yield next(augmentor.flow(batch_features, batch_labels, range_offset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_prediction_generator(X_test_filename, batch_size):\n    loop_range = len(X_test_filename)\n    \n    while True:\n        for i in range(loop_range):\n            start_offset = batch_size * i\n            range_offset = min(batch_size, loop_range-start_offset)\n            \n            if range_offset <= 0:\n                break\n                \n            batch_features = np.zeros((range_offset, 128, 128, 3))\n            \n            for j in range(range_offset):\n                image = Image.open(X_test_filename[start_offset + j])\n                image.thumbnail((128,128))\n                image = np.asarray(image.convert('RGB'), dtype=np.float32)\n                image = image[:,:,::-1]\n                image[:, :, 0] -= 103.939\n                image[:, :, 1] -= 116.779\n                image[:, :, 2] -= 123.68\n                image = image/255\n    \n                batch_features[j] = image\n        \n            yield batch_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(shape):\n    inputLayer = Input(shape)\n    baseModel = VGG16(include_top=False, weights='imagenet', input_shape=shape)\n    x = BatchNormalization()(inputLayer)\n    x = baseModel(x)\n    x = Flatten()(x)\n    outputLayer = Dense(17, activation='sigmoid')(x)\n    model = Model(inputLayer, outputLayer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, X_test_filename, X_test, batch_size=128):\n    generator = _get_prediction_generator(X_test_filename, batch_size)\n    predictions = model.predict_generator(generator=generator, verbose=1, steps=len(X_test_filename)/batch_size)\n    assert len(X_test_filename) == len(predictions), \"len(X_test_filename) = {}, len(predictions) = {}\".format(len(X_test_filename), len(predictions))\n    return np.array(X_test), predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def map_predictions(predictions, thresholds):\n    predictions_labels = []\n    for prediction in predictions:\n        labels = [y_map[i] for i,value in enumerate(prediction) if value>thresholds[i]]\n        predictions_labels.append(labels)\n    return predictions_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fbeta(model, X_valid, y_valid):\n    p_valid = model.predict(X_valid)\n    return fbeta_score(y_valid, np.array(p_valid)>0.2, beta=2, average='samples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_resize = (128,128)\nvalidation_split_size = 0.2\ntrain_jpeg_dir = '../input/planet-understanding-the-amazon-from-space/train-jpg'\ntest_jpeg_dir = '../input/planet-understanding-the-amazon-from-space/test-jpg-v2'\nprocess_count = cpu_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train, X_val_pre, y_val_pre, y_map = _get_train_data_files(df_train, train_jpeg_dir, validation_split_size, process_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val, y_val = _preprocess_val_files(process_count, X_val_pre, y_val_pre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, X_test_filename = _get_test_data_files(test_jpeg_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model((128,128,3))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [History(), \n             ModelCheckpoint(filepath='/kaggle/working/models/weights.best.hdf5', verbose=1, save_best_only=True, save_weights_only=True, mode='auto'),\n             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=0, min_lr=1e-7, verbose=1)]\n\nbatch_size = 128\ntrain_generator = _get_train_generator(X_train, y_train, batch_size)\nsteps = len(X_train) / batch_size\n\nmodel.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\nhistory = model.fit_generator(train_generator, steps, epochs=25, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(callbacks[0].history['loss'])\nplt.plot(callbacks[0].history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"/kaggle/working/models/weights.best.hdf5\")\nprint(\"Weights loaded\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fbeta_score = fbeta(model, X_val, y_val)\nfbeta_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_filename, predictions = predict(model, X_test_filename, X_test, batch_size=128)\nprint(\"Predictions shape: {}\\nFiles name shape: {}\\n1st predictions ({}) entry:\\n{}\".format(predictions.shape, \n                                                                              x_test_filename.shape,\n                                                                              x_test_filename[0], predictions[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_labels = map_predictions(predictions=predictions, thresholds=[0.2]*len(counts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_tags = [None] * len(predicted_labels)\nfor i, tags in enumerate(predicted_labels):\n    predicted_tags[i] = ' '.join(map(str, tags))\n    \nresult = [[filename.split('.')[0], tags] for filename, tags in zip(x_test_filename, predicted_tags)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result = pd.DataFrame(result, columns=['image_name', 'tags'])\ndf_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result.to_csv('/kaggle/working/submission_file.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(r'/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'submission_file.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}