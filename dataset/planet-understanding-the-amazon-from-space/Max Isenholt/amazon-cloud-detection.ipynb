{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3ed4d95-5a05-7745-f740-0a7b3ad19c0d"},"outputs":[],"source":"import os\n\nfrom skimage import io\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efa1ed33-3e77-c25b-6a44-8b8a864b163b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51b280cd-1e27-a532-7029-98203f392170"},"outputs":[],"source":"PLANET_KAGGLE_ROOT = os.path.abspath(\"../input/\")\nPLANET_KAGGLE_TIF_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-tif-v2')\nPLANET_KAGGLE_TEST_TIF_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'test-tif-v2')\nPLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\nassert os.path.exists(PLANET_KAGGLE_ROOT)\nassert os.path.exists(PLANET_KAGGLE_TIF_DIR)\nassert os.path.exists(PLANET_KAGGLE_TEST_TIF_DIR)\nassert os.path.exists(PLANET_KAGGLE_LABEL_CSV)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8bf9c91-2c1b-a52a-6b2c-db6f81a248c6"},"outputs":[],"source":"labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\nlabels_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1a01fb5-0a50-a17a-985e-ed0b7e6041ac"},"outputs":[],"source":"tagSet = set()\n\nfor tagStr in labels_df['tags']:\n    tagSet.update(tagStr.split())\n    \nfor tag in tagSet:\n    labels_df[tag] = labels_df['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \nlabels_df.head()\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7dbe565e-f72b-8330-e1ed-ee9688dc3da0"},"outputs":[],"source":"cloud_df = labels_df[['image_name', 'clear', 'partly_cloudy', 'cloudy', 'haze']]\ncloud_df.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1eb40283-bc3e-6e7c-43f5-f0f5362a33f8"},"outputs":[],"source":"cloud_df_samp = cloud_df.sample(n=2000)\ncloud_df_samp.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d66ad49-5c25-e2e5-63a3-98cb2d3c484f"},"outputs":[],"source":"def loadImage(imageName, suffix='tif', dirPath=PLANET_KAGGLE_TIF_DIR):\n    \n    fileName = '.'.join((imageName, suffix))\n    path = os.path.abspath(os.path.join(dirPath, fileName))\n    if os.path.exists(path):\n        #print('Found image {}'.format(path))\n        return io.imread(path)\n    \n    print('Load failed: could not find image {}'.format(path))\n    \nimageName = cloud_df.iloc[9870,:]['image_name']\nsampleImage = loadImage(imageName)\nlabels_df.loc[labels_df['image_name'] == imageName]['tags']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8837a137-4fca-0513-77d0-2a7d0d0224d7"},"outputs":[],"source":"sampleImage.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d52cd6d-6e81-8c86-c84f-167ceb853c7b"},"outputs":[],"source":"def image2grey_avg(image):\n    #image is exppected to be a numpy 3d array where the first two dimensions\n    #are the raster of pixels and the third dimension is the rgb values.\n    #This method averages the rgb values to produce 2d matrix of greyscale values.\n    \n    assert(image.shape[2] == 3)\n    return np.apply_along_axis(np.mean, axis=2, arr=image)\n    \navg_grey = image2grey_avg(sampleImage[:,:,:3])\nplt.imshow(avg_grey, cmap='Greys')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1081276d-8992-de23-6aa3-e691d9e4698b"},"outputs":[],"source":"def dot_lum(rgb):\n    return np.dot(rgb, (.21, .72, .07))\n\ndef image2grey_lum(image):\n    #image is exppected to be a numpy 3d array where the first two dimensions\n    #are the raster of pixels and the third dimension is the rgb values.\n    #This method averages the rgb values to produce 2d matrix of greyscale values.\n    \n    assert(image.shape[2] == 3)\n    return np.apply_along_axis(dot_lum, axis=2, arr=image)\n    \nlum_grey = image2grey_lum(sampleImage[:,:,:3])\nplt.imshow(lum_grey, cmap='Greys')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0850049-0106-45b9-d497-0a2f0b5fc735"},"outputs":[],"source":"def compress_image(width, height, image):\n    #image is presumed to be a 2D array of values\n    retMat = np.empty((width, height))\n    x_slice = int(np.ceil(image.shape[0]/width))\n    y_slice = int(np.ceil(image.shape[1]/height))\n    for x in range(width):\n        for y in range(height):\n            s = (x*x_slice,(x+1)*x_slice,y*y_slice,(y+1)*y_slice)\n            slc = image[s[0]:s[1],s[2]:s[3]]\n            retMat[x][y] = np.mean(slc)\n            \n    return retMat\n\ncompressed_image = compress_image(16, 16, sampleImage[:,:,:3])\ncompressed_nir = compress_image(16, 16, sampleImage[:,:,3])\ncompressed_image_avg_grey = compress_image(16, 16, avg_grey)\ncompressed_image_lum_grey = compress_image(16, 16, lum_grey)\n\nplt.figure()\nplt.imshow(compressed_image, cmap='Greys')\n\nplt.figure()\nplt.imshow(compressed_nir, cmap='Greys')\n\nplt.figure()\nplt.imshow(compressed_image_avg_grey, cmap='Greys')\n\nplt.figure()\nplt.imshow(compressed_image_lum_grey, cmap='Greys')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16fdb995-7f76-9adf-43b5-7a4c158d3f1f"},"outputs":[],"source":"v = compressed_image.reshape((-1,1))\nv.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"929f9910-2d72-94a4-f4fd-2b95885b042c"},"outputs":[],"source":"cloud_df_samp.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be0cd735-428d-6a23-8bb3-7940384a1f32"},"outputs":[],"source":"def feat_ext_nir(x):\n    print(x.shape)\n    img = loadImage(x)\n    compressed_img = compress_image(16, 16, img[:,:,3])\n    return compressed_image.ravel()\n\ncloud_nir_names = cloud_df_samp['image_name'].values\nprint(cloud_nir_names.shape)\ncloud_feat_nir = np.apply_along_axis(feat_ext_nir, 1, cloud_nir_names)\ntype(cloud_feat_nir)\n#cloud_feat_nir = [feat_ext_nir(x) for x in cloud_df_samp['image_name']]\n#cloud_feat_nir[:5]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fbb7216-5613-1048-2c28-fed4637dec82"},"outputs":[],"source":"cloud_feat_nir.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18520ff0-bc8a-2f65-8e9e-34aec5abbe73"},"outputs":[],"source":"cloud_train_nir = pd.concat([cloud_df_samp, cloud_feat_nir], axis=1, join_axes=[cloud_df_samp.index])\ncloud_train_nir.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4391599f-906b-f772-f550-ff2e66c5af26"},"outputs":[],"source":"cloud_train_nir.head()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}