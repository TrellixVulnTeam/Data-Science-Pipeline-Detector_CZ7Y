{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f37a9596-11de-4330-6e6d-2fda24efdba3"},"source":"This is based on our Kaggles notebook.\nhttps://github.com/planetlabs/planet-amazon-deforestation/blob/master/planet_chip_examples.ipynb\n\n# *Planet: Understanding the Amazon from Space* challenge\n\nThis notebook is just to explore the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9018e828-1983-15e2-6566-b93fa759ca04"},"outputs":[],"source":"import sys\nimport os\nimport subprocess\nfrom six import string_types\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport scipy\nfrom skimage import io\nfrom scipy import ndimage\nfrom IPython.display import display\n%matplotlib inline\nfrom spectral import imshow"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e51259c-c390-6751-a321-2ede2b312a7c"},"outputs":[],"source":"!ls -lha ../input"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4f4f743-8c83-28b6-b759-1f85d91bd4f9"},"outputs":[],"source":"!ls -lha ../input/test-tif-v2 | wc -l"},{"cell_type":"markdown","metadata":{"_cell_guid":"de648e34-cf96-3c7d-37ad-59bc2b8360f7"},"source":"## Setup\nSet `PLANET_KAGGLE_ROOT` to the proper directory where we've got the TIFF and JPEG zip files, and accompanying CSVs."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bace665c-f34b-09ff-7808-9efa412c65ca"},"outputs":[],"source":"PLANET_KAGGLE_ROOT = os.path.abspath(\"../input/\")\nPLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\nPLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\nassert os.path.exists(PLANET_KAGGLE_ROOT)\nassert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\nassert os.path.exists(PLANET_KAGGLE_LABEL_CSV)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3468c4df-3507-4650-e1ef-33348b7507ec"},"source":"## Inspect image labels\nThe labels are in a CSV entitled `train.csv`. Note that each image can be tagged with multiple tags. We'll convert them to a \"one hot\" style representation where each label is a column:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a90f711-8222-e7b0-9635-a00456ed64b0"},"outputs":[],"source":"labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\nlabels_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f556c7f8-5e52-aab8-ca43-f5184a85836e"},"outputs":[],"source":"# Build list with unique labels\nlabel_list = []\nfor tag_str in labels_df.tags.values:\n    labels = tag_str.split(' ')\n    for label in labels:\n        if label not in label_list:\n            label_list.append(label)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9f1be5a-b833-e0c3-bbf3-a95a72d02335"},"outputs":[],"source":"# Add onehot features for every label\nfor label in label_list:\n    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n# Display head\nlabels_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"918adbb3-fd30-0d4d-6da2-12b49c6fa3bd"},"outputs":[],"source":"# Histogram of label instances\nlabels_df[label_list].sum().sort_values().plot.bar()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"345bfce6-c8d5-1c83-4e69-c2ba2ddf256c"},"outputs":[],"source":"def make_cooccurence_matrix(labels):\n    numeric_df = labels_df[labels]; \n    c_matrix = numeric_df.T.dot(numeric_df)\n    sns.heatmap(c_matrix)\n    return c_matrix\n\n# Compute the co-ocurrence matrix\nmake_cooccurence_matrix(label_list)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c130a544-2ae7-71c9-04f1-51c3e69ce842"},"source":"Each image should have exactly one weather label:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c40a10f-83cc-5ab3-7c95-f8e26a08068f"},"outputs":[],"source":"weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\nmake_cooccurence_matrix(weather_labels)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f61ee506-ee56-9ba1-db45-1da151978e5c"},"source":"But the land labels may overlap:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b503e3da-a478-ac7f-41e5-1893394f3a68"},"outputs":[],"source":"land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation']\nmake_cooccurence_matrix(land_labels)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3e06f07e-3c31-067b-78dc-323505ca5d6c"},"source":"The rarer labels have very little overlap:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8703df07-3d6b-abfe-8614-28d4ff068e4a"},"outputs":[],"source":"rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\nmake_cooccurence_matrix(rare_labels)"},{"cell_type":"markdown","metadata":{"_cell_guid":"cbd4cc2b-dc23-5d51-813d-58191d04e36a"},"source":"## Inspect images\nLet's display an image and visualize the pixel values. Here we will pick an image, load every single single band, then create RGB stack. These raw images are 16-bit (from 0 to 65535), and contain red, green, blue, and [Near infrared (NIR)](https://en.wikipedia.org/wiki/Infrared#Regions_within_the_infrared) channels. In this example, we are discarding the NIR band just to simplify the steps to visualize the image. However, you should probably keep it for ML classification.\n\nThe files can be easily read into numpy arrays with the skimage."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee7b99e6-53d9-3443-67db-3ab30742d448"},"outputs":[],"source":"def sample_images(tags, n=None):\n    \"\"\"Randomly sample n images with the specified tags.\"\"\"\n    condition = True\n    if isinstance(tags, string_types):\n        raise ValueError(\"Pass a list of tags, not a single tag.\")\n    for lbl in label_list:\n        if lbl in tags:\n            condition = condition & (labels_df[lbl] == 1)\n        else:\n            condition = condition & (labels_df[lbl] == 0)\n    if n is not None:\n        return labels_df[condition].sample(n)\n    else:\n        return labels_df[condition]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d645aba-8089-6fa7-7057-601d65946e0f"},"outputs":[],"source":"sample_images(['clear','primary'], n=10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4165497-7319-fe38-b113-c572493c9c8c"},"outputs":[],"source":"def load_image(filename):\n    '''Look through the directory tree to find the image you specified\n    (e.g. train_10.tif vs. train_10.jpg)'''\n    for dirname in os.listdir(PLANET_KAGGLE_ROOT):\n        path = os.path.abspath(os.path.join(PLANET_KAGGLE_ROOT, dirname, filename))\n        if os.path.exists(path):\n            #print('Found image {}'.format(path))\n            return io.imread(path)\n    # if you reach this line, you didn't find the image you're looking for\n    print('Load failed: could not find image {}'.format(path))\n    \ndef sample_to_fname(sample_df, row_idx, suffix='tif'):\n    '''Given a dataframe of sampled images, get the\n    corresponding filename.'''\n    fname = sample_df.get_value(sample_df.index[row_idx], 'image_name')\n    return '{}.{}'.format(fname, suffix)\n\ndef display_sample_im(tags, n=None):\n    s = sample_images(tags, n=n)\n    if n is None:\n        n=0\n    for i in range(n):\n        fname = sample_to_fname(s.iloc[i], 0)\n        rgbn_image = load_image(fname)\n        imshow(rgbn_image[:,:,:3])\n    return rgbn_image, s\n    \n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b39255e-22df-74d2-4d63-37b20d8871d3"},"outputs":[],"source":"im, s = display_sample_im(['primary', 'clear'], n=4);\ns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"beb0cd22-6a4a-6db6-5682-e3d254ee628c"},"outputs":[],"source":"im_m = np.vstack([im[i*16:(i+1)*16,j*16:(j+1)*16,0].ravel() for i in range(16) for j in range(16)])\ncov = np.cov(im_m)\neigen_value, eigen_vector = np.linalg.eig(cov)\neigen_value = eigen_value.reshape(-1,1)\nsignificance_ind = eigen_value.argsort(axis=0)[::-1]\neigen_value[significance_ind[:,0]]\n# The n_th eigen vector\nn = 0\ni = significance_ind[n,0]\nfeature = eigen_vector[:,i:i+1].T\nfinaldata = np.dot(feature,im_m).T\nfirst_eigen_image = np.dot(feature.T,finaldata.T).T\nplt.imshow(im[0:16,0:16,0]);\nplt.figure()\nplt.imshow(finaldata.reshape(16,16));\nplt.figure()\nplt.imshow(first_eigen_image)\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"46156d4c-b583-2650-0e2b-a30f932e91a6"},"source":"### Calibrate colors for visual inspection"},{"cell_type":"markdown","metadata":{"_cell_guid":"9f2903ab-f1d6-55a8-8615-0387a8784ee3"},"source":"And now, we have a function that can calibrate any raw image reasonably well:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae8ece5e-8de5-156b-fb53-fe9516f149c2"},"outputs":[],"source":" def calibrate_image(rgb_image):\n    ref_stds = [41.262260630543992, 35.759466445746916, 33.383302346657047]\n    ref_means = [80.198569793701168, 87.701977996826173, 76.552578582763672]\n    \n    # Transform test image to 32-bit floats to avoid \n    # surprises when doing arithmetic with it \n    calibrated_img = rgb_image.copy().astype('float32')\n\n    # Loop over RGB\n    for i in range(3):\n        # Subtract mean \n        calibrated_img[:,:,i] = calibrated_img[:,:,i]-np.mean(calibrated_img[:,:,i])\n        # Normalize variance\n        calibrated_img[:,:,i] = calibrated_img[:,:,i]/np.std(calibrated_img[:,:,i])\n        # Scale to reference \n        calibrated_img[:,:,i] = calibrated_img[:,:,i]*ref_stds[i] + ref_means[i]\n        # Clip any values going out of the valid range\n        calibrated_img[:,:,i] = np.clip(calibrated_img[:,:,i],0,255)\n\n    # Convert to 8-bit unsigned int\n    return calibrated_img.astype('uint8')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3b10fd3-3ff3-0f6c-5f08-c6cde6ceab98"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}