{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"558c6543-7398-38be-cb27-f039ea547cbb"},"source":"Image Features\n=============="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c571eb29-4e46-e89b-0057-d1d529f2df21"},"outputs":[],"source":"from multiprocessing import Pool, cpu_count\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import fbeta_score\nfrom PIL import Image, ImageStat\nfrom skimage import io\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport glob, cv2\nimport random\nimport scipy\n\nrandom.seed(1)\nnp.random.seed(1)\nnp.seterr(divide='ignore', invalid='ignore')\n\ndef get_features(path):\n    try:\n        st = []\n        #pillow jpg\n        img = Image.open(path)\n        im_stats_ = ImageStat.Stat(img)\n        st += im_stats_.sum\n        st += im_stats_.mean\n        st += im_stats_.rms\n        st += im_stats_.var\n        st += im_stats_.stddev\n        img = np.array(img)[:,:,:3]\n        st += [scipy.stats.kurtosis(img[:,:,0].ravel())]\n        st += [scipy.stats.kurtosis(img[:,:,1].ravel())]\n        st += [scipy.stats.kurtosis(img[:,:,2].ravel())]\n        st += [scipy.stats.skew(img[:,:,0].ravel())]\n        st += [scipy.stats.skew(img[:,:,1].ravel())]\n        st += [scipy.stats.skew(img[:,:,2].ravel())]\n        #cv2 jpg\n        img = cv2.imread(path)\n        bw = cv2.imread(path,0)\n        st += list(cv2.calcHist([bw],[0],None,[256],[0,256]).flatten()) #bw \n        st += list(cv2.calcHist([img],[0],None,[256],[0,256]).flatten()) #r\n        st += list(cv2.calcHist([img],[1],None,[256],[0,256]).flatten()) #g\n        st += list(cv2.calcHist([img],[2],None,[256],[0,256]).flatten()) #b\n        try:\n            #skimage tif\n            if 'train' in path:\n                imgr = io.imread(path.replace('jpg','tif').replace('-tif', '-tif-v2'))\n            else:\n                imgr = io.imread(path.replace('jpg','tif'))\n            tf = imgr[:, :, 3]\n            st += list(cv2.calcHist([tf],[0],None,[256],[0,65536]).flatten()) #near ifrared\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 0]) / (imgr[:, :, 3] + imgr[:, :, 0])) #water ~ -1.0, barren area ~ 0.0, shrub/grass ~ 0.2-0.4, forest ~ 1.0\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 1]) / (imgr[:, :, 3] + imgr[:, :, 1]))\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 2]) / (imgr[:, :, 3] + imgr[:, :, 2]))\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n        except:\n            st += [-1 for i in range(256)]\n            st += [-2 for i in range(60)]\n            print('err', path.replace('jpg','tif'))\n        m, s = cv2.meanStdDev(img) #mean and standard deviation\n        st += list(m)\n        st += list(s)\n        st += [cv2.Laplacian(bw, cv2.CV_64F).var()] \n        st += [cv2.Laplacian(img, cv2.CV_64F).var()]\n        st += [cv2.Sobel(bw,cv2.CV_64F,1,0,ksize=5).var()]\n        st += [cv2.Sobel(bw,cv2.CV_64F,0,1,ksize=5).var()]\n        st += [cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5).var()]\n        st += [cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5).var()]\n        st += [(bw<30).sum()]\n        st += [(bw>225).sum()]\n    except:\n        print(path)\n    return [path, st]\n\ndef normalize_img(paths):\n    imf_d = {}\n    p = Pool(cpu_count())\n    ret = p.map(get_features, paths)\n    for i in range(len(ret)):\n        imf_d[ret[i][0]] = ret[i][1]\n    ret = []\n    fdata = [imf_d[f] for f in paths]\n    return fdata\n\nin_path = '../input/'\ntrain = pd.read_csv(in_path + 'train.csv')[:500]\ntrain['path'] = train['image_name'].map(lambda x: in_path + 'train-jpg/' + x + '.jpg')\nprint(train.head(3))\ny = train['tags'].str.get_dummies(sep=' ')\nxtrain = normalize_img(train['path']); print('train...')\n\n\ntest_jpg = glob.glob(in_path + 'test-jpg-v2/*')[:500]\n#test_jpg[0:10]\ntest = pd.DataFrame([[p.split('/')[3].replace('.jpg',''),p] for p in test_jpg])\nprint(test.head(5))\ntest.columns = ['image_name','path']\nxtest = normalize_img(test['path']); print('test...')"},{"cell_type":"markdown","metadata":{"_cell_guid":"1b375771-34eb-9cfc-0c19-2471c780bfa3"},"source":"Model 1\n======="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1cf42207-a2d3-6eff-324a-af4134836b88"},"outputs":[],"source":"etr = ExtraTreesRegressor(n_estimators=200, max_depth=30, n_jobs=-1, random_state=1)\netr.fit(xtrain, y); print('etr fit...')\n\ntrain_pred = etr.predict(xtrain)\ntrain_pred[train_pred > 0.20] = 1\ntrain_pred[train_pred < 1] = 0\nprint(fbeta_score(y,train_pred,beta=2, average='samples'))\n\npred1 = etr.predict(xtest); print('etr predict...')\netr_test = pd.DataFrame(pred1, columns=y.columns)\netr_test['image_name'] =  test[['image_name']]\n\ntags = []\nfor r in etr_test[y.columns].values:\n    r = list(r)\n    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.23], reverse=True)]))\n\ntest['tags'] = tags\ntest[['image_name','tags']].to_csv('submission_blend.csv', index=False)\ntest.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"584ecb7e-d4fb-e8e4-0707-a1abef34e0f8"},"source":"Model 2\n======="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dea02b47-2b9f-7004-6dd4-63349d24f246"},"outputs":[],"source":"xgb_train = pd.DataFrame(train[['path']], columns=['path'])\nxgb_test = pd.DataFrame(test[['image_name']], columns=['image_name'])\nprint('xgb fit...')\nfor c in y.columns:\n    model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=4, seed=1, base_score=0.5)\n    model.fit(np.array(xtrain), y[c])\n    xgb_train[c] = model.predict_proba(np.array(xtrain))[:, 1]\n    xgb_test[c] = model.predict_proba(np.array(xtest))[:, 1]\n    print(c)\n\ntrain_pred = xgb_train[y.columns].values\ntrain_pred[train_pred >0.20] = 1\ntrain_pred[train_pred < 1] = 0\nprint(fbeta_score(y,train_pred,beta=2, average='samples')) \nprint('xgb predict...')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2361e62d-85f1-d041-e3aa-b988f69075ac"},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nth = []\ntrain_predx = xgb_train[y.columns].values\nfor i in np.arange(0.0, 0.9, 0.01):\n    train_pred = train_predx.copy()\n    train_pred[train_pred >i] = 1\n    train_pred[train_pred < 1] = 0\n    th.append([i, fbeta_score(y,train_pred,beta=2, average='samples')])\n_ = pd.DataFrame(th, columns=['th','f2_score']).plot(kind='line', x='th', y='f2_score')"},{"cell_type":"markdown","metadata":{"_cell_guid":"479d9f76-56d2-2999-e0d8-ed781c9fb9af"},"source":"Blend\n====="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0505c24-f558-62f4-37fe-31e02154877d"},"outputs":[],"source":"xgb_test.columns = [x+'_' if x not in ['image_name'] else x for x in xgb_test.columns]\nblend = pd.merge(etr_test, xgb_test, how='left', on='image_name')\n\nfor c in y.columns:\n    blend[c] = (blend[c] * 0.60)  + (blend[c+'_'] * 0.40)\n\nblend = blend[etr_test.columns]"},{"cell_type":"markdown","metadata":{"_cell_guid":"c48167f2-ae05-dfcb-3b9b-95927dc4121c"},"source":"Prepare Submission\n=================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b965d747-ed78-0741-f899-c5b875b7d3e5"},"outputs":[],"source":"tags = []\nfor r in blend[y.columns].values:\n    r = list(r)\n    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.20], reverse=True)]))\n\ntest['tags'] = tags\ntest[['image_name','tags']].to_csv('submission_blend.csv', index=False)\ntest.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a57263d0-0734-cbc6-ddac-cbe224e5e859"},"source":"Visualize Results\n================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5012d37-5260-8d83-ef71-0fe916c9953e"},"outputs":[],"source":"for l in y.columns:\n    try:\n        pathsx = test[test['tags'].str.contains(str(l))==True].path.tolist()[:9]\n        plt.rcParams['figure.figsize'] = (10.0, 10.0)\n        plt.subplots_adjust(wspace=0, hspace=0)\n        fig = plt.figure()\n        fig.suptitle(l)\n        for x in range(9):\n                plt.subplot(3, 3, x+1)\n                im = Image.open(pathsx[x])\n                #im = im.resize((100, 100), Image.ANTIALIAS)\n                plt.imshow(im)\n                plt.axis('off')\n    except:\n        print(l)"},{"cell_type":"markdown","metadata":{"_cell_guid":"28d87f52-af77-13bc-8886-7814b0f0ed0a"},"source":"Visualize Feature Importance\n============================"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"380fd559-c85b-f961-97dd-c04e0b55d240"},"outputs":[],"source":"col = ['sum1','sum2','sum3','sum4','mean1','mean2','mean3','mean4','rms1','rms2','rms3','rms4','var1','var2','var3','var4','stddev1','stddev2','stddev3','stddev4','kurtosis1','kurtosis2','kurtosis3','skew1','skew2','skew3']\ncol += ['bw'+str(i) for i in range(256)]\ncol += ['r'+str(i) for i in range(256)]\ncol += ['g'+str(i) for i in range(256)]\ncol += ['b'+str(i) for i in range(256)]\ncol += ['infrared'+str(i) for i in range(256)]\ncol += ['nvdi'+str(i) for i in range(60)]\ncol += ['cv2mean1','cv2mean2','cv2mean3','cv2stddev1','cv2stddev2','cv2stddev3','Laplacian_bw','Laplacian_img','Sobel1_bw','Sobel2_bw','Sobel1_img','Sobel2_img','black_bw','white_bw']\nimp = etr.feature_importances_\nfeat_imp = [[imp[i], col[i]] for i in range(len(imp))]\n_ = pd.DataFrame(feat_imp, columns=['importance','column']).sort_values(['importance','column'], ascending=[False, False])[:30].plot(kind='barh', x='column', y='importance')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}