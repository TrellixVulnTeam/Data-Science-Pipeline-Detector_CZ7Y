{"cells":[{"metadata":{"_cell_guid":"640c03c5-130e-84b6-bbc8-baa9a71ecf5c","_uuid":"45d389ce55f55c1bc5cb610d3e6f2eeb19af2d01"},"cell_type":"markdown","source":"We were promised a noisy data set. I want to find out how bad it actually is.\n\n**Goal**: Preprocess image formats and explore the data looking for anomalies.\nThe images will include some noise. This kernel's goal is to detect outliers and mistagged images."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"c2f9cee8-3ec3-a610-5e5f-ec769e9b90db","_uuid":"3002727bc6ddb7458ac060136a5a7b7c39790e63"},"cell_type":"code","source":"from scipy import ndimage\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nfrom skimage import io\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67d27e3a-84b4-e93a-af5d-83f4a51e7dcd","_uuid":"eb55183b90bb1d4390cd6d57623d4cdf233f7a6f"},"cell_type":"markdown","source":"## Loading Data and Encoding Tags"},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"18208e5b-da8b-296e-fd94-35ce1f631cd2","_uuid":"90ebc74d429674c02b9388148e7dcc79ff63de93"},"cell_type":"code","source":"Labels = pd.read_csv('../input/train_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"6dd3bdcf-413b-5d4b-b3f6-38ef92de291f","_uuid":"a52186de5a40b876c03fd8d98d5f988c5d72b6a0"},"cell_type":"code","source":"Labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"a5da1f1a-a1fd-2562-3e1e-05aca27fd178","_uuid":"44eee1bac8cd6220aae2d480337fd7e102f7012b"},"cell_type":"code","source":"Labels.tail()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb32a568-a9f4-2dd4-7d18-b8761eb139a1","_uuid":"2adb033d692355a23430fb786e76b0f119d09bc0"},"cell_type":"markdown","source":"Encoding tags."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"5facdd03-e7d6-512b-70f6-76f661a68903","_uuid":"2834221aebf9d1e43f5a8e23d1ef17a5a6b92955"},"cell_type":"code","source":"tagnames = list(set(\n    [tag for sublist in Labels['tags'].apply(\n        lambda tagstring: tagstring.split()) for tag in sublist]))\nprint('Tags: ' + '%s' % ', '.join(tagnames))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"a30144f8-2e74-10dd-8870-e55696d40a9d","_uuid":"5c6e53e0260ed0baa11ff40ae6e43fce3a1fa99e"},"cell_type":"code","source":"# Useful function for encoding.\ndef containsTag(tag, taglist):\n    if tag in taglist.split():\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"9fe2cb35-f618-e6d2-018b-2115bba82ab0","_uuid":"710d11837db3b427e3f12a3120d44efff2f5afc5"},"cell_type":"code","source":"for tag in tagnames:\n    Labels[tag] = Labels['tags'].apply(\n        lambda taglist: containsTag(tag, taglist))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"ce5f0e58-697a-0641-b6ac-21df119707eb","_uuid":"102f69062afbceb3b0748f57997ce10d7b944b27"},"cell_type":"code","source":"Labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"13f75c2a-03e4-cfd2-6f2d-9ea2ae5a6b0c","_uuid":"f43d6824ab98f1f215706358a69fdb8f54f9c199"},"cell_type":"code","source":"Labels.tail()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a323b2f9-6fac-f8db-32ae-84563d39c912","_uuid":"a15d415633670721cad2cec71eae0e88df9c6d48"},"cell_type":"markdown","source":"As loading all the images at once would overload memory, we will load each image one at a time for processing. We could batch load too."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"12c1a14e-eeb4-e5b0-ab14-897f25845432","_uuid":"93c03a742162f636aa19b45c3811077799ae2e33"},"cell_type":"code","source":"def load_image(ImageName):\n    \"\"\"Convert an image given by filename to a numpy array.\n\n    Note, image sizes are expected to be 256 pixels by 256 pixels\n    \"\"\"\n    try:\n        image_data = io.imread(ImageName).astype(float)\n        if image_data.shape != (256, 256, 4):\n            raise Exception('Unexpected image shape: %s' %\n                            str(image_data.shape))\n    except IOError as e:\n        print('Could not read:', image, ':', e, '.')\n    return image_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"fd4d049c-e3aa-9b25-92fa-d1b22b839583","_uuid":"87e2d2f8b7ecf22b59839f090d47207fc521d4ee"},"cell_type":"code","source":"Labels['jpgFilename'] = Labels['image_name'].apply(\n    lambda name: '../input/train-jpg/' + name + '.jpg')\nLabels['tifFilename'] = Labels['image_name'].apply(\n    lambda name: '../input/train-tif-v2/' + name + '.tif')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ab31a28-6b89-ca77-0336-c1b3b7888e99","_uuid":"c4d11d46d5abd4c0f1f3dc961312c281a298f09f"},"cell_type":"markdown","source":"## Label Analysis\nWe will first gain and understanding of the distribution of image tags.\n\nIt is worth noting we did not create one-hot encodings as there are multiple tags per image. However, there should be a one-hot encoding for the atmospheric conditions of the image. Let's investigate that first."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"66ff9587-c4e0-6b9a-b97b-0239f98b5b6c","_uuid":"7a73ce4357bd700cd70ee01b4a2716e15fe71b6a"},"cell_type":"code","source":"# Check to see if there is any duplicate or missing atmospheric conditions.\nLabels[Labels[['clear', 'haze', 'partly_cloudy', 'cloudy']].sum(axis=1) != 1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"896c72de-18e3-5de4-9a72-a749a473a35e","_uuid":"a67a33fa3e944aec6367ce04af84e162aac965a1"},"cell_type":"markdown","source":"Let's look at this image. It has no atmospheric condition listed."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e587f9b3-affa-3db1-5623-908440dab8e7","_uuid":"6fed9aba247c6ca779828559d0f7655ba70d30a7"},"cell_type":"code","source":"imageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_24448.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 24448.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"d19aacc4-b487-5133-e1d5-00f730c1b370","_uuid":"6f72bc55c43cee358ffa19bdef945a2c3f023eed"},"cell_type":"code","source":"# A comparison water image with haze to see if there is haze.\nimageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_3561.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 3561 - water under haze conditions.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"6c4596ac-bbb4-1f1f-97ff-4af6f35fddfb","_uuid":"7a6b0b5638ae8dc60280fdb171bd31785604b574"},"cell_type":"code","source":"# A comparison water image without haze.\nimageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_2750.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 2750 - water under clear conditions.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bdd22557-d6e4-2180-9d4f-37c74ee499e4","_uuid":"5f2161179d1d604eb1c6950c281966d02f02c6f9"},"cell_type":"markdown","source":"Our image seems to be under clear conditions. I will fix that in the dataset. Alternately, one could remove this image from the training set altogether."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"9c2cded8-5398-ad6e-415c-06c33478fc0c","_uuid":"bc0d87c0d1c79900fcf49144c2c371d3d7074e78"},"cell_type":"code","source":"Labels.loc[24448, 'clear'] = 1\nLabels.loc[24448, 'tags'] = 'clear water'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7ca991d9-8637-1e46-6267-8ccb1791a472","_uuid":"13cf716ab98a082e58bb040a49e0eb3095ad7371"},"cell_type":"markdown","source":"Cloudy images should not have any other tags. We will check this."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"4f0703bd-43bc-4e28-cffc-e0857964cf7f","_uuid":"a05d42084959c0131ed240ebd17168b1748e8260"},"cell_type":"code","source":"# I will use an isin trick to not have to list all of the encoded tags.\nLabels[(Labels[Labels.columns[\n    Labels.columns.isin(tagnames)]].sum(axis=1) > 1) & (Labels['cloudy'] == 1)]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"486cfa13-e146-81bc-4db4-d7526530178d","_uuid":"87d7918eb70381b5ba015b9e7f456ee9a2d6d1a9"},"cell_type":"markdown","source":"Let's also check to see if any images have only one tag that is not cloudy."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"ace4e10e-9ee8-72e4-7669-d507ea848abe","_uuid":"1e3944bf5e7dab3d1b8a71cbe3cebecbbfa6ddb3"},"cell_type":"code","source":"Labels[(Labels[Labels.columns[\n    Labels.columns.isin(tagnames)]].sum(axis=1) == 1) & (Labels['cloudy'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e7189aff-4ee2-7149-c891-a9afa75726c8","_uuid":"16b8c0ed02ef203293a0a245918ad511b74f308d"},"cell_type":"markdown","source":"Let's look at this image."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"3064ece7-12cb-1f1c-88eb-7e5180e9dde9","_uuid":"517432c8c1c64b1d2265d479b44e47a16a3305a1"},"cell_type":"code","source":"imageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_21276.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 21276.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d86d6fd9-7892-58dc-5c77-8d02ce642643","_uuid":"0800173cbada9c2234cc619a29f3b32d443b569a"},"cell_type":"markdown","source":"That looks like primary. Let's add that tag."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"a15efeaf-b5ce-4cc4-5bb3-ba12195b19ae","_uuid":"c42750069ebb0a83c165468de18db18d90745d09"},"cell_type":"code","source":"Labels.loc[21276, 'primary'] = 1\nLabels.loc[21276, 'tags'] = 'partly_cloudy primary'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1db45bbf-baa6-5d8a-f760-add44cfe97fd","_uuid":"8641c9d9e1dfa5803568cd0adfcbf1b58f11a326"},"cell_type":"markdown","source":"We will now explore the label distributions."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"cf667f69-10b5-6531-0d0b-dba373744be7","_uuid":"cc19d4d5c2ac725f3460e834b55cd5518c8d8924"},"cell_type":"code","source":"ConditionCounts = Labels[['clear', 'haze', 'partly_cloudy', 'cloudy']].sum().sort_values(\n    ascending=False)\nConditionCounts = ConditionCounts.reset_index(name='Count')\nfig = sns.barplot(x='index', y='Count', data=ConditionCounts)\nfig.set(xlabel='Condition Type', ylabel='Count', title='Images by Condition')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"9f11eb3e-789f-2d8f-93ab-931c0943f461","_uuid":"7dbace54276d12d04077f2fd679bae7a85e2afa9"},"cell_type":"code","source":"typeTags = ['artisinal_mine', 'blow_down', 'water', 'cultivation', 'road', 'agriculture',\n            'bare_ground', 'blooming', 'selective_logging', 'habitation', 'conventional_mine',\n            'slash_burn', 'primary']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"3e1351c2-cbc5-12e1-59ea-125cf25d79bb","_uuid":"7e9db0eda21516796b19d6f3277543147c2d9e19"},"cell_type":"code","source":"TypeCounts = Labels[Labels.columns[Labels.columns.isin(typeTags)]].sum().sort_values(\n    ascending=False)\nTypeCounts = TypeCounts.reset_index(name='Count')\nfig = plt.figure(figsize=(12, 4))\nfig = sns.barplot(x='index', y='Count', data=TypeCounts)\nfig.set(xlabel='Type', ylabel='Count', title='Images by Type')\n# Rotate the tick-labels\nfor ticklabel in fig.get_xticklabels():\n    ticklabel.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"be3e0271-89ff-b54c-cda6-a4a36d8d139f","_uuid":"8abe4a56420e97411d9708ab7fdabfee55b8e398"},"cell_type":"code","source":"# Focusing on the rare types:\nRareTypeCounts = Labels[['artisinal_mine', 'blow_down', 'bare_ground', 'blooming',\n                         'selective_logging', 'conventional_mine',\n                         'slash_burn']].sum().sort_values(ascending=False)\nRareTypeCounts = RareTypeCounts.reset_index(name='Count')\nfig = plt.figure(figsize=(8, 4))\nfig = sns.barplot(x='index', y='Count', data=RareTypeCounts)\nfig.set(xlabel='Type', ylabel='Count', title='Images by Less Common Types')\n# Rotate the tick-labels\nfor ticklabel in fig.get_xticklabels():\n    ticklabel.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b0fda39c-42df-4218-6436-b67294a35159","_uuid":"9bcbb167cfdab08675f283ead1d750a9b28e9143"},"cell_type":"markdown","source":"Now we explore what image types we have in each of the atmospheric conditions (excluding cloudy)."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"4ceab78a-9ad9-a709-1dc6-59f81eaaf343","_uuid":"4334a45f64ab48149cc2e11e318ef379ce25ab08"},"cell_type":"code","source":"for condition in ['clear', 'haze', 'partly_cloudy']:\n    _ConditionalTypeCounts = Labels[Labels.columns[\n        Labels.columns.isin(typeTags)]][Labels[condition] == 1].sum().sort_values(\n        ascending=False)\n    _ConditionalTypeCounts = _ConditionalTypeCounts.reset_index(name='Count')\n    fig = plt.figure(figsize=(12, 4))\n    fig = sns.barplot(x='index', y='Count', data=_ConditionalTypeCounts)\n    fig.set(xlabel='Type', ylabel='Count',\n            title='Images by Type for Condition %s' % condition)\n    # Rotate the tick-labels\n    for ticklabel in fig.get_xticklabels():\n        ticklabel.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dd0a5b84-4986-d607-24e9-4c76f8565467","_uuid":"5abb3126be4178514e72a1852baaccd875976f4c"},"cell_type":"markdown","source":"They look like similar distributions. That is a good sign. Haze does have noticeably damped cultivation, agriculture, and road frequencies. This may be due to the difficulty of spotting these features in hazy images."},{"metadata":{"_cell_guid":"05b086ef-0d66-8da4-c39e-17c3a324693d","_uuid":"1d1497beca9b73f303f83e4f8d7e0d3fb1cd5caa"},"cell_type":"markdown","source":"## Image Loading\nLet's first visualize some randomly chosen images."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"425c7a07-dac9-caaf-dda4-d846a2dbf283","_uuid":"c4f2a9bfca63d1b1f13d4b9b72638ba93aee9acd"},"cell_type":"code","source":"def plot_image(tifImage, jpgImage, tag, imgNum):\n    imageplot = plt.figure(figsize=(10, 6))\n    # Plot Red Band\n    axis1 = imageplot.add_axes([0, .5, .2, .4])\n    axis1.imshow(tifImage[:, :, 2], cmap='Reds')\n    axis1.set_title('Red')\n    # Plot Green Band\n    axis2 = imageplot.add_axes([.25, .5, .2, .4])\n    axis2.imshow(tifImage[:, :, 1], cmap='Greens')\n    axis2.set_title('Green')\n    # Plot Blue Band\n    axis3 = imageplot.add_axes([.5, .5, .2, .4])\n    axis3.imshow(tifImage[:, :, 0], cmap='Blues')\n    axis3.set_title('Blue')\n    # Plot NIR Band\n    axis4 = imageplot.add_axes([.75, .5, .2, .4])\n    axis4.imshow(tifImage[:, :, 3], cmap='magma')\n    axis4.set_title('NIR')\n    # Plot image\n    axis5 = imageplot.add_axes([0, 0, .2, .4])\n    axis5.imshow(cv2.cvtColor(jpgImage, cv2.COLOR_BGR2RGB))\n    axis5.set_title('JPG Image')\n    # Plot color histogram\n    axis6 = imageplot.add_axes([.3, .05, .5, .3])\n    axis6.hist([tifImage[:, :, 2], tifImage[:, :, 1], tifImage[:, :, 0], tifImage[:, :, 3]],\n               bins=100, label=['r', 'g', 'b', 'nir'],\n               color=['red', 'green', 'blue', 'magenta'], histtype='step')\n    axis6.legend()\n    axis6.set_title('Color Histogram')\n    imageplot.suptitle('Image Number: %s. Tags: %s.' % (imgNum, tag))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"51fd020a-a258-bdd3-1d3f-18a9be3fe9cf","_uuid":"a34f5b826b9668af5e80b19a2175e3e68b537248"},"cell_type":"code","source":"image_sample = Labels.sample(6)\nfor img in image_sample.index:\n    tag = image_sample.loc[img]['tags']\n    tifImage = load_image(image_sample.loc[img]['tifFilename'])\n    jpgImage = cv2.imread(image_sample.loc[img]['jpgFilename'])\n    plot_image(tifImage, jpgImage, tag, img)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bbe93e8a-a3c1-46e0-7f17-3a5b20f9a068","_uuid":"832c4d6915e1bfd1f844fd749b080aa31f00d743"},"cell_type":"markdown","source":"## Finding Mistagged Images\nNow we will attempt to find mistagged images. The main technique is to investigate the distributions of numerical measures on the bands for each type of tag."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"266f7c60-b6b2-95ba-a560-ae911e421be4","_uuid":"0b3433cfb0de10047fab2ce434452d904c986ee6"},"cell_type":"code","source":"def get_band_information(image):\n    \"\"\"Given a single color band of an image, returns the following tuple:\n    (band_mean, band_median, band_std, band_max, band_min, band_kurtosis, band_skewness)\n    \"\"\"\n    band = image[:, :].ravel()\n    return (np.mean(band), np.median(band), np.std(band), np.max(band), np.min(band),\n            stats.kurtosis(band), stats.skew(band))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e3cbd40f-3e53-93c1-211b-2f8944970b91","_uuid":"9ca7134edc89cccdaf93e4e9365075edef713cbe"},"cell_type":"code","source":"# We will use ColorStats as an array to hold our color information and later join it to the data frame.\nn, _ = Labels.shape\nColorStats = np.zeros((n, 28))\nfor ind in Labels.index:\n    imageName = Labels['tifFilename'].loc[ind]\n    current_image = load_image(imageName)\n    r_stats = get_band_information(current_image[:, :, 2])\n    g_stats = get_band_information(current_image[:, :, 1])\n    b_stats = get_band_information(current_image[:, :, 0])\n    n_stats = get_band_information(current_image[:, :, 3])\n    ColorStats[ind, :7] = list(r_stats)  # columns 0-6 are for red\n    ColorStats[ind, 7:14] = list(g_stats)  # columns 7-13 are for green\n    ColorStats[ind, 14:21] = list(b_stats)  # columns 14-20 are for blue\n    ColorStats[ind, 21:] = list(n_stats)  # columns 21-27 are for near-ir\n    if ind % 5000 == 0:\n        print('Processed %s images.' % ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"d7bda6af-9990-b6ba-ce80-0c1dd4260eac","_uuid":"d7cf305cb9b46ff181523270ae6c920f352d009a"},"cell_type":"code","source":"names = []\nfor color in ['r', 'g', 'b', 'n']:\n    for stat in ['mean', 'median', 'std', 'max', 'min', 'kurtosis', 'skewness']:\n        names.append(color + '_' + stat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"6b25ff17-a085-fe42-bb5d-2703c7c7801a","_uuid":"3492711a5f509f6bd3d6741faf7376cbd171702f"},"cell_type":"code","source":"ColorStatsDF = pd.DataFrame(ColorStats, columns=names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"a67ece6e-6f25-7264-f81d-e0786ae0298f","_uuid":"2c941948f0d4084919294d2aab9e256abe634148"},"cell_type":"code","source":"ColorStatsDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"8cab323a-ce90-65de-fcc9-339645ec1866","_uuid":"9d1029177564b725fffc31f1dd07df024388a24e"},"cell_type":"code","source":"Labels = pd.concat([Labels, ColorStatsDF], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"3d6624ab-8bef-706f-2c66-567a9b97f247","_uuid":"6fc0ee57efd8fb650f8a0149ccb4401b99262c14"},"cell_type":"code","source":"Labels.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8f8a94c9-06c8-02ab-4b54-ab89787a1f30","_uuid":"619d482107ad535e627509e171014629a07a81b1"},"cell_type":"markdown","source":"This would be a good time to save the data frame for future use.\n\nWe will now use the band statistics to try to find mistagged images."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e08d2d13-f8ad-c685-5e83-b947be14da55","_uuid":"ccd2ee0eab502ee4a07f332c112aa15c6211f943"},"cell_type":"code","source":"sns.distplot(Labels[Labels['cloudy'] == 1]['b_std'], kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"17862b21-01a1-fa26-7bd5-1b73eae4b7cf","_uuid":"b6cc66d59e10e95ae767d9964791bde6df96b120"},"cell_type":"code","source":"sns.boxplot(Labels[Labels['cloudy']==1]['b_std'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f9f5143e-95df-8469-699b-9ca997810ba1","_uuid":"cc5d7b712cfaf83f999105fabc60b0e7e76075d3"},"cell_type":"markdown","source":"Let's visually inspect the high blue-band standard deviation cloudy images."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"77e61b4e-ef76-5609-d5d7-fef92dec72c3","_uuid":"f0373b5dc559cbe90b350cb662fd7c3f6c89ef96"},"cell_type":"code","source":"Labels[(Labels['cloudy'] == 1) & (Labels['b_std'] > 8000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"f62d6cf8-ad31-3a1c-b324-7b2acb3bbf1d","_uuid":"e910c8aeb59c67218ff205dd02bc0997becf087e"},"cell_type":"code","source":"plot_image(\n    io.imread(Labels['tifFilename'].loc[352]), \n    cv2.imread(Labels['jpgFilename'].loc[352]), \n    Labels['tags'].loc[352], 352)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"74ad4540-9c04-e009-efc3-9a3600181546","_uuid":"344a3950bc1aa4910361186fcf800b42d39a3733"},"cell_type":"markdown","source":"Let's get a close up of the jpg."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"35042d72-e3d3-a886-d8fa-d911f5d931b7","_uuid":"02ffd6da6823036ad2fb67b3c1a72ca30c7951d4"},"cell_type":"code","source":"cv2imageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_352.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 352.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a458b07f-dba7-fc0b-5cdc-e5d758535e5e","_uuid":"1ee41c52a8d229d1338387f6c3acd9eda3f522bd"},"cell_type":"markdown","source":"That looks be primary or bare-ground underneath. You could use NDVI to confirm this. For example below is partly cloudy with primary. However, it does seem to be more than 90% cloudy. We will keep it as cloudy."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"d3078047-5c39-c753-9cc5-7c80b7115572","_uuid":"1f7a1aee15e79cca3dffd36758255cb47b66b7ae"},"cell_type":"code","source":"plot_image(io.imread(Labels['tifFilename'].loc[22748]), \n           cv2.imread(Labels['jpgFilename'].loc[22748]), \n           Labels['tags'].loc[22748], 22748)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"7f22f87f-e6a6-5ffe-e223-e8461978f4b5","_uuid":"a949421a9ca754877368eaf668e1a75268a8ec6d"},"cell_type":"code","source":"imageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_22748.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 22748.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"6f53ae65-d42c-8c0c-cc9a-4f491773493c","_uuid":"0ac59e2f967e21bac5ae3b8a7b1acd3519f276ae"},"cell_type":"code","source":"plot_image(io.imread(Labels['tifFilename'].loc[2550]), \n           cv2.imread(Labels['jpgFilename'].loc[2550]), \n           Labels['tags'].loc[2550], 2550)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"c59c4efc-4006-09f2-bfd4-c7b733fdec30","_uuid":"0c3923f36bf36f534540aaa22a188425f99e29a9"},"cell_type":"code","source":"imageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_2550.jpg')\naxis.imshow(cv2.cvtColor(_image, cv2.COLOR_BGR2RGB))\nimageplot.suptitle('Image Number: 2550.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"edd42792-69d8-6702-953d-e138cd1ada4f","_uuid":"036745073011af982d96d1a370c9bb5ddf8413d1"},"cell_type":"markdown","source":"This does have enough ground underneath to be partly cloudy. The ground seems to be primary."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"44906103-afb9-22e7-4cd2-533f1bc7ad5b","_uuid":"eaf53805769d01ed18bb293488ab5b894e88d6fe"},"cell_type":"code","source":"# Fix the miss labelling\nLabels.loc[2550, 'cloudy'] = 0\nLabels.loc[2550, 'partly_cloudy'] = 1\nLabels.loc[2550, 'primary'] = 1\nLabels.loc[2550, 'tags'] = 'partly_cloudy primary'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8113f374-62ab-67a2-2529-e277ac6454d1","_uuid":"f2423ca4bf5ca834cded7607c8c18628f8d04f23"},"cell_type":"markdown","source":"Let's try another example using near-ir."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"b9ff27ef-b84c-c5db-dc96-a19dfb6f91bc","_uuid":"6b0d8e734c5b90bd1d7fe9a7f98cfbe9d4c13111"},"cell_type":"code","source":"sns.distplot(Labels[Labels['partly_cloudy'] == 1]['n_min'], kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"071fe0c8-3168-ae62-5fe2-f40ab5e978e8","_uuid":"7dd76b3ab163d01c3e35589d1daca27d24d05eed"},"cell_type":"code","source":"sns.boxplot(Labels[Labels['partly_cloudy'] == 1]['n_min'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"2db10b15-cd45-bd54-a4d7-e5b6967bbbbd","_uuid":"7566abe28216747adc5366a8e65ee52fa350811e"},"cell_type":"code","source":"Labels[(Labels['partly_cloudy'] == 1) & (Labels['n_min'] > 14000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"1cb646dd-a6ab-050c-3cdf-b9041a0b55d0","_uuid":"1f00b4eaec921419ad2741762d5aca944fc4ae4e"},"cell_type":"code","source":"plot_image(io.imread(Labels['tifFilename'].loc[35252]), \n           cv2.imread(Labels['jpgFilename'].loc[35252]), \n           Labels['tags'].loc[35252], 35252)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"22cff40d-6918-fd15-9720-f305b99f0e12","_uuid":"78855a67b7775ed1cc15c2096537950db7a1d58a"},"cell_type":"code","source":"imageplot = plt.figure(figsize=(6, 6))\naxis = imageplot.add_axes([0, 0, .9, .9])\n_image = cv2.imread('../input/train-jpg/train_35252.jpg')\naxis.imshow(_image[:, :, 0], cmap = 'Reds')\nimageplot.suptitle('Image Number: 35252.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"2372ee2f-c211-27f3-1028-e3dc202c283f","_uuid":"780d44e42a8cc4230ede9776ab8f0af45f5fa754"},"cell_type":"code","source":"# Make sure this is not an issue in the data frame\nLabels[['tifFilename', 'jpgFilename']].loc[35252]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7eafc85f-a0b3-f3e1-eeb7-3d741738874c","_uuid":"5870159b8b387e7400799e5b57b30f706a9b062d"},"cell_type":"markdown","source":"This seems to be an issue where the jpeg and tiff images are not in agreement (which has been noted by others).\n\nLet's look at the color band distributions for images just tagged 'primary' and 'clear'."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"f221a1ce-2e52-96cd-e74c-70add7e18a2e","_uuid":"63365c7d8bc86539bd64118c848bdd3b12db10ff"},"cell_type":"code","source":"# Create a list of statistics that we can log transform. We will not log transform skew or kurtosis.\nlognames = []\nfor color in ['r', 'g', 'b', 'n']:\n    for stat in ['mean', 'median', 'std', 'max', 'min']:\n        lognames.append(color + '_' + stat)\n\n\n# Helper functions for investigating band statistics.\ndef plot_band_stats(DataFrame, name='Unknown'):\n    \"\"\"Given a DataFrame as a data frame of Labels, will plot all band statistics for that data frame.\n\n    Parameters\n        DataFrame: The data frame of Labels to plot\n        name: Name for the statistics.\n\n    Example\n    plot_band_stats(Labels['primary'], 'primary') will plot all band statistics for images\n    that are tagged 'primary'\n    \"\"\"\n    for stat in names:\n        fig = plt.figure(figsize=(9, 4))\n        histogram = plt.subplot(2, 1, 1)\n        sns.distplot(DataFrame[stat], kde=False, bins=100)\n        boxplot = plt.subplot(2, 1, 2)\n        sns.boxplot(DataFrame[stat])\n        plt.suptitle(stat + ' for: ' + name)\n\n\ndef plot_logband_stats(DataFrame, name='Unknown'):\n    \"\"\"Given a DataFrame as a data frame of Labels, will plot logged band statistics for that data frame.\n    Note: skewness and kurotosis are not plotted.\n\n    Parameters\n        DataFrame: The data frame of Labels to plot\n        name: Name for the statistics.\n\n    Example\n    plot_band_stats(Labels['primary'], 'primary') will plot all logged band statistics for images\n    that are tagged 'primary'\n    \"\"\"\n    for stat in lognames:\n        fig = plt.figure(figsize=(9, 4))\n        histogram = plt.subplot(2, 1, 1)\n        sns.distplot(np.log(1 + DataFrame[stat]), kde=False, bins=100)\n        boxplot = plt.subplot(2, 1, 2)\n        sns.boxplot(np.log(1 + DataFrame[stat]))\n        plt.suptitle('logged ' + stat + ' for: ' + name)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b0dce73-03b3-75c8-4ad1-e26b14fbfc49","_uuid":"502592bb33024264d42bab48cdd956ea942d7bcc"},"cell_type":"markdown","source":"We will now investigate 'primary' and 'clear' images."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"8009257a-2838-376d-1445-df5515e335b1","_uuid":"f910e3f49d6d28cf49e4b4f24fc4e79268a7c54b"},"cell_type":"code","source":"ClearPrimary = Labels[Labels['tags'] == 'clear primary']\nplot_band_stats(ClearPrimary, name='clear primary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"b7c29b2a-558f-d734-610d-7c0c0b5030dc","_uuid":"bda7406c530ec7b3a4dc48bb8597764c36ba6a01"},"cell_type":"code","source":"# You can also investigate logged statistics as follows, but the kernel is running out of memory.\n# plot_logband_stats(ClearPrimary, name='clear primary')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c3a2885c-0f55-f2cd-395c-53b9df4bf308","_uuid":"7f8ee3385d6375124de5f53e4a0ce001afdb5fd2"},"cell_type":"markdown","source":"For now, we will finish by considering n_max. Let's pull every image 3*IQR past Q1 and Q3."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"0a7ba160-d544-32f5-2b51-500270bc3323","_uuid":"29178b4680ed1d90688199ba75b8c85483bda938"},"cell_type":"code","source":"IQR = stats.iqr(ClearPrimary['n_max'])\nLower = np.percentile(ClearPrimary['n_max'], 25) - 3*IQR\nUpper = np.percentile(ClearPrimary['n_max'], 75) + 3*IQR","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"bb4c3937-4050-3cc1-14f4-c6e4a4e492b1","_uuid":"1ac4c97c4afadfdaf9beb4a23db4da6a47298e6c"},"cell_type":"code","source":"Candidates = ClearPrimary[(ClearPrimary['n_max'] < Lower) | (ClearPrimary['n_max'] > Upper)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e702d83f-767d-d9a6-ef19-f82e88aedd2d","_uuid":"93e9db7f09c85941bce6e1cb8b00f2d3d2c34194"},"cell_type":"code","source":"Candidates.shape # 70 images found.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4bbe5941-6555-43ed-e2cb-091070782c38","_uuid":"5c057ecf81bd75737dda2c8de543775035f7ab2a"},"cell_type":"markdown","source":"Due to kernel memory, I will skip displaying each image from this data frame. I will just display images I found with issues."},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"ebe51b73-96bf-8592-7211-b682a3be61a1","_uuid":"b44c7f1d0ec0fab50250877537f5059f11ca3b14"},"cell_type":"code","source":"for img in [221, 1270, 1652, 3518, 4639, 7112, 12645, 14687, 23638, 28381, 34729, 4978, 25513]:\n    tag = Candidates.loc[img]['tags']\n    tifImage = load_image(Candidates.loc[img]['tifFilename'])\n    jpgImage = cv2.imread(Candidates.loc[img]['jpgFilename'])\n    plot_image(tifImage, jpgImage, tag, img)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a1e48ccf-f40d-e779-36ed-d20a64441933","_uuid":"36c17c2b1632c20a0de392eefa52a66d79c2647c"},"cell_type":"markdown","source":"From the list of images above:\n\n - Images 221, 1270, 1652, 3518, 4639, 7112, 12645, 14687, 23638, 28381, and 34729 have NIR resolution issues.\n - Images 4978 and 25513 have different tiff vs. jpegs"},{"metadata":{"_cell_guid":"82ac8b77-b510-a568-cac9-0ffdf8715124","_uuid":"991536db9cdf80ad3cc4fb610465509b3c7c3beb"},"cell_type":"markdown","source":"## Final thoughts\nAs promised, there is noise in the data, but I was impressed by how few mistagged images I found in this precursory glance. It may be worth visually inspecting each outlier (I suggest 3 times IQR past the quartiles), dropping the outliers, or just using the jpeg version of the outliers.\n\nUpdate:  After visually inspecting major outliers (8 IQR from the first and third quartiles), the proportion of clearly mistagged images is under 1%."}],"metadata":{"_is_fork":false,"_change_revision":0,"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","version":"3.6.1","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":1}