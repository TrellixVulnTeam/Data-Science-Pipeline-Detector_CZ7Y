{"cells":[{"metadata":{},"cell_type":"markdown","source":"# transposing a mnist script \n\nsome experiments with image transformations\nand some tests with classifications\nyou should attain approx 98%"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\ndf_train = pd.read_csv(os.path.join(dirname, 'train.csv'))\ntrain_y = df_train['label'].reset_index()\ntrain_x = df_train.drop(['label'], axis=1)\ntest_x = pd.read_csv(os.path.join(dirname, 'test.csv'))\ntest_x=test_x.drop(['id'],axis=1)\n\nprint(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\ntotal=train_x.append(test_x)\ntotal=total.values.reshape(-1,28,28)\nprint(total.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# loading image\n#img0 = cv2.imread('SanFrancisco.jpg',)\nimg0 = train_x.iloc[8].values.reshape(28,28)\nimg = np.array(img0 ,dtype=np.uint8)\n\n# converting to gray scale\ngray = img0\n# remove noise\n#img = cv2.GaussianBlur(gray,(3,3),0)\n\n# convolute with proper kernels\nlaplacian = cv2.Laplacian(img,cv2.CV_64F)\nsobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\nsobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n\nplt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\nplt.title('Original'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\nplt.title('Laplacian'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\nplt.title('Sobel X'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\nplt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import ndimage\ndef moments(image):\n    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n    totalImage = np.sum(image) #sum of pixels\n    m0 = np.sum(c0*image)/totalImage #mu_x\n    m1 = np.sum(c1*image)/totalImage #mu_y\n    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n    return mu_vector, covariance_matrix\n\ndef deskew(image):\n    c,v = moments(image)\n    alpha = v[0,1]/v[0,0]\n    affine = np.array([[1,0],[alpha,1]])\n    ocenter = np.array(image.shape)/2.0\n    offset = c-np.dot(affine,ocenter)\n    img=ndimage.interpolation.affine_transform(image,affine,offset=offset)\n    return (img - img.min()) / (img.max() - img.min())*255\n\ntrainx=train_x.values.reshape(-1,28,28)\nfor xi in range(len(train_x)):\n    #print(train[xi])\n    trainx[xi]= deskew(trainx[xi]) \n\nfrom PIL import Image\nimgP=Image.fromarray(img, mode='L')\nimgP.show()\nimgP.thumbnail((14,14), resample=3)\nImage.frombuffer('L', (14,14), imgP.tobytes(), 'raw', 'L', 0, 1) #.thumbnail(14, resample=3)\n#np.str(imgP.tobytes()).split('\\\\x')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom numpy import *\n\ndef pca(X):\n  \"\"\"  Principal Component Analysis\n    input: X, matrix with training data stored as flattened arrays in rows\n    return: projection matrix (with important dimensions first), variance\n    and mean.\"\"\"\n\n  # get dimensions\n  num_data,dim = X.shape\n\n  # center data\n  mean_X = X.mean(axis=0)\n  X = X - mean_X\n\n  if dim>num_data:\n    # PCA - compact trick used\n    M = dot(X,X.T) # covariance matrix\n    e,EV = linalg.eigh(M) # eigenvalues and eigenvectors\n    tmp = dot(X.T,EV).T # this is the compact trick\n    V = tmp[::-1] # reverse since last eigenvectors are the ones we want\n    S = sqrt(e)[::-1] # reverse since eigenvalues are in increasing order\n    for i in range(V.shape[1]):\n      V[:,i] /= S\n  else:\n    # PCA - SVD used\n    print('svd')\n    U,S,V = linalg.svd(X,full_matrices=False)\n    #V = V[:num_data] # only makes sense to return the first num_data\n\n  # return the projection matrix, the variance and the mean\n  return U,V,S,mean_X\n\nfrom PIL import Image\nfrom numpy import *\nfrom pylab import *\n#import pca\n\nim = train_x.iloc[8].values.reshape(28,28) #array(Image.open(imlist[0])) # open one image to get size\nm,n = im.shape[0:2] # get the size of the images\nimnbr = 10 #len(imlist) # get the number of images\n\n# create matrix to store all flattened images\nimmatrix = trainx[:42000].reshape(42000,-1) #SkelTR.reshape(42000,-1) #  #array([array(Image.open(im)).flatten()\n           #   for im in imlist],'f')\n\n# perform PCA\nU,V,S,immean = pca(immatrix)\n\n# show some images (mean and 7 first modes)\nfigure()\ngray()\nsubplot(5,4,1)\nimshow(immean.reshape(m,n))\nfor i in range(19):\n    subplot(5,4,i+1)\n    #print(U[i].shape,V.shape,S.shape,np.dot(U[i],V.T/S).shape)\n    imshow(np.dot(U[:,:100][i]*S[:100],V[:100,:]).reshape(m,n) )\n\nshow()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA, FastICA\npca = PCA(n_components=100)\nTRANS = pca.inverse_transform(pca.fit_transform(immatrix))\n#ica = FastICA(random_state=42)\n#TRANS = ica.fit_transform(train_x.values.reshape(-1,28*28))  # Estimate the sources\n\n# show some images (mean and 7 first modes)\nfigure()\ngray()\nsubplot(5,4,1)\n\nfor i in range(19):\n    subplot(5,4,i+1)\n    #print(U[i].shape,V.shape,S.shape,np.dot(U[i],V.T/S).shape)\n    imshow(TRANS[i].reshape(28,28) )\n\nshow()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA, FastICA,NMF\n#nmf = NMF()\n#TRANS = nmf.inverse_transform(nmf.fit_transform(immatrix[:1000]))\nica = FastICA(n_components=50,random_state=42)\nTRANS = ica.inverse_transform(ica.fit_transform(train_x.values.reshape(-1,28*28)) )  # Estimate the sources\n\n# show some images (mean and 7 first modes)\nfigure()\ngray()\nsubplot(5,4,1)\n\nfor i in range(19):\n    subplot(5,4,i+1)\n    #print(U[i].shape,V.shape,S.shape,np.dot(U[i],V.T/S).shape)\n    imshow(TRANS[i].reshape(28,28) )\n\nshow()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVDTR=np.dot(U*S,V)# ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# skeletonizing all the letters\nsearching the skelet, makes it worse"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import skeletonize\nfrom skimage import data\nimport matplotlib.pyplot as plt\nfrom skimage.util import invert\n\n# Invert the horse image\nimage = np.array(train_x.iloc[14].values.reshape(28,28)  ,dtype=np.uint8)>mean(train_x.iloc[14])\n\n# perform skeletonization\nskeleton = skeletonize(image)\n\n# display results\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4),\n                         sharex=True, sharey=True)\n\nax = axes.ravel()\n\nax[0].imshow(image, cmap=plt.cm.gray)\nax[0].axis('off')\nax[0].set_title('original', fontsize=20)\n\nax[1].imshow(skeleton, cmap=plt.cm.gray)\nax[1].axis('off')\nax[1].set_title('skeleton', fontsize=20)\n\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import skeletonize\nfrom tqdm import tqdm_notebook\n\nSkelTR=np.asarray([])\nfor yi in range(21):\n    Lapl=np.asarray([])\n    for xi in tqdm_notebook(range(2000)):\n        gray = np.array(train_x.iloc[yi*2000+xi].values.reshape(28,28)  ,dtype=np.uint8)>mean(train_x.iloc[yi*2000+xi])\n        # remove noise\n        #img = cv2.GaussianBlur(gray,(3,3),0)\n        img=gray\n        # convolute with proper kernels\n        skelet = skeletonize(img)\n        Lapl=np.append(Lapl,skelet.reshape(-1,1))\n    SkelTR=np.append(SkelTR,Lapl)\nprint(SkelTR.reshape(-1,28,28).shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# laplace transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\nLapTR=np.asarray([])\nfor yi in range(21):\n    Lapl=np.asarray([])\n    for xi in tqdm_notebook(range(2000)):\n        gray = np.array(train_x.iloc[yi*2000+xi].values.reshape(28,28)  ,dtype=np.uint8)\n        # remove noise\n        #img = cv2.GaussianBlur(gray,(3,3),0)\n        img=gray\n        # convolute with proper kernels\n        laplacian = cv2.Laplacian(img,cv2.CV_64F)\n        Lapl=np.append(Lapl,laplacian.reshape(-1,1))\n    LapTR=np.append(LapTR,Lapl)\nprint(LapTR.reshape(-1,28,28).shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# classification code"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\nclass classGS():  \n    # fit should give a pandas database X and a pandas y\n    # define 'veld' as the labelfield and add the name in the y data\n    # define 'index' as an index field and add the name in the y data\n    #defining constructor  \n    def __init__(self, clf=[KNeighborsClassifier(10)],thres=0.1,probtrigger=False,ncomp=5,neighU=5,ncompU=5,midiU=0.3,veld='label',idvld='index',lentrain=30000):  \n        self.clf2=clf\n        self.thres=thres\n        self.probtrigger=probtrigger\n        self.ncomp=ncomp\n        self.neighU=neighU\n        self.ncompU=ncompU\n        self.midiU=midiU\n        self.lentrain=lentrain\n        self.veld=veld\n        self.idvld=idvld\n        \n    def get_params(self, deep=True):\n        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n        return {\"clf\":self.clf2,'thres':self.thres,'probtrigger':self.probtrigger,'ncomp':self.ncomp,'neighU':self.neighU,'ncompU':self.ncompU,'midiU':self.midiU,'lentrain':self.lentrain}\n\n    def set_params(self, **parameters):\n        for parameter, value in parameters.items():\n            setattr(self, parameter, value)\n        return self\n    \n    def fit(self, e__,mtrain_):\n        from umap import UMAP\n        from sklearn.decomposition import PCA\n        from sklearn import preprocessing\n        min_max_scaler = preprocessing.MinMaxScaler() #.RobustScaler() #\n\n\n        #klasseerGS(e_,mtrain,mtest,veld,idvld,thres,probtrigger,ncomp,neighU,ncompU,midiU):\n        mtest=pd.DataFrame( e__[self.lentrain:].index,columns=[self.idvld] )\n        mtest[self.veld]=mtrain_[self.lentrain:][self.veld]\n        label = mtrain_[:self.lentrain][self.veld]\n        print('1:',e__.shape,mtrain_.shape,label.shape,self.lentrain,e__[self.lentrain:].shape)        \n        e__ = min_max_scaler.fit_transform(e__)\n        e__ = sigmoid(e__) \n        \n        e__ = PCA(n_components=self.ncomp).fit_transform(e__)\n        e__ = UMAP(n_neighbors=self.neighU,n_components=self.ncompU, min_dist=self.midiU,metric='minkowski').fit_transform(e__)\n        self.e__=e__\n        \n        pd.DataFrame(e__[:self.lentrain]).plot(x=0,y=1,c=mtrain_[:self.lentrain][self.veld]+1,kind='scatter',title='classesplot',colormap ='jet')\n        pd.DataFrame(e__).plot.scatter(x=0,y=1,c=['r' for x in range(self.lentrain)] +['g' for x in range(len(e__[self.lentrain:]))])   \n        print('Model with threshold',self.thres/1000,mtrain_[:self.lentrain].shape,e__.shape,self.ncomp,self.neighU,self.ncompU,self.midiU,)\n    \n        for clf2 in self.clf2:\n            #train\n            fit=clf2.fit(e__[:self.lentrain],label)\n            print(fit)\n\n            #if clf.__class__.__name__=='DecisionTreeClassifier':\n                #treeprint(clf)\n            pred=fit.predict(e__)\n            #Model.append(self.clf2.__class__.__name__)\n            #Accuracy.append(accuracy_score(mtrain[:self.lentrain][self.veld],pred))\n            #predict\n            print('3:',self.idvld,self.veld,len(mtest))\n            self.sub = pd.DataFrame({self.idvld: mtest[self.idvld],self.veld: pred[-len(mtest):]})\n            self.sub.plot(x=self.idvld,kind='kde',title=clf2.__class__.__name__ +str(( mtrain_[:self.lentrain][self.veld]==pred[:self.lentrain]).mean()) +'prcnt') \n            sub2=pd.DataFrame(pred,columns=[self.veld])\n\n            #estimate sample if  accuracy\n            if self.veld in mtest.columns:\n                print( clf2.__class__.__name__ +str(round( accuracy_score(mtrain_[:self.lentrain][self.veld],pred[:self.lentrain]),2)*100 )+'prcnt accuracy versus unknown',(mtrain_[self.lentrain:][self.veld]==pred[self.lentrain:]).mean() )\n                from sklearn.metrics import confusion_matrix\n                print(confusion_matrix(mtrain_[self.lentrain:][self.veld],pred[self.lentrain:]))\n                #write results\n            if self.probtrigger:\n                pred_prob=fit.predict_proba(e__[-len(mtest):])\n                sub=pd.DataFrame(pred_prob)        \n        #defining class methods  \n            self.f1score=((mtrain_[self.veld]==pred[:len(mtrain_)]).mean())\n            self.treshold_=pred\n\n            print(self.sub.shape)\n        return self\n        \n    def _meaning(self, _e1):\n        # returns True/False according to fitted classifier\n        # notice underscore on the beginning\n        print('meaning')\n        return( True if _e1 >= self.treshold_ else True )\n\n    def predict(self, e__, mtrain_):\n        try:\n            getattr(self, \"treshold_\")\n        except AttributeError:\n            raise RuntimeError(\"You must train classifer before predicting data!\")\n        print('predict',e__.shape,mtrain_.shape)\n        return([True for _e1 in e__])\n\n    def score(self, e__, mtrain_):\n        # counts number of values bigger than mean\n        print('score',self.e__.shape,mtrain_.shape,self.f1score)\n        return(self.f1score) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVD denoised classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"cGS=classGS(ncomp=30,midiU=0.1,ncompU=7,neighU=5,lentrain=30000)\nresult=cGS.fit(pd.DataFrame(SVDTR[:40000]),train_y[:40000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# original data cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"LapTR=LapTR.reshape(-1,784)\ncGS=classGS(ncomp=30,midiU=0.1,ncompU=7,neighU=5,lentrain=30000)\nresult=cGS.fit(pd.DataFrame(train_x[:40000]),train_y[:40000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA transformed data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cGS=classGS(ncomp=30,midiU=0.1,ncompU=7,neighU=5,lentrain=30000)\nresult=cGS.fit(pd.DataFrame(TRANS[:40000]),train_y[:40000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Laplace + SVD + original data"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x.shape,LapTR.reshape(42000,-1).shape)\nmtotal=np.concatenate( (SVDTR, LapTR.reshape(42000,-1),trainx[:42000].reshape(42000,28*28)), axis=1)\nmtotal.shape\ncGS=classGS(ncomp=30,midiU=0.1,ncompU=7,neighU=5,lentrain=30000)\nresult=cGS.fit(pd.DataFrame(mtotal[:40000]),train_y[:40000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# try a mnist resize"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom numpy import *\nfrom pylab import *\n\n#trainx=pd.DataFrame(trainx.reshape(60000,-1))\nsubplot(1,3,1)\nfor ii in range(3):\n    subplot(1,3,ii+1)\n    print( train_x.iloc[ii].mean(),train_x.iloc[ii].median() ,train_x.iloc[ii][:3])\n    marr=train_x.iloc[ii].values.reshape(28,28) #-train_x.iloc[ii].median()\n    img2 = Image.fromarray(np.uint8(marr)) #-train_x.iloc[i].median())\n    imgres = img2.resize((7,28), Image.ANTIALIAS)\n    img3=np.array(imgres.getdata(),np.uint8).reshape(imgres.size[1], imgres.size[0])\n    print(img3)\n    imshow(img3)\n    #img2 = img2.resize( (28, 28), Image.ANTIALIAS)\n    #img2.show()\n\nxtrain1=[]\nfor ii in tqdm_notebook(range(len(train_x))):\n    marr=train_x.iloc[ii].values.reshape(28,28) #-train_x.iloc[ii].median()\n    img2 = Image.fromarray(np.uint8(marr)) #-train_x.iloc[i].median())\n    imgres = img2.resize((7,28), Image.ANTIALIAS)\n    #img3=np.array(imgres.getdata(),np.uint8) #.reshape(imgres.size[1], imgres.size[0])\n    xtrain1.append(np.array(imgres.getdata(),np.uint8).reshape(-1,1) )\n    \nxtrain1=np.reshape(xtrain1, (-1, 7*28))\n\nxtrain2=[]\nfor ii in tqdm_notebook(range(len(train_x))):\n    marr=train_x.iloc[ii].values.reshape(28,28) #-train_x.iloc[ii].median()\n    img2 = Image.fromarray(np.uint8(marr)) #-train_x.iloc[i].median())\n    imgres = img2.resize((28,7), Image.ANTIALIAS)\n    #img3=np.array(imgres.getdata(),np.uint8).reshape(imgres.size[1], imgres.size[0])\n    xtrain2.append(np.array(imgres.getdata(),np.uint8).reshape(-1,1) )\n\n    \nxtrain2=np.reshape(xtrain2, (-1, 7*28))\n\nxtrain3=[]\nfor ii in tqdm_notebook(range(len(train_x))):\n    marr=train_x.iloc[ii].values.reshape(28,28) #-train_x.iloc[ii].median()\n    img2 = Image.fromarray(np.uint8(marr)) #)\n    imgres = img2.resize((14,14), Image.ANTIALIAS)\n    #img3=np.array(imgres.getdata(),np.uint8).reshape(imgres.size[1], imgres.size[0])\n    xtrain3.append(np.array(imgres.getdata(),np.uint8).reshape(-1,1) )\n\n    \nxtrain3=np.reshape(xtrain3, (-1,14*14))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nmtotal=np.concatenate( (train_x,xtrain1,xtrain2,xtrain3), axis=1)\nmtotal.shape\n\nif True: #for nco in range(5,10):\n    cGS=classGS(clf=[KNeighborsClassifier(10)],ncomp=60,midiU=0.1,ncompU=8,neighU=8,lentrain=30000)  #OneVsRestClassifier(SVC(kernel='linear', probability=True)),\n    result=cGS.fit(pd.DataFrame(mtotal[:40000]),train_y[:40000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse.linalg import svds\nfrom scipy.sparse import coo_matrix\nfrom scipy  import sparse\n\nimg=train_x.iloc[1].astype('float32').values.reshape(28,28) #-train_x.iloc[1].median()\nimg=sparse.csr_matrix(img)\n\nprint(min(img.shape))\nnco = 3\nu, s, v = svds(img, k=nco)\n#X = np.dot(u*s,v)\nprint(u.shape,s.shape,v.shape)\ns=s/s.max()\nus=np.concatenate((u,s.reshape(1,-1)),0)\nvs=np.concatenate((v,s.reshape(-1,1)),1)\nprint(us.shape,vs.shape)\nuv=np.concatenate((us,vs.T),1)\nplt.imshow(uv,cmap = 'gray')\nplt.show()\n\n\ntrainsv=[]\nfor xi in tqdm_notebook(range(len(train_x)) ):\n    img=train_x.iloc[xi].astype('float32').values.reshape(28,28) #-train_x.iloc[1].median()\n    img=sparse.csr_matrix(img)\n    u, s, v = svds(img, k=nco)    \n    us=np.concatenate((u,s.reshape(1,-1)),0)\n    vs=np.concatenate((v,s.reshape(-1,1)),1)\n\n    uv=np.concatenate((us,vs.T),1)\n    trainsv.append(uv)\n\ntrainsv=np.reshape(trainsv, (-1, 28*nco*2+nco*2)) \nprint(trainsv.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if True: #for nco in range(5,10):\n    cGS=classGS(clf=[KNeighborsClassifier(10)],ncomp=60,midiU=0.1,ncompU=8,neighU=8,lentrain=30000)  #OneVsRestClassifier(SVC(kernel='linear', probability=True)),\n    result=cGS.fit(pd.DataFrame(trainsv[:40000]),train_y[:40000])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}