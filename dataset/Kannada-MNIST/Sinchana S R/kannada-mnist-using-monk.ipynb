{"cells":[{"metadata":{},"cell_type":"markdown","source":"Kannada (/ˈkɑːnədə, ˈkæn-/; ಕನ್ನಡ, [ˈkɐnnɐɖaː]; lesser known as Kanarese) is a Dravidian language spoken predominantly by people of Karnataka in Southwestern India and by linguistic minorities in the states of Maharashtra, Andhra Pradesh, Tamil Nadu, Telangana, Kerala and Goa and also by Carnatican expats abroad. The language has roughly 44 million native speakers, who are called Kannadigas. Kannada is also spoken as a second and third language by over 12.9 million non-Kannada speakers in Karnataka, which adds up to 56 million speakers. It is one of the scheduled languages of India and the official and administrative language of the state of Karnataka. Kannada was the court language of some of the most powerful empires of South and Central India, such as the Chalukya dynasty, the Rashtrakuta dynasty, the Vijayanagara Empire and the Hoysala Empire.\n\nSource: https://en.wikipedia.org/wiki/Kannada","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Kannada Numbers](https://2.bp.blogspot.com/-e13ee8EcKxU/Wl7dQ32q44I/AAAAAAAAAB4/um6EcQ9gq0YL9un_WWQNpw_d_uTvrDpBgCLcBGAs/s1600/numbers-kannada1.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn3.vectorstock.com/i/1000x1000/98/02/set-of-monochrome-icons-with-kannada-numbers-vector-15469802.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"monk\"> [MONK](https://github.com/Tessellate-Imaging/monk_v1) </div>\n\nMonk is a low code Deep Learning tool and a unified wrapper for Computer Vision.\n\nMonk Features\n\n* low-code\n* unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n* syntax invariant wrapper\n\nMonk Enables\n\n* To create, manage and version control deep learning experiments.\n* To compare experiments across training metrics.\n* To quickly find best hyper-parameters.\n\nGoals\n\n* To experiment with Models\n* Understand how easy is it to use Monk","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Table of Contents","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* [MONK](#monk)\n* [Converting the given dataset into the required format](#pp)\n* [Installing Monk](#im)\n* [Importing pytorch backend](#pb)\n* [Creating and managing experiments](#cm)\n* [List of models-See what other models Monk's backend supports](#lm)\n* [Quick Mode Training - Load the data and the model](#ldm)\n* [Train the classifier](#tc)\n* [Running inference on test images](#rit)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"pp\"> Converting the given dataset into the required format </div>","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/Kannada-MNIST/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=train.drop('label',axis=1)\nY_train=train.label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.drop('id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train/255\ntest=test/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.values.reshape((-1,28,28,1))\ntest=test.values.reshape((-1,28,28,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of rows in X_train\nX_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(X_train[0][:,:,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[0][:,:,0])\nplt.title(Y_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[1][:,:,0])\nplt.title(Y_train[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! mkdir trainIm testIm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = X_train[0][:,:,0].astype(np.uint8)\nprint(array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting the pixel values given into images and storing them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lengthX_train = X_train.shape[0]\nfor i in range(lengthX_train):\n    array = X_train[i][:,:,0].astype(np.uint8)\n    img = Image.fromarray(array)\n    img = img.convert(\"L\")\n    fn = \"/kaggle/working/trainIm/TrainImg{}.png\".format(i)\n    img.save(fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lengthtest = test.shape[0]\nfor i in range(lengthtest):\n    array = test[i][:,:,0].astype(np.uint8)\n    img = Image.fromarray(array)\n    img = img.convert(\"L\")\n    fn = \"/kaggle/working/testIm/TestImg{}.png\".format(i)\n    img.save(fn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a CSV file that contains the labels of the training images**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label = pd.DataFrame(columns = ['image_id_path', 'Label']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index,row in Y_train.iteritems():\n    #print(row)\n    #print(index)\n    pathname = \"TrainImg{}.png\".format(index)\n    train_label.loc[index,'image_id_path']=pathname\n    train_label.loc[index,'Label']=row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label.to_csv(\"train.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pwd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"im\"> [Installing Monk](https://github.com/Tessellate-Imaging/monk_v1/tree/master/installation) </div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* git clone https://github.com/Tessellate-Imaging/monk_v1.git\n\n* cd monk_v1/installation/Linux && pip install -r requirements_cu9.txt\n\n(Select the requirements file as per OS and CUDA version)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/Tessellate-Imaging/monk_v1.git","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* If using Colab install using the commands below\n\n!cd monk_v1/installation/Misc && pip install -r requirements_colab.txt\n\n* If using Kaggle uncomment the following command\n\n!cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt\n\n\n* Select the requirements file as per OS and CUDA version when using a local system or cloud\n\n!cd monk_v1/installation/Linux && pip install -r requirements_cu9.txt","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install pillow==5.4.1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Monk\nimport os\nimport sys\nsys.path.append(\"monk_v1/monk/\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"pb\"> Importing pytorch backend </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using pytorch backend \nfrom pytorch_prototype import prototype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* To use mxnet backend\n\nfrom gluon_prototype import prototype\n\n* To use keras backend\n\nfrom keras_prototype import prototype","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"cm\"> Creating and managing experiments </div>\n\n* Provide project name\n* Provide experiment name\n* For a specific data create a single project\n* Inside each project multiple experiments can be created\n* Every experiment can be have diferent hyper-parameters attached to it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = prototype(verbose=1);\ngtf.Prototype(\"Kannada-MNIST\", \"Using_Pytorch_Backend\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This creates files and directories as per the following structure\nworkspace\n\n|\n|--------Kannada-MNIST (Project name can be different)\n\n                |\n                |\n                |-----Using_Pytorch_Backend (Experiment name can be different)\n                            |\n                            |-----experiment-state.json\n                            |\n                            |-----output\n                                    |\n                                    |------logs (All training logs and graphs saved here)\n                                    |\n                                    |------models (all trained models saved here)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"lm\"> List of models </div>\n\nSee what other models Monk's backend supports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.List_Models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"ldm\"> Load the data and the model </div>\n\nDocs on quick mode loading of data and model: https://github.com/Tessellate-Imaging/monk_v1#4\n\nTutorials on Monk: https://github.com/Tessellate-Imaging/monk_v1/tree/master/study_roadmaps/1_getting_started_roadmap\n\n# Quick mode training\n\n* Using Default Function\n* dataset_path\n* model_name\n* num_epochs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Default(dataset_path=\"/kaggle/working/trainIm/\",\n            path_to_csv=\"/kaggle/working/train.csv\", # updated csv file \n            model_name=\"resnet50\", \n            freeze_base_network=False,\n            num_epochs=20); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"tc\"> Train the classifier </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Start Training\ngtf.Train();\n#Read the training summary generated once you run the cell and training is completed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"rit\"> Running inference on test images </div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Load the experiment in inference mode\n\n* Set flag eval_infer as True","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = prototype(verbose=0);\ngtf.Prototype(\"Kannada-MNIST\", \"Using_Pytorch_Backend\", eval_infer=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Select image and Run inference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = \"/kaggle/working/testIm/TestImg0.png\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name,width=200,height=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook as tqdm\nfrom scipy.special import softmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = \"/kaggle/working/testIm/TestImg1.png\";\npredictions = gtf.Infer(img_name=img_name);\nprint(predictions)\nprint(predictions['predicted_class'])\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name,width=200,height=300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Running Inference on all test images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm(range(len(sample_submission))):\n    img_name = \"/kaggle/working/testIm/TestImg{}.png\".format(i)\n    \n    #Invoking Monk's nferencing engine inside a loop\n    predictions = gtf.Infer(img_name=img_name, return_raw=True);\n    x = predictions['predicted_class']\n    sample_submission[\"id\"][i] = i;\n    sample_submission[\"label\"][i] = x;\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! rm -r monk_v1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! rm -r workspace","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check out\n\n* [Monk_Object_Detection](https://github.com/Tessellate-Imaging/Monk_Object_Detection)\n\nA one-stop repository for low-code easily-installable object detection pipelines.\n\n\n* [Monk_Gui](https://github.com/Tessellate-Imaging/Monk_Gui)\n\nA Graphical user Interface for deep learning and computer vision over Monk Libraries\n\n\n* [Pytorch_Tutorial](https://github.com/Tessellate-Imaging/Pytorch_Tutorial)\n\nA set of jupyter notebooks on pytorch functions with examples","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}