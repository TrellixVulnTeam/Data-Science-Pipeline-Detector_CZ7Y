{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T03:00:12.278968Z","iopub.execute_input":"2022-01-21T03:00:12.279704Z","iopub.status.idle":"2022-01-21T03:00:12.293033Z","shell.execute_reply.started":"2022-01-21T03:00:12.27966Z","shell.execute_reply":"2022-01-21T03:00:12.292165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dig = pd.read_csv(r'/kaggle/input/Kannada-MNIST/Dig-MNIST.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:15.911626Z","iopub.execute_input":"2022-01-21T03:00:15.912207Z","iopub.status.idle":"2022-01-21T03:00:16.52403Z","shell.execute_reply.started":"2022-01-21T03:00:15.912168Z","shell.execute_reply":"2022-01-21T03:00:16.523269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport random\nimport torchvision.datasets\nimport torchvision.transforms\nimport torchvision.transforms.functional\nimport matplotlib.pyplot as plt\nimport copy\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:20.321951Z","iopub.execute_input":"2022-01-21T03:00:20.322542Z","iopub.status.idle":"2022-01-21T03:00:20.327692Z","shell.execute_reply.started":"2022-01-21T03:00:20.32249Z","shell.execute_reply":"2022-01-21T03:00:20.326978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:23.220573Z","iopub.execute_input":"2022-01-21T03:00:23.220835Z","iopub.status.idle":"2022-01-21T03:00:23.227923Z","shell.execute_reply.started":"2022-01-21T03:00:23.220805Z","shell.execute_reply":"2022-01-21T03:00:23.226993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=116\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\n\n#to reproduce same result over and over\n#also we lose some performance in gpu if it set to true\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:25.122666Z","iopub.execute_input":"2022-01-21T03:00:25.123002Z","iopub.status.idle":"2022-01-21T03:00:25.128287Z","shell.execute_reply.started":"2022-01-21T03:00:25.122927Z","shell.execute_reply":"2022-01-21T03:00:25.127396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r'/kaggle/input/Kannada-MNIST/train.csv')\ndf = pd.concat([dig,df],axis=0)\ndf_train = df.iloc[:,:]\ndf_val = df.iloc[40000:,:]","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:27.811425Z","iopub.execute_input":"2022-01-21T03:00:27.811998Z","iopub.status.idle":"2022-01-21T03:00:31.868245Z","shell.execute_reply.started":"2022-01-21T03:00:27.811959Z","shell.execute_reply":"2022-01-21T03:00:31.867403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_train, inputs_train = df_train.iloc[:,0].values,df_train.iloc[:,1:].values\nlabels_val, inputs_val = df_val.iloc[:,0].values,df_val.iloc[:,1:].values","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:35.425258Z","iopub.execute_input":"2022-01-21T03:00:35.425763Z","iopub.status.idle":"2022-01-21T03:00:35.440438Z","shell.execute_reply.started":"2022-01-21T03:00:35.425718Z","shell.execute_reply":"2022-01-21T03:00:35.439636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(torch.nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = torch.nn.Conv2d(1, 64, 3, padding=1)\n        self.conv2 = torch.nn.Conv2d(64, 64, 3, padding=1)\n        self.conv3 = torch.nn.Conv2d(64, 128, 3, padding=0)\n        self.conv4 = torch.nn.Conv2d(128, 256, 3, padding=0)\n        self.conv5 = torch.nn.Conv2d(256, 128, 3, padding=1)\n        self.conv6 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.relu = torch.nn.LeakyReLU()\n        self.avgpool1 = torch.nn.AvgPool2d(kernel_size=(5, 5))\n        self.fc1 = torch.nn.Linear(128, 10)\n        self.maxpool1 = torch.nn.MaxPool2d(2, 2)\n        self.maxpool2 = torch.nn.MaxPool2d(2, 2)\n        self.dropout = torch.nn.Dropout(0.22)\n        # an affine operation: y = Wx + b\n        #self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n        #self.fc2 = torch.nn.Linear(120, 84)\n        #self.fc3 = torch.nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n        \n        x = self.conv3(x)\n        x = self.relu(x)\n        x = self.conv4(x)\n        x = self.relu(x)\n        x = self.maxpool2(x)\n        \n        x = self.conv5(x)\n        x = self.relu(x)\n        x = self.conv6(x)\n        x = self.relu(x)\n        x = self.avgpool1(x)\n        x = x.reshape(x.shape[0], x.shape[1])\n        x = self.fc1(x)\n    \n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:38.091841Z","iopub.execute_input":"2022-01-21T03:00:38.0921Z","iopub.status.idle":"2022-01-21T03:00:38.105741Z","shell.execute_reply.started":"2022-01-21T03:00:38.092069Z","shell.execute_reply":"2022-01-21T03:00:38.105004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def acc_n_loss_func(preds, labels):\n    f = torch.nn.CrossEntropyLoss()\n  \n    loss = f(preds, labels)\n    accuracy = (preds.argmax(dim=1) == labels).float().mean()\n    return accuracy, loss","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:40.393545Z","iopub.execute_input":"2022-01-21T03:00:40.39397Z","iopub.status.idle":"2022-01-21T03:00:40.399154Z","shell.execute_reply.started":"2022-01-21T03:00:40.393932Z","shell.execute_reply":"2022-01-21T03:00:40.39809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, accnlossfunc, optimizer, scheduler, num_epochs):\n    try:\n        best_model_wts = copy.deepcopy(model.state_dict())\n        best_acc = 0.0\n        \n        val_accuracy_history = []\n        val_loss_history = []\n        \n        for epoch in range(num_epochs):\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    dataloader = zip(inputs_train.reshape(-1,7840),labels_train.reshape(-1,10))\n                    count_n = len(inputs_train.reshape(-1,7840))\n                    model.train()  # Set model to training mode\n                else:\n                    dataloader = zip(inputs_val.reshape(-1,7840),labels_val.reshape(-1,10))\n                    count_n = len(inputs_val.reshape(-1,7840))\n                    model.eval()   # Set model to evaluate mode\n                running_loss = 0.\n                running_acc = 0\n                # Iterate over data.\n                for i, (inputs, labels) in enumerate(dataloader):\n                    \n                    inputs = torch.tensor(inputs.reshape(10,1,28,28)).to(device)\n                    labels = torch.tensor(labels).type(torch.LongTensor).to(device)\n                    labels = labels.flatten()\n                    optimizer.zero_grad()\n                    # forward and backward\n                    with torch.set_grad_enabled(phase == 'train'):\n                        \n                        \n                        preds = model(inputs.float())\n                        \n                  \n           \n                        acc, loss_value = accnlossfunc(preds, labels)\n                   \n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss_value.backward()\n                            optimizer.step() \n                            scheduler.step()\n\n                    # statistics\n                    running_loss += loss_value.item()\n                    running_acc += acc.item()\n                    print(\"epoch: {}/{} nested {}/{} {}  - loss: {:.4f} - acc: {:.4f}\".format(epoch+1, num_epochs, (i+1), \n                                                            count_n, phase, running_loss/(i+1), running_acc/(i+1)), end='\\r')\n                epoch_loss = running_loss / count_n\n                epoch_acc = running_acc / count_n\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                    val_loss_history.append(epoch_loss)\n                    val_accuracy_history.append(epoch_acc)\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n    except (KeyboardInterrupt or RuntimeError) as e:\n        model.load_state_dict(best_model_wts)\n        print(f\"Returning model saved with best accuracy:{best_acc}\")\n        return model, val_loss_history, val_accuracy_history\n        \n    model.load_state_dict(best_model_wts)\n    print(f\"Returning model saved with best accuracy:{best_acc}\")\n    return model, val_loss_history, val_accuracy_history","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:42.109395Z","iopub.execute_input":"2022-01-21T03:00:42.109673Z","iopub.status.idle":"2022-01-21T03:00:42.126795Z","shell.execute_reply.started":"2022-01-21T03:00:42.10964Z","shell.execute_reply":"2022-01-21T03:00:42.126003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = MNISTnet(n_hidden_neurons=64)\nmodel = Net()\nmodel = model.to(device)\nloss = acc_n_loss_func\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n# Decay LR by a factor of 0.1 every 88 epochs\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2240, gamma=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:45.961036Z","iopub.execute_input":"2022-01-21T03:00:45.961639Z","iopub.status.idle":"2022-01-21T03:00:45.98099Z","shell.execute_reply.started":"2022-01-21T03:00:45.9616Z","shell.execute_reply":"2022-01-21T03:00:45.980288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, val_loss_history, val_accuracy_history = train_model(model, loss, optimizer, scheduler, num_epochs=6)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T03:00:47.791663Z","iopub.execute_input":"2022-01-21T03:00:47.792098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv = pd.read_csv(r'/kaggle/input/Kannada-MNIST/test.csv').iloc[:,1:]\n\ntest_data = torch.zeros([len(test_csv),1,28,28])\n\nfor i in range(len(test_csv)):\n    test_data[i,0] = (torch.tensor(test_csv.iloc[i, :]).reshape(28, 28))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T02:59:16.655476Z","iopub.execute_input":"2022-01-21T02:59:16.655789Z","iopub.status.idle":"2022-01-21T02:59:32.901181Z","shell.execute_reply.started":"2022-01-21T02:59:16.655757Z","shell.execute_reply":"2022-01-21T02:59:32.900406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model(test_data[:100].to(device))\nlabels = test_preds.argmax(dim=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T12:57:47.272245Z","iopub.execute_input":"2022-01-20T12:57:47.272501Z","iopub.status.idle":"2022-01-20T12:57:47.282005Z","shell.execute_reply.started":"2022-01-20T12:57:47.27247Z","shell.execute_reply":"2022-01-20T12:57:47.281278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 1000\nresult = torch.zeros(len(test_data)).to(device)\n\nfor index in range(0, len(test_data), batch_size):\n    test_preds = model(test_data[index:index+batch_size].to(device))\n    result[index:index+batch_size] = test_preds.argmax(dim=1)\nresult = result.type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T12:57:47.283653Z","iopub.execute_input":"2022-01-20T12:57:47.283884Z","iopub.status.idle":"2022-01-20T12:57:47.452945Z","shell.execute_reply.started":"2022-01-20T12:57:47.283853Z","shell.execute_reply":"2022-01-20T12:57:47.452174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(r'/kaggle/input/Kannada-MNIST/sample_submission.csv')\nsubmission['label'] = result.data.cpu()\n\nsubmission.to_csv(r'/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:11:21.799743Z","iopub.execute_input":"2022-01-20T13:11:21.800338Z","iopub.status.idle":"2022-01-20T13:11:21.882601Z","shell.execute_reply.started":"2022-01-20T13:11:21.800249Z","shell.execute_reply":"2022-01-20T13:11:21.881805Z"},"trusted":true},"execution_count":null,"outputs":[]}]}