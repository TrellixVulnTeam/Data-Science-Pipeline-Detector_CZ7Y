{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.shape,test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.columns, test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['label'],axis=1)\ny = train['label']\ndisplay(X.head(),y.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.utils import to_categorical\n# num_classes = len(set(y))\n# y = to_categorical(y, num_classes=num_classes)\n# y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test.loc[:,'id']\ntest = test.iloc[:, 1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X).reshape(len(X),28,28)\ny = np.array(y)\ntest = np.array(test).reshape(len(test),28,28)\ndisplay(X.shape,test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X[24])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure()\nfor i in range(9):\n  plt.subplot(3,3,i+1)\n  plt.tight_layout()\n  plt.imshow(X[i], cmap='gray', interpolation='none')\n  plt.title(\"Digit: {}\".format(y[i]))\n  plt.xticks([])\n  plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.applications.vgg16 import VGG16\n# from keras.applications.resnet import ResNet50\n# model = ResNet50(include_top=False, input_shape=(300, 300, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image augumantation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Image augumantation\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def train_mnist():\n\n\n# #     class myCallback(tf.keras.callbacks.Callback):\n# #         def on_epoch_end(self,epoch,logs={}):\n# #             if(logs.get('acc')>0.999) and (logs.get('val_acc')>0.999):\n# #                 print(\"\\nReached 99.9% accuracy so cancelling training!\")\n# #                 self.model.stop_training = True    \n# #     callbacks = myCallback()\n\n#     callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\n#     X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=0,test_size=0.2,shuffle=True)\n#     X_val, X_test, y_val, y_test = train_test_split(X_val,y_val,random_state=0,test_size=0.5,shuffle=True)\n\n#     X_train, X_val = (X_train / 255.0).reshape(len(X_train),28,28,1), (X_val / 255.0).reshape(len(X_val),28,28,1)\n\n\n#     datagen.fit(X_train)\n    \n#     model = tf.keras.models.Sequential([\n\n#         tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n# #         tf.keras.layers.BatchNormalization(),\n#         tf.keras.layers.MaxPooling2D(2, 2),\n#         tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n# #         tf.keras.layers.BatchNormalization(),\n#         tf.keras.layers.MaxPooling2D(2,2),\n        \n#         tf.keras.layers.Flatten(),\n#         tf.keras.layers.Dense(1024, activation='relu'),\n#         tf.keras.layers.Dropout(rate=0.5),\n#         tf.keras.layers.Dense(1024, activation='relu'),\n#         tf.keras.layers.Dropout(rate=0.5),\n#         tf.keras.layers.Dense(10, activation='softmax')\n\n#     ])\n\n#     #optimizer = tf.keras.optimizers.Adam(lr=0.001)\n#     optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9,decay=1e-6)\n#     model.compile(optimizer=optimizer,\n#                   loss='sparse_categorical_crossentropy',\n#                   metrics=['accuracy'])\n    \n#     batch_size = 32\n#     history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n#                               validation_data = (X_val,y_val), \n#                               epochs=100,\n#                               steps_per_epoch=X_train.shape[0] // batch_size,\n#                               callbacks=[callback])\n\n#     return history, model, X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_mnist():\n\n\n#     class myCallback(tf.keras.callbacks.Callback):\n#         def on_epoch_end(self,epoch,logs={}):\n#             if(logs.get('acc')>0.999) and (logs.get('val_acc')>0.999):\n#                 print(\"\\nReached 99.9% accuracy so cancelling training!\")\n#                 self.model.stop_training = True    \n#     callbacks = myCallback()\n\n    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\n    X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=0,test_size=0.2,shuffle=True)\n    X_val, X_test, y_val, y_test = train_test_split(X_val,y_val,random_state=0,test_size=0.5,shuffle=True)\n\n    X_train, X_val = (X_train / 255.0).reshape(len(X_train),28,28,1), (X_val / 255.0).reshape(len(X_val),28,28,1)\n\n\n    datagen.fit(X_train)\n    \n    model = tf.keras.models.Sequential([\n\n        tf.keras.layers.Conv2D(64, (3,3), input_shape=(28, 28, 1)),\n#         tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Conv2D(64, (3,3)),\n#         tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        tf.keras.layers.MaxPooling2D(2,2),\n        \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(1024),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        tf.keras.layers.Dropout(rate=0.5),\n        tf.keras.layers.Dense(1024),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        tf.keras.layers.Dropout(rate=0.5),\n        tf.keras.layers.Dense(10, activation='softmax')\n\n    ])\n\n    #optimizer = tf.keras.optimizers.Adam(lr=0.001)\n    optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9,decay=1e-6)\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    batch_size = 32\n    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              validation_data = (X_val,y_val), \n                              epochs=60,\n                              steps_per_epoch=X_train.shape[0] // batch_size,\n                              callbacks=[callback])\n\n    return history, model, X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def train_mnist():\n    \n#     callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\n#     X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=0,test_size=0.2,shuffle=True)\n#     X_val, X_test, y_val, y_test = train_test_split(X_val,y_val,random_state=0,test_size=0.5,shuffle=True)\n#     X_train, X_val = (X_train / 255.0).reshape(len(X_train),28,28,1), (X_val / 255.0).reshape(len(X_val),28,28,1)\n\n#     datagen.fit(X_train)\n    \n#     model = tf.keras.models.Sequential([\n        \n#         tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n#         tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n#         tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n#         tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n\n#         tf.keras.layers.MaxPooling2D(2, 2),\n#         tf.keras.layers.Dropout(0.2),\n    \n#         tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n#         tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n#         tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n#         tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n    \n#         tf.keras.layers.MaxPooling2D(2,2),\n#         tf.keras.layers.Dropout(0.2),    \n    \n#         tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n#         tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n#         tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n#         tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    \n#         tf.keras.layers.MaxPooling2D(2,2),\n#         tf.keras.layers.Dropout(0.2),\n    \n    \n#         tf.keras.layers.Flatten(),\n#         tf.keras.layers.Dense(256),\n#         tf.keras.layers.LeakyReLU(alpha=0.1),\n\n#         tf.keras.layers.BatchNormalization(),\n#         tf.keras.layers.Dense(10, activation='softmax')\n    \n        \n#     ])\n    \n    \n#     optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9,decay=1e-6)\n#     model.compile(optimizer=optimizer,\n#                   loss='sparse_categorical_crossentropy',\n#                   metrics=['accuracy'])\n    \n#     batch_size = 32\n#     history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n#                               validation_data = (X_val,y_val), \n#                               epochs=1,\n#                               steps_per_epoch=X_train.shape[0] // batch_size,\n#                               callbacks=[callback])\n\n#     return history, model, X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history, model, X_test, y_test = train_mnist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.DataFrame(history.history).plot(figsize=(8, 5))\n# plt.grid(True)\n# plt.gca().set_ylim(0.75, 1.) # set the vertical range\n# plt.show()\n\n# pd.DataFrame(history.history).plot(figsize=(8, 5))\n# plt.grid(True)\n# plt.gca().set_ylim(0.0, 0.4) # set the vertical range\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = (X_test / 255.0).reshape(len(X_test),28,28,1)\ntest = (test / 255.0).reshape(len(test),28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(X_test,y_test)\nprint(f\"Accuracy: {acc}\")\nprint(f\"Loss: {loss}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred = model.predict_classes(X_test)\nCM = confusion_matrix(y_test, y_pred)\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(test)\ndisplay(predictions,len(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'id': test_id,\n                   'Label': predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}