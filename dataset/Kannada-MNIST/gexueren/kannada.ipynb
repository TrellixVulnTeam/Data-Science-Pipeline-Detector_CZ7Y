{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\n#28,28\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3),  # 16, 26 ,26\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True))\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=3),  # 32, 24, 24\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2))  # 32, 12,12     (24-2) /2 +1\n\n        self.dropout = nn.Dropout(p=0.4)  # dropout训练\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3),  # 64,10,10\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True))\n        \n        self.layer4 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3),  # 128,8,8\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2))  # 128, 4,4\n\n        self.fc = nn.Sequential(\n            nn.Linear(128 * 4 * 4, 1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024, 128),\n            nn.ReLU(inplace=True),\n            nn.Linear(128, 10))\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.dropout(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n    \nmodel = CNN()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.utils.data\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nimport numpy as np\n\nclass MyDataset(torch.utils.data.Dataset):\n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform=transforms.Compose([\n                            transforms.ToPILImage(),\n                           # Add random transformations to the image.\n                           transforms.RandomAffine(\n                               degrees=20,\n                               translate=(0.1, 0.2),\n                               shear=(-10, 20, -10, 20),\n                               scale=(0.60, 1.25)),\n\n                           transforms.ToTensor()\n                       ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\ntrain_data = MyDataset('/kaggle/input/Kannada-MNIST/train.csv', transform=transform)\ntrain_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\nval_data = MyDataset('/kaggle/input/Kannada-MNIST/test.csv', transform=transform)\nval_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_num = 20\naccuracy = []\nlosses = []\nfor epoch in range(epoch_num):\n    train_correct = 0\n    running_loss = 0\n    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n        var_X_batch = Variable(X_batch).float()\n        var_y_batch = Variable(y_batch)\n        optimizer.zero_grad()\n        \n        output = model(var_X_batch)\n        loss = criterion(output, var_y_batch)\n        running_loss += loss.item()\n        \n        predicted = torch.max(output.data, 1)[1]\n        train_correct += (predicted == var_y_batch).sum()\n        batch_accuracy = float(train_correct*100) / float(batch_size*(batch_idx+1)) # in all trained data calculate the accracy\n        accuracy.append(batch_accuracy)\n\n        if batch_idx % 50 == 0:\n            print('Epoch : {} [{}/{}]  Loss:{:.6f}  Accuracy:{:.2f}%'.format(\n                epoch,\n                batch_idx*len(X_batch), # how much data has been trained\n                len(train_loader.dataset),\n                loss.item(),\n                batch_accuracy))\n        loss.backward()\n        optimizer.step()\n        \n    losses.append(running_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss_accuracy(loss, accuracy):\n    fid = plt.figure(figsize=(20,5))\n\n    Axes = plt.subplot(121, title=\"loss\")\n    Axes.axes.tick_params(which='both',direction='in',top=True, right=True)\n    plt.minorticks_on()\n    Axes.set_facecolor((0,0,0,0.02))\n    # draw the line\n    loss_X = np.arange(0,len(loss))\n    plt.plot(loss_X, loss, 'k-', linewidth=3, color = 'r', label='loss')\n    plt.grid(True,which='major',linewidth=0.5)\n    plt.grid(True,which='minor',linewidth=0.1)\n    plt.xlabel(\"epoch number\")\n    plt.ylabel(\"loss\")\n    plt.legend(loc='best',fontsize='x-small')\n\n    Axes = plt.subplot(122, title=\"accuracy\")\n    Axes.axes.tick_params(which='both',direction='in',top=True, right=True)\n    plt.minorticks_on()\n    Axes.set_facecolor((0,0,0,0.02))\n    # draw the line\n    accuracy_X = np.arange(0,len(accuracy))\n    plt.plot(accuracy_X, accuracy, 'k-', linewidth=3, color = 'b', label='accuracy')\n    plt.grid(True,which='major',linewidth=0.5)\n    plt.grid(True,which='minor',linewidth=0.1)\n    plt.xlabel(\"epoch number\")\n    plt.ylabel(\"accuracy\")\n    plt.legend(loc='best',fontsize='x-small')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss_accuracy(losses, accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = []\ndata_submission = pd.read_csv(\"/kaggle/input/Kannada-MNIST/sample_submission.csv\")\nfor idx, (test_data, y_label) in enumerate(val_loader):\n    var_test_data = Variable(test_data).float()\n    output = model(var_test_data)\n    prediction.append(torch.max(output.data, 1)[1].numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = []\nfor i in prediction:\n    for j in i:\n        res.append(j)\ndata_submission['label'] = res\ndata_submission.to_csv('./submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}