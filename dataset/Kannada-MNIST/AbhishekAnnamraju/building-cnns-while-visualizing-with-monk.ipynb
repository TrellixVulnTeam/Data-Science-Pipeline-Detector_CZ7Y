{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Monk Library - https://github.com/Tessellate-Imaging/monk_v1\n\n## Monk is an opensource low-code tool for computer vision and deep learning\n\nMonk features\n\n    low-code\n    unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n    syntax invariant wrapper\n\nEnables\n  - to create, manage and version control deep learning experiments\n  - to compare experiments across training metrics\n  - to quickly find best hyper-parameters\n\nAt present it only supports transfer learning, but we are working each day to incorporate\n  - GUI based custom model creation\n  - various object detection and segmentation algorithms\n  - deployment pipelines to cloud and local platforms\n  - acceleration libraries such as TensorRT\n  - preprocessing and post processing libraries\n    \n    \n### Feature showcase\n  - Custom Model Creation with Monk in Gluon Backend (Soon will be released for pytorch and keras backends too)\n\n\nTo contribute to Monk AI or Pytorch RoadMap repository raise an issue in the git-repo or dm us on linkedin\n  - Abhishek - https://www.linkedin.com/in/abhishek-kumar-annamraju/\n  - Akash - https://www.linkedin.com/in/akashdeepsingh01/\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since Monk supports Image as inputs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Convert CSV data to images\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\nfrom tqdm import tqdm_notebook as tqdm\n\nos.mkdir(\"images\");\nos.mkdir(\"images/train\");\nos.mkdir(\"images/test\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training data\ndv = pd.read_csv(\"/kaggle/input/Kannada-MNIST/train.csv\");\nfor i in tqdm(range(60000)):\n    x = dv.iloc[i].to_numpy();\n    label = str(x[0])\n    img = x[1:]\n    img = np.reshape(img, (28, 28));\n    img = np.expand_dims(img, axis=0);\n    img = np.vstack((img, img, img))\n    img = np.swapaxes(img, 0, 1);\n    img = np.swapaxes(img, 1, 2);\n    if(not os.path.isdir(\"images/train/\" + label)):\n        os.mkdir(\"images/train/\" + label);\n    \n    cv2.imwrite(\"images/train/\" + label + \"/\" + str(i) + \".jpg\", img);\n    \n    \n#Testing data\ndv = pd.read_csv(\"/kaggle/input/Kannada-MNIST/test.csv\");\nfor i in tqdm(range(5000)):\n    x = dv.iloc[i].to_numpy();\n    id_ = str(x[0])\n    img = x[1:]\n    img = np.reshape(img, (28, 28));\n    img = np.expand_dims(img, axis=0);\n    img = np.vstack((img, img, img))\n    img = np.swapaxes(img, 0, 1);\n    img = np.swapaxes(img, 1, 2);\n    cv2.imwrite(\"images/test/\" + str(id_) + \".jpg\", img);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the kernel cannot use internet, the installation got a little lengthy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/monk-kaggle/kaggle/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/monk-kaggle/kaggle/installs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/monk-kaggle/kaggle/installs/ && pip install PyLg-1.3.3-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/monk-kaggle/kaggle/installs/ && pip install blessings-1.7-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/monk-kaggle/kaggle/installs/ && pip install netron-3.7.3-py2.py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/monk-kaggle/kaggle/installs/ && pip install gpustat-0.6.0-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/monk-kaggle/kaggle/monk_v1/monk/\")\nsys.path.append(\"/kaggle/input/monk-kaggle/kaggle/installs/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gluon_prototype import prototype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = prototype(verbose=1);\ngtf.Prototype(\"sample-project\", \"sample-experiment-1\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Dataset_Params(dataset_path=\"images/train/\", \n                   split=0.8, input_size=28, \n                batch_size=16, shuffle_data=True, num_processors=3);\n\n# Transform\ngtf.apply_random_horizontal_flip(train=True, val=True);\ngtf.apply_normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], train=True, val=True, test=True);\n\n# Set Dataset\ngtf.Dataset();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = gtf.system_dict[\"dataset\"][\"params\"][\"classes\"];\nclasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Create network by carefully visalizing and arranging"},{"metadata":{"trusted":true},"cell_type":"code","source":"network = [];\nnetwork.append(gtf.convolution(output_channels=64));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.convolution(output_channels=64));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.max_pooling());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.debug_custom_model_design(network);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subnetwork = [];\nbranch1 = [];\nbranch1.append(gtf.convolution(output_channels=64));\nbranch1.append(gtf.batch_normalization());\nbranch1.append(gtf.convolution(output_channels=64));\nbranch1.append(gtf.batch_normalization());\n\nbranch2 = [];\nbranch2.append(gtf.convolution(output_channels=64));\nbranch2.append(gtf.batch_normalization());\n\nbranch3 = [];\nbranch3.append(gtf.identity())\n\nsubnetwork.append(branch1);\nsubnetwork.append(branch2);\nsubnetwork.append(branch3);\nsubnetwork.append(gtf.concatenate());\n\nnetwork.append(subnetwork);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.debug_custom_model_design(network);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.append(gtf.convolution(output_channels=128));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.max_pooling());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.debug_custom_model_design(network);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subnetwork = [];\nbranch1 = [];\nbranch1.append(gtf.convolution(output_channels=128));\nbranch1.append(gtf.batch_normalization());\nbranch1.append(gtf.convolution(output_channels=128));\nbranch1.append(gtf.batch_normalization());\n\nbranch2 = [];\nbranch2.append(gtf.convolution(output_channels=128));\nbranch2.append(gtf.batch_normalization());\n\nbranch3 = [];\nbranch3.append(gtf.identity())\n\nsubnetwork.append(branch1);\nsubnetwork.append(branch2);\nsubnetwork.append(branch3);\nsubnetwork.append(gtf.add());\n\nnetwork.append(subnetwork);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.debug_custom_model_design(network);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.append(gtf.convolution(output_channels=256));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.max_pooling());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.debug_custom_model_design(network);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.append(gtf.flatten());\nnetwork.append(gtf.fully_connected(units=1024));\nnetwork.append(gtf.dropout(drop_probability=0.2));\nnetwork.append(gtf.fully_connected(units=len(classes)));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Compile_Network(network, data_shape=(3, 28, 28));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Training_Params(num_epochs=10, display_progress=True, display_progress_realtime=True, \n        save_intermediate_models=False, intermediate_model_prefix=\"intermediate_model_\", save_training_logs=True);\n\ngtf.optimizer_sgd(0.01);\ngtf.lr_fixed();\ngtf.loss_softmax_crossentropy();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Train();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inference_dataset = \"images/test/\";\noutput = gtf.Infer(img_dir=inference_dataset);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create submission\nimport pandas as pd\nsub = pd.read_csv(\"/kaggle/input/Kannada-MNIST/sample_submission.csv\");\nfor i in range(len(output)):\n    index = int(sub[sub['id']==int(output[i]['img_name'].split(\".\")[0])].index[0])\n    #print(output[i]);\n    #print(index);\n    sub['label'][index] = int(output[i]['predicted_class'])\n    #print(sub.iloc[index:index+1])\n    #break\nsub.to_csv(\"submission.csv\", index=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}