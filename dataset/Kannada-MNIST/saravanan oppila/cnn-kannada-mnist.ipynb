{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import required packages #\nimport matplotlib.pyplot as plt,seaborn as sns,pandas as pd,numpy as np\nfrom keras.models import Sequential, load_model\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers import Conv2D, MaxPooling2D,MaxPool2D,Flatten,BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ntrain_data = pd.read_csv('../input/Kannada-MNIST/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 'label' column\nx_train = train_data.drop(labels = [\"label\"],axis = 1) \ny_train = train_data[\"label\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot target class #\nsns.countplot(train_data.label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.values.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's print the shape before we reshape and normalize\nprint(\"X_train shape\", x_train.shape)\nprint(\"y_train shape\", y_train.shape)\nprint(\"X_test shape\", x_test.shape)\nprint(\"y_test shape\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# building the input vector from the 28x28 pixels\nX_train = x_train.reshape(-1, 28, 28,1)\nX_test = x_test.reshape(-1, 28, 28,1)\n# print the final input shape ready for training\nprint(\"Train matrix shape\", X_train.shape)\nprint(\"Test matrix shape\", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding using keras' numpy-related utilities\nn_classes = 10\nprint(\"Shape before one-hot encoding: \", y_train.shape)\nY_train = np_utils.to_categorical(y_train, n_classes)\nY_test = np_utils.to_categorical(y_test, n_classes)\nprint(\"Shape after one-hot encoding: \", Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build LeNet-5 Convolution neural network #\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size = 4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n\nadam = Adam(lr=5e-4)\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set a learning rate annealer\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', \n                                patience=3, \n                                verbose=1, \n                                factor=0.2, \n                                min_lr=1e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Augmentation\ndatagen = ImageDataGenerator(\n            rotation_range=10, \n            width_shift_range=0.1, \n            height_shift_range=0.1, \n            zoom_range=0.1)\nhistory = datagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=100), steps_per_epoch=len(X_train)/100, \n                    epochs=20, validation_data=(X_test, Y_test), callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model with test data\nscore = model.evaluate(X_test, Y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Accuracy and Loss graph #\nf = plt.figure(figsize=(20,7))\nf.add_subplot(121)\nplt.plot(history.epoch,history.history['accuracy'],label = \"accuracy\")\nplt.plot(history.epoch,history.history['val_accuracy'],label = \"val_accuracy\")\nplt.title(\"Accuracy Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Accuracy\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n\nf.add_subplot(122)\nplt.plot(history.epoch,history.history['loss'],label=\"loss\") \nplt.plot(history.epoch,history.history['val_loss'],label=\"val_loss\")\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load test data #\ntest_data = pd.read_csv('../input/Kannada-MNIST/test.csv')\nid_ = test_data.id \ntest_data = test_data.drop(\"id\",axis=\"columns\")\ntest_data = test_data.values.reshape(-1, 28, 28,1)\ntest_data = test_data.astype('float32')\n# Normalise test data #\ntest_data /= 255\nprint(\"Test data matrix shape\", test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict test data #\ny_pred = model.predict_classes(test_data, verbose=0)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict indivdual input image #\ni = 7\npredicted_value = np.argmax(model.predict(X_test[i].reshape(1,28, 28,1)))\nprint('predicted value:',predicted_value)\nplt.imshow(X_test[i].reshape([28, 28]), cmap='Greys_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub=pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')\nsample_sub['label']=y_pred\nsample_sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}