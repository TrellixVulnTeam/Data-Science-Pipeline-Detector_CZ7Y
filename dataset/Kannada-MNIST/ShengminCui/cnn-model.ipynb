{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data path\ntrain_set = \"../input/Kannada-MNIST/train.csv\"\nvalid_set = \"../input/Kannada-MNIST/Dig-MNIST.csv\"\ntest_set = \"../input/Kannada-MNIST/test.csv\"\n\n# Read data\ntrain = pd.read_csv(train_set)\nvalid = pd.read_csv(valid_set)\ntest = pd.read_csv(test_set)\n\nxtrain = train.drop('label', axis=1)\nytrain = train.label\nxtest = test.drop('id', axis=1)\nxval = valid.drop('label', axis=1)\nyval = valid.label\n\nxtrain = xtrain.values\nytrain = ytrain.values\nxval = xval.values\nyval = yval.values\nxtest = xtest.values\n\nxtrain = xtrain.reshape(-1, 28, 28, 1).astype('float32')\nxval = xval.reshape(-1, 28, 28, 1).astype('float32')\nxtest = xtest.reshape(-1, 28, 28, 1).astype('float32')\n\nxtrain = (xtrain - np.mean(xtrain))/255\nxval = (xval - np.mean(xval))/255\nxtest = (xtest - np.mean(xtest))/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    inputs = tf.keras.Input(shape=(28,28,1))\n    \n    x1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(inputs)\n    x1 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x1)\n    x1 = tf.keras.layers.LeakyReLU(alpha=0.1)(x1)\n\n    x2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(x1)\n    x2 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x2)\n    x2 = tf.keras.layers.LeakyReLU(alpha=0.1)(x2)\n\n    x3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(x2)\n    x3 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x3)\n    x3 = tf.keras.layers.LeakyReLU(alpha=0.1)(x3)\n\n#     x4 = tf.keras.layers.concatenate([x1, x3], axis=-1)\n#     x4 = tf.keras.layers.Add()([inputs, x3])\n    x4 = tf.keras.layers.Average()([x1, x2, x3])\n    x4 = tf.keras.layers.MaxPooling2D((2, 2))(x4)\n    x4 = tf.keras.layers.Dropout(0.25)(x4)\n\n    x5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x4)\n    x5 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x5)\n    x5 = tf.keras.layers.LeakyReLU(alpha=0.1)(x5)\n\n    x6 = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x5)\n    x6 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x6)\n    x6 = tf.keras.layers.LeakyReLU(alpha=0.1)(x6)\n\n    x7 = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x6)\n    x7 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x7)\n    x7 = tf.keras.layers.LeakyReLU(alpha=0.1)(x7)\n\n#     x8 = tf.keras.layers.concatenate([x5, x7], axis=-1)\n#     x8 = tf.keras.layers.Add()([x5, x7])\n    x8 = tf.keras.layers.Average()([x5, x6, x7])\n    x8 = tf.keras.layers.MaxPooling2D((2, 2))(x8)\n    x8 = tf.keras.layers.Dropout(0.25)(x8)\n \n    x9 = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x8)\n    x9 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x9)\n    x9 = tf.keras.layers.LeakyReLU(alpha=0.1)(x9)\n\n    x10 = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x9)\n    x10 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x10)\n    x10 = tf.keras.layers.LeakyReLU(alpha=0.1)(x10)\n\n    x11 = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x10)\n    x11 = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(x11)\n    x11 = tf.keras.layers.LeakyReLU(alpha=0.1)(x11)\n\n    x12 = tf.keras.layers.Average()([x9, x10, x11])\n    x12 = tf.keras.layers.MaxPooling2D((2, 2))(x12)\n    x12 = tf.keras.layers.Dropout(0.25)(x12)\n    \n\n    x = tf.keras.layers.Flatten()(x12)\n    x = tf.keras.layers.Dense(256, activation=tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(128, activation=tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(64, activation=tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n    output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=output)\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.RMSprop(learning_rate=0.002, rho=0.9)\nmodel = build_model()\nmodel.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n                                                rotation_range=12,\n                                                zoom_range=0.35,\n                                                width_shift_range=0.3,\n                                                height_shift_range=0.3)\n\ndata_generator.fit(xtrain)\n\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n                                                monitor='loss',\n                                                factor=0.2,\n                                                patience=2,\n                                                verbose=2,\n                                                mode=\"min\",\n                                                min_delta=0.0001,\n                                                cooldown=0,\n                                                min_lr=0.0000001)\n\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(data_generator.flow(xtrain, ytrain, batch_size=1024), \n                                       steps_per_epoch=len(xtrain)//1024,\n                                       epochs=500,\n                                       validation_data=(np.array(xval), np.array(yval)),\n                                       validation_steps=50,\n                                       callbacks=[learning_rate_reduction, es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(xtest)\npreds = preds.argmax(axis=1)\nprint(preds)\n# predictions to dataframe\npreds = preds.astype(int).flatten()\npreds = (LabelEncoder().fit_transform((preds)))\npreds = pd.DataFrame({'label': preds})\n\nsub = pd.DataFrame(data=test.id)\nsub = sub.join(preds)\n\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}