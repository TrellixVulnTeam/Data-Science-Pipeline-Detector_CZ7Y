{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np \nimport os\nimport torch\nimport torch.utils.data as data\nimport torch.utils.data as data_utils\nfrom torchvision import transforms\nimport torch.nn as nn\nimport csv\nfrom matplotlib.pylab import plt # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ownDatatype(data.Dataset):\n    def __init__(self, tensor, transform = None):\n        self.tensor = tensor\n        self.transform = transform\n    def __len__(self):\n        return self.tensor[1].size(0)\n    def __getitem__(self, index):\n        if self.transform is not None:\n            X = self.tensor[0][index]\n            X = self.transform(X)\n        else:\n            X = self.tensor[0][index]\n        y = self.tensor[1][index]\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_dataset_in_torch(dataset,  batch_size, train, tranform = None):\n    dataset = dataset[1:]\n    label = dataset[:, 0].astype(int)\n    dataset = dataset[:, 1:]\n    label = torch.from_numpy(label).to(device)\n    dataset = torch.from_numpy(dataset).to(device)\n    #label = label[:, None]\n    dataset = dataset.view(-1, 28, 28)\n    dataset = dataset[:, None]\n    dataset_as_dataloader = ownDatatype((dataset, label), tranform)\n    if train == False:\n        loader = data_utils.DataLoader(dataset_as_dataloader, batch_size=batch_size, shuffle=False)\n        return loader\n    else:\n        dataset_size = int(len(dataset_as_dataloader)*0.9)\n        validation_size = len(dataset_as_dataloader) - dataset_size \n\n        train_set, validate_set = data_utils.random_split(dataset_as_dataloader, [dataset_size, validation_size])\n\n        loader = data_utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n        vali = data_utils.DataLoader(validate_set, batch_size=batch_size, shuffle=True)\n        return loader, vali\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNNCell(nn.Module):\n    def __init__(self, input_channels, output_channels):\n        super(CNNCell, self).__init__()\n        self.convolutional = nn.Conv2d(in_channels = input_channels, \n                                    kernel_size = 3, out_channels = output_channels,\n                                     stride=1, padding=1)\n        self.batchn = nn.BatchNorm2d(num_features = output_channels) \n        self.activation = nn.ReLU()\n    def forward(self, data):\n        output = self.convolutional(data)\n        output = self.batchn(output)\n        output = self.activation(output)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNNNetwork(nn.Module):\n    def __init__(self):\n        super(CNNNetwork, self).__init__()\n        self.CNNcell1 = CNNCell(input_channels = 1, output_channels = 30)\n        self.CNNcell2 = CNNCell(input_channels = 30, output_channels = 30)\n        self.max_pool1 = nn.MaxPool2d(kernel_size = 2)\n        self.CNNcell3 = CNNCell(input_channels = 30, output_channels = 60)\n        self.CNNcell4 = CNNCell(input_channels = 60, output_channels = 60)\n        self.max_pool2 = nn.MaxPool2d(kernel_size = 2)\n        self.CNNcell5 = CNNCell(input_channels = 60, output_channels = 90)\n        self.CNNcell6 = CNNCell(input_channels = 90, output_channels = 90)\n        self.max_pool3 = nn.MaxPool2d(kernel_size = 2)\n        \n        self.fc1 = nn.Linear(in_features = 90*3*3, out_features = 400)\n        self.dropout1 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(in_features = 400, out_features = 300)\n        self.dropout2 = nn.Dropout(0.3)\n        self.fc3 = nn.Linear(in_features = 300, out_features = 10)\n\n        self.CNNnetwork = nn.Sequential(self.CNNcell1, self.CNNcell2, \n                  self.max_pool1, self.CNNcell3, self.CNNcell4, self.max_pool2, self.CNNcell5, self.CNNcell6, self.max_pool3)\n        self.activation = nn.ReLU()\n    def forward(self, x):\n        x = self.CNNnetwork(x)\n        x = x.view(-1, 90*3*3)\n        x = self.activation(self.fc1(x))\n        x = self.dropout1(x)\n        x = self.activation(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Training_class():\n    def __init__(self, model, lr, device, wd):\n        self.model = model\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr = lr, weight_decay=wd, amsgrad=False)\n        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size = 200, gamma=0.5)\n        self.device = device\n        self.listLoss_val = []\n        self.listLoss_train = []\n        self.listAcc_batch_train = []\n        self.listAccval = []\n        self.listAccTrain = []\n\n    def kaggle_sub(self, validate_loader):\n        output = []\n        accuracy = []\n        epoch_loss = 0\n        self.model = self.model.eval()\n        for batch_index, (input, label) in enumerate(validate_loader):\n            with torch.no_grad():\n                label = label.to(self.device)\n                input = input.to(self.device)\n                label_prediction = self.model(input.float())\n                #\n                indicies_predicted = torch.argmax(label_prediction, dim=1)\n                label = label.cpu().numpy().reshape((len(label), 1)).astype(int)\n                indicies_predicted = indicies_predicted.cpu().numpy().reshape((len(label), 1)).astype(int)\n                out = np.concatenate((label, indicies_predicted), axis=1).tolist()\n                output += out\n                #\n        return output\n\n\n    def test(self, batch_size, validate_loader):\n        accuracy = []\n        epoch_loss = 0\n        self.model = self.model.eval()\n        for batch_index, (input, label) in enumerate(validate_loader):\n            with torch.no_grad():\n                label = label.to(self.device)\n                input = input.to(self.device)\n                label_prediction = self.model(input.float())\n                #\n                indicies_predicted = torch.argmax(label_prediction, dim=1)\n                number_of_wrong = torch.where(label != indicies_predicted, \n                                torch.tensor([1]).to(self.device), torch.tensor([0]).to(self.device))\n                accuracy_batch = 1 - torch.sum(number_of_wrong).item() / batch_size #*\n                accuracy.append(accuracy_batch)\n                #\n                loss = self.criterion(label_prediction, label)\n                epoch_loss += loss.item()\n        self.listLoss_val.append(epoch_loss)\n        self.listAccval.append(np.mean(accuracy))\n        print(\"val total loss:{:4} ; val accuracy: {:4}\".format(epoch_loss, np.mean(accuracy)))\n\n    def train_funct(self, batch_size, train_loader, validate_loader, test_data, epochs):\n        print(\"hm\")\n        for epoch in range(epochs):\n            self.model = self.model.train()\n            epoch_loss = 0\n            epoch_accuracy = []\n            for batch_index, (input, label) in enumerate(train_loader):\n                self.optimizer.zero_grad()\n                input = input.to(self.device)\n                label = label.to(self.device)\n                label_prediction = model(input.float())\n                #\n                indicies_predicted = torch.argmax(label_prediction, dim=1)\n                number_of_wrong = torch.where(label != indicies_predicted, \n                                torch.tensor([1]).to(self.device), torch.tensor([0]).to(self.device))\n                accuracy_batch = 1 - torch.sum(number_of_wrong).item() / batch_size\n                epoch_accuracy.append(accuracy_batch)\n                #\n                loss = self.criterion(label_prediction, label)\n                epoch_loss += loss.item()\n                loss.backward()\n                self.optimizer.step()\n                self.scheduler.step()\n                self.listAcc_batch_train.append(accuracy_batch)\n            print(\"Epoch now:{} ; training total loss:{:4} ; training accuracy: {:4}\".format(epoch, epoch_loss, np.mean(epoch_accuracy)))\n            self.test(batch_size, validate_loader)\n            self.listLoss_train.append(epoch_loss)\n            self.listAccTrain.append(np.mean(epoch_accuracy))\n        print(\"This is test data\")\n        self.test(batch_size, test_data)\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Normalize((0.5,),(0.5,))]) # can add more\ntransform = None\nbatch_size = 100\n\npath = \"../input/Kannada-MNIST/\"\n\ntrain_data = np.genfromtxt(path +'train.csv', delimiter=',')\ntrain_data, validation_data = get_dataset_in_torch(train_data, batch_size, True, transform)\n\ntest_data = np.genfromtxt(path +'Dig-MNIST.csv', delimiter=',')\ntest_data = get_dataset_in_torch(test_data, batch_size, False, transform)\n\nkaggle_data = np.genfromtxt(path +'test.csv', delimiter=',')\nkaggle_data = get_dataset_in_torch(kaggle_data, batch_size, False, transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CNNNetwork()\nmodel.to(device)\n\nepochs = 5\nlr = 3e-4\nwd = 1e-2\n\ntrain_class = Training_class(model, lr, device, wd)\n\nmodel = train_class.train_funct(batch_size, train_data, validation_data, test_data, epochs)\noutput = train_class.kaggle_sub(kaggle_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')\nlabels = []\nfor i in range(len(output)):\n    labels.append(output[i][1])\n\nsub['label']=labels\nsub.to_csv('submission.csv',index=False)\n\nsub.head()\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}