{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 导入包，加载数据，可视化数据"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Activation\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train=pd.read_csv('../input/Kannada-MNIST/train.csv')\ndata_test=pd.read_csv('../input/Kannada-MNIST/test.csv')\ny=data_train['label']\nx=data_train.drop(['label'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 可视化数据\nx1=np.array(x).reshape(len(data_train),28,28)\nplt.figure(figsize=(18,4))\nfor i in range(20):\n    plt.subplot(2,10,i+1)\n    plt.imshow(x1[i],cmap='Greys')\n    plt.title(y[i])\n    plt.xticks([])\n    plt.yticks([])\n\nY_train=keras.utils.to_categorical(y)\nX_train=np.array(x/255).reshape(len(data_train),28,28,1)\nX_test=np.array(data_test.drop(['id'],axis=1)/255).reshape(len(data_test),28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 三层cnn模型\n    1.卷积层conv1：10个3x3的卷积核,strides=1,padding=1(same)，output=28x28x10\n    batchnormalization1:\n    activation funcion1:relu\n    Maxpool1: 2x2,strides=2,padding=valid,output=14x14x10\n\n    2.卷积层conv2：20个3x3的卷积核,strides=1,padding=1(same)，output=14x14x20\n    batchnormalization2:\n    activation funcion2:relu\n    Maxpool2: 2x2,strides=2,padding=valid,output=7x7x10\n\n    3.卷积层conv3：40个2x2的卷积核,strides=1,padding=0(valid)，output=6x6x40\n    batchnormalization3:\n    activation funcion3:relu\n    Maxpool2: 2x2,strides=2,padding=valid,output=3x3x40\n\n    4.flatten()\n    全连接层dense(10) \n    activation:softmax"},{"metadata":{"trusted":true},"cell_type":"code","source":"#参数设置\nnp.random.seed(0)\ntf.random.set_seed(0)\nnumberfilters1,numberfilters2,numberfilters3=10,20,40\nsizefilter1,sizefilter2,sizefilter3=3,3,2\n#搭建模型\ncnn=Sequential()\ncnn.add(Conv2D(filters=numberfilters1,\n              kernel_size=(sizefilter1,sizefilter1),\n              strides=(1,1),\n              padding='same'))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n\ncnn.add(Conv2D(filters=numberfilters2,\n              kernel_size=(sizefilter2,sizefilter2),\n              strides=(1,1),\n              padding='same'))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n\ncnn.add(Conv2D(filters=numberfilters3,\n              kernel_size=(sizefilter3,sizefilter3),\n              strides=(1,1),\n              padding='valid'))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n\ncnn.add(Flatten())\ncnn.add(Dense(10))\ncnn.add(Activation('softmax'))\n\ncnn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nsummary=cnn.fit(x=X_train,y=Y_train, validation_split=0.15, epochs=10, batch_size=64, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 结果展示"},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss\nplt.figure(figsize=(9,7), dpi=80)\nplt.plot(summary.history['loss'])\nplt.plot(summary.history['val_loss'])\nplt.title('Model loss', fontsize=16)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n#accurcy\nplt.figure(figsize=(9,7),dpi=80)\nplt.plot(summary.history['accuracy'])\nplt.plot(summary.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('accuracy')\nplt.legend(['Train','Validation'], loc='upper left')\nplt.show()\nprint('Train accuarcy: {:.4f}'.format(summary.history['accuracy'][-1]))\nprint('Validation accuracy:{:.4f}'.format(summary.history['val_accuracy'][-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_test = cnn.predict_classes(X_test).astype(int)\nsubmission=pd.DataFrame({'id':data_test['id'],'label':pre_test})\nsubmission.to_csv('/kaggle/working/submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}