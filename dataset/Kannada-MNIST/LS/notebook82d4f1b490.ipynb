{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport PIL\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\n\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Get Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_data(data_set, label_column='label'):\n    # data_set:   pd DataFrame\n    data_X = data_set.drop(columns=label_column)\n    data_y = data_set[label_column]\n    return data_X, data_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# read data\ntrain_set = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest_set = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\ndig_set = pd.read_csv('/kaggle/input/Kannada-MNIST/Dig-MNIST.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, y_train = get_data(train_set, label_column='label')\nX_dig, y_dig = get_data(dig_set, label_column='label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.shape, y_train.shape, X_dig.shape, y_dig.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = X_train.to_numpy().reshape(-1, 28, 28, 1)\ny_train = y_train.to_numpy().reshape(-1, 1)\nX_dig = X_dig.to_numpy().reshape(-1, 28, 28, 1)\ny_dig = y_dig.to_numpy().reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_set = test_set.drop(columns='id').to_numpy().reshape(-1, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# no need to do this for CNN, otherwise some image preprocessing packages \n# can convert any value between 0-1 to 0 or 1\n# X_train = X_train / 255.0\n# X_dig = X_dig / 255.0\n# test_set = test_set / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_cat = to_categorical(y_train)\ny_dig_cat = to_categorical(y_dig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class_names = np.arange(10)\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i,:,:,0], cmap='gray')\n    # y_train_cat is in one-hot format\n    plt.xlabel(np.where(y_train_cat[i]==1)[0][0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. array to rgb"},{"metadata":{"trusted":false},"cell_type":"code","source":"def array2rgb(input_array, reshape_size, interp_method):\n    output_list = []\n    for i in range(len(input_array)):\n        data = input_array[i,:,:, 0]\n        img_rgb = Image.fromarray(data.astype('uint8')).convert('RGB')\n        img_resized = img_rgb.resize(reshape_size, resample=interp_method)\n        img_resized = np.array(img_resized).astype('float32')\n        output_list.append(img_resized)\n    output_array = np.array(output_list)\n\n    return output_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reshape_size = (94, 94)\ninterp_method = PIL.Image.BICUBIC\n\nX_train_rgb = array2rgb(X_train, reshape_size=reshape_size, interp_method=interp_method)\nX_dig_rgb = array2rgb(X_dig, reshape_size=reshape_size, interp_method=interp_method)\ntest_set_rgb = array2rgb(test_set, reshape_size=reshape_size, interp_method=interp_method)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_rgb.shape, X_dig_rgb.shape, test_set_rgb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class_names = np.arange(10)\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train_rgb[i,:,:,:], cmap='gray')\n    # y_train_cat is in one-hot format\n    plt.xlabel(np.where(y_train_cat[i]==1)[0][0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. data generator"},{"metadata":{"trusted":false},"cell_type":"code","source":"height_shift_range = 0.1\nwidth_shift_range = 0.1\nzoom_range = 0.1\nrotation_range=10\ndatagen = ImageDataGenerator(rotation_range=10, zoom_range=zoom_range,\n                             width_shift_range=width_shift_range,\n                             height_shift_range=height_shift_range)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"it = datagen.flow(X_train_rgb[0:10,:,:,:], batch_size=1)\nplt.figure(figsize=(5, 5))\nfor i in range(9):\n    plt.subplot(330 + 1+ i)\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    #print(image.shape)\n    plt.imshow(image, cmap='gray')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. build model"},{"metadata":{"trusted":false},"cell_type":"code","source":"base_model = tf.keras.applications.MobileNetV2(\n    weights = 'imagenet', input_shape = (94, 94, 3),\n    include_top = False\n)\n\nbase_model.trainable =False","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = models.Sequential([\n    base_model, layers.GlobalAveragePooling2D()\n    ,\n    layers.Dropout(0.4), layers.Dense(10, activation='softmax')\n])\n\n\"\"\"\n# Another way to implement the model\ninputs = tf.keras.Input(shape=(94, 94, 3))\nx = base_model(inputs)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.4)(x)\noutputs = layers.Dense(10, activation='softmax')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\"\"\"\nprint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Adam optimizer\nlearning_rate = 0.001\nbeta_1 = 0.9\nbeta_2 = 0.999\noptimizer = Adam(lr=learning_rate, beta_1=beta_1, beta_2=beta_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.compile(optimizer=optimizer,\n              loss=['categorical_crossentropy'],\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size = 32\n# reduce learning rate\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,\n                              patience=3, min_lr=0.00001)\nhistory = model.fit(datagen.flow(X_train_rgb, y_train_cat, batch_size=batch_size), callbacks=[reduce_lr],\n          steps_per_epoch=len(X_train) / batch_size, epochs=10, validation_data=(X_dig_rgb, y_dig_cat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(history.history['acc'], label='accuracy')\nplt.plot(history.history['val_acc'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"start= time.time()\ny_pred = model.predict_classes(test_set_rgb)\nend = time.time()\ntest_time = (end - start) / 60\nprint(f'testing time: {test_time}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_pd = pd.DataFrame({'id': np.arange(len(y_pred)),\n                          'label': y_pred})\ny_pred_pd.to_csv('./y_pred.csv', sep=',', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. compare to the previous model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# conv layers\nmodel_2 = models.Sequential()\nmodel_2.add(layers.Conv2D(32, kernel_size=(3, 3),padding='Same', activation='relu', input_shape=(28, 28, 1)))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Conv2D(32, kernel_size=(3, 3), padding='Same', activation='relu'))\nmodel_2.add(layers.BatchNormalization(momentum=0.1))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Dropout(0.2))\n\nmodel_2.add(layers.Conv2D(64, kernel_size=(5, 5),padding='Same', activation='relu', input_shape=(28, 28, 1)))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Conv2D(64, kernel_size=(5, 5), padding='Same', activation='relu'))\nmodel_2.add(layers.BatchNormalization(momentum=0.1))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Dropout(0.2))\n\n\"\"\"\nmodel_2.add(layers.Conv2D(32, kernel_size=(3, 3),padding='Same', activation='relu', input_shape=(28, 28, 1)))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Conv2D(32, kernel_size=(3, 3), padding='Same', activation='relu'))\nmodel_2.add(layers.BatchNormalization(momentum=0.1))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Dropout(0.2))\n\"\"\"\n\n# Fully connected layers\nmodel_2.add(layers.Flatten())\nmodel_2.add(layers.Dense(128, activation='relu'))\nmodel_2.add(layers.Dropout(0.4))\nmodel_2.add(layers.Dense(64, activation='relu'))\nmodel_2.add(layers.Dropout(0.4))\nmodel_2.add(layers.Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_2.compile(optimizer=optimizer,\n              loss=['categorical_crossentropy'],\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nhistory_2 = model_2.fit(datagen.flow(X_train, y_train_cat, batch_size=batch_size), callbacks=[reduce_lr],\n          steps_per_epoch=len(X_train) / batch_size, epochs=10, validation_data=(X_dig, y_dig_cat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(10,5))\naxs[0].plot(history_2.history['acc'], label='accuracy')\naxs[0].plot(history_2.history['val_acc'], label = 'val_accuracy')\naxs[0].set_ylim(0.5, 1)\naxs[0].set_title('transfer learning: MobileNetV2')\naxs[0].set_xlabel('Epoch')\naxs[0].set_ylabel('Accuracy')\naxs[0].legend(loc='lower right')\n\naxs[1].plot(history.history['acc'], label='accuracy')\naxs[1].plot(history.history['val_acc'], label = 'val_accuracy')\naxs[1].set_ylim(0.5, 1)\naxs[1].set_title('classic CNN')\naxs[1].set_xlabel('Epoch')\naxs[1].set_ylabel('Accuracy')\naxs[1].legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that the classic CNN model works better, we might need to unfreeze the weights of the MobileNetV2 model to achieve similar or better result."},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}