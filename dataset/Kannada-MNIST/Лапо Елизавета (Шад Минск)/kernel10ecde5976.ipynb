{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras import layers, optimizers\nfrom keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nplt.style.use('ggplot')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/Kannada-MNIST/test.csv')\ntrain = pd.read_csv('../input/Kannada-MNIST/train.csv')\ndig_df = pd.read_csv('../input/Kannada-MNIST/Dig-MNIST.csv')\nsample_df = pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert dataframes to numpy matricies\nX = train.drop('label', axis=1).to_numpy()\ny = train['label'].to_numpy()\nX_test = test.drop('id', axis=1).to_numpy()\nX_dig = dig_df.drop('label', axis=1).to_numpy()\ny_dig = dig_df['label'].to_numpy()\n\n# reshape X's for keras and encode y using one-hot-vector-encoding\nX = X.reshape(-1, 28, 28, 1)\ny = to_categorical(y)\nX_test = X_test.reshape(-1, 28, 28, 1)\nX_dig = X_dig.reshape(-1, 28, 28, 1)\n\n# normalize the data to range(0, 1)\nX = X / 255\nX_dig = X_dig / 255\nX_test = X_test / 255\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1.0,\n                                   rotation_range=10,\n                                   width_shift_range=0.25,\n                                   height_shift_range=0.25,\n                                   shear_range=0.1,\n                                   zoom_range=0.25,\n                                   horizontal_flip=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=7, \n                                            verbose=1, \n                                            factor=0.1, \n                                            min_lr=1e-8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_norm_model():\n      inputs = layers.Input(shape=(28, 28, 1))\n\n      x = layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', input_shape=(28, 28, 1))(inputs)\n      x = layers.LeakyReLU(alpha=0.3)(x)\n      x = layers.BatchNormalization()(x)  \n      x = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1))(x)\n      x = layers.LeakyReLU(alpha=0.3)(x)\n      x = layers.BatchNormalization()(x)\n      x = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1))(x)\n      x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n      x = layers.LeakyReLU(alpha=0.3)(x)\n      x = layers.BatchNormalization()(x)\n      x = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))(x)\n      x = layers.LeakyReLU(alpha=0.3)(x)\n      x = layers.BatchNormalization()(x)\n      x = layers.Dropout(0.5)(x)\n      x = layers.BatchNormalization()(x)\n      x = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))(x)\n      x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n      x = layers.LeakyReLU(alpha=0.3)(x)\n      x = layers.BatchNormalization()(x)\n      x = layers.Flatten()(x)\n      x = layers.Dense(units=256)(x)\n      x = layers.LeakyReLU(alpha=0.3)(x)\n      x = layers.BatchNormalization()(x)\n      x = layers.Dropout(0.5)(x)\n      output = layers.Dense(10, activation='softmax')(x)\n\n      return Model(inputs=inputs, outputs=output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_val_accuracy(histories, y_label, epochs):\n  plt.figure(figsize=(15, 8))\n  epoch_range = np.arange(epochs - 10)\n  for id, history in enumerate(histories):\n    plt.plot(epoch_range, history.history['val_accuracy'][10:], label='batch size=' + str(y_label[id]))\n    plt.plot(epoch_range, history.history['accuracy'][10:], label='batch size=' + str(y_label[id]))\n    plt.title('Model validation accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_prediction(model, x):\n    y_pred = model.predict(x)\n    return np.argmax(y_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_add = make_prediction(sgd_norm_model, X_dig)\n\n#idx = y_add == y_dig\n#X_train = np.concatenate((X_train, X_dig[idx]))\n#y_dig = to_categorical(y_dig)\n#y_train = np.concatenate((y_train, y_dig))\n#X_train = np.concatenate((X_train, X_dig))\n#y_train = np.concatenate((y_train, y_dig[idx]))\n\n#y_test_add = make_prediction(sgd_norm_model, X_test)\n#X_train = np.concatenate((X_train, X_test))\n#y_train = np.concatenate((y_train,to_categorical(y_test_add)))\n\n#shuffler = np.random.permutation(X_train.shape[0])\n#X_train = X_train[shuffler]\n#y_train = y_train[shuffler]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = build_norm_model()\nfinal_model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nhistory_final = final_model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=1024),\n                                           steps_per_epoch=100,\n                                           epochs=120,\n                                           validation_data=(X_valid, y_valid),\n                                           callbacks=[learning_rate_reduction],\n                                           verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_val_accuracy([history_final], [1024], len(history_final.history['val_accuracy']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_result = make_prediction(final_model, X_test)\n\n# save predictions\nsample_df['label'] = y_result\nsample_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}