{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nfrom keras.models import load_model\nfrom keras import layers, optimizers \nfrom keras.preprocessing import image\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, GlobalAveragePooling2D, Dense, concatenate, AveragePooling2D\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.core import Activation, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.compat.v1.Session(config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n    history_dict = history.history\n    loss_values = history_dict['loss']\n    val_loss_values = history_dict['val_loss']\n    epochs = range(1, len(loss_values) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n\n    ax1.plot(epochs, loss_values, 'bo',\n             label='Training loss')\n    ax1.plot(epochs, val_loss_values, 'r',\n             label='Validation loss')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Loss')\n    ax1.set_xscale('log')\n\n    acc_values = history_dict['accuracy']\n    val_acc_values = history_dict['val_accuracy']\n\n    ax2.plot(epochs, acc_values, 'bo',\n             label='Training acc')\n    ax2.plot(epochs, val_acc_values, 'r',\n             label='Validation acc')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Accuracy')\n    ax2.set_xscale('log')\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/Kannada-MNIST/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/Kannada-MNIST/train.csv\")\ndig_mnist = pd.read_csv(\"/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/Kannada-MNIST/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test.shape\", test.shape)\nprint(\"train.shape\", train.shape)\nprint(\"dig_mnist.shape\", dig_mnist.shape)\nprint(\"sample_submission.shape\", sample_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.loc[:, train.columns!='label'].values.astype('uint8')\nprint(\"X_train.shape\", X_train.shape)\ny_train = train['label'].values\nX_train = X_train.reshape((X_train.shape[0],28,28))\nprint(\"X_train.shape\", X_train.shape)\nprint(\"y_train.shape\",X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test.loc[:,  test.columns!='id'].values.astype('uint8')\nprint(\"X_test.shape\", X_test.shape)\ny_id = test['id'].values\nX_test = X_test.reshape((X_test.shape[0],28,28))\nprint(\"X_test.shape\", X_test.shape)\nprint(\"y_id.shape\", y_id.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = np.random.randint(X_train.shape[0])\nplt.imshow(Image.fromarray(X_train[n]))\nplt.show()\nprint(f'This is a {y_train[n]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train[:,:,:,None]\nX_test = X_test[:,:,:,None]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train.shape\", X_train.shape)\nprint(\"X_test.shape\", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nnum_epochs = 50\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_samples = X_train.shape[0]\nnum_classes = np.unique(y_train).shape[0]\nimg_rows, img_cols = X_train[0,:,:,0].shape\nclasses = np.unique(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"num_samples\",num_samples)\nprint(\"num_classes\",num_classes)\nprint(\"img_rows\",img_rows)\nprint(\"img_cols\",img_cols)\nprint(\"classes\",classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np_utils.to_categorical(y_train, num_classes)\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_norm = X_train.astype('float32')\nX_test_norm = X_test.astype('float32')\nX_train_norm /= 255\nX_test_norm /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction=ReduceLROnPlateau(monitor='val_loss',\n                                          patience=5, \n                                          verbose=1,\n                                          factor=0.2\n                                         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', \n                               mode='min', \n                               verbose=1, \n                               patience=10\n                              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_check_point = ModelCheckpoint('model.h5', save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DenseNet:\n    def __init__(self, input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None,\n                 dropout_rate=None, bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n\n        # Checks\n        if nb_classes == None:\n            raise Exception(\n                'Please define number of classes (e.g. num_classes=10). This is required for final softmax.')\n\n        if compression <= 0.0 or compression > 1.0:\n            raise Exception('Compression have to be a value between 0.0 and 1.0.')\n\n        if type(dense_layers) is list:\n            if len(dense_layers) != dense_blocks:\n                raise AssertionError('Number of dense blocks have to be same length to specified layers')\n        elif dense_layers == -1:\n            dense_layers = int((depth - 4) / 3)\n            if bottleneck:\n                dense_layers = int(dense_layers / 2)\n            dense_layers = [dense_layers for _ in range(dense_blocks)]\n        else:\n            dense_layers = [dense_layers for _ in range(dense_blocks)]\n\n        self.dense_blocks = dense_blocks\n        self.dense_layers = dense_layers\n        self.input_shape = input_shape\n        self.growth_rate = growth_rate\n        self.weight_decay = weight_decay\n        self.dropout_rate = dropout_rate\n        self.bottleneck = bottleneck\n        self.compression = compression\n        self.nb_classes = nb_classes\n        \n    def build_model(self):\n        img_input = Input(shape=self.input_shape, name='img_input')\n        nb_channels = self.growth_rate\n        \n        x = Conv2D(2*self.growth_rate, (3,3), \n                   padding='same', strides = (1,1), \n                   kernel_regularizer=keras.regularizers.l2(self.weight_decay))(img_input)\n        \n        for block in range(self.dense_blocks-1):\n            x, nb_channels = self.dense_block(x, self.dense_layers[block], nb_channels, self.growth_rate,\n                                              self.dropout_rate, self.bottleneck, self.weight_decay)\n            \n            x = self.transition_layer(x, nb_channels, self.dropout_rate, self.compression, self.weight_decay)\n            nb_channels = int(nb_channels*self.compression)\n            \n        x, nb_channels = self.dense_block(x, self.dense_layers[-1], nb_channels, self.growth_rate, self.dropout_rate, self.weight_decay)\n        \n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = GlobalAveragePooling2D()(x)\n        prediction = Dense(self.nb_classes, activation='softmax')(x)\n        \n        return Model(inputs=img_input, outputs=prediction, name='densenet')\n        \n    def dense_block(self, x, nb_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n        for i in range(nb_layers):\n            cb = self.convolution_block(x, growth_rate, dropout_rate, bottleneck)\n            nb_channels += growth_rate\n            x = concatenate([cb,x])\n            \n        return x, nb_channels\n    \n    def convolution_block(self, x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):       \n\n        # Bottleneck\n        if bottleneck:\n            bottleneckWidth = 4\n            x = BatchNormalization()(x)\n            x = Activation('relu')(x)\n            x = Conv2D(nb_channels * bottleneckWidth, (1, 1),\n                                     kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n            # Dropout\n            if dropout_rate:\n                x = Dropout(dropout_rate)(x)\n\n        # Standard (BN-ReLU-Conv)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2D(nb_channels, (3, 3), padding='same')(x)\n\n        # Dropout\n        if dropout_rate:\n            x = Dropout(dropout_rate)(x)\n\n        return x\n\n    def transition_layer(self, x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2D(int(nb_channels * compression), (1, 1), padding='same',\n                                 kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n\n        # Adding dropout\n        if dropout_rate:\n            x = Dropout(dropout_rate)(x)\n\n        x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet = DenseNet((28,28,1), nb_classes=10, depth=21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = densenet.build_model()\nmodel_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nmodel.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train_norm, \n                     y_train, \n                     batch_size = batch_size,  \n                     epochs = num_epochs, \n                     validation_split = 0.1,\n                     shuffle = True,\n                     callbacks = [learning_rate_reduction, early_stopping]\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = load_model('/kaggle/input/kannada-mnist-simpe-densenet-in-keras-weight/model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.argmax(pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['label'] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}