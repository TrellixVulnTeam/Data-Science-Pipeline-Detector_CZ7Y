{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n#from keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, TensorBoard\n\n#load the data\ntrain = pd.read_csv(\"../input/Kannada-MNIST/train.csv\")\ntest = pd.read_csv(\"../input/Kannada-MNIST/test.csv\")\ndig_test = pd.read_csv(\"../input/Kannada-MNIST/Dig-MNIST.csv\")\n# print(train)\nY_train = train[\"label\"] \nY_dig = dig_test[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1)  \ntest = test.drop(labels=['id'], axis=1) \ndig_test = dig_test.drop(labels = [\"label\"],axis = 1)\ndel train\n\nprint(Y_train.value_counts())\n\n# Normalize the data\nX_train = X_train / 255.0\ntest = test / 255.0\ndig_test = dig_test / 255.0\n\n# Reshape the image data (height = 28px, width = 28px , chanal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\ndig_test = dig_test.values.reshape(-1,28,28,1)\n\nY_train = to_categorical(Y_train, num_classes = 10)  \nY_dig = to_categorical(Y_dig, num_classes=10)\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',\n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',\n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',\n                 activation ='relu'))  #11月21日加\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))  #11月21日加\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',\n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(Dense(10, activation = \"softmax\"))\n\n\n# Compile the model\nmodel.compile(optimizer = 'Adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n                                            patience=3,\n                                            verbose=1,\n                                            factor=0.5,\n                                            min_lr=0.00001)\nepochs = 30 # larger epochs will be needed for higher accuracy\nbatch_size = 124\n\nTensorBoardcallback = TensorBoard(\n    log_dir='./logs',\n    histogram_freq=1, batch_size=32,\n    write_graph=True, write_grads=False, write_images=True,\n    embeddings_freq=0, embeddings_layer_names=None,\n    embeddings_metadata=None, embeddings_data=None, update_freq=epochs\n)\n\ndatagen = ImageDataGenerator(\n       \n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        ) \n\ndatagen.fit(X_train)\n\n#Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction, TensorBoardcallback],use_multiprocessing=False)\n\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n#legend = ax[0].legend(loc='best', shadow=True)\nax[0].legend(loc='best', shadow=False)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n#legend = ax[1].legend(loc='best', shadow=True)\nax[1].legend(loc='best', shadow=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test on the Dig-MNIST data\ndig_result = model.evaluate(dig_test, Y_dig, verbose=0)\nprint('loss of the model on Dig-MNIST:', dig_result[0])\nprint('Accuracy of the model on Dig-MNIST:', dig_result[1])\n# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\n#results = pd.Series(results,name=\"label\")\n\nsubmission = pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')\nsubmission['label'] = results\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}