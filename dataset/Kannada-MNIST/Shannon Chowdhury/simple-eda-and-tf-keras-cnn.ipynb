{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic import of libraries to support our analysis\nimport numpy as np \nimport pandas as pd\n\n# Visualization Libs\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Check which version of TF is hosted \nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/Kannada-MNIST/train.csv\")\ntest=pd.read_csv(\"../input/Kannada-MNIST/test.csv\")\n\nprint(\"Train Shape: {}\".format(train.shape))\nprint(\"Test Shape: {}\".format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Nulls: {}\".format(train.isna().any().sum()))\nprint(\"Test Nulls: {}\".format(test.isna().any().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training set\nfig, axs = plt.subplots(2, 5, figsize=(16,6))\nfor i, ax  in zip(range(0,10), axs.flat):\n    ax.imshow(train[train['label'] == i].drop(columns=['label']).iloc[0].values.reshape(28, 28), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 5, figsize=(16,6))\nfor i, ax  in zip(range(0,10), axs.flat):\n    ax.imshow(test.drop(columns=['id']).iloc[i].values.reshape(28, 28), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the distribution of each label\nplt.figure(figsize=(24, 7))\nplt.hist(train['label'], color='c', rwidth=0.5, align='mid')\nplt.xlabel('Digits')\nplt.ylabel('Frequency')\nplt.title('Distribution of Labels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Downcasting all the values to save memory\ny = train['label'].astype('int8')\n\n# Downcast to float16 for every column except label\nX = train.drop(columns=['label']).astype('float16').values\n\n# Reshape the arrays so they are easier to visualize and input to NN\nX = X.reshape(len(train), 28,28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create our image generator\ntrain_image_generator = ImageDataGenerator(\n    rescale=1./255\n)\n\nvalidation_image_generator = ImageDataGenerator(\n    rescale=1./255\n)\n\n# Create instance of image generator attach to the dataset\ntrain_image_gen = train_image_generator.flow(\n    x=X_train, \n    y=y_train,\n)\n\nvalidation_image_gen = validation_image_generator.flow(\n    x=X_validation, \n    y=y_validation,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same', input_shape=(28, 28, 1)),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Dropout(0.1),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Dropout(0.1),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()  # For easy reset of notebook state.\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_image_gen,\n    epochs=5,\n    validation_data=validation_image_gen\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy of the validation and training set\nfig, axs = plt.subplots(1,2, figsize=(20,5))\naxs[0].plot(history.history['loss'], label='Train')\naxs[0].plot(history.history['val_loss'], label='Validation')\naxs[0].set_title(\"Loss of Validation and Train\")\naxs[0].legend()\n\naxs[1].plot(history.history['accuracy'], label='Train')\naxs[1].plot(history.history['val_accuracy'], label='Validation')\naxs[1].set_title(\"Accuracy of Validation and Train\")\naxs[1].legend()\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets predict the values on the validation set\nvalidation_predict = model.predict(X_validation)\n\n# Create a dataframe to store the label and the confidence in their predictions\nlow_predictions = pd.DataFrame()\nlow_predictions['label'] = np.argmax(validation_predict, axis=1)\nlow_predictions['Confidence'] = np.max(validation_predict, axis=1)\n\nlow_index = low_predictions.sort_values(by=['Confidence'])[:10].index\nlow_labels = low_predictions.sort_values(by=['Confidence'])['label']\n\nfig, axs = plt.subplots(2, 5, figsize=(24,9.5))\nfor i, low_label, ax  in zip(low_index,low_labels, axs.flat):\n    image = X_validation[i].astype('float32').reshape(28, 28)\n    ax.imshow(image, cmap='gray')\n    ax.set_xlabel(\"True: {}\".format(y_validation.iloc[i]))\n    ax.set_title(\"Guessed:{} \".format(low_label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create our image generator\ntrain_image_generator = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=25,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    zoom_range=0.1\n)\n\nvalidation_image_generator = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=25,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    zoom_range=0.1\n)\n\n# Create the dataset\ntrain_image_gen = train_image_generator.flow(\n    x=X_train, \n    y=y_train,\n)\n\nvalidation_image_gen = validation_image_generator.flow(\n    x=X_validation, \n    y=y_validation,\n)\n\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n    initial_learning_rate=0.001,\n    decay_steps=250,\n    decay_rate=1,\n    staircase=False\n)\n\ndef get_optimizer():\n    return tf.keras.optimizers.Adam(lr_schedule)\n\ntf.keras.backend.clear_session()  # For easy reset of notebook state.\n\nmodel.compile(optimizer=get_optimizer(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_image_gen,\n    epochs=100,\n    validation_data=validation_image_gen\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy of validation and train\nfig, axs = plt.subplots(1,2, figsize=(20,5))\naxs[0].plot(history.history['loss'], label='Train')\naxs[0].plot(history.history['val_loss'], label='Validation')\naxs[0].set_title(\"Loss of Validation and Train\")\naxs[0].legend()\n\naxs[1].plot(history.history['accuracy'], label='Train')\naxs[1].plot(history.history['val_accuracy'], label='Validation')\naxs[1].set_title(\"Accuracy of Validation and Train\")\naxs[1].legend()\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test.drop(columns=['id']).astype('float16').values\nX_test = X_test / 255.0\nX_test = X_test.reshape(len(X_test), 28, 28, 1)\n\nlabel_pred = model.predict_classes(X_test, verbose=0)\n\nsubmission = pd.DataFrame()\nsubmission['label'] = label_pred\nsubmission['id'] = submission.index\nsubmission.to_csv('../working/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}