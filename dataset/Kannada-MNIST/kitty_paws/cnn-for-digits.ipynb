{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/Kannada-MNIST/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/Kannada-MNIST/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run intial setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nnum_classes = 10\nimg_rows = 28\nimg_cols = 28\n\ndef raw_to_img_array(raw_data):\n    y = np.array(raw_data.iloc[:, 0])\n    out_y = keras.utils.to_categorical(y, num_classes)\n    \n    x = np.array(raw_data.iloc[:,1:])\n    num_images = raw_data.shape[0]\n    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x / 255\n    return out_x, out_y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.2, \n        shear_range=20, \n        width_shift_range=0.2,  \n        height_shift_range=0.2,  \n        horizontal_flip=False, \n        vertical_flip=False,\n        )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"convert pixel data from the columns to np array"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_x, train_y = raw_to_img_array(train_data)\ntrain_x,val_x,train_y,val_y=train_test_split(train_x, train_y, test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Play around with data obtained"},{"metadata":{},"cell_type":"markdown","source":"Create a CNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D, BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nkannada_model = Sequential()\nkannada_model.add(Conv2D(128, kernel_size=(4, 4),\n                 activation='relu',padding=\"same\",\n                 input_shape=(img_rows, img_cols, 1)))\nkannada_model.add(BatchNormalization())\nkannada_model.add(MaxPool2D(pool_size=2,padding=\"valid\"))\nkannada_model.add(Dropout(0.25))\nkannada_model.add(Conv2D(256,kernel_size=(4, 4),padding=\"same\", activation='relu'))\nkannada_model.add(BatchNormalization())\nkannada_model.add(MaxPool2D(pool_size=2,padding=\"valid\"))\nkannada_model.add(Dropout(0.25))\nkannada_model.add(Conv2D(512,kernel_size=(4, 4),padding=\"same\", activation='relu'))\nkannada_model.add(BatchNormalization())\nkannada_model.add(MaxPool2D(pool_size=2,padding=\"valid\"))\nkannada_model.add(Dropout(0.25))\nkannada_model.add(Flatten())\nkannada_model.add(Dense(1024, activation='relu'))\nkannada_model.add(BatchNormalization())\nkannada_model.add(Dropout(0.4))\nkannada_model.add(Dense(256, activation='relu'))\nkannada_model.add(BatchNormalization())\nkannada_model.add(Dropout(0.4))\nkannada_model.add(Dense(num_classes, activation='softmax'))\n\nkannada_model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=\"adam\",\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\ncheckpoint = ModelCheckpoint(\"bestmodel.model\", monitor='val_acc', verbose=1, save_best_only=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"fit the model with the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=64\nkannada_model.fit_generator(datagen.flow(train_x,train_y, batch_size=batch_size),\n          steps_per_epoch=train_x.shape[0]//batch_size,\n          epochs=50,callbacks= [checkpoint,learning_rate_reduction],\n          validation_data=datagen.flow(val_x,val_y,batch_size=batch_size),\n                           validation_steps = val_x.shape[0]//batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtain predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = np.array(test_data.iloc[:,1:])\ntest_index = np.array(test_data.iloc[:,0])\nnum_images = test_data.shape[0]\ntest_x = test_x.reshape(num_images, img_rows, img_cols, 1)\ntest_x = test_x / 255\nkannada_model.load_weights('bestmodel.model')\npreds = kannada_model.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"format submissions"},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions = np.zeros((len(preds),2),dtype=int)\nfor ix in range(preds.shape[0]):\n    submissions[ix][0] = test_index[ix]\n    submissions[ix][1] = np.argmax(preds[ix])\nprint(submissions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert to csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions_pd = pd.DataFrame(data=submissions,columns=[\"id\",\"label\"])\nsubmissions_pd.head()\nsubmissions_pd.to_csv(\"submissions.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}