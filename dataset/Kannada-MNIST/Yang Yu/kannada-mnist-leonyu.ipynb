{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom keras.models import Sequential, load_model\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.callbacks import ModelCheckpoint,History,EarlyStopping,LearningRateScheduler\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam, Adadelta, RMSprop\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\nprint(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dig_data = pd.read_csv(\"/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\")\nprint(dig_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dig_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validate_data = train_data[55000:]\n# find label column\ntrain_label = np.float32(train_data.label)\nvalidate_label = np.float32(validate_data.label)\ntest_label = np.float32(test_data.id)\ndig_label = np.float32(dig_data.label)\n\n# find image values \ntrain_image = np.float32(train_data[train_data.columns[1:]])\nvalidate_image = np.float32(validate_data[validate_data.columns[1:]])\ntest_image = np.float32(test_data[test_data.columns[1:]])\ndig_image = np.float32(dig_data[dig_data.columns[1:]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_data shape:%s' %str(train_data.shape))\nprint('validate_data shape:%s' %str(validate_data.shape))\nprint('train_label shape:%s' %str(train_label.shape))\nprint('validate_label shape:%s' %str(validate_label.shape))\nprint('test_label shape:%s' %str(test_label.shape))\nprint('dig_label shape:%s' %str(dig_label.shape))\nprint('train_image shape:%s' %str(train_image.shape))\nprint('validate_image shape:%s' %str(validate_image.shape))\nprint('test_image shape:%s' %str(test_image.shape))\nprint('dig_image shape:%s' %str(dig_image.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We use Keras ImageDataGenerator to increase our training set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range = 10,\n    horizontal_flip = False,\n    zoom_range = 0.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. ** we can use One hot encode method to change label **\n2. ** we change label column to (..,10) type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import OneHotEncoder\n# encoder = OneHotEncoder(sparse=False,categories='auto')\n# yy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n# encoder.fit(yy)\n\n# # transform\n# train_label = train_label.reshape(-1,1)\n# validate_label = validate_label.reshape(-1,1)\n\n# dig_label = dig_label.reshape(-1,1)\n\n# train_label_transform = encoder.transform(train_label)\n# validate_label_transform = encoder.transform(validate_label)\n\n# dig_label_transform = encoder.transform(dig_label)\n\n# print('train_label_transform shape: %s'%str(train_label_transform.shape))\n# print('validate_label_transform shape: %s'%str(validate_label_transform.shape))\n# print('dig_label_transform shape: %s'%str(dig_label_transform.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Also we can use kears to_categorical method to change label**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label_transform = to_categorical(train_data.iloc[:,0])\nvalidate_label_transform = to_categorical(validate_data.iloc[:,0])\ndig_label_transform = to_categorical(dig_data.iloc[:,0])\n\nprint('train_label_transform shape: %s'%str(train_label_transform.shape))\nprint('validate_label_transform shape: %s'%str(validate_label_transform.shape))\nprint('dig_label_transform shape: %s'%str(dig_label_transform.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**see the MNIST picture**"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_row = 1\nn_col = 10\n\nplt.figure(figsize=(13,12))\nfor i in list(range(n_row * n_col)):\n    offset =0\n    plt.subplot(n_row, n_col, i+1)\n    plt.imshow(train_image[i].reshape(28,28))\n    title_text = 'Eigenvalue ' + str(i + 1)\n    plt.title(title_text, size=6.5)\n    plt.xticks(())\n    plt.yticks(())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image = train_image / 255.0\nvalidate_image = validate_image / 255.0\ntest_image = test_image / 255.0\ndig_image = dig_image / 255.0\n\ntrain_image_reshape = train_image.reshape(train_image.shape[0],28,28,1)\nvalidate_image_reshape = validate_image.reshape(validate_image.shape[0],28,28,1)\ntest_image_reshape = test_image.reshape(test_image.shape[0],28,28,1)\ndig_image_reshape = dig_image.reshape(dig_image.shape[0],28,28,1)\n\nprint('train_image_reshape shape %s' %str(train_image_reshape.shape))\nprint('validate_image_reshape shape %s' %str(validate_image_reshape.shape))\nprint('test_image_reshape shape %s' %str(test_image_reshape.shape))\nprint('dig_image_reshape shape %s' %str(dig_image_reshape.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bulid the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1),padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 512\nEPOCHS = 60\n#EPOCHS = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer=Adadelta(),metrics=['accuracy'])\n# fit data\ndatagen.fit(train_image_reshape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training\nhistory = model.fit_generator(datagen.flow(train_image_reshape,train_label_transform, batch_size=BATCH_SIZE),\n                              epochs = EPOCHS,\n                              shuffle=True,\n                              validation_data = (validate_image_reshape,validate_label_transform),\n                              verbose = 1,\n                              steps_per_epoch=train_image_reshape.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Verify DIG MNIST data set accuracy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_dig = history.model.predict_classes(dig_image_reshape)\nprint(metrics.accuracy_score(pred_dig, np.argmax(dig_label_transform, axis = 1)))\nprint(metrics.accuracy_score(pred_dig, dig_label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Verify accuracy from validate data of train data set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"validate_labels = []\nfor i in validate_label_transform:\n    for j, val in enumerate(i):\n        if val == 0.:\n            pass\n        else:\n            validate_labels.append(j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_validate = history.model.predict_classes(validate_image_reshape)\nmetrics.accuracy_score(pred_validate, np.array(validate_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**data Visualization for accuracy **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**data Visualization for loss **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = history.model.predict_classes(test_image_reshape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['label'] = pred_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}