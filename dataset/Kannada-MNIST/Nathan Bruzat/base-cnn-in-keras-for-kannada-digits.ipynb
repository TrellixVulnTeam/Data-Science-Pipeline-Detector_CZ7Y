{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport keras\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest = pd.read_csv(\"/kaggle/input/Kannada-MNIST/test.csv\")\nDig_MNIST = pd.read_csv(\"/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(\"/kaggle/input/Kannada-MNIST/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train set shape = \" +str(train.shape))\nprint(\"Test set shape = \" +str(test.shape))\nprint(\"Dif set shape = \" +str(Dig_MNIST.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We slice the dataframes to define the features and the labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.iloc[:,1:].values \nY=train.iloc[:,0].values \nY[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we must reshape the date to make it Keras friendly."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.reshape(X.shape[0], 28, 28,1) \nprint(X.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we convert the labels to categorical."},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = keras.utils.to_categorical(Y, 10) \nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test=test.drop('id', axis=1).iloc[:,:].values\nx_test = x_test.reshape(x_test.shape[0], 28, 28,1)\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dig_MNIST.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_dig=Dig_MNIST.iloc[:,1:].values \nY_dig=Dig_MNIST.iloc[:,0].values \nX_dig = X_dig.reshape(X_dig.shape[0], 28, 28,1)\nY_dig = keras.utils.to_categorical(Y_dig, 10) \nprint(X_dig.shape,Y_dig.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We split the data into training and validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size = 0.10, random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use Keras ImageDataGenerator to artificially increase our training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 10,\n                                   width_shift_range = 0.25,\n                                   height_shift_range = 0.25,\n                                   shear_range = 0.1,\n                                   zoom_range = 0.25,\n                                   horizontal_flip = False,\n                                   vertical_flip = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen = ImageDataGenerator(rescale=1./255.) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# trainning part"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = Input(shape=(28,28,1,))\nf = Flatten()(a)\nb = Dense(128, activation=\"relu\")(f)\nb = Dense(10, activation=\"softmax\")(b)\nsimple_model = Model(inputs=a, outputs=b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\nhistory = simple_model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=batch_size), validation_data=valid_datagen.flow(X_valid, Y_valid, batch_size=batch_size),  epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalu = simple_model.evaluate_generator(valid_datagen.flow(X_dig, Y_dig, batch_size=batch_size))\nprint(\"loss : \" + str(evalu[0]))\nprint(\"accuracy : \" + str(evalu[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Test accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Test loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convolution\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = Input(shape=(28,28,1,))\nc = Conv2D(128, (3,3), activation=\"relu\")(a)\nc = Conv2D(128, (3,3), activation=\"relu\")(c)\nc = Conv2D(128, (3,3), activation=\"relu\")(c)\nf = Flatten()(c)\nb = Dense(128, activation=\"relu\")(f)\nb = Dense(10, activation=\"softmax\")(b)\nconv_model = Model(inputs=a, outputs=b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\nhistory = conv_model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=batch_size), validation_data=valid_datagen.flow(X_valid, Y_valid, batch_size=batch_size),  epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalu = conv_model.evaluate_generator(valid_datagen.flow(X_dig, Y_dig, batch_size=batch_size))\nprint(\"loss : \" + str(evalu[0]))\nprint(\"accuracy : \" + str(evalu[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Test accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Test loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hard model"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = Input(shape=(28,28,1,))\nc = Conv2D(128, (3,3), activation=\"relu\", padding='same', bias=False)(a)\nc = MaxPooling2D()(c)\nc = BatchNormalization()(c)\nc = Conv2D(128, (3,3), activation=\"relu\", padding='same', bias=False)(c)\nc = MaxPooling2D()(c)\nc = BatchNormalization()(c)\nc = Conv2D(128, (3,3), activation=\"relu\", padding='same', bias=False)(c)\nc = MaxPooling2D()(c)\nc = BatchNormalization()(c)\nf = Flatten()(c)\nb = Dropout(0.5)(f)\nb = Dense(128, activation=\"relu\", bias=False)(b)\nb = BatchNormalization()(b)\nb = Dropout(0.5)(b)\nb = Dense(128, activation=\"relu\", bias=False)(b)\nb = BatchNormalization()(b)\nb = Dense(10, activation=\"softmax\")(b)\nhard_model = Model(inputs=a, outputs=b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hard_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\nhistory = hard_model.fit_generator(train_datagen.flow(X, Y, batch_size=batch_size), validation_data=valid_datagen.flow(X_dig, Y_dig, batch_size=batch_size),  epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalu = hard_model.evaluate_generator(valid_datagen.flow(X_dig, Y_dig))\nprint(\"loss : \" + str(evalu[0]))\nprint(\"accuracy : \" + str(evalu[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Test accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Test loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hardmodel merge dig+train"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_merg = np.concatenate((X, X_dig))\nY_merg = np.concatenate((Y, Y_dig))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_merg_train, X_merg_valid, Y_merg_train, Y_merg_valid = train_test_split(X_merg, Y_merg, test_size = 0.20, random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = Input(shape=(28,28,1,))\nc = Conv2D(128, (3,3), activation=\"relu\", padding='same', bias=False)(a)\nc = MaxPooling2D()(c)\nc = BatchNormalization()(c)\nc = Conv2D(128, (3,3), activation=\"relu\", padding='same', bias=False)(c)\nc = MaxPooling2D()(c)\nc = BatchNormalization()(c)\nc = Conv2D(128, (3,3), activation=\"relu\", padding='same', bias=False)(c)\nc = MaxPooling2D()(c)\nc = BatchNormalization()(c)\nf = Flatten()(c)\nb = Dropout(0.5)(f)\nb = Dense(128, activation=\"relu\", bias=False)(b)\nb = BatchNormalization()(b)\nb = Dropout(0.5)(b)\nb = Dense(128, activation=\"relu\", bias=False)(b)\nb = BatchNormalization()(b)\nb = Dense(10, activation=\"softmax\")(b)\nhard_model = Model(inputs=a, outputs=b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hard_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\nhistory = hard_model.fit_generator(train_datagen.flow(X_merg_train, Y_merg_train, batch_size=batch_size), validation_data=valid_datagen.flow(X_merg_valid, Y_merg_valid, batch_size=batch_size),  epochs=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalu = hard_model.evaluate_generator(valid_datagen.flow(X_dig, Y_dig))\nprint(\"loss : \" + str(evalu[0]))\nprint(\"accuracy : \" + str(evalu[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Test accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Test loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submite"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = hard_model.predict(x_test/255.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['label'] = np.argmax(predictions, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}