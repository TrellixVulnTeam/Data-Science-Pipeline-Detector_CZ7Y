{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport csv\n\nimport tensorflow as tf\nfrom keras.engine.input_layer import Input\nfrom keras.layers import *\nfrom keras.models import Model\nimport keras\n\ndef cnn_model():\n    inp = tf.keras.Input(shape=(28,28,1))\n    x1 = tf.keras.layers.Conv2D(128, (1,1), strides=(1,1), activation='relu')(inp)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x3 = tf.keras.layers.Conv2D(128, (3,3), padding='same', strides=(1,1), activation='relu')(inp)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x5 = tf.keras.layers.Conv2D(128, (5,5), padding='same', strides=(1,1), activation='relu')(inp)\n    x5 = tf.keras.layers.BatchNormalization()(x5)\n\n    averaged = tf.keras.layers.Average()([x1,x3,x5])\n    averaged = tf.keras.layers.Activation('relu')(averaged)\n    averaged = tf.keras.layers.BatchNormalization()(averaged)\n\n    x = tf.keras.layers.Conv2D(128, (5,5), strides=(1,1), activation='relu')(averaged)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Dropout(rate=0.25)(x)\n    first_block_out = tf.keras.layers.Flatten()(x)\n\n\n    x1 = tf.keras.layers.Conv2D(128, (1,1), strides=(1,1), activation='relu')(x)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x3 = tf.keras.layers.Conv2D(128, (3,3), padding='same', strides=(1,1), activation='relu')(x)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x5 = tf.keras.layers.Conv2D(128, (5,5), padding='same', strides=(1,1), activation='relu')(x)\n    x5 = tf.keras.layers.BatchNormalization()(x5)\n\n    averaged = tf.keras.layers.Average()([x1,x3,x5])\n    averaged = tf.keras.layers.Activation('relu')(averaged)\n    averaged = tf.keras.layers.BatchNormalization()(averaged)\n\n    x = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), activation='relu')(averaged)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Dropout(rate=0.25)(x)\n    second_block_out = tf.keras.layers.Flatten()(x)\n\n    x1 = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), activation='relu')(x)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x3 = tf.keras.layers.Conv2D(256, (3,3), padding='same', strides=(1,1), activation='relu')(x)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x5 = tf.keras.layers.Conv2D(256, (5,5), padding='same', strides=(1,1), activation='relu')(x)\n    x5 = tf.keras.layers.BatchNormalization()(x5)\n\n    averaged = tf.keras.layers.Average()([x1,x3,x5])\n    averaged = tf.keras.layers.Activation('relu')(averaged)\n    averaged = tf.keras.layers.BatchNormalization()(averaged)\n\n    x = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), activation='relu')(averaged)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Dropout(rate=0.25)(x)\n    third_block_out = tf.keras.layers.Flatten()(x)\n    \n    x1 = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), activation='relu')(x)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x3 = tf.keras.layers.Conv2D(256, (3,3), padding='same', strides=(1,1), activation='relu')(x)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x5 = tf.keras.layers.Conv2D(256, (5,5), padding='same', strides=(1,1), activation='relu')(x)\n    x5 = tf.keras.layers.BatchNormalization()(x5)\n\n    averaged = tf.keras.layers.Average()([x1,x3,x5])\n    averaged = tf.keras.layers.Activation('relu')(averaged)\n    averaged = tf.keras.layers.BatchNormalization()(averaged)\n\n    x = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), activation='relu')(averaged)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Dropout(rate=0.25)(x)\n    fourth_block_out = tf.keras.layers.Flatten()(x)\n    \n    print(first_block_out.shape, second_block_out.shape, third_block_out.shape, fourth_block_out.shape)\n    #x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Concatenate()([second_block_out, third_block_out, fourth_block_out])\n    x = tf.keras.layers.Dense(512, activation=tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(256, activation=tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(64, activation=tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    \n    output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n\n    model = tf.keras.Model(inputs=inp, outputs=output)\n    return model\n\n# here the paths are\n# /kaggle/input/Kannada-MNIST/train.csv\n# /kaggle/input/Kannada-MNIST/Dig-MNIST.csv\n# /kaggle/input/Kannada-MNIST/test.csv\n# /kaggle/input/Kannada-MNIST/sample_submission.csv\n\n# file_paths\ntrain_file = \"/kaggle/input/Kannada-MNIST/train.csv\"\nvalidate_file = \"/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\"\ntest_file = \"/kaggle/input/Kannada-MNIST/test.csv\"\n\n#train\ndata = pd.read_csv(train_file)\ndata_numpy = np.array(data)\nprint(data_numpy.shape)\n\n# (60000, 785) -> (60000, 1)\n# pull one column out and whole image\ndata_numpy_label = data_numpy[:,0]\ndata_numpy_image = data_numpy[:,1:]\n\ndata_numpy_label = data_numpy_label.reshape(60000, 1)\nprint(data_numpy_label.shape)\nprint(data_numpy_image.shape)\n\n# (60000, 784) => (60000, 28, 28)\ndata_numpy_image_28x28 = data_numpy_image.reshape(60000, 28, 28)\nprint(data_numpy_image_28x28.shape)\n\n# visualize the images formed\n# image -> (0, 255) (unsigned integer 8)\n\nprint(type(data_numpy_image_28x28[0][0][0]))\ndata_numpy_image_28x28 = data_numpy_image_28x28.astype(np.uint8)\n\nprint(type(data_numpy_image_28x28[0][0][0]))\n# now, (60000, 28, 28) => which is of <class 'numpy.uint8'>\n\n# for cnt, i in enumerate(data_numpy_image_28x28):\n#     # just see this is from image processing\n#     label = data_numpy_label[cnt][0]\n#     #print(label)\n#     cv2.imshow(\"image_window\", i)\n#     if cv2.waitKey(0) == 27:\n#         break\n# cv2.destroyAllWindows()\n\n#validate_\nvalidate_data = pd.read_csv(validate_file)\nvalidate_data_numpy = np.array(validate_data)\nprint(validate_data_numpy.shape)\n\n# (10240, 785) -> (10240, 1)\n# pull one column out and whole image\nvalidate_data_numpy_label = validate_data_numpy[:,0]\nvalidate_data_numpy_image = validate_data_numpy[:,1:]\n\nvalidate_data_numpy_label = validate_data_numpy_label.reshape(10240, 1)\nprint(validate_data_numpy_label.shape)\nprint(validate_data_numpy_image.shape)\n\n# (10240, 784) => (10240, 28, 28)\nvalidate_data_numpy_image_28x28 = validate_data_numpy_image.reshape(10240, 28, 28)\nprint(validate_data_numpy_image_28x28.shape)\n\nvalidate_data_numpy_image = validate_data_numpy_image.astype(np.float32)\nvalidate_data_numpy_label = validate_data_numpy_label.astype(np.float32)\n\n#test\ntest_data = pd.read_csv(test_file)\ntest_data_numpy = np.array(test_data)\nprint(test_data_numpy.shape)\n\n# (5000, 785) -> (5000, 1)\n# pull one column out and whole image\ntest_data_numpy_label = test_data_numpy[:,0]\ntest_data_numpy_image = test_data_numpy[:,1:]\n\ntest_data_numpy_label = test_data_numpy_label.reshape(-1, 1)\nprint(test_data_numpy_label.shape)\nprint(test_data_numpy_image.shape)\n\n# (60000, 784) => (5000, 28, 28)\ntest_data_numpy_image_28x28 = test_data_numpy_image.reshape(-1, 28, 28)\nprint(test_data_numpy_image_28x28.shape)\n\ntest_data_numpy_image = test_data_numpy_image.astype(np.float32)\ntest_data_numpy_label = test_data_numpy_label.astype(np.float32)\n\ndata_numpy_image_28x28 = data_numpy_image_28x28.astype(np.float32)\ndata_numpy_image = data_numpy_image.astype(np.float32)\n\n# now what we have,....\n# data_numpy_image -> (60000, 784) -> (float32)\n# data_numpy_image_28x28 -> (60000, 28, 28) -> (float32)\n# data_numpy_label -> (60000, 1) -> (int)\n\n\n# machine learning starts from here\n\n# 1. Linear regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import LinearSVC\n\n\n#reg = LinearRegression().fit(data_numpy_image, data_numpy_label)\n#reg = ElasticNet(random_state=0).fit(data_numpy_image, data_numpy_label)\nreg = LinearSVC(random_state=0, tol=1e-5).fit(data_numpy_image, data_numpy_label)\n\nscore = reg.score(data_numpy_image, data_numpy_label)\nprint(score)\n\n\n\n# 1. Linear regression\nprint(reg.get_params())\n\npredict_label = reg.predict(validate_data_numpy_image)\nprint(predict_label.shape)\n\ncorrect = 0\ntotal = 0\nfor i in range(len(predict_label)):\n    pred_label = predict_label[i]\n    ground_truth_label = validate_data_numpy_label[i][0]\n    #print(round(pred_label),\"\\t\", ground_truth_label)\n    \n    if int(round(pred_label)) == int(ground_truth_label):\n        correct += 1\n    total += 1\nprint(\"correct / total, %\", correct, total, correct*100./total, \"%\")\n\ntest_label = reg.predict(test_data_numpy_image)\nprint(test_label.shape)\n\n# result = []\n# for i in range(len(test_label)):\n#     pred_label = test_label[i]\n#     output_got = int(round(pred_label))\n#     result.append([i, output_got])\n# result = np.append(np.array([['id', 'label']]), result, axis=0)\n# print(result.shape)\n\n# with open(\"submission.csv\", 'w', newline='') as csvfile:\n#     spamwriter = csv.writer(csvfile)\n#     for r in result:\n#         spamwriter.writerow(r)\n\nfrom keras.engine.input_layer import Input\nfrom keras.layers import *\nfrom keras.models import Model\nimport keras\n\n# input : (60000, 28, 28) => output (60000, 1)\nx_inp = Input(shape=(28,28,1)) # shape -> (?, 28, 28)\nx = Conv2D(filters=64, kernel_size=((3,3)), strides=(1, 1), padding='valid', activation='tanh')(x_inp)\nx = Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='valid', activation='tanh')(x)\nx = Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='valid', activation='tanh')(x)\nx = Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='valid', activation='tanh')(x)\n\nx_flat = Flatten()(x)\n\n\nx_flat = Dense(256, activation='tanh')(x_flat)\nx_flat = Dropout(rate=0.3)(x_flat)\nx_flat = Dense(256, activation='tanh')(x_flat)\nx_flat = Dropout(rate=0.3)(x_flat)\nx4 = Dense(10, activation='softmax')(x_flat)\n\n# upto here, input: (?, 28, 28), output: (?, 10)\n\n#model = Model(inputs=x_inp, outputs=x4)\nmodel = cnn_model()\n\ndata_numpy_label_cate = keras.utils.to_categorical(data_numpy_label, num_classes=10, dtype='float32')\ndata_numpy_image_28x28 = np.expand_dims(data_numpy_image_28x28, axis=-1)\n\n# Sanity check\n# what you have till now\nprint(data_numpy_image_28x28.shape, data_numpy_image_28x28.dtype)\nprint(data_numpy_label_cate.shape, data_numpy_label_cate.dtype)\n\n# required for the model\nprint(model.input_shape, model.output_shape)\n\nmodel.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy', 'mse'])\n\n# fit the model\nmodel.fit(x=data_numpy_image_28x28, y=data_numpy_label_cate, batch_size=64, epochs=15, verbose=1, validation_split=0.1)\n\n# sanity check of shapes, of validation data\nvalidate_data_numpy_image_28x28 = validate_data_numpy_image_28x28.astype(np.float32)\nvalidate_data_numpy_image_28x28 = np.expand_dims(validate_data_numpy_image_28x28, axis=-1)\nvalidate_data_numpy_label_cate = keras.utils.to_categorical(validate_data_numpy_label, num_classes=10, dtype='float32')\n\nprint(validate_data_numpy_image_28x28.shape, validate_data_numpy_image_28x28.dtype)\nprint(validate_data_numpy_label_cate.shape, validate_data_numpy_label_cate.dtype)\n\nresultss_validation=model.evaluate(validate_data_numpy_image_28x28, validate_data_numpy_label_cate, verbose=1)\nprint(model.metrics_names)\nprint(resultss_validation)\n\ntest_data_numpy_image_28x28 = test_data_numpy_image_28x28.astype(np.float32)\ntest_data_numpy_image_28x28_expnd = np.expand_dims(test_data_numpy_image_28x28, axis=-1)\n\ntest_label = model.predict(test_data_numpy_image_28x28_expnd)\nprint(test_label.shape)\n\nresult = []\nfor i in range(len(test_label)):\n    pred_label = np.argmax(test_label[i])\n    output_got = int(round(pred_label))\n    result.append([i, output_got])\nresult = np.append(np.array([['id', 'label']]), result, axis=0)\nprint(result.shape)\n\nwith open(\"submission.csv\", 'w', newline='') as csvfile:\n    spamwriter = csv.writer(csvfile)\n    for r in result:\n        spamwriter.writerow(r)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}