{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # to handle matrix and data operation\nimport pandas as pd # to read csv and handle dataframe\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch.utils.data import Dataset\nfrom torch.autograd import Variable\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport random\n\nuse_cuda=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetMNIST(Dataset):\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform=transforms.Compose([\n                            transforms.ToPILImage(),\n                           # Add random transformations to the image.\n                           transforms.RandomAffine(\n                               degrees=5, translate=(0.1, 0.2), scale=(0.55, 1.2),\n                               shear=(-20, 10, -20, 10)),\n\n                           transforms.ToTensor()\n                       ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = DatasetMNIST('/kaggle/input/Kannada-MNIST/train.csv', transform=transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(28, 28))\ncolumns = 12\nrows = 1\nfor i in range(1, columns*rows +1):\n    r=random.randint(2,int(len(train_dataset)/columns*rows))\n    img, lab = train_dataset.__getitem__(i*r)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img.squeeze())\n    plt.title(lab)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(15488, 10)\n#         self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.conv3(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n#         x = self.fc1(x)\n#         x = F.relu(x)\n        x = self.fc1(x)\n        output = F.log_softmax(x, dim=1)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\nmodel = net.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\n\noptimizer = torch.optim.Adam(model.parameters(),lr=0.001)#, momentum=0.9)\nerror = nn.CrossEntropyLoss()\nEPOCHS = 10\n\nmodel.train()\nfor epoch in range(EPOCHS):\n    correct = 0\n    running_loss=0\n    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n        var_X_batch = Variable(X_batch).float()\n        var_y_batch = Variable(y_batch)\n        var_X_batch = var_X_batch.cuda()\n        var_y_batch = var_y_batch.cuda()\n        optimizer.zero_grad()\n        output = model(var_X_batch)\n        loss = error(output, var_y_batch)\n        loss.backward()\n        optimizer.step()\n        running_loss+=loss.item()\n\n        # Total correct predictions\n        predicted = torch.max(output.data, 1)[1] \n        correct += (predicted == var_y_batch).sum()\n       \n    print('Epoch : {} \\t\\tLoss: {:.5f}\\t Accuracy:{:.2f}%'.format(\n                epoch, \n                100.*batch_idx / len(train_loader),\n                loss.item(), \n                float(correct*100) / float(batch_size*(batch_idx+1))))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}