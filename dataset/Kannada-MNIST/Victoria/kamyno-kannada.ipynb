{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport struct\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import *\nfrom keras.models import Sequential, load_model\nfrom keras.optimizers import *\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.callbacks import CSVLogger, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\n\nvalid_part = 10\ntest_id = test.id\ntest = test.drop('id', axis=1)\ny_train = train.label\nx_train = train.drop('label', axis=1)\n\ntrain_size = int(x_train.shape[0] / valid_part * (valid_part - 1))\nx_valid, y_valid = x_train[train_size:], y_train[train_size:]\nx_train, y_train = x_train[:train_size], y_train[:train_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(-1, 1))\n\nrows, cols = 28, 28\nx_train = x_train.astype('float32')\ntest = test.astype('float32')\n\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_valid = scaler.transform(x_valid)\ntest = scaler.transform(test)\nprint(x_train.min(), x_train.max())\n\nx_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\ntest = test.reshape(test.shape[0], rows, cols, 1)\nx_valid = x_valid.reshape(x_valid.shape[0], rows, cols, 1)\n\ny_train = keras.utils.to_categorical(y_train, 10)\ny_valid = keras.utils.to_categorical(y_valid, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range = 10,\n                                   shear_range = 0.1,\n                                   width_shift_range = 0.25,\n                                   height_shift_range = 0.25,\n                                   zoom_range = 0.25,\n                                   horizontal_flip = False)\nepochs = 40\nbatch_size = 1024\n\nmodel = Sequential()\nmodel.add(Conv2D(64,\n              kernel_size=(5, 5),\n              input_shape=(28, 28, 1),\n              padding='same'))  \nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Conv2D(64,\n              kernel_size=(3, 3),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Conv2D(64,\n              kernel_size=(3, 3),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128,\n              kernel_size=(5, 5),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Conv2D(128,\n              kernel_size=(3, 3),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Conv2D(128,\n              kernel_size=(3, 3),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(256,\n              kernel_size=(5, 5),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Conv2D(256,\n              kernel_size=(3, 3),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Conv2D(256,\n              kernel_size=(3, 3),\n              padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization(gamma_initializer='uniform', epsilon=0.0001, momentum=0.15))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n            optimizer=Adam(lr=0.001),\n            metrics=['accuracy'])\n\nmodel.fit_generator(\n  train_datagen.flow(x_train, y_train, batch_size=batch_size),\n  steps_per_epoch=100,\n  epochs=epochs,\n  callbacks=[CSVLogger('log.csv'), ModelCheckpoint('model.h5', save_best_only=True)],\n  validation_data=(x_valid, y_valid),\n  validation_steps=50,  \n  verbose=1)\n\nmodel = load_model('model.h5')\nlabel = model.predict(test)\nlabel = np.argmax(label, axis=1)\ndf = pd.DataFrame({'id': test_id, 'label': label})\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}