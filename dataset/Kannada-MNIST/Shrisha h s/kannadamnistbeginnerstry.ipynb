{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras as ks\nimport tensorflow as tf\nimport glob\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers\nimport time\nfrom IPython import display\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/Kannada-MNIST/train.csv')\ntest=pd.read_csv('../input/Kannada-MNIST/test.csv')\nsubmission_sample = pd.read_csv(\"../input/Kannada-MNIST/sample_submission.csv\")\ntrain_CNN=train\nGtrain=train\nlabel0=Gtrain.groupby('label').get_group(0)\nlabel1=Gtrain.groupby('label').get_group(1)\nlabel2=Gtrain.groupby('label').get_group(2)\nlabel3=Gtrain.groupby('label').get_group(3)\nlabel4=Gtrain.groupby('label').get_group(4)\nlabel5=Gtrain.groupby('label').get_group(5)\nlabel6=Gtrain.groupby('label').get_group(6)\nlabel7=Gtrain.groupby('label').get_group(7)\nlabel8=Gtrain.groupby('label').get_group(8)\nlabel9=Gtrain.groupby('label').get_group(9)\n#plt.imshow(test[4][,:,:0])\n\nX_label0=label0.drop('label',axis=1)\nX_label1=label1.drop('label',axis=1)\nX_label2=label2.drop('label',axis=1)\nX_label3=label3.drop('label',axis=1)\nX_label4=label4.drop('label',axis=1)\nX_label5=label5.drop('label',axis=1)\nX_label6=label6.drop('label',axis=1)\nX_label7=label7.drop('label',axis=1)\nX_label8=label8.drop('label',axis=1)\nX_label9=label9.drop('label',axis=1)\n\nY_label0=label0.label\nY_label1=label1.label\nY_label2=label2.label\nY_label3=label3.label\nY_label4=label4.label\nY_label5=label5.label\nY_label6=label6.label\nY_label7=label7.label\nY_label8=label8.label\nY_label9=label9.label\n\nX_label0=np.asarray(X_label0,dtype=np.float32).reshape(-1,28,28,1)\nX_label1=np.asarray(X_label1,dtype=np.float32).reshape(-1,28,28,1)\nX_label2=np.asarray(X_label2,dtype=np.float32).reshape(-1,28,28,1)\nX_label3=np.asarray(X_label3,dtype=np.float32).reshape(-1,28,28,1)\nX_label4=np.asarray(X_label4,dtype=np.float32).reshape(-1,28,28,1)\nX_label5=np.asarray(X_label5,dtype=np.float32).reshape(-1,28,28,1)\nX_label6=np.asarray(X_label6,dtype=np.float32).reshape(-1,28,28,1)\nX_label7=np.asarray(X_label7,dtype=np.float32).reshape(-1,28,28,1)\nX_label8=np.asarray(X_label8,dtype=np.float32).reshape(-1,28,28,1)\nX_label9=np.asarray(X_label9,dtype=np.float32).reshape(-1,28,28,1)\n#label1=Gtrain.get_group('1')\n\n#label1=Gtrain.get_group(\"1\")\n#print(label9)\n\n#train=np.array(train,dtype=np.float32)\n\ntest=test.drop('id',axis=1)\ny=train.label.value_counts()\n\nX_train=train.drop('label',axis=1)\nY_train=train.label\n\nX_train=np.array(X_train,dtype=np.float32)\nY_train=np.array(Y_train)\nX_train=X_train/255\ntest=test/255\n\nX_train=X_train.reshape(-1,28,28,1)\nnew_image_set=X_train\ntest=test.values.reshape(-1,28,28,1)\n\n#Y_train=to_categorical(Y_train)\n\nX_train,X_test,y_train,y_test=train_test_split(X_train,Y_train,random_state=42,test_size=0.15)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y_label0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_CNN_X=train_CNN.drop('label',axis=1)\ntrain_CNN_Y=train.label\n\ntrain_CNN_X=np.array(train_CNN_X,dtype=np.float32)\ntrain_CNN_Y=np.array(train_CNN_Y)\ntrain_CNN_X=train_CNN_X/255\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 6000\nBATCH_SIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_label0=np.asarray(X_label0).reshape(-1,28,28)\n#train_dataset = tf.data.Dataset.from_tensor_slices(X_label0).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 28, 28, 1)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint (decision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 75\nnoise_dim = 100\nnum_examples_to_generate = 6000\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # Produce images for the GIF as we go\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n    # Save the model every 15 epochs\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  # Generate after the final epoch\n  display.clear_output(wait=True)\n  new_images=generate_and_save_images(generator,\n                           epochs,\n                           seed)\n  return new_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n    new_images = model(test_input, training=False)\n    return new_images\n    #print(new_images[1].shape)\n    #new_images=np.asarray(new_images)\n    #new_images=np.reshape(16,28,28)\n   # plt.imshow(new_images[1].reshape(28,28))\n'''\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n    img = image.array_to_img(predictions[i] * 255., scale=False)\n    plt.figure()\n    plt.imshow(img)\n    plt.show()\n  '''      \n       # plt.subplot(4, 4, i+1)\n     # plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n     # plt.axis('off')\n\n # plt.savefig('image_at_epoch_{:01d}.png'.format(epoch))\n # plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%%time\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label0).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images0=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images1=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label2).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images2=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label3).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images3=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label4).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images4=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label5).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images5=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label6).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images6=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label7).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images7=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label8).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images8=train(train_dataset, EPOCHS)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(X_label9).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ngen_images9=train(train_dataset, EPOCHS)\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nprint(gen_images5.shape)\ngen_images5=np.asarray(gen_images5)\ngen_images5=gen_images5.reshape(-1,28,28)\nprint(gen_images5.shape)\nplt.imshow(gen_images5[5009])\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#print(gen_images.shape)\ngen_images0=np.asarray(gen_images0)\ngen_images0=gen_images0.reshape(-1,28,28,1)\nprint(gen_images0.shape)\n#plt.imshow(gen_images[3])\n\ngen_images1=np.asarray(gen_images1)\ngen_images1=gen_images1.reshape(-1,28,28,1)\nprint(gen_images1.shape)\n\ngen_images2=np.asarray(gen_images2)\ngen_images2=gen_images2.reshape(-1,28,28,1)\nprint(gen_images2.shape)\n\ngen_images3=np.asarray(gen_images3)\ngen_images3=gen_images3.reshape(-1,28,28,1)\nprint(gen_images3.shape)\n\ngen_images4=np.asarray(gen_images4)\ngen_images4=gen_images4.reshape(-1,28,28,1)\nprint(gen_images4.shape)\n\ngen_images5=np.asarray(gen_images5)\ngen_images5=gen_images5.reshape(-1,28,28,1)\nprint(gen_images5.shape)\n\ngen_images6=np.asarray(gen_images0)\ngen_images6=gen_images6.reshape(-1,28,28,1)\nprint(gen_images6.shape)\n\ngen_images7=np.asarray(gen_images7)\ngen_images7=gen_images7.reshape(-1,28,28,1)\nprint(gen_images7.shape)\n\ngen_images8=np.asarray(gen_images8)\ngen_images8=gen_images8.reshape(-1,28,28,1)\nprint(gen_images8.shape)\n\ngen_images9=np.asarray(gen_images9)\ngen_images9=gen_images9.reshape(-1,28,28,1)\nprint(gen_images0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_images=np.vstack((gen_images0,gen_images1,gen_images2,gen_images3,gen_images4,gen_images5,gen_images6,gen_images7,gen_images8,gen_images9))\nprint(gen_images.shape)\nY_labels=np.vstack((Y_label0,Y_label1,Y_label2,Y_label3,Y_label4,Y_label5,Y_label6,Y_label7,Y_label8,Y_label9,))\nY_labels=Y_labels.reshape(60000)\n#print(Y_labels[40000])\n#gen_images=gen_images.reshape(-1,28,28)\n#plt.imshow(gen_images[48000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_CNN_X=np.vstack((train_CNN_X.reshape(-1,28,28,1),gen_images.reshape(-1,28,28,1)))\nprint(train_CNN_X.shape)\ntrain_CNN_Y=np.vstack((train_CNN_Y,Y_labels))\ntrain_CNN_Y=train_CNN_Y.reshape(120000)\nprint(train_CNN_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.Conv2D(filters=32, kernel_size=(5, 5),padding='Same',activation='relu',input_shape=(28,28,1)),\n    keras.layers.Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',),\n    keras.layers.BatchNormalization(momentum=.15),\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    keras.layers.Dropout(0.25),\n    keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'),\n    keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'),\n    keras.layers.BatchNormalization(momentum=0.15),\n    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    keras.layers.Dropout(0.25),\n    keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)),\n    keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'),\n    keras.layers.BatchNormalization(momentum=.15),\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    keras.layers.Dropout(0.25),\n    keras.layers.Flatten(),\n    keras.layers.Dense(256, activation='relu'),\n    keras.layers.Dropout(0.4),\n    keras.layers.Dense(10, activation='softmax')\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_CNN_X=train_CNN_X.reshape(-1,28,28,1)\n\nmodel.fit(train_CNN_X, train_CNN_Y, epochs=75)\n\n#test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n#print('\\nTest accuracy:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#prediction=model.predict(gen_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#labels=np.argmax(prediction,axis=1)\n\n#print(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit(gen_images, labels, epochs=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1=test.reshape(-1,28,28,1)\nprediction1=model.predict(test1)\nprediction1=np.argmax(prediction1,axis=1)\n#print(prediction1)\nsubmission_sample['label']=prediction1\n#print(submission_sample.head(10))\nsubmission_sample.to_csv('submission.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}