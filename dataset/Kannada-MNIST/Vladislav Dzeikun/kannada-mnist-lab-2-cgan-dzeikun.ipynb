{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Conv2DTranspose, Dropout, Dense, Flatten, BatchNormalization, MaxPooling2D, AvgPool2D\nfrom keras.layers import Input, Lambda, UpSampling2D, concatenate, Activation, Embedding, Reshape, Concatenate, multiply\nfrom keras.optimizers import RMSprop, SGD, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import CSVLogger, ModelCheckpoint\nfrom keras.utils.np_utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\nDig_MNIST = pd.read_csv(\"../input/Kannada-MNIST/Dig-MNIST.csv\")\nsample_submission = pd.read_csv(\"../input/Kannada-MNIST/sample_submission.csv\")\ntest = pd.read_csv(\"../input/Kannada-MNIST/test.csv\")\ntrain = pd.read_csv(\"../input/Kannada-MNIST/train.csv\")\n\nx_train = train.drop('label', axis=1).to_numpy().reshape((60000, 28, 28))\ny_train = train['label'].to_numpy()\n\nimg_shape = (28, 28, 1)\nz_dim = 100\nnum_classes = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1 часть. Толерантно создаём генератор для генераций**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_generator(z_dim):\n    \n    model = Sequential()\n    model.add(Dense(7*7*256, input_shape=(z_dim, )))\n    model.add(Reshape((7, 7, 256)))\n    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n    model.add(Activation('tanh'))\n    \n    z = Input(shape=(z_dim, ))\n\n    label = Input(shape=(1,), dtype='int32')\n    \n    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n    \n    label_embedding = Flatten()(label_embedding)\n\n    joined_representation = multiply([z, label_embedding])\n    \n    img = model(joined_representation)\n    \n    return Model([z, label], img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2 часть. Нетолерантно создаём дискриминатор для дискриминаций**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator(img_shape):\n    \n    model = Sequential()\n    \n    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(28, 28, 2)))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    \n    img = Input(shape=img_shape)\n\n    label = Input(shape=(1,), dtype='int32')\n    \n    label_embedding = Embedding(input_dim=num_classes, output_dim=np.prod(img_shape), input_length=1)(label)\n    \n    label_embedding = Flatten()(label_embedding)\n    \n    label_embedding = Reshape(img_shape)(label_embedding)\n    \n    concatenated = Concatenate(axis=-1)([img, label_embedding])\n    \n    prediction = model(concatenated)\n    \n    return Model([img, label], prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3 часть. Коннектим это всё дело вместе**"},{"metadata":{"trusted":true},"cell_type":"code","source":"disc = build_discriminator(img_shape)\ndisc.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n\ngen = build_generator(z_dim)\nz = Input(shape=(z_dim,))\nlabel = Input(shape=(1,))\n\nimg = gen([z, label])\n\ndisc.trainable = False\n\nprediction = disc([img, label])\n\ncgan = Model([z, label], prediction)\ncgan.compile(loss='binary_crossentropy', optimizer=Adam())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Чуть-чуть красоты**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_images(image_grid_rows=2, image_grid_columns=5):\n    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n    labels = np.arange(0, 10).reshape(-1, 1)\n    gen_imgs = gen.predict([z, labels])\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(10,4), sharey=True, sharex=True)\n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            axs[i,j].set_title(\"Digit: %d\" % labels[cnt])\n            cnt += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Часть 4. Тренировочки**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = []\nlosses = []\n\ndef train(iterations, batch_size, sample_interval):\n    \n    X_train = (x_train - 127.5) / 127.5\n    X_train = np.expand_dims(X_train, axis=3)\n    \n    real = np.ones(shape=(batch_size, 1))\n    fake = np.zeros(shape=(batch_size, 1))\n    \n    for iteration in range(iterations):\n        \n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs, labels = X_train[idx], y_train[idx]\n        \n        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n        gen_imgs = gen.predict([z, labels])\n        \n        d_loss_real = disc.train_on_batch([imgs, labels], real)\n        d_loss_fake = disc.train_on_batch([gen_imgs, labels], fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n        \n        g_loss = cgan.train_on_batch([z, labels], real)\n        \n        if iteration % sample_interval == 0:\n            print('{} [D loss: {}, accuracy: {:.2f}] [G loss: {}]'.format(iteration, d_loss[0], 100 * d_loss[1], g_loss))\n        \n            losses.append((d_loss[0], g_loss))\n            accuracies.append(d_loss[1])\n            \n            sample_images()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Проверяем, что всё работает**"},{"metadata":{"trusted":true},"cell_type":"code","source":"iterations = 40000\nbatch_size = 64\nsample_interval = 1000\n\ntrain(iterations, batch_size, sample_interval)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}