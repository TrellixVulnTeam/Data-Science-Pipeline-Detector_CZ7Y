{"cells":[{"metadata":{},"cell_type":"markdown","source":"# If this kernel helps you fortunately, please upvote it. Thanks you. :)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom keras.models import Sequential, load_model\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.callbacks import ModelCheckpoint,History,EarlyStopping,LearningRateScheduler\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam, Adadelta, RMSprop\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Divide data into training and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data[:]\nval = data[55000:]\ntrain_label = np.float32(train.label)\nval_label = np.float32(val.label)\ntrain_image = np.float32(train[train.columns[1:]])\nval_image = np.float32(val[val.columns[1:]])\ntest_image = np.float32(test_data[test_data.columns[1:]])\nprint('train shape: %s'%str(train.shape))\nprint('val shape: %s'%str(val.shape))\nprint('train_label shape: %s'%str(train_label.shape))\nprint('val_label shape: %s'%str(val_label.shape))\nprint('train_image shape: %s'%str(train_image.shape))\nprint('val_image shape: %s'%str(val_image.shape))\nprint('test_image shape: %s'%str(test_image.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data enhancement"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range = 10,\n    horizontal_flip = False,\n    zoom_range = 0.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One-hot encode"},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot coding\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False,categories='auto')\nyy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\nencoder.fit(yy)\n# transform\ntrain_label = train_label.reshape(-1,1)\nval_label = val_label.reshape(-1,1)\n\ntrain_label = encoder.transform(train_label)\nval_label = encoder.transform(val_label)\n\nprint('train_label shape: %s'%str(train_label.shape))\nprint('val_label shape: %s'%str(val_label.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_image[13].reshape(28,28))\nplt.show()\nprint(train_image[13].shape)\n\ntrain_image = train_image/255.0\nval_image = val_image/255.0\ntest_image = test_image/255.0\n\ntrain_image = train_image.reshape(train_image.shape[0],28,28,1)\nval_image = val_image.reshape(val_image.shape[0],28,28,1)\ntest_image = test_image.reshape(test_image.shape[0],28,28,1)\nprint('train_image shape: %s'%str(train_image.shape))\n\nprint('train_image shape: %s'%str(train_image.shape))\nprint('val_image shape: %s'%str(val_image.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1),padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 512\nEPOCHS = 60","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer=Adadelta(),metrics=['accuracy'])\n# fit data\ndatagen.fit(train_image)\n\n# training\nhistory = model.fit_generator(datagen.flow(train_image,train_label, batch_size=BATCH_SIZE),\n                              epochs = EPOCHS,\n                              shuffle=True,\n                              validation_data = (val_image,val_label),\n                              verbose = 1,\n                              steps_per_epoch=train_image.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 绘制训练 & 验证的准确率值\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# 绘制训练 & 验证的损失值\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_label = model.predict(test_image)\n# label = np.argmax(label_hot,1)\n# id_ = np.arange(0,label.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_hot = model.predict(test_image)\nlabel = np.argmax(label_hot,1)\nid_ = np.arange(0,label.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sim = pd.read_csv('/kaggle/input/Kannada-MNIST/sample_submission.csv')\nprint(sim.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save = pd.DataFrame({'id':id_,'label':label})\nprint(save.head(10))\nsave.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}