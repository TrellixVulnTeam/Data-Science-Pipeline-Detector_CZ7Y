{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Calculate mean and std for entire dataset\nWhen scaling the input data during preprocessing, it is common practice to normalize data with a fixed mean and std (rather than individual on file level). So here we will simply calculate mean and std for each detector using [Welfordâ€™s algorithm](https://pypi.org/project/welford/) across the entire dataset.","metadata":{}},{"cell_type":"code","source":"!pip install welford --user","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-19T14:36:21.951239Z","iopub.execute_input":"2021-08-19T14:36:21.951607Z","iopub.status.idle":"2021-08-19T14:36:32.46797Z","shell.execute_reply.started":"2021-08-19T14:36:21.951578Z","shell.execute_reply":"2021-08-19T14:36:32.466797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom welford import Welford\nimport glob\nimport json\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport tensorflow_datasets as tfds","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:36:32.469913Z","iopub.execute_input":"2021-08-19T14:36:32.470219Z","iopub.status.idle":"2021-08-19T14:36:39.518082Z","shell.execute_reply.started":"2021-08-19T14:36:32.470182Z","shell.execute_reply":"2021-08-19T14:36:39.516894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train dataset\nWe create a tensorflow dataset here, not because we need to - just to practice.","metadata":{}},{"cell_type":"code","source":"train_files = glob.glob('../input/g2net-gravitational-wave-detection/train/*/*/*/*.npy')","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:36:39.519826Z","iopub.execute_input":"2021-08-19T14:36:39.520114Z","iopub.status.idle":"2021-08-19T14:39:19.502924Z","shell.execute_reply.started":"2021-08-19T14:36:39.520087Z","shell.execute_reply":"2021-08-19T14:39:19.50198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 1\n\ndef _parse_function1(filename):\n    np_data = tf.io.read_file(filename)\n    np_data = tf.strings.substr(np_data, 128, 98304) # header is 128 bytes (skip)\n    np_data = tf.reshape(tf.io.decode_raw(np_data, tf.float64), (3, 4096))\n    return np_data\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(train_files)\ntrain_ds = train_ds.map(_parse_function1, num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:39:19.504235Z","iopub.execute_input":"2021-08-19T14:39:19.504709Z","iopub.status.idle":"2021-08-19T14:39:21.754589Z","shell.execute_reply.started":"2021-08-19T14:39:19.504666Z","shell.execute_reply":"2021-08-19T14:39:21.753713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Welford library is actually super slow, much faster to use a TF implementation here. But we first calculate mean and variance for a subset with the slow and the fast implementation as a quality check of the TF version.","metadata":{}},{"cell_type":"code","source":"w0 = Welford()\nw1 = Welford()\nw2 = Welford()\n\nCHK_COUNT = 25000\n\nfor i in tqdm(range(CHK_COUNT)):\n    d = np.load(train_files[i])\n    w0.add_all(np.expand_dims(d[0], axis = 1))\n    w1.add_all(np.expand_dims(d[1], axis = 1))\n    w2.add_all(np.expand_dims(d[2], axis = 1))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:39:21.755989Z","iopub.execute_input":"2021-08-19T14:39:21.756385Z","iopub.status.idle":"2021-08-19T14:41:27.255776Z","shell.execute_reply.started":"2021-08-19T14:39:21.756344Z","shell.execute_reply":"2021-08-19T14:41:27.254743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then the TF implementation:","metadata":{}},{"cell_type":"code","source":"def tf_welford(ds, cnt_limit=-1):\n    ds_numpy = tfds.as_numpy(ds)\n    w_mean = np.zeros(3, dtype=np.float64)\n    w_var = np.zeros(3, dtype=np.float64)\n    sumsq = np.zeros(3, dtype=np.float64)\n    cnt = 0.0\n    for da in tqdm(ds_numpy):\n        cnt += 1.0\n        for j in range(3):\n            x = da[0,j]\n            delta = tf.math.reduce_mean(x - w_mean[j]).numpy()\n            w_mean[j] += delta / cnt\n            # variance calculation deviates a little from Welford as it uses a batch of 4096 \n            sumsq[j] += tf.math.reduce_sum(tf.math.multiply(x, x)).numpy()\n            w_var[j] = (sumsq[j]/(cnt*4096.)) - w_mean[j]*w_mean[j]\n    \n        if cnt == float(cnt_limit):\n            break \n    return w_mean, w_var","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:41:30.318035Z","iopub.execute_input":"2021-08-19T14:41:30.318393Z","iopub.status.idle":"2021-08-19T14:41:30.328489Z","shell.execute_reply.started":"2021-08-19T14:41:30.318364Z","shell.execute_reply":"2021-08-19T14:41:30.326887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w1_mean, w1_var = tf_welford(train_ds, CHK_COUNT)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:41:44.056185Z","iopub.execute_input":"2021-08-19T14:41:44.056548Z","iopub.status.idle":"2021-08-19T14:41:45.299479Z","shell.execute_reply.started":"2021-08-19T14:41:44.056504Z","shell.execute_reply":"2021-08-19T14:41:45.298489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's compare the values computed by the two implementations:","metadata":{}},{"cell_type":"code","source":"stats = [[w0.mean[0], w1_mean[0], w0.mean[0]/w1_mean[0], w0.var_s[0], w1_var[0], w0.var_s[0]/w1_var[0]],\n         [w1.mean[0], w1_mean[1], w1.mean[0]/w1_mean[1], w1.var_s[0], w1_var[1], w1.var_s[0]/w1_var[1]],\n         [w2.mean[0], w1_mean[2], w2.mean[0]/w1_mean[2], w2.var_s[0], w1_var[2], w2.var_s[0]/w1_var[2]]]\ndfs = pd.DataFrame(stats, columns=['PyPI mean', 'TF mean', 'PyPi/TF mean ratio', 'PyPI var', 'TF var', 'PyPi/TF var ratio'])\ndfs","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-19T14:41:49.401647Z","iopub.execute_input":"2021-08-19T14:41:49.402021Z","iopub.status.idle":"2021-08-19T14:41:49.444618Z","shell.execute_reply.started":"2021-08-19T14:41:49.401987Z","shell.execute_reply":"2021-08-19T14:41:49.443344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yes, happy with that - good enough for this purpose! Now run through the entire train dataset:","metadata":{}},{"cell_type":"code","source":"w1_mean, w1_var = tf_welford(train_ds)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:44:47.27966Z","iopub.execute_input":"2021-08-19T14:44:47.27995Z","iopub.status.idle":"2021-08-19T14:44:57.976585Z","shell.execute_reply.started":"2021-08-19T14:44:47.27992Z","shell.execute_reply":"2021-08-19T14:44:57.975618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Store the mean and std in a json file for use in other notebooks:","metadata":{}},{"cell_type":"code","source":"train_stats = {}\ntrain_stats['detector'] = []\nfor i in range(3):\n    train_stats['detector'].append({\n                'idx': i,\n                'mean': w1_mean[i],\n                'std': np.sqrt(w1_var[i])})\n    \nwith open('train_stats.json', 'w') as fp:\n    json.dump(train_stats, fp, indent=4)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:43:07.269096Z","iopub.execute_input":"2021-08-19T14:43:07.269663Z","iopub.status.idle":"2021-08-19T14:43:07.275088Z","shell.execute_reply.started":"2021-08-19T14:43:07.269606Z","shell.execute_reply":"2021-08-19T14:43:07.274392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test dataset\nRepeat for the test dataset.","metadata":{}},{"cell_type":"code","source":"test_files = glob.glob('../input/g2net-gravitational-wave-detection/test/*/*/*/*.npy')","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:43:10.564927Z","iopub.execute_input":"2021-08-19T14:43:10.565468Z","iopub.status.idle":"2021-08-19T14:44:01.147841Z","shell.execute_reply.started":"2021-08-19T14:43:10.565413Z","shell.execute_reply":"2021-08-19T14:44:01.146781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices(test_files)\ntest_ds = test_ds.map(_parse_function1, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:44:14.278838Z","iopub.execute_input":"2021-08-19T14:44:14.279394Z","iopub.status.idle":"2021-08-19T14:44:15.128937Z","shell.execute_reply.started":"2021-08-19T14:44:14.27936Z","shell.execute_reply":"2021-08-19T14:44:15.128146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2_mean, w2_var = tf_welford(test_ds)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:44:29.981796Z","iopub.execute_input":"2021-08-19T14:44:29.982172Z","iopub.status.idle":"2021-08-19T14:44:47.278057Z","shell.execute_reply.started":"2021-08-19T14:44:29.982142Z","shell.execute_reply":"2021-08-19T14:44:47.2763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Store results to json as well:","metadata":{}},{"cell_type":"code","source":"test_stats = {}\ntest_stats['detector'] = []\nfor i in range(3):\n    test_stats['detector'].append({\n                'idx': i,\n                'mean': w2_mean[i],\n                'std': np.sqrt(w2_var[i])})\n    \nwith open('test_stats.json', 'w') as fp:\n    json.dump(test_stats, fp, indent=4)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T14:46:22.333075Z","iopub.execute_input":"2021-08-19T14:46:22.333447Z","iopub.status.idle":"2021-08-19T14:46:22.340274Z","shell.execute_reply.started":"2021-08-19T14:46:22.333417Z","shell.execute_reply":"2021-08-19T14:46:22.339133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\nSo is there a difference between then train and test data sets when it comes to mean and variance?","metadata":{}},{"cell_type":"code","source":"stats = []\nfor j in range(3):\n    stats.append([w1_mean[j], w2_mean[j], w1_mean[j]/w2_mean[j], w1_var[j], w2_var[j], w1_var[j]/w2_var[j]])\ndfs = pd.DataFrame(stats, columns=['Train mean', 'Test mean', 'Train/test mean ratio', 'Train var', 'Test var', 'Train/test var ratio'])\ndfs","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-19T14:45:53.780233Z","iopub.execute_input":"2021-08-19T14:45:53.780606Z","iopub.status.idle":"2021-08-19T14:45:53.799219Z","shell.execute_reply.started":"2021-08-19T14:45:53.780576Z","shell.execute_reply":"2021-08-19T14:45:53.798156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yes - mean values vary quite a bit actually, while variance is very similar.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}