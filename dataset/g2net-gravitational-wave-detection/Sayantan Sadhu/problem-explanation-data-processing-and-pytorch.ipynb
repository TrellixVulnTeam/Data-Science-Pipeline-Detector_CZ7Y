{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q nnAudio","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:45:46.046102Z","iopub.execute_input":"2021-07-24T14:45:46.046582Z","iopub.status.idle":"2021-07-24T14:45:52.022217Z","shell.execute_reply.started":"2021-07-24T14:45:46.046549Z","shell.execute_reply":"2021-07-24T14:45:52.020977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:45:52.026224Z","iopub.execute_input":"2021-07-24T14:45:52.026561Z","iopub.status.idle":"2021-07-24T14:45:58.591883Z","shell.execute_reply.started":"2021-07-24T14:45:52.026529Z","shell.execute_reply":"2021-07-24T14:45:58.59089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-07-24T14:45:58.596038Z","iopub.execute_input":"2021-07-24T14:45:58.596339Z","iopub.status.idle":"2021-07-24T14:45:58.603183Z","shell.execute_reply.started":"2021-07-24T14:45:58.596292Z","shell.execute_reply":"2021-07-24T14:45:58.602236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = np.load('../input/g2net-gravitational-wave-detection/train/0/0/0/00000e74ad.npy')\nprint(example.shape)\ndisplay(pd.DataFrame(example).head())","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:45:58.605116Z","iopub.execute_input":"2021-07-24T14:45:58.60567Z","iopub.status.idle":"2021-07-24T14:45:58.644922Z","shell.execute_reply.started":"2021-07-24T14:45:58.605632Z","shell.execute_reply":"2021-07-24T14:45:58.643973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/g2net-gravitational-wave-detection/training_labels.csv')\ntest = pd.read_csv('../input/g2net-gravitational-wave-detection/sample_submission.csv')\n\ndef get_train_file_path(image_id):\n    return \"../input/g2net-gravitational-wave-detection/train/{}/{}/{}/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ndef get_test_file_path(image_id):\n    return \"../input/g2net-gravitational-wave-detection/test/{}/{}/{}/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ntrain['file_path'] = train['id'].apply(get_train_file_path)\ntest['file_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:45:58.647191Z","iopub.execute_input":"2021-07-24T14:45:58.647639Z","iopub.status.idle":"2021-07-24T14:45:59.807054Z","shell.execute_reply.started":"2021-07-24T14:45:58.647598Z","shell.execute_reply":"2021-07-24T14:45:59.806287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:45:59.808303Z","iopub.execute_input":"2021-07-24T14:45:59.808661Z","iopub.status.idle":"2021-07-24T14:45:59.950106Z","shell.execute_reply.started":"2021-07-24T14:45:59.808623Z","shell.execute_reply":"2021-07-24T14:45:59.948977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,a =  plt.subplots(3,1)\na[0].plot(example[1],color='green')\na[1].plot(example[1],color='red')\na[2].plot(example[1],color='yellow')\nfig.suptitle('Target 1', fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:45:59.951512Z","iopub.execute_input":"2021-07-24T14:45:59.951856Z","iopub.status.idle":"2021-07-24T14:46:00.238393Z","shell.execute_reply.started":"2021-07-24T14:45:59.951818Z","shell.execute_reply":"2021-07-24T14:46:00.237453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 5\nprint(train.columns)\n#print(file_paths[:5])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.240987Z","iopub.execute_input":"2021-07-24T14:46:00.241398Z","iopub.status.idle":"2021-07-24T14:46:00.246457Z","shell.execute_reply.started":"2021-07-24T14:46:00.241341Z","shell.execute_reply":"2021-07-24T14:46:00.245505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2\nclass G2NetDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df['target'].values\n        self.wave_transform = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def apply_qtransform(self, waves, transform):\n        waves = np.hstack(waves)\n        waves = waves / np.max(waves)\n        waves = torch.from_numpy(waves).float()\n        image = transform(waves)\n        return image\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        waves = np.load(file_path)\n        image = self.apply_qtransform(waves, self.wave_transform)\n        if self.transform:\n            image = image.squeeze().numpy()\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return {'image':image,\n                'targets': label}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.248332Z","iopub.execute_input":"2021-07-24T14:46:00.248742Z","iopub.status.idle":"2021-07-24T14:46:00.261474Z","shell.execute_reply.started":"2021-07-24T14:46:00.248706Z","shell.execute_reply":"2021-07-24T14:46:00.260504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.262914Z","iopub.execute_input":"2021-07-24T14:46:00.263245Z","iopub.status.idle":"2021-07-24T14:46:00.276998Z","shell.execute_reply.started":"2021-07-24T14:46:00.263211Z","shell.execute_reply":"2021-07-24T14:46:00.276082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df,valid_df = train_test_split(train,test_size=0.05,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.278072Z","iopub.execute_input":"2021-07-24T14:46:00.278549Z","iopub.status.idle":"2021-07-24T14:46:00.509206Z","shell.execute_reply.started":"2021-07-24T14:46:00.278512Z","shell.execute_reply":"2021-07-24T14:46:00.508361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = G2NetDataset(train_df,transform=get_transforms(data='train'))\nvalid_dataset = G2NetDataset(valid_df,transform=get_transforms(data='train'))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.510631Z","iopub.execute_input":"2021-07-24T14:46:00.510995Z","iopub.status.idle":"2021-07-24T14:46:00.666817Z","shell.execute_reply.started":"2021-07-24T14:46:00.510958Z","shell.execute_reply":"2021-07-24T14:46:00.664514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\n\nclass CustomModel(nn.Module):\n    def __init__(self,pretrained=False):\n        super().__init__()\n        self.model = timm.create_model('tf_efficientnet_b7_ns', pretrained=pretrained, in_chans=1)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, 1)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.668704Z","iopub.execute_input":"2021-07-24T14:46:00.669141Z","iopub.status.idle":"2021-07-24T14:46:00.678608Z","shell.execute_reply.started":"2021-07-24T14:46:00.669091Z","shell.execute_reply":"2021-07-24T14:46:00.677443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    # put the model in train mode\n    model.train()\n    l = len(data_loader)\n    step = 0\n    # go over every batch of data in data loader\n    for data in data_loader:\n         # remember, we have image and targets\n         # in our dataset class\n        inputs = data[\"image\"]\n        targets = data[\"targets\"]\n         # move inputs/targets to cuda/cpu device\n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n         # zero grad the optimizer\n        optimizer.zero_grad()\n         # do the forward step of model\n        outputs = model(inputs)\n     # calculate loss\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n     # backward step the loss\n        loss.backward()\n     # step optimizer\n        optimizer.step()\n        print(f'{step}/{l},loss={loss}')\n        step = step + 1","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:47:46.300866Z","iopub.execute_input":"2021-07-24T14:47:46.301201Z","iopub.status.idle":"2021-07-24T14:47:46.309297Z","shell.execute_reply.started":"2021-07-24T14:47:46.301169Z","shell.execute_reply":"2021-07-24T14:47:46.308389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(data_loader, model, device):\n     # put model in evaluation mode\n    model.eval()\n     # init lists to store targets and outputs\n    final_targets = []\n    final_outputs = []\n     # we use no_grad context\n    with torch.no_grad():\n        for data in data_loader:\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            # do the forward step to generate prediction\n            output = model(inputs)\n            # convert targets and outputs to lists\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n\n            # extend the original list\n            final_targets.extend(targets)\n            final_outputs.extend(output)\n\n     # return final output and final targets\n    return final_outputs, final_targets","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:46:00.703083Z","iopub.execute_input":"2021-07-24T14:46:00.705772Z","iopub.status.idle":"2021-07-24T14:46:00.71345Z","shell.execute_reply.started":"2021-07-24T14:46:00.705735Z","shell.execute_reply":"2021-07-24T14:46:00.712659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomModel(pretrained = True)\nmodel.to(device)\nepochs = 2\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\nvalid_loader =  torch.utils.data.DataLoader(valid_dataset,batch_size =16, shuffle=True, num_workers=4)\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\nfor epoch in range(epochs):\n    train(train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(\n     valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:47:50.361077Z","iopub.execute_input":"2021-07-24T14:47:50.36144Z","iopub.status.idle":"2021-07-24T17:53:00.964519Z","shell.execute_reply.started":"2021-07-24T14:47:50.361405Z","shell.execute_reply":"2021-07-24T17:53:00.957335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}