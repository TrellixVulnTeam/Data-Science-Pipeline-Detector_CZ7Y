{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nimport time\n\n#import tensorflow.keras as keras\n#from keras import backend as K\nfrom sklearn.preprocessing import OneHotEncoder\n\n#import tensorflow as tf\nimport random\n\nimport torch\nfrom torch import nn, optim\n#from torchsummary import summary\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split, Dataset\nimport math\nfrom IPython.display import display\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-24T00:38:11.797525Z","iopub.execute_input":"2021-09-24T00:38:11.797931Z","iopub.status.idle":"2021-09-24T00:38:13.949268Z","shell.execute_reply.started":"2021-09-24T00:38:11.797849Z","shell.execute_reply":"2021-09-24T00:38:13.948468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisis","metadata":{}},{"cell_type":"code","source":"#totalDir=0\n#totalFiles=0\n#for base, dirs, files in os.walk('../input/g2net-gravitational-wave-detection/train'):\n    #print('Searching in : ',base)\n    #for directories in dirs:\n        #totalDir += 1\n    #for Files in files:\n        #totalFiles += 1\n        \n#print('Total number of files',totalFiles,'\\n\\n')\n\n\nlabels = pd.read_csv('../input/g2net-gravitational-wave-detection/training_labels.csv')\nlabels.info()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:13.950467Z","iopub.execute_input":"2021-09-24T00:38:13.950858Z","iopub.status.idle":"2021-09-24T00:38:14.471299Z","shell.execute_reply.started":"2021-09-24T00:38:13.950831Z","shell.execute_reply":"2021-09-24T00:38:14.470418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_complete_path(basedir, file_id): \n    #return os.path.join(basedir, file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\n    return os.path.join(basedir,file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\ndef get_part_path(basedir, file_id): \n    #return os.path.join(basedir, file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\n    return os.path.join(basedir, file_id[1], file_id[2], file_id+ '.npy' )","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:14.472699Z","iopub.execute_input":"2021-09-24T00:38:14.473194Z","iopub.status.idle":"2021-09-24T00:38:14.478662Z","shell.execute_reply.started":"2021-09-24T00:38:14.473146Z","shell.execute_reply":"2021-09-24T00:38:14.477948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Revisamos si están balanceadas las clases\nprint(len(labels))#total de observaciones\nlabels.target.sum()# total de clase 1","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:23.078541Z","iopub.execute_input":"2021-09-24T00:38:23.07891Z","iopub.status.idle":"2021-09-24T00:38:23.088746Z","shell.execute_reply.started":"2021-09-24T00:38:23.078874Z","shell.execute_reply":"2021-09-24T00:38:23.087737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#leer N ejemplos aleatorios\nN=4\n\noptions = random.sample(range(0, 150), N)\n\n\neventos = [labels['id'].iloc[i] for i in options]\ncategorias = [labels['target'].iloc[i]for i in options]\n\nprint(eventos)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:34.138257Z","iopub.execute_input":"2021-09-24T00:38:34.13895Z","iopub.status.idle":"2021-09-24T00:38:34.146976Z","shell.execute_reply.started":"2021-09-24T00:38:34.138897Z","shell.execute_reply":"2021-09-24T00:38:34.145861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_array_list=[]\nfor evento in eventos:\n    path=get_complete_path('../input/g2net-gravitational-wave-detection/train/',evento)\n    data_array = np.load(path)\n    data_array_list.append(data_array)\n    \n'''print(\"\\nData summary:\\n\", data_array)\nprint(\"\\nData shape:\\n\", data_array.shape)\n'''\ndf = pd.DataFrame(data_array).T\n\nfig, axs =f, axs = plt.subplots(N,figsize=(15,5*N)) \nfor i in range(N):\n    for j in range(3):\n        \n        axs[i].plot(data_array_list[i][j])\n        \n\n#df.plot( figsize=(15,4))\n\nprint(\"\\n\\n\\n--------------------------------Las categoría son:\",categorias,'---------------------------\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:36.393896Z","iopub.execute_input":"2021-09-24T00:38:36.394472Z","iopub.status.idle":"2021-09-24T00:38:37.324582Z","shell.execute_reply.started":"2021-09-24T00:38:36.394439Z","shell.execute_reply":"2021-09-24T00:38:37.322506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparación ","metadata":{}},{"cell_type":"code","source":"\n\nclass Dataset(torch.utils.data.Dataset):\n    'Characterizes a dataset for PyTorch'\n    def __init__(self, list_IDs, labels):\n        'Initialization'\n        self.labels = labels\n        #print(self.labels)\n        self.list_IDs = list_IDs\n        #print(self.list_IDs)\n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.list_IDs)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        #print(index)\n        ID = self.list_IDs[index]\n        #print('ID',ID)    \n        # Load data and get label\n        path = get_complete_path('../input/g2net-gravitational-wave-detection/train', ID)\n        #print(path)\n        X = torch.from_numpy(np.load(path))\n        #X=X[:][0]\n        #print(X)\n        y = self.labels[index]\n        #print(y)\n\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:40.347021Z","iopub.execute_input":"2021-09-24T00:38:40.347624Z","iopub.status.idle":"2021-09-24T00:38:40.354346Z","shell.execute_reply.started":"2021-09-24T00:38:40.347587Z","shell.execute_reply":"2021-09-24T00:38:40.353435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_trainDL(labels):\n    trainingDS = Dataset(labels['id'], labels['target'])\n    training_generator = DataLoader(trainingDS,batch_size=16, shuffle=True)\n    return trainingDS , training_generator \n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:41.247387Z","iopub.execute_input":"2021-09-24T00:38:41.247736Z","iopub.status.idle":"2021-09-24T00:38:41.253033Z","shell.execute_reply.started":"2021-09-24T00:38:41.247707Z","shell.execute_reply":"2021-09-24T00:38:41.252339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def make_train_data(path,labels):\n    data_list=[]\n    target_list=[]\n    n=1\n    for base, dirs, files in os.walk(path):\n        for file in files:\n            indir=base[:-5]\n            n+=1\n            file_path = get_complete_path(indir,file)[:-4]\n            array = np.load(file_path)\n            #array = array.transpose()\n            data_list.append(array)\n            a=labels.loc[labels['id'] == file[:-4], 'target'].iloc[0]\n            target_list.append(a)\n    data = np.stack(data_list, axis=0)\n    data_l = np.array(target_list)\n    data_l = data_l.reshape(data_l.shape[0],-1)\n    return data,data_l\n            \n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:37:57.807694Z","iopub.execute_input":"2021-08-26T17:37:57.807962Z","iopub.status.idle":"2021-08-26T17:37:57.818453Z","shell.execute_reply.started":"2021-08-26T17:37:57.807937Z","shell.execute_reply":"2021-08-26T17:37:57.817588Z"}}},{"cell_type":"code","source":"%%time\n\nmsk = np.random.rand(len(labels)) < 0.98\ntrain_data=labels[msk].reset_index()\nval_data=labels[~msk].reset_index()\n\n\n\nprint(train_data.iloc[:32])\ntrain, train_dl = make_trainDL(train_data.iloc[:32])\nval, val_dl = make_trainDL(train_data.iloc[:32])\n","metadata":{"execution":{"iopub.status.busy":"2021-09-24T00:38:52.695679Z","iopub.execute_input":"2021-09-24T00:38:52.696167Z","iopub.status.idle":"2021-09-24T00:38:52.764084Z","shell.execute_reply.started":"2021-09-24T00:38:52.696135Z","shell.execute_reply":"2021-09-24T00:38:52.7634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Para probar el DataLoader","metadata":{}},{"cell_type":"code","source":"# Display text and label.\nprint(len(train),len(val))\nprint('\\nFirst iteration of data set: ', next(iter(train_dl)), '\\n')# Print how many items are in the data set\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:02.166918Z","iopub.execute_input":"2021-09-23T23:53:02.167256Z","iopub.status.idle":"2021-09-23T23:53:02.213677Z","shell.execute_reply.started":"2021-09-23T23:53:02.167229Z","shell.execute_reply":"2021-09-23T23:53:02.212504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(train.shape,y_labels.shape)\n\ntrainiter = iter(train_dl)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:02.93864Z","iopub.execute_input":"2021-09-23T23:53:02.939053Z","iopub.status.idle":"2021-09-23T23:53:03.027308Z","shell.execute_reply.started":"2021-09-23T23:53:02.939006Z","shell.execute_reply":"2021-09-23T23:53:03.026445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:03.483811Z","iopub.execute_input":"2021-09-23T23:53:03.484275Z","iopub.status.idle":"2021-09-23T23:53:03.489223Z","shell.execute_reply.started":"2021-09-23T23:53:03.484239Z","shell.execute_reply":"2021-09-23T23:53:03.488132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisis de frecuencias","metadata":{}},{"cell_type":"markdown","source":"from scipy.fft import fft, ifft,fftfreq,rfft,rfftfreq\n\nyf=[]\nyf.append(rfft(train[1][0]))\n#yf.append(rfft(train[1][1]))\n#yf.append(rfft(train[1][2]))\n\n# Number of sample points\nprint(np.abs(yf[0]),'\\n',len(yf[0]))\nN = len(train[1][0])\nT = 1.0/N\n\nxf = rfftfreq(N, T)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(20,10))\nplt.plot(xf[:100],np.abs(yf[0][:100]))\n\nplt.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T17:12:35.668575Z","iopub.execute_input":"2021-08-22T17:12:35.668999Z","iopub.status.idle":"2021-08-22T17:12:35.793379Z","shell.execute_reply.started":"2021-08-22T17:12:35.668963Z","shell.execute_reply":"2021-08-22T17:12:35.791521Z"}}},{"cell_type":"markdown","source":"print('train tiene forma: ',train.shape)\n#train=np.transpose(train, (0,2,1))\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-22T17:12:39.180897Z","iopub.execute_input":"2021-08-22T17:12:39.181383Z","iopub.status.idle":"2021-08-22T17:12:39.203537Z","shell.execute_reply.started":"2021-08-22T17:12:39.181339Z","shell.execute_reply":"2021-08-22T17:12:39.201285Z"}}},{"cell_type":"code","source":"#onehot_encoder = OneHotEncoder(sparse=False)\n#integer_encoded = y_labels.reshape(len(y_labels), 1)\n#y_labels = onehot_encoder.fit_transform(integer_encoded)\n#print(y_labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:05.39103Z","iopub.execute_input":"2021-09-23T23:53:05.391388Z","iopub.status.idle":"2021-09-23T23:53:05.395254Z","shell.execute_reply.started":"2021-09-23T23:53:05.391358Z","shell.execute_reply":"2021-09-23T23:53:05.394253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dividir en train/validation\n\n\nX_train, X_val, y_train, y_val = \\\n    train_test_split(train, y_labels, test_size=0.3, random_state=42)\n\nprint('X_train',X_train.shape,'y_train', y_train.shape,'\\nX_val',X_val.shape,'y_val',y_val.shape)\nver=X_train[0].shape\nprint(ver)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T04:42:46.914015Z","iopub.execute_input":"2021-08-22T04:42:46.914337Z","iopub.status.idle":"2021-08-22T04:42:47.020726Z","shell.execute_reply.started":"2021-08-22T04:42:46.914303Z","shell.execute_reply":"2021-08-22T04:42:47.019746Z"}}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"\nX_trainT=torch.from_numpy(X_train)\ny_trainT=torch.from_numpy(y_train)\nX_valT=torch.from_numpy(X_val)\ny_valT=torch.from_numpy(y_val)\n\ntrain_dl = [[X_trainT,y_trainT]]\nval_dl = [[X_valT,y_valT]]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-22T04:42:47.022014Z","iopub.execute_input":"2021-08-22T04:42:47.022312Z","iopub.status.idle":"2021-08-22T04:42:47.03524Z","shell.execute_reply.started":"2021-08-22T04:42:47.022271Z","shell.execute_reply":"2021-08-22T04:42:47.034067Z"}}},{"cell_type":"markdown","source":"y_trainT.type()\nX_trainT.type()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T04:42:47.037028Z","iopub.execute_input":"2021-08-22T04:42:47.037479Z","iopub.status.idle":"2021-08-22T04:42:47.051672Z","shell.execute_reply.started":"2021-08-22T04:42:47.03743Z","shell.execute_reply":"2021-08-22T04:42:47.050822Z"}}},{"cell_type":"markdown","source":"# Definimos un Modelo","metadata":{}},{"cell_type":"code","source":"class funcionesBase(nn.Module):\n    \n\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \n    def validation_step(self, batch, loss_):\n        graf, labels = batch \n        out = self(graf.double().to(device))  \n        #print(labels)\n        loss = loss_(out.to(device), labels.to(device)) \n        acc = accuracy(out.to(device), labels.to(device))           \n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      \n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\ndef accuracy(outputs, labels):\n    #print(outputs)\n    _, preds = torch.max(outputs, dim=1)\n    #print('PRED:',preds,'LABELS:',labels)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:07.746202Z","iopub.execute_input":"2021-09-23T23:53:07.746678Z","iopub.status.idle":"2021-09-23T23:53:07.757511Z","shell.execute_reply.started":"2021-09-23T23:53:07.746644Z","shell.execute_reply":"2021-09-23T23:53:07.756418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class clasificadorOndasGrav(funcionesBase):\n    \n    def __init__(self):\n        \n            super().__init__()   \n            self.c1=nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=3).double()\n            self.m1=nn.MaxPool1d(4).double()\n            self.c2=nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=3).double()\n            self.m2=nn.MaxPool1d(4).double()\n            self.c3=nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1).double()\n            self.m3=nn.MaxPool1d(2).double()\n            #self.c4=nn.Conv1d(in_channels=8, out_channels=8, kernel_size=3, stride=1).double()\n            #self.m4=nn.MaxPool1d(2).double()\n            self.f=nn.Flatten().double()\n            #self.l1=nn.Linear(21824,10912).double()\n            #self.r1=nn.ReLU().double()\n            self.l2=nn.Linear(104,36).double()\n            self.r2=nn.ReLU().double()\n            self.l3=nn.Linear(36,2).double()\n            self.s=nn.Sigmoid().double()\n            \n            \n    \n    def forward(self, xb):\n        #self.network = self.network.double()\n        #print('xb',xb.shape)\n        out=self.c1(xb.double())\n        out=self.m1(out)\n        out=self.c2(out)\n        out=self.m2(out)\n        out=self.c3(out)\n        out=self.m3(out)\n        #out=self.c4(out)\n        #out=self.m4(out)\n        #print(out.shape)\n        out=self.f(out)\n        #print(out.shape)\n        #out=self.l1(out)\n        #print(out.shape)\n        #out=self.r1(out)\n        out=self.l2(out)\n        out=self.r2(out)\n        out=self.l3(out)\n        out=self.s(out)\n        return out\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:08.359246Z","iopub.execute_input":"2021-09-23T23:53:08.3596Z","iopub.status.idle":"2021-09-23T23:53:08.371413Z","shell.execute_reply.started":"2021-09-23T23:53:08.359568Z","shell.execute_reply":"2021-09-23T23:53:08.370307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=clasificadorOndasGrav()\n#model.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:09.0727Z","iopub.execute_input":"2021-09-23T23:53:09.073266Z","iopub.status.idle":"2021-09-23T23:53:09.081395Z","shell.execute_reply.started":"2021-09-23T23:53:09.073232Z","shell.execute_reply":"2021-09-23T23:53:09.08061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Para entrenar","metadata":{}},{"cell_type":"markdown","source":"criterion = nn.BCELoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T02:35:34.213304Z","iopub.execute_input":"2021-08-27T02:35:34.213725Z","iopub.status.idle":"2021-08-27T02:35:34.218645Z","shell.execute_reply.started":"2021-08-27T02:35:34.213626Z","shell.execute_reply":"2021-08-27T02:35:34.217449Z"}}},{"cell_type":"markdown","source":"for epoch in range(22):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_dl, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs.double(), labels.double())\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2 == 0:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T02:35:35.013981Z","iopub.execute_input":"2021-08-27T02:35:35.014314Z","iopub.status.idle":"2021-08-27T02:36:26.964145Z","shell.execute_reply.started":"2021-08-27T02:35:35.014284Z","shell.execute_reply":"2021-08-27T02:36:26.962447Z"}}},{"cell_type":"code","source":"#@torch.no_grad()\ndef evaluate(model, loss_, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch, loss_) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, loss_, train_loader,val_loader, opt_func = torch.optim.SGD):\n    \n    history = []\n    optimizer = opt_func(model.parameters(),lr)\n    for epoch in range(epochs):\n        \n        #model.train()\n        train_losses = []\n        for i,batch in enumerate(train_loader):\n        \n            graf, labels = batch\n            #print(graf.shape)\n            graf = graf*1e20\n            #print(graf)\n            optimizer.zero_grad()\n            \n            \n            out = model(graf.to(device))\n            #print(out.shape,labels.shape)\n            print('out',out,'labels',labels,'\\n')\n            loss = loss_(out.to(device), labels.to(device)) \n            print(loss)\n            \n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            \n            '''if i%10==0:\n                print(\".\",end=\"\")\n            #if i%100==0:\n            print(\".\",end=\"\")\n        result = evaluate(model,loss_, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n        #model.train()\n    \n    return history'''","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:53:13.577867Z","iopub.execute_input":"2021-09-23T23:53:13.578436Z","iopub.status.idle":"2021-09-23T23:53:13.587041Z","shell.execute_reply.started":"2021-09-23T23:53:13.578402Z","shell.execute_reply":"2021-09-23T23:53:13.585992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 300\nopt_func = torch.optim.Adam\nlr = 0.001\n\nloss=nn.CrossEntropyLoss() \n\nfit(num_epochs, lr, model, loss, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:54:24.748719Z","iopub.execute_input":"2021-09-23T23:54:24.74913Z","iopub.status.idle":"2021-09-23T23:54:42.219855Z","shell.execute_reply.started":"2021-09-23T23:54:24.749096Z","shell.execute_reply":"2021-09-23T23:54:42.218917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hacer predicción ","metadata":{}},{"cell_type":"code","source":"def hacer_predic (model,graf):\n    with torch.no_grad():\n        y_pred = model(graf)\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:29:08.146998Z","iopub.status.idle":"2021-09-23T23:29:08.147403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\npred_list=[]\nfor i in range(1):\n    evento_a_pred = submission['id'].iloc[i]\n    path_pred = get_complete_path('../input/g2net-gravitational-wave-detection/test', evento_a_pred)\n    array = np.load(path_pred)\n    pred_list.append(array)\n    \ndata = torch.from_numpy(np.stack(pred_list, axis=0))\npred = hacer_predic(model,data)\npred.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:29:08.148544Z","iopub.status.idle":"2021-09-23T23:29:08.149192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\n\n\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:29:08.150352Z","iopub.status.idle":"2021-09-23T23:29:08.151004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(submission)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:29:08.152127Z","iopub.status.idle":"2021-09-23T23:29:08.152516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}