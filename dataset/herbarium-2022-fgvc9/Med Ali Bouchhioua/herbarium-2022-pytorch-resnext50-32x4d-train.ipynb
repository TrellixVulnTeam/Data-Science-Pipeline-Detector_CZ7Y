{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n- PyTorch resnext50_32x4d starter code\n- single fold\n- 2 epochs\n\n# Improvements maybe\n\n- Use smaller models for speed improvemnts (VGG)\n- Use High Performance GPU-Dedicated Architecture like TResNet\n- Use ArcFace or add triplet loss with cross entropy for score improvement\n\n# acknowledgement\n- Y.NAKAMA great [notebook](https://www.kaggle.com/yasufuminakama/herbarium-2020-pytorch-resnet18-train/notebook)\n\nIf this notebook is helpful, feel free to upvote :)","metadata":{}},{"cell_type":"code","source":"!pip install -q --upgrade wandb\n!pip install -q ttach\n!pip install  timm","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:14:57.216324Z","iopub.execute_input":"2022-03-16T01:14:57.217099Z","iopub.status.idle":"2022-03-16T01:15:25.744235Z","shell.execute_reply.started":"2022-03-16T01:14:57.217006Z","shell.execute_reply":"2022-03-16T01:15:25.743466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\npd.options.display.max_columns = 300","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:25.747252Z","iopub.execute_input":"2022-03-16T01:15:25.74753Z","iopub.status.idle":"2022-03-16T01:15:26.966218Z","shell.execute_reply.started":"2022-03-16T01:15:25.747493Z","shell.execute_reply":"2022-03-16T01:15:26.965526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/herbarium-2022-pandas/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:26.967467Z","iopub.execute_input":"2022-03-16T01:15:26.967715Z","iopub.status.idle":"2022-03-16T01:15:29.095099Z","shell.execute_reply.started":"2022-03-16T01:15:26.967683Z","shell.execute_reply":"2022-03-16T01:15:29.094379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"category\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:29.096373Z","iopub.execute_input":"2022-03-16T01:15:29.096647Z","iopub.status.idle":"2022-03-16T01:15:29.128861Z","shell.execute_reply.started":"2022-03-16T01:15:29.096612Z","shell.execute_reply":"2022-03-16T01:15:29.127866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Quick EDA","metadata":{}},{"cell_type":"code","source":"for i in range(5):\n    image = cv.imread(train.loc[i, 'directory'])\n    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n    target = train.loc[i, 'category']\n    plt.imshow(image)\n    plt.title(f\"target: {target}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:29.131218Z","iopub.execute_input":"2022-03-16T01:15:29.131585Z","iopub.status.idle":"2022-03-16T01:15:30.460739Z","shell.execute_reply.started":"2022-03-16T01:15:29.131545Z","shell.execute_reply":"2022-03-16T01:15:30.460046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(train['category'])\ntrain['category'] = le.transform(train['category'])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:30.461984Z","iopub.execute_input":"2022-03-16T01:15:30.462336Z","iopub.status.idle":"2022-03-16T01:15:30.620217Z","shell.execute_reply.started":"2022-03-16T01:15:30.462306Z","shell.execute_reply":"2022-03-16T01:15:30.61952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directory settings","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:30.621621Z","iopub.execute_input":"2022-03-16T01:15:30.621877Z","iopub.status.idle":"2022-03-16T01:15:30.626304Z","shell.execute_reply.started":"2022-03-16T01:15:30.621844Z","shell.execute_reply":"2022-03-16T01:15:30.625352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    apex=False\n    debug=False\n    print_freq=100\n    size=128\n    num_workers=8\n    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n    epochs=2\n    # CosineAnnealingLR params\n    cosanneal_params={\n        'T_max':4,\n        'eta_min':1e-5,\n        'last_epoch':-1\n    }\n    #ReduceLROnPlateau params\n    reduce_params={\n        'mode':'min',\n        'factor':0.2,\n        'patience':4,\n        'eps':1e-6,\n        'verbose':True\n    }\n    # CosineAnnealingWarmRestarts params\n    cosanneal_res_params={\n        'T_0':3,\n        'eta_min':1e-6,\n        'T_mult':1,\n        'last_epoch':-1\n    }\n    onecycle_params={\n        'pct_start':0.1,\n        'div_factor':1e2,\n        'max_lr':1e-3\n    }\n    batch_size=32\n    lr=1e-3\n    weight_decay=1e-5\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    target_size=train[\"category\"].shape[0]\n    nfolds=2\n    trn_folds=[0]\n    model_name='resnext50_32x4d'     #'vit_base_patch32_224_in21k' 'tf_efficientnetv2_b0' 'resnext50_32x4d'\n    train=True\n    early_stop=True\n    target_col=\"category\"\n    fc_dim=512\n    early_stopping_steps=5\n    grad_cam=False\n    seed=42\n    \nif CFG.debug:\n    CFG.epochs=1\n    train=train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:30.627742Z","iopub.execute_input":"2022-03-16T01:15:30.628174Z","iopub.status.idle":"2022-03-16T01:15:30.703603Z","shell.execute_reply.started":"2022-03-16T01:15:30.628138Z","shell.execute_reply":"2022-03-16T01:15:30.702898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport sys\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\nfrom PIL import ImageFile\n# sometimes, you will have images without an ending bit\n# this takes care of those kind of (corrupt) images\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.optim.optimizer import Optimizer\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:30.704909Z","iopub.execute_input":"2022-03-16T01:15:30.705159Z","iopub.status.idle":"2022-03-16T01:15:33.75153Z","shell.execute_reply.started":"2022-03-16T01:15:30.705124Z","shell.execute_reply":"2022-03-16T01:15:33.750555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# W&B","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_key\")\n\nimport wandb\nwandb.login(key=wandb_api)\n\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\nrun = wandb.init(project=\"Herbarium 2022\", \n                 name=\"resnext50_32x4d\",\n                 config=class2dict(CFG),\n                 group=CFG.model_name,\n                 job_type=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:33.753318Z","iopub.execute_input":"2022-03-16T01:15:33.754238Z","iopub.status.idle":"2022-03-16T01:15:41.983426Z","shell.execute_reply.started":"2022-03-16T01:15:33.75419Z","shell.execute_reply":"2022-03-16T01:15:41.982761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = f1_score(y_true, y_pred, average=\"macro\")\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:41.985027Z","iopub.execute_input":"2022-03-16T01:15:41.985522Z","iopub.status.idle":"2022-03-16T01:15:41.999679Z","shell.execute_reply.started":"2022-03-16T01:15:41.985466Z","shell.execute_reply":"2022-03-16T01:15:41.999046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV schem","metadata":{}},{"cell_type":"code","source":"%%time\nskf = StratifiedKFold(n_splits=CFG.nfolds, shuffle=True, random_state=CFG.seed)\nfor fold, (trn_idx, vld_idx) in enumerate(skf.split(train, train[CFG.target_col])):\n    train.loc[vld_idx, \"folds\"] = int(fold)\ntrain[\"folds\"] = train[\"folds\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:42.002338Z","iopub.execute_input":"2022-03-16T01:15:42.00274Z","iopub.status.idle":"2022-03-16T01:15:42.066783Z","shell.execute_reply.started":"2022-03-16T01:15:42.002712Z","shell.execute_reply":"2022-03-16T01:15:42.066133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['directory'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        try:\n            image = cv2.imread(file_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        except:\n            image = Image.open(file_path)\n            image = image.convert(\"RGB\")\n            image = np.array(image)\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:42.068032Z","iopub.execute_input":"2022-03-16T01:15:42.068348Z","iopub.status.idle":"2022-03-16T01:15:42.077029Z","shell.execute_reply.started":"2022-03-16T01:15:42.068311Z","shell.execute_reply":"2022-03-16T01:15:42.076127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose(\n        [\n           A.Resize(CFG.size, CFG.size),\n           A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            A.Flip(p=0.05),\n            \n            A.Cutout(p=0.05),\n            A.HorizontalFlip(p=0.05),\n            A.VerticalFlip(p=0.05),\n            A.Rotate(limit=180, p=0.05),\n            A.ShiftScaleRotate(\n                shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.05\n            ),\n            A.HueSaturationValue(\n                hue_shift_limit=0.2, sat_shift_limit=0.4,\n                val_shift_limit=0.2, p=0.05\n            ),\n            A.RandomBrightnessContrast(\n                brightness_limit=(-0.1, 0.1),\n                contrast_limit=(-0.1, 0.1), p=0.05\n            ),\n            ToTensorV2(p=1.0),\n        ]\n    )\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:42.080357Z","iopub.execute_input":"2022-03-16T01:15:42.081039Z","iopub.status.idle":"2022-03-16T01:15:42.092037Z","shell.execute_reply.started":"2022-03-16T01:15:42.081003Z","shell.execute_reply":"2022-03-16T01:15:42.09127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(5):\n    plt.figure(figsize=(4, 4))\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:42.094411Z","iopub.execute_input":"2022-03-16T01:15:42.094934Z","iopub.status.idle":"2022-03-16T01:15:43.174957Z","shell.execute_reply.started":"2022-03-16T01:15:42.094899Z","shell.execute_reply":"2022-03-16T01:15:43.174316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=3)\n        \n        if cfg.model_name == 'tf_efficientnetv2_b0':\n            self.n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(self.n_features, self.cfg.fc_dim)\n        \n        if cfg.model_name.split('_')[1] == \"efficientnet\":\n            self.n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(self.n_features, self.cfg.fc_dim)\n            \n        if cfg.model_name == 'resnext50_32x4d':\n            self.in_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(self.in_features, self.cfg.fc_dim)\n            \n        elif cfg.model_name.split('_')[0] == 'vit':\n            self.n_features = self.model.head.in_features\n            self.model.head = nn.Linear(self.n_features, self.cfg.fc_dim)\n        \n        self.fc = nn.Linear(self.cfg.fc_dim, self.cfg.target_size)\n\n    def forward(self, x):\n        features = self.model(x)\n        output = self.fc(features)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:43.176263Z","iopub.execute_input":"2022-03-16T01:15:43.176659Z","iopub.status.idle":"2022-03-16T01:15:43.187467Z","shell.execute_reply.started":"2022-03-16T01:15:43.176622Z","shell.execute_reply":"2022-03-16T01:15:43.186785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    if CFG.apex:\n        scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device).float()\n        labels = labels.to(device).long()\n        batch_size = labels.size(0)\n        if CFG.apex:\n            with autocast():\n                y_preds = model(images)\n                loss = criterion(y_preds, labels)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        if CFG.apex:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            if CFG.apex:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f} '\n                  'LR: {lr:.6f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n        wandb.log({f\"[fold{fold}] loss\": losses.val,\n                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device).float()\n        labels = labels.to(device).long()\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        preds.append(y_preds.argmax(1).to('cpu').numpy())\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:43.18905Z","iopub.execute_input":"2022-03-16T01:15:43.189303Z","iopub.status.idle":"2022-03-16T01:15:43.215503Z","shell.execute_reply.started":"2022-03-16T01:15:43.189269Z","shell.execute_reply":"2022-03-16T01:15:43.214765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['folds'] != fold].index\n    val_idx = folds[folds['folds'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[\"category\"].values\n\n    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.reduce_params)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = nn.CrossEntropyLoss()\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        \n        #preds_label = np.argmax(preds, axis=1)\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                   f\"[fold{fold}] score\": score})\n\n        if score >= best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds_score': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n            \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds_loss': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n        \n        \n    valid_folds[\"preds_score\"] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth', \n                                      map_location=torch.device('cpu'))['preds_score']\n    valid_folds[\"preds_loss\"] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth', \n                                      map_location=torch.device('cpu'))['preds_loss']\n   \n\n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:43.218607Z","iopub.execute_input":"2022-03-16T01:15:43.218815Z","iopub.status.idle":"2022-03-16T01:15:43.239897Z","shell.execute_reply.started":"2022-03-16T01:15:43.218791Z","shell.execute_reply":"2022-03-16T01:15:43.23924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train \n    \"\"\"\n\n    def get_result(result_df):\n        preds_score = result_df['preds_score'].values\n        preds_loss = result_df['preds_loss'].values\n        labels = result_df[\"category\"].values\n        score = get_score(labels, preds_score)\n        score_loss = get_score(labels, preds_loss)\n        LOGGER.info(f'Score with best score weights: {score:<.4f}')\n        LOGGER.info(f'Score with best loss weights: {score_loss:<.4f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.nfolds):\n            if fold in CFG.trn_folds:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n        \n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:43.241365Z","iopub.execute_input":"2022-03-16T01:15:43.241613Z","iopub.status.idle":"2022-03-16T01:15:43.25332Z","shell.execute_reply.started":"2022-03-16T01:15:43.241582Z","shell.execute_reply":"2022-03-16T01:15:43.252421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:15:43.254452Z","iopub.execute_input":"2022-03-16T01:15:43.254745Z","iopub.status.idle":"2022-03-16T01:16:51.027026Z","shell.execute_reply.started":"2022-03-16T01:15:43.254708Z","shell.execute_reply":"2022-03-16T01:16:51.026307Z"},"trusted":true},"execution_count":null,"outputs":[]}]}