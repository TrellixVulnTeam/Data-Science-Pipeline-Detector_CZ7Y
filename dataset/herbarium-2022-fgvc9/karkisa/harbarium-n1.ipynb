{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Party!!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pytorch_lightning as pl\nimport torch ,json, torchvision, os, glob\nimport torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T20:44:40.34502Z","iopub.execute_input":"2022-03-30T20:44:40.345399Z","iopub.status.idle":"2022-03-30T20:44:43.279706Z","shell.execute_reply.started":"2022-03-30T20:44:40.345292Z","shell.execute_reply":"2022-03-30T20:44:43.278666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple visualisation\n","metadata":{}},{"cell_type":"code","source":"def read_img(path):\n    img=torchvision.io.read_image(path)\n    return img\n\n\ndef plot_imgs(df,r=8,c=8,figsize=(20,20)):\n    _, axs = plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    for n, ax in enumerate(axs):\n        img=read_img(df.directory[n])\n        cat=df.category[n]\n        ax.imshow(torchvision.transforms.functional.to_pil_image(img))\n        ax.set_title(cat)\n        ax.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n    \ndef display_(path):\n    df=pd.read_csv(path)\n    display(df)\n    \n    print(df.info())\n    print(\"unique values in columns\")\n    for col in df.columns:\n        print(col,\"           :          \", df[col].nunique())\n    return df\n    \n    \ndef main():\n    \n    train_base_folder='../input/herbarium-2022-fgvc9/train_images'\n    test_base_folder='../input/herbarium-2022-fgvc9/test_images'\n    train_df_path='../input/herbarium-2022-pandas/train.csv'\n    test_df_path='../input/herbarium-2022-pandas/test.csv'\n    \n    train_df=display_(train_df_path)\n    plot_imgs(train_df)\n    \n    \n    \nmain()\n","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-03-30T20:44:43.282019Z","iopub.execute_input":"2022-03-30T20:44:43.28236Z","iopub.status.idle":"2022-03-30T20:44:55.93068Z","shell.execute_reply.started":"2022-03-30T20:44:43.282312Z","shell.execute_reply":"2022-03-30T20:44:55.917969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader,Dataset\nfrom pytorch_lightning import LightningDataModule,LightningModule\nfrom sklearn.model_selection import train_test_split\nfrom kornia import image_to_tensor, tensor_to_image\nfrom kornia.augmentation import ColorJitter, RandomChannelShuffle, RandomHorizontalFlip, RandomThinPlateSpline\nfrom torchvision import transforms\n\nclass basic_pipe (Dataset):\n    \n    def __init__(\n                self,\n                df,\n                ):\n        \n        self.df=df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def read_img(self,path):\n        \n        img=torchvision.io.read_image(path)\n        img=torchvision.transforms.Resize(size=(512,512))(img)\n        \n        return img/255.0\n    \n    \n    def get_label(self,info):\n        \n        lab=torch.nn.functional.one_hot(torch.tensor(info), num_classes=15504)  ##############? solve\n        \n        return lab\n    \n    \n    def __getitem__(self, idx):\n        img=self.read_img(self.df.directory[idx])\n        lab=self.get_label(self.df.category[idx])\n        \n        return img,lab\n    \n    \n    \nclass pl_pipeline(LightningDataModule):\n    \n    def __init__(\n        \n        self, \n        dataset,\n        df,\n        bs,\n        num_workers\n                ):\n        \n        self.dataset=dataset\n        self.df=df\n        self.bs=bs\n        self.num_workers=num_workers\n        self.train_df,self.val_df=train_test_split(df)\n        \n        self.train_df,self.val_df=self.train_df.reset_index(),self.val_df.reset_index()\n        \n#     def setup(self):\n#         self.train_df,self.val_df=train_test_split(df)\n        \n        \n    def train_dataloader(self):\n        data=self.dataset(self.train_df)\n        dataloader=DataLoader(data,batch_size=self.bs )\n        return dataloader\n    \n    def validation_dataloader(self):\n        data=self.dataset(self.val_df)\n        dataloader=DataLoader(data,batch_size=self.bs )\n        return dataloader\n        \n        \ndef plot_basic_pipeline(data,r=8,c=8,figsize=(25,25)):\n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        img,lab=data[n]\n        ax.imshow(torchvision.transforms.functional.to_pil_image(img))\n        ax.set_title(lab)\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\ndef plot_pl_pipeline(imgs,labs,r=8,c=8,figsize=(25,25)):\n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        img,lab=imgs[n],labs[n]\n        ax.imshow(torchvision.transforms.functional.to_pil_image(img))\n        ax.set_title(lab)\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n    \ndef main():\n    \n    train_base_folder='../input/herbarium-2022-fgvc9/train_images'\n    test_base_folder='../input/herbarium-2022-fgvc9/test_images'\n    train_df_path='../input/herbarium-2022-pandas/train.csv'\n    test_df_path='../input/herbarium-2022-pandas/test.csv'\n    \n    train_df=display_(train_df_path)\n# uncomment the following to test the basic_pipeline for debuging purpose\n#     data=basic_pipe(train_df)\n#     plot_pipeline(data)\n    dataloader=pl_pipeline(\n        basic_pipe,\n        df=train_df,\n        bs=64,\n        num_workers=1\n    )\n    img,lab=next(iter(dataloader.train_dataloader()))\n    plot_pl_pipeline(img,lab)\n    \n    \n    \nmain()\n\n    \n    \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T20:44:55.931865Z","iopub.execute_input":"2022-03-30T20:44:55.932264Z","iopub.status.idle":"2022-03-30T20:45:09.215815Z","shell.execute_reply.started":"2022-03-30T20:44:55.932231Z","shell.execute_reply":"2022-03-30T20:45:09.214628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model and Classifier","metadata":{}},{"cell_type":"code","source":"# torchvision.models.densenet121(pretrained=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T20:45:09.218078Z","iopub.execute_input":"2022-03-30T20:45:09.218312Z","iopub.status.idle":"2022-03-30T20:45:09.222388Z","shell.execute_reply.started":"2022-03-30T20:45:09.218284Z","shell.execute_reply":"2022-03-30T20:45:09.221492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class pl_model(LightningModule):\n    \n    def __init__(self,\n                model_name='default_model_name',\n                 model=torchvision.models.densenet121(pretrained=True),\n                 num_class=15504\n                 \n                ):\n        super(pl_model,self).__init__()\n        self.model_name=model_name\n        self.model=model\n        self.linear=torch.nn.Linear\n        self.num_class=num_class\n        self.get_head(self.model)\n        \n        \n        \n    def get_head(self,model):  # basic exp model ( baseline )\n        \n        model_base_features=self.model.classifier.in_features\n        self.model.classifier=self.linear(model_base_features,out_features=self.num_class)\n        \n    def forward(self,x):\n        \n        out=self.model(x) # can add many hydra typeheadesor add stages here\n        \n        return out\n\nimport torchmetrics\nimport torch.nn.functional as F\n\nclass classifier(LightningModule):\n    def __init__(self,\n                model,\n                ):\n        super(classifier,self).__init__()\n        self.model=model\n        self.train_acc = torchmetrics.Accuracy()\n        self.val_acc = torchmetrics.Accuracy()\n        \n        \n    def compute_loss(self,preds,gts):\n        loss=F.cross_entropy(preds,gts)\n        return loss\n\n    def training_step(self,batch,batch_idx):\n        x,y=batch\n        prediction=self.model(x)\n        loss=self.compute_loss(prediction,y)\n        self.train_acc(prediction,y)\n        self.log('train_acc',self.train_acc)\n        self.log('loss',loss)\n        \n        return {'loss':loss,'matric_1':self.train_acc}\n    \n    \n    def validation_step(self,batch,batch_idx):\n        \n        x,y=batch\n        prediction=self.model(x)\n        loss=self.compute_loss(prediction,y)\n        \n        self.val_acc(prediction,y)\n        self.log('val_lacc',self.val_acc)\n        self.log('loss',loss)\n        \n        return {'loss':loss, 'val_acc':self.val}\n    \n    def optimizer_step(self,model):\n        opt=torch.nn.optim.Adam()\n        opt(self.model.parameters)\n        return opt\n\n    \ndef plot_predictions(imgs,preds,r=2,c=3,figsize=(20,20)):\n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        ax.imshow(transforms.functional.to_pil_image(imgs[n]))\n        ax.set_title(preds[n])\n        ax.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n        \ndef main():\n    \n    train_base_folder='../input/herbarium-2022-fgvc9/train_images'\n    test_base_folder='../input/herbarium-2022-fgvc9/test_images'\n    train_df_path='../input/herbarium-2022-pandas/train.csv'\n    test_df_path='../input/herbarium-2022-pandas/test.csv'\n    \n    train_df=display_(train_df_path)\n#     data=basic_pipe(train_df)\n    dataloader=pl_pipeline(\n        basic_pipe,\n        df=train_df,\n        bs=64,\n        num_workers=1\n    )\n    imgs,labs= next(iter(dataloader.train_dataloader()))\n    imgs=imgs[2:8]\n    model=pl_model()\n    preds=model(imgs)\n#     print(preds.shape,'\\n ', labs.shape)\n    plot_predictions(imgs,torch.argmax(preds,dim=1))\n    \n    \nmain()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T20:48:25.663972Z","iopub.execute_input":"2022-03-30T20:48:25.664283Z","iopub.status.idle":"2022-03-30T20:48:35.988677Z","shell.execute_reply.started":"2022-03-30T20:48:25.664247Z","shell.execute_reply":"2022-03-30T20:48:35.987486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}