{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project Goals\n* Conduct error analysis on model predictions on a test set\n* Explore different ensembling techniques for improving overall inference accuracy"},{"metadata":{},"cell_type":"markdown","source":"# Model Information\n* bert-base-multilingual-cased\n    * Numbers of parameters: 177 M\n    * Max epochs: 10\n    * Best epoch: 1\n    * Accuracy on Leaderboard public dataset: 0.63156\n\n\n* xlm-roberta-base\n    * Numbers of parameters: 278 M\n    * Max epochs: 10\n    * Best epoch: 3\n    * Accuracy on Leaderboard public dataset: 0.67930\n    \n\n* xlm-roberta-large\n    * Numbers of parameters: 560 M\n    * Max epochs: 5\n    * Best epoch: 2\n    * Accuracy on Leaderboard public dataset: 0.73763"},{"metadata":{},"cell_type":"markdown","source":"# Environment Setup"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Check if TPU/GPU is available\nimport tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    DEVICE = \"tpu\"\nexcept ValueError:\n    if tf.test.is_gpu_available():\n        DEVICE = \"gpu\"\n    else:\n        DEVICE = \"cpu\"\n\nprint(\"Accelerator: {}\".format(DEVICE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up an environment for accessing TPU\nif DEVICE == \"tpu\":\n    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n    !pip install pytorch-lightning\n    import torch_xla\n    import torch_xla.core.xla_model as xm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.environ[\"WANDB_API_KEY\"] = \"0\"  # to silence warning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install datasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport datasets\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom typing import List, Dict\nfrom tqdm import tqdm\nfrom scipy.special import softmax\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.utils.extmath import weighted_mode\nfrom collections import OrderedDict, defaultdict\nfrom transformers import BertTokenizer, BertForSequenceClassification, XLMRobertaTokenizer, XLMRobertaForSequenceClassification\nfrom torch.utils.data import Dataset, DataLoader\ntry:\n    from pytorch_lightning import LightningModule, loggers, seed_everything\n    from pytorch_lightning.core.decorators import auto_move_data\nexcept OSError:  # Reloading pytorch_lightning again to resolve OSError issues with TPU\n    from pytorch_lightning import LightningModule, loggers, seed_everything\n    from pytorch_lightning.core.decorators import auto_move_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove temp installation files to release space\ngc.collect()\npaths = glob.glob(\"/kaggle/working/*\")\nfor path in paths:\n    try:\n        if os.path.isfile(path):\n            os.remove(path)\n        elif os.path.isdir(path):\n            shutil.rmtree(path)\n    except:\n        print(\"Not removable: {}\".format(path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Global Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# MultilingualBERT Model\nPRETRAINED_BERT_MODEL = \"bert-base-multilingual-cased\"\nFINETUNED_BERT_MODEL = \"../input/multilingualbert-finetuned-10epochs/bert-base-multilingual-cased_ft_10epochs_epoch1.ckpt\"\n\n# XLM-RoBERTa-Base Model\nPRETRAINED_XLMBASE_MODEL = \"xlm-roberta-base\"\nFINETUNED_XLMBASE_MODEL = \"../input/xlmrobertabase-finetuned-10epochs/xlm-roberta-base_ft_10epochs_epoch3.ckpt\"\n\n# XLM-RoBERTa-Large Model\nPRETRAINED_XLMLARGE_MODEL = \"xlm-roberta-large\"\nFINETUNED_XLMLARGE_MODEL = \"../input/xlmrobertalarge-finetuned-5epochs/xlm-roberta-large_ft_5epochs_epoch2.ckpt\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Global Variables\nSEED = 2020\nMAX_EPOCHS = 1\nif DEVICE == \"tpu\":\n    BATCH_SIZE = 8\n    MAX_TOKEN_LEN = 50\n    TPU_CORES = 8\n    GPUS = 1\n    NUM_WORKERS = 4\nelse:\n    BATCH_SIZE = 16\n    MAX_TOKEN_LEN = 50\n    TPU_CORES = 1\n    GPUS = 1\n    NUM_WORKERS = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set with labels\ntestset_df = pd.read_csv(\"../input/nli-test-set/nli_test_set.csv\")\ntestset_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(testset_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset_df.groupby([\"language\", \"label\"]).size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Production dataset for inference and submission\nprod_df = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\nprod_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(prod_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_df[\"language\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"class NLIEvalDataset(Dataset):\n    def __init__(self, \n                 dataset: pd.DataFrame, \n                 model_name: str,\n                 max_token_len: int = MAX_TOKEN_LEN,\n                 production: bool = False\n                ):\n        self.dataset = dataset\n        self.model_name = model_name\n        self.max_token_len = max_token_len\n        self.production = production\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, index: int):\n        row_id = self.dataset.id.values[index]\n        premise = self.dataset.premise.values[index]\n        hypothesis = self.dataset.hypothesis.values[index]\n        \n        if self.model_name in [\"bert-base-multilingual-cased\"]:\n            tokenizer = BertTokenizer.from_pretrained(self.model_name)\n        elif self.model_name in [\"xlm-roberta-base\", \"xlm-roberta-large\"]:\n            tokenizer = XLMRobertaTokenizer.from_pretrained(self.model_name)\n        \n        encoded_sents = tokenizer.encode_plus(premise, \n                                              hypothesis,\n                                              add_special_tokens=True, \n                                              pad_to_max_length=True, \n                                              max_length=self.max_token_len, \n                                              truncation=True, \n                                              return_attention_mask=True, \n                                              return_token_type_ids=True,\n                                              return_tensors=\"pt\")\n        \n        inputs = {\n            \"input_ids\": encoded_sents[\"input_ids\"][0],\n            \"token_type_ids\": encoded_sents[\"token_type_ids\"][0],\n            \"attention_mask\": encoded_sents[\"attention_mask\"][0]\n        }\n        \n        if self.production:\n            return inputs, row_id\n        else:\n            label = self.dataset.label.values[index]\n            return inputs, label, row_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NLIEvalModelModule(LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    @auto_move_data\n    def forward(self, inputs):\n        predictions = self.model(input_ids=inputs[\"input_ids\"], \n                                 attention_mask=inputs[\"attention_mask\"],\n                                 token_type_ids=inputs[\"token_type_ids\"])\n        return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation(dataset: pd.DataFrame, \n                     model_name: str, \n                     checkpoint_path: str, \n                     batch_size: int = BATCH_SIZE):\n    # Prepare Dataset\n    nli_dataset = NLIEvalDataset(dataset, model_name, production=False)\n    nli_dataloader = DataLoader(nli_dataset, batch_size=batch_size, shuffle=False)\n    \n    # Load Fine-tuned Model\n    checkpoint = torch.load(checkpoint_path)\n    state_dict = checkpoint[\"state_dict\"]\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k[6:]  # remove 'model.' of DataParallel\n        new_state_dict[name] = v\n    \n    if model_name in [\"bert-base-multilingual-cased\"]:\n        model = BertForSequenceClassification.from_pretrained(model_name, \n                                                              state_dict=new_state_dict,\n                                                              num_labels=3)\n    elif model_name in [\"xlm-roberta-base\", \"xlm-roberta-large\"]:\n        model = XLMRobertaForSequenceClassification.from_pretrained(model_name, \n                                                                    state_dict=new_state_dict, \n                                                                    num_labels=3)\n    \n    model_module = NLIEvalModelModule(model)\n    model_module.freeze() # eval\n    info_dict = defaultdict(list)\n    prob_list = []\n\n    # Model inference\n    for inputs, label, row_id in tqdm(nli_dataloader):\n        raw_predictions = model_module.forward(inputs)\n        predictions = raw_predictions[0].cpu().numpy()\n        pred_label = np.argmax(predictions, axis=1)\n        pred_probs = softmax(predictions, axis=1)\n        \n        info_dict[\"row_id\"] += row_id\n        info_dict[\"label\"] += label.cpu().numpy().tolist()\n        info_dict[\"pred_label\"] += pred_label.tolist()\n        prob_list += pred_probs.tolist()\n        \n    info_df = pd.DataFrame.from_dict(info_dict)\n    prob_df = pd.DataFrame(prob_list, columns=[\"label_0_prob\", \"label_1_prob\", \"label_2_prob\"])\n    return pd.concat([info_df, prob_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# General settings\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(confusion_matrix, norm=False):\n    plt.figure(figsize=(7, 7))\n    cm_df = pd.DataFrame(confusion_matrix, \n                         index=[\"True Label: 0\", \"True Label: 1\", \"True Label: 2\"],\n                         columns=[\"Predicted Label: 0\", \"Predicted Label: 1\", \"Predicted Label: 2\"])\n    if norm:\n        sn.heatmap(cm_df, cmap=\"YlGnBu\", annot=True, fmt=\".2g\")\n    else:\n        sn.heatmap(cm_df, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation: bert-base-multilingual-cased"},{"metadata":{"trusted":true},"cell_type":"code","source":"BERT_TESTSET_PREDICTIONS = \"../input/nli-test-set/bert_testset_predictions.csv\"\nif os.path.isfile(BERT_TESTSET_PREDICTIONS):\n    bert_pred_df = pd.read_csv(BERT_TESTSET_PREDICTIONS, index_col=0)\nelse:\n    bert_pred_df = model_evaluation(testset_df, PRETRAINED_BERT_MODEL, FINETUNED_BERT_MODEL)\n    bert_pred_df.to_csv(\"bert_testset_predictions.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_pred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_accuracy_score = accuracy_score(bert_pred_df.label.values, bert_pred_df.pred_label.values)\nprint(bert_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_confusion_matrix = confusion_matrix(bert_pred_df.label.values, \n                                         bert_pred_df.pred_label.values)\nbert_norm_confusion_matrix = confusion_matrix(bert_pred_df.label.values, \n                                              bert_pred_df.pred_label.values, \n                                              normalize=\"true\")\nplot_confusion_matrix(bert_confusion_matrix)\nplot_confusion_matrix(bert_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation: xlm-roberta-base"},{"metadata":{"trusted":true},"cell_type":"code","source":"XLMBASE_TESTSET_PREDICTIONS = \"../input/nli-test-set/xlmbase_testset_predictions.csv\"\nif os.path.isfile(XLMBASE_TESTSET_PREDICTIONS):\n    xlmbase_pred_df = pd.read_csv(XLMBASE_TESTSET_PREDICTIONS, index_col=0)\nelse:\n    xlmbase_pred_df = model_evaluation(testset_df, PRETRAINED_XLMBASE_MODEL, FINETUNED_XLMBASE_MODEL)\n    xlmbase_pred_df.to_csv(\"xlmbase_testset_predictions.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlmbase_pred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlmbase_accuracy_score = accuracy_score(xlmbase_pred_df.label.values, xlmbase_pred_df.pred_label.values)\nprint(xlmbase_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlmbase_confusion_matrix = confusion_matrix(xlmbase_pred_df.label.values, \n                                            xlmbase_pred_df.pred_label.values)\nxlmbase_norm_confusion_matrix = confusion_matrix(xlmbase_pred_df.label.values, \n                                                 xlmbase_pred_df.pred_label.values, \n                                                 normalize=\"true\")\nplot_confusion_matrix(xlmbase_confusion_matrix)\nplot_confusion_matrix(xlmbase_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation: xlm-roberta-large"},{"metadata":{"trusted":true},"cell_type":"code","source":"XLMLARGE_TESTSET_PREDICTIONS = \"../input/nli-test-set/xlmlarge_testset_predictions.csv\"\nif os.path.isfile(XLMLARGE_TESTSET_PREDICTIONS):\n    xlmlarge_pred_df = pd.read_csv(XLMLARGE_TESTSET_PREDICTIONS, index_col=0)\nelse:\n    xlmlarge_pred_df = model_evaluation(testset_df, PRETRAINED_XLMLARGE_MODEL, FINETUNED_XLMLARGE_MODEL)\n    xlmlarge_pred_df.to_csv(\"xlmlarge_testset_predictions.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlmlarge_pred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlmlarge_accuracy_score = accuracy_score(xlmlarge_pred_df.label.values, xlmlarge_pred_df.pred_label.values)\nprint(xlmlarge_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlmlarge_confusion_matrix = confusion_matrix(xlmlarge_pred_df.label.values, \n                                             xlmlarge_pred_df.pred_label.values)\nxlmlarge_norm_confusion_matrix = confusion_matrix(xlmlarge_pred_df.label.values, \n                                                  xlmlarge_pred_df.pred_label.values, \n                                                  normalize=\"true\")\nplot_confusion_matrix(xlmlarge_confusion_matrix)\nplot_confusion_matrix(xlmlarge_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Option 1 - Argmax + Majority Voting"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_df = pd.merge(bert_pred_df, \n                  xlmbase_pred_df[[\"row_id\", \"pred_label\", \"label_0_prob\", \"label_1_prob\", \"label_2_prob\"]], \n                  on=\"row_id\", \n                  suffixes=('_bert', '_xlmbase'))\nmerge_df = pd.merge(tmp_df, \n                    xlmlarge_pred_df[[\"row_id\", \"pred_label\", \"label_0_prob\", \"label_1_prob\", \"label_2_prob\"]], \n                    on=\"row_id\")\nmerge_df.rename(columns={'label_bert': 'label',\n                         'pred_label': 'pred_label_xlmlarge',\n                         'label_0_prob': 'label_0_prob_xlmlarge',\n                         'label_1_prob': 'label_1_prob_xlmlarge',\n                         'label_2_prob': 'label_2_prob_xlmlarge'}, \n                inplace=True)\nmerge_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"majority_voting_df = merge_df.loc[:, [\"pred_label_bert\", \"pred_label_xlmbase\", \"pred_label_xlmlarge\"]]\nmajority_voting_df['majority'] = majority_voting_df.mode(axis=1)[0].astype(\"int\")\nmajority_voting_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"majority_voting_accuracy_score = accuracy_score(merge_df.label.values, majority_voting_df.majority.values)\nprint(majority_voting_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"majority_voting_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                    majority_voting_df.majority.values)\nmajority_voting_norm_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                         majority_voting_df.majority.values,\n                                                         normalize=\"true\")\nplot_confusion_matrix(majority_voting_confusion_matrix)\nplot_confusion_matrix(majority_voting_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Option 2 - Argmax + Weighted Voting"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_acc_array = np.array([bert_accuracy_score, xlmbase_accuracy_score, xlmlarge_accuracy_score])\nMODEL_WEIGHTING = model_acc_array / sum(model_acc_array)\nprint(MODEL_WEIGHTING)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_voting_df = merge_df.loc[:, [\"pred_label_bert\", \"pred_label_xlmbase\", \"pred_label_xlmlarge\"]]\nweighted_voting_df['majority'], weighted_voting_df['majority_score'] = weighted_mode(weighted_voting_df, MODEL_WEIGHTING, axis=1)\nweighted_voting_df['majority'] = weighted_voting_df['majority'].astype(\"int\")\nweighted_voting_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_voting_accuracy_score = accuracy_score(merge_df.label.values, weighted_voting_df.majority.values)\nprint(weighted_voting_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_voting_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                    weighted_voting_df.majority.values)\nweighted_voting_norm_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                         weighted_voting_df.majority.values,\n                                                         normalize=\"true\")\nplot_confusion_matrix(weighted_voting_confusion_matrix)\nplot_confusion_matrix(weighted_voting_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Option 3 - Averaged Probabilities + Argmax"},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_df = merge_df[merge_df.columns.difference([\"pred_label_bert\", \"pred_label_xlmbase\", \"pred_label_xlmlarge\", \"row_id\"])]\nprob_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"averaged_prob_df = pd.DataFrame()\naveraged_prob_df[\"label_0_prob_avg\"] = np.average(prob_df.loc[:, prob_df.columns.str.startswith('label_0')], axis=1)\naveraged_prob_df[\"label_1_prob_avg\"] = np.average(prob_df.loc[:, prob_df.columns.str.startswith('label_1')], axis=1)\naveraged_prob_df[\"label_2_prob_avg\"] = np.average(prob_df.loc[:, prob_df.columns.str.startswith('label_2')], axis=1)\naveraged_prob_df[\"idxmax\"] = averaged_prob_df.idxmax(axis=1)\nlabel_mapping = {\"label_0_prob_avg\": 0, \"label_1_prob_avg\": 1, \"label_2_prob_avg\": 2}\naveraged_prob_df[\"pred_label\"] = averaged_prob_df[\"idxmax\"].map(label_mapping)\naveraged_prob_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"averaged_prob_accuracy_score = accuracy_score(merge_df.label.values, averaged_prob_df.pred_label.values)\nprint(averaged_prob_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"averaged_prob_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                  averaged_prob_df.pred_label.values)\naveraged_prob_norm_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                       averaged_prob_df.pred_label.values,\n                                                       normalize=\"true\")\nplot_confusion_matrix(averaged_prob_confusion_matrix)\nplot_confusion_matrix(averaged_prob_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Option 4 - Weighted Probabilities + Argmax"},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_prob_df = pd.DataFrame()\nweighted_prob_df[\"label_0_prob_avg\"] = np.average(prob_df.loc[:, prob_df.columns.str.startswith('label_0')], weights=MODEL_WEIGHTING, axis=1)\nweighted_prob_df[\"label_1_prob_avg\"] = np.average(prob_df.loc[:, prob_df.columns.str.startswith('label_1')], weights=MODEL_WEIGHTING, axis=1)\nweighted_prob_df[\"label_2_prob_avg\"] = np.average(prob_df.loc[:, prob_df.columns.str.startswith('label_2')], weights=MODEL_WEIGHTING, axis=1)\nweighted_prob_df[\"idxmax\"] = weighted_prob_df.idxmax(axis=1)\nlabel_mapping = {\"label_0_prob_avg\": 0, \"label_1_prob_avg\": 1, \"label_2_prob_avg\": 2}\nweighted_prob_df[\"pred_label\"] = weighted_prob_df[\"idxmax\"].map(label_mapping)\nweighted_prob_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_prob_accuracy_score = accuracy_score(merge_df.label.values, weighted_prob_df.pred_label.values)\nprint(weighted_prob_accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_prob_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                  weighted_prob_df.pred_label.values)\nweighted_prob_norm_confusion_matrix = confusion_matrix(merge_df.label.values, \n                                                       weighted_prob_df.pred_label.values,\n                                                       normalize=\"true\")\nplot_confusion_matrix(weighted_prob_confusion_matrix)\nplot_confusion_matrix(weighted_prob_norm_confusion_matrix, norm=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Inference: Weighted Probabilities + Argmax"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenization(dataset, model_name, prefix):\n    if model_name in [\"bert-base-multilingual-cased\"]:\n        tokenizer = BertTokenizer.from_pretrained(model_name)\n    elif model_name in [\"xlm-roberta-base\", \"xlm-roberta-large\"]:\n        tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n    \n    sents = list(zip(dataset.premise.values, dataset.hypothesis.values))\n    encoded_sents = tokenizer.batch_encode_plus(sents,\n                                                add_special_tokens=True,\n                                                pad_to_max_length=True,\n                                                max_length=MAX_TOKEN_LEN,\n                                                truncation=True,\n                                                return_attention_mask=True,\n                                                return_token_type_ids=True)\n    \n    dataset[prefix + \"_input_ids\"] = encoded_sents[\"input_ids\"]\n    dataset[prefix + \"_token_type_ids\"] = encoded_sents[\"token_type_ids\"]\n    dataset[prefix + \"_attention_mask\"] = encoded_sents[\"attention_mask\"]\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_df = tokenization(prod_df, \"bert-base-multilingual-cased\", \"bert\")\nprod_df = tokenization(prod_df, \"xlm-roberta-base\", \"xlmbase\")\nprod_df = tokenization(prod_df, \"xlm-roberta-large\", \"xlmlarge\")\nprod_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NLIProdDataset(Dataset):\n    def __init__(self, dataset: pd.DataFrame):\n        self.dataset = dataset\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, index: int):\n        row_id = self.dataset.id.values[index]\n        \n        bert_inputs = {\n            \"input_ids\": np.array(self.dataset.bert_input_ids.values[index]),\n            \"token_type_ids\": np.array(self.dataset.bert_token_type_ids.values[index]),\n            \"attention_mask\": np.array(self.dataset.bert_attention_mask.values[index])\n        }\n                \n        xlmbase_inputs = {\n            \"input_ids\": np.array(self.dataset.xlmbase_input_ids.values[index]),\n            \"token_type_ids\": np.array(self.dataset.xlmbase_token_type_ids.values[index]),\n            \"attention_mask\": np.array(self.dataset.xlmbase_attention_mask.values[index])\n        }\n        \n        xlmlarge_inputs = {\n            \"input_ids\": np.array(self.dataset.xlmlarge_input_ids.values[index]),\n            \"token_type_ids\": np.array(self.dataset.xlmlarge_token_type_ids.values[index]),\n            \"attention_mask\": np.array(self.dataset.xlmlarge_attention_mask.values[index])\n        }\n\n        return bert_inputs, xlmbase_inputs, xlmlarge_inputs, row_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NLIProdModelModule(LightningModule):\n    def __init__(self, bert_model, xlmbase_model, xlmlarge_model):\n        super().__init__()\n        self.bert_model = bert_model\n        self.xlmbase_model = xlmbase_model\n        self.xlmlarge_model = xlmlarge_model\n\n    @auto_move_data\n    def forward(self, bert_inputs, xlmbase_inputs, xlmlarge_inputs):\n        bert_predictions = self.bert_model(input_ids=bert_inputs[\"input_ids\"], \n                                           attention_mask=bert_inputs[\"attention_mask\"],\n                                           token_type_ids=bert_inputs[\"token_type_ids\"])\n        \n        xlmbase_predictions = self.xlmbase_model(input_ids=xlmbase_inputs[\"input_ids\"], \n                                                 attention_mask=xlmbase_inputs[\"attention_mask\"],\n                                                 token_type_ids=xlmbase_inputs[\"token_type_ids\"])\n        \n        xlmlarge_predictions = self.xlmlarge_model(input_ids=xlmlarge_inputs[\"input_ids\"], \n                                                   attention_mask=xlmlarge_inputs[\"attention_mask\"],\n                                                   token_type_ids=xlmlarge_inputs[\"token_type_ids\"])\n        \n        return bert_predictions, xlmbase_predictions, xlmlarge_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(model_dict: Dict[str, str], accelerator: str = DEVICE):\n    model_name = model_dict[\"model_name\"]\n    checkpoint_path = model_dict[\"checkpoint_path\"]\n    \n    if accelerator == \"gpu\":\n        checkpoint = torch.load(checkpoint_path)\n    else:\n        checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n    state_dict = checkpoint[\"state_dict\"]\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k[6:]  # remove 'model.' of DataParallel\n        new_state_dict[name] = v\n\n    if model_name in [\"bert-base-multilingual-cased\"]:\n        model = BertForSequenceClassification.from_pretrained(model_name, \n                                                              state_dict=new_state_dict,\n                                                              num_labels=3)\n    elif model_name in [\"xlm-roberta-base\", \"xlm-roberta-large\"]:\n        model = XLMRobertaForSequenceClassification.from_pretrained(model_name, \n                                                                    state_dict=new_state_dict, \n                                                                    num_labels=3)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_inference(dataset: pd.DataFrame, \n                    model_dict: Dict[str, str],\n                    batch_size: int = BATCH_SIZE):\n\n    # Prepare Dataset\n    nli_dataset = NLIProdDataset(dataset)\n    nli_dataloader = DataLoader(nli_dataset, batch_size=batch_size, shuffle=False)\n    \n    # Load Fine-tuned Model\n    bert_model = load_model(model_dict[\"bert\"])\n    xlmbase_model = load_model(model_dict[\"xlmbase\"])\n    xlmlarge_model = load_model(model_dict[\"xlmlarge\"])\n    \n    model_module = NLIProdModelModule(bert_model, xlmbase_model, xlmlarge_model)\n    model_module.freeze() # eval\n    info_dict = defaultdict(list)\n    bert_prob_list = []\n    xlmbase_prob_list = []\n    xlmlarge_prob_list = []\n    \n    # Model inference\n    for bert_inputs, xlmbase_inputs, xlmlarge_inputs, row_ids in tqdm(nli_dataloader):\n        raw_bert_predictions, raw_xlmbase_predictions, raw_xlmlarge_predictions = model_module.forward(bert_inputs, \n                                                                                                       xlmbase_inputs, \n                                                                                                       xlmlarge_inputs)\n        bert_predictions = raw_bert_predictions[0].cpu().numpy()\n        xlmbase_predictions = raw_xlmbase_predictions[0].cpu().numpy()\n        xlmlarge_predictions = raw_xlmlarge_predictions[0].cpu().numpy()\n        \n        bert_pred_probs = softmax(bert_predictions, axis=1)\n        xlmbase_pred_probs = softmax(xlmbase_predictions, axis=1)\n        xlmlarge_pred_probs = softmax(xlmlarge_predictions, axis=1)\n        \n        info_dict[\"row_id\"] += row_ids\n        bert_prob_list += bert_pred_probs.tolist()\n        xlmbase_prob_list += xlmbase_pred_probs.tolist()\n        xlmlarge_prob_list += xlmlarge_pred_probs.tolist()\n\n    info_df = pd.DataFrame.from_dict(info_dict)\n    bert_df = pd.DataFrame(bert_prob_list, columns=[\"label_0_prob\", \"label_1_prob\", \"label_2_prob\"])\n    xlmbase_df = pd.DataFrame(xlmbase_prob_list, columns=[\"label_0_prob\", \"label_1_prob\", \"label_2_prob\"])\n    xlmlarge_df = pd.DataFrame(xlmlarge_prob_list, columns=[\"label_0_prob\", \"label_1_prob\", \"label_2_prob\"])\n    return pd.concat([info_df, bert_df], axis=1), pd.concat([info_df, xlmbase_df], axis=1), pd.concat([info_df, xlmlarge_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_ensemble(pred_dfs: List[pd.DataFrame], \n                   model_weighting: np.array):    \n    weighted_prob_df = pd.DataFrame()    \n    weighted_prob_df[\"label_0_prob_avg\"] = np.average(np.vstack((pred_dfs[0].label_0_prob.values,\n                                                                 pred_dfs[1].label_0_prob.values,\n                                                                 pred_dfs[2].label_0_prob.values)), \n                                                      weights=model_weighting, \n                                                      axis=0)\n    weighted_prob_df[\"label_1_prob_avg\"] = np.average(np.vstack((pred_dfs[0].label_1_prob.values,\n                                                                 pred_dfs[1].label_1_prob.values,\n                                                                 pred_dfs[2].label_1_prob.values)), \n                                                      weights=model_weighting, \n                                                      axis=0)\n    weighted_prob_df[\"label_2_prob_avg\"] = np.average(np.vstack((pred_dfs[0].label_2_prob.values,\n                                                                 pred_dfs[1].label_2_prob.values,\n                                                                 pred_dfs[2].label_2_prob.values)), \n                                                      weights=model_weighting, \n                                                      axis=0)\n    weighted_prob_df[\"idxmax\"] = weighted_prob_df.idxmax(axis=1)\n    label_mapping = {\"label_0_prob_avg\": 0, \"label_1_prob_avg\": 1, \"label_2_prob_avg\": 2}\n    weighted_prob_df[\"id\"] = pred_dfs[0].row_id.values\n    weighted_prob_df[\"prediction\"] = weighted_prob_df[\"idxmax\"].map(label_mapping)\n    return weighted_prob_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dict = defaultdict(str)\nmodel_dict[\"bert\"] = defaultdict(str)\nmodel_dict[\"bert\"][\"model_name\"] = PRETRAINED_BERT_MODEL\nmodel_dict[\"bert\"][\"checkpoint_path\"] = FINETUNED_BERT_MODEL\nmodel_dict[\"xlmbase\"] = defaultdict(str)\nmodel_dict[\"xlmbase\"][\"model_name\"] = PRETRAINED_XLMBASE_MODEL\nmodel_dict[\"xlmbase\"][\"checkpoint_path\"] = FINETUNED_XLMBASE_MODEL\nmodel_dict[\"xlmlarge\"] = defaultdict(str)\nmodel_dict[\"xlmlarge\"][\"model_name\"] = PRETRAINED_XLMLARGE_MODEL\nmodel_dict[\"xlmlarge\"][\"checkpoint_path\"] = FINETUNED_XLMLARGE_MODEL\n\npred_dfs = list(model_inference(prod_df, model_dict))\nweighted_prob_df = model_ensemble(pred_dfs, MODEL_WEIGHTING)\nweighted_prob_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_pd = weighted_prob_df[[\"id\", \"prediction\"]]\npred_pd.to_csv('submission.csv', index=False)\npred_pd.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}