{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, Adamax\n\nfrom transformers import DistilBertTokenizer, TFDistilBertModel\n\nfrom datasets import load_dataset, list_datasets\n\nfrom sklearn.model_selection import train_test_split\n\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport warnings,json\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T01:49:33.804008Z","iopub.execute_input":"2022-05-07T01:49:33.804523Z","iopub.status.idle":"2022-05-07T01:49:43.195445Z","shell.execute_reply.started":"2022-05-07T01:49:33.80443Z","shell.execute_reply":"2022-05-07T01:49:43.194613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:43.198795Z","iopub.execute_input":"2022-05-07T01:49:43.199448Z","iopub.status.idle":"2022-05-07T01:49:43.20386Z","shell.execute_reply.started":"2022-05-07T01:49:43.199411Z","shell.execute_reply":"2022-05-07T01:49:43.203116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Init_TPU():  \n\n    try:\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(resolver)\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n        REPLICAS = strategy.num_replicas_in_sync\n        print(\"Connected to TPU Successfully:\\n TPUs Initialised with Replicas:\",REPLICAS)\n        \n        return strategy\n    \n    except ValueError:\n        \n        print(\"Connection to TPU Falied\")\n        print(\"Using default strategy for CPU and single GPU\")\n        strategy = tf.distribute.get_strategy()\n        \n        return strategy\n    \nstrategy=Init_TPU()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:43.204866Z","iopub.execute_input":"2022-05-07T01:49:43.205067Z","iopub.status.idle":"2022-05-07T01:49:49.394765Z","shell.execute_reply.started":"2022-05-07T01:49:43.205044Z","shell.execute_reply":"2022-05-07T01:49:49.394019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/contradictory-my-dear-watson/'","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:49.396212Z","iopub.execute_input":"2022-05-07T01:49:49.396408Z","iopub.status.idle":"2022-05-07T01:49:49.399964Z","shell.execute_reply.started":"2022-05-07T01:49:49.396386Z","shell.execute_reply":"2022-05-07T01:49:49.399197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_url = os.path.join(path,'train.csv')\ntrain_data = pd.read_csv(train_url, header='infer')\n\nsample_sub_url = os.path.join(path,'sample_submission.csv')\nsample_sub = pd.read_csv(sample_sub_url, header='infer')\n\ntest_url = os.path.join(path,'test.csv')\ntest_data = pd.read_csv(test_url, header='infer')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:49.401461Z","iopub.execute_input":"2022-05-07T01:49:49.401706Z","iopub.status.idle":"2022-05-07T01:49:49.579853Z","shell.execute_reply.started":"2022-05-07T01:49:49.401674Z","shell.execute_reply":"2022-05-07T01:49:49.579002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:49.581002Z","iopub.execute_input":"2022-05-07T01:49:49.581631Z","iopub.status.idle":"2022-05-07T01:49:49.602311Z","shell.execute_reply.started":"2022-05-07T01:49:49.581596Z","shell.execute_reply":"2022-05-07T01:49:49.601703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:49.603221Z","iopub.execute_input":"2022-05-07T01:49:49.603447Z","iopub.status.idle":"2022-05-07T01:49:49.801443Z","shell.execute_reply.started":"2022-05-07T01:49:49.603421Z","shell.execute_reply":"2022-05-07T01:49:49.800505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformer Model Name\ntransformer_model = 'distilbert-base-multilingual-cased'\n\n# Define Tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained(transformer_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:49.803341Z","iopub.execute_input":"2022-05-07T01:49:49.803966Z","iopub.status.idle":"2022-05-07T01:49:51.970163Z","shell.execute_reply.started":"2022-05-07T01:49:49.803909Z","shell.execute_reply":"2022-05-07T01:49:51.9694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the output of tokenizer\ntokenizer.convert_tokens_to_ids(list(tokenizer.tokenize(\"Elementary, My Dear Watson!\")))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:51.971377Z","iopub.execute_input":"2022-05-07T01:49:51.971745Z","iopub.status.idle":"2022-05-07T01:49:51.979178Z","shell.execute_reply.started":"2022-05-07T01:49:51.971706Z","shell.execute_reply":"2022-05-07T01:49:51.978625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset('xnli', 'all_languages', split='train+validation+test') #returns a Dataset object  \nprint(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:49:51.982145Z","iopub.execute_input":"2022-05-07T01:49:51.982375Z","iopub.status.idle":"2022-05-07T01:52:54.921268Z","shell.execute_reply.started":"2022-05-07T01:49:51.982348Z","shell.execute_reply":"2022-05-07T01:52:54.920383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nentries = []   \nfor entry in tqdm(dataset): \n    hypothesis_langs = entry['hypothesis']['language'] #list of 15 lang string values\n    hypothesis_values = entry['hypothesis']['translation'] #list of 15 hypothesis string values\n\n    premise_langs = list(entry['premise'].keys()) #list of 15 lang string values\n    premise_values = list(entry['premise'].values()) #list of 15 premise string values\n\n    labels = [entry['label']]*len(hypothesis_langs) #all 15 languages for the same example have same label \n\n    if premise_langs == hypothesis_langs: #the languages in premise and hypothesis are in same order\n#             values = list(zip(premise_values, hypothesis_values, hypothesis_langs, labels))\n        values = list(zip(premise_values, hypothesis_values, hypothesis_langs,labels))\n        entries += values\n\n#     xnli_df = pd.DataFrame(entries, columns=['premise', 'hypothesis', 'lang_abv', 'label']) #create dataframe for each key\nxnli_df = pd.DataFrame(entries, columns=['premise', 'hypothesis', 'lang_abv','label']) ","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:52:54.922646Z","iopub.execute_input":"2022-05-07T01:52:54.922873Z","iopub.status.idle":"2022-05-07T01:54:40.57722Z","shell.execute_reply.started":"2022-05-07T01:52:54.922826Z","shell.execute_reply":"2022-05-07T01:54:40.576247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_xnli = xnli_df.isnull().sum() \n\nprint(\"Number of missing data points per column in XNLI corpus:\")\nprint (missing_values_xnli)\n\n# Drop the missing value rows\nxnli_df.dropna(axis=0, inplace=True)\nprint(\"Total number of data examples in XNLI corpus after dropping NA values: {}\".format(xnli_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:54:40.57885Z","iopub.execute_input":"2022-05-07T01:54:40.579124Z","iopub.status.idle":"2022-05-07T01:54:46.281003Z","shell.execute_reply.started":"2022-05-07T01:54:40.579097Z","shell.execute_reply":"2022-05-07T01:54:46.280132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xnli_df","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:54:46.282794Z","iopub.execute_input":"2022-05-07T01:54:46.283732Z","iopub.status.idle":"2022-05-07T01:54:46.298327Z","shell.execute_reply.started":"2022-05-07T01:54:46.283687Z","shell.execute_reply":"2022-05-07T01:54:46.297139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xnli_df = xnli_df[['premise', 'hypothesis' ,'label']]\nxnli_df","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:54:46.30124Z","iopub.execute_input":"2022-05-07T01:54:46.30148Z","iopub.status.idle":"2022-05-07T01:54:46.639504Z","shell.execute_reply.started":"2022-05-07T01:54:46.301454Z","shell.execute_reply":"2022-05-07T01:54:46.638935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_mnli(use_validation=True):\n    result=[]\n    dataset=load_dataset('multi_nli')\n    print(dataset)\n    for record in dataset['train']:\n        c1, c2, c3 = record['premise'],record['hypothesis'], record['label']\n        if c1 and c2 and c3 in {0, 1, 2}:\n            result.append((c1, c2, 'en',c3))\n    result=pd.DataFrame(result, columns=['premise', 'hypothesis', 'lang_abv' ,'label'])\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:54:46.640338Z","iopub.execute_input":"2022-05-07T01:54:46.64102Z","iopub.status.idle":"2022-05-07T01:54:46.647028Z","shell.execute_reply.started":"2022-05-07T01:54:46.640988Z","shell.execute_reply":"2022-05-07T01:54:46.646278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nmnli=load_mnli()\nmnli","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:54:46.647977Z","iopub.execute_input":"2022-05-07T01:54:46.648178Z","iopub.status.idle":"2022-05-07T01:56:53.546742Z","shell.execute_reply.started":"2022-05-07T01:54:46.648155Z","shell.execute_reply":"2022-05-07T01:56:53.545793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = mnli[['premise', 'hypothesis' ,'label']]\nmnli","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:56:53.54804Z","iopub.execute_input":"2022-05-07T01:56:53.54825Z","iopub.status.idle":"2022-05-07T01:56:53.580784Z","shell.execute_reply.started":"2022-05-07T01:56:53.548225Z","shell.execute_reply":"2022-05-07T01:56:53.579972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.concat([train_data, xnli_df.loc[:60000],mnli.loc[:180000]], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:56:53.582555Z","iopub.execute_input":"2022-05-07T01:56:53.583057Z","iopub.status.idle":"2022-05-07T01:56:53.626448Z","shell.execute_reply.started":"2022-05-07T01:56:53.583012Z","shell.execute_reply":"2022-05-07T01:56:53.625668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create seperate list from Train & Test Dataframes with only Premise & Hypothesis\ntrain = train_data[['premise','hypothesis']].values.tolist()\ntest = test_data[['premise','hypothesis']].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:56:53.628959Z","iopub.execute_input":"2022-05-07T01:56:53.629404Z","iopub.status.idle":"2022-05-07T01:56:54.072998Z","shell.execute_reply.started":"2022-05-07T01:56:53.629362Z","shell.execute_reply":"2022-05-07T01:56:54.072111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Max Length\nmax_len = 80   # << change if you wish\n\n# Encode the training & test data \ntrain_encode = tokenizer.batch_encode_plus(train, pad_to_max_length=True, max_length=max_len)\ntest_encode = tokenizer.batch_encode_plus(test, pad_to_max_length=True, max_length=max_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:56:54.074463Z","iopub.execute_input":"2022-05-07T01:56:54.074825Z","iopub.status.idle":"2022-05-07T01:57:50.268724Z","shell.execute_reply.started":"2022-05-07T01:56:54.074784Z","shell.execute_reply":"2022-05-07T01:57:50.267788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the Training Data into Training (90%) & Validation (10%)\n\ntest_size = 0.1  # << change if you wish\nx_train, x_val, y_train, y_val = train_test_split(train_encode['input_ids'], train_data.label.values, test_size=test_size)\n\n\n# Split Test Data\nx_test = test_encode['input_ids']","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:57:50.270202Z","iopub.execute_input":"2022-05-07T01:57:50.270608Z","iopub.status.idle":"2022-05-07T01:57:50.302179Z","shell.execute_reply.started":"2022-05-07T01:57:50.270565Z","shell.execute_reply":"2022-05-07T01:57:50.301451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#garbage collect\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:57:50.303191Z","iopub.execute_input":"2022-05-07T01:57:50.303412Z","iopub.status.idle":"2022-05-07T01:57:50.853307Z","shell.execute_reply.started":"2022-05-07T01:57:50.303388Z","shell.execute_reply":"2022-05-07T01:57:50.852679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading Data Into TensorFlow Dataset\nAUTO = tf.data.experimental.AUTOTUNE\nbatch_size = 16 * strategy.num_replicas_in_sync\n\ntrain_ds = (tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat().shuffle(3072).batch(batch_size).prefetch(AUTO))\nval_ds = (tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size).prefetch(AUTO))\n\ntest_ds = (tf.data.Dataset.from_tensor_slices(x_test).batch(batch_size))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:57:50.854695Z","iopub.execute_input":"2022-05-07T01:57:50.855654Z","iopub.status.idle":"2022-05-07T01:58:06.245167Z","shell.execute_reply.started":"2022-05-07T01:57:50.855614Z","shell.execute_reply":"2022-05-07T01:58:06.244344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage Collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:58:06.246261Z","iopub.execute_input":"2022-05-07T01:58:06.246481Z","iopub.status.idle":"2022-05-07T01:58:06.812526Z","shell.execute_reply.started":"2022-05-07T01:58:06.246456Z","shell.execute_reply":"2022-05-07T01:58:06.811677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(strategy,transformer):\n    with strategy.scope():\n        transformer_encoder = TFDistilBertModel.from_pretrained(transformer)  #Pretrained BERT Transformer Model\n        \n        input_layer = Input(shape=(max_len,), dtype=tf.int32, name=\"input_layer\")\n        \n        sequence_output = transformer_encoder(input_layer)[0]\n        \n        cls_token = sequence_output[:, 0, :]\n        \n        output_layer = Dense(3, activation='softmax')(cls_token)\n        \n        model = Model(inputs=input_layer, outputs=output_layer)\n        \n        model.compile(\n            Adamax(lr=1e-5), \n            loss='sparse_categorical_crossentropy', \n            metrics=['accuracy']\n        )\n        \n        return model\n    \n\n# Applying the build model function\nmodel = build_model(strategy,transformer_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:58:06.813822Z","iopub.execute_input":"2022-05-07T01:58:06.814193Z","iopub.status.idle":"2022-05-07T01:58:58.688125Z","shell.execute_reply.started":"2022-05-07T01:58:06.814161Z","shell.execute_reply":"2022-05-07T01:58:58.687369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:58:58.689442Z","iopub.execute_input":"2022-05-07T01:58:58.68978Z","iopub.status.idle":"2022-05-07T01:58:58.703431Z","shell.execute_reply.started":"2022-05-07T01:58:58.689739Z","shell.execute_reply":"2022-05-07T01:58:58.702059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Model\n\nepochs = 30  # < change if you wish\nn_steps = len(train_data) // batch_size \n\nmodel.fit(train_ds, \n          steps_per_epoch = n_steps, \n          validation_data = val_ds,\n          epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T01:58:58.705388Z","iopub.execute_input":"2022-05-07T01:58:58.705679Z","iopub.status.idle":"2022-05-07T02:11:35.906599Z","shell.execute_reply.started":"2022-05-07T01:58:58.705643Z","shell.execute_reply":"2022-05-07T02:11:35.905576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage Collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T02:11:35.912177Z","iopub.execute_input":"2022-05-07T02:11:35.91303Z","iopub.status.idle":"2022-05-07T02:11:37.169506Z","shell.execute_reply.started":"2022-05-07T02:11:35.912977Z","shell.execute_reply":"2022-05-07T02:11:37.168927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(test_ds, verbose=0)\nsample_sub['prediction'] = prediction.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T02:11:37.184291Z","iopub.execute_input":"2022-05-07T02:11:37.184894Z","iopub.status.idle":"2022-05-07T02:11:46.334623Z","shell.execute_reply.started":"2022-05-07T02:11:37.184859Z","shell.execute_reply":"2022-05-07T02:11:46.333939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T02:11:46.336277Z","iopub.execute_input":"2022-05-07T02:11:46.336831Z","iopub.status.idle":"2022-05-07T02:11:46.357979Z","shell.execute_reply.started":"2022-05-07T02:11:46.336791Z","shell.execute_reply":"2022-05-07T02:11:46.357054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T02:11:46.359438Z","iopub.execute_input":"2022-05-07T02:11:46.359854Z","iopub.status.idle":"2022-05-07T02:11:46.369984Z","shell.execute_reply.started":"2022-05-07T02:11:46.359794Z","shell.execute_reply":"2022-05-07T02:11:46.369119Z"},"trusted":true},"execution_count":null,"outputs":[]}]}