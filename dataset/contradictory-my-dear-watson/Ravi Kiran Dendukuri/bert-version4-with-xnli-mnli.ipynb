{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom transformers import BertTokenizer, TFBertModel, AutoTokenizer,TFAutoModel\nimport tensorflow as tf\nfrom datasets import load_dataset\nimport kerastuner as kt\n#import plotlib as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom datasets import load_dataset, list_datasets\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport warnings\n\nwarnings.filterwarnings('ignore') # ignore Jupiter warnings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T21:55:01.134292Z","iopub.execute_input":"2022-05-06T21:55:01.134939Z","iopub.status.idle":"2022-05-06T21:55:10.290517Z","shell.execute_reply.started":"2022-05-06T21:55:01.134838Z","shell.execute_reply":"2022-05-06T21:55:10.28956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset('xnli', 'all_languages', split='train+validation+test') #returns a Dataset object  \nprint(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:55:10.295215Z","iopub.execute_input":"2022-05-06T21:55:10.295757Z","iopub.status.idle":"2022-05-06T21:58:13.142086Z","shell.execute_reply.started":"2022-05-06T21:55:10.295718Z","shell.execute_reply":"2022-05-06T21:58:13.141194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nentries = []   \nfor entry in tqdm(dataset): \n    hypothesis_langs = entry['hypothesis']['language'] #list of 15 lang string values\n    hypothesis_values = entry['hypothesis']['translation'] #list of 15 hypothesis string values\n\n    premise_langs = list(entry['premise'].keys()) #list of 15 lang string values\n    premise_values = list(entry['premise'].values()) #list of 15 premise string values\n\n    labels = [entry['label']]*len(hypothesis_langs) #all 15 languages for the same example have same label \n\n    if premise_langs == hypothesis_langs: #the languages in premise and hypothesis are in same order\n#             values = list(zip(premise_values, hypothesis_values, hypothesis_langs, labels))\n        values = list(zip(premise_values, hypothesis_values, hypothesis_langs,labels))\n        entries += values\n\n#     xnli_df = pd.DataFrame(entries, columns=['premise', 'hypothesis', 'lang_abv', 'label']) #create dataframe for each key\nxnli_df = pd.DataFrame(entries, columns=['premise', 'hypothesis', 'lang_abv','label']) ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:59:50.12232Z","iopub.execute_input":"2022-05-06T21:59:50.123342Z","iopub.status.idle":"2022-05-06T22:01:39.134968Z","shell.execute_reply.started":"2022-05-06T21:59:50.123296Z","shell.execute_reply":"2022-05-06T22:01:39.134057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_xnli = xnli_df.isnull().sum() \n\nprint(\"Number of missing data points per column in XNLI corpus:\")\nprint (missing_values_xnli)\n\n# Drop the missing value rows\nxnli_df.dropna(axis=0, inplace=True)\nprint(\"Total number of data examples in XNLI corpus after dropping NA values: {}\".format(xnli_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:01:39.137427Z","iopub.execute_input":"2022-05-06T22:01:39.137691Z","iopub.status.idle":"2022-05-06T22:01:44.880058Z","shell.execute_reply.started":"2022-05-06T22:01:39.13766Z","shell.execute_reply":"2022-05-06T22:01:44.879158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xnli_df","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:01:44.92792Z","iopub.execute_input":"2022-05-06T22:01:44.928324Z","iopub.status.idle":"2022-05-06T22:01:44.941425Z","shell.execute_reply.started":"2022-05-06T22:01:44.928278Z","shell.execute_reply":"2022-05-06T22:01:44.940557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_mnli(use_validation=True):\n    result=[]\n    dataset=load_dataset('multi_nli')\n    print(dataset)\n    for record in dataset['train']:\n        c1, c2, c3 = record['premise'],record['hypothesis'], record['label']\n        if c1 and c2 and c3 in {0, 1, 2}:\n            result.append((c1, c2, 'en',c3))\n    result=pd.DataFrame(result, columns=['premise', 'hypothesis', 'lang_abv','label'])\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:01:44.943556Z","iopub.execute_input":"2022-05-06T22:01:44.944042Z","iopub.status.idle":"2022-05-06T22:01:44.951575Z","shell.execute_reply.started":"2022-05-06T22:01:44.944007Z","shell.execute_reply":"2022-05-06T22:01:44.950659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli=load_mnli()\nmnli","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:01:44.952823Z","iopub.execute_input":"2022-05-06T22:01:44.953326Z","iopub.status.idle":"2022-05-06T22:03:53.315294Z","shell.execute_reply.started":"2022-05-06T22:01:44.953289Z","shell.execute_reply":"2022-05-06T22:03:53.314363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:02.729377Z","iopub.execute_input":"2022-05-06T22:04:02.729677Z","iopub.status.idle":"2022-05-06T22:04:08.701003Z","shell.execute_reply.started":"2022-05-06T22:04:02.729645Z","shell.execute_reply":"2022-05-06T22:04:08.700227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_Bert = 'bert-base-multilingual-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_Bert)\nmodel = TFAutoModel.from_pretrained(model_Bert)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:08.702585Z","iopub.execute_input":"2022-05-06T22:04:08.702843Z","iopub.status.idle":"2022-05-06T22:04:53.799524Z","shell.execute_reply.started":"2022-05-06T22:04:08.702801Z","shell.execute_reply":"2022-05-06T22:04:53.798594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\" ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:53.801247Z","iopub.execute_input":"2022-05-06T22:04:53.801556Z","iopub.status.idle":"2022-05-06T22:04:53.80949Z","shell.execute_reply.started":"2022-05-06T22:04:53.801514Z","shell.execute_reply":"2022-05-06T22:04:53.808501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\ntest = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:53.811669Z","iopub.execute_input":"2022-05-06T22:04:53.812002Z","iopub.status.idle":"2022-05-06T22:04:54.081514Z","shell.execute_reply.started":"2022-05-06T22:04:53.811937Z","shell.execute_reply":"2022-05-06T22:04:54.080358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.082675Z","iopub.execute_input":"2022-05-06T22:04:54.082931Z","iopub.status.idle":"2022-05-06T22:04:54.09607Z","shell.execute_reply.started":"2022-05-06T22:04:54.082902Z","shell.execute_reply":"2022-05-06T22:04:54.095047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.097196Z","iopub.execute_input":"2022-05-06T22:04:54.097428Z","iopub.status.idle":"2022-05-06T22:04:54.109758Z","shell.execute_reply.started":"2022-05-06T22:04:54.097402Z","shell.execute_reply":"2022-05-06T22:04:54.108842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlabels, frequencies =np.unique(train['language'], return_counts=True)\nplt.figure(figsize=[10, 10])\nplt.pie(frequencies, labels=labels, autopct='%1.1f%%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.111433Z","iopub.execute_input":"2022-05-06T22:04:54.111754Z","iopub.status.idle":"2022-05-06T22:04:54.438637Z","shell.execute_reply.started":"2022-05-06T22:04:54.111713Z","shell.execute_reply":"2022-05-06T22:04:54.43802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[['premise', 'hypothesis', 'lang_abv', 'label']]\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.439801Z","iopub.execute_input":"2022-05-06T22:04:54.440059Z","iopub.status.idle":"2022-05-06T22:04:54.458278Z","shell.execute_reply.started":"2022-05-06T22:04:54.440031Z","shell.execute_reply":"2022-05-06T22:04:54.4577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.concat([train, xnli_df.loc[:100000],mnli.loc[:100000]], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.460322Z","iopub.execute_input":"2022-05-06T22:04:54.460859Z","iopub.status.idle":"2022-05-06T22:04:54.49561Z","shell.execute_reply.started":"2022-05-06T22:04:54.460802Z","shell.execute_reply":"2022-05-06T22:04:54.494719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.496818Z","iopub.execute_input":"2022-05-06T22:04:54.497092Z","iopub.status.idle":"2022-05-06T22:04:54.503227Z","shell.execute_reply.started":"2022-05-06T22:04:54.497063Z","shell.execute_reply":"2022-05-06T22:04:54.502394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEQ_LEN = 236  \n\ndef bert_encode(df, tokenizer):    \n    batch_premises = df['premise'].tolist()\n    batch_hypothesis = df['hypothesis'].tolist()\n\n    tokens = tokenizer(batch_premises, batch_hypothesis, max_length = SEQ_LEN,\n                   truncation=True, padding='max_length',\n                   add_special_tokens=True, return_attention_mask=True,\n                   return_token_type_ids=True,\n                   return_tensors='tf')\n    inputs = {\n          'input_ids': tokens['input_ids'], \n          'attention_mask': tokens['attention_mask'],\n          'token_type_ids': tokens['token_type_ids']  }  \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.504681Z","iopub.execute_input":"2022-05-06T22:04:54.505029Z","iopub.status.idle":"2022-05-06T22:04:54.515145Z","shell.execute_reply.started":"2022-05-06T22:04:54.504989Z","shell.execute_reply":"2022-05-06T22:04:54.514308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input = bert_encode(train, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:04:54.516327Z","iopub.execute_input":"2022-05-06T22:04:54.516632Z","iopub.status.idle":"2022-05-06T22:05:03.903634Z","shell.execute_reply.started":"2022-05-06T22:04:54.516603Z","shell.execute_reply":"2022-05-06T22:05:03.902548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:05:03.905285Z","iopub.execute_input":"2022-05-06T22:05:03.905508Z","iopub.status.idle":"2022-05-06T22:05:04.336492Z","shell.execute_reply.started":"2022-05-06T22:05:03.905482Z","shell.execute_reply":"2022-05-06T22:05:04.335849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\ndef build_model(): \n   \n    encoder = TFAutoModel.from_pretrained(model_Bert)\n    input_ids = tf.keras.Input(shape=(SEQ_LEN,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.Input(shape=(SEQ_LEN,), dtype=tf.int32, name=\"attention_mask\")\n    token_type_ids = tf.keras.Input(shape=(SEQ_LEN,), \n                                    dtype=tf.int32,  name=\"token_type_ids\")\n        \n    embedding = encoder([input_ids, attention_mask , token_type_ids])[0] \n    inputs=[input_ids, attention_mask  , token_type_ids ] \n    hp_units1 = 64 \n    hp_units2 = 32 \n    x = tf.keras.layers.Dense(units = hp_units1, activation=tf.nn.relu)(embedding[:,0,:])\n    x = tf.keras.layers.Dense(units = hp_units2, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(l2=1e-4))(x)\n    output = tf.keras.layers.Dense(3, activation='softmax')(x)\n      \n    model = tf.keras.Model(inputs=inputs, outputs=output)\n    hp_learning_rate = 1e-6\n    model.compile(tf.keras.optimizers.Adam(learning_rate = hp_learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])   \n    return model ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:05:04.337781Z","iopub.execute_input":"2022-05-06T22:05:04.338252Z","iopub.status.idle":"2022-05-06T22:05:04.348057Z","shell.execute_reply.started":"2022-05-06T22:05:04.338221Z","shell.execute_reply":"2022-05-06T22:05:04.347264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope(): \n    model = build_model()\n    model.summary()      \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:05:04.349118Z","iopub.execute_input":"2022-05-06T22:05:04.349646Z","iopub.status.idle":"2022-05-06T22:05:32.31621Z","shell.execute_reply.started":"2022-05-06T22:05:04.349612Z","shell.execute_reply":"2022-05-06T22:05:32.315576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in train_input.keys():\n    train_input[key] = train_input[key][:,:SEQ_LEN]","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:05:32.317548Z","iopub.execute_input":"2022-05-06T22:05:32.318535Z","iopub.status.idle":"2022-05-06T22:05:32.324958Z","shell.execute_reply.started":"2022-05-06T22:05:32.318492Z","shell.execute_reply":"2022-05-06T22:05:32.324115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory = model.fit(train_input, train['label'], epochs = 20, batch_size=64, \n                    validation_split = 0.2) #,callbacks=[hist]) verbose = 1,  ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:05:32.327339Z","iopub.execute_input":"2022-05-06T22:05:32.327571Z","iopub.status.idle":"2022-05-06T22:19:55.341762Z","shell.execute_reply.started":"2022-05-06T22:05:32.327546Z","shell.execute_reply":"2022-05-06T22:19:55.34055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:19:55.343724Z","iopub.execute_input":"2022-05-06T22:19:55.343998Z","iopub.status.idle":"2022-05-06T22:19:55.580452Z","shell.execute_reply.started":"2022-05-06T22:19:55.343969Z","shell.execute_reply":"2022-05-06T22:19:55.579434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.clf() \nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:19:55.582404Z","iopub.execute_input":"2022-05-06T22:19:55.582643Z","iopub.status.idle":"2022-05-06T22:19:55.816315Z","shell.execute_reply.started":"2022-05-06T22:19:55.582616Z","shell.execute_reply":"2022-05-06T22:19:55.815473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input = bert_encode(test, tokenizer) ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:19:55.817703Z","iopub.execute_input":"2022-05-06T22:19:55.817947Z","iopub.status.idle":"2022-05-06T22:19:56.591551Z","shell.execute_reply.started":"2022-05-06T22:19:55.81792Z","shell.execute_reply":"2022-05-06T22:19:56.590581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor key in test_input.keys():\n    test_input[key] = test_input[key][:,:SEQ_LEN]","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:19:56.592912Z","iopub.execute_input":"2022-05-06T22:19:56.593154Z","iopub.status.idle":"2022-05-06T22:19:56.601751Z","shell.execute_reply.started":"2022-05-06T22:19:56.593127Z","shell.execute_reply":"2022-05-06T22:19:56.601085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [np.argmax(i) for i in model.predict(test_input)]\nmodel.evaluate(test_input)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:19:56.603356Z","iopub.execute_input":"2022-05-06T22:19:56.603619Z","iopub.status.idle":"2022-05-06T22:20:22.00159Z","shell.execute_reply.started":"2022-05-06T22:19:56.603591Z","shell.execute_reply":"2022-05-06T22:20:22.00088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test.id.copy().to_frame()\nsubmission['prediction'] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:20:22.00482Z","iopub.execute_input":"2022-05-06T22:20:22.00512Z","iopub.status.idle":"2022-05-06T22:20:22.016414Z","shell.execute_reply.started":"2022-05-06T22:20:22.00509Z","shell.execute_reply":"2022-05-06T22:20:22.015409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"./submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:20:22.017888Z","iopub.execute_input":"2022-05-06T22:20:22.018127Z","iopub.status.idle":"2022-05-06T22:20:22.047065Z","shell.execute_reply.started":"2022-05-06T22:20:22.0181Z","shell.execute_reply":"2022-05-06T22:20:22.046065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:20:22.048438Z","iopub.execute_input":"2022-05-06T22:20:22.048956Z","iopub.status.idle":"2022-05-06T22:20:22.06036Z","shell.execute_reply.started":"2022-05-06T22:20:22.048922Z","shell.execute_reply":"2022-05-06T22:20:22.059626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}