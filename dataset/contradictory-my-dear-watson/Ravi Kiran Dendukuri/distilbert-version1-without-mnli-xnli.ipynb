{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, Adamax\n\nfrom transformers import DistilBertTokenizer, TFDistilBertModel\n\nfrom sklearn.model_selection import train_test_split\n\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport warnings,json\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T22:41:36.104836Z","iopub.execute_input":"2022-05-06T22:41:36.105411Z","iopub.status.idle":"2022-05-06T22:41:44.876837Z","shell.execute_reply.started":"2022-05-06T22:41:36.105302Z","shell.execute_reply":"2022-05-06T22:41:44.875731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:44.878742Z","iopub.execute_input":"2022-05-06T22:41:44.879126Z","iopub.status.idle":"2022-05-06T22:41:44.885661Z","shell.execute_reply.started":"2022-05-06T22:41:44.879068Z","shell.execute_reply":"2022-05-06T22:41:44.884838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Init_TPU():  \n\n    try:\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(resolver)\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n        REPLICAS = strategy.num_replicas_in_sync\n        print(\"Connected to TPU Successfully:\\n TPUs Initialised with Replicas:\",REPLICAS)\n        \n        return strategy\n    \n    except ValueError:\n        \n        print(\"Connection to TPU Falied\")\n        print(\"Using default strategy for CPU and single GPU\")\n        strategy = tf.distribute.get_strategy()\n        \n        return strategy\n    \nstrategy=Init_TPU()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:44.887161Z","iopub.execute_input":"2022-05-06T22:41:44.887702Z","iopub.status.idle":"2022-05-06T22:41:51.24562Z","shell.execute_reply.started":"2022-05-06T22:41:44.887664Z","shell.execute_reply":"2022-05-06T22:41:51.244715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/contradictory-my-dear-watson/'","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:51.247757Z","iopub.execute_input":"2022-05-06T22:41:51.248029Z","iopub.status.idle":"2022-05-06T22:41:51.25289Z","shell.execute_reply.started":"2022-05-06T22:41:51.247999Z","shell.execute_reply":"2022-05-06T22:41:51.25198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_url = os.path.join(path,'train.csv')\ntrain_data = pd.read_csv(train_url, header='infer')\n\nsample_sub_url = os.path.join(path,'sample_submission.csv')\nsample_sub = pd.read_csv(sample_sub_url, header='infer')\n\ntest_url = os.path.join(path,'test.csv')\ntest_data = pd.read_csv(test_url, header='infer')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:51.253924Z","iopub.execute_input":"2022-05-06T22:41:51.254155Z","iopub.status.idle":"2022-05-06T22:41:51.467773Z","shell.execute_reply.started":"2022-05-06T22:41:51.25413Z","shell.execute_reply":"2022-05-06T22:41:51.46689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:51.469722Z","iopub.execute_input":"2022-05-06T22:41:51.469996Z","iopub.status.idle":"2022-05-06T22:41:51.491841Z","shell.execute_reply.started":"2022-05-06T22:41:51.469965Z","shell.execute_reply":"2022-05-06T22:41:51.491011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:51.493401Z","iopub.execute_input":"2022-05-06T22:41:51.493761Z","iopub.status.idle":"2022-05-06T22:41:51.685465Z","shell.execute_reply.started":"2022-05-06T22:41:51.493703Z","shell.execute_reply":"2022-05-06T22:41:51.684638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformer Model Name\ntransformer_model = 'distilbert-base-multilingual-cased'\n\n# Define Tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained(transformer_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:51.687017Z","iopub.execute_input":"2022-05-06T22:41:51.687832Z","iopub.status.idle":"2022-05-06T22:41:53.811198Z","shell.execute_reply.started":"2022-05-06T22:41:51.687788Z","shell.execute_reply":"2022-05-06T22:41:53.810201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the output of tokenizer\ntokenizer.convert_tokens_to_ids(list(tokenizer.tokenize(\"Elementary, My Dear Watson!\")))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:53.812604Z","iopub.execute_input":"2022-05-06T22:41:53.812849Z","iopub.status.idle":"2022-05-06T22:41:53.820596Z","shell.execute_reply.started":"2022-05-06T22:41:53.81282Z","shell.execute_reply":"2022-05-06T22:41:53.819981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create seperate list from Train & Test Dataframes with only Premise & Hypothesis\ntrain = train_data[['premise','hypothesis']].values.tolist()\ntest = test_data[['premise','hypothesis']].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:53.823129Z","iopub.execute_input":"2022-05-06T22:41:53.823912Z","iopub.status.idle":"2022-05-06T22:41:53.856656Z","shell.execute_reply.started":"2022-05-06T22:41:53.823854Z","shell.execute_reply":"2022-05-06T22:41:53.85573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Max Length\nmax_len = 80   # << change if you wish\n\n# Encode the training & test data \ntrain_encode = tokenizer.batch_encode_plus(train, pad_to_max_length=True, max_length=max_len)\ntest_encode = tokenizer.batch_encode_plus(test, pad_to_max_length=True, max_length=max_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:41:53.857905Z","iopub.execute_input":"2022-05-06T22:41:53.858309Z","iopub.status.idle":"2022-05-06T22:42:12.094323Z","shell.execute_reply.started":"2022-05-06T22:41:53.85828Z","shell.execute_reply":"2022-05-06T22:42:12.093469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the Training Data into Training (90%) & Validation (10%)\n\ntest_size = 0.1  # << change if you wish\nx_train, x_val, y_train, y_val = train_test_split(train_encode['input_ids'], train_data.label.values, test_size=test_size)\n\n\n# Split Test Data\nx_test = test_encode['input_ids']","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:42:12.095434Z","iopub.execute_input":"2022-05-06T22:42:12.096246Z","iopub.status.idle":"2022-05-06T22:42:12.111163Z","shell.execute_reply.started":"2022-05-06T22:42:12.096206Z","shell.execute_reply":"2022-05-06T22:42:12.109783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#garbage collect\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:42:12.112471Z","iopub.execute_input":"2022-05-06T22:42:12.112724Z","iopub.status.idle":"2022-05-06T22:42:12.362647Z","shell.execute_reply.started":"2022-05-06T22:42:12.112696Z","shell.execute_reply":"2022-05-06T22:42:12.361747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading Data Into TensorFlow Dataset\nAUTO = tf.data.experimental.AUTOTUNE\nbatch_size = 16 * strategy.num_replicas_in_sync\n\ntrain_ds = (tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat().shuffle(3072).batch(batch_size).prefetch(AUTO))\nval_ds = (tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size).prefetch(AUTO))\n\ntest_ds = (tf.data.Dataset.from_tensor_slices(x_test).batch(batch_size))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:42:12.363708Z","iopub.execute_input":"2022-05-06T22:42:12.363981Z","iopub.status.idle":"2022-05-06T22:42:17.41784Z","shell.execute_reply.started":"2022-05-06T22:42:12.363951Z","shell.execute_reply":"2022-05-06T22:42:17.41717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage Collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:42:17.419126Z","iopub.execute_input":"2022-05-06T22:42:17.419894Z","iopub.status.idle":"2022-05-06T22:42:17.660581Z","shell.execute_reply.started":"2022-05-06T22:42:17.419826Z","shell.execute_reply":"2022-05-06T22:42:17.659242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(strategy,transformer):\n    with strategy.scope():\n        transformer_encoder = TFDistilBertModel.from_pretrained(transformer)  #Pretrained BERT Transformer Model\n        \n        input_layer = Input(shape=(max_len,), dtype=tf.int32, name=\"input_layer\")\n        \n        sequence_output = transformer_encoder(input_layer)[0]\n        \n        cls_token = sequence_output[:, 0, :]\n        \n        output_layer = Dense(3, activation='softmax')(cls_token)\n        \n        model = Model(inputs=input_layer, outputs=output_layer)\n        \n        model.compile(\n            Adamax(lr=1e-5), \n            loss='sparse_categorical_crossentropy', \n            metrics=['accuracy']\n        )\n        \n        return model\n    \n\n# Applying the build model function\nmodel = build_model(strategy,transformer_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:42:17.662096Z","iopub.execute_input":"2022-05-06T22:42:17.662335Z","iopub.status.idle":"2022-05-06T22:43:11.544292Z","shell.execute_reply.started":"2022-05-06T22:42:17.662309Z","shell.execute_reply":"2022-05-06T22:43:11.54361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:43:11.545249Z","iopub.execute_input":"2022-05-06T22:43:11.545903Z","iopub.status.idle":"2022-05-06T22:43:11.561992Z","shell.execute_reply.started":"2022-05-06T22:43:11.54586Z","shell.execute_reply":"2022-05-06T22:43:11.561164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Model\n\nepochs = 30  # < change if you wish\nn_steps = len(train_data) // batch_size \n\nmodel.fit(train_ds, \n          steps_per_epoch = n_steps, \n          validation_data = val_ds,\n          epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:43:11.563733Z","iopub.execute_input":"2022-05-06T22:43:11.564059Z","iopub.status.idle":"2022-05-06T22:47:02.881792Z","shell.execute_reply.started":"2022-05-06T22:43:11.564019Z","shell.execute_reply":"2022-05-06T22:47:02.880913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage Collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:47:02.88316Z","iopub.execute_input":"2022-05-06T22:47:02.883397Z","iopub.status.idle":"2022-05-06T22:47:03.520278Z","shell.execute_reply.started":"2022-05-06T22:47:02.88337Z","shell.execute_reply":"2022-05-06T22:47:03.519436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(test_ds, verbose=0)\nsample_sub['prediction'] = prediction.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:47:03.521717Z","iopub.execute_input":"2022-05-06T22:47:03.522033Z","iopub.status.idle":"2022-05-06T22:47:12.651621Z","shell.execute_reply.started":"2022-05-06T22:47:03.521994Z","shell.execute_reply":"2022-05-06T22:47:12.650598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:47:12.652848Z","iopub.execute_input":"2022-05-06T22:47:12.653175Z","iopub.status.idle":"2022-05-06T22:47:12.671689Z","shell.execute_reply.started":"2022-05-06T22:47:12.653144Z","shell.execute_reply":"2022-05-06T22:47:12.670473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T22:47:12.673399Z","iopub.execute_input":"2022-05-06T22:47:12.673738Z","iopub.status.idle":"2022-05-06T22:47:12.68381Z","shell.execute_reply.started":"2022-05-06T22:47:12.673694Z","shell.execute_reply":"2022-05-06T22:47:12.682918Z"},"trusted":true},"execution_count":null,"outputs":[]}]}