{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Natural Language Inferencing (NLI) is a classic NLP (Natural Language Processing) problem that involves taking two sentences (the _premise_ and the _hypothesis_ ), and deciding how they are related- if the premise entails the hypothesis, contradicts it, or neither.\n\nIn this tutorial we'll look at the _Contradictory, My Dear Watson_ competition dataset, build a preliminary model using Tensorflow 2, Keras, and BERT, and prepare a submission file.","metadata":{"_uuid":"7edff2eb-50cb-4285-8255-b3262dbd5161","_cell_guid":"5c1b75ee-94f3-40c8-adbe-4ca8325b9f9c","trusted":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"d3a20929-8e1d-48d2-869c-cc57f8c63cc9","_cell_guid":"20666a1f-e31b-4134-94f8-fea9a50998d3","execution":{"iopub.status.busy":"2022-01-25T05:57:08.938548Z","iopub.execute_input":"2022-01-25T05:57:08.938922Z","iopub.status.idle":"2022-01-25T05:57:08.952382Z","shell.execute_reply.started":"2022-01-25T05:57:08.938885Z","shell.execute_reply":"2022-01-25T05:57:08.951342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning","metadata":{"execution":{"iopub.status.busy":"2022-01-25T05:57:14.973838Z","iopub.execute_input":"2022-01-25T05:57:14.974478Z","iopub.status.idle":"2022-01-25T05:57:14.978033Z","shell.execute_reply.started":"2022-01-25T05:57:14.974428Z","shell.execute_reply":"2022-01-25T05:57:14.977414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFRobertaModel\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","metadata":{"_uuid":"e3dd507b-c502-488c-9dd0-419c5d73c159","_cell_guid":"863de620-d4b7-4711-b587-e1c75be9e36f","execution":{"iopub.status.busy":"2022-01-25T18:23:21.236585Z","iopub.execute_input":"2022-01-25T18:23:21.237661Z","iopub.status.idle":"2022-01-25T18:23:28.898447Z","shell.execute_reply.started":"2022-01-25T18:23:21.237597Z","shell.execute_reply":"2022-01-25T18:23:28.897551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's set up our TPU.","metadata":{"_uuid":"58fb9ec5-c099-494c-bf59-6ec9d6e64628","_cell_guid":"6c5122f9-8c39-4892-81a9-1f8830b64484","trusted":true}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"_uuid":"386d0823-63ab-4765-9561-32c5f382e71d","_cell_guid":"ca2729e3-9275-4a9c-b150-592320bd3e54","execution":{"iopub.status.busy":"2022-01-25T05:58:04.575206Z","iopub.execute_input":"2022-01-25T05:58:04.575552Z","iopub.status.idle":"2022-01-25T05:58:10.750359Z","shell.execute_reply.started":"2022-01-25T05:58:04.575516Z","shell.execute_reply":"2022-01-25T05:58:10.749488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Data","metadata":{"_uuid":"0b64130f-530a-4560-8afd-462a55fc14b3","_cell_guid":"44a1d22f-053c-4188-b25f-d714aa745016","trusted":true}},{"cell_type":"markdown","source":"The training set contains a premise, a hypothesis, a label (0 = entailment, 1 = neutral, 2 = contradiction), and the language of the text. For more information about what these mean and how the data is structured, check out the data page: https://www.kaggle.com/c/contradictory-my-dear-watson/data","metadata":{"_uuid":"b9285071-38f2-421b-9b1c-9c44d41c7365","_cell_guid":"6fb2939c-b14a-450f-85dd-7220439eaf55","trusted":true}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")","metadata":{"_uuid":"6e60d19f-aeae-417a-a10a-50cc1d5ee685","_cell_guid":"f3ad567b-a156-4ffc-a6f8-1f5e6e989a4e","execution":{"iopub.status.busy":"2022-01-25T05:58:18.342951Z","iopub.execute_input":"2022-01-25T05:58:18.343243Z","iopub.status.idle":"2022-01-25T05:58:18.491268Z","shell.execute_reply.started":"2022-01-25T05:58:18.343213Z","shell.execute_reply":"2022-01-25T05:58:18.490259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use the pandas head() function to take a quick look at the training set.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"82e6d183-b8e1-412b-816f-c9020bac1428","_cell_guid":"d3b9a632-7abb-4bef-acd3-9cba577dc2c0","execution":{"iopub.status.busy":"2022-01-24T23:16:24.396027Z","iopub.execute_input":"2022-01-24T23:16:24.39636Z","iopub.status.idle":"2022-01-24T23:16:24.41085Z","shell.execute_reply.started":"2022-01-24T23:16:24.39633Z","shell.execute_reply":"2022-01-24T23:16:24.410266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at one of the pairs of sentences.","metadata":{"_uuid":"abfb11e9-865c-4b50-b0cc-9d25851618ff","_cell_guid":"817c2470-9778-46e8-be86-fdd1b9449b93","trusted":true}},{"cell_type":"code","source":"train.premise.values[1]","metadata":{"_uuid":"dea716f0-9698-4a10-a7f1-1a0bb36054db","_cell_guid":"bcca3548-bb15-4868-86ec-95fe084d6e06","execution":{"iopub.status.busy":"2022-01-24T23:16:24.4122Z","iopub.execute_input":"2022-01-24T23:16:24.412451Z","iopub.status.idle":"2022-01-24T23:16:24.420655Z","shell.execute_reply.started":"2022-01-24T23:16:24.412424Z","shell.execute_reply":"2022-01-24T23:16:24.419836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hypothesis.values[1]","metadata":{"_uuid":"5b639eff-aeea-4dca-b516-7e729cdeb741","_cell_guid":"15dcbe6c-4914-4400-a8fd-65b6e4cbf652","execution":{"iopub.status.busy":"2022-01-24T23:16:24.421968Z","iopub.execute_input":"2022-01-24T23:16:24.422419Z","iopub.status.idle":"2022-01-24T23:16:24.435032Z","shell.execute_reply.started":"2022-01-24T23:16:24.422381Z","shell.execute_reply":"2022-01-24T23:16:24.434276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.label.values[1]","metadata":{"_uuid":"c63a91e0-05f7-4a67-acf8-2131ef50f054","_cell_guid":"e16e8879-c565-4a29-bacc-26648659da29","execution":{"iopub.status.busy":"2022-01-24T23:16:24.436307Z","iopub.execute_input":"2022-01-24T23:16:24.436964Z","iopub.status.idle":"2022-01-24T23:16:24.448947Z","shell.execute_reply.started":"2022-01-24T23:16:24.436929Z","shell.execute_reply":"2022-01-24T23:16:24.448103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These statements are contradictory, and the label shows that.\n\nLet's look at the distribution of languages in the training set.","metadata":{"_uuid":"216dc9c2-1699-4b89-af27-443d1b4c7289","_cell_guid":"8c9122ea-797d-48f1-b4ba-85bc2e0e6f18","trusted":true}},{"cell_type":"code","source":"labels, frequencies = np.unique(train.language.values, return_counts = True)\n\nplt.figure(figsize = (10,10))\nplt.pie(frequencies,labels = labels, autopct = '%1.1f%%')\nplt.show()","metadata":{"_uuid":"7243f511-d81e-436c-971f-6328b7c0cf43","_cell_guid":"7d9b43ef-4ac1-40d5-aebc-a162f1b9a6c0","execution":{"iopub.status.busy":"2022-01-24T23:16:24.450315Z","iopub.execute_input":"2022-01-24T23:16:24.451043Z","iopub.status.idle":"2022-01-24T23:16:24.701701Z","shell.execute_reply.started":"2022-01-24T23:16:24.451005Z","shell.execute_reply":"2022-01-24T23:16:24.700687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nlp\nfrom nlp import load_dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-25T05:58:45.014425Z","iopub.execute_input":"2022-01-25T05:58:45.015363Z","iopub.status.idle":"2022-01-25T05:58:57.342501Z","shell.execute_reply.started":"2022-01-25T05:58:45.015327Z","shell.execute_reply":"2022-01-25T05:58:57.341704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    validation=True\n    result = []\n    dataset = load_dataset('multi_nli')\n    keys = ['train', 'validation_matched','validation_mismatched'] if validation else ['train']\n    for k in keys:\n        for record in dataset[k]:\n            p, h, l = record['premise'], record['hypothesis'], record['label']\n            if p and h and l in {0,1,2}:\n                result.append((p,h,l,'en'))\n    result = pd.DataFrame(result, columns=['premise','hypothesis', 'label','lang_abv'])\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-01-25T05:59:12.176012Z","iopub.execute_input":"2022-01-25T05:59:12.176522Z","iopub.status.idle":"2022-01-25T05:59:12.184365Z","shell.execute_reply.started":"2022-01-25T05:59:12.176487Z","shell.execute_reply":"2022-01-25T05:59:12.183378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = load_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T05:59:14.015265Z","iopub.execute_input":"2022-01-25T05:59:14.016106Z","iopub.status.idle":"2022-01-25T05:59:59.462055Z","shell.execute_reply.started":"2022-01-25T05:59:14.016065Z","shell.execute_reply":"2022-01-25T05:59:59.461019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = mnli[['premise', 'hypothesis', 'lang_abv', 'label']]\nmnli.insert(0, 'language', 'English')\nmnli = mnli[['premise', 'hypothesis', 'lang_abv', 'language', 'label']]\nmnli.insert(0, 'id', 'xxx')\nmnli.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T05:59:59.464086Z","iopub.execute_input":"2022-01-25T05:59:59.464362Z","iopub.status.idle":"2022-01-25T05:59:59.704633Z","shell.execute_reply.started":"2022-01-25T05:59:59.464333Z","shell.execute_reply":"2022-01-25T05:59:59.703736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_training_data = train[['id', 'premise', 'hypothesis','lang_abv', 'language', 'label']]\nall_training_data = pd.concat([all_training_data, mnli], axis = 0)\nall_training_data","metadata":{"execution":{"iopub.status.busy":"2022-01-25T06:00:04.813995Z","iopub.execute_input":"2022-01-25T06:00:04.815042Z","iopub.status.idle":"2022-01-25T06:00:04.904622Z","shell.execute_reply.started":"2022-01-25T06:00:04.815Z","shell.execute_reply":"2022-01-25T06:00:04.903692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Data for Input","metadata":{"_uuid":"68cee874-838e-4f0e-9f80-bfebc4a295d0","_cell_guid":"a7f5d429-083e-4d81-883f-e032dfb0e236","trusted":true}},{"cell_type":"markdown","source":"To start out, we can use a pretrained model. Here, we'll use a multilingual BERT model from huggingface. For more information about BERT, see: https://github.com/google-research/bert/blob/master/multilingual.md\n\nFirst, we download the tokenizer.","metadata":{"_uuid":"27e66828-76b9-44f4-ba79-66fe0cb8f922","_cell_guid":"f20a33db-a377-43b6-825e-157456ed1092","trusted":true}},{"cell_type":"code","source":"model_name = \"roberta-large-mnli\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"0af7b876-e719-474a-b6a5-fef500624b83","_cell_guid":"ddc3e65e-24a4-43dc-98f0-194655d17cfd","execution":{"iopub.status.busy":"2022-01-25T06:35:25.783053Z","iopub.execute_input":"2022-01-25T06:35:25.78343Z","iopub.status.idle":"2022-01-25T06:35:28.983002Z","shell.execute_reply.started":"2022-01-25T06:35:25.783394Z","shell.execute_reply":"2022-01-25T06:35:28.981915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tokenizers turn sequences of words into arrays of numbers. Let's look at an example:","metadata":{"_uuid":"a6088f3d-8778-4a6c-82b0-db6a5461ec95","_cell_guid":"f6f4ab91-c9b5-4861-a400-89969200b7f4","trusted":true}},{"cell_type":"code","source":"def encode_sentence(s):\n   return tokenizer(s)['input_ids']","metadata":{"_uuid":"2cd597c4-6204-44ba-869a-fbf7c32c711d","_cell_guid":"55838dc3-c459-4097-b5b2-44d049429e25","execution":{"iopub.status.busy":"2022-01-25T06:40:36.865067Z","iopub.execute_input":"2022-01-25T06:40:36.865575Z","iopub.status.idle":"2022-01-25T06:40:36.87004Z","shell.execute_reply.started":"2022-01-25T06:40:36.865525Z","shell.execute_reply":"2022-01-25T06:40:36.869055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(encode_sentence(\"I love machine learning\"))\nprint(encode_sentence(\"Machine Learning is great\"))","metadata":{"_uuid":"797de062-6743-4455-9ead-73527bf6c3b6","_cell_guid":"f05a9baa-b7fa-44da-89dd-04fdfc149cba","execution":{"iopub.status.busy":"2022-01-25T06:40:38.456031Z","iopub.execute_input":"2022-01-25T06:40:38.456545Z","iopub.status.idle":"2022-01-25T06:40:38.462688Z","shell.execute_reply.started":"2022-01-25T06:40:38.456508Z","shell.execute_reply":"2022-01-25T06:40:38.461734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"roBERTa uses two kind of input data- input word IDs and input masks.\n\nThese allow the model to know that the premise and hypothesis are distinct sentences, and also to ignore any padding from the tokenizer.\n\nNow, we're going to encode all of our premise/hypothesis pairs for input into roBERTa.","metadata":{"_uuid":"1fb6acf3-3c19-494e-83bd-84d6d933e6f0","_cell_guid":"e80e3fcd-513e-4d14-88fd-9417b746c107","trusted":true}},{"cell_type":"code","source":"def roberta_encode(hypotheses, premises, tokenizer):\n    \n  num_examples = len(hypotheses)\n  \n  sentence1 = tf.ragged.constant([\n      encode_sentence(s)\n      for s in np.array(hypotheses)])\n  sentence2 = tf.ragged.constant([\n      encode_sentence(s)\n       for s in np.array(premises)])\n\n    \n  input_word_ids = tf.concat([sentence1, sentence2], axis=-1)\n\n  input_mask = tf.ones_like(input_word_ids).to_tensor()\n\n  inputs = {\n      'input_word_ids': input_word_ids.to_tensor(),\n      'input_mask': input_mask,}\n\n  return inputs","metadata":{"_uuid":"dedb18d0-63cb-492b-8fe0-b4ebb8819e4c","_cell_guid":"037b0a29-3e6d-42b6-b13a-328fab19d15d","execution":{"iopub.status.busy":"2022-01-25T06:41:18.224572Z","iopub.execute_input":"2022-01-25T06:41:18.225597Z","iopub.status.idle":"2022-01-25T06:41:18.233065Z","shell.execute_reply.started":"2022-01-25T06:41:18.225552Z","shell.execute_reply":"2022-01-25T06:41:18.232138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input = roberta_encode(all_training_data.premise.values, all_training_data.hypothesis.values, tokenizer)","metadata":{"_uuid":"697579c5-9f89-421c-8cbc-4321a7c93179","_cell_guid":"fc14d779-d0c6-4585-8e80-ebf539bd132c","execution":{"iopub.status.busy":"2022-01-25T06:41:22.494493Z","iopub.execute_input":"2022-01-25T06:41:22.495092Z","iopub.status.idle":"2022-01-25T06:44:48.065174Z","shell.execute_reply.started":"2022-01-25T06:41:22.495053Z","shell.execute_reply":"2022-01-25T06:44:48.063942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating & Training Model","metadata":{"_uuid":"e1bf9ee4-e872-45d8-a118-a72eb7917d8b","_cell_guid":"3dbd7066-6469-4823-8e09-e2dfa0a68bcc","trusted":true}},{"cell_type":"markdown","source":"Now, we can incorporate the roBERTa transformer into a Keras Functional Model. For more information about the Keras Functional API, see: https://www.tensorflow.org/guide/keras/functional.\n\nThis model was inspired by the model in this notebook: https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert#BERT-and-Its-Implementation-on-this-Competition, which is a wonderful introduction to NLP!","metadata":{"_uuid":"33811793-9df3-4d97-84c3-c5367a130cd7","_cell_guid":"7ebc4032-48bf-4bbd-8244-6b4ee38a1f56","trusted":true}},{"cell_type":"code","source":"max_len = 250\n\ndef max_length(file):\n    for key in file.keys():\n        file[key] = file[key][:,:max_len]\n    return file\n\ndef build_model():\n    roberta_encoder = TFRobertaModel.from_pretrained(model_name)\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    \n    embedding = roberta_encoder([input_word_ids, input_mask])[0]\n    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n    \n    model = tf.keras.Model(inputs=[input_word_ids, input_mask], outputs=output)\n    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"_uuid":"1094f3ff-6b5b-4b15-9d93-b0065ae586bd","_cell_guid":"69f90af1-4d66-4b83-a264-df23a3a68e26","execution":{"iopub.status.busy":"2022-01-25T18:23:33.758667Z","iopub.execute_input":"2022-01-25T18:23:33.759099Z","iopub.status.idle":"2022-01-25T18:23:33.767979Z","shell.execute_reply.started":"2022-01-25T18:23:33.759061Z","shell.execute_reply":"2022-01-25T18:23:33.767179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()\n    model.summary()","metadata":{"_uuid":"47c8cc2f-a7b9-4bae-971b-e41277b45c8b","_cell_guid":"97885b33-70f1-4d14-b788-fd1a650d5a57","execution":{"iopub.status.busy":"2022-01-25T06:45:42.055611Z","iopub.execute_input":"2022-01-25T06:45:42.056188Z","iopub.status.idle":"2022-01-25T06:47:05.202677Z","shell.execute_reply.started":"2022-01-25T06:45:42.056153Z","shell.execute_reply":"2022-01-25T06:47:05.201335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze model\nmodel.layers[2].trainable=True","metadata":{"execution":{"iopub.status.busy":"2022-01-25T06:47:34.974629Z","iopub.execute_input":"2022-01-25T06:47:34.974975Z","iopub.status.idle":"2022-01-25T06:47:34.99423Z","shell.execute_reply.started":"2022-01-25T06:47:34.974933Z","shell.execute_reply":"2022-01-25T06:47:34.993441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input = max_length(train_input)\nmodel.fit(train_input, all_training_data.label.values, epochs = 10, verbose = 1, batch_size = 64, validation_split = 0.2)","metadata":{"_uuid":"316f4376-9df7-40ea-bbbd-ae46eb5562e5","_cell_guid":"0423d993-8ff5-4ab9-bc47-87e1cb74c0c5","execution":{"iopub.status.busy":"2022-01-25T06:47:43.185815Z","iopub.execute_input":"2022-01-25T06:47:43.186331Z","iopub.status.idle":"2022-01-25T10:53:57.306777Z","shell.execute_reply.started":"2022-01-25T06:47:43.186283Z","shell.execute_reply":"2022-01-25T10:53:57.304816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\ntest_input = bert_encode(test.premise.values, test.hypothesis.values, tokenizer)","metadata":{"_uuid":"3bfd96e9-cf2c-41ad-bdcc-8c31408f05bd","_cell_guid":"e26cba08-7fe9-4e2e-ab2e-062a26a5fcac","execution":{"iopub.status.busy":"2022-01-25T10:53:57.313599Z","iopub.execute_input":"2022-01-25T10:53:57.313898Z","iopub.status.idle":"2022-01-25T10:54:01.237608Z","shell.execute_reply.started":"2022-01-25T10:53:57.313869Z","shell.execute_reply":"2022-01-25T10:54:01.236748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"_uuid":"9f040800-653f-4f51-9f60-0456d89068be","_cell_guid":"4b871234-9a42-4f5e-9792-7fc90615b808","execution":{"iopub.status.busy":"2022-01-25T10:54:01.239125Z","iopub.execute_input":"2022-01-25T10:54:01.239355Z","iopub.status.idle":"2022-01-25T10:54:01.257657Z","shell.execute_reply.started":"2022-01-25T10:54:01.239324Z","shell.execute_reply":"2022-01-25T10:54:01.256969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating & Submitting Predictions","metadata":{"_uuid":"fb1ff888-7684-4888-b861-3c31a3f360b7","_cell_guid":"87b18b05-30f3-45f9-9c3e-6f8184934bd0","trusted":true}},{"cell_type":"code","source":"test_input = max_length(test_input)\npredictions = [np.argmax(i) for i in model.predict(test_input)]","metadata":{"_uuid":"f9db46a1-1f83-4ddb-85bf-da8f40afe623","_cell_guid":"a7ab0c33-0377-4cb2-b4f9-fc489383fdb7","execution":{"iopub.status.busy":"2022-01-25T10:54:01.259818Z","iopub.execute_input":"2022-01-25T10:54:01.260213Z","iopub.status.idle":"2022-01-25T10:54:38.582625Z","shell.execute_reply.started":"2022-01-25T10:54:01.260177Z","shell.execute_reply":"2022-01-25T10:54:38.581613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The submission file will consist of the ID column and a prediction column. We can just copy the ID column from the test file, make it a dataframe, and then add our prediction column.","metadata":{"_uuid":"7b489c00-896d-44af-9371-16c2cf222365","_cell_guid":"1d0e8e42-2746-4331-95a5-3eb78ca6861c","trusted":true}},{"cell_type":"code","source":"submission = test.id.copy().to_frame()\nsubmission['prediction'] = predictions","metadata":{"_uuid":"9e0e34fa-1ef7-4207-a5c3-c21863c7be27","_cell_guid":"add7302f-ae26-4e78-b69d-858cacb35991","execution":{"iopub.status.busy":"2022-01-25T10:54:38.584267Z","iopub.execute_input":"2022-01-25T10:54:38.584638Z","iopub.status.idle":"2022-01-25T10:54:38.600847Z","shell.execute_reply.started":"2022-01-25T10:54:38.584594Z","shell.execute_reply":"2022-01-25T10:54:38.60012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"_uuid":"1d4999aa-10d2-4a88-962a-8f10bded837b","_cell_guid":"d4fdefdc-4839-4962-ae75-6807390a6de7","execution":{"iopub.status.busy":"2022-01-25T10:54:38.601991Z","iopub.execute_input":"2022-01-25T10:54:38.602606Z","iopub.status.idle":"2022-01-25T10:54:38.62324Z","shell.execute_reply.started":"2022-01-25T10:54:38.602565Z","shell.execute_reply":"2022-01-25T10:54:38.622632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"_uuid":"b8463f7e-8b2f-4c24-8eb3-a35ec02a2d6e","_cell_guid":"84abe9e3-ef04-4dac-97d2-2308a0f11313","execution":{"iopub.status.busy":"2022-01-25T10:54:38.624256Z","iopub.execute_input":"2022-01-25T10:54:38.62478Z","iopub.status.idle":"2022-01-25T10:54:38.656519Z","shell.execute_reply.started":"2022-01-25T10:54:38.62475Z","shell.execute_reply":"2022-01-25T10:54:38.65558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now we've created our submission file, which can be submitted to the competition. Good luck!","metadata":{"_uuid":"1af8c748-a13d-4274-9208-94d9895fdc19","_cell_guid":"4d057f53-824d-400f-b9f0-5adfc06322ef","trusted":true}}]}