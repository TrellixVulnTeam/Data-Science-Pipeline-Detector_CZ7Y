{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install sentence-transformers\n!pip install pandas\n!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\"\nThis examples trains a CrossEncoder for the NLI task. A CrossEncoder takes a sentence pair\nas input and outputs a label. Here, it learns to predict the labels: \"contradiction\": 0, \"entailment\": 1, \"neutral\": 2.\nIt does NOT produce a sentence embedding and does NOT work for individual sentences.\nUsage:\npython training_nli.py\n\"\"\"\nimport pandas\nfrom torch.utils.data import DataLoader\nimport math\nfrom sentence_transformers import LoggingHandler, util\nfrom sentence_transformers.cross_encoder import CrossEncoder\nfrom sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\nfrom sentence_transformers.readers import InputExample\nimport logging\nfrom datetime import datetime\nimport numpy as np\nimport csv\n\n#### Just some code to print debug information to stdout\nlogging.basicConfig(format='%(asctime)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    level=logging.INFO,\n                    handlers=[LoggingHandler()])\n#### /print debug information to stdout\n\n\n# As dataset, we use SNLI + MultiNLI\n# Check if dataset exsist. If not, download and extract  it\n\ndataset_path = '../input/contradictory-my-dear-watson/train.csv'\n\n# Read the AllNLI.tsv.gz file and create the training dataset\nlogging.info(\"Read AllNLI train dataset\")\n\nlabel2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\ntrain_samples = []\ndev_samples = []\ntrain_data = pandas.read_csv(dataset_path)\ntrain_data['label'] = train_data['label'].replace([0, 2], [2, 0])\nfor id, row in train_data.iterrows():\n    label_id = int(row['label'])\n    train_samples.append(InputExample(texts=[row['premise'], row['hypothesis']], label=label_id))\n\ntrain_batch_size = 16\nnum_epochs = 20\nmodel_save_path = './training_allnli-' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n# Define our CrossEncoder model. We use distilroberta-base as basis and setup it up to predict 3 labels\n# model = CrossEncoder('sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking', num_labels=len(label2int))\nmodel = CrossEncoder('sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens', num_labels=len(label2int))\n# model = CrossEncoder('xlm-roberta-base', num_labels=len(label2int))\n\n# Trye smaller batch size\n# model = CrossEncoder('joeddav/xlm-roberta-large-xnli', num_labels=len(label2int))\n\n# We wrap train_samples, which is a list ot InputExample, in a pytorch DataLoader\ntrain_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n\n# During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\nevaluator = CESoftmaxAccuracyEvaluator.from_input_examples(dev_samples, name='AllNLI-dev')\n\nwarmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\nlogging.info(\"Warmup-steps: {}\".format(warmup_steps))\n\n# Train the model\nmodel.fit(train_dataloader=train_dataloader,\n          epochs=num_epochs,\n          warmup_steps=warmup_steps,\n          output_path=model_save_path)\n\ntest_dataset = '../input/contradictory-my-dear-watson/test.csv'\ndf = pandas.read_csv(test_dataset)\nsentence_pairs = []\nids = []\nfor id, row in df.iterrows():\n    label_id = 0\n    ids.append(row['id'])\n    sentence_pairs.append([row['premise'], row['hypothesis']])\n\npred_scores = model.predict(sentence_pairs, convert_to_numpy=True, show_progress_bar=False, \n                            batch_size=train_batch_size)\npred_labels = np.argmax(pred_scores, axis=1)\n\nout_df = pandas.DataFrame([ids, pred_labels]).transpose()\nout_df = out_df.rename(columns={0: 'id', 1: 'prediction'})\nout_df['prediction'] = out_df['prediction'].replace([0, 2],[2, 0])\n\nout_df.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}