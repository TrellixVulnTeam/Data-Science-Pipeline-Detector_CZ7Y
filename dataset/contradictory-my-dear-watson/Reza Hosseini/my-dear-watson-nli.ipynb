{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\nfrom sklearn.utils import shuffle\n# import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\n\nimport transformers\nimport tokenizers\n\n# Hugging Face new library for datasets (https://huggingface.co/nlp/)\nimport nlp\nimport time\n\nimport torch\n# import torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data\n\n### 1. Original Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\n\noriginal_train = shuffle(original_train)\noriginal_valid = original_train[:len(original_train) // 5]\noriginal_train = original_train[len(original_train) // 5:]\n\noriginal_train.shape[0], original_valid.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"original - training: {len(original_train)} examples\")\noriginal_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. MNLI Multilingual Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mnli_multi_train = pd.read_csv(\"../input/mnli-multilanguage-dataset/mnli_train_translated.csv\")\n\n# mnli_multi_train = mnli_multi_train.dropna(how='any')\n# mnli_multi_train = mnli_multi_train[mnli_multi_train.lang.isin(['ar', 'en', 'de', 'es', 'fr', 'th', 'ru'])]\n# mnli_multi_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rand_idx = np.random.choice(mnli_multi_train.shape[0], int(0.2*mnli_multi_train.shape[0]), replace=False)\n# mnli_multi_train = mnli_multi_train.iloc[rand_idx]\n# mnli_multi_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _build_dataset_from_list(ds_list):\n    df = pd.concat([d[['premise', 'hypothesis', 'label']] for d in ds_list])\n    df = df[df['label'].isin([0,1,2])]\n#     df_valid = pd.concat([d.loc[['premise', 'hypothesis', 'label']] for d in ds_valid_list])\n    return df\n\ndef _get_sentence_pairs(df):\n    return df['premise'].tolist(), df['hypothesis'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultiLangDataset(Dataset):\n    \"\"\"Multi Lang Dataset For NLI Tasks\"\"\"\n    def __init__(self, ds_list, model_name, tokenizer, max_len=300, device=None):\n        df = _build_dataset_from_list(ds_list)\n        \n        self.tokenizer = tokenizer\n        text, text_pair = _get_sentence_pairs(df)\n        self.tokenized_ids = self.tokenizer(text=text, text_pair=text_pair,\n                                   return_tensors='pt',\n                                   max_length=max_len, \n                                   padding='max_length', \n                                   truncation=True,\n                            )\n        self.tokenized_att = self.tokenized_ids['attention_mask']\n        self.tokenized_ids = self.tokenized_ids['input_ids']\n        self.targets = torch.tensor(df['label'].values)\n        self.len = df.shape[0]\n        \n        if device:\n            self.tokenized = self.tokenized.to(device)\n            self.targets = self.targets.to(device)\n            \n    def __len__(self):\n        return self.len\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        return ((self.tokenized_ids[idx], self.tokenized_att[idx]), self.targets[idx])\n    def to(self, device):\n        self.tokenized_ids = self.tokenized_ids.to(device)\n        self.tokenized_att = self.tokenized_att.to(device)\n        self.targets = self.targets.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nsns.set(style=\"darkgrid\")\n# %matplotlib inline\nimport time\nimport pylab\nfrom IPython import display as dsp\n\ndef update_metrics_fig(epoch_df):\n    epoch_long = epoch_df.set_index(['epoch', 'type', 'freezed']).stack().reset_index()\\\n                        .rename(columns={'level_3':'metric', 0:'value'})\n    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n    \n    ax_0 = sns.lineplot(x=\"epoch\", y=\"value\", hue='type', markers=True,\n                          data=epoch_long[epoch_long['metric']=='accuracy'], \n                          ax=axs[0])\n    ax_1 = sns.lineplot(x=\"epoch\", y=\"value\", hue='type', markers=True,\n                          data=epoch_long[epoch_long['metric']=='loss'], \n                          ax=axs[1])\n    ax_0.set_title('Accuracy', fontsize=18, pad=10)\n    ax_1.set_title('Average Loss', fontsize=18, pad=10)\n    \n    fig.subplots_adjust(hspace=.3)\n    \n    # Clear output and re-plot\n    dsp.clear_output(wait=True)\n    dsp.display(_= plt.show())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Training Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(outputs, targets):\n    # pass in outputs and targets, return loss function\n    return torch.nn.BCEWithLogitsLoss()(outputs, \n                                        torch.nn.functional.one_hot(targets.long(), \n                                                                    num_classes=3).float())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model_gpu(model, train, valid, epochs, loss_fn, \n                    batch_size=36, warmup_ratio=0.3, lr=1e-5,\n                    train_ratio=1.0, valid_ratio=1.0, gradient_accumulation=2, \n                    device='cuda', logs_df=None, num_labels=3, scheduler=False):\n    torch.manual_seed(42)\n    np.random.seed(42)\n    time_glob_start = time.perf_counter()\n    # Get loss function, optimizer, and model\n    # Initializing Dataloaders  \n    train.to(device)\n    valid.to(device)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train,\n        batch_size=batch_size,\n        shuffle=True)\n    \n    valid_loader = torch.utils.data.DataLoader(\n        valid,\n        batch_size=batch_size,\n        shuffle=False,\n        drop_last=True)\n    \n    # Initializing model\n    for param in model.base_model.parameters(): # unfreeze some layers\n        param.requires_grad = False\n    freezed = True\n#     for param in model.base_model.parameters(): # freeze some layers\n#         param.requires_grad = False\n    model = model.to(device)\n    # Grouping Parameters\n    param_optimizer = list(model.named_parameters()) # model parameters to optimize\n    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n    # apply to weight decay\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n\n#     optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=lr)\n    optimizer = optim.SGD(optimizer_grouped_parameters, lr=lr)\n#     scheduler = OneCycleLR(optimizer, \n#                            learning_rate, \n#                            div_factor=10.0, \n#                            final_div_factor=50.0, \n#                            epochs=epochs,\n#                            steps_per_epoch=len(train_loader))\n    num_train_steps = int(len(train_loader) * epochs)\n    if scheduler:\n        scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n                                                    num_warmup_steps=int(warmup_ratio*epochs*len(train_loader)), \n                                                    num_training_steps=num_train_steps)\n    else:\n        scheduler = None\n    \n    if logs_df is None:\n        logs_df = pd.DataFrame(columns=['epoch', 'type', 'freezed', 'accuracy', 'loss'])\n        epoch_start = logs_df.shape[0]+1\n    else:\n        epoch_start = 1\n        \n    def train_loop_fn(loader, model, optimizer, freezed, \n                      train_ratio, gradient_accumulation,\n                      device='cuda', scheduler=None, epoch=None):\n        if train_ratio>1.0:\n            raise ValueError(\"Train ratio value cannot be larger than 1.0 .\")\n            \n        model.train()\n        train_loss = 0.0\n        train_preds = np.array([])\n        train_targets = np.array([])\n        grad_ctr = 0\n        loader_idx = np.random.choice(len(loader), int(train_ratio*len(loader)), replace=False)\n        for x, (inputs, targets) in enumerate(loader):\n#             inputs = inputs.to(device) \n#             targets = targets.to(device)\n            if x in loader_idx:\n                grad_ctr += 1\n                if grad_ctr%gradient_accumulation==0:\n                    optimizer.zero_grad()\n                    grad_ctr = 0\n                outputs = model(inputs[0], inputs[1])[0]\n    #             loss = loss_fn(outputs.view(-1, num_labels), targets.view(-1))\n                loss = loss_fn(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                if scheduler is not None:\n                    scheduler.step()\n                # since the loss is on all 8 cores, reduce the loss values and print the average (as defined in reduce_fn)\n    #             loss_reduced = xm.mesh_reduce('loss_reduce',loss,reduce_fn) \n                train_loss += loss.item()\n                train_preds = np.append(train_preds, outputs.argmax(-1).cpu().detach().numpy())\n                train_targets = np.append(train_targets, targets.cpu().detach().numpy())\n                print(\"Training... Epoch: {:,}\\t Is freezed: {}\\tbatch {:,}/{:,}\\tOptimizer LRs: {}\\tBatch Loss:{}\"\n                      .format(epoch, freezed, x, len(loader), \n                              '\\t'.join([str(pg['lr']) for pg in optimizer.param_groups]), loss.item()\n                             ), end='\\r')\n        \n        acc = 1.0*(train_preds==train_targets).sum().item()/train_preds.shape[0]\n        avg_loss = train_loss/(x+1)\n        return acc, avg_loss\n\n    def eval_loop_fn(loader, model, device='cuda', valid_ratio=1.0):\n        with torch.no_grad():\n            total_samples, correct, loss = 0, 0, 0.0\n            model.eval()\n            time_start = time.perf_counter()\n            idx_selected = np.random.choice(len(loader), int(1.0*valid_ratio*len(loader)), replace=False)\n            for i, (inputs, targets) in enumerate(loader):\n                if i in idx_selected:\n                    print(\"Evaluation Step {:,} out of {:,} -\\tTime Passed: {:.1f}s, Remaining: {:.1f}s\"\n                          .format(i, len(loader), time.perf_counter()-time_start, (time.perf_counter()-time_start)/((i+1)/len(loader))), \n                          end=\"\\r\")\n                    outputs = model(inputs[0], inputs[1])[0]\n                    loss += loss_fn(outputs.view(-1, 3), targets.view(-1)).item()\n                    preds = outputs.argmax(1)#.cpu().numpy()\n                    correct += (targets==preds).sum().item()#/preds.shape[0]\n                    total_samples += preds.shape[0]\n                else:\n                    pass\n            accuracy = 1.0 * correct / total_samples\n            loss = 1.0*loss/total_samples\n        model.train()\n        return accuracy, loss\n\n    # Train and eval loops\n#     accuracy = []\n    for epoch in range(epoch_start, epochs + epoch_start):\n        start = time.time()\n        train_acc, train_loss = train_loop_fn(train_loader, model=model, \n                                              optimizer=optimizer, device=device, \n                                              train_ratio=train_ratio,\n                                              gradient_accumulation=gradient_accumulation,\n                                              freezed=freezed, scheduler=scheduler, epoch=epoch)\n        valid_acc, valid_loss = eval_loop_fn(valid_loader, model=model, \n                                             valid_ratio=valid_ratio, \n                                             device=device)\n        # Updating metrics\n        logs_df = logs_df.append(dict(\n            epoch=epoch, type='train', freezed=freezed, accuracy=train_acc, loss=train_loss, \n            #lr=[pg['lr'] for pg in optimizer.param_groups][0]\n        ), ignore_index=True)\n        logs_df = logs_df.append(dict(\n            epoch=epoch, type='valid', freezed=freezed, accuracy=valid_acc, loss=valid_loss, #lr=None\n        ), ignore_index=True)\n        # Plotting Results\n        update_metrics_fig(logs_df)\n        if (1.0*epoch/epochs)>=0.7:\n            for param in model.base_model.parameters(): # unfreeze some layers\n                param.requires_grad = False\n            freezed=False\n            \n    # save our model\n    torch.save(model.state_dict(), \"xlm_roberta_model.bin\")\n        \n#         if epoch == 15: #unfreeze\n#                 for param in model.base_model.parameters():\n#                     param.requires_grad = True\n    print('')\n    print('Training Finished!\\nTotal Time Elapsed: {}'\n          .format(int(1.0*(time.perf_counter()-time_glob_start)/60)))\n    display(logs_df)\n    return logs_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Main Run\n\n### 5.1. Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(\"joeddav/xlm-roberta-large-xnli\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = MultiLangDataset(ds_list=[original_train], \n                            tokenizer=tokenizer, \n                            model_name=\"xlm-roberta-base\", \n                            device=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del mnli_multi_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_ds = MultiLangDataset(ds_list=[original_valid], \n                            tokenizer=tokenizer, \n                            model_name=\"xlm-roberta-base\", \n                            device=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.2. Loading XLM-Roberta Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = transformers.AutoModelForSequenceClassification.from_pretrained(\"joeddav/xlm-roberta-large-xnli\", \n                                                                        output_hidden_states=False, \n                                                                        num_labels=3)#.to(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/my-dear-watson/xlm_roberta_multi_model_3.bin'\nmodel.load_state_dict(torch.load(PATH))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3. Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"logs_df = train_model_gpu(model=model, train=train_ds, valid=valid_ds, epochs=2, loss_fn=loss_fn,\n                          batch_size=16, lr=1e-5, scheduler=True,\n                          train_ratio=1.0, valid_ratio=0.2,\n                          warmup_ratio=0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Sample Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _build_submission_dataset_from_list(ds_list):\n    df = pd.concat([d[['premise', 'hypothesis']] for d in ds_list])\n#     df_valid = pd.concat([d.loc[['premise', 'hypothesis', 'label']] for d in ds_valid_list])\n    return df\n\nclass SubmissionDataset(Dataset):\n    \"\"\"Multi Lang Dataset For NLI Tasks\"\"\"\n    def __init__(self, ds_list, tokenizer, max_len=300, device=None):\n        df = _build_submission_dataset_from_list(ds_list)\n        \n        self.tokenizer = tokenizer\n        text, text_pair = _get_sentence_pairs(df)\n        self.tokenized_ids = self.tokenizer(text=text, text_pair=text_pair,\n                                   return_tensors='pt',\n                                   max_length=max_len, \n                                   padding='max_length', \n                                   truncation=True,\n                            )\n        self.tokenized_att = self.tokenized_ids['attention_mask']\n        self.tokenized_ids = self.tokenized_ids['input_ids']\n        self.len = df.shape[0]\n        if device:\n            self.tokenized = self.tokenized.to(device)\n            \n    def __len__(self):\n        return self.len\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        return (self.tokenized_ids[idx], self.tokenized_att[idx])\n    def to(self, device):\n        self.tokenized_ids = self.tokenized_ids.to(device)\n        self.tokenized_att = self.tokenized_att.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(ds, model, batch_size=24, device='cuda'):\n    model.to(device)\n    ds.to(device)\n    loader = torch.utils.data.DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=False,\n        drop_last=False)\n    predictions = []\n    with torch.no_grad():\n        model.eval()\n        time_start = time.perf_counter()\n        for i, inputs in enumerate(loader):\n            print(\"Evaluation Step {:,} out of {:,} -\\tTime Passed: {:.1f}s, Remaining: {:.1f}s\"\n                  .format(i, len(loader), time.perf_counter()-time_start, (time.perf_counter()-time_start)/((i+1)/len(loader))), \n                  end=\"\\r\")\n            outputs = model(inputs[0], inputs[1])[0]\n            preds = outputs.argmax(1).cpu().numpy().tolist()\n            predictions.extend(preds)\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.1. Loading Submission Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\nprint(f\"original - test: {len(submission_df)} examples\")\nprint(\"Number of languages: {}\".format(len(submission_df.lang_abv.unique().shape)))\nsubmission_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.2. Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_ds = SubmissionDataset(ds_list=[submission_df],\n                                 tokenizer=tokenizer, \n                                 device=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['prediction'] = predict(submission_ds, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df[['id', 'prediction']].to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}