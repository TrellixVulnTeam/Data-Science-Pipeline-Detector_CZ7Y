{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.model_selection import StratifiedKFold\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\ntest_data=pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check sentences with less than 5 characters\n\nfor i in range(len(data)):\n    if len(data[\"premise\"][i])<5 or len(data[\"hypothesis\"][i])<5:\n        print(data[\"premise\"][i]+ \">>\"+ data[\"hypothesis\"][i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check max avg and min len of sentences\npremise=[]\nhypothesis=[]\n\nfor i in range(len(data)):\n    premise.append(len(data[\"premise\"][i]))\n    hypothesis.append(len(data[\"hypothesis\"][i]))\n    \nprint(\"Average len of characters in premise\",sum(premise)//len(premise))\nprint(\"Maximum len of characters in premise\",max(premise))\nprint(\"Minimum len of characters in premise\",min(premise),end=\"\\n\\n\")\n\nprint(\"Average len of characters in hypothesis\",sum(hypothesis)//len(hypothesis))\nprint(\"Maximum len of characters in hypothesis\",max(hypothesis))\nprint(\"Minimum len of characters in hypothesis\",min(hypothesis))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"language_data=pd.DataFrame(data[\"language\"].value_counts()).reset_index().rename(columns={\"index\":\"language\",\"language\":\"counts\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(20,5))\n\nsns.set(style=\"whitegrid\")\nax = sns.barplot(x=language_data[\"language\"], y=language_data[\"counts\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"languages4plot=[]\nPercentage=[]\nfor ind in range(len(language_data)):\n    Percentage.append(round((language_data[\"counts\"][ind]/sum(language_data[\"counts\"]))*100,2))\n    languages4plot.append(language_data['language'][ind])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explode=np.random.uniform(0,0,len(Percentage))\nplt.figure(figsize=(10,10))\nplt.pie(Percentage, explode=explode, labels=languages4plot, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import RobertaConfig, RobertaModel,RobertaTokenizer\nfrom transformers import BertTokenizer, TFBertModel, AutoTokenizer, TFAutoModel\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\",do_lower_case=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenize_premise=[]\ntokenize_hypothesis=[]\nlanguages=[]\n\nfor ind in range(len(data)):\n    tokenize_premise.append(len(list(tokenizer.tokenize(data[\"premise\"][ind], return_tensors=\"tf\"))))\n    tokenize_hypothesis.append(len(list(tokenizer.tokenize(data[\"hypothesis\"][ind], return_tensors=\"tf\"))))\n    languages.append(data[\"language\"][ind])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average len of premise\",sum(tokenize_premise)//len(tokenize_premise))\nprint(\"Maximum len of premise\",max(tokenize_premise))\nprint(\"Minimum len of premise\",min(tokenize_premise),end=\"\\n\\n\")\n\nprint(\"Average len of hypothesis\",sum(tokenize_hypothesis)//len(tokenize_hypothesis))\nprint(\"Maximum len of hypothesis\",max(tokenize_hypothesis))\nprint(\"Minimum len of hypothesis\",min(tokenize_hypothesis))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the plot of average length of the Sentences according the the languages for premise column"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\n\nsns.set(style=\"whitegrid\")\nax = sns.scatterplot(x=languages, y=tokenize_premise)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Average Sentence length for hypothesis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\n\nsns.set(style=\"whitegrid\")\nax = sns.scatterplot(x=languages, y=tokenize_hypothesis)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_sentence(s):\n   tokens = list(tokenizer.tokenize(s))\n   tokens.append('[SEP]')\n   token_ids=tokenizer.convert_tokens_to_ids(tokens)\n   return token_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_encode(hypotheses, premises, tokenizer):\n    \n  num_examples = len(hypotheses)\n  \n  sentence1 = tf.ragged.constant([\n      encode_sentence(s)\n      for s in np.array(hypotheses)])\n  sentence2 = tf.ragged.constant([\n      encode_sentence(s)\n       for s in np.array(premises)])\n    \n  \n\n  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n\n  input_mask = tf.ones_like(input_word_ids).to_tensor()\n\n  type_cls = tf.zeros_like(cls)\n  type_s1 = tf.zeros_like(sentence1)\n  type_s2 = tf.ones_like(sentence2)\n  input_type_ids = tf.concat(\n      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n\n  inputs = {\n      'input_word_ids': input_word_ids.to_tensor(),\n      'input_mask': input_mask,\n      'input_type_ids': input_type_ids}\n\n  return inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.sample(frac=1).reset_index(drop=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data=data[[\"premise\", \"hypothesis\"]]\nY_data=data[\"label\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_df=pd.DataFrame(Y_data.value_counts()).reset_index().rename(columns={\"index\":\"label\",\"label\":\"counts\"})\nlabels=list(count_df[\"label\"])\nsizes=[(i/len(Y_data))*100 for i in count_df[\"counts\"]]\nexplode = (0, 0.1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tab_data=pd.get_dummies(data[\"language\"]).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nskf = StratifiedKFold(n_splits=5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ninputs=bert_encode(data.hypothesis.values, data.premise.values, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print('Number of replicas:', strategy.num_replicas_in_sync)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow_addons as tfa\n\nmax_len = 50\n\ndef build_model():\n#     bert_encoder = TFAutoModel.from_pretrained(\"roberta-large-mnli\")\n    bert_encoder = TFBertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n    \n    for layer in bert_encoder.layers:\n        layer.trainable=True\n    \n    \n    \n    \n#     embedding = bert_encoder(input_word_ids)[0]\n    embedding = bert_encoder([input_word_ids,input_mask,input_type_ids])[0]\n    d1=tf.keras.layers.Dropout(0.1)(embedding[:,0,:])\n#     first = tf.keras.layers.Dense(256, activation='relu')(embedding[:,0,:])\n    \n#     second = tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(embedding[:,0,:])\n    \n\n    output = tf.keras.layers.Dense(3, activation='softmax')(d1)\n    \n  \n\n# ...\n\n#     optimizer = tfa.optimizers.Adagrad(learning_rate=1e-3, weight_decay=1e-2)\n# ...\n\n    optimizer = tf.optimizers.Adagrad(learning_rate=0.001)\n    \n    \n    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n#     model = tf.keras.Model(inputs=input_word_ids, outputs=output)\n\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CUSTOM LEARNING SCHEUDLE\nimport matplotlib.pyplot as plt\n\n\ndef build_lrfn(lr_start=0.0001, lr_max=0.001, \n               lr_min=0.00001, lr_rampup_epochs=4, \n               lr_sustain_epochs=0, lr_exp_decay=.87):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn\n\nplt.figure(figsize=(10, 7))\n\n_lrfn = build_lrfn()\nplt.plot([i for i in range(35)], [_lrfn(i) for i in range(35)]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=test_data\nX_test=train_inputs=bert_encode(X_test.premise.values, X_test.hypothesis.values, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntest_pred=np.zeros((len(test_data),3))\n\nEPOCHS=10\na=0\nscore=[]\nfor train_index, test_index in skf.split(X_data, Y_data):\n    tf.keras.backend.clear_session()\n    \n    with strategy.scope():\n        model = build_model()\n    \n    print(\"\",end=\"\\n\\n\")\n        \n    print(f\"Generating Inputs for fold {a}\")\n    \n    print(\"==\"*20)\n    \n    train_inputs=bert_encode(X_data.iloc[train_index].premise.values, X_data.iloc[train_index].hypothesis.values, tokenizer)\n  \n    \n    train_labels=Y_data[train_index]\n    \n    val_inputs=bert_encode(X_data.iloc[test_index].premise.values, X_data.iloc[test_index].hypothesis.values, tokenizer)\n    test_labels=Y_data[test_index]\n    \n    \n    \n    lr2 = tf.keras.callbacks.LearningRateScheduler(_lrfn, verbose = True)\n    \n    lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n                                            factor=0.5, \n                                            patience=5)\n    early_stopping=tf.keras.callbacks.EarlyStopping(patience=5)\n    model.fit(train_inputs, train_labels,epochs=50, verbose = 1,\n              validation_data=(val_inputs,test_labels),\n              batch_size = 128,callbacks=[early_stopping,lr])\n    results=model.evaluate(val_inputs,test_labels)\n    print(\"====== predicting test===========\")\n    test_pred += model.predict(X_test)\n    \n  \n    print(\"====== predicting test Done===========\")\n    print(f\"score for fold {a} is\",results[1])\n    \n    print(\"===\"*20)\n    score.append(results[1])\n    \n    a+=1\n    \nprint(\"final LB score\",np.mean(score))\n    \n    \n       \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds=test_pred/5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions=np.argmax(test_preds,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data=pd.read_csv(\"../input/contradictory-my-dear-watson/sample_submission.csv\")\nsubmission_data[\"prediction\"]=final_predictions\n\nsubmission_data.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}