{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This notebook is just an explanation for why Transformers are the new BOSS \n**Conventional methods of performing NLP tasks were done by using RNN (LSTM/GRU). These are derived from feed forward networksand possess an internal state (memory) which aide in processing of variable length sequences. LSTMs and GRUs are the subtypes of RNNs with a small difference in architecture.**\n\n*I'll make a seperate notebook for the transformers section because of the sheer size of explanation and code needed to be demonstrated*\n\n*If you enjoy the content of this notebook, please upvote and show your appreciation.\n\nIf you happen to notice any discrepencies, please mention them in the comments below and i'll update the notebook. \n\nAlso, I'd love to discuss with you in the comments abput this topic, because, tbh, what we know is a drop, what we dont, is an ocean*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**RNN demonstration and intuition:**\n\nLets now see what an RNN looks like \n![](https://kvitajakub.github.io/img/rnn-unrolled.png)\n\n![](https://cdn-images-1.medium.com/max/1600/1*Niu_c_FhGtLuHjrStkB_4Q.png) *An LSTM cell*\n\n![](https://www.data-blogger.com/wp-content/uploads/2017/08/gru.png) *A GRU cell*\n\n\nOn observing closely, we see that the previous state input is fed along with the current state input; the output of stage 1 will be the input for stage 2 and so on. But there are some grave issues that people face with RNNs.\n1. Vanishing Gradients\n2. Exploding gradients\n3. Nearly impossible to parallelize\n4. Difficult to save weights\n5. TBH, they are f'ing slow... \n\n**Lets see what each issues are in a bit more detail..**\n1. Vanishing Gradients :\n    This happens during backpropagation. In backpropagation, a signal is sent back into the network that direct the nodes to adjust the weights. Now, since these nodes have variable lengths due to the variable length inputs, we may experience a loss of signal towards the start of the network.(I'll add an image for better understanding). To put it simply, we cannot adjust the weights towards the start of the network as we can do at the end.\n    \n2. Exploding gradients :\n    This happens when we foolishly assign large value of weights to a neuron that hampers the accuracy/usefulness of a network.\n    \n*Lets take an example. Take 2 values, 0.8 and 1.2. Now, lets calculate the 111th power of each of these values. 0.8 ^ 111 = 1.749~e-11 while 1.2 ^ 111 = 615,344,483. See the difference? this is a small demonstration of vanishing and exploding gradients.*\n\n3. RNNs are difficult to parallelie :\n    RNNs can be said to have a mesh kid of connection between nodes. For ease, lets imagine a matrix N[n1][n2]. Now, say you need to train the network, you'll have to keep re-adjusting the weights. Lets say you need to update Node[3][12]. Now, you'll have to adjust the weights of all the preceeding nodes. This makes it difficult to parallelize.\n    \n4. Difficult to save weights :\n    Because the finicky nature of RNNs (lstm/gru), its difficult to save their weights.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Transformers\n*An Introduction*\n**Attention is all you need **[Paper](https://arxiv.org/pdf/1706.03762.pdf)\n\nThis paper was a breakthrough in NLP, specifically machine translation. This architecture doesnot rely on RNNs and ConvNets, but on attention mechanisms. So what are attention mechanisms? Attention mechanisms are ways where we can add context to a sequence of words. \nConsider an example: Bruce loves to play fetch \nfirst, all these words will be converted into vectors\nNow, Bruce is related to the action fetch(performs), play is related to fetch(as a game), and so on. Now, if we take these words individually, i.e. without any context, we may end up with a poor mechanism which will be practically useless. Now, if we consider the words around the selected word, we may develop a general idea of what the word means. Attention mechanisms do just that. They add context to words which will now make more sense to the neural network.\n\n**We will now divide the above paper into 4 parts:\n    1. Self attention\n    2. Keys, Queries, Values\n    3. Multi headed attention\n    4. The overall architecture.**\n    \nI'll be making seperate notebooks for each of them. Till then, study other notebooks here to get an insight on how to implement these networks. I'll link the notebooks for transformers here later. Stay safe!!!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}