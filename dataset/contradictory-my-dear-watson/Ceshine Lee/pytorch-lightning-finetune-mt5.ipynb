{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"[Training code is from this repo of mine](https://github.com/ceshine/finetuning-t5/tree/mt5-classifier-single-token/mnli). Currently my fine-tunes mT5 models still underperforms comparing to the BERT and XLM models.","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip uninstall -y allennlp\n!pip install transformers==4.1.1 typer\n!pip install -U pytorch-lightning\n!pip install pytorch-lightning-spells","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /src/finetuning-t5\n!git clone https://github.com/ceshine/finetuning-t5.git -b master /src/finetuning-t5","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /src/finetuning-t5/mnli","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p data/kaggle\n!cp -r /kaggle/input/contradictory-my-dear-watson/* data/kaggle\n!ls data/kaggle/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p cache/kaggle/\n!python preprocess/preprocess_kaggle.py\n!python preprocess/tokenize_dataset.py kaggle --tokenizer-name google/mt5-base","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!SEED=9923 python train.py --t5-model google/mt5-base --batch-size 32 --grad-accu 1 \\\n        --epochs 10 --lr 1e-3 --disable-progress-bar --dataset kaggle \\\n        --max-len 128 --valid-frequency 0.5 --full-model ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls cache/\n!mv cache/tb_logs /kaggle/working\n!mv cache/mt5-base_best /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python kaggle_inference.py /kaggle/working/mt5-base_best\n!cp submission.csv /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}