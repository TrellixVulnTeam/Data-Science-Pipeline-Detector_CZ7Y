{"cells":[{"metadata":{},"cell_type":"markdown","source":"[The mT5 models were trained with the multitask objective, so it'll be harder to get good results with simple finetuning procedure.](https://github.com/google-research/text-to-text-transfer-transformer/blob/master/released_checkpoints.md#t511) This notebook conducts an experiment to find the level of accuracy we can get with a naive finetuning scheme.\n\nIn my experiment, AdaFactor with a custom learning rate schedule has been shown to perform better than AdamW and AdaFactor with the built-in schedule."},{"metadata":{},"cell_type":"markdown","source":"## Prepare the environment"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install --upgrade pip\n!pip uninstall -y allennlp\n!pip install transformers==4.1.1 typer\n!pip install -U pytorch-lightning\n!pip install https://github.com/veritable-tech/pytorch-lightning-spells/archive/master.zip\n!pip install -U sentencepiece","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get the code"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!mkdir -p /src/finetuning-t5\n!git clone https://github.com/ceshine/finetuning-t5.git -b master /src/finetuning-t5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /src/finetuning-t5/mnli\n%git checkout 13b9351","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p data/multinli_1.0\n!cp -r /kaggle/input/multinli-nyu/multinli_1.0/* data/multinli_1.0/\n!ls data/multinli_1.0/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p data/kaggle\n!cp -r /kaggle/input/contradictory-my-dear-watson/* data/kaggle/\n!ls data/kaggle/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Only keep tokens that we need"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python preprocess/preprocess_kaggle.py\n!python preprocess/preprocess_mnli.py\n!python utils/reduce_sentencepiece_vocab.py google/mt5-base","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenize"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir cache/multinli\n!python preprocess/tokenize_dataset.py multinli --tokenizer-name cache/mt5-base","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine-tune the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!SEED=3313 python train.py --batch-size 64 --grad-accu 1 --max-len 128 --epochs 2 --t5-model cache/mt5-base \\\n    --lr 2e-3 --dataset multinli --disable-progress-bar --valid-frequency 0.5 --freeze-embeddings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate accuracy of the \"matched\" dev set"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python evaluate.py cache/mt5-base_best --corpus multinli --split-name test_matched --batch-size 32","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate accuracy of the \"mismatched\" dev set"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python evaluate.py cache/mt5-base_best --corpus multinli --split-name test_mismatched --batch-size 32","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Export the Tensorboard log files and the trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mv cache/tb_logs /kaggle/working\n!mv cache/mt5-base_best /kaggle/working","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}