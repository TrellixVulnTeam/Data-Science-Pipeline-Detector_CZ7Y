{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os,time,tqdm,random,gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\nimport plotly.express as px\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom sklearn.utils import shuffle\nfrom IPython.display import clear_output\n\n# !pip uninstall -y transformers\n# !pip install transformers\n!pip install nlp\n\nimport transformers\nimport tokenizers\nimport nlp\nimport tensorflow as tf\n\n\nos.environ[\"WANDB_API_KEY\"] = \"0\"\n\ndef seed_all(seed=2001):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    \ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)\n  \n    \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'bert-base-multilingual-cased'\nmax_len = 50","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"original = pd.read_csv('../input/contradictory-my-dear-watson/train.csv')\nmnli = nlp.load_dataset(path='glue', name='mnli')\n\nclear_output(wait=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnli_train = pd.DataFrame(mnli['train'])\nmnli_valid1 = pd.DataFrame(mnli['validation_matched'])\nmnli_valid2 = pd.DataFrame(mnli['validation_mismatched'])\n\nmnli = pd.concat([mnli_train,mnli_valid1,mnli_valid2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnli = mnli[['premise','hypothesis','label']]\nmnli = mnli.rename(columns = {0 : 'premise', 1: 'hypothesis',2: 'label' })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original = original[['premise','hypothesis','label']].sample(len(original)//(8*strategy.num_replicas_in_sync)*8*strategy.num_replicas_in_sync)\nlen(original)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's use the original dataset as a validation one ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = mnli\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_encoded = tokenizer.batch_encode_plus(train[['premise','hypothesis']].values.tolist(),pad_to_max_length=True,max_length=max_len,return_tensors='tf')\nvalid_encoded = tokenizer.batch_encode_plus(original[['premise','hypothesis']].values.tolist(),pad_to_max_length=True,max_length=max_len,return_tensors='tf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(l):\n    bert_encoder = transformers.TFBertModel.from_pretrained(model_name)\n    \n    input_words_ids = tf.keras.layers.Input(shape=(max_len),dtype=tf.int32,name='input_ids')\n    input_mask = tf.keras.layers.Input(shape=(max_len,),dtype=tf.int32,name='attention_mask')\n    input_type_ids = tf.keras.layers.Input(shape=(max_len,),dtype=tf.int32,name='token_type_ids')\n    \n    embedding = bert_encoder([input_words_ids,input_mask,input_type_ids])[0]\n\n    \n    output = tf.keras.layers.Dense(3,activation='softmax')(embedding[:,0,:])\n    \n    \n    model = tf.keras.models.Model(inputs=[input_words_ids,input_mask,input_type_ids],outputs=output)\n    \n\n    model.compile(\n        optimizer = tf.keras.optimizers.Adam(lr=l),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n\nwith strategy.scope():\n    model = build_model(l=1e-5)\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(dict(train_encoded),train.label.values,epochs=10,batch_size=128*strategy.num_replicas_in_sync,verbose=1,validation_data=(dict(valid_encoded),original.label.values),validation_batch_size=8*strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/contradictory-my-dear-watson/test.csv')\n\ntest_encoded = tokenizer.batch_encode_plus(test[['premise','hypothesis']].values.tolist(),pad_to_max_length=True,max_length=max_len,return_tensors='tf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [np.argmax(i) for i in model.predict(dict(test_encoded))]\n\nsubmission = test.id.copy().to_frame()\nsubmission['prediction'] = preds\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df = pd.DataFrame(hist.history)\nhist_df['epoch'] = np.arange(1,len(hist_df)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"py.offline.init_notebook_mode()\ntrain_acc =go.Scatter(x=hist_df['epoch'],y=hist_df['accuracy'],mode = \"lines+markers\",name='train_acc')\nval_acc =go.Scatter(x=hist_df['epoch'],y=hist_df['val_accuracy'],mode = \"lines+markers\",name='valid_acc')\n\ndata = [train_acc, val_acc]\nlayout = dict(title = 'Accuracy',\n              xaxis= dict(title= 'epoch',ticklen= 1,zeroline= False)\n             )\n\nfig = dict(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_acc =go.Scatter(x=hist_df['epoch'],y=hist_df['loss'],mode = \"lines+markers\",name='loss')\nval_acc =go.Scatter(x=hist_df['epoch'],y=hist_df['val_loss'],mode = \"lines+markers\",name='valid_loss')\n\ndata = [train_acc, val_acc]\nlayout = dict(title = 'Loss',\n              xaxis= dict(title= 'epoch',ticklen= 1,zeroline= False)\n             )\n\nfig = dict(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}