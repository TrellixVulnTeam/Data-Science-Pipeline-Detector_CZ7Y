{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sentence_transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\n#import math\nfrom sentence_transformers import LoggingHandler, util\nfrom sentence_transformers.cross_encoder import CrossEncoder\nfrom sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\nimport logging\nfrom datetime import datetime\nimport os\nimport csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\ntest_df = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeRegressor\ny = train_df[\"\"]\nfeatures = [\"lang_abv\",\"language\",\"label\"]\nX = train_df[y]\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\":  2}\ntrain_samples = []\ndev_samples = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install math\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport pandas.core as pc\nimport pandas as pd\nimport numpy as np\nimport argparse\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport argparse\ndf = pd.Dataframe()\n\n\ntrain_samples = []\ndev_samples = []\ntrain_data = df.read_csv(train_df)\ntrain_data['label'] = train_data['label'].replace([0,2],[2,0])\nfor id, row in train_data.iterrows():\n    label_id = int(row=['label'])\n    train_samples.append(InputExample(texts = [row['premise'], row['hypothesis']], label=label_id))\n    \ntrain_batch_size = 16\nnum_epochs = 4\n\nmodel = CrossEncoder('sentence_transformers/distilbert-base-nli-stsb-mean-tokens', num_labels=len(label2int))\nmodel = CrossEncoder('sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking', num_labels=len(label2int))\nmodel = CrossEncoder('sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens', num_labels=len(label2int))\n\n\nmodel = CrossEncoder('joeddav/xlm-roberta-large-xnli', num_labels=len(label2int))\ntrain_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n\nevaluator = CESoftmaxAccuracyEvaluator.from_input_examples(dev_samples, name='ALLNLI-dev')\n\nup_steps = math.ceil(len(train_dataloader)* num_epochs * 0.1)\nlogging.info(r\"Warmup-steps: {}\".format(up_step))\n\n#Train_the model\nmodel.fit(train_dataloader=train_dataloader,\n         evaluator=evaluator,\n         epochs = num_epochs,\n         evaluation_steps=10000,\n         up_steps=up_steps,\n         output_path=model_save_path)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = '../input/contradictory-my-dear-watson/test.csv'\ndf = pd.read_csv(test_dataset)\nsentence_pairs =[]\nids = []\nfor id, row in df.iterrows():\n    label_id = 0\n    ids.append=(row[str('id')])\n    sentence_pairs.append([row['premise'], row['hypothesis']])\n    \npred_scores = model.predict(sentence_pairs, convert_to_numpy=True, show_progress_bar=False, batch_size=4)\npred_labels = np.argmax(pred_scores, axis=1)\n\nout_df = pd.DataFrame([ids, pred_labels]).transpose()\nout_df = out_df.rename(columns={0: 'id', 1: 'predictio'})\nout_df ['prediction'] = out_df['prediction'].replace([2,0], [0,2])\nout_df.to_csv('submission.csv',index=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}