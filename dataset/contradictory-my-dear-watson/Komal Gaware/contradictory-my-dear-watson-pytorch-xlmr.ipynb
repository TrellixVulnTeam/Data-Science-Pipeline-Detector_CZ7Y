{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-30T08:20:49.146385Z","iopub.execute_input":"2022-01-30T08:20:49.146754Z","iopub.status.idle":"2022-01-30T08:20:49.172869Z","shell.execute_reply.started":"2022-01-30T08:20:49.146666Z","shell.execute_reply":"2022-01-30T08:20:49.171935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Please switch on the TPU before running these lines.\n\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:20:51.732573Z","iopub.execute_input":"2022-01-30T08:20:51.732844Z","iopub.status.idle":"2022-01-30T08:21:55.359995Z","shell.execute_reply.started":"2022-01-30T08:20:51.732816Z","shell.execute_reply":"2022-01-30T08:21:55.359024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch_xla\nimport torch_xla.core.xla_model as xm","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:21:55.362379Z","iopub.execute_input":"2022-01-30T08:21:55.362798Z","iopub.status.idle":"2022-01-30T08:21:56.002888Z","shell.execute_reply.started":"2022-01-30T08:21:55.362765Z","shell.execute_reply":"2022-01-30T08:21:56.001611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#huggingface libraries \nimport transformers\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\nfrom transformers import AdamW\n#torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset, TensorDataset\n\n#random libraries\nfrom tqdm import tqdm \nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport random\nfrom datasets import load_dataset\n\n# set a seed value\ntorch.manual_seed(555)\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:21:56.004366Z","iopub.execute_input":"2022-01-30T08:21:56.004805Z","iopub.status.idle":"2022-01-30T08:22:03.592849Z","shell.execute_reply.started":"2022-01-30T08:21:56.004755Z","shell.execute_reply":"2022-01-30T08:22:03.591888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:22:03.889101Z","iopub.execute_input":"2022-01-30T08:22:03.889933Z","iopub.status.idle":"2022-01-30T08:22:04.010728Z","shell.execute_reply.started":"2022-01-30T08:22:03.88989Z","shell.execute_reply":"2022-01-30T08:22:04.009813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:22:04.012057Z","iopub.execute_input":"2022-01-30T08:22:04.012291Z","iopub.status.idle":"2022-01-30T08:22:12.271069Z","shell.execute_reply.started":"2022-01-30T08:22:04.012266Z","shell.execute_reply":"2022-01-30T08:22:12.270086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = load_dataset('glue', 'mnli')\nprint(len(mnli))\nprint(mnli['train'])","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:22:12.272516Z","iopub.execute_input":"2022-01-30T08:22:12.27279Z","iopub.status.idle":"2022-01-30T08:23:13.977359Z","shell.execute_reply.started":"2022-01-30T08:22:12.272758Z","shell.execute_reply":"2022-01-30T08:23:13.976178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli_df=pd.DataFrame()\nmnli_df['id']=mnli['train']['idx']\nmnli_df['premise']=mnli['train']['premise']\nmnli_df['hypothesis']=mnli['train']['hypothesis']\nmnli_df['lang_abv']=['en']*len(mnli['train']['idx'])\nmnli_df['language']=['English']*len(mnli['train']['idx'])\nmnli_df['label']=mnli['train']['label']\nmnli_df","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:23:13.978848Z","iopub.execute_input":"2022-01-30T08:23:13.979233Z","iopub.status.idle":"2022-01-30T08:23:16.792506Z","shell.execute_reply.started":"2022-01-30T08:23:13.979191Z","shell.execute_reply":"2022-01-30T08:23:16.791575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xnli = load_dataset ('xnli', 'all_languages')\n# # xnli   = load_dataset ('xnli')\n# print(xnli['train'])\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:23:16.79427Z","iopub.execute_input":"2022-01-30T08:23:16.794631Z","iopub.status.idle":"2022-01-30T08:26:20.002177Z","shell.execute_reply.started":"2022-01-30T08:23:16.794589Z","shell.execute_reply":"2022-01-30T08:26:20.00136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xnli_df=pd.DataFrame()\n# xnli_df['premise']=mnli['train']['premise']\n# xnli_df['hypothesis']=mnli['train']['hypothesis']\n# xnli_df['label']=mnli['train']['label']","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:26:20.004415Z","iopub.execute_input":"2022-01-30T08:26:20.004676Z","iopub.status.idle":"2022-01-30T08:26:21.626663Z","shell.execute_reply.started":"2022-01-30T08:26:20.004649Z","shell.execute_reply":"2022-01-30T08:26:21.625692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data1=train_data[['premise','hypothesis','label']]\nval_data=train_data1[:len(train_data1)//2]\ntrain_data1=train_data1[len(train_data1)//2:]\nmnli_df=mnli_df[['premise','hypothesis','label']]\nframes=[train_data1,mnli_df]\ntrain_data1=pd.concat(frames)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:33:05.975862Z","iopub.execute_input":"2022-01-30T08:33:05.976383Z","iopub.status.idle":"2022-01-30T08:33:06.05575Z","shell.execute_reply.started":"2022-01-30T08:33:05.97635Z","shell.execute_reply":"2022-01-30T08:33:06.054891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data1)\nprint(len(val_data))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:33:12.338286Z","iopub.execute_input":"2022-01-30T08:33:12.3386Z","iopub.status.idle":"2022-01-30T08:33:12.347919Z","shell.execute_reply.started":"2022-01-30T08:33:12.338553Z","shell.execute_reply":"2022-01-30T08:33:12.346919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data['label'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:33:16.792108Z","iopub.execute_input":"2022-01-30T08:33:16.792668Z","iopub.status.idle":"2022-01-30T08:33:16.798219Z","shell.execute_reply.started":"2022-01-30T08:33:16.792637Z","shell.execute_reply":"2022-01-30T08:33:16.797307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing data","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:35:23.867785Z","iopub.execute_input":"2022-01-27T16:35:23.868527Z","iopub.status.idle":"2022-01-27T16:35:23.87414Z","shell.execute_reply.started":"2022-01-27T16:35:23.868487Z","shell.execute_reply":"2022-01-27T16:35:23.872933Z"}}},{"cell_type":"code","source":"#model_name = 'bert-base-multilingual-uncased'\n#model_name = 'xlm-roberta-base'\nmodel_name = 'joeddav/xlm-roberta-large-xnli' \nbatch_size = 32\nMAX_LENGTH = 256\nNUM_EPOCHS = 3\nL_RATE = 1e-5\nNUM_CORES = os.cpu_count()\n\nNUM_CORES","metadata":{"execution":{"iopub.status.busy":"2022-01-30T09:16:49.794769Z","iopub.execute_input":"2022-01-30T09:16:49.79546Z","iopub.status.idle":"2022-01-30T09:16:49.80431Z","shell.execute_reply.started":"2022-01-30T09:16:49.795413Z","shell.execute_reply":"2022-01-30T09:16:49.803336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = xm.xla_device()\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:26:38.432381Z","iopub.execute_input":"2022-01-30T08:26:38.432979Z","iopub.status.idle":"2022-01-30T08:26:44.362753Z","shell.execute_reply.started":"2022-01-30T08:26:38.432947Z","shell.execute_reply":"2022-01-30T08:26:44.361934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tokenizer=BertTokenizer.from_pretrained(model_name, do_lower_case=True)\ntokenizer=XLMRobertaTokenizer.from_pretrained(model_name, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:26:44.364457Z","iopub.execute_input":"2022-01-30T08:26:44.364904Z","iopub.status.idle":"2022-01-30T08:26:46.833266Z","shell.execute_reply.started":"2022-01-30T08:26:44.364849Z","shell.execute_reply":"2022-01-30T08:26:46.83236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_data = list(zip(train_data['premise'][:2], train_data['hypothesis'][:2]))\n# print(sample_data)\n# tokenized_sample = tokenizer.batch_encode_plus(sample_data, **kwargs)\n# print(tokenized_sample)\ndef preprocess(data1, tokenizer):\n    kwargs = { 'truncation': True,\n    'max_length': MAX_LENGTH,\n    'padding': 'max_length',\n     'return_attention_mask': True, \n    'return_token_type_ids': True     \n    }\n    data = list(zip(data1['premise'], data1['hypothesis']))\n    tokenized = tokenizer.batch_encode_plus(data,**kwargs)\n    input_ids = torch.LongTensor(tokenized.input_ids)\n    attention_masks = torch.LongTensor(tokenized.attention_mask)\n    token_type_ids = torch.LongTensor(tokenized.token_type_ids)\n    return input_ids, attention_masks, token_type_ids","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:26:46.834775Z","iopub.execute_input":"2022-01-30T08:26:46.835022Z","iopub.status.idle":"2022-01-30T08:26:46.841801Z","shell.execute_reply.started":"2022-01-30T08:26:46.834994Z","shell.execute_reply":"2022-01-30T08:26:46.840974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data1['label'].shape)\n#labels=np. reshape(train_data1['label'], (791464,1))\nlabels = torch.Tensor(train_data1['label']).reshape(-1, 1)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:33:25.63686Z","iopub.execute_input":"2022-01-30T08:33:25.637164Z","iopub.status.idle":"2022-01-30T08:33:25.957392Z","shell.execute_reply.started":"2022-01-30T08:33:25.637133Z","shell.execute_reply":"2022-01-30T08:33:25.956456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids, attention_masks, token_type_ids = preprocess(train_data1,tokenizer)\nlabels = torch.Tensor(train_data1['label']).reshape(-1, 1)\ntrain_dataset_final = TensorDataset(input_ids, attention_masks, token_type_ids,labels)\ntrain_dataloader = DataLoader(train_dataset_final, sampler=RandomSampler(train_dataset_final), batch_size=batch_size)\ntrain_dataset_final","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:33:28.80622Z","iopub.execute_input":"2022-01-30T08:33:28.807049Z","iopub.status.idle":"2022-01-30T08:35:38.401379Z","shell.execute_reply.started":"2022-01-30T08:33:28.807006Z","shell.execute_reply":"2022-01-30T08:35:38.400646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids1, attention_masks1, token_type_ids1 = preprocess(val_data,tokenizer)\nlabels1 = torch.Tensor(val_data['label']).reshape(-1, 1)\nval_dataset_final = TensorDataset(input_ids1, attention_masks1, token_type_ids1,labels1)\nval_dataloader = DataLoader(val_dataset_final, sampler=RandomSampler(val_dataset_final), batch_size=batch_size)\nlen(val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:35:38.403048Z","iopub.execute_input":"2022-01-30T08:35:38.403518Z","iopub.status.idle":"2022-01-30T08:35:40.204454Z","shell.execute_reply.started":"2022-01-30T08:35:38.403488Z","shell.execute_reply":"2022-01-30T08:35:40.203697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:35:40.205575Z","iopub.execute_input":"2022-01-30T08:35:40.205797Z","iopub.status.idle":"2022-01-30T08:35:40.21095Z","shell.execute_reply.started":"2022-01-30T08:35:40.205773Z","shell.execute_reply":"2022-01-30T08:35:40.210015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids_test, attention_masks_test, token_type_ids_test = preprocess(test_data,tokenizer)\ntest_dataset_final = TensorDataset(input_ids_test, attention_masks_test, token_type_ids_test)\ntest_dataloader = DataLoader(test_dataset_final, sampler=SequentialSampler(test_dataset_final), batch_size=batch_size)\nlen(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:35:40.212557Z","iopub.execute_input":"2022-01-30T08:35:40.212874Z","iopub.status.idle":"2022-01-30T08:35:41.756488Z","shell.execute_reply.started":"2022-01-30T08:35:40.212847Z","shell.execute_reply":"2022-01-30T08:35:41.755557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"#model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3, output_hidden_states=False, output_attentions=False)\nmodel = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:35:47.977111Z","iopub.execute_input":"2022-01-30T08:35:47.977388Z","iopub.status.idle":"2022-01-30T08:37:14.637907Z","shell.execute_reply.started":"2022-01-30T08:35:47.977358Z","shell.execute_reply":"2022-01-30T08:37:14.637317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testing model ","metadata":{}},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nb_input_ids = batch[0].to(device)\nb_input_mask = batch[1].to(device)\nb_token_type_ids = batch[2].to(device)\nb_labels = batch[3].to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:37:14.639129Z","iopub.execute_input":"2022-01-30T08:37:14.639495Z","iopub.status.idle":"2022-01-30T08:37:14.710958Z","shell.execute_reply.started":"2022-01-30T08:37:14.639424Z","shell.execute_reply":"2022-01-30T08:37:14.710117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = model(b_input_ids, \n                token_type_ids=b_token_type_ids, \n                attention_mask=b_input_mask,\n                labels=b_labels)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:37:14.712754Z","iopub.execute_input":"2022-01-30T08:37:14.713078Z","iopub.status.idle":"2022-01-30T08:37:14.840693Z","shell.execute_reply.started":"2022-01-30T08:37:14.713039Z","shell.execute_reply":"2022-01-30T08:37:14.839806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(outputs)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T09:44:52.425074Z","iopub.execute_input":"2022-01-29T09:44:52.425356Z","iopub.status.idle":"2022-01-29T09:44:52.429719Z","shell.execute_reply.started":"2022-01-29T09:44:52.425324Z","shell.execute_reply":"2022-01-29T09:44:52.428735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(outputs[0])\nprint(outputs[0].item())","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:37:14.844365Z","iopub.execute_input":"2022-01-30T08:37:14.84489Z","iopub.status.idle":"2022-01-30T08:37:30.200464Z","shell.execute_reply.started":"2022-01-30T08:37:14.844846Z","shell.execute_reply":"2022-01-30T08:37:30.199623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n              lr = L_RATE, \n              eps = 1e-8\n            )","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:37:30.201592Z","iopub.execute_input":"2022-01-30T08:37:30.201819Z","iopub.status.idle":"2022-01-30T08:37:30.208346Z","shell.execute_reply.started":"2022-01-30T08:37:30.201793Z","shell.execute_reply":"2022-01-30T08:37:30.207665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:37:30.209335Z","iopub.execute_input":"2022-01-30T08:37:30.209682Z","iopub.status.idle":"2022-01-30T08:37:30.535802Z","shell.execute_reply.started":"2022-01-30T08:37:30.209655Z","shell.execute_reply":"2022-01-30T08:37:30.53495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_val = 1024\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:37:30.536925Z","iopub.execute_input":"2022-01-30T08:37:30.537152Z","iopub.status.idle":"2022-01-30T08:37:30.552833Z","shell.execute_reply.started":"2022-01-30T08:37:30.537126Z","shell.execute_reply":"2022-01-30T08:37:30.551848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    model.train()\n    torch.set_grad_enabled(True)\n    total_train_loss=0\n    epoch_acc_scores_list = []\n    for i,batch in tqdm(enumerate(train_dataloader)):\n        model.zero_grad()\n        input_ids, attention_masks, token_type_ids, labels=batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device)\n        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_masks, labels=labels)\n        loss=outputs[0]\n        if i%10==0:\n            print(f'loss of batch {i}: {loss}')\n        total_train_loss+=loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n        xm.optimizer_step(optimizer, barrier=True) \n    print(f'total loss of epoch {epoch}: {total_train_loss}')\n    gc.collect()\n    \n    model.eval()\n    torch.set_grad_enabled(False)\n    total_val_loss = 0\n    targets_list=[]\n    for j, val_batch in enumerate(val_dataloader):\n        b_input_ids = val_batch[0].to(device)\n        b_input_mask = val_batch[1].to(device)\n        b_token_type_ids = val_batch[2].to(device)\n        b_labels = val_batch[3].to(device)      \n        outputs = model(b_input_ids, \n                token_type_ids=b_token_type_ids, \n                attention_mask=b_input_mask, \n                labels=b_labels)\n        loss = outputs[0]\n        total_val_loss = total_val_loss + loss.item()\n        preds = outputs[1]\n        val_preds = preds.detach().cpu().numpy()\n        targets_np = b_labels.to('cpu').numpy()\n        targets_list.extend(targets_np)\n        if j == 0:  # first batch\n            stacked_val_preds = val_preds\n\n        else:\n            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n    y_true = targets_list\n    y_pred = np.argmax(stacked_val_preds, axis=1)\n    val_acc = accuracy_score(y_true, y_pred)\n    print('val accuracy: ',val_acc)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T08:45:55.877201Z","iopub.execute_input":"2022-01-30T08:45:55.877841Z","iopub.status.idle":"2022-01-30T09:16:47.607925Z","shell.execute_reply.started":"2022-01-30T08:45:55.877802Z","shell.execute_reply":"2022-01-30T09:16:47.606577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_val_labels = []\nmodel.eval()\n\ntorch.set_grad_enabled(False)\ntotal_val_loss = 0\n\nfor j, h_batch in enumerate(test_dataloader):\n\n    b_input_ids = h_batch[0].to(device)\n    b_input_mask = h_batch[1].to(device)\n    b_token_type_ids = h_batch[2].to(device)     \n    outputs = model(b_input_ids, \n            token_type_ids=b_token_type_ids, \n            attention_mask=b_input_mask)\n    preds = outputs[0]\n    val_preds = preds.detach().cpu().numpy()\n    if j == 0:  # first batch\n        stacked_val_preds = val_preds\n\n    else:\n        stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n        #stacked_val_preds.extend(val_preds)\n    #print(len(stacked_val_preds))\n    \n            \nprint('\\nPrediction complete.')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-29T10:56:20.15264Z","iopub.execute_input":"2022-01-29T10:56:20.155067Z","iopub.status.idle":"2022-01-29T10:57:04.757935Z","shell.execute_reply.started":"2022-01-29T10:56:20.155012Z","shell.execute_reply":"2022-01-29T10:57:04.75699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(stacked_val_preds)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T10:58:55.373024Z","iopub.execute_input":"2022-01-29T10:58:55.373369Z","iopub.status.idle":"2022-01-29T10:58:55.381164Z","shell.execute_reply.started":"2022-01-29T10:58:55.373336Z","shell.execute_reply":"2022-01-29T10:58:55.379878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.argmax(stacked_val_preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T10:58:58.350608Z","iopub.execute_input":"2022-01-29T10:58:58.351681Z","iopub.status.idle":"2022-01-29T10:58:58.356441Z","shell.execute_reply.started":"2022-01-29T10:58:58.351633Z","shell.execute_reply":"2022-01-29T10:58:58.35578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/contradictory-my-dear-watson/sample_submission.csv'\n\ndf_sample = pd.read_csv(path)\n\nprint(df_sample.shape)\ndf_sample['prediction'] = test_preds\n\ndf_sample.head()\ndf_sample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T10:58:59.949772Z","iopub.execute_input":"2022-01-29T10:58:59.950223Z","iopub.status.idle":"2022-01-29T10:58:59.997586Z","shell.execute_reply.started":"2022-01-29T10:58:59.950193Z","shell.execute_reply":"2022-01-29T10:58:59.996614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# extra code","metadata":{}},{"cell_type":"code","source":"# def dataset_lang(data,lang_abv,language):\n#     mnli_df=pd.DataFrame()\n#     mnli_df['id']=[i for i in range(len(data['train']['premise']))]\n#     mnli_df['premise']=mnli['train']['premise']\n#     mnli_df['hypothesis']=mnli['train']['hypothesis']\n#     mnli_df['lang_abv']=[lang_abv]*len(data['train']['premise'])\n#     mnli_df['language']=[language]*len(data['train']['premise'])\n#     mnli_df['label']=mnli['train']['label']\n#     return mnli_df\n# lang_dict={}\n# lang_abv=train_data['lang_abv'].unique()\n# language=train_data['language'].unique()\n# print(lang_abv)\n# for i in range(len(lang_abv)):\n#     lang_dict[lang_abv[i]]=language[i]\n# xnli_df=pd.DataFrame()  \n# ind=1\n# for i in tqdm(lang_dict):\n#     abv=i\n#     lang=lang_dict[i]\n#     data1=load_dataset ('xnli', abv)\n#     get_df=dataset_lang(data1,abv,lang)\n#     if ind==1: \n#         xnli_df=get_df\n#         ind+=1\n#     else:\n#         xnli_df=pd.concat([xnli_df,get_df])\n# print(xnli_df)        \n    ","metadata":{},"execution_count":null,"outputs":[]}]}