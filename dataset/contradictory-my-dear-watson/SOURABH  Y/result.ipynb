{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom IPython.display import Audio\nimport tensorflow as tf\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport random\nimport tqdm\nfrom transformers import AutoModel, AutoTokenizer\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T03:32:24.506146Z","iopub.execute_input":"2022-01-10T03:32:24.506452Z","iopub.status.idle":"2022-01-10T03:32:32.437632Z","shell.execute_reply.started":"2022-01-10T03:32:24.506424Z","shell.execute_reply":"2022-01-10T03:32:32.436849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/contradictory-my-dear-watson/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:32:32.439607Z","iopub.execute_input":"2022-01-10T03:32:32.439981Z","iopub.status.idle":"2022-01-10T03:32:32.542328Z","shell.execute_reply.started":"2022-01-10T03:32:32.439946Z","shell.execute_reply":"2022-01-10T03:32:32.541242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:32:32.543698Z","iopub.execute_input":"2022-01-10T03:32:32.544217Z","iopub.status.idle":"2022-01-10T03:32:32.576875Z","shell.execute_reply.started":"2022-01-10T03:32:32.544178Z","shell.execute_reply":"2022-01-10T03:32:32.575889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:32:32.581498Z","iopub.execute_input":"2022-01-10T03:32:32.584741Z","iopub.status.idle":"2022-01-10T03:32:32.608568Z","shell.execute_reply.started":"2022-01-10T03:32:32.584697Z","shell.execute_reply":"2022-01-10T03:32:32.60726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/contradictory-my-dear-watson/'\ntrain = pd.read_csv(data_dir + 'train.csv')\ntest = pd.read_csv(data_dir + 'test.csv')\nsample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\npremise=data['premise']","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:32:32.616456Z","iopub.execute_input":"2022-01-10T03:32:32.618867Z","iopub.status.idle":"2022-01-10T03:32:32.759507Z","shell.execute_reply.started":"2022-01-10T03:32:32.618821Z","shell.execute_reply":"2022-01-10T03:32:32.758494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModel.from_pretrained('joeddav/xlm-roberta-large-xnli')\ntokenizer = AutoTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:32:32.76439Z","iopub.execute_input":"2022-01-10T03:32:32.766582Z","iopub.status.idle":"2022-01-10T03:34:01.636673Z","shell.execute_reply.started":"2022-01-10T03:32:32.766541Z","shell.execute_reply":"2022-01-10T03:34:01.635872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nlp\nfrom nlp import load_dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:01.638603Z","iopub.execute_input":"2022-01-10T03:34:01.639107Z","iopub.status.idle":"2022-01-10T03:34:10.602936Z","shell.execute_reply.started":"2022-01-10T03:34:01.639069Z","shell.execute_reply":"2022-01-10T03:34:10.602128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_mnli(use_validation=True):\n    result = []\n    dataset = load_dataset('multi_nli')\n    print(dataset['train'])\n    keys = ['train', 'validation_matched','validation_mismatched'] if use_validation else ['train']\n    for k in keys:\n        for record in dataset[k]:\n            c1, c2, c3 = record['premise'], record['hypothesis'], record['label']\n            if c1 and c2 and c3 in {0,1,2}:\n                result.append((c1,c2,c3,'en'))\n    result = pd.DataFrame(result, columns=['premise','hypothesis', 'label','lang_abv'])\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:10.604435Z","iopub.execute_input":"2022-01-10T03:34:10.604808Z","iopub.status.idle":"2022-01-10T03:34:10.612152Z","shell.execute_reply.started":"2022-01-10T03:34:10.604754Z","shell.execute_reply":"2022-01-10T03:34:10.611254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = load_mnli()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:10.613451Z","iopub.execute_input":"2022-01-10T03:34:10.614032Z","iopub.status.idle":"2022-01-10T03:34:48.604891Z","shell.execute_reply.started":"2022-01-10T03:34:10.613995Z","shell.execute_reply":"2022-01-10T03:34:48.604074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train = train[['id', 'premise', 'hypothesis','lang_abv', 'language', 'label']]\ntotal_train","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:48.606195Z","iopub.execute_input":"2022-01-10T03:34:48.606511Z","iopub.status.idle":"2022-01-10T03:34:48.631345Z","shell.execute_reply.started":"2022-01-10T03:34:48.606477Z","shell.execute_reply":"2022-01-10T03:34:48.630368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = mnli[['premise', 'hypothesis', 'lang_abv', 'label']]\nmnli.insert(0, 'language', 'English')\nmnli = mnli[['premise', 'hypothesis', 'lang_abv', 'language', 'label']]\nmnli.insert(0, 'id', 'xxx')\nmnli","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:48.632985Z","iopub.execute_input":"2022-01-10T03:34:48.63363Z","iopub.status.idle":"2022-01-10T03:34:48.776962Z","shell.execute_reply.started":"2022-01-10T03:34:48.633588Z","shell.execute_reply":"2022-01-10T03:34:48.775982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train = pd.concat([total_train, mnli], axis = 0)\ntotal_train","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:48.778404Z","iopub.execute_input":"2022-01-10T03:34:48.778745Z","iopub.status.idle":"2022-01-10T03:34:48.87523Z","shell.execute_reply.started":"2022-01-10T03:34:48.778709Z","shell.execute_reply":"2022-01-10T03:34:48.874484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.excerpt = df['premise'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        \n        \n        \n        \n        \n        \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    model.to(device)\n    model.eval()\n    \n \n    ds = CLRPDataset(df, tokenizer)\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in enumerate(dl):\n\n            inputz = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputz)\n            outputs = outputs[0][:, 0,:].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n} \nseed_everything(seed=config['seed'])\n\ntrain_embeddings_premise =  get_embeddings(train,'../input/modelf1')\ntest_embeddings_premise = get_embeddings(test,'../input/modelf1')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:34:48.877529Z","iopub.execute_input":"2022-01-10T03:34:48.878134Z","iopub.status.idle":"2022-01-10T03:41:59.845075Z","shell.execute_reply.started":"2022-01-10T03:34:48.878096Z","shell.execute_reply":"2022-01-10T03:41:59.844094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.excerpt = df['hypothesis'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        \n        \n        \n        \n        \n        \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    model.to(device)\n    model.eval()\n    \n \n    ds = CLRPDataset(df, tokenizer)\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in enumerate(dl):\n\n            inputz = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputz)\n            outputs = outputs[0][:, 0,:].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n} \nseed_everything(seed=config['seed'])\n\ntrain_embeddings_hypo =  get_embeddings(train,'../input/modelf1')\ntest_embeddings_hypo = get_embeddings(test,'../input/modelf1')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:41:59.846689Z","iopub.execute_input":"2022-01-10T03:41:59.84708Z","iopub.status.idle":"2022-01-10T03:49:03.580294Z","shell.execute_reply.started":"2022-01-10T03:41:59.847039Z","shell.execute_reply":"2022-01-10T03:49:03.579231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical \ny=train['label']\ny = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:49:03.583605Z","iopub.execute_input":"2022-01-10T03:49:03.584003Z","iopub.status.idle":"2022-01-10T03:49:03.637704Z","shell.execute_reply.started":"2022-01-10T03:49:03.583964Z","shell.execute_reply":"2022-01-10T03:49:03.636865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:49:03.6393Z","iopub.execute_input":"2022-01-10T03:49:03.639672Z","iopub.status.idle":"2022-01-10T03:49:03.648564Z","shell.execute_reply.started":"2022-01-10T03:49:03.639634Z","shell.execute_reply":"2022-01-10T03:49:03.647465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.excerpt = df['premise'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        \n        \n        \n        \n        \n        \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    model.to(device)\n    model.eval()\n    \n \n    ds = CLRPDataset(df, tokenizer)\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in enumerate(dl):\n\n            inputz = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputz)\n            outputs = outputs[0][:, 0,:].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n} \nseed_everything(seed=config['seed'])\n\ntotal_train_embeddings_premise =  get_embeddings(total_train,'../input/modelf1')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T03:49:03.650885Z","iopub.execute_input":"2022-01-10T03:49:03.651728Z","iopub.status.idle":"2022-01-10T04:57:35.07878Z","shell.execute_reply.started":"2022-01-10T03:49:03.651685Z","shell.execute_reply":"2022-01-10T04:57:35.07713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.excerpt = df['hypothesis'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        \n        \n        \n        \n        \n        \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    model.to(device)\n    model.eval()\n    \n \n    ds = CLRPDataset(df, tokenizer)\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in enumerate(dl):\n\n            inputz = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputz)\n            outputs = outputs[0][:, 0,:].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n} \nseed_everything(seed=config['seed'])\n\ntotal_train_embeddings_hypo =  get_embeddings(total_train,'../input/modelf1')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:57:35.08012Z","iopub.status.idle":"2022-01-10T04:57:35.080931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_y= total_train['label']\ntotal_y = to_categorical(total_y)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:57:35.082176Z","iopub.status.idle":"2022-01-10T04:57:35.082972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings_premise.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:58:21.375779Z","iopub.execute_input":"2022-01-10T04:58:21.376191Z","iopub.status.idle":"2022-01-10T04:58:21.389197Z","shell.execute_reply.started":"2022-01-10T04:58:21.376156Z","shell.execute_reply":"2022-01-10T04:58:21.38785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, LSTM,Dropout,concatenate\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense, Activation, Embedding, LSTM,Dropout,Bidirectional,GRU\nfrom keras.utils import plot_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Flatten ,Embedding,Input,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Dropout,MaxPooling1D,Bidirectional,GRU,Concatenate\nfrom keras.models import Sequential,Model","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:59:07.950677Z","iopub.execute_input":"2022-01-10T04:59:07.951056Z","iopub.status.idle":"2022-01-10T04:59:07.961575Z","shell.execute_reply.started":"2022-01-10T04:59:07.951016Z","shell.execute_reply":"2022-01-10T04:59:07.960834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crt_model():\n    i1=Input(shape=(1024,1))\n    l1=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i1)\n    l2 =MaxPooling1D(2) (l1)\n    l3=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l2)\n    l3 =MaxPooling1D(2) (l3)\n    l3=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l4=GlobalMaxPooling1D()(l3)\n    \n    \n    i12=Input(shape=(1024,1))\n    l12=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i12)\n    l22 =MaxPooling1D(2) (l12)\n    l32=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l22)\n    l32 =MaxPooling1D(2) (l32)\n    l32=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l32)\n    l42=GlobalMaxPooling1D()(l32)\n    \n    l5=concatenate([l4,l42])\n    \n    l5=Dense(120, kernel_initializer='normal',activation='relu')(l5)\n    l5=Dense(240, kernel_initializer='normal',activation='relu')(l5)\n    l7=Dense(3, kernel_initializer='normal',activation='softmax')(l5)\n    model=Model(inputs=[i1,i12], outputs=l7)\n    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:59:08.307841Z","iopub.execute_input":"2022-01-10T04:59:08.308169Z","iopub.status.idle":"2022-01-10T04:59:08.318566Z","shell.execute_reply.started":"2022-01-10T04:59:08.308141Z","shell.execute_reply":"2022-01-10T04:59:08.317404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=crt_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:59:09.072042Z","iopub.execute_input":"2022-01-10T04:59:09.072372Z","iopub.status.idle":"2022-01-10T04:59:09.647343Z","shell.execute_reply.started":"2022-01-10T04:59:09.072342Z","shell.execute_reply":"2022-01-10T04:59:09.646574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='multiple_inputs.png')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:59:10.054743Z","iopub.execute_input":"2022-01-10T04:59:10.055109Z","iopub.status.idle":"2022-01-10T04:59:10.77179Z","shell.execute_reply.started":"2022-01-10T04:59:10.05508Z","shell.execute_reply":"2022-01-10T04:59:10.770849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:59:11.304086Z","iopub.execute_input":"2022-01-10T04:59:11.304422Z","iopub.status.idle":"2022-01-10T04:59:11.311385Z","shell.execute_reply.started":"2022-01-10T04:59:11.30439Z","shell.execute_reply":"2022-01-10T04:59:11.310507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfolds = 5\nkf = KFold(n_splits=nfolds, shuffle=True, random_state=config['seed'])\nbest_iterations = []\noof_rmses = []\npreds = np.zeros(test.shape[0])\nfor k, (train_idx, valid_idx) in enumerate(kf.split(train)): \n    print(f'Fold {k}')\n    train_x_prm,train_x_hypo,train_y,test_x_prm,test_x_hypo,test_y=total_train_embeddings_premise[train_idx],total_train_embeddings_hypo[train_idx], total_y[train_idx],total_train_embeddings_premise[valid_idx],total_train_embeddings_hypo[valid_idx], total_y[valid_idx]\n    model.fit([train_x_prm.reshape(train_x_prm.shape+(1,)),train_x_hypo.reshape(train_x_hypo.shape+(1,))],\n              train_y,\n              epochs=40,\n              validation_data=([test_x_prm, test_x_hypo],test_y),\n              batch_size=32)\n    y_pred=model.predict([test_embeddings_premise,test_embeddings_hypo])\n    y_pred=y_pred.reshape(-1)\n    preds+=y_pred\n    \npreds = np.array(preds)/nfolds\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-10T04:59:17.86728Z","iopub.execute_input":"2022-01-10T04:59:17.867602Z","iopub.status.idle":"2022-01-10T05:00:35.680862Z","shell.execute_reply.started":"2022-01-10T04:59:17.867574Z","shell.execute_reply":"2022-01-10T05:00:35.678753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':dt.id,'prediction':preds})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}