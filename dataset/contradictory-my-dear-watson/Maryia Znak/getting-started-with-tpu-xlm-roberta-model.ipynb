{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-01T00:57:25.773949Z","iopub.execute_input":"2022-05-01T00:57:25.774519Z","iopub.status.idle":"2022-05-01T00:57:25.789712Z","shell.execute_reply.started":"2022-05-01T00:57:25.77441Z","shell.execute_reply":"2022-05-01T00:57:25.788814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:25.790781Z","iopub.execute_input":"2022-05-01T00:57:25.791539Z","iopub.status.idle":"2022-05-01T00:57:25.807678Z","shell.execute_reply.started":"2022-05-01T00:57:25.791499Z","shell.execute_reply":"2022-05-01T00:57:25.806776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading and exploring the data ","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ndf_test = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:25.809059Z","iopub.execute_input":"2022-05-01T00:57:25.809568Z","iopub.status.idle":"2022-05-01T00:57:25.923843Z","shell.execute_reply.started":"2022-05-01T00:57:25.809532Z","shell.execute_reply":"2022-05-01T00:57:25.922873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:25.928765Z","iopub.execute_input":"2022-05-01T00:57:25.929039Z","iopub.status.idle":"2022-05-01T00:57:25.947222Z","shell.execute_reply.started":"2022-05-01T00:57:25.92901Z","shell.execute_reply":"2022-05-01T00:57:25.946213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:25.948738Z","iopub.execute_input":"2022-05-01T00:57:25.949097Z","iopub.status.idle":"2022-05-01T00:57:25.962365Z","shell.execute_reply.started":"2022-05-01T00:57:25.949057Z","shell.execute_reply":"2022-05-01T00:57:25.961464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:25.963802Z","iopub.execute_input":"2022-05-01T00:57:25.964119Z","iopub.status.idle":"2022-05-01T00:57:25.975481Z","shell.execute_reply.started":"2022-05-01T00:57:25.964062Z","shell.execute_reply":"2022-05-01T00:57:25.974549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:25.977305Z","iopub.execute_input":"2022-05-01T00:57:25.977718Z","iopub.status.idle":"2022-05-01T00:57:26.000032Z","shell.execute_reply.started":"2022-05-01T00:57:25.977667Z","shell.execute_reply":"2022-05-01T00:57:25.999176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:26.001145Z","iopub.execute_input":"2022-05-01T00:57:26.001413Z","iopub.status.idle":"2022-05-01T00:57:26.013855Z","shell.execute_reply.started":"2022-05-01T00:57:26.001383Z","shell.execute_reply":"2022-05-01T00:57:26.012774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:26.015785Z","iopub.execute_input":"2022-05-01T00:57:26.016573Z","iopub.status.idle":"2022-05-01T00:57:26.052139Z","shell.execute_reply.started":"2022-05-01T00:57:26.016517Z","shell.execute_reply":"2022-05-01T00:57:26.051412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check whether target value is skewed\ndf_train.label.hist()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:26.053458Z","iopub.execute_input":"2022-05-01T00:57:26.053867Z","iopub.status.idle":"2022-05-01T00:57:26.355865Z","shell.execute_reply.started":"2022-05-01T00:57:26.053837Z","shell.execute_reply":"2022-05-01T00:57:26.354928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how many languages is in dataset\nprint('train lang_abv: ', len(df_train.lang_abv.unique()), ', languages: ', len(df_train.language.unique()))\nprint('test lang_abv: ', len(df_test.lang_abv.unique()), ', languages: ', len(df_test.language.unique()))\nprint('train lang & test lang: ', len(set(df_train.lang_abv.unique()) and set(df_test.lang_abv.unique())))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:26.357233Z","iopub.execute_input":"2022-05-01T00:57:26.357508Z","iopub.status.idle":"2022-05-01T00:57:26.373687Z","shell.execute_reply.started":"2022-05-01T00:57:26.357477Z","shell.execute_reply":"2022-05-01T00:57:26.372398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# great, there is the same set of languages in both train and test datasets\n# lets see what exact languages are presented and how diff sentences in diff languages look like\nfor lang in df_train.lang_abv.unique():\n    first_row = df_train[df_train.lang_abv == lang].iloc[0]\n    print(first_row.language, first_row.premise)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:26.374921Z","iopub.execute_input":"2022-05-01T00:57:26.375219Z","iopub.status.idle":"2022-05-01T00:57:26.438889Z","shell.execute_reply.started":"2022-05-01T00:57:26.375175Z","shell.execute_reply":"2022-05-01T00:57:26.438001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TPU Setup","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:26.442545Z","iopub.execute_input":"2022-05-01T00:57:26.442808Z","iopub.status.idle":"2022-05-01T00:57:28.620177Z","shell.execute_reply.started":"2022-05-01T00:57:26.442779Z","shell.execute_reply":"2022-05-01T00:57:28.619157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    \n    strategy = tf.distribute.experimental.TPUStrategy\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() \n    print('Number of replicas:', strategy.num_replicas_in_sync) ","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:28.622288Z","iopub.execute_input":"2022-05-01T00:57:28.622633Z","iopub.status.idle":"2022-05-01T00:57:34.579186Z","shell.execute_reply.started":"2022-05-01T00:57:28.622588Z","shell.execute_reply":"2022-05-01T00:57:34.578409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\nexcept ValueError:\n    tpu = None\n    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n    \nif tpu:\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu,) \n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nelif len(gpus) > 1:\n    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\nelif len(gpus) == 1:\n    strategy = tf.distribute.get_strategy() \n    print('Running on single GPU ', gpus[0].name)\nelse:\n    strategy = tf.distribute.get_strategy() \n    print('Running on CPU')\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:34.580618Z","iopub.execute_input":"2022-05-01T00:57:34.581246Z","iopub.status.idle":"2022-05-01T00:57:42.541889Z","shell.execute_reply.started":"2022-05-01T00:57:34.581188Z","shell.execute_reply":"2022-05-01T00:57:42.541241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XLM_RoBERTa model","metadata":{}},{"cell_type":"code","source":"from transformers import TFAutoModel, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:42.542916Z","iopub.execute_input":"2022-05-01T00:57:42.543332Z","iopub.status.idle":"2022-05-01T00:57:43.52975Z","shell.execute_reply.started":"2022-05-01T00:57:42.543292Z","shell.execute_reply":"2022-05-01T00:57:43.528675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def input_convert(data):\n        # -in- data - list of dict\n        # -out- inputs - dict of <key + list>\n        \n        inputs = {\n            'input_word_ids': [],\n            'input_mask': []\n        }\n        \n        for i in data:\n            inputs['input_word_ids'].append(i['input_ids'])\n            inputs['input_mask'].append(i['attention_mask'])\n            \n        inputs['input_word_ids'] = tf.ragged.constant(inputs['input_word_ids']).to_tensor()\n        inputs['input_mask'] = tf.ragged.constant(inputs['input_mask']).to_tensor()\n           \n        return inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:43.531382Z","iopub.execute_input":"2022-05-01T00:57:43.531757Z","iopub.status.idle":"2022-05-01T00:57:43.539769Z","shell.execute_reply.started":"2022-05-01T00:57:43.531712Z","shell.execute_reply":"2022-05-01T00:57:43.538636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df_train.pop('label')\ndf = pd.concat([df_train, df_test], ignore_index = True)\ndf_train.shape, df_test.shape, df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:43.541667Z","iopub.execute_input":"2022-05-01T00:57:43.542027Z","iopub.status.idle":"2022-05-01T00:57:43.560924Z","shell.execute_reply.started":"2022-05-01T00:57:43.541984Z","shell.execute_reply":"2022-05-01T00:57:43.560256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'joeddav/xlm-roberta-large-xnli'\n\n# tokenizing\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmask = []\nfor i in range(len(df)):\n    padded_seq = tokenizer(df['premise'][i], df['hypothesis'][i], padding = True, add_special_tokens = True)\n    mask.append(padded_seq)\n\ninputs = input_convert(mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:43.561913Z","iopub.execute_input":"2022-05-01T00:57:43.562525Z","iopub.status.idle":"2022-05-01T00:57:59.949428Z","shell.execute_reply.started":"2022-05-01T00:57:43.562472Z","shell.execute_reply":"2022-05-01T00:57:59.948254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split df into train and test\ninputs_train = {}\ninputs_test = {}\n\nfor key in inputs.keys():\n    inputs_train[key] = inputs[key][:len(y), :]\n    inputs_test[key] = inputs[key][len(y):, :]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:59.950862Z","iopub.execute_input":"2022-05-01T00:57:59.95119Z","iopub.status.idle":"2022-05-01T00:57:59.961373Z","shell.execute_reply.started":"2022-05-01T00:57:59.95115Z","shell.execute_reply":"2022-05-01T00:57:59.960235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# build model\nwith strategy.scope():\n    max_len = inputs['input_word_ids'].shape[1]\n    \n    encoder = TFAutoModel.from_pretrained(model_name)\n    \n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n\n    embedding = encoder([input_word_ids, input_mask])[0]\n    dense1 = Dense(256, activation='relu')(Dropout(0.1)(embedding[:,0,:]))\n    dense2 = Dense(64, activation='relu')(dense1)\n    output = Dense(3, activation='softmax')(dense2)\n\n    model = Model(inputs=[input_word_ids, input_mask], outputs = output)\n    model.compile(Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'], steps_per_execution = 100)\n\n# fit the model\nearly_stop = tf.keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)\nmodel.fit(inputs_train, y.values, epochs = 10, verbose = 1, validation_split = 0.1,\n                    batch_size = 16 * strategy.num_replicas_in_sync, callbacks = [early_stop])","metadata":{"execution":{"iopub.status.busy":"2022-05-01T00:57:59.962553Z","iopub.execute_input":"2022-05-01T00:57:59.962825Z","iopub.status.idle":"2022-05-01T01:06:39.175967Z","shell.execute_reply.started":"2022-05-01T00:57:59.962796Z","shell.execute_reply":"2022-05-01T01:06:39.175214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions\npredictions = [np.argmax(i) for i in model.predict(inputs_test)]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T01:06:39.1776Z","iopub.execute_input":"2022-05-01T01:06:39.178128Z","iopub.status.idle":"2022-05-01T01:07:33.250181Z","shell.execute_reply.started":"2022-05-01T01:06:39.178064Z","shell.execute_reply":"2022-05-01T01:07:33.249254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit the result\nsubmission = df_test.id.copy().to_frame()\nsubmission['prediction'] = predictions\nsubmission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T01:07:33.251597Z","iopub.execute_input":"2022-05-01T01:07:33.251871Z","iopub.status.idle":"2022-05-01T01:07:33.277731Z","shell.execute_reply.started":"2022-05-01T01:07:33.25184Z","shell.execute_reply":"2022-05-01T01:07:33.276998Z"},"trusted":true},"execution_count":null,"outputs":[]}]}