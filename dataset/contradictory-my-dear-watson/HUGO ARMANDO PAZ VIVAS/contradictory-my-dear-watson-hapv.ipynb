{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"transformers necesarios para abordar el problema con Bert.","metadata":{"id":"SnS3OQGoVPCQ"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:26:20.380171Z","iopub.execute_input":"2021-05-25T11:26:20.38062Z","iopub.status.idle":"2021-05-25T11:26:20.397791Z","shell.execute_reply.started":"2021-05-25T11:26:20.380515Z","shell.execute_reply":"2021-05-25T11:26:20.396901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade fsspec\n!pip install fsspec==0.9.0","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:26:29.915625Z","iopub.execute_input":"2021-05-25T11:26:29.915991Z","iopub.status.idle":"2021-05-25T11:26:45.727243Z","shell.execute_reply.started":"2021-05-25T11:26:29.91596Z","shell.execute_reply":"2021-05-25T11:26:45.726412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip3 install datasets\n!pip3 install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:26:45.729899Z","iopub.execute_input":"2021-05-25T11:26:45.730181Z","iopub.status.idle":"2021-05-25T11:27:07.220344Z","shell.execute_reply.started":"2021-05-25T11:26:45.730141Z","shell.execute_reply":"2021-05-25T11:27:07.218973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFAutoModel\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.layers import GlobalAveragePooling1D, Dense\nfrom tensorflow.keras import  Model\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:27:07.222928Z","iopub.execute_input":"2021-05-25T11:27:07.223369Z","iopub.status.idle":"2021-05-25T11:27:15.733445Z","shell.execute_reply.started":"2021-05-25T11:27:07.223319Z","shell.execute_reply":"2021-05-25T11:27:15.732508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inicialización de TPU","metadata":{}},{"cell_type":"code","source":"print(\"Tensorflow version \" + tf.__version__)\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"id":"eNHhoLBBBMtf","outputId":"c7f46ad8-4f5f-4e60-d1cb-7f6380904ce9","execution":{"iopub.status.busy":"2021-05-25T11:27:15.734663Z","iopub.execute_input":"2021-05-25T11:27:15.734936Z","iopub.status.idle":"2021-05-25T11:27:21.267319Z","shell.execute_reply.started":"2021-05-25T11:27:15.73491Z","shell.execute_reply":"2021-05-25T11:27:21.266282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"carga de archivos, entrenamiento y testing","metadata":{"id":"Ey-6CbGhcGZb"}},{"cell_type":"code","source":"max_len = 120\nbatch_size = 128\ntest = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\ntrain1 = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")","metadata":{"id":"Vp0WnvEM1coe","execution":{"iopub.status.busy":"2021-06-10T17:21:52.697166Z","iopub.execute_input":"2021-06-10T17:21:52.697529Z","iopub.status.idle":"2021-06-10T17:21:52.775194Z","shell.execute_reply.started":"2021-06-10T17:21:52.697438Z","shell.execute_reply":"2021-06-10T17:21:52.773582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"analisis de los idiomas en el data set, para elegir modelo que los contenga","metadata":{}},{"cell_type":"code","source":"train1['language'].value_counts(normalize=True)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"según https://www.kaggle.com/yoohyuck/multilingual-roberta aumentar el dataset de entrenamiento muestra mejoras en el resultado, usa para ello el dataset de huggingface, replicaré esa consideración.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_mnli(use_validation=True):\n    result = []\n    dataset = load_dataset('multi_nli')\n    print(dataset['train'])\n    keys = ['train', 'validation_matched','validation_mismatched'] if use_validation else ['train']\n    for k in keys:\n        for record in dataset[k]:\n            c1, c2, c3 = record['premise'], record['hypothesis'], record['label']\n            if c1 and c2 and c3 in {0,1,2}:\n                result.append((c1,c2,c3,'en'))\n    result = pd.DataFrame(result, columns=['premise','hypothesis', 'label','lang_abv'])\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = load_mnli()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train = train1[['id', 'premise', 'hypothesis','lang_abv', 'language', 'label']]\ntotal_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnli = mnli[['premise', 'hypothesis', 'lang_abv', 'label']]\nmnli.insert(0, 'language', 'English')\nmnli = mnli[['premise', 'hypothesis', 'lang_abv', 'language', 'label']]\nmnli.insert(0, 'id', 'xxx')\nmnli","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train = pd.concat([total_train, mnli], axis = 0)\ntotal_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train1 = total_train[['premise', 'hypothesis', 'label']] #eliminamos los datos no relevantes, como el idioma o el id\ntrain1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tokenizador con el modelo bert basico multilenguaje ","metadata":{"id":"0lgtf7pBGoh3"}},{"cell_type":"code","source":"modelo = 'joeddav/xlm-roberta-large-xnli'\ntokenizer = AutoTokenizer.from_pretrained(modelo)","metadata":{"id":"uYWmsppeshBp","outputId":"3b62d4ae-6805-43ac-cae9-417a29f6c628","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"función para tokenizar palabras","metadata":{"id":"N6FpWIjeLbZj"}},{"cell_type":"code","source":"def token(x):\n    tokens = list(tokenizer.tokenize(x))\n    tokens.append('</s>')\n    t = tokenizer.convert_tokens_to_ids(tokens)\n    return t","metadata":{"id":"kR0Sqj6VtNzS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"función para codificar las premisas y las hipotesis","metadata":{"id":"a70rqyKxLwwz"}},{"cell_type":"code","source":"def roberta_encode(hypotheses, premises, tokenizer):\n  Pad = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n  sentence1 = tf.ragged.constant([token(s) for s in np.array(hypotheses)],  dtype=tf.int32)\n  sentence2 = tf.ragged.constant([token(s) for s in np.array(premises)], dtype=tf.int32)\n  cls = [tokenizer.convert_tokens_to_ids([tokenizer.cls_token])]*sentence1.shape[0]\n  tokens = tf.concat([cls, sentence1, sentence2], axis=-1)\n  tokens = tokens[:, :max_len] #quitar para la version full\n  \n  tokens = tokens.to_tensor(default_value=Pad)\n  pad = max_len - tf.shape(tokens)[1]\n  tokens = tf.pad(tokens, [[0, 0], [0, pad]], constant_values=Pad)\n  input_word_ids = tf.reshape(tokens, [-1, max_len])\n\n   \n  input_mask = tf.cast(input_word_ids != Pad, tf.int32)\n  input_mask = tf.reshape(input_mask, [-1, max_len])\n\n  \n  input_type_ids = tf.concat([tf.zeros_like(cls), tf.zeros_like(sentence1), tf.ones_like(sentence2)], \n                             axis=-1).to_tensor()\n\n\n  inputs = {\n    'input_word_ids': input_word_ids,\n    'input_mask': input_mask,\n    'input_type_ids': input_type_ids}\n\n  return inputs","metadata":{"id":"FkoSoJ15iLwK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dataset(x, y, mode, batch_size):#función vista en varios notebook's\n    if mode == \"train\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices((x, y))\n            .repeat()\n            .shuffle(5678)\n            .batch(batch_size)\n            .prefetch(tf.data.experimental.AUTOTUNE)\n        )\n    elif mode == \"valid\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices((x, y))\n            .batch(batch_size)\n            .cache()\n            .prefetch(tf.data.experimental.AUTOTUNE)\n        )\n    elif mode == \"test\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices(x)\n            .batch(batch_size)\n            )\n    else:\n        raise NotImplementedError\n    return dataset","metadata":{"id":"h2QxjdJmj1Mw","outputId":"ed0d1b29-931d-44e0-99c0-668dd0fd6970","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(train1[['premise', 'hypothesis']].values.tolist(), train1['label'], test_size=0.25, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"o = []\np = []\nq = []\nr = []\nfor i in range(len(x_train)):\n  o.append(x_train[i][0])\n  p.append(x_train[i][1])\nfor i in range(len(x_valid)):\n  q.append(x_valid[i][0]) #cambio\n  r.append(x_valid[i][1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_ = roberta_encode(o, p, tokenizer)\nx_valid_ = roberta_encode(q, r, tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = build_dataset(x_train_, y_train, \"train\", batch_size)\nvalid_dataset = build_dataset(x_valid_, y_valid, \"valid\", batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(model, max_len):\n    \n    tf.keras.backend.clear_session()\n    tf.random.set_seed(0)\n    \n    with strategy.scope():\n        \n        input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n        model = TFAutoModel.from_pretrained(modelo)\n        roberta = model([input_word_ids])[0]\n        output = GlobalAveragePooling1D()(roberta)\n        output = Dense(3, activation='softmax')(output)\n        \n        model = Model(inputs=[input_word_ids], outputs = output)\n        model.compile(optimizer=Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    model.summary()\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(modelo, max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = len(x_train) // batch_size\nstop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=2, mode='min', restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset, validation_data=valid_dataset, steps_per_epoch=steps_per_epoch, epochs=4, callbacks=[stop])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"hacemos la predicción","metadata":{"id":"L4NpO6qPw8-c"}},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['premise', 'hypothesis']] #eliminamos los datos no relevantes, como el idioma o el id\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = roberta_encode(test.premise.values, test.hypothesis.values, tokenizer)\ntest_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data  = build_dataset(test_data, None, \"test\", batch_size)\ntest_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [np.argmax(i) for i in model.predict(test_data)]\n","metadata":{"id":"MczpCq5mtY3N","outputId":"72e16200-ab9e-4152-a156-c635fbcfc80f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"creamos y guardamos el archvo a enviar","metadata":{"id":"69jqG4UzxGq8"}},{"cell_type":"code","source":"submission = test1.id.copy().to_frame()\nprint(submission)","metadata":{"id":"rkXLeU9FuceL","outputId":"dae3ac8e-f6f0-4ec5-d033-7a9862ca1347","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['prediction'] = predictions","metadata":{"id":"xt-7vUwiwuaQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"id":"J_gKUjjvycN4","outputId":"07cd0c5d-d0a1-4342-f5ec-175ced97777a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"id":"7qY7mGRcynUH","trusted":true},"execution_count":null,"outputs":[]}]}