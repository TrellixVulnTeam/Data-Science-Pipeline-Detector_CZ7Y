{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Dealing with non-English inputs\n\nNeural machine translation (NMT) is the approach adoped ever more frequently to tackle machine translation tasks. Despite our goal in the challenge is not exactly match it we might benefit from applying it to the data at hand. We have seen in <a href='https://www.kaggle.com/erelin6613/eda-elementary'>EDA: Elementary...</a> nearly a half of the inputs are non-English texts.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook we utilize Marian model, if you want to get deeper understanding of it the paper <a href='https://arxiv.org/pdf/1805.12096.pdf'>Marian: Cost-effective High-Quality Neural Machine Translation in C++</a> is a good place to start. We will use models pretrained on a massive collection of translations <a href='http://opus.nlpl.eu/'>OPUS</a>. It will be understatment to say Language Technology Research Group at the University of Helsinki did a great job at bridging so many languages. If you are interested in their work check out their blog at https://blogs.helsinki.fi/language-technology/.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q transformers\n!pip install -q mosestokenizer\n!pip install -q translators","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\nfrom transformers import MarianMTModel, MarianTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = '../input/contradictory-my-dear-watson'\ntrain_path = 'train.csv'\ntest_path = 'test.csv'\n\ntrain_df = pd.read_csv(os.path.join(root_dir, train_path))\ntest_df = pd.read_csv(os.path.join(root_dir, test_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {k: f'Helsinki-NLP/opus-mt-{k}-en' for k in train_df.lang_abv.unique()}\nmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def translate_df(df, compare=True, fields=['premise', 'hypothesis']):\n    \n    def translate_google(string, lang):\n        import translators as ts\n        string = ts.google(query_text=string,\n                           from_language=lang, \n                           to_language='en',\n                            sleep_seconds=1)\n        return string\n\n    def translate_merian(tokenizer, model, string):\n        batch = tokenizer.prepare_translation_batch(\n                src_texts=[string])\n        gen = model.generate(**batch)\n        translation = tokenizer.batch_decode(\n            gen, skip_special_tokens=True)\n        \n        return translation[0]\n    \n    def compare(subset, tokenizer, model):\n        idx = subset.index[-1]\n        original = subset[fields[0]][idx]\n        g_translation = translate_google(\n            subset[fields[0]][idx], subset.lang_abv[idx])\n        trs = translate_merian(tokenizer, model, subset[fields[0]][idx])\n        print(f'Original: {original},\\n\\\n        Google trainslation: {g_translation}\\n\\\n        Marian translation: {trs}')\n        \n        \n    for k in models:\n        if k == 'en':\n            continue\n        print('translating: ', k)\n        \n        try:\n            tokenizer = MarianTokenizer.from_pretrained(models[k])\n            model = MarianMTModel.from_pretrained(models[k])\n        except Exception as e:\n            print(e)\n            continue\n        subset = df[df.lang_abv==k]\n        \n        if compare:\n            compare(subset, tokenizer, model)\n            \n        for idx in tqdm(subset.index):\n            for f in fields:\n                df.loc[idx, f] = translate_merian(\n                    tokenizer, model, df.loc[idx, f])\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = translate_df(train_df)\ntest_df = translate_df(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.to_csv('train_df.csv', index=False)\ntest_df.to_csv('test_df.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Was it useful? Probably not as much as one might expect, but it is certainly fun application. Hope you enjoyed this little overview of Google vs MarianMT :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}