{"cells":[{"metadata":{"_uuid":"7edff2eb-50cb-4285-8255-b3262dbd5161","_cell_guid":"5c1b75ee-94f3-40c8-adbe-4ca8325b9f9c","trusted":true},"cell_type":"markdown","source":"Natural Language Inferencing (NLI) is a classic NLP (Natural Language Processing) problem that involves taking two sentences (the _premise_ and the _hypothesis_ ), and deciding how they are related- if the premise entails the hypothesis, contradicts it, or neither.\n\nIn this tutorial we'll look at the _Contradictory, My Dear Watson_ competition dataset, build a preliminary model using Tensorflow 2, Keras, and BERT, and prepare a submission file."},{"metadata":{"_uuid":"d3a20929-8e1d-48d2-869c-cc57f8c63cc9","_cell_guid":"20666a1f-e31b-4134-94f8-fea9a50998d3","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3dd507b-c502-488c-9dd0-419c5d73c159","_cell_guid":"863de620-d4b7-4711-b587-e1c75be9e36f","trusted":true},"cell_type":"code","source":"!pip install deep_translator\n!pip install transformers\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nfrom deep_translator import GoogleTranslator\nimport tensorflow as tf\nimport transformers\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58fb9ec5-c099-494c-bf59-6ec9d6e64628","_cell_guid":"6c5122f9-8c39-4892-81a9-1f8830b64484","trusted":true},"cell_type":"markdown","source":"Let's set up our TPU."},{"metadata":{"_uuid":"386d0823-63ab-4765-9561-32c5f382e71d","_cell_guid":"ca2729e3-9275-4a9c-b150-592320bd3e54","trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)\n    \ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b64130f-530a-4560-8afd-462a55fc14b3","_cell_guid":"44a1d22f-053c-4188-b25f-d714aa745016","trusted":true},"cell_type":"markdown","source":"## Downloading Data"},{"metadata":{"_uuid":"b9285071-38f2-421b-9b1c-9c44d41c7365","_cell_guid":"6fb2939c-b14a-450f-85dd-7220439eaf55","trusted":true},"cell_type":"markdown","source":"The training set contains a premise, a hypothesis, a label (0 = entailment, 1 = neutral, 2 = contradiction), and the language of the text. For more information about what these mean and how the data is structured, check out the data page: https://www.kaggle.com/c/contradictory-my-dear-watson/data"},{"metadata":{"_uuid":"6e60d19f-aeae-417a-a10a-50cc1d5ee685","_cell_guid":"f3ad567b-a156-4ffc-a6f8-1f5e6e989a4e","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\ntest = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We reset index for better interpretablity of our code"},{"metadata":{"_uuid":"82e6d183-b8e1-412b-816f-c9020bac1428","_cell_guid":"d3b9a632-7abb-4bef-acd3-9cba577dc2c0","trusted":true},"cell_type":"code","source":"train = train.reset_index()\ntest = test.reset_index()\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abfb11e9-865c-4b50-b0cc-9d25851618ff","_cell_guid":"817c2470-9778-46e8-be86-fdd1b9449b93","trusted":true},"cell_type":"markdown","source":"Translate the non_english data"},{"metadata":{"_uuid":"c63a91e0-05f7-4a67-acf8-2131ef50f054","_cell_guid":"e16e8879-c565-4a29-bacc-26648659da29","trusted":true},"cell_type":"code","source":"def trans_to_eng(row):\n    premise = row['premise']\n    hypothesis = row['hypothesis']\n    \n    nmber = row['index']\n    source = row['lang_abv']\n    target = 'en'\n    \n    if source != 'en':\n        en_return_premise = GoogleTranslator(source=source, target=target).translate(premise)\n        en_return_hypothesis = GoogleTranslator(source=source, target=target).translate(hypothesis)\n    else:\n        en_return_premise = premise\n        en_return_hypothesis = hypothesis\n       \n    #print(en_return)\n    #if  umprint(nmber, sep=' ', end='', flush=True)\n    if nmber % 1000 == 0:\n        print(nmber)\n    return en_return_premise, en_return_hypothesis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get Translated Premise and Hypothesis"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['premise_en'], train['hypothesis_en'] = zip(*train.apply(lambda x: trans_to_eng(x), axis = 1 ))\ntest['premise_en'], test['hypothesis_en'] = zip(*test.apply(lambda x: trans_to_eng(x), axis = 1 ))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"216dc9c2-1699-4b89-af27-443d1b4c7289","_cell_guid":"8c9122ea-797d-48f1-b4ba-85bc2e0e6f18","trusted":true},"cell_type":"markdown","source":"Let's checkout the data"},{"metadata":{"_uuid":"7243f511-d81e-436c-971f-6328b7c0cf43","_cell_guid":"7d9b43ef-4ac1-40d5-aebc-a162f1b9a6c0","trusted":true},"cell_type":"code","source":"print(f\"premise: {train.loc[13, 'premise_en']}\")\nprint(f\"hypothesis: {train.loc[13, 'hypothesis_en']}\")\nprint(f\"label: {train.loc[13, 'label']}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68cee874-838e-4f0e-9f80-bfebc4a295d0","_cell_guid":"a7f5d429-083e-4d81-883f-e032dfb0e236","trusted":true},"cell_type":"markdown","source":"## Preparing Data for Input"},{"metadata":{"_uuid":"27e66828-76b9-44f4-ba79-66fe0cb8f922","_cell_guid":"f20a33db-a377-43b6-825e-157456ed1092","trusted":true},"cell_type":"markdown","source":"Load and Tokenize using electra model"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = 100  # Maximum length of input sentence to the model.\nbatch_size = 16\n#epochs = 6","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0af7b876-e719-474a-b6a5-fef500624b83","_cell_guid":"ddc3e65e-24a4-43dc-98f0-194655d17cfd","trusted":true},"cell_type":"code","source":"tokenizer = transformers.ElectraTokenizer.from_pretrained(\"google/electra-large-discriminator\", do_lower_case=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_encoded = tokenizer(text=list(train.premise_en.values),\n                    text_pair=list(train.hypothesis_en.values),\n                    add_special_tokens=True,\n                    max_length=max_length,\n                    truncation=True,\n                    padding=True,\n                    return_attention_mask=True,\n                    return_token_type_ids=True,\n                    return_tensors='tf'\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_size = int(len(train)*0.33)\n\ndataset = tf.data.Dataset.from_tensor_slices((train_encoded.data, train.label.values))\nval_dataset = (dataset.take(val_size).batch(batch_size))\ntrain_dataset = (dataset.skip(val_size).batch(batch_size))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6088f3d-8778-4a6c-82b0-db6a5461ec95","_cell_guid":"f6f4ab91-c9b5-4861-a400-89969200b7f4","trusted":true},"cell_type":"markdown","source":"Model"},{"metadata":{"_uuid":"2cd597c4-6204-44ba-869a-fbf7c32c711d","_cell_guid":"55838dc3-c459-4097-b5b2-44d049429e25","trusted":true},"cell_type":"code","source":"MODEL_NAME = 'google/electra-large-discriminator'\nwith tpu_strategy.scope():\n    transformer = transformers.TFAutoModel.from_pretrained(MODEL_NAME)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1bf9ee4-e872-45d8-a118-a72eb7917d8b","_cell_guid":"3dbd7066-6469-4823-8e09-e2dfa0a68bcc","trusted":true},"cell_type":"markdown","source":"## Creating & Training Model"},{"metadata":{"_uuid":"1094f3ff-6b5b-4b15-9d93-b0065ae586bd","_cell_guid":"69f90af1-4d66-4b83-a264-df23a3a68e26","trusted":true},"cell_type":"code","source":"def create_model():\n\n    input_1 = tf.keras.Input(shape=(max_length,),name='input_ids', dtype='int32')\n    input_2 = tf.keras.Input(shape=(max_length,),name='attention_mask', dtype='int32')\n    input_3 = tf.keras.Input(shape=(max_length,),name='token_type_ids', dtype='int32')\n\n    #x = transformer((input_1, input_2, input_3))[0]\n    #output_1 = tf.keras.layers.Dense(300, activation='relu')(x[:,0,:])\n    #output_2 = tf.keras.layers.Dense(100, activation='relu')(output_1)\n    #output = tf.keras.layers.Dense(3, activation='softmax', name='output_layer')(output_2)\n    sequence_output = transformer((input_1, input_2, input_3))[0]\n    output_1 = tf.keras.layers.Dense(400, activation='relu')(sequence_output[:,0,:])\n    output_2 = tf.keras.layers.Dense(100, activation='relu')(output_1)\n    output = tf.keras.layers.Dense(3, activation='softmax', name='output_layer')(output_2)\n     \n    \n    model = tf.keras.Model(inputs=(input_1, input_2, input_3), outputs=output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47c8cc2f-a7b9-4bae-971b-e41277b45c8b","_cell_guid":"97885b33-70f1-4d14-b788-fd1a650d5a57","trusted":true},"cell_type":"code","source":"with tpu_strategy.scope():\n    model = create_model()\n    optimizer = tf.keras.optimizers.Adam(learning_rate =1e-5)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.3,\n    patience= 1,\n    min_lr=1e-7\n)\n\nhistory = model.fit(\n    train_dataset,\n    epochs = 10,\n    verbose = 2,\n    batch_size = batch_size,\n    callbacks=[lr_reduction],\n    validation_data=val_dataset\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding_test = tokenizer(text=list(test.premise_en.values),\n                    text_pair=list(test.hypothesis_en.values),\n                    add_special_tokens=True,\n                    max_length=max_length,\n                    truncation=True,\n                    padding=True,\n                    return_attention_mask=True,\n                    return_token_type_ids=True,\n                    return_tensors='tf'\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_submission = model.predict(encoding_test.data, batch_size=128, verbose=1)\ntest_pred_labels = np.argmax(pred_submission, axis=1)\n\n#submission = pd.DataFrame()\ntest['prediction'] = test_pred_labels\ntest = test[['id','prediction']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}