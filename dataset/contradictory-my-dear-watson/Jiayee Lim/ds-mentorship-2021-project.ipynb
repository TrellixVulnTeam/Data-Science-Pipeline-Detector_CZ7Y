{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Natural Language Inferencing (NLI) is a classic NLP (Natural Language Processing) problem that involves taking two sentences (the _premise_ and the _hypothesis_ ), and deciding how they are related- if the premise entails the hypothesis, contradicts it, or neither.\n\nIn this tutorial we'll look at the _Contradictory, My Dear Watson_ competition dataset, build a preliminary model using Tensorflow 2, Keras, and BERT, and prepare a submission file.","metadata":{"_uuid":"7edff2eb-50cb-4285-8255-b3262dbd5161","_cell_guid":"5c1b75ee-94f3-40c8-adbe-4ca8325b9f9c","trusted":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"d3a20929-8e1d-48d2-869c-cc57f8c63cc9","_cell_guid":"20666a1f-e31b-4134-94f8-fea9a50998d3","execution":{"iopub.status.busy":"2021-08-16T07:27:11.419156Z","iopub.execute_input":"2021-08-16T07:27:11.419549Z","iopub.status.idle":"2021-08-16T07:27:11.430015Z","shell.execute_reply.started":"2021-08-16T07:27:11.419512Z","shell.execute_reply":"2021-08-16T07:27:11.429188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:27:11.431372Z","iopub.execute_input":"2021-08-16T07:27:11.431958Z","iopub.status.idle":"2021-08-16T07:27:11.442747Z","shell.execute_reply.started":"2021-08-16T07:27:11.431916Z","shell.execute_reply":"2021-08-16T07:27:11.441988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, TFBertModel\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# from tensorflow import keras\n# import keras_tuner as kt\n\n# from numpy.random import seed\n# seed(1)\n# from tensorflow import set_random_seed\n# set_random_seed(2)\n\n# ImportError: cannot import name 'set_random_seed' from 'tensorflow' (/opt/conda/lib/python3.7/site-packages/tensorflow/__init__.py)\n\nimport numpy as np\nimport tensorflow as tf\nimport random as rn\n\n# The below is necessary in Python 3.2.3 onwards to\n# have reproducible behavior for certain hash-based operations.\n# See these references for further details:\n# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n\nos.environ['PYTHONHASHSEED'] = '0'\n\n# The below is necessary for starting Numpy generated random numbers\n# in a well-defined initial state.\n\nnp.random.seed(42)\n\n# The below is necessary for starting core Python generated random numbers\n# in a well-defined state.\n\nrn.seed(12345)\n\n# Force TensorFlow to use single thread.\n# Multiple threads are a potential source of\n# non-reproducible results.\n# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n\n# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n\nfrom keras import backend as K\n\n# The below tf.set_random_seed() will make random number generation\n# in the TensorFlow backend have a well-defined initial state.\n# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n\ntf.random.set_seed(1234)\n\n# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n# K.set_session(sess)","metadata":{"_uuid":"e3dd507b-c502-488c-9dd0-419c5d73c159","_cell_guid":"863de620-d4b7-4711-b587-e1c75be9e36f","execution":{"iopub.status.busy":"2021-08-16T07:27:11.444687Z","iopub.execute_input":"2021-08-16T07:27:11.445221Z","iopub.status.idle":"2021-08-16T07:27:18.990366Z","shell.execute_reply.started":"2021-08-16T07:27:11.445181Z","shell.execute_reply":"2021-08-16T07:27:18.989427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's set up our TPU.","metadata":{"_uuid":"58fb9ec5-c099-494c-bf59-6ec9d6e64628","_cell_guid":"6c5122f9-8c39-4892-81a9-1f8830b64484","trusted":true}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"_uuid":"386d0823-63ab-4765-9561-32c5f382e71d","_cell_guid":"ca2729e3-9275-4a9c-b150-592320bd3e54","execution":{"iopub.status.busy":"2021-08-16T07:27:18.991797Z","iopub.execute_input":"2021-08-16T07:27:18.992079Z","iopub.status.idle":"2021-08-16T07:27:24.618094Z","shell.execute_reply.started":"2021-08-16T07:27:18.992053Z","shell.execute_reply":"2021-08-16T07:27:24.617164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Data","metadata":{"_uuid":"0b64130f-530a-4560-8afd-462a55fc14b3","_cell_guid":"44a1d22f-053c-4188-b25f-d714aa745016","trusted":true}},{"cell_type":"markdown","source":"The training set contains a premise, a hypothesis, a label (0 = entailment, 1 = neutral, 2 = contradiction), and the language of the text. For more information about what these mean and how the data is structured, check out the data page: https://www.kaggle.com/c/contradictory-my-dear-watson/data","metadata":{"_uuid":"b9285071-38f2-421b-9b1c-9c44d41c7365","_cell_guid":"6fb2939c-b14a-450f-85dd-7220439eaf55","trusted":true}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")","metadata":{"_uuid":"6e60d19f-aeae-417a-a10a-50cc1d5ee685","_cell_guid":"f3ad567b-a156-4ffc-a6f8-1f5e6e989a4e","execution":{"iopub.status.busy":"2021-08-16T07:27:24.61959Z","iopub.execute_input":"2021-08-16T07:27:24.619998Z","iopub.status.idle":"2021-08-16T07:27:24.77861Z","shell.execute_reply.started":"2021-08-16T07:27:24.619957Z","shell.execute_reply":"2021-08-16T07:27:24.777552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use the pandas head() function to take a quick look at the training set.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"82e6d183-b8e1-412b-816f-c9020bac1428","_cell_guid":"d3b9a632-7abb-4bef-acd3-9cba577dc2c0","execution":{"iopub.status.busy":"2021-08-16T07:27:24.780173Z","iopub.execute_input":"2021-08-16T07:27:24.780577Z","iopub.status.idle":"2021-08-16T07:27:24.809047Z","shell.execute_reply.started":"2021-08-16T07:27:24.780544Z","shell.execute_reply":"2021-08-16T07:27:24.808048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at one of the pairs of sentences.","metadata":{"_uuid":"abfb11e9-865c-4b50-b0cc-9d25851618ff","_cell_guid":"817c2470-9778-46e8-be86-fdd1b9449b93","trusted":true}},{"cell_type":"code","source":"train.premise.values[1]","metadata":{"_uuid":"dea716f0-9698-4a10-a7f1-1a0bb36054db","_cell_guid":"bcca3548-bb15-4868-86ec-95fe084d6e06","execution":{"iopub.status.busy":"2021-08-16T07:27:24.811637Z","iopub.execute_input":"2021-08-16T07:27:24.812204Z","iopub.status.idle":"2021-08-16T07:27:24.820179Z","shell.execute_reply.started":"2021-08-16T07:27:24.812163Z","shell.execute_reply":"2021-08-16T07:27:24.819256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hypothesis.values[1]","metadata":{"_uuid":"5b639eff-aeea-4dca-b516-7e729cdeb741","_cell_guid":"15dcbe6c-4914-4400-a8fd-65b6e4cbf652","execution":{"iopub.status.busy":"2021-08-16T07:27:24.821965Z","iopub.execute_input":"2021-08-16T07:27:24.822267Z","iopub.status.idle":"2021-08-16T07:27:24.833274Z","shell.execute_reply.started":"2021-08-16T07:27:24.822241Z","shell.execute_reply":"2021-08-16T07:27:24.832406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.label.values[1]","metadata":{"_uuid":"c63a91e0-05f7-4a67-acf8-2131ef50f054","_cell_guid":"e16e8879-c565-4a29-bacc-26648659da29","execution":{"iopub.status.busy":"2021-08-16T07:27:24.834695Z","iopub.execute_input":"2021-08-16T07:27:24.835067Z","iopub.status.idle":"2021-08-16T07:27:24.845117Z","shell.execute_reply.started":"2021-08-16T07:27:24.83504Z","shell.execute_reply":"2021-08-16T07:27:24.844488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These statements are contradictory, and the label shows that.\n\nLet's look at the distribution of languages in the training set.","metadata":{"_uuid":"216dc9c2-1699-4b89-af27-443d1b4c7289","_cell_guid":"8c9122ea-797d-48f1-b4ba-85bc2e0e6f18","trusted":true}},{"cell_type":"code","source":"labels, frequencies = np.unique(train.language.values, return_counts = True)\n\nplt.figure(figsize = (10,10))\nplt.pie(frequencies,labels = labels, autopct = '%1.1f%%')\nplt.show()","metadata":{"_uuid":"7243f511-d81e-436c-971f-6328b7c0cf43","_cell_guid":"7d9b43ef-4ac1-40d5-aebc-a162f1b9a6c0","execution":{"iopub.status.busy":"2021-08-16T07:27:24.846127Z","iopub.execute_input":"2021-08-16T07:27:24.846541Z","iopub.status.idle":"2021-08-16T07:27:25.141757Z","shell.execute_reply.started":"2021-08-16T07:27:24.846499Z","shell.execute_reply":"2021-08-16T07:27:25.140696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Data for Input","metadata":{"_uuid":"68cee874-838e-4f0e-9f80-bfebc4a295d0","_cell_guid":"a7f5d429-083e-4d81-883f-e032dfb0e236","trusted":true}},{"cell_type":"markdown","source":"To start out, we can use a pretrained model. Here, we'll use a multilingual BERT model from huggingface. For more information about BERT, see: https://github.com/google-research/bert/blob/master/multilingual.md\n\nFirst, we download the tokenizer.","metadata":{"_uuid":"27e66828-76b9-44f4-ba79-66fe0cb8f922","_cell_guid":"f20a33db-a377-43b6-825e-157456ed1092","trusted":true}},{"cell_type":"code","source":"model_name = 'bert-base-multilingual-cased'\ntokenizer = BertTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"0af7b876-e719-474a-b6a5-fef500624b83","_cell_guid":"ddc3e65e-24a4-43dc-98f0-194655d17cfd","execution":{"iopub.status.busy":"2021-08-16T07:27:25.143186Z","iopub.execute_input":"2021-08-16T07:27:25.143772Z","iopub.status.idle":"2021-08-16T07:27:26.933386Z","shell.execute_reply.started":"2021-08-16T07:27:25.143728Z","shell.execute_reply":"2021-08-16T07:27:26.932362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tokenizers turn sequences of words into arrays of numbers. Let's look at an example:","metadata":{"_uuid":"a6088f3d-8778-4a6c-82b0-db6a5461ec95","_cell_guid":"f6f4ab91-c9b5-4861-a400-89969200b7f4","trusted":true}},{"cell_type":"code","source":"def encode_sentence(s):\n   tokens = list(tokenizer.tokenize(s))\n   tokens.append('[SEP]')\n   return tokenizer.convert_tokens_to_ids(tokens)","metadata":{"_uuid":"2cd597c4-6204-44ba-869a-fbf7c32c711d","_cell_guid":"55838dc3-c459-4097-b5b2-44d049429e25","execution":{"iopub.status.busy":"2021-08-16T07:27:26.935003Z","iopub.execute_input":"2021-08-16T07:27:26.935309Z","iopub.status.idle":"2021-08-16T07:27:26.940208Z","shell.execute_reply.started":"2021-08-16T07:27:26.935278Z","shell.execute_reply":"2021-08-16T07:27:26.939241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encode_sentence(\"I love machine learning\")","metadata":{"_uuid":"797de062-6743-4455-9ead-73527bf6c3b6","_cell_guid":"f05a9baa-b7fa-44da-89dd-04fdfc149cba","execution":{"iopub.status.busy":"2021-08-16T07:27:26.941369Z","iopub.execute_input":"2021-08-16T07:27:26.941711Z","iopub.status.idle":"2021-08-16T07:27:26.955913Z","shell.execute_reply.started":"2021-08-16T07:27:26.941674Z","shell.execute_reply":"2021-08-16T07:27:26.954965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BERT uses three kind of input data- input word IDs, input masks, and input type IDs.\n\nThese allow the model to know that the premise and hypothesis are distinct sentences, and also to ignore any padding from the tokenizer.\n\nWe add a [CLS] token to denote the beginning of the inputs, and a [SEP] token to denote the separation between the premise and the hypothesis. We also need to pad all of the inputs to be the same size. For more information about BERT inputs, see: https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel\n\nNow, we're going to encode all of our premise/hypothesis pairs for input into BERT.","metadata":{"_uuid":"1fb6acf3-3c19-494e-83bd-84d6d933e6f0","_cell_guid":"e80e3fcd-513e-4d14-88fd-9417b746c107","trusted":true}},{"cell_type":"code","source":"max_len = 50\n\ndef bert_encode(hypotheses, premises, tokenizer):\n    num_examples = len(hypotheses)\n    \n    sentence1 = tf.ragged.constant([encode_sentence(s) for s in np.array(hypotheses)])\n    sentence2 = tf.ragged.constant([encode_sentence(s) for s in np.array(premises)])\n    \n    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n    input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n    input_mask = tf.ones_like(input_word_ids).to_tensor()\n    \n    type_cls = tf.zeros_like(cls)\n    type_s1 = tf.zeros_like(sentence1)\n    type_s2 = tf.ones_like(sentence2)\n    \n    input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1).to_tensor()\n    inputs = {\n        'input_word_ids': input_word_ids.to_tensor()[:,:max_len],\n        'input_mask': input_mask[:,:max_len],\n        'input_type_ids': input_type_ids[:,:max_len]\n    }\n    return inputs","metadata":{"_uuid":"dedb18d0-63cb-492b-8fe0-b4ebb8819e4c","_cell_guid":"037b0a29-3e6d-42b6-b13a-328fab19d15d","execution":{"iopub.status.busy":"2021-08-16T07:27:26.957121Z","iopub.execute_input":"2021-08-16T07:27:26.957437Z","iopub.status.idle":"2021-08-16T07:27:26.967379Z","shell.execute_reply.started":"2021-08-16T07:27:26.957411Z","shell.execute_reply":"2021-08-16T07:27:26.96636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input = bert_encode(train.premise.values, train.hypothesis.values, tokenizer)","metadata":{"_uuid":"697579c5-9f89-421c-8cbc-4321a7c93179","_cell_guid":"fc14d779-d0c6-4585-8e80-ebf539bd132c","execution":{"iopub.status.busy":"2021-08-16T07:27:26.968773Z","iopub.execute_input":"2021-08-16T07:27:26.969147Z","iopub.status.idle":"2021-08-16T07:27:41.445437Z","shell.execute_reply.started":"2021-08-16T07:27:26.969119Z","shell.execute_reply":"2021-08-16T07:27:41.444417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating & Training Model","metadata":{"_uuid":"e1bf9ee4-e872-45d8-a118-a72eb7917d8b","_cell_guid":"3dbd7066-6469-4823-8e09-e2dfa0a68bcc","trusted":true}},{"cell_type":"markdown","source":"Now, we can incorporate the BERT transformer into a Keras Functional Model. For more information about the Keras Functional API, see: https://www.tensorflow.org/guide/keras/functional.\n\nThis model was inspired by the model in this notebook: https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert#BERT-and-Its-Implementation-on-this-Competition, which is a wonderful introduction to NLP!","metadata":{"_uuid":"33811793-9df3-4d97-84c3-c5367a130cd7","_cell_guid":"7ebc4032-48bf-4bbd-8244-6b4ee38a1f56","trusted":true}},{"cell_type":"code","source":"def build_model():\n    bert_encoder = TFBertModel.from_pretrained(model_name)\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n\n    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0] # sentence embedding instead of word embedding\n    # print('Embedding.shape is:', embedding.shape) # (None, 50, 768)\n#     x = tf.keras.layers.BatchNormalization(\n#         axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n#         beta_initializer='zeros', gamma_initializer='ones',\n#         moving_mean_initializer='zeros',\n#         moving_variance_initializer='ones', beta_regularizer=None,\n#         gamma_regularizer=None, beta_constraint=None, gamma_constraint=None\n#     )(embedding[:,0,:]) # find the weights\n#     x = tf.keras.layers.Dropout(0.2, noise_shape=None, seed=None)(embedding[:,0,:]) # find the weights\n#     x = tf.keras.layers.Dense(6, activation='relu')(embedding[:,0,:]) # find the weights\n    x = tf.keras.layers.Dense(6, activation='relu')(tf.keras.layers.Dense(8, activation='relu')(embedding[:,0,:])) # find the weights\n#     x = (embedding[:,0,:]) # find the weights\n    output = tf.keras.layers.Dense(3, activation='softmax')(x)\n    # Dense = linear layer\n    # 3 because we want the prob of each category (we have 3 categories)\n    # softmax transforms output vector (whose sum may not = 1) into probabilities for each category (sum = 1 and each prob >= 0)\n\n    inputs = [input_word_ids, input_mask, input_type_ids]\n    model = tf.keras.Model(inputs=inputs, outputs=output)\n\n    # Tune the learning rate for the optimizer\n#     hp_learning_rate = hp.Choice('learning_rate', values=[1e-4, 1e-5, 1e-6])\n    \n    # 27 July 2021 TODO: Try -4, -6.\n    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    # knowing backpropagation will help know what Adam, loss and metrics are doing\n    # loss(input truth prob, output prob) = diff\n    # grad = grad - lr*loss()\n    # we train by batch, but when we train \"perfectly\" for one batch, it doesn't mean the model applies well to the other\n    # batches\n    # lr determines how fast grad moves when learning\n    # https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other\n    \n    return model","metadata":{"_uuid":"1094f3ff-6b5b-4b15-9d93-b0065ae586bd","_cell_guid":"69f90af1-4d66-4b83-a264-df23a3a68e26","execution":{"iopub.status.busy":"2021-08-16T07:27:41.446755Z","iopub.execute_input":"2021-08-16T07:27:41.447061Z","iopub.status.idle":"2021-08-16T07:27:41.45651Z","shell.execute_reply.started":"2021-08-16T07:27:41.447034Z","shell.execute_reply":"2021-08-16T07:27:41.455545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()\n    model.summary()\n\n# tuner = kt.RandomSearch(\n#     build_model,\n#     objective='val_accuracy',\n#     max_trials=3\n# )\n# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\n# tuner.search(train_input, train.label.values, epochs=5, validation_split=0.2, callbacks=[])\n\n# # Get the optimal hyperparameters\n# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# print(f\"\"\"\n# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n# is {best_hps.get('learning_rate')}.\n# \"\"\")\n\n# Can't use tuner because:\n# UnimplementedError: File system scheme '[local]' not implemented (file: './untitled_project/trial_5e9d562af088aefa377fff1b7f1539ac/checkpoints/epoch_0/checkpoint_temp/part-00000-of-00001')\n# \tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.","metadata":{"_uuid":"47c8cc2f-a7b9-4bae-971b-e41277b45c8b","_cell_guid":"97885b33-70f1-4d14-b788-fd1a650d5a57","execution":{"iopub.status.busy":"2021-08-16T07:27:41.457681Z","iopub.execute_input":"2021-08-16T07:27:41.45795Z","iopub.status.idle":"2021-08-16T07:28:45.163396Z","shell.execute_reply.started":"2021-08-16T07:27:41.457917Z","shell.execute_reply":"2021-08-16T07:28:45.162259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for (k, v) in train_input.items():\n#     print(k, v.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:28:45.167521Z","iopub.execute_input":"2021-08-16T07:28:45.167805Z","iopub.status.idle":"2021-08-16T07:28:45.171538Z","shell.execute_reply.started":"2021-08-16T07:28:45.167779Z","shell.execute_reply":"2021-08-16T07:28:45.170672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Original call:\n# model.fit(train_input, train.label.values, epochs = 2, verbose = 1, batch_size = 64, validation_split = 0.2)\n\n# Choosing between accuracy, precision, recall etc can depend on tasks.\n# But for tasks with no preferred metric, use ROC to compare model performances because one may have higher precision,\n# others may have higher recall etc.\n\n# These are hyperparameter tuning.\n\n# Should split the sets explicitly so that we can do a case study on what works and what doesn't.\n# Got overfitting when epoch increases. Consider increasing validation split.\n\n# 27 July 2021:\n# TODO: Split sets explicitly. No need to vary validation_split too much. Use small amount for validation (10% or 20%).\n# TODO: Random search batch size (start from 16, etc) and learning rate.\n# TODO: Seed the initial values so that it's deterministic.\n# TODO: Always compare models with the highest val_accuracy value.\n# Model performance after each epoch should be similar if the model architecture is largely the same. Seed initial values.\n\n# 03 Aug 2021: TODOS:\n# Batch norm, dropout\n# Add Linear layers\n# Size of hidden state in linear layers\n# Experiments\n# If model fails to predict, look at the test cases. Case study. Print those that are wrong.\n\nimport matplotlib.pyplot as plt\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', min_delta=0, patience=5, verbose=0,\n    mode='max', baseline=None, restore_best_weights=False\n)\nfitted = model.fit(train_input, train.label.values, epochs = 20, verbose = 1, batch_size = 64, validation_split = 0.2, callbacks = [early_stopping])\nprint(fitted.history)\nplt.plot(fitted.history['accuracy'])\nplt.plot(fitted.history['val_accuracy'])\nplt.plot(fitted.history['loss'])\nplt.plot(fitted.history['val_loss'])\nplt.title('Accuracy and loss')\nplt.ylabel('Accuracy or loss')\nplt.xlabel('Epoch')\nplt.legend(['Accuracy', 'Validation Accuracy', 'Loss', 'Validation Loss'], loc='upper left')\nplt.show()","metadata":{"_uuid":"316f4376-9df7-40ea-bbbd-ae46eb5562e5","_cell_guid":"0423d993-8ff5-4ab9-bc47-87e1cb74c0c5","execution":{"iopub.status.busy":"2021-08-16T07:28:45.172881Z","iopub.execute_input":"2021-08-16T07:28:45.17315Z","iopub.status.idle":"2021-08-16T07:33:16.465664Z","shell.execute_reply.started":"2021-08-16T07:28:45.173124Z","shell.execute_reply":"2021-08-16T07:33:16.464626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\n# test_input = bert_encode(test.premise.values, test.hypothesis.values, tokenizer)","metadata":{"_uuid":"3bfd96e9-cf2c-41ad-bdcc-8c31408f05bd","_cell_guid":"e26cba08-7fe9-4e2e-ab2e-062a26a5fcac","execution":{"iopub.status.busy":"2021-08-16T07:33:16.467225Z","iopub.execute_input":"2021-08-16T07:33:16.467667Z","iopub.status.idle":"2021-08-16T07:33:16.471928Z","shell.execute_reply.started":"2021-08-16T07:33:16.467625Z","shell.execute_reply":"2021-08-16T07:33:16.470864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test.head()","metadata":{"_uuid":"9f040800-653f-4f51-9f60-0456d89068be","_cell_guid":"4b871234-9a42-4f5e-9792-7fc90615b808","execution":{"iopub.status.busy":"2021-08-16T07:33:16.473524Z","iopub.execute_input":"2021-08-16T07:33:16.473918Z","iopub.status.idle":"2021-08-16T07:33:16.488122Z","shell.execute_reply.started":"2021-08-16T07:33:16.473878Z","shell.execute_reply":"2021-08-16T07:33:16.487264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating & Submitting Predictions","metadata":{"_uuid":"fb1ff888-7684-4888-b861-3c31a3f360b7","_cell_guid":"87b18b05-30f3-45f9-9c3e-6f8184934bd0","trusted":true}},{"cell_type":"code","source":"# predictions = [np.argmax(i) for i in model.predict(test_input)]","metadata":{"_uuid":"f9db46a1-1f83-4ddb-85bf-da8f40afe623","_cell_guid":"a7ab0c33-0377-4cb2-b4f9-fc489383fdb7","execution":{"iopub.status.busy":"2021-08-16T07:33:16.489033Z","iopub.execute_input":"2021-08-16T07:33:16.489294Z","iopub.status.idle":"2021-08-16T07:33:16.498951Z","shell.execute_reply.started":"2021-08-16T07:33:16.489269Z","shell.execute_reply":"2021-08-16T07:33:16.498071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The submission file will consist of the ID column and a prediction column. We can just copy the ID column from the test file, make it a dataframe, and then add our prediction column.","metadata":{"_uuid":"7b489c00-896d-44af-9371-16c2cf222365","_cell_guid":"1d0e8e42-2746-4331-95a5-3eb78ca6861c","trusted":true}},{"cell_type":"code","source":"# submission = test.id.copy().to_frame()\n# submission['prediction'] = predictions","metadata":{"_uuid":"9e0e34fa-1ef7-4207-a5c3-c21863c7be27","_cell_guid":"add7302f-ae26-4e78-b69d-858cacb35991","execution":{"iopub.status.busy":"2021-08-16T07:33:16.500059Z","iopub.execute_input":"2021-08-16T07:33:16.500328Z","iopub.status.idle":"2021-08-16T07:33:16.509739Z","shell.execute_reply.started":"2021-08-16T07:33:16.500303Z","shell.execute_reply":"2021-08-16T07:33:16.508752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.head()","metadata":{"_uuid":"1d4999aa-10d2-4a88-962a-8f10bded837b","_cell_guid":"d4fdefdc-4839-4962-ae75-6807390a6de7","execution":{"iopub.status.busy":"2021-08-16T07:33:16.511016Z","iopub.execute_input":"2021-08-16T07:33:16.51131Z","iopub.status.idle":"2021-08-16T07:33:16.51938Z","shell.execute_reply.started":"2021-08-16T07:33:16.511282Z","shell.execute_reply":"2021-08-16T07:33:16.518448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv(\"submission.csv\", index = False)","metadata":{"_uuid":"b8463f7e-8b2f-4c24-8eb3-a35ec02a2d6e","_cell_guid":"84abe9e3-ef04-4dac-97d2-2308a0f11313","execution":{"iopub.status.busy":"2021-08-16T07:33:16.520492Z","iopub.execute_input":"2021-08-16T07:33:16.520768Z","iopub.status.idle":"2021-08-16T07:33:16.529279Z","shell.execute_reply.started":"2021-08-16T07:33:16.520737Z","shell.execute_reply":"2021-08-16T07:33:16.528449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now we've created our submission file, which can be submitted to the competition. Good luck!","metadata":{"_uuid":"1af8c748-a13d-4274-9208-94d9895fdc19","_cell_guid":"4d057f53-824d-400f-b9f0-5adfc06322ef","trusted":true}}]}