{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-09T16:29:13.300857Z","iopub.execute_input":"2021-06-09T16:29:13.301221Z","iopub.status.idle":"2021-06-09T16:29:13.310725Z","shell.execute_reply.started":"2021-06-09T16:29:13.301179Z","shell.execute_reply":"2021-06-09T16:29:13.309652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:14.441715Z","iopub.execute_input":"2021-06-09T16:29:14.442054Z","iopub.status.idle":"2021-06-09T16:29:21.578976Z","shell.execute_reply.started":"2021-06-09T16:29:14.442023Z","shell.execute_reply":"2021-06-09T16:29:21.577978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install googletrans==3.1.0a0","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:21.580792Z","iopub.execute_input":"2021-06-09T16:29:21.581182Z","iopub.status.idle":"2021-06-09T16:29:27.140179Z","shell.execute_reply.started":"2021-06-09T16:29:21.581139Z","shell.execute_reply":"2021-06-09T16:29:27.139157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:27.143844Z","iopub.execute_input":"2021-06-09T16:29:27.144136Z","iopub.status.idle":"2021-06-09T16:29:27.149889Z","shell.execute_reply.started":"2021-06-09T16:29:27.144105Z","shell.execute_reply":"2021-06-09T16:29:27.14905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nimport copy\nimport math\nimport os\nimport re\nimport json\nfrom sklearn.utils import shuffle\nimport googletrans","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:27.151806Z","iopub.execute_input":"2021-06-09T16:29:27.152236Z","iopub.status.idle":"2021-06-09T16:29:27.159906Z","shell.execute_reply.started":"2021-06-09T16:29:27.152163Z","shell.execute_reply":"2021-06-09T16:29:27.158563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:27.161328Z","iopub.execute_input":"2021-06-09T16:29:27.161741Z","iopub.status.idle":"2021-06-09T16:29:27.17124Z","shell.execute_reply.started":"2021-06-09T16:29:27.161703Z","shell.execute_reply":"2021-06-09T16:29:27.170408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:27.174213Z","iopub.execute_input":"2021-06-09T16:29:27.174478Z","iopub.status.idle":"2021-06-09T16:29:29.094061Z","shell.execute_reply.started":"2021-06-09T16:29:27.174454Z","shell.execute_reply":"2021-06-09T16:29:29.093196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translator = googletrans.Translator()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:29.095283Z","iopub.execute_input":"2021-06-09T16:29:29.095618Z","iopub.status.idle":"2021-06-09T16:29:29.110569Z","shell.execute_reply.started":"2021-06-09T16:29:29.095583Z","shell.execute_reply":"2021-06-09T16:29:29.109748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 5\nWARMUP_EPOCHS = 5\nCKPT_PATH = \"ckpt/\"\ntry:\n    os.makedirs(CKPT_PATH)\nexcept:\n    print(\"path exist\")","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:29.113888Z","iopub.execute_input":"2021-06-09T16:29:29.114152Z","iopub.status.idle":"2021-06-09T16:29:29.119884Z","shell.execute_reply.started":"2021-06-09T16:29:29.114127Z","shell.execute_reply":"2021-06-09T16:29:29.119063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:32.583709Z","iopub.execute_input":"2021-06-09T16:29:32.584081Z","iopub.status.idle":"2021-06-09T16:29:32.728807Z","shell.execute_reply.started":"2021-06-09T16:29:32.584052Z","shell.execute_reply":"2021-06-09T16:29:32.727886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = shuffle(data)\nl_0 = data[(data.label == 0)]\nl_1 = data[(data.label == 1)]\nl_2 = data[(data.label == 2)]\ntrain = pd.concat([l_0[:len(l_0)//10*8], l_1[:len(l_1)//10*8], l_2[:len(l_2)//10*8]])\nval = pd.concat([l_0[len(l_0)//10*8:], l_1[len(l_1)//10*8:], l_2[len(l_2)//10*8:]])\nprint(len(data), len(l_0), len(l_1), len(l_2), len(train), len(val))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T13:49:52.383443Z","iopub.execute_input":"2021-06-09T13:49:52.3837Z","iopub.status.idle":"2021-06-09T13:49:52.428608Z","shell.execute_reply.started":"2021-06-09T13:49:52.383675Z","shell.execute_reply":"2021-06-09T13:49:52.427692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_clean(text):\n    # 全轉半形\n    new_text = ''\n    for t in text:\n        u_code = ord(t)\n        if u_code == 12288:  # 全形空格直接轉換\n            u_code = 32\n        elif 65281 <= u_code <= 65374:  # 全形字元（除空格）根據關係轉化\n            u_code -= 65248\n        s = chr(u_code)\n        # 英文轉統一小寫\n        if s.isupper(): s = s.lower()\n        new_text += s\n\n    new_text = re.sub(r'[^\\w\\s]','',new_text)\n    return new_text","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:40.982731Z","iopub.execute_input":"2021-06-09T16:29:40.983077Z","iopub.status.idle":"2021-06-09T16:29:40.989087Z","shell.execute_reply.started":"2021-06-09T16:29:40.983045Z","shell.execute_reply":"2021-06-09T16:29:40.987966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class dataset(Dataset):\n    def __init__(\n            self,\n            data,\n            tokenizer, \n            maxLengh=512\n    ):\n        self.data = data\n        self.maxLengh = maxLengh\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self, i):\n        premise = text_clean(self.data.iloc[i]['premise'])\n        hypothesis = text_clean(self.data.iloc[i]['hypothesis'])\n        language = text_clean(self.data.iloc[i]['language'])\n        label = int(self.data.iloc[i]['label'])\n\n        if language == \"Thai\":\n            premise = translator.translate(premise, dest='en', src='th').text\n            hypothesis = translator.translate(hypothesis, dest='en', src='th').text\n        elif language == \"Vietnamese\":\n            premise = translator.translate(premise, dest='en', src='vi').text\n            hypothesis = translator.translate(hypothesis, dest='en', src='vi').text\n\n        if label == 0:\n            lb = [1, 0, 0]\n        elif label == 1:\n            lb = [0, 1, 0]\n        else: \n            lb = [0, 0, 1]\n\n        encoded = self.tokenizer.encode_plus(premise, hypothesis, max_length=512, \n                                                truncation=True, add_special_tokens=True, \n                                                padding='max_length', return_tensors='pt')\n        token = encoded['input_ids'][0]\n        attn_mask = encoded['attention_mask'][0]\n\n        # token = torch.from_numpy(np.concatenate(token, axis=0))\n        # attn_mask = torch.from_numpy(np.concatenate(attn_mask, axis=0))\n        label = torch.from_numpy(np.array(lb, dtype='float32'))\n\n        return {\n            'token':token,\n            'attn_mask':attn_mask,\n            'label':label,\n        }\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:43.352922Z","iopub.execute_input":"2021-06-09T16:29:43.353271Z","iopub.status.idle":"2021-06-09T16:29:43.364008Z","shell.execute_reply.started":"2021-06-09T16:29:43.353239Z","shell.execute_reply":"2021-06-09T16:29:43.363148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset(train, tokenizer)\ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            batch_size=1, # Trains with this batch size.\n            shuffle=True\n        )\nbatch = next(iter(train_dataloader))\n# print(tokenizer.convert_ids_to_tokens(batch['token'][0]))\nprint(batch['token'].shape)\nprint(batch['attn_mask'].shape)\nprint(batch['label'].shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T13:49:52.453087Z","iopub.execute_input":"2021-06-09T13:49:52.45349Z","iopub.status.idle":"2021-06-09T13:49:52.496681Z","shell.execute_reply.started":"2021-06-09T13:49:52.453452Z","shell.execute_reply":"2021-06-09T13:49:52.495965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClsBert(nn.Module):\n    def __init__(self):\n        super(ClsBert, self).__init__()\n        self.encoder = BertModel.from_pretrained('bert-base-multilingual-cased')\n        self.cls_head = nn.Sequential(\n            nn.Dropout(0.1),\n            nn.Linear(in_features=768, out_features=3),\n            # nn.Softmax(dim=-1)\n        )\n    def forward(self, x, attn_mask):\n        # print(x.size())\n        outputs = self.encoder(x, attention_mask=attn_mask)\n        # print(outputs[0].shape)\n        # print(outputs[1].shape)\n        x = self.cls_head(outputs[1])\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:47.111773Z","iopub.execute_input":"2021-06-09T16:29:47.112148Z","iopub.status.idle":"2021-06-09T16:29:47.118975Z","shell.execute_reply.started":"2021-06-09T16:29:47.112118Z","shell.execute_reply":"2021-06-09T16:29:47.117985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AccMetric(nn.Module):\n    def __init__(self):\n        super(AccMetric, self).__init__()\n            \n    def forward(self, y_pred, y_true):\n        y_pred = nn.functional.softmax(y_pred, dim=-1)\n        y_pred = (y_pred > 0.5).float()\n        # tp = (y_pred*y_true).sum()\n        # tn = ((1-y_pred)*(1-y_true)).sum()\n        tp = (y_pred*y_true).sum()\n        acc = (tp+1e-7)/(y_true.size()[0]+1e-7)\n\n\n        return acc.item()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:47.28961Z","iopub.execute_input":"2021-06-09T16:29:47.289895Z","iopub.status.idle":"2021-06-09T16:29:47.295201Z","shell.execute_reply.started":"2021-06-09T16:29:47.289867Z","shell.execute_reply":"2021-06-09T16:29:47.294386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# move optimizer to gpu\ndef optimizer_to(optim, device):\n    for param in optim.state.values():\n        # Not sure there are any global tensors in the state dict\n        if isinstance(param, torch.Tensor):\n            param.data = param.data.to(device)\n            if param._grad is not None:\n                param._grad.data = param._grad.data.to(device)\n        elif isinstance(param, dict):\n            for subparam in param.values():\n                if isinstance(subparam, torch.Tensor):\n                    subparam.data = subparam.data.to(device)\n                    if subparam._grad is not None:\n                        subparam._grad.data = subparam._grad.data.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T13:49:52.521182Z","iopub.execute_input":"2021-06-09T13:49:52.521442Z","iopub.status.idle":"2021-06-09T13:49:52.529601Z","shell.execute_reply.started":"2021-06-09T13:49:52.521418Z","shell.execute_reply":"2021-06-09T13:49:52.528743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset(train, tokenizer)\ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            batch_size=8, # Trains with this batch size.\n            shuffle=True,\n            num_workers=2\n        )\nval_dataset = dataset(val, tokenizer)\nval_dataloader = DataLoader(\n            val_dataset,  # The training samples.\n            batch_size=8, # Trains with this batch size.\n            shuffle=False,\n            num_workers=2\n        )\ndataloaders = {'train':train_dataloader,\n               'val':val_dataloader}\nnet = ClsBert()\noptimizer = AdamW(net.parameters(), lr=5e-5)\nwarm_up_lr = lambda epoch: epoch / WARMUP_EPOCHS if epoch < WARMUP_EPOCHS else (EPOCHS - epoch) / (EPOCHS - WARMUP_EPOCHS)\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, warm_up_lr)\nscaler = torch.cuda.amp.GradScaler()\ncate_ce = nn.CrossEntropyLoss()\nacc_metric = AccMetric()\naccumulated_step = 4\ntry:\n    state = torch.load(os.path.join(CKPT_PATH, 'train_state.pt'), map_location='cpu')\n    net.load_state_dict(state['model_state_dict'])\n    print(\"net state loaded\")\n    optimizer.load_state_dict(state['optimizer_state_dict'])\n    optimizer_to(optimizer, device)\n    print(\"optimizer state loaded\")\n    print(f\"current learning rate {optimizer.param_groups[0]['lr']}\") \n    scheduler.load_state_dict(state['scheduler_state_dict'])\n    print(\"scheduler state loaded\")\n    scaler.load_state_dict(state['scaler_state_dict'])\n    print(\"scaler state loaded\")\n    history = pd.read_csv(os.path.join(CKPT_PATH, \"history.csv\"))\n    print(f\"history loaded\")\n    print(f\"best train loss {history['loss'].min():.10f}\")\n    print(f\"best train acc {history['acc'].max():.10f}\")\n    print(f\"best val acc {history['val_acc'].max():.10f}\")\n    best_train_acc = history['acc'].max()\n    last_epoch = state['epoch']\n    best_val_acc = max(history['val_acc'].to_list())\n\n    del state\nexcept:\n    print(\"did not find trained model\")\n    best_train_acc = 0.\n    best_val_acc = 0.\n    data = {\n        'loss':[np.inf], \n        'acc':[0], \n        'val_loss':[np.inf], \n        'val_acc':[0], \n    }\n    history = pd.DataFrame(data)\n    history.to_csv(os.path.join(CKPT_PATH, \"history.csv\"), index=False)\n    last_epoch = 0\n\n\nif torch.cuda.is_available():\n    net.to(device)\n    cate_ce.to(device)\n    acc_metric.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T13:49:52.532746Z","iopub.execute_input":"2021-06-09T13:49:52.533034Z","iopub.status.idle":"2021-06-09T13:50:38.622987Z","shell.execute_reply.started":"2021-06-09T13:49:52.53301Z","shell.execute_reply":"2021-06-09T13:50:38.622147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0, EPOCHS):\n  print()\n  print(f\"Epoch {epoch+1} start\")\n  for mode in ['train', 'val']:\n    if mode == 'train':\n      epoch_loss = []\n      epoch_acc = []\n\n      print(\"===== Training =====\")\n      net.train()\n\n      for i, batch in enumerate(dataloaders[mode]):\n#         print(f\"data {i+1} / {len(dataloaders[mode])}\")\n        x = batch['token']\n        y_true = batch['label']\n        attn_mask = batch['attn_mask']\n        if torch.cuda.is_available():\n          x = x.to(device)\n          y_true = y_true.to(device)\n          attn_mask = attn_mask.to(device)\n      \n        with torch.cuda.amp.autocast():\n          y_pred = net(x, attn_mask)\n          loss = cate_ce(y_pred, torch.argmax(y_true, dim=-1))\n\n        loss = loss / accumulated_step\n        scaler.scale(loss).backward()\n        if (i + 1) % accumulated_step == 0:\n#             print(\"optimizer step\")\n            scaler.step(optimizer)\n            optimizer.zero_grad()\n            scaler.update()\n        # torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n        \n        # loss.backward()\n        # optimizer.step()\n\n        running_loss = loss.item() * accumulated_step\n        if not math.isnan(running_loss):\n          epoch_loss.append(running_loss)\n#         print(f\"running loss {running_loss:.10f}\")\n        \n        running_acc = acc_metric(y_pred, y_true)\n        epoch_acc.append(running_acc)\n#         print(f\"running acc : {running_acc:.10f}\")\n\n        if (i+1)%100 == 0: \n            print(f\"data {i+1} / {len(dataloaders[mode])}\")\n            print(f\"running loss {running_loss:.10f}\")\n            print(f\"running acc : {running_acc:.10f}\")\n          \n\n      epoch_loss = np.mean(epoch_loss)\n      epoch_acc = np.mean(epoch_acc)\n\n      print()\n      print(f\"epoch loss {epoch_loss:.10f}\")\n      print(f\"epoch avg acc {epoch_acc:.10f}\")\n      now_lr = optimizer.param_groups[0]['lr']\n      print(f\"now lr {now_lr:.10f}\")\n\n      train_loss = epoch_loss\n      acc = epoch_acc\n\n      #save model\n      torch.save({\n            'epoch': epoch+1,\n            'lr':now_lr,\n            'model_state_dict': net.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict':scheduler.state_dict(),\n            'scaler_state_dict':scaler.state_dict()\n            }, os.path.join(CKPT_PATH, \"train_state.pt\"))\n      print(\"saving training weights to path\", os.path.join(CKPT_PATH, f\"train_state.pt\"))\n\n      scheduler.step()\n\n    else:\n      epoch_loss = []\n      epoch_acc = []\n      print(\"===== Validating =====\")\n      net.eval()\n      for i, batch in enumerate(dataloaders[mode]):\n#         print(f\"data {i+1} / {len(dataloaders[mode])}\")\n        x = batch['token']\n        y_true = batch['label']\n        attn_mask = batch['attn_mask']\n        if torch.cuda.is_available():\n          x = x.to(device)\n          y_true = y_true.to(device)\n          attn_mask = attn_mask.to(device)\n        \n        with torch.no_grad():\n          with torch.cuda.amp.autocast():\n            y_pred = net(x, attn_mask)\n            loss = cate_ce(y_pred, torch.argmax(y_true, dim=-1))\n\n        running_loss = loss.item()\n        if not math.isnan(running_loss):\n          epoch_loss.append(running_loss)\n#         print(f\"running loss {running_loss:.10f}\")\n\n        running_acc = acc_metric(y_pred, y_true)\n        epoch_acc.append(running_acc)\n#         print(f\"running acc : {running_acc:.10f}\")\n\n        if (i+1)%100 == 0: \n            print(f\"data {i+1} / {len(dataloaders[mode])}\")\n            print(f\"running loss {running_loss:.10f}\")\n            print(f\"running acc : {running_acc:.10f}\")\n          \n\n      epoch_loss = np.mean(epoch_loss)\n      epoch_acc = np.mean(epoch_acc)\n\n      print()\n      print(f\"epoch loss {epoch_loss:.10f}\")\n      print(f\"epoch avg acc {epoch_acc:.10f}\")\n      val_loss = epoch_loss\n      val_acc = epoch_acc\n\n      # save model\n      if (epoch_acc > best_val_acc):\n        print(f\"validating acc improved from {best_val_acc:.10f} to {epoch_acc:.10f}\")\n        print(\"saving weights to path\", os.path.join(CKPT_PATH, f\"val_acc.pt\"))\n        torch.save(net.state_dict(), os.path.join(CKPT_PATH, f\"val_acc.pt\"))\n        best_val_acc = epoch_acc\n\n\n  append_data = {\n        'loss':train_loss, \n        'acc':acc, \n        'val_loss':val_loss, \n        'val_acc':val_acc, \n        'lr':now_lr\n    }\n\n  history = history.append(\n    append_data,\n    ignore_index=True\n    )\n  \n  history.to_csv(os.path.join(CKPT_PATH, \"history.csv\"), index=False)\n  print(\"Saving history to\", os.path.join(CKPT_PATH, \"history.csv\"))\n  print(f\"Epoch {epoch+1} end\")\n  # print()\n  # print()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T13:50:38.624388Z","iopub.execute_input":"2021-06-09T13:50:38.624725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = pd.read_csv(os.path.join(CKPT_PATH, \"history.csv\"))\n\ntrain_loss = history['loss']\ntrain_acc = history['acc']\n\nval_loss = history['val_loss']\nval_acc = history['val_acc']\n\n\nlr = history['lr']\n\n\nfig, axs = plt.subplots(2, 2, figsize=(20, 20))\n# axs[0].set_ylim(0, 5)\naxs[0, 0].plot(train_loss, label=f'train loss {train_loss.min():.3f}')\naxs[0, 0].plot(val_loss, label=f'val loss {val_loss.min():.3f}')\naxs[0, 0].legend(loc=\"upper right\", fontsize=20)\naxs[0, 0].set_title('Loss', fontsize=20)\naxs[0, 0].set_xlabel('epoch', fontsize=20)\naxs[0, 0].set_ylabel('loss', fontsize=20)\n\naxs[0, 1].plot(train_acc, label=f'train acc {train_acc.max():.3f}')\naxs[0, 1].plot(val_acc, label=f'val acc {val_acc.max():.3f}')\naxs[0, 1].legend(loc=\"best\", fontsize=20)\naxs[0, 1].set_title('Acc', fontsize=20)\naxs[0, 1].set_xlabel('epoch', fontsize=20)\naxs[0, 1].set_ylabel('acc', fontsize=20)\n\nx = val_acc.argmax()\ny = val_acc.max()\nprint(x, y)\naxs[0, 1].plot(x, y, 'r*')\naxs[0, 1].annotate(f\"{y:.3f}\", (x, y), fontsize=15)\n\n\naxs[1, 0].plot(lr)\naxs[1, 0].set_title('lr', fontsize=20)\naxs[1, 0].set_xlabel('epoch', fontsize=20)\naxs[1, 0].set_ylabel('lr', fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:29:54.202738Z","iopub.execute_input":"2021-06-09T16:29:54.203108Z","iopub.status.idle":"2021-06-09T16:29:54.821671Z","shell.execute_reply.started":"2021-06-09T16:29:54.203075Z","shell.execute_reply":"2021-06-09T16:29:54.82081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = ClsBert()\nstate = torch.load(os.path.join(CKPT_PATH, 'train_state.pt'), map_location='cpu')\nnet.load_state_dict(state['model_state_dict'])\nnet.eval()\nnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:30:01.072807Z","iopub.execute_input":"2021-06-09T16:30:01.073169Z","iopub.status.idle":"2021-06-09T16:30:10.919725Z","shell.execute_reply.started":"2021-06-09T16:30:01.073138Z","shell.execute_reply":"2021-06-09T16:30:10.918924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor i in range(len(test)):\n    premise = text_clean(test.iloc[i]['premise'])\n    hypothesis = text_clean(test.iloc[i]['hypothesis'])\n    language = text_clean(test.iloc[i]['language'])\n\n    if language == \"Thai\":\n        premise = translator.translate(premise, dest='en', src='th').text\n        hypothesis = translator.translate(hypothesis, dest='en', src='th').text\n    elif language == \"Vietnamese\":\n        premise = translator.translate(premise, dest='en', src='vi').text\n        hypothesis = translator.translate(hypothesis, dest='en', src='vi').text\n\n    encoded = tokenizer.encode_plus(premise, hypothesis, max_length=512, \n                                                truncation=True, add_special_tokens=True, \n                                                padding='max_length', return_tensors='pt')\n    token = encoded['input_ids']\n    attn_mask = encoded['attention_mask']\n\n    token = token.to(device)\n    attn_mask = attn_mask.to(device)\n\n    # print(token.shape)\n    with torch.no_grad():\n        with torch.cuda.amp.autocast():\n            y_pred = net(token, attn_mask)\n\n    y_pred = nn.functional.softmax(y_pred, dim=-1)\n    y_pred = torch.argmax(y_pred).item()\n    preds.append(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:30:10.921229Z","iopub.execute_input":"2021-06-09T16:30:10.921649Z","iopub.status.idle":"2021-06-09T16:32:38.132272Z","shell.execute_reply.started":"2021-06-09T16:30:10.921611Z","shell.execute_reply":"2021-06-09T16:32:38.131422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/sample_submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:32:38.133991Z","iopub.execute_input":"2021-06-09T16:32:38.134321Z","iopub.status.idle":"2021-06-09T16:32:38.178714Z","shell.execute_reply.started":"2021-06-09T16:32:38.134286Z","shell.execute_reply":"2021-06-09T16:32:38.1779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.prediction = preds\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:32:38.179924Z","iopub.execute_input":"2021-06-09T16:32:38.180246Z","iopub.status.idle":"2021-06-09T16:32:38.194911Z","shell.execute_reply.started":"2021-06-09T16:32:38.180216Z","shell.execute_reply":"2021-06-09T16:32:38.193933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T16:32:38.196452Z","iopub.execute_input":"2021-06-09T16:32:38.196825Z","iopub.status.idle":"2021-06-09T16:32:38.214297Z","shell.execute_reply.started":"2021-06-09T16:32:38.196788Z","shell.execute_reply":"2021-06-09T16:32:38.213556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}