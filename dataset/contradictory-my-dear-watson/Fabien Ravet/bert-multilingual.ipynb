{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nos.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning\n\n# nlp augmentation\n!pip install --quiet google_trans_new\nfrom google_trans_new import google_translator  \n\nfrom transformers import BertTokenizer, TFBertModel\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n#for fast parallel processing\nfrom dask import bag, diagnostics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BACKTRSL_DEPTH = 1\n\nBACKTRSL_TIMES = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def back_translate(sequence):\n    languages = ['en', 'fr', 'th', 'tr', 'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi',\n                 'sw', 'vi', 'es', 'el']\n    \n    translator = google_translator()\n    \n    org_lang = translator.detect(sequence)[0]\n    used_languages = [org_lang]\n    for i in range(BACKTRSL_DEPTH):\n        #randomly choose language to translate sequence to  \n        used_languages.append(np.random.choice([lang for lang in languages if lang is not used_languages]))\n    \n    if org_lang in languages:\n        for i in range(BACKTRSL_DEPTH):\n            #translate to new language\n            #translated = translator.translate(sequence, dest = used_languages[i+1]).text\n            translated = translator.translate(sequence, lang_tgt = used_languages[i+1], lang_src = used_languages[i])\n        #translate back to original language\n        #translated_back = translator.translate(translated, dest = org_lang).text\n        translated_back = translator.translate(translated, lang_tgt = org_lang, lang_src = used_languages[-1])\n    \n        output_sequence = translated_back\n            \n    #if detected language not in our list of languages, do nothing\n    else:\n        output_sequence = sequence\n    \n    return output_sequence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def translate(sequence, lang = 'vi'):\n    \n    #instantiate translator\n    translator = google_translator()\n    \n    org_lang = translator.detect(sequence)[0]\n    \n    translated = translator.translate(sequence, lang_tgt = lang, lang_src = org_lang)\n        \n    output_sequence = translated\n    \n    return output_sequence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applies above define function with Dask\ndef upsampling_parallel(dataset, language):\n    if(language == 'backtrsl'):\n        prem_bag = bag.from_sequence(dataset['premise'].tolist()).map(back_translate)\n        hyp_bag =  bag.from_sequence(dataset['hypothesis'].tolist()).map(back_translate)\n    else:\n        prem_bag = bag.from_sequence(dataset['premise'].tolist()).map(lambda x: translate(x, lang = language))\n        hyp_bag =  bag.from_sequence(dataset['hypothesis'].tolist()).map(lambda x: translate(x, lang = language))\n        \n    with diagnostics.ProgressBar():\n        prems = prem_bag.compute()\n        hyps = hyp_bag.compute()\n\n    #pair premises and hypothesis\n    dataset[['premise', 'hypothesis']] = list(zip(prems, hyps))\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"train_bg = upsampling_parallel(train, \"bg\")\ntrain_bg[['lang_abv', 'language']] = ['bg', 'Bulgarian']\ntrain_bg.head()\n\ntrain_bg.to_csv(\"train_translated_bg.csv\", index = False)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_backtrsl = upsampling_parallel(test, 'backtrsl')\n\ntrain_backtrsl.to_csv(\"train_backtrsl.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"test = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\n\ntest_backtrsl1 = upsampling_parallel(test, 'backtrsl')\ntest_backtrsl2 = upsampling_parallel(test, 'backtrsl')\ntest_backtrsl3 = upsampling_parallel(test, 'backtrsl')\n\ntest_backtrsl1.to_csv(\"test_backtrsl1.csv\", index = False)\ntest_backtrsl2.to_csv(\"test_backtrsl2.csv\", index = False)\ntest_backtrsl3.to_csv(\"test_backtrsl3.csv\", index = False)\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}