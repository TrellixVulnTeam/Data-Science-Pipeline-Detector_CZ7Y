{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-27T23:02:30.26755Z","iopub.execute_input":"2021-10-27T23:02:30.267917Z","iopub.status.idle":"2021-10-27T23:02:30.298659Z","shell.execute_reply.started":"2021-10-27T23:02:30.267824Z","shell.execute_reply":"2021-10-27T23:02:30.297606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ライブラリのインポート\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AdamWeightDecay, AutoTokenizer, TFAutoModelForSequenceClassification\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:02:34.747862Z","iopub.execute_input":"2021-10-27T23:02:34.748963Z","iopub.status.idle":"2021-10-27T23:02:42.528212Z","shell.execute_reply.started":"2021-10-27T23:02:34.748912Z","shell.execute_reply":"2021-10-27T23:02:42.527423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TPUとの接続、初期化\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print('Number of replicas:', strategy.num_replicas_in_sync)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:02:47.149189Z","iopub.execute_input":"2021-10-27T23:02:47.149468Z","iopub.status.idle":"2021-10-27T23:02:53.3863Z","shell.execute_reply.started":"2021-10-27T23:02:47.149439Z","shell.execute_reply":"2021-10-27T23:02:53.38528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ハイパーパラメータの定義、トークナイザの初期化\nmodel_name = \"bert-base-multilingual-cased\"\nepochs = 100\nmax_length = 120\n\nbatch_size = 16 * strategy.num_replicas_in_sync\nprint(f\"batch_size: {batch_size}\")\n\nauto = tf.data.experimental.AUTOTUNE\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:02:57.838334Z","iopub.execute_input":"2021-10-27T23:02:57.8386Z","iopub.status.idle":"2021-10-27T23:03:00.506446Z","shell.execute_reply.started":"2021-10-27T23:02:57.838573Z","shell.execute_reply":"2021-10-27T23:03:00.505471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習データの読み込み\nall_train = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\n\n# 交差検証のためにデータを分割\ntrain, valid = train_test_split(all_train, test_size=0.2, random_state=0)\n\n# 前提、仮説のテキストのみを抽出\ntrain_text = train[['premise', 'hypothesis']].values.tolist()\nvalid_text = valid[['premise', 'hypothesis']].values.tolist()\n\n# トークナイズ + インデキシング\ntrain_encoded = tokenizer.batch_encode_plus(train_text, padding=True, max_length=max_length, truncation=True)\nvalid_encoded = tokenizer.batch_encode_plus(valid_text, padding=True, max_length=max_length, truncation=True)\n\n# TensorFlowのDatasetに変換\ntrain_dataset = (\n    tf.data.Dataset.from_tensor_slices((dict(train_encoded), train.label.values)).repeat().shuffle(2048).batch(batch_size).prefetch(auto)\n)\nvalid_dataset = (\n    tf.data.Dataset.from_tensor_slices((dict(valid_encoded), valid.label.values)).batch(batch_size).cache().prefetch(auto)\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:03:06.268373Z","iopub.execute_input":"2021-10-27T23:03:06.268661Z","iopub.status.idle":"2021-10-27T23:03:22.705054Z","shell.execute_reply.started":"2021-10-27T23:03:06.26863Z","shell.execute_reply":"2021-10-27T23:03:22.703979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# strategyスコープ内でモデルをインスタンス化することで、TPU上にモデルが作られる\nwith strategy.scope():\n    model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n    model.compile(\n        optimizer=AdamWeightDecay(learning_rate=1e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=tf.metrics.SparseCategoricalAccuracy(),\n    )\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:03:29.008451Z","iopub.execute_input":"2021-10-27T23:03:29.008923Z","iopub.status.idle":"2021-10-27T23:04:22.223873Z","shell.execute_reply.started":"2021-10-27T23:03:29.008866Z","shell.execute_reply":"2021-10-27T23:04:22.222966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# モデル保存用のコールバック。val_lossが最小のときにモデルの重みを保存する\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    f'watson-{model_name}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min'\n)\n\n# 学習を早期終了させるためのコールバック。val_lossが2度連続して改善されなかった場合に学習を終了させる\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')\n\n# モデルの学習\nmodel.fit(\n    train_dataset,\n    steps_per_epoch=len(train) // batch_size,\n    epochs=epochs,\n    validation_data=valid_dataset,\n    callbacks = [checkpoint, early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:04:26.405653Z","iopub.execute_input":"2021-10-27T23:04:26.405925Z","iopub.status.idle":"2021-10-27T23:06:25.03619Z","shell.execute_reply.started":"2021-10-27T23:04:26.405896Z","shell.execute_reply":"2021-10-27T23:06:25.035118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:09:02.749068Z","iopub.execute_input":"2021-10-27T23:09:02.749532Z","iopub.status.idle":"2021-10-27T23:09:03.593455Z","shell.execute_reply.started":"2021-10-27T23:09:02.749492Z","shell.execute_reply":"2021-10-27T23:09:03.592352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ライブラリのインポート\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:09:08.700273Z","iopub.execute_input":"2021-10-27T23:09:08.700581Z","iopub.status.idle":"2021-10-27T23:09:08.705772Z","shell.execute_reply.started":"2021-10-27T23:09:08.700551Z","shell.execute_reply":"2021-10-27T23:09:08.704733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ハイパーパラメータの定義、トークナイザの初期化\nmodel_name = \"bert-base-multilingual-cased\"\nmax_length = 120\nbatch_size = 16\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# 学習後のモデルの重みの読み込み\nmodel = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n#model.load_weights(\"../input/watson-bert-baseline-training/watson-bert-base-multilingual-cased.h5\")\nmodel.load_weights(\"watson-bert-base-multilingual-cased.h5\")\n\n# テストデータの読み込み\ntest = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:09:33.946769Z","iopub.execute_input":"2021-10-27T23:09:33.947056Z","iopub.status.idle":"2021-10-27T23:09:40.953525Z","shell.execute_reply.started":"2021-10-27T23:09:33.947026Z","shell.execute_reply":"2021-10-27T23:09:40.952631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 前提、仮説のテキストのみを抽出\ntest_text = test[['premise', 'hypothesis']].values.tolist()\n\n# トークナイズ + インデキシング\ntest_encoded = tokenizer.batch_encode_plus(test_text, padding=True, max_length=120, truncation=True)\n\n# TensorFlowのDatasetに変換\ntest_dataset = (\n    tf.data.Dataset.from_tensor_slices((dict(test_encoded))).batch(batch_size)\n)\n\n# 推論\ntest_preds = model.predict(test_dataset)\n\n# 推論したデータの確認。logitsがモデルの最終層の出力\ntest_preds","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:09:42.558501Z","iopub.execute_input":"2021-10-27T23:09:42.55884Z","iopub.status.idle":"2021-10-27T23:12:23.091369Z","shell.execute_reply.started":"2021-10-27T23:09:42.558808Z","shell.execute_reply":"2021-10-27T23:12:23.089947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 提出用ファイルの作成\nsubmission = pd.read_csv(\"../input/contradictory-my-dear-watson/sample_submission.csv\")\nsubmission['prediction'] = test_preds[\"logits\"].argmax(axis=1)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:12:26.915007Z","iopub.execute_input":"2021-10-27T23:12:26.915346Z","iopub.status.idle":"2021-10-27T23:12:26.973385Z","shell.execute_reply.started":"2021-10-27T23:12:26.915314Z","shell.execute_reply":"2021-10-27T23:12:26.97269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:12:34.232717Z","iopub.execute_input":"2021-10-27T23:12:34.233437Z","iopub.status.idle":"2021-10-27T23:12:35.07575Z","shell.execute_reply.started":"2021-10-27T23:12:34.233399Z","shell.execute_reply":"2021-10-27T23:12:35.074638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}