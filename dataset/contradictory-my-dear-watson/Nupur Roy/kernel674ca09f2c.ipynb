{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **1. Introduction**"},{"metadata":{},"cell_type":"markdown","source":"**The Challenge:**\n\nIf you have two sentences, there are three ways they could be related: \n\n* one could entail the other, one could contradict the other, or they could be unrelated. \n\n* Natural Language Inferencing (NLI) is a popular NLP problem that involves determining how pairs of sentences (consisting of a premise and a hypothesis) are related.\n\n* The given task here, is to create an NLI model that assigns labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses. Also, the hypothesis and premise are in multiple languages.\n\n\n**The Approach for solving the Problem:**\n\n**Goal:** As per the competition our goal is to predict whether a given hypothesis is related to its premise by contradiction, entailment, or whether neither of those is true (neutral).\nFor each sample in the test set, you must predict a 0, 1, or 2 value for the variable.\nThose values map to the logical condition as:\n0 == entailment\n1 == neutral\n2 == contradiction\n\nTo achieve this goal we will be following the below steps:\n\n* Exploratory Data Analysis (EDA) will be performed on the given datasets to understand the pattern in the data and to gain more insights into what the data looks like.\n\n* Generally, as per any given project we consider the following EDA steps:\n\n    • Previewing the data – which consists of loading and checking out the datasets.\n    \n    • Checking out the total number of entries and the shape of the datasets consisting of given number of columns and their types.\n    \n    • To check if the datasets consists of any null values and duplicate entries.\n    \n    • Plotting the distribution of the data. Which consists of numeric and categorical data.\n    \n    • Visualizing this distribution using seaborn, matplotlib, ggplot, boxplot and other visualization techniques suitable for this data.\n    \n    • We can visualize the word count using histograms.\n    \n    • Create our own Graphs for the visualization of the language distributions and the data label distribution.\n    \nThere will be some experimental steps which will be done as part of this project as we will be using the TensorFlow for the distribution strategy. Tensorflow provides us the Api’s to use them to distribute training across multiple GPUs or TPUs. As it provides multiple distribution strategies as:\n\n    • Mirrored Strategy\n    • TPU Strategy\n    • MultiWorkerMirrored Strategy\n    • CentralStorage Strategy\n    • ParameterServer Strategy\n    \nWe will be using the TPU Strategy for our project. As the GPUs and TPUs can radically reduce the time required to execute a single training step. Achieving peak performance requires an efficient input pipeline that delivers data for the next step before the current step has finished. \n\n   * For this we will be building flexible and efficient input pipelines using TensorFlow (tf.data).\n\n   * Scaling the data as batch size.\n\n   * We will be pre-processing it to the data before we use it for the transformers. Where we will be using the AutoTokenizer and later feed it to the model.\n\n   * Encoding the data.\n\n   * Since, we have both the train and test set given we will be using the train dataset for training the models by using the Train-test split.\n\nThere will be two-way approach for the modelling here, where we will be experimenting with a pre-defined model to check and validate the performance of the models.\n\nFor the pre-defined models, we will be using:\n\n   * KFold which is one of the models from sklearn.\n    \n   * Bidirectional Encoder Representations [BERT] model - technique for NLP pre-training.\n    \nAs BERT has different models under it, we will be considering: XLM-RoBERTa, DistilBERT for our project.\n\n• Create predictions to store them as the final submission.csv\n\n• The accuracy metrics will be used to score the models."},{"metadata":{},"cell_type":"markdown","source":"**Description of the Datasets:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\nfrom sklearn import ensemble, metrics, model_selection\nimport os\n\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n#!pip install transformers\nimport transformers\nfrom transformers import BertTokenizer,AutoTokenizer, TFAutoModel,BertForSequenceClassification, TFBertModel\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\nfrom transformers import AdamW\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n#!pip install googletrans\n#from googletrans import Translator\nimport copy\nimport copy\nfrom sklearn.model_selection import train_test_split\n\n\nos.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence the warning:wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TensorFlow:**\n\nTensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks.[4] It is used for both research and production at Google\n\n**Tensor processing unit (TPU):**\n\nIn May 2016, Google announced its Tensor processing unit (TPU), an application-specific integrated circuit (ASIC, a hardware chip) built specifically for machine learning and tailored for TensorFlow. A TPU is a programmable AI accelerator designed to provide high throughput of low-precision arithmetic (e.g., 8-bit), and oriented toward using or running models rather than training them. Google announced they had been running TPUs inside their data centers for more than a year, and had found them to deliver an order of magnitude better-optimized performance per watt for machine learning.\n"},{"metadata":{},"cell_type":"markdown","source":"TRAIN DATA:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is very straight forward here, where the premise, hypothesis and the class(label) tells us the relation between these attributes i.e. if the two attributes are entailment or contradiction or neutral and returns us any one of these label. So, the model takes two inputs i.e. the two sentences from the two attributes(premise & hypothesis) and returns one of the classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"a = train_data.shape\n\nprint(\"The shape of train the data is:\",a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the attributes are\",train_data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The train data consists of 12,120 instances and 6 attributes.\n\nThe attributes are: \n\n    'id'\n    'premise'\n    'hypothesis'\n    'lang_abv'\n    'language'\n    'label'"},{"metadata":{},"cell_type":"markdown","source":"The .info() method tells us the shape of object types of our data.\n\nBelow is description of the object types of our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TEST DATA:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")\ntest_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = test_data.shape\nprint(\"The shape of the test data is:\",b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The test data consists of 5,195 instances and 5 attributes.\n\nThe attributes are:\n\n    id\n    premise\n    hypothesis\n    lang_abv\n    language\n    \nHere, the target attribute is 'label'."},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at two of the Pairs of sentences from Premise and Hypothesis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['premise'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['hypothesis'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['label'].values[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\nWe know that this is true based on the information in the premise.\nThe above premise and hypothesis are entailing each other and the label shows that. \nSo, this pair is related by entailment."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['premise'].values[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['hypothesis'].values[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['label'].values[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\nWe know that this is false based on the information in the premise.\nThe above premise and hypothesis are contradicting each other and the label shows that. \nSo, this pair is related by contradiction and the label shows that."},{"metadata":{},"cell_type":"markdown","source":"# **2. Explore the Data**"},{"metadata":{},"cell_type":"markdown","source":"**Numeric Columns in the data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = train_data._get_numeric_data().columns\nprint(\"The numeric columns in the train data are:\",num_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Catogrical Columns in the data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat = train_data[train_data.columns.difference(num_cols)]\nprint(\"The catrgorical columns in the train data are:\",df_cat.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualization of the languages given in the data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"value = train_data.language.values\nvalue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = train_data['language'].unique()\nprint(\"The unique languages in the dataset are:\",t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tl = train_data.language.nunique()\nprint(\"The total number of languages present in the data are:\",tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v = train_data.language.value_counts()\nv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize=(15,6))\nsns.countplot(x=\"language\", data=train_data, palette=\"Set2\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Percentage Disribution of all the languages:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels, frequencies = np.unique(value, return_counts = True)\nplt.figure(figsize = (20,10))\nplt.pie(frequencies,labels = labels, autopct = '%.1f%%')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n1. From the above two distributions we can see that English is the most dominating language in the given dataset which is consisting of 56.7%.\n\n2. And the rest of the languages are more or less equally distributed."},{"metadata":{},"cell_type":"markdown","source":"**Comparing the Languages Distribution in both Train and Test data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\n\nplt.subplot(1,2,1)\nplt.title('Train data language distribution')\nsns.countplot(data = train_data, x = 'language', order = v.index)\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nplt.title('Test data laguage distribution')\nsns.countplot(data = test_data, x = 'language', order = test_data['language'].value_counts().index)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\nFrom the above plots we can see that the language distribution in both train and test data are equal."},{"metadata":{},"cell_type":"markdown","source":"**Visualization of the Labels in the Data:**\n\n* Here the target Variable is the \"Label\" attribute."},{"metadata":{"trusted":true},"cell_type":"code","source":"value_label = train_data.label.values\nvalue_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v_label = pd.DataFrame()\nv_label['Type'] = train_data.label.value_counts().index\nv_label['Count'] = train_data.label.value_counts().values\nv_label['Type']=v_label['Type'].replace(0,'Entailment')\nv_label['Type']=v_label['Type'].replace(1,'Neutral')\nv_label['Type']=v_label['Type'].replace(2,'Contradiction')\nv_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.hist(bins=50, figsize=(8,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize=(10,5))\nsns.countplot(x=\"Type\", data=v_label)\nplt.title(\"Distribution of the lable types\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels, frequencies = np.unique(v_label['Type'], return_counts = True)\nplt.figure(figsize = (10,10))\nplt.pie(frequencies,labels = labels, autopct = '%.1f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n    There are total of 12120 instances of the data, which contains 6 attributes/features\n\n    There are total of 4176 records of Entailment\n    \n    There are total of 4064 records of Contradiction\n    \n    There are total of 3880 records of Neutral.\n\n    Therefore, we can say that there is No Class Imblanace for the given data."},{"metadata":{},"cell_type":"markdown","source":"# **3. Prepare the Data**"},{"metadata":{},"cell_type":"markdown","source":"**To check if any null value is present in the data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\nThere are no missing values present in the data."},{"metadata":{},"cell_type":"markdown","source":"**Translating the non-english sentences into english sentences by using Googletrans:**"},{"metadata":{},"cell_type":"markdown","source":"* Googletrans is a free and unlimited python library that implemented Google Translate API. This uses the Google Translate Ajax API to make calls to such methods as detect and translate.\n\nFeatures which we will be using for our project:\n\n    1. Fast and reliable - it uses the same servers that translate.google.com uses\n    \n    2. Auto language detection\n    \n    3. Bulk translations\n    \n* Since, we are having 15 different types of languages, we will use the GoogleTranslator to translate the non-english      langugaes into english language. \n\n* We will create seperate new Translated csv file for both the test and train data and run the below code only once."},{"metadata":{},"cell_type":"markdown","source":"**Translated Train data is as below:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = pd.read_csv('../input/translated-data/translated_train.csv')\n#train.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Translated Test data is as below:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_data.premise[test_data.lang_abv!= 'en']=test_data.premise[test_data.lang_abv!= 'en'].apply(lambda x: Translation(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_data.hypothesis[test_data.lang_abv!= 'en']=test_data.hypothesis[test_data.lang_abv!= 'en'].apply(lambda x: Translation(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_data.to_csv(r'translated_test.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test = pd.read_csv('../input/translated-data/translated_test.csv')\n#test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Configuring the TPU:**"},{"metadata":{},"cell_type":"markdown","source":"* Here, we are going to detect the hardware and return the appropriate distribution strategy.\n\n* A TPU needs to found and setup to work with the models which we will be using in the notebook.\n\n* A strategy needs to be defined regarding how the model will replicated accross the GPU chips on the TPU board and how these replica's model will be merged back together once the training has completed of various models.\n\n* This piece of the code below will define the defualt distribution strategy in Tensorflow and work on finding a TPU or gets CPU and single GPU if its not available and sets it up."},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Shortlist Promising Models**"},{"metadata":{},"cell_type":"markdown","source":"**Models:**\n\n* We have trained computer vision models which have built models with \"backbones\". These are pre-trained models whose weights can be generalised to a new task. Stick some extra layers (the head) to the end of the model to handle the new task and you have a model that benefits from cutting edge trained but that is still built to complete the current task in mind.\n\n* We will be building a model where we will be  using roberta as the backbone and a sofmax layer on the end to apply the correct class (entailment, neutral, contradiction or 0, 1, 2).\n\n* BERT (the original language transformer model that models like roberta are based on) is quite a complex model. \n\n* As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT.The use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train."},{"metadata":{},"cell_type":"markdown","source":"* We have used the transformers concept here where the import of the transformers allows us to use the pre-trained models from \"Hugging Face\". [https://huggingface.co/transformers/index.html]\n\n\n* Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.\n\n\n**Features:**\n\n    High performance on NLU and NLG tasks\n\n    Low barrier to entry for educators and practitioners\n\n    State-of-the-art NLP for everyone:\n\n        Deep learning researchers\n\n        Hands-on practitioners\n\n        AI/ML/NLP teachers and educators\n\n    Lower compute costs, smaller carbon footprint:\n\n        Researchers can share trained models instead of always retraining\n\n        Practitioners can reduce compute time and production costs\n\n        8 architectures with over 30 pretrained models, some in more than 100 languages\n\n    Choose the right framework for every part of a model’s lifetime:\n\n        Train state-of-the-art models in 3 lines of code\n\n        Deep interoperability between TensorFlow 2.0 and PyTorch models\n\n        Move a single model between TF2.0/PyTorch frameworks at will\n\n        Seamlessly pick the right framework for training, evaluation, production"},{"metadata":{},"cell_type":"markdown","source":"# **XLM-RoBERTa Model:**"},{"metadata":{},"cell_type":"markdown","source":"**Overview:**\n\nThe XLM-RoBERTa model was proposed in Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov. It is based on Facebook’s RoBERTa model released in 2019. It is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data.\n\nThe abstract from the paper is the following:\n\nThis paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +13.8% average accuracy on XNLI, +12.3% average F1 score on MLQA, and +2.1% average F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 11.8% in XNLI accuracy for Swahili and 9.2% for Urdu over the previous XLM model. We also present a detailed empirical evaluation of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-Ris very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make XLM-R code, data, and models publicly available.\n\n\nSeveral versions of xlm roberta are available in the Transformers library. Here are two:\n\n* xlm-roberta-base\n\n* xlm-roberta-large\n\nThis is the link to the XLM-RoBERTa paper:\n\nhttps://arxiv.org/pdf/1911.02116.pdf"},{"metadata":{},"cell_type":"markdown","source":"# **XLM-RoBERTa Model: (Large)**"},{"metadata":{},"cell_type":"markdown","source":"**Defining Parameters to be used:**\n\nTo be able to tweak the parameters of the model we have defined them as globals.\n\nThe batch size needed to be multiplied by the number of replicas which is 8. \nThis is simply to make sure each of the eight GPU chips in the TPU uses the specified batch size and not one eighth of that number."},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE\nstep = len(train_data) // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building The Model defination:**"},{"metadata":{},"cell_type":"markdown","source":"* We have used the classmethodfrom_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n\n* Then we load the strategy which we have defined above.\n\n* [cls] token is the sequence approximate i.e. the classifier token is used when doing sequence classification ( classification of the whole sequence instead of per-token classification). It is the first token of the sequence when built with special tokens.\n\n* Then we apply the softmax layer that produces the class and compile the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_defination(strategy,transformer):\n    with strategy.scope():\n        encoder = TFAutoModel.from_pretrained(transformer)\n        input_layer = Input(shape=(30,), dtype=tf.int32, name=\"input_layer\")\n        sequence_output = encoder(input_layer)[0]\n        cls_token = sequence_output[:, 0, :]\n        output_layer = Dense(3, activation='softmax')(cls_token)\n        model = Model(inputs=input_layer, outputs=output_layer)\n        model.compile(\n            Adam(lr=1e-5), \n            loss='sparse_categorical_crossentropy', \n            metrics=['accuracy']\n        )\n        return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* After we have compiled the model above we are going to call the model_defination and load our pre-trained model into the strategy."},{"metadata":{"trusted":true},"cell_type":"code","source":"model=model_defination(strategy,\"jplu/tf-xlm-roberta-large\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below shows us the summary of the Model which we have loaded above in the model defination."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tokenizing: With (xlm-roberta-large)**\n\n* As a Machine Learning model a language model works with numbers, not text. \n\n* We need to be tokenizing them to prepare the sentences for training.\n\n* These tokens are number indexes that represent each of the words. Each model has it's own unique set of tokens."},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('jplu/tf-xlm-roberta-large')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating 3-folds for using in our model:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\n\n# shuffle\ndf = shuffle(train_data)\n\n# initialize kfold\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1024)\n\n# for stratification\ny = df['label']\n\n# Put the folds into a list. This is a list of tuples.\nfold_list = list(kf.split(df, y))\n\ntrain_df_list = []\nval_df_list = []\n\nfor i, fold in enumerate(fold_list):\n\n    # map the train and val index values to dataframe rows\n    df_train = df[df.index.isin(fold[0])]\n    df_val = df[df.index.isin(fold[1])]\n    \n    train_df_list.append(df_train)\n    val_df_list.append(df_val)\n    \n    \n\nprint(len(train_df_list))\nprint(len(val_df_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display one train fold:\n\ndf_train = train_df_list[0]\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display one val fold\n\ndf_val = val_df_list[0]\n\ndf_val.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating the training, validation and test sets:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = df_train[['premise','hypothesis']].values.tolist()\ntest_set = test_data[['premise','hypothesis']].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Encoding the Data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train = tokenizer.batch_encode_plus(train_set, pad_to_max_length=True, max_length=30)\nencoded_test = tokenizer.batch_encode_plus(test_set, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below example shows what the tokenizer has done to the first sentence at \"premise[0]\":"},{"metadata":{},"cell_type":"markdown","source":"**The textual form of the data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.premise.values[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is the few tokens from the above sentence:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(encoded_train.input_ids[0][0:20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below example shows what the tokenizer has done to the first sentence at \"hypothesis[0]\":"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.hypothesis.values[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below are the token for the above sentence:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(encoded_train.input_ids[0][20:32])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So we can see above sentences has been split into an array, where each word is represented by a number index. \n\n* The tokeniser even splits the words themselves up into sub words."},{"metadata":{},"cell_type":"markdown","source":"**Below we are checking the vocab which the tokenizer has tokens defined:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# vocab size\n\ntokenizer.vocab_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the special tokens\n\ntokenizer.special_tokens_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('bos_token_id <s>:', tokenizer.bos_token_id)\nprint('eos_token_id </s>:', tokenizer.eos_token_id)\nprint('sep_token_id </s>:', tokenizer.sep_token_id)\nprint('pad_token_id <pad>:', tokenizer.pad_token_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The token 0 represents \"\\<\\s>\", which represents the start of a sentence.\n\n* When a model has two inputs (like a premise and hypothesis) the transformer will merge the tokens from the two sentences into the one array. \n\n* The \"\\<\\s>\" token is used to denote the end of the the premise and the beginning of the hypothesis."},{"metadata":{},"cell_type":"markdown","source":"**Train and Test Split:**\n\n* Splitting the dataset into respective training and validation set.\n\n* Using the 3-folds which are created above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(0):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_test['input_ids']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pipeline:**\n\n* When we are using the tensorflow and TPUs it is best to build a data pipeline.\n\n* This pipeline is build using tensorflows data api. Which provides a better performance during training.\n\n* In the pipeline we insert the data using the from tensor slices commmand, shuffle it, batch it and prefetch the next batch while the model is training on the current batch."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training the Model: at different Epoch values(3 and 5)**\n\n\nWhere \"Epoch\" is one complete presentation of the whole dataset which is needed to be learned by the machine.\nThe number of epochs represent the hyperparameter of \"Gradient Descent\" which controls the number of complete passes which the machine makes when it is passing through the training dataset.\n\n* Here, we will first find out the best epoch and then run our the next 2 folds on that epoch for this model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3 = model.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=5\nmodel_5 = model.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_5.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_5.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_5.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_5.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_5.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_5.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_5.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_5.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Accuracy -  is calculated on the training data. This tells us the percentage of the instances that are correctly classified.\n\n* Val_accuracy - is calculated on the validation data. This is a measure of how good the predictions are of the model.\n\n* Loss - This represents the training loss which is the average of the losses occuring over every batch of the training data.\n\n* Val_loss - This tells us the loss occuring over every batch of the test data. Which is the unseen data at this point of time.\n"},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* At the start since, the model is changing over the time, the loss over the first batch of the training data of an epoch is generally higher than the last batches of the data.\n\n* We can tell the model is getting trained in a good way when the two losses(loss and the val_loss) are decreasing over each epoch and the two accuracies(accuracy and val_accuracy) are increasing gradually.\n\n* Now if we see the last batch of each epoch at 3 and 5 we can see the following:\n\n    * At epoch=3 loss and val_loss has decreased and accuracy and val_accuracy has increased.\n    \n    * At epoch = 5 loss is decreasing but val_loss is increasing. And accuracy is increasing whereas val_accuracy has reached constant.\n    \n    Hence, we stop at epoch = 5 otherwise the model is getting overfitted."},{"metadata":{},"cell_type":"markdown","source":"**Now we will run the next fold at [1] for epoch = 3 value:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train1 = train_df_list[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set1 = df_train1[['premise','hypothesis']].values.tolist()\ntest_set1 = test_data[['premise','hypothesis']].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train1 = tokenizer.batch_encode_plus(train_set1, pad_to_max_length=True, max_length=30)\nencoded_test1 = tokenizer.batch_encode_plus(test_set1, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(1):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train1['input_ids'], df_train1.label.values, test_size=0.3)\n\nx_test = encoded_test1['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df1 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df1 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df1 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3_1 = model.fit(train_df1,steps_per_epoch=step,validation_data=valid_df1,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_1.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_1.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we will run the next fold at [2] for epoch = 3 value:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train2 = train_df_list[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set2 = df_train2[['premise','hypothesis']].values.tolist()\ntest_set2 = test_data[['premise','hypothesis']].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train2 = tokenizer.batch_encode_plus(train_set2, pad_to_max_length=True, max_length=30)\nencoded_test2 = tokenizer.batch_encode_plus(test_set2, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(2):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train2['input_ids'], df_train2.label.values, test_size=0.3)\n\nx_test = encoded_test2['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df2 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df2 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3_2 = model.fit(train_df2,steps_per_epoch=step,validation_data=valid_df2,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_2.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_2.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Model_name at epoch=3                   |  n-fold      |  mean_loss    | mean_val_loss  | mean_accuracy | mean_val_accuracy |\n ----------------------------------------|--------------|---------------|----------------|---------------|-------------------|\n XLM-RoBERTa Model: (Large)              |   1          | 0.95          | 0.87           |  0.53         |  0.60             |\n XLM-RoBERTa Model: (Large)              |   2          | 0.36          | 0.82           |  0.86         |   0.78            |\n XLM-RoBERTa Model: (Large)              |   3          | 0.22          | 0.49           |  0.92         |  0.87             |"},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing of the model at epoch = 3 for better understanding:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(model_3.history['loss'], label = '0 fold loss')\nplt.plot(model_3.history['val_loss'], label = '0 fold val_loss')\nplt.plot(model_3_1.history['loss'], label = '1 fold loss')\nplt.plot(model_3_1.history['val_loss'], label = '1 fold val_loss')\nplt.plot(model_3_2.history['loss'], label = '2 fold loss')\nplt.plot(model_3_2.history['val_loss'], label = '2 fold val_loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(model_3.history['accuracy'], label = '0 fold accuracy')\nplt.plot(model_3.history['val_accuracy'], label = '0 fold val_accuracy')\nplt.plot(model_3_1.history['accuracy'], label = '1 fold accuracy')\nplt.plot(model_3_1.history['val_accuracy'], label = '1 fold val_accuracy')\nplt.plot(model_3_2.history['accuracy'], label = '2 fold accuracy')\nplt.plot(model_3_2.history['val_accuracy'], label = '2 fold val_accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\n* As per the above visualization graph the model fits good at fold(0) and at epoch = 3 value.\n\n* Hence, we will be considering this value for the XLM-RoBERTa Large model. "},{"metadata":{},"cell_type":"markdown","source":"# **XLM-RoBERTa Model: (BASE)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=model_defination(strategy,\"jplu/tf-xlm-roberta-base\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tokenizing: With (xlm-roberta-base)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer1 = AutoTokenizer.from_pretrained('jplu/tf-xlm-roberta-base')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** For n-fold(0):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train = tokenizer1.batch_encode_plus(train_set, pad_to_max_length=True, max_length=30)\nencoded_test = tokenizer1.batch_encode_plus(test_set, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(0):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_test['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3_b = model1.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_b.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_b.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_b.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_b.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_b.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_b.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_b.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_b.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=5\nmodel_3_b5 = model1.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_b5.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_b5.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_b5.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_b5.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_b5.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_b5.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_b5.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_b5.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* Now if we see the last batch of each epoch at 3 and 5 we can see the following:\n\n    * At epoch=3 loss has decreased and val_loss has decreased and accuracy has increased and val_accuracy has also increased.\n    * At epoch = 5 loss is decreasing and val_loss is increasing. And accuracy is increasing whereas val_accuracy has reached constant.\n    \n    \n Hence, we stop at epoch = 5 otherwise the model is getting overfitted.\n \n Hence, we consider the epoch value as 3."},{"metadata":{},"cell_type":"markdown","source":"*** For n-fold(1):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train1 = tokenizer1.batch_encode_plus(train_set1, pad_to_max_length=True, max_length=30)\nencoded_test1 = tokenizer1.batch_encode_plus(test_set1, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(1):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train1['input_ids'], df_train1.label.values, test_size=0.3)\n\nx_test = encoded_test1['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df1 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df1 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df1 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3_b1 = model1.fit(train_df1,steps_per_epoch=step,validation_data=valid_df1,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_b1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_b1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_b1.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_b1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_b1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_b1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_b1.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_b1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** For n-fold(2):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train2 = tokenizer1.batch_encode_plus(train_set2, pad_to_max_length=True, max_length=30)\nencoded_test2 = tokenizer1.batch_encode_plus(test_set2, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(2):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train2['input_ids'], df_train2.label.values, test_size=0.3)\n\nx_test = encoded_test2['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df2 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df2 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3_b2 = model1.fit(train_df2,steps_per_epoch=step,validation_data=valid_df2,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_b2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_b2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_b2.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_b2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_b2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_b2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_b2.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_b2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing of the model at epoch = 3 for better understanding:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(model_3_b.history['loss'], label = '0 fold loss')\nplt.plot(model_3_b.history['val_loss'], label = '0 fold val_loss')\nplt.plot(model_3_b1.history['loss'], label = '1 fold loss')\nplt.plot(model_3_b1.history['val_loss'], label = '1 fold val_loss')\nplt.plot(model_3_b2.history['loss'], label = '2 fold loss')\nplt.plot(model_3_b2.history['val_loss'], label = '2 fold val_loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(model_3_b.history['accuracy'], label = '0 fold accuracy')\nplt.plot(model_3_b.history['val_accuracy'], label = '0 fold val_accuracy')\nplt.plot(model_3_b1.history['accuracy'], label = '1 fold accuracy')\nplt.plot(model_3_b1.history['val_accuracy'], label = '1 fold val_accuracy')\nplt.plot(model_3_b2.history['accuracy'], label = '2 fold accuracy')\nplt.plot(model_3_b2.history['val_accuracy'], label = '2 fold val_accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* As per the above visualization graph the model fits good at fold(0) and at epoch = 3 value.\n\n* Hence, we will be considering this value for the XLM-RoBERTa Base model."},{"metadata":{},"cell_type":"markdown","source":" Model_name at epoch=3                   |  n-fold      |  mean_loss    | mean_val_loss  | mean_accuracy | mean_val_accuracy |\n ----------------------------------------|--------------|---------------|----------------|---------------|-------------------|\n XLM-RoBERTa Model: (Base)               |   1          | 0.99          | 0.99           |  0.47         |  0.50             |\n XLM-RoBERTa Model: (Base)               |   2          | 0.57          | 0.84           |  0.78         |  0.70             |\n XLM-RoBERTa Model: (Base)               |   3          | 0.35          | 0.61           |  0.87         |  0.82             |"},{"metadata":{},"cell_type":"markdown","source":"# **For Model: xlm-roberta-base, let us experiment with XLMRobertaTokenizer for Tokenizing:**"},{"metadata":{},"cell_type":"markdown","source":"* Since, we have found that at epoch = 3 and at n-fold(0) the model is fitting well we will experiment at these values for the XLMRoberta Tokenizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer3 = XLMRobertaTokenizer.from_pretrained('jplu/tf-xlm-roberta-base')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train = tokenizer3.batch_encode_plus(train_set, pad_to_max_length=True, max_length=30)\nencoded_test = tokenizer3.batch_encode_plus(test_set, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(0):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_test['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_x = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df_x = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df_x = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_3_b_x = model1.fit(train_df_x,steps_per_epoch=step,validation_data=valid_df_x,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_3_b_x.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_3_b_x.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_3_b_x.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_3_b_x.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_3_b_x.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_3_b_x.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_3_b_x.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_3_b_x.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(model_3_b_x.history['loss'], label = '0 fold loss')\nplt.plot(model_3_b_x.history['val_loss'], label = '0 fold val_loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(model_3_b_x.history['accuracy'], label = '0 fold accuracy')\nplt.plot(model_3_b_x.history['val_accuracy'], label = '0 fold val_accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* For Model: xlm-roberta-base, experimenting with XLMRobertaTokenizer has not given any better outcome than the previous models.\n\n* xlm-roberta-base with XLMRobertaTokenizer at epoch = 3 has performed the worst among other xlm-roberta models.\n\n\n\n Model_name at epoch=3                   |  n-fold      |  mean_loss    | mean_val_loss  | mean_accuracy | mean_val_accuracy |\n ----------------------------------------|--------------|---------------|----------------|---------------|-------------------|\n XLM-RoBERTa Model: (Large)              |   1          | 1.03          | 0.97           |  0.48         |  0.52             |\n XLM-RoBERTa Model: (Large)              |   2          | 0.17          | 0.43           |  0.93         |  0.89             |\n XLM-RoBERTa Model: (Large)              |   3          | 0.17          | 0.38           |  0.94         |  0.90             |\n \n \n  Model_name at epoch=3                  |  n-fold      |  mean_loss    | mean_val_loss  | mean_accuracy | mean_val_accuracy |\n ----------------------------------------|--------------|---------------|----------------|---------------|-------------------|\n XLM-RoBERTa Model: (Base)               |   1          | 0.99          | 0.99           |  0.47         |  0.50             |\n XLM-RoBERTa Model: (Base)               |   2          | 0.57          | 0.84           |  0.78         |  0.70             |\n XLM-RoBERTa Model: (Base)               |   3          | 0.35          | 0.61           |  0.87         |  0.82             |\n \n"},{"metadata":{},"cell_type":"markdown","source":"* As we have considered epoch =3 and n-fold(0) as the best values where the model fits perfectly for the XLM-RoBERTa (BASE AND LARGE) models from the above we would consider   XLM-RoBERTa Model-Base model at first fold n-fold(0)."},{"metadata":{},"cell_type":"markdown","source":"# **Implementing Model: distilbert-base-multilingual-cased**"},{"metadata":{},"cell_type":"markdown","source":"**Overview:**\n\nThe DistilBERT model was proposed in the blog post Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT, and the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. DistilBERT is a small, fast, cheap and light Transformer model trained by distilling Bert base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of Bert’s performances as measured on the GLUE language understanding benchmark.\n\n\n* For the above model defination.\n\n* Running it on the train and test data respectively for the 3 different folds."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_b=model_defination(strategy,\"distilbert-base-multilingual-cased\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_b.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizerb = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** At first n-fold(0):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_trainb = tokenizerb.batch_encode_plus(train_set, pad_to_max_length=True, max_length=30)\nencoded_testb = tokenizerb.batch_encode_plus(test_set, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(encoded_trainb['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_testb['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dfb = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_dfb = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_dfb = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=3\nmodelb = model_b.fit(train_dfb,steps_per_epoch=step,validation_data=valid_dfb,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelb.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelb.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelb.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelb.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelb.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelb.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelb.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelb.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=6\nmodelb_1 = model_b.fit(train_dfb,steps_per_epoch=step,validation_data=valid_dfb,epochs=6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualization:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(modelb.history['loss'], label = 'Train_data Loss')\nplt.plot(modelb.history['val_loss'], label = 'test_data loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\n\nplt.subplot(122)\nplt.plot(modelb.history['accuracy'], label = 'Train_data accuracy')\nplt.plot(modelb.history['val_accuracy'], label = 'Validation_data accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(modelb_1.history['loss'], label = 'Train_data Loss')\nplt.plot(modelb_1.history['val_loss'], label = 'test_data loss')\nplt.title(\"Curve at epoch=6\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(modelb_1.history['accuracy'], label = 'Train_data accuracy')\nplt.plot(modelb_1.history['val_accuracy'], label = 'Validation_data accuracy')\nplt.title(\"Curve at epoch=6\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\n* At epoch=6 the model fits badly.\n\n* Hence, we consider at epoch =3 and will further experiment with different parameters below."},{"metadata":{},"cell_type":"markdown","source":"*** At second n-fold(1):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train1 = tokenizerb.batch_encode_plus(train_set1, pad_to_max_length=True, max_length=30)\nencoded_test1 = tokenizerb.batch_encode_plus(test_set1, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(1):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train1['input_ids'], df_train1.label.values, test_size=0.3)\n\nx_test = encoded_test1['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df1 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df1 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df1 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=3\nmodelb_1 = model_b.fit(train_df1,steps_per_epoch=step,validation_data=valid_df1,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelb_1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelb_1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelb_1.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelb_1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelb_1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelb_1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelb_1.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelb_1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** At third n-fold(2):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train2 = tokenizerb.batch_encode_plus(train_set2, pad_to_max_length=True, max_length=30)\nencoded_test2 = tokenizerb.batch_encode_plus(test_set2, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(2):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train2['input_ids'], df_train2.label.values, test_size=0.3)\n\nx_test = encoded_test2['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df2 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df2 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=3\nmodelb_2 = model_b.fit(train_df2,steps_per_epoch=step,validation_data=valid_df2,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelb_2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelb_2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelb_2.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelb_2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelb_2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelb_2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelb_2.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelb_2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  Model_name at epoch=3                  |  n-fold      |  mean_loss    | mean_val_loss  | mean_accuracy | mean_val_accuracy |\n ----------------------------------------|--------------|---------------|----------------|---------------|-------------------|\n distilbert-base-multilingual-cased               |   1          | 0.94          | 1.08           |  0.52         |  0.46             |\n distilbert-base-multilingual-cased               |   2          | 0.58          | 0.99           |  0.76         |  0.64             |\n distilbert-base-multilingual-cased               |   3          | 0.34          | 0.66           |  0.88         |  0.80             |"},{"metadata":{},"cell_type":"markdown","source":"# **Visualization:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(modelb.history['loss'], label = '0 fold loss')\nplt.plot(modelb.history['val_loss'], label = '0 fold val_loss')\nplt.plot(modelb_1.history['loss'], label = '1 fold loss')\nplt.plot(modelb_1.history['val_loss'], label = '1 fold val_loss')\nplt.plot(modelb_2.history['loss'], label = '2 fold loss')\nplt.plot(modelb_2.history['val_loss'], label = '2 fold val_loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(modelb.history['accuracy'], label = '0 fold accuracy')\nplt.plot(modelb.history['val_accuracy'], label = '0 fold val_accuracy')\nplt.plot(modelb_1.history['accuracy'], label = '1 fold accuracy')\nplt.plot(modelb_1.history['val_accuracy'], label = '1 fold val_accuracy')\nplt.plot(modelb_2.history['accuracy'], label = '2 fold accuracy')\nplt.plot(modelb_2.history['val_accuracy'], label = '2 fold val_accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\n\n* The DistillBERT model is performing well at epoch = 3 and n-fold [0] \n\n* We will be further experimenting and fine tuning this model with different values at the same epoch and n-fold value."},{"metadata":{},"cell_type":"markdown","source":"# **Implementing Model: \"Bert-base-multilingual-cased\"**"},{"metadata":{},"cell_type":"markdown","source":"**Overview:**\n\n* The BERT model was proposed in BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova. It’s a bidirectional transformer pre-trained using a combination of masked language modeling objective and next sentence prediction on a large corpus comprising the Toronto Book Corpus and Wikipedia.\n\n**The abstract from the paper is the following:**\n\n* We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.\n\n* BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\n\n\n* BERT is a model with absolute position embeddings so it’s usually advised to pad the inputs on the right rather than the left.\n\n* BERT was trained with the masked language modeling (MLM) and next sentence prediction (NSP) objectives. It is efficient at predicting masked tokens and at NLU in general, but is not optimal for text generation."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_bert=model_defination(strategy,\"bert-base-multilingual-cased\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_bert.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer_bert = BertTokenizer.from_pretrained('bert-base-multilingual-cased')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** At the first n-fold(0):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train_bert = tokenizer_bert.batch_encode_plus(train_set, pad_to_max_length=True, max_length=30)\nencoded_testb_bert = tokenizer_bert.batch_encode_plus(test_set, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train_bert['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_testb_bert['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_bert = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df_bert = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df_bert = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=2\nmodelbert = model_bert.fit(train_df_bert,steps_per_epoch=step,validation_data=valid_df_bert,epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelbert.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelbert.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelbert.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelbert.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelbert.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelbert.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelbert.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelbert.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=3\nmodelbert_3 = model_bert.fit(train_df_bert,steps_per_epoch=step,validation_data=valid_df_bert,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelbert_3.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelbert_3.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelbert_3.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelbert_3.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelbert_3.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelbert_3.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelbert_3.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelbert_3.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualization:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(modelbert.history['loss'], label = 'Train_data Loss')\nplt.plot(modelbert.history['val_loss'], label = 'test_data loss')\nplt.title(\"Curve at epoch=2\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(modelbert.history['accuracy'], label = 'Train_data accuracy')\nplt.plot(modelbert.history['val_accuracy'], label = 'Validation_data accuracy')\nplt.title(\"Curve at epoch=2\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(modelbert_3.history['loss'], label = 'Train_data Loss')\nplt.plot(modelbert_3.history['val_loss'], label = 'test_data loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(modelbert_3.history['accuracy'], label = 'Train_data accuracy')\nplt.plot(modelbert_3.history['val_accuracy'], label = 'Validation_data accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATION:**\n\n\n* For the model Bert-base-multilingual-cased the model performs well at epoch = 2"},{"metadata":{},"cell_type":"markdown","source":"*** At the second n-fold(1):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train_bert1 = tokenizer_bert.batch_encode_plus(train_set1, pad_to_max_length=True, max_length=30)\nencoded_testb_bert1 = tokenizer_bert.batch_encode_plus(test_set1, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train_bert1['input_ids'], df_train1.label.values, test_size=0.3)\n\nx_test = encoded_testb_bert1['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_bert1 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df_bert1 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df_bert1 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=2\nmodelbert1 = model_bert.fit(train_df_bert1,steps_per_epoch=step,validation_data=valid_df_bert1,epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelbert1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelbert1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelbert1.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelbert1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelbert1.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelbert1.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelbert1.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelbert1.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* At the third n-fold(2):"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train_bert2 = tokenizer_bert.batch_encode_plus(train_set2, pad_to_max_length=True, max_length=30)\nencoded_testb_bert2 = tokenizer_bert.batch_encode_plus(test_set2, pad_to_max_length=True, max_length=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train_bert2['input_ids'], df_train2.label.values, test_size=0.3)\n\nx_test = encoded_testb_bert2['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_bert2 = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df_bert2 = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df_bert2 = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Epochs=2\nmodelbert2 = model_bert.fit(train_df_bert2,steps_per_epoch=step,validation_data=valid_df_bert2,epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(modelbert2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(modelbert2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(modelbert2.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(modelbert2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(modelbert2.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(modelbert2.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(modelbert2.history['accuracy'])))\nprint(\"loss {}\".format(np.std(modelbert2.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  Model_name at epoch=3                  |  n-fold      |  mean_loss    | mean_val_loss  | mean_accuracy | mean_val_accuracy |\n ----------------------------------------|--------------|---------------|----------------|---------------|-------------------|\n Bert-base-multilingual-cased               |   1          | 0.41          | 1.69           |  0.83         |  0.48             |\n Bert-base-multilingual-cased               |   2          | 0.68          | 0.85           |  0.72         |  0.67             |\n Bert-base-multilingual-cased               |   3          | 0.46          | 0.66           |  0.82         |  0.77             |\n "},{"metadata":{},"cell_type":"markdown","source":"# **Visualization:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(modelbert.history['loss'], label = '0 fold loss')\nplt.plot(modelbert.history['val_loss'], label = '0 fold val_loss')\nplt.plot(modelbert1.history['loss'], label = '1 fold loss')\nplt.plot(modelbert1.history['val_loss'], label = '1 fold val_loss')\nplt.plot(modelbert2.history['loss'], label = '2 fold loss')\nplt.plot(modelbert2.history['val_loss'], label = '2 fold val_loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(modelbert.history['accuracy'], label = '0 fold accuracy')\nplt.plot(modelbert.history['val_accuracy'], label = '0 fold val_accuracy')\nplt.plot(modelbert1.history['accuracy'], label = '1 fold accuracy')\nplt.plot(modelbert1.history['val_accuracy'], label = '1 fold val_accuracy')\nplt.plot(modelbert2.history['accuracy'], label = '2 fold accuracy')\nplt.plot(modelbert2.history['val_accuracy'], label = '2 fold val_accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* BERT model is performing good at epoch =2 and at the first n-fold(0).\n\n* We will further fine tune the parameter and do the experiments at first n-fold(0) for all the the below models:\n\n    1. XLM-RoBERTA BASE\n    2. DistillBERT\n    3. BERT"},{"metadata":{},"cell_type":"markdown","source":"# **5. Fine-tune the Models**"},{"metadata":{},"cell_type":"markdown","source":"**1. XLM-RoBERTa BASE:**\n\n****at epoch = 3 and at the fist fold(n-fold[0]):****"},{"metadata":{},"cell_type":"markdown","source":"* Build the model with different parameters for Dense layer and activation along different loss value.\n\n* Changing the MAX_LEN value to 80 to change the input_layer shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_defination(strategy,transformer):\n    with strategy.scope():\n        encoder = TFAutoModel.from_pretrained(transformer)\n        input_layer = Input(shape=(80,), dtype=tf.int32, name=\"input_layer\")\n        sequence_output = encoder(input_layer)[0]\n        cls_token = sequence_output[:, 0, :]\n        output_layer = Dense(1, activation='sigmoid')(cls_token)\n        model = Model(inputs=input_layer, outputs=output_layer)\n        model.compile(\n            Adam(lr=1e-5), \n            loss='binary_crossentropy', \n            metrics=['accuracy']\n        )\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=model_defination(strategy,\"jplu/tf-xlm-roberta-base\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer1 = AutoTokenizer.from_pretrained('jplu/tf-xlm-roberta-base')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train = tokenizer1.batch_encode_plus(train_set, pad_to_max_length=True, max_length=80)\nencoded_test = tokenizer1.batch_encode_plus(test_set, pad_to_max_length=True, max_length=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(0):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_test['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_x = model1.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_x.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_x.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_x.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_x.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_x.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_x.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_x.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_x.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. distilbert-base-multilingual-cased:**\n\n*at epoch = 3 and at the fist fold(n-fold[0]):*"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_d=model_defination(strategy,\"distilbert-base-multilingual-cased\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_d.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer_b = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train = tokenizer_b.batch_encode_plus(train_set, pad_to_max_length=True, max_length=80)\nencoded_test = tokenizer_b.batch_encode_plus(test_set, pad_to_max_length=True, max_length=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(0):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_test['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_d = model_d.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_d.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_d.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_d.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_d.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_d.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_d.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_d.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_d.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Bert-base-multilingual-cased\n\n*at epoch = 3 and at the fist fold(n-fold[0]):*"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_b=model_defination(strategy,\"bert-base-multilingual-cased\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_b.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer_d = BertTokenizer.from_pretrained('bert-base-multilingual-cased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_train = tokenizer_d.batch_encode_plus(train_set, pad_to_max_length=True, max_length=80)\nencoded_test = tokenizer_d.batch_encode_plus(test_set, pad_to_max_length=True, max_length=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the first fold(0):\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(encoded_train['input_ids'], df_train.label.values, test_size=0.3)\n\nx_test = encoded_test['input_ids']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = (tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n\nvalid_df = (tf.data.Dataset.from_tensor_slices((X_valid, Y_valid)).batch(BATCH_SIZE).cache().prefetch(AUTO))\n\ntest_df = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At epochs=3\nmodel_b = model_b.fit(train_df,steps_per_epoch=step,validation_data=valid_df,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.mean(model_b.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.mean(model_b.history['val_loss'])))\nprint(\"accuracy {}\".format(np.mean(model_b.history['accuracy'])))\nprint(\"loss {}\".format(np.mean(model_b.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"validation accuracy {}\".format(np.std(model_b.history['val_accuracy'])))\nprint(\"validation loss {}\".format(np.std(model_b.history['val_loss'])))\nprint(\"accuracy {}\".format(np.std(model_b.history['accuracy'])))\nprint(\"loss {}\".format(np.std(model_b.history['loss'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparing the results of the above Models:**\n\n \n Model_names                             |  epoch value |  loss    | val_loss  | accuracy | val_accuracy |\n ----------------------------------------|--------------|----------|-----------|----------|--------------|\n XLM-RoBERTa Model: (Base)               |   3          | 0.05     |  -0.09      |  0.31    |  0.32        |\n distilbert-base-multilingual-cased      |   3          | -2.07     | -1.87      |  0.36    |  0.35        |     \n Bert-base-multilingual-cased            |   2          |-3.30     | -3.62      |  0.40    |  0.41        |"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(121)\nplt.plot(model_x.history['loss'], label = 'x fold loss')\nplt.plot(model_x.history['val_loss'], label = 'x fold val_loss')\nplt.plot(model_d.history['loss'], label = 'd fold loss')\nplt.plot(model_d.history['val_loss'], label = 'd fold val_loss')\nplt.plot(model_b.history['loss'], label = 'b fold loss')\nplt.plot(model_b.history['val_loss'], label = 'b fold val_loss')\nplt.title(\"Curve at epoch=3\")\nplt.legend()\n\nplt.subplot(122)\nplt.plot(model_x.history['accuracy'], label = 'x fold accuracy')\nplt.plot(model_x.history['val_accuracy'], label = 'x fold val_accuracy')\nplt.plot(model_d.history['accuracy'], label = 'd fold accuracy')\nplt.plot(model_d.history['val_accuracy'], label = 'd fold val_accuracy')\nplt.plot(model_b.history['accuracy'], label = 'b fold accuracy')\nplt.plot(model_b.history['val_accuracy'], label = 'b fold val_accuracy')\nplt.title(\"Curve at epoch=3\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* The best epoch value for the models are 3.\n\n* The models are getting fit at first n-fold without getting overfit.\n\n* DistillBERT model is performing the best among all the other three above models.\n\n* Hence, we will use \"DistillBERT\" model for further prediction of the target value: \"labels\"."},{"metadata":{},"cell_type":"markdown","source":"# **6. Reporting Results**"},{"metadata":{},"cell_type":"markdown","source":"**Generating the submission file as per the competition:**\n\n* From the above we would consider \"DistillBERT\" model here to perform the prediction of the target attribute \"label\" on the test data given in the competition.\n\n* And generate the submission file to submit the predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Given test data:\n\ntest_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the given Submission File from the competition:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/contradictory-my-dear-watson/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction:**\n\n* Making the prediction using the model_d(defined for DistillBERT model) and the test data(test_df) which was sliced using the tensor flow for this model above."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = model_d.predict(test_df, verbose=1)\nsub['prediction'] = test_predict.argmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Top 10 of the submission file generated are as below:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Writing the results to the new submission file generated as below:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('Submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Displaying the submission results from the file written to:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('Submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OBSERVATIONS:**\n\n* The best epoch value for the models are 3.\n\n* The models are getting fit at first n-fold without getting overfit.\n\n* DistillBERT model is performing the best among all the other three above models at the first fold which I have taken into consideration for training of the data during which we have fine tuned the selected models(XLM-RoBERTA, DistillBERT and BERT).\n\n* The main reason for considering the above models are as this is the task where, it is to create an NLI model that assigns labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses. Also, the hypothesis and premise are in multiple languages. \n\n* The chosen models are trained in more than 70 different languages which statisfies our data descriptionand the task.\n\n\n* Based on this we were successfully able to generate the final submission results using the final selected model from our above analysis at different n-folds and epoch values.\n\n**System Limitations:**\n\n* The main limitation of the system here is : we had used the TPU strategy and the TPU utilization quota which was provided by Kaggle for this competition.\n\n* These NLP pre-trained models are quite expensive and they require TPU accelerators to run and train fast.\n\n* The time taken to run these models were more than expected and the TPU distribution strategy had to be sometimes re-run due issues arising when the model could not allocate space.\n\n**Assumptions:**\n\n* The assumption of running the models together on the three n-folds created had not worked out properly and the models were not performing as expected.\n\n* Hence, to perform more analysis the models has been run on each n-fold and at different epoch values.\n"},{"metadata":{},"cell_type":"markdown","source":"# **7. Conclusion**\n\n\nThe expected outcome of the project is to predict whether a given hypothesis is related to its premise by contradiction, entailment, or whether neither of those is true (neutral).\nFor each sample in the test set, you must predict a 0, 1, or 2 value for the variable.\nThose values map to the logical condition as:\n0 == entailment\n1 == neutral\n2 == contradiction\n\n* This project will help me in learning and exploring different Feature Engineering Techniques which have been taught in the course. \n\n* Explore the transformations and the scaling techniques being applied in a project.\n\n* Apart from that the skills and knowledge which I will be getting to learn and enhance from this project will be:\n\nNatural Language Processing related features:\n\n• Natural language toolkit (NLTK) is the most popular library for natural language processing (NLP). The use of NLP to develop applications and services that can understand the human language and process them.\n\n• The knowledge which we will be exploring under NLP will be : using fastText library for efficient learning of word representations and sentence classification.\n\n\nTensorFlow related features:\n\n1. Tokenization:\nRepresenting the words in a tokenized way that a computer can process them and train them with a Neural network that can understand their meaning.\n\n2. Sequencing:\nRepresent sentences by a sequence of numbers in the correct order for processing by a neural network to understand or maybe even generate new text.\n\n3. Word Embeddings:\nTo get the meaning of the sentences to number, with numbers being tokens and represented as words is where we will be using the embedding feature.\n\nThe areas where I have learned the lessons are:\n\n• How to use Keras along with TensorFlow for creating Data Input Pipelines for Optimization and Analyzation. Along with how to use accelerators for projects.\n\n• How to use Bidirectional Encoder Representations from Transformers.\n\n• The different pre-trained models that are used by BERT.\n\n• How to use the k-fold technique on TPUs to prevent memory issues.\n\n• How to deal with enhance the performance of models by preventing leakages."},{"metadata":{},"cell_type":"markdown","source":"8. References\nReferences and Citations of the resources used while developing the Project is:\n\nhttps://huggingface.co/transformers/task_summary.html\n\nhttps://huggingface.co/transformers/index.html\n\nhttps://en.wikipedia.org/wiki/TensorFlow\n\nhttps://www.kaggle.com/pradeepmuniasamy/contradictory-my-dear-watson-everything-you-need\n\nhttps://www.kaggle.com/vbookshelf/basics-of-bert-and-xlm-roberta-pytorch\n\nhttps://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert?select=submission.csv\n\nhttps://www.kaggle.com/mattbast/training-transformers-with-tensorflow-and-tpus\n\nhttps://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}