{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Check TPU is available","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import tensorflow as tf\ntry:\n   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n   tpu = None\nif tpu:\n   tf.config.experimental_connect_to_cluster(tpu)\n   tf.tpu.experimental.initialize_tpu_system(tpu)\n   strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n   strategy = tf.distribute.get_strategy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setup Dependencies","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true},"cell_type":"code","source":"!pip install nlp\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly  --apt-packages libomp5 libopenblas-dev","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":false},"cell_type":"code","source":"%%time\n%autosave 60\n\nimport os\nos.environ['XLA_USE_BF16'] = \"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n\nimport gc\ngc.enable()\nimport time\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm \n\nimport nlp\nimport transformers\nfrom transformers import (AdamW, \n                          XLMRobertaTokenizer, \n                          XLMRobertaModel, \n                          get_cosine_schedule_with_warmup)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.distributed import DistributedSampler\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.serialization as xser\nimport torch_xla.version as xv\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint('PYTORCH:', xv.__torch_gitrev__)\nprint('XLA:', xv.__xla_gitrev__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Files","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train = pd.read_csv('../input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('../input/contradictory-my-dear-watson/test.csv')\nsample_submission = pd.read_csv('../input/contradictory-my-dear-watson/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CONFIG","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"TRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nEPOCHS = 4\nMAX_LEN = 80\n# Scale learning rate to 8 TPU's\nLR = 2e-5 * xm.xrt_world_size() \nMETRICS_DEBUG = True\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### External Datasets\n\nHuggingFace [`nlp`](https://huggingface.co/nlp/index.html) library contains datasets and evaluation metrics for natural language processing.\nIt is compatible with NumPy, Pandas, PyTorch and TensorFlow. \n\nWe will be using three external datasets:\n\n1. [XNLI](https://huggingface.co/nlp/viewer/?dataset=xnli) is a subset of a few thousand examples from MNLI which has been translated into a 14 different languages (some low-ish resource). \n2. [Glue](https://huggingface.co/nlp/viewer/?dataset=glue&config=mnli) the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n3. [SNLI](https://huggingface.co/nlp/viewer/?dataset=snli) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).\n\n*Note: Three datasets combined reach more than 100k examples and hence will be difficult to train within the assigned resources. Since this is a multi-lingual based competition we will fetch **100% test, validation data** from XNLI, **25% train data** from Glue/MNLI and **25% train data** from SNLI.*","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"# mnli data\nmnli = nlp.load_dataset(path='glue', name='mnli', split='train[:5%]')\n\n# xnli data\nxnli = nlp.load_dataset(path='xnli')\nxnli = nlp.concatenate_datasets([xnli['test'], xnli['validation']])\n\n# snli data\nsnli = nlp.load_dataset(path='snli', split='train[:5%]')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### External Data Statistics","execution_count":null},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true,"scrolled":false},"cell_type":"code","source":"print(\"#\"*25)\nprint(\"  MNLI\"); print(\"#\"*25)\nprint(\"Shape: \", mnli.shape)\nprint(\"Num of Samples: \", mnli.num_rows)\nprint(\"Num of Columns: \", mnli.num_columns)\nprint(\"Column Names: \", mnli.column_names)\nprint(\"Features: \", mnli.features)\nprint(\"Num of Classes: \", mnli.features['label'].num_classes)\nprint(\"Split: \", mnli.split)\nprint(\"Description: \", mnli.description)\nprint(f\"Labels Count - 0's:{len(mnli.filter(lambda x: x['label']==0))}, 1's:{len(mnli.filter(lambda x: x['label']==1))}, 2's: 0's:{len(mnli.filter(lambda x: x['label']==2))}\")\nprint()\nprint(\"#\"*25)\nprint(\"  XNLI\"); print(\"#\"*25)\nprint(\"Shape: \", xnli.shape)\nprint(\"Num of Samples: \", xnli.num_rows)\nprint(\"Num of Columns: \", xnli.num_columns)\nprint(\"Column Names: \", xnli.column_names)\nprint(\"Features: \", xnli.features)\nprint(\"Split: \", xnli.split)\nprint(\"Description: \", xnli.description)\nprint(f\"Labels Count - 0's:{len(xnli.filter(lambda x: x['label']==0))}, 1's:{len(xnli.filter(lambda x: x['label']==1))}, 2's: 0's:{len(xnli.filter(lambda x: x['label']==2))}\")\nprint()\nprint(\"#\"*25)\nprint(\"  SNLI\"); print(\"#\"*25)\nprint(\"Shape: \", snli.shape)\nprint(\"Num of Samples: \", snli.num_rows)\nprint(\"Num of Columns: \", snli.num_columns)\nprint(\"Column Names: \", snli.column_names)\nprint(\"Features: \", snli.features)\nprint(\"Num of Classes: \", snli.features['label'].num_classes)\nprint(\"Split: \", snli.split)\nprint(\"Description: \", snli.description)\nprint(f\"Labels Count - 0's:{len(snli.filter(lambda x: x['label']==0))}, 1's:{len(snli.filter(lambda x: x['label']==1))}, 2's: 0's:{len(snli.filter(lambda x: x['label']==2))}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Helper Functions","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# encoding\ndef convert_to_features(batch):\n    input_pairs = list(zip(batch['premise'], batch['hypothesis']))\n    encodings = tokenizer.batch_encode_plus(input_pairs, \n                                            add_special_tokens=True, \n                                            pad_to_max_length=True, \n                                            max_length=MAX_LEN, \n                                            truncation=True, \n                                            return_attention_mask=True, \n                                            return_token_type_ids=True)\n    return encodings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# function to preprocess special structure of xnli\ndef preprocess_xnli(example):\n    premise_output = []\n    hypothesis_output = []\n    label_output = []\n    for prem, hyp, lab in zip(example['premise'],  example['hypothesis'], example[\"label\"]):\n        label = lab\n        langs = hyp['language']\n        translations = hyp['translation']\n        hypothesis = {k: v for k, v in zip(langs, translations)}\n        for lang in prem:\n            if lang in hypothesis:\n                premise_output += [prem[lang]]\n                hypothesis_output += [hypothesis[lang]]\n                label_output += [label]\n    return {'premise':premise_output, 'hypothesis':hypothesis_output, 'label':label_output}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Encode Datasets","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"# encode mnli and convert to torch tensor\nmnli_encoded = mnli.map(convert_to_features, batched=True, remove_columns=['idx', 'premise', 'hypothesis'])\nmnli_encoded.set_format(\"torch\", columns=['attention_mask', 'input_ids', 'token_type_ids', 'label'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"# preprocess xnli, encode and convert to torch tensor\nxnli_processed = xnli.map(preprocess_xnli, batched=True)\nxnli_encoded = xnli_processed.map(convert_to_features, batched=True, remove_columns=['premise', 'hypothesis'])\nxnli_encoded.set_format(\"torch\", columns=['attention_mask', 'input_ids', 'token_type_ids', 'label']) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"# encode snli and convert to torch tensor\nsnli_encoded = snli.map(convert_to_features, batched=True, remove_columns=['premise', 'hypothesis'])\nsnli_encoded.set_format(\"torch\", columns=['attention_mask', 'input_ids', 'token_type_ids', 'label']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Encoded Data Statistics","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"print(mnli_encoded.column_names)\nprint(snli_encoded.column_names)\nprint(xnli_encoded.column_names)\n\nprint(mnli_encoded.num_rows)\nprint(snli_encoded.num_rows)\nprint(xnli_encoded.num_rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Competitions Data - Convert & Encode ","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"train_dataset = nlp.load_dataset('csv', data_files=['../input/contradictory-my-dear-watson/train.csv'])['train']\n\nprint(train_dataset.num_rows)\nprint(train_dataset.column_names)\ndrop_columns = train_dataset.column_names[:-1]\n\nencoded_train_dataset = train_dataset.map(convert_to_features, batched=True, remove_columns=drop_columns)\nencoded_train_dataset.set_format(\"torch\", columns=['attention_mask', 'input_ids', 'token_type_ids', 'label']) \nprint(encoded_train_dataset.num_rows)\nprint(encoded_train_dataset.column_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cocatenate and shuffle all datasets","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"train_dataset = nlp.concatenate_datasets([mnli_encoded, \n                                          xnli_encoded, \n                                          snli_encoded,\n                                          encoded_train_dataset\n                                         ])\n\nprint(train_dataset.num_rows)\nprint(train_dataset.column_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"train_dataset.cleanup_cache_files()\ndel mnli, mnli_encoded\ndel xnli, xnli_encoded, xnli_processed\ndel snli, snli_encoded\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset Factory","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, dataset:nlp.arrow_dataset.Dataset):\n        self.dataset = dataset\n        self.ids = self.dataset['input_ids']\n        self.mask = self.dataset['attention_mask']\n        self.type_ids = self.dataset['token_type_ids']\n        self.targets = self.dataset[\"label\"]\n        \n    def __len__(self):\n        return self.dataset.num_rows\n    \n    def __getitem__(self, index):   \n        ids = self.ids[index]\n        mask = self.mask[index]\n        type_ids = self.type_ids[index]\n        targets = self.targets[index]\n        return {\n            'ids':torch.tensor(ids),\n            'mask':torch.tensor(mask),\n            'type_ids':torch.tensor(type_ids),\n            'targets':targets\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Factory","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class XLMRoberta(nn.Module):\n    def __init__(self, num_labels, multisample):\n        super(XLMRoberta, self).__init__()\n        output_hidden_states = False\n        self.num_labels = num_labels\n        self.multisample= multisample\n        self.roberta = XLMRobertaModel.from_pretrained(\"xlm-roberta-large\", \n                                                       output_hidden_states=output_hidden_states, \n                                                       num_labels=1)\n        self.layer_norm = nn.LayerNorm(1024*2)\n        self.dropout = nn.Dropout(p=0.2)\n        self.high_dropout = nn.Dropout(p=0.5)        \n        self.classifier = nn.Linear(1024*2, self.num_labels)\n    \n    def forward(self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None):\n        outputs = self.roberta(input_ids,\n                               attention_mask=attention_mask,\n                               token_type_ids=token_type_ids,\n                               position_ids=position_ids,\n                               head_mask=head_mask,\n                               inputs_embeds=inputs_embeds)\n        average_pool = torch.mean(outputs[0], 1)\n        max_pool, _ = torch.max(outputs[0], 1)\n        concatenate_layer = torch.cat((average_pool, max_pool), 1)\n        normalization = self.layer_norm(concatenate_layer)\n        if self.multisample:\n            # Multisample Dropout\n            logits = torch.mean(\n                torch.stack(\n                    [self.classifier(self.dropout(normalization)) for _ in range(5)],\n                    dim=0,\n                ),\n                dim=0,\n            )\n        else:\n            logits = self.dropout(normalization)\n            logits = self.classifier(logits)       \n        outputs = logits\n        return outputs  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics Factory","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def display(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n\ndef accuracy(output, target, topk=(1,)):\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimizer Factory","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def get_model_optimizer(model):\n    # Differential Learning Rate\n    def is_backbone(name):\n        return \"roberta\" in name\n    \n    optimizer_grouped_parameters = [\n       {'params': [param for name, param in model.named_parameters() if is_backbone(name)], 'lr': LR},\n       {'params': [param for name, param in model.named_parameters() if not is_backbone(name)], 'lr': 1e-3} \n    ]\n    \n    optimizer = AdamW(\n        optimizer_grouped_parameters, lr=LR, weight_decay=1e-2\n    )\n    \n    return optimizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss Factory","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return nn.CrossEntropyLoss()(outputs, targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def train_loop_fn(train_loader, model, optimizer, device, scheduler, epoch=None):\n    # Train\n    batch_time = AverageMeter('Time', ':6.3f')\n    data_time = AverageMeter('Data', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    progress = ProgressMeter(\n        len(train_loader),\n        [batch_time, data_time, losses, top1],\n        prefix=\"[xla:{}]Train:  Epoch: [{}]\".format(xm.get_ordinal(), epoch)\n    )\n    model.train()\n    end = time.time()\n    for i, data in enumerate(train_loader):\n        data_time.update(time.time()-end)\n        ids, mask, type_ids, targets = data[\"input_ids\"], data[\"attention_mask\"], data['token_type_ids'], data[\"label\"]\n        ids = ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        type_ids = type_ids.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n        optimizer.zero_grad()\n        outputs = model(\n            input_ids = ids,\n            attention_mask = mask,\n            token_type_ids = type_ids\n        )\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        xm.optimizer_step(optimizer)\n        loss = loss_fn(outputs, targets)\n        acc1= accuracy(outputs, targets, topk=(1,))\n        losses.update(loss.item(), ids.size(0))\n        top1.update(acc1[0].item(), ids.size(0))\n        scheduler.step()\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if i % 50 == 0:\n            progress.display(i)\n    del loss\n    del outputs\n    del ids\n    del mask\n    del targets\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def eval_loop_fn(validation_loader, model, device):\n    #Validation\n    model.eval()\n    batch_time = AverageMeter('Time', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    learning_rate = AverageMeter('LR',':2.8f')\n    progress = ProgressMeter(\n        len(validation_loader),\n        [batch_time, losses, top1],\n        prefix='[xla:{}]Validation: '.format(xm.get_ordinal()))\n    with torch.no_grad():\n        end = time.time()\n        for i, data in enumerate(validation_loader):\n            ids, mask, type_ids, targets = data[\"input_ids\"], data[\"attention_mask\"], data['token_type_ids'], data[\"label\"]\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            type_ids = type_ids.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n            outputs = model(\n                input_ids = ids,\n                attention_mask = mask,\n                token_type_ids = type_ids\n            )\n            loss = loss_fn(outputs, targets)\n            acc1= accuracy(outputs, targets, topk=(1,))\n            losses.update(loss.item(), ids.size(0))\n            top1.update(acc1[0].item(), ids.size(0))\n            batch_time.update(time.time() - end)\n            end = time.time()\n            if i % 50 == 0:\n                progress.display(i)\n    del loss\n    del outputs\n    del ids\n    del mask\n    del targets\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model and Dataset Config","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"WRAPPED_MODEL = xmp.MpModelWrapper(XLMRoberta(num_labels=3, multisample=False))\n\ndataset = train_dataset.train_test_split(test_size=0.1)\ntrain_dataset = dataset['train']\nvalid_dataset = dataset['test']\ntrain_dataset.set_format(\"torch\", columns=['attention_mask', 'input_ids', 'token_type_ids', 'label']) \nvalid_dataset.set_format(\"torch\", columns=['attention_mask', 'input_ids', 'token_type_ids', 'label']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Run","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def _run():\n    xm.master_print('Starting Run ...')\n    train_sampler = DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False\n    )\n    \n    train_data_loader = DataLoader(\n        train_dataset,\n        batch_size=TRAIN_BATCH_SIZE,\n        sampler=train_sampler,\n        drop_last=True,\n        num_workers=0\n    )\n    xm.master_print('Train Loader Created.')\n    \n    valid_sampler = DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False\n    )\n    \n    valid_data_loader = DataLoader(\n        valid_dataset,\n        batch_size=VALID_BATCH_SIZE,\n        sampler=valid_sampler,\n        drop_last=True,\n        num_workers=0\n    )\n    xm.master_print('Valid Loader Created.')\n    \n    num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE / xm.xrt_world_size())\n    device = xm.xla_device()\n    model = WRAPPED_MODEL.to(device)\n    xm.master_print('Done Model Loading.')\n    optimizer = get_model_optimizer(model)\n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps = 0,\n        num_training_steps = num_train_steps * EPOCHS\n    )\n    xm.master_print(f'Num Train Steps= {num_train_steps}, XRT World Size= {xm.xrt_world_size()}.')\n    \n    for epoch in range(EPOCHS):\n        para_loader = pl.ParallelLoader(train_data_loader, [device])\n        xm.master_print('Parallel Loader Created. Training ...')\n        train_loop_fn(para_loader.per_device_loader(device),\n                      model,  \n                      optimizer, \n                      device, \n                      scheduler, \n                      epoch\n                     )\n        \n        xm.master_print(\"Finished training epoch {}\".format(epoch))\n            \n        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n        xm.master_print('Parallel Loader Created. Validating ...')\n        eval_loop_fn(para_loader.per_device_loader(device), \n                     model,  \n                     device\n                    )\n        \n        # Serialized and Memory Reduced Model Saving\n        if epoch == EPOCHS-1:\n            xm.master_print('Saving Model ..')\n            xm.save(model.state_dict(), \"model.bin\")\n            xm.master_print('Model Saved.')\n            \n    if METRICS_DEBUG:\n      xm.master_print(met.metrics_report(), flush=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"def _mp_fn(rank, flags):\n    # torch.set_default_tensor_type('torch.FloatTensor')\n    _run()\n\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}