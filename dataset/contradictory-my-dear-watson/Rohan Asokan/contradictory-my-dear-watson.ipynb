{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Prepare training and validation sets\nX = train_data.iloc[:,:-1]\ny = train_data.iloc[:,-1]\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.3\n)\n\nprint(X_train)\nprint(X_val)\nprint(y_train)\nprint(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\ntrain_data.groupby([\"language\"]).sum().plot(kind=\"pie\", y=\"label\", figsize=(14, 14), autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a english-base model for tokenization\nfrom keras.preprocessing.text import Tokenizer\n\ncorpus_data = pd.concat([X_train[\"premise\"], X_train[\"hypothesis\"]])\ntokenizer = Tokenizer(lower=True, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(corpus_data)\nword_index = tokenizer.word_index\nprint(len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Parameters\ninput_size = 1000\nnum_words = len(word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n# Largest possible sequence length in training dataset\nmax_train_seq_len = corpus_data.apply(lambda x: len(x)).max()\n\ntrain_premises = tokenizer.texts_to_sequences(X_train[\"premise\"])\ntrain_hypothesis = tokenizer.texts_to_sequences(X_train['hypothesis'])\n\ntrain_premises = pad_sequences(train_premises, padding=\"post\", maxlen=1000)\ntrain_hypothesis = pad_sequences(train_hypothesis, padding=\"post\", maxlen=1000)\n\nval_premises = tokenizer.texts_to_sequences(X_val[\"premise\"])\nval_hypothesis = tokenizer.texts_to_sequences(X_val['hypothesis'])\n\nval_premises = pad_sequences(val_premises, padding=\"post\", maxlen=1000)\nval_hypothesis = pad_sequences(val_hypothesis, padding=\"post\", maxlen=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert y values to categorical\nfrom keras.utils import np_utils\n\ncat_y_train = np_utils.to_categorical(y_train)\ncat_y_val = np_utils.to_categorical(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\npremise_input = keras.Input(\n    shape=(input_size,), name=\"premise\"\n) # Handle premises in a head\nhypothesis_input = keras.Input(\n    shape=(input_size,), name=\"hypothesis\"\n) # Handle hypotheses in a different head\n\nembedding_layer = layers.Embedding(num_words, 64)\npremise_features = embedding_layer(premise_input)\nhypothesis_features = embedding_layer(hypothesis_input)\n\nlstm_layer = layers.LSTM(128)\npremise_features = lstm_layer(premise_features)\nhypothesis_features = lstm_layer(hypothesis_features)\n\nx = layers.concatenate([premise_features, hypothesis_features])\n\nhidden_layer = layers.Dense(64, activation=\"relu\")(x)\nhidden_layer = layers.Dropout(0.2)(hidden_layer)\n\nstatement_class = layers.Dense(3, activation=\"softmax\")(hidden_layer)\n\nmodel = keras.Model(\n    inputs = [premise_input, hypothesis_input],\n    outputs = [statement_class]\n)\n\nkeras.utils.plot_model(model, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=\"adam\",\n    metrics=\"accuracy\"\n)\n\nhistory = model.fit(\n    {\"premise\": train_premises, \"hypothesis\": train_hypothesis},\n    cat_y_train,\n    epochs=10,\n    batch_size=101\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}