{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Task:\n\nWe have two sentences, there are three ways they could be related: \n- one could entail the other (entailment)\n- one could contradict the other (contradiction) or\n- they could be unrelated (neutral)\n\nNatural Language Inferencing (NLI) is a popular NLP problem that involves determining how pairs of sentences (consisting of a premise and a hypothesis) are related. \n\nIn this notebook, Will explore the [Contradictory, My Dear Watson](https://www.kaggle.com/c/contradictory-my-dear-watson/overview) challange.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nimport plotly.express as px\n#px.offline.init_notebook_mode(connected=True)\nfrom IPython.core.display import HTML\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport tensorflow as tf\n\n!pip install googletrans\nfrom googletrans import Translator\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nimport random\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# directory\nDATA_DIR = \"/kaggle/input/contradictory-my-dear-watson\"\n\n# read train and test csv files\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n#print(f\"train data {train_df.shape} test data {test_df.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dataset_size = {\"train set\":train_df.shape[0], \"test set\":test_df.shape[0]}\nfig = px.bar(y = list(dataset_size.keys()), x = list(dataset_size.values()), \n             title=\"Distribution of train and test\", text= list(dataset_size.values()))\nfig.update_layout(\n    xaxis_title=\"No of samples\",\n    yaxis_title=\"Dataset\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We would be ideally spliting the dataset in ratio of 70-30% or 80-20% for train and test split. Likewise, here also we could see 70-30% split for train and test available already.\n\nWe have 17315 samples for train and test. This is descent enough amount of data for any problem. ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# show list of columns available\n\nhtml = '<h3>Available columns in the Training data:</h3></br><center><table style=\"width:50%; border: 1px solid black; \"><tr style=\"border: 1px solid black\"><th style=\"border: 1px solid black\">Column name</th><th style=\"border: 1px solid black\">Desc</th></tr>'\ncols = train_df.columns.tolist()\ncols_desc = [\"A unique identifier\",\n             \"Actual sentence\",\n             \"Hypothesis sentence\",\n             \"Language abbreviation code\",\n             \"Language\",           \n             \"Classification of the relationship between the premise and hypothesis (0 for entailment, 1 for neutral, 2 for contradiction)\"]\ncols_desc = list(zip(cols, cols_desc))\nhtml += \" \".join([f\"<tr style='border: 1px solid black;'><td style='border: 1px solid black'>{col}<td style='border: 1px solid black'>{desc}</td></tr>\" for col, desc in cols_desc])\nhtml += '</table></center>'\ndisplay(HTML(html))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total 7 columns available including with label (target variable). As we could see, the label contains 3 different values that needs to be classified.\n\nHence, the problem type is **Multi-class classification** since it has more than 2 classes.\n\nThe primary input for this challange is:\n- premise (Actual sentence)\n- hypothesis (Hypothesis sentence)\n\nAlso, language code help us to identify what kind of language it contains in our input. Otherise, We would need to identify what kind of language our input contains without this information.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# show list of languages available\n\nhtml = '''<head><style>\ntable, th, td {\n  border: 1px solid black;\n  border-collapse: collapse;\n}\nth, td {\n  padding: 5px;\n  text-align: left;\n}\n</style></head><body><h3>This dataset contains premise-hypothesis pairs in 15 different languages:</h3></br><center><table style=\"width:25%\"><tr><th>Languages</th><th>Languages code</th></tr>\n'''\nlanguage_codes = train_df[[\"language\", \"lang_abv\"]].drop_duplicates().set_index('language').to_dict()[\"lang_abv\"]\n\nhtml += \" \".join([f\"<tr><td>{lang}</td><td>{language_codes[lang]}</td></tr>\" for lang in language_codes])\nhtml += '</table></center></body>'\ndisplay(HTML(html))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Input text contains multiple language. This could be real challanging itself to handle **Multi-lingual** data.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"language_distribution_class = train_df[[\"id\", \"language\",\"label\"]].groupby([\"language\",\"label\"])[\"id\"].count().reset_index().rename(columns={\"id\":\"count\",\"label\":'class'})\nlanguages_count_dict = language_distribution_class.groupby(\"language\")[\"count\"].sum().to_dict()\n# total count of samples for each language\nlanguage_distribution_class[\"total_count\"] = language_distribution_class[\"language\"].map(languages_count_dict)\nlanguage_distribution_class[\"percent\"] = round(language_distribution_class[\"count\"] / language_distribution_class[\"total_count\"], 2)\nlanguage_distribution_class[\"class_count\"] = language_distribution_class[\"class\"].astype(str) + \", \"+ language_distribution_class[\"percent\"].astype(str) + \"%\"\nfig = px.pie(language_distribution_class, values='count', names='language',hover_data=[\"class\"], title='Distribution of language of text')\nfig1 = px.sunburst(language_distribution_class, path=['language', 'class_count'], values='count', hover_data=[\"count\"], title='Distribution of language with labels')\nfig.show()\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is **56.7%** English text available in which **35%, 32% and 33%** data distributed for each label (0,1, and 2).\n\nLikewise, other language text vary from 3.39% to 2.89% distribution. This is highly unbalanced dataset with respect to each language but we would need to check with the distribution of each labels.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"label_distribution = train_df[\"label\"].value_counts() \nlabel_distribution.index = [\"entailment\", \"neutral\", \"contradiction\"]\n\nfig = px.bar(label_distribution, title=\"Label (target variable) distribution\")\nfig.update_layout(\n    xaxis_title=\"Labels\",\n    yaxis_title=\"Frequency\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label distribution almost balanced for each class.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"stopwords = set(STOPWORDS)\n\nurl = \"https://raw.githubusercontent.com/amueller/word_cloud/master/examples/a_new_hope.png\"\nresponse = requests.get(url)\nimg = Image.open(BytesIO(response.content))\n\nwordcloud = WordCloud(stopwords=stopwords, contour_width=3, contour_color='steelblue', background_color=\"white\", max_words=500).generate(\",\".join(train_df[train_df[\"language\"].str.contains(\"English\")][\"premise\"].tolist()))\nmask = np.array(img)\n\nplt.figure(figsize = (20,15))\nplt.imshow(mask, cmap=plt.cm.gray, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"English word distribution\",fontdict={\"fontsize\":20}, pad=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above Word cloud is for English language. If you make an Word cloud with entire corpus we might see other languages frequency would be very less.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The label (target variable) distribution is close to balanced. Based on the distribution of language is highly different than distribution of each class. \n\nHence, we can conclude following observation:\n- Multiclass problem\n    - 3 classes available to classify\n- Multi-lingual\n    - Have 15 different languages\n- Unbalanced with distribution of language\n    - This may cause issue with the lesser vocabulary size in differenct language.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Tranlate Non-english to English for train and test set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![image.png](attachment:image.png)\n\nBasic idea is, we have seen there are 15 different languages available in the training data. Hence, doing the experimentation of translating the non-English to English input.","attachments":{"image.png":{"image/png":"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"}},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate translator\ntranslator = Translator()\n\n# function to translate sentence\ndef translate_sentence(sentence, src_lang):\n    if \"en\" == src_lang:        \n        return sentence\n    \n    src_lang = \"zh-cn\" if \"zh\" in src_lang else src_lang\n    translated_sentence = translator.translate(sentence, src=src_lang, dest=\"en\")    \n    return translated_sentence.text\n\ndef generate_translate_for_other_language():\n    ## translation for training data \n    for index, row in tqdm(train_df.iterrows()): \n        # translate premise sentence train set\n        train_df.loc[index, \"premise_translated\"] = translate_sentence(row['premise'], row[\"lang_abv\"])\n        # translate hypothesis sentence train set\n        train_df.loc[index, \"hypothesis_translated\"] = translate_sentence(row['hypothesis'], row[\"lang_abv\"])\n\n\n    file_name = r'translated_text.csv'\n    ## save translated dataframe\n    train_df.to_csv(file_name, index=False)\n    print(f\"Translated train dataset saved in {file_name} csv file\")\n    ## translation for testing data \n    for index, row in tqdm(test_df.iterrows()): \n        # translate premise sentence train set\n        test_df.loc[index, \"premise_translated\"] = translate_sentence(row['premise'], row[\"lang_abv\"])\n        # translate hypothesis sentence train set\n        test_df.loc[index, \"hypothesis_translated\"] = translate_sentence(row['hypothesis'], row[\"lang_abv\"])\n\n\n    file_name = r'translated_test_dataset.csv'\n    ## save translated dataframe\n    train_df.to_csv(file_name, index=False)\n    print(f\"Translated train dataset saved in {file_name} csv file\")\n\nPROCESSED_OUTPUT_DIR = \"../input/my-dear-watson-translated-text\"\nif os.path.exists(PROCESSED_OUTPUT_DIR):\n    train_df[['premise_translated', 'hypothesis_translated']] = pd.read_csv(os.path.join(PROCESSED_OUTPUT_DIR, \"translated_train_dataset.csv\"))[['premise_translated', 'hypothesis_translated']]\n    test_df[['premise_translated', 'hypothesis_translated']] = pd.read_csv(os.path.join(PROCESSED_OUTPUT_DIR, \"translated_test_dataset.csv\"))[['premise_translated', 'hypothesis_translated']]\n\nprint(train_df[train_df[\"lang_abv\"] != 'en'][['premise_translated', 'hypothesis_translated', 'label']].head(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stratified KFold","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLD = 5\nk_fold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=42)\nfor fold, (train_idx, val_idx) in enumerate(k_fold.split(train_df, y=train_df[\"label\"])):\n    print(fold, train_idx.shape, val_idx.shape)\n    train_df.loc[val_idx,'fold'] = fold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's build Transformer model","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"## setting up TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\nprint('Number of replicas:', strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer, TFBertModel\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Input tokens should be tokenized in [CLS] Hello, my dog is cute [SEP] your dog too. [SEP] format.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_sentence(sentence):\n    tokens = list(tokenizer.tokenize(sentence))\n    tokens.append('[SEP]')\n    return tokenizer.convert_tokens_to_ids(tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_encoder(hypotheses, premises, tokenizer):\n    \n    num_examples = len(hypotheses)\n\n    sentence1 = tf.ragged.constant([\n      encode_sentence(s)\n      for s in np.array(hypotheses)])\n    sentence2 = tf.ragged.constant([\n      encode_sentence(s)\n       for s in np.array(premises)])\n\n    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n    input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n\n    input_mask = tf.ones_like(input_word_ids).to_tensor()\n\n    type_cls = tf.zeros_like(cls)\n    type_s1 = tf.zeros_like(sentence1)\n    type_s2 = tf.ones_like(sentence2)\n    input_type_ids = tf.concat(\n      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n\n    inputs = {\n      'input_word_ids': input_word_ids.to_tensor(),\n      'input_mask': input_mask,\n      'input_type_ids': input_type_ids}\n\n    return inputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augument NLP data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are various ways that you can do word augument.\n- Word embeddings\n- TF-IDF\n- Contextual Word Embeddings\n- Synonym\n\nWill experiment with Synonym augment. Will do substitute the word by **WordNet's synonym**","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install nlpaug\nimport nlpaug.augmenter.word as naw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.SynonymAug(aug_src='wordnet')\naugmented_text = aug.augment(train_df['premise_translated'][0])\nprint(f\"Orginial: \\n{train_df['premise_translated'][0]}\\nAugmented Text: \\n{augmented_text}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above is the sample sentence where augmented a word by **Wordnet** synonym.\n\nLet's randomly augment text for **5% of training data** for each fold. This number is randomly taken.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## augment text\ndef agument_text(data_df, col_name):\n    aug = naw.SynonymAug(aug_src='wordnet')\n    \n    for index, row in tqdm(enumerate(data_df[col_name])):\n        data_df.loc[index, col_name] = aug.augment(row)\n    \n    return data_df[col_name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 75\n\ndef build_model():\n    bert_model = TFBertModel.from_pretrained(model_name)\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n    \n    embedding = bert_model([input_word_ids, input_mask, input_type_ids])[0]\n    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n    \n    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stratified K-fold model training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## test set input\ntest_input = bert_encoder(test_df['premise_translated'].values, test_df['hypothesis_translated'].values, tokenizer) \n\n## storing prediction results\ntest_prediction = np.zeros((test_df.shape[0], 3))\n\n## iterate each fold\nfor fold in range(FOLD):\n    train_df_fold = train_df[train_df[\"fold\"] != fold]\n    val_df = train_df[train_df[\"fold\"] == fold]\n    \n    ## agument 5% of training data\n    sample_selection = train_df_fold.sample(frac=0.05).reset_index(drop=True)\n    \n    sample_selection[\"premise_translated\"] = agument_text(sample_selection, \"premise_translated\")\n    sample_selection[\"hypothesis_translated\"] = agument_text(sample_selection, \"hypothesis_translated\")\n    \n    train_df_fold = pd.concat([train_df_fold, sample_selection])\n    train_input = bert_encoder(train_df_fold['premise_translated'].values, train_df_fold['hypothesis_translated'].values, tokenizer) \n    val_input = bert_encoder(val_df['premise_translated'].values, val_df['hypothesis_translated'].values, tokenizer) \n    \n    with strategy.scope():\n        model = build_model()\n        model.fit(train_input, train_df_fold.label.values, epochs = 6, verbose = 1, batch_size = 64, validation_data = val_input)        \n        \n        ## predict for unseen data\n        predictions = model.predict(test_input)\n        \n        test_prediction += predictions \n        \n## take mean of the prediction\ntest_prediction = test_prediction / FOLD\n## take the maximum probability value \ntest_prediction = np.argmax(test_prediction, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submittion of Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"prediction\"] = test_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## submission file\ntest_df[[\"id\", \"prediction\"]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[[\"id\", \"prediction\"]].to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thanks for reading the basic exploration notebook with BERT model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}