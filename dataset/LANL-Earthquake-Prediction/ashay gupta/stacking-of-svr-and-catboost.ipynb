{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.metrics import mean_absolute_error, make_scorer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import BayesianRidge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc8e29ae5a2bc3d59463162138da4ed0e62b88b4"},"cell_type":"code","source":"train=pd.read_csv(\"../input/train.csv\",dtype={\"acoustic_data\": np.int16, \"time_to_failure\": np.float64})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cdf103b3faaf9e6d0e23964c383acaada92b05f"},"cell_type":"code","source":"rows = 150000\nsegments = int(np.floor(train.shape[0] / rows))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb396c13c8d310d22a2caae4578edbdee827ab60"},"cell_type":"code","source":"col_names = ['mean','max','variance','min', 'stdev', 'q1', 'q5', 'q95', 'q99']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf974af2a65da9ff28f7bc35724356edbcfb369f"},"cell_type":"code","source":"X1= pd.DataFrame(index=range(segments), dtype=np.float64, columns=col_names)\nY1 = pd.DataFrame(index=range(segments), dtype=np.float64, columns=['time_to_failure'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f34f6d18b427a26b68d53b417b058bbe249358c7"},"cell_type":"code","source":"for segment in tqdm(range(segments)):\n    seg = train.iloc[segment*rows:segment*rows+rows]\n    x = seg['acoustic_data'].values\n    y = seg['time_to_failure'].values[-1]\n    Y1.loc[segment, 'time_to_failure'] = y\n    X1.loc[segment, 'mean'] = x.mean()\n    X1.loc[segment, 'stdev'] = x.std()\n    X1.loc[segment, 'variance'] = np.var(x)\n    X1.loc[segment, 'max'] = x.max()\n    X1.loc[segment, 'min'] = x.min()\n    X1.loc[segment, 'q1'] = np.quantile(x, 0.01)\n    X1.loc[segment, 'q5'] = np.quantile(x, 0.05)\n    X1.loc[segment, 'q95'] = np.quantile(x, 0.95)\n    X1.loc[segment, 'q99'] = np.quantile(x, 0.99)  \n    z = np.fft.fft(x)\n    realFFT = np.real(z)\n    imagFFT = np.imag(z)\n    X1.loc[segment, 'A0'] = abs(z[0])\n    X1.loc[segment, 'Real_mean'] = realFFT.mean()\n    X1.loc[segment, 'Real_std'] = realFFT.std()\n    X1.loc[segment, 'Real_max'] = realFFT.max()\n    X1.loc[segment, 'Real_min'] = realFFT.min()\n    X1.loc[segment, 'Imag_mean'] = imagFFT.mean()\n    X1.loc[segment, 'Imag_std'] = imagFFT.std()\n    X1.loc[segment, 'Imag_max'] = imagFFT.max()\n    X1.loc[segment, 'Imag_min'] = imagFFT.min()\n    \nX1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"413aaae3c22366b917043dac5f794fd8eb4493b3"},"cell_type":"code","source":"sub=pd.read_csv(\"../input/sample_submission.csv\",index_col='seg_id')\nxtest=pd.DataFrame(columns=X1.columns,dtype=np.float64,index=sub.index)\nxtest.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"601d76537cab60626ae51cf2a86644f70cdde6eb"},"cell_type":"code","source":"for i, seg_id in enumerate(tqdm(xtest.index)):\n    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n    \n    x = pd.Series(seg['acoustic_data'].values)\n    z = np.fft.fft(x)\n    realFFT = np.real(z)\n    imagFFT = np.imag(z)\n    \n    xtest.loc[seg_id, 'mean'] = x.mean()\n    xtest.loc[seg_id, 'stdev'] = x.std()\n    xtest.loc[seg_id, 'variance'] = np.var(x)\n    xtest.loc[seg_id, 'max'] = x.max()\n    xtest.loc[seg_id, 'min'] = x.min()\n    xtest.loc[seg_id, 'q1'] = np.quantile(x, 0.01)\n    xtest.loc[seg_id, 'q5'] = np.quantile(x, 0.05)\n    xtest.loc[seg_id, 'q95'] = np.quantile(x, 0.95)\n    xtest.loc[seg_id, 'q99'] = np.quantile(x, 0.99)\n    xtest.loc[seg_id, 'A0'] = abs(z[0])\n    xtest.loc[seg_id, 'Real_mean'] = realFFT.mean()\n    xtest.loc[seg_id, 'Real_std'] = realFFT.std()\n    xtest.loc[seg_id, 'Real_max'] = realFFT.max()\n    xtest.loc[seg_id, 'Real_min'] = realFFT.min()\n    xtest.loc[seg_id, 'Imag_mean'] = imagFFT.mean()\n    xtest.loc[seg_id, 'Imag_std'] = imagFFT.std()\n    xtest.loc[seg_id, 'Imag_max'] = imagFFT.max()\n    xtest.loc[seg_id, 'Imag_min'] = imagFFT.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64297919017621f6f073447e78512aa35b7a5b6a"},"cell_type":"code","source":"sc=StandardScaler()\nsc.fit(X1)\nscX = pd.DataFrame(sc.transform(X1), columns = X1.columns)\nsctestx = pd.DataFrame(sc.transform(xtest), columns = xtest.columns)\nsctestx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b9196984fccebee8ea292c5fcaeab9f30deedef"},"cell_type":"code","source":"parameters = {'num_leaves': 31,'min_data_in_leaf': 32, \n         'objective':'regression',\n         'max_depth': -1,\n         'learning_rate': 0.001,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.1,\n         \"nthread\": 4,\n         \"verbosity\": -1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f117da27402ed907d02861fb050e35e2d09777e9"},"cell_type":"code","source":"import lightgbm as lgb\nfeatures=scX.columns\nfolds = KFold(n_splits=5, random_state = 10,shuffle = True)\n\noof_clf1 = np.zeros(len(scX))\npred1=np.zeros(len(sctestx))\nfeature_importance_df = pd.DataFrame()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6421670018b2a1eb90d43ba1ba78f56fbccd227"},"cell_type":"code","source":"for fold_, (trn_idx, val_idx) in enumerate(folds.split(scX.values, Y1.values)):\n    print(\"fold n°{}\".format(fold_))\n    trn_data = lgb.Dataset(scX.iloc[trn_idx][features], label=Y1.iloc[trn_idx])\n    val_data = lgb.Dataset(scX.iloc[val_idx][features], label=Y1.iloc[val_idx])\n    num_round = 10000\n    model1=lgb.train(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n    oof_clf1[val_idx] = model1.predict(scX.iloc[val_idx][features], num_iteration=model1.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = model1.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    pred1 += model1.predict(sctestx[features], num_iteration=model1.best_iteration) / folds.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04d9e76680e42b43f7be4fbc4a09d9d6cfed61bf"},"cell_type":"code","source":"print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_clf1, Y1)**0.5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"497344cfa0fb11ae28877ec483287f0f734fb31d"},"cell_type":"code","source":"import xgboost as xgb\n\nxgb_params = {'eta': 0.001, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'alpha':0.1,\n          'objective': 'reg:linear', 'eval_metric': 'mae', 'silent': True, 'random_state':folds}\n\n\nfolds = KFold(n_splits=5, random_state=4520)\noof_xgb = np.zeros(len(scX))\npred2 = np.zeros(len(sctestx))\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(scX.values, Y1.values)):\n    print(\"fold n°{}\".format(fold_ + 1))\n    trn_data = xgb.DMatrix(data=scX.iloc[trn_idx][features], label=Y1.iloc[trn_idx])\n    val_data = xgb.DMatrix(data=scX.iloc[val_idx][features], label=Y1.iloc[val_idx])\n    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n    print(\"-\" * 10 + \"Xgboost \" + str(fold_) + \"-\" * 10)\n    num_round = 11000\n    xgb_model = xgb.train(xgb_params, trn_data, num_round, watchlist, early_stopping_rounds=50, verbose_eval=1000)\n    oof_xgb[val_idx] = xgb_model.predict(xgb.DMatrix(scX.iloc[val_idx][features]), ntree_limit=xgb_model.best_ntree_limit+50)\n\n    pred2 += xgb_model.predict(xgb.DMatrix(sctestx[features]), ntree_limit=xgb_model.best_ntree_limit+50) / folds.n_splits\n    \nnp.save('oof_xgb', oof_xgb)\nnp.save('predictions_xgb', pred2)\nprint(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_xgb, Y1)**0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b5c3e514b4b4291887620b8b3da568994642f6e"},"cell_type":"code","source":"train_stack = np.vstack([oof_clf1, oof_xgb]).transpose()\ntest_stack = np.vstack([pred1,pred2]).transpose()\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=15)\noof_stack = np.zeros(train_stack.shape[0])\nprediction = np.zeros(test_stack.shape[0])\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(scX, Y1)):\n    print(\"fold n°{}\".format(fold_))\n    trn_data, trn_y = train_stack[trn_idx], Y1.iloc[trn_idx].values\n    val_data, val_y = train_stack[val_idx], Y1.iloc[val_idx].values\n\n    print(\"-\" * 10 + \"Ridge Regression\" + str(fold_) + \"-\" * 10)\n    smodel = BayesianRidge()\n    smodel.fit(trn_data, trn_y)\n    \n    oof_stack[val_idx] = smodel.predict(val_data)\n    prediction += smodel.predict(test_stack) / 5\nprint(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_stack, Y1)**0.5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a52167a970222fbd7cff1e3ad88e9c26d7b8a5"},"cell_type":"code","source":"sub['time_to_failure'] = prediction\nsub.to_csv('fianlprediction.csv')\nprint(sub.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}