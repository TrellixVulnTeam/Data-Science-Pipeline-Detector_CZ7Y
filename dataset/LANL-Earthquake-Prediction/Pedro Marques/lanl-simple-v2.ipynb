{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n# Fix seeds\nnp.random.seed(20190411)\ntf.set_random_seed(20190411)\n","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n\nclass DataTrainTestSplit(object):\n    def __init__(self, df, sample_size, split=0.1):\n        n_samples = int(np.floor(df.shape[0] / sample_size))\n        perm = np.random.permutation(n_samples)\n        test_samples = int(np.floor(n_samples * split))\n        self.train_slice = perm[:-test_samples]\n        self.test_slice = perm[-test_samples:]\n    def train(self):\n        return self.train_slice\n    def test(self):\n        return self.test_slice\n        \nclass Generator(keras.utils.Sequence):\n  sample_size = 150_000\n\n  def __init__(self, df, indices, batch_size=32):\n    self.dataframe = df\n    self.indices = indices\n    self.batch_size = batch_size\n\n  def __len__(self):\n    return int((self.indices.shape[0] - 1) / self.batch_size) + 1\n  \n  def __getitem__(self, index: int):\n    s_begin = index * self.batch_size\n    s_end = min(s_begin + self.batch_size, self.indices.shape[0])\n\n    X = np.empty((s_end - s_begin, self.sample_size, 1))\n    y = np.empty((s_end - s_begin))\n    for m in range(s_begin, s_end):\n        begin = self.indices[m] * self.sample_size\n        end = begin + self.sample_size\n        X[m - s_begin, :] = self.dataframe['acoustic_data'].values[begin:end].reshape(self.sample_size, 1)\n        y[m - s_begin] = self.dataframe['time_to_failure'].iloc[end - 1]\n\n    return X, y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, Sequential\n\nsample = Input(shape=(150_000, 1,))\n\nb0_l1 = Conv1D(10, 100, strides=20)(sample)\nb0_l2 = Dense(100, activation='relu')(b0_l1)\nb0_l3 = Conv1D(100, 200, strides=100)(b0_l2)\nb0_l4 = LSTM(100)(b0_l3)\n\nttf = Dense(1)(b0_l4)\nmodel = Model(inputs=sample, outputs=ttf)\nmodel.compile('sgd', 'mean_absolute_error')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"slices = DataTrainTestSplit(df, Generator.sample_size)\n\ncb_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit_generator(Generator(df, slices.train(), batch_size=128), validation_data=Generator(df, slices.test()),\n                              callbacks=[cb_stop],\n                              epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(history.history['loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.plot()\n\nplt.figure()\nplt.plot(history.history['val_loss'])\nplt.title('Validation loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.plot()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id', dtype={'time_to_failure': np.float32})\n# X_test = pd.DataFrame(columns=df.columns, dtype=np.float64, index=submission.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\n\nfor seg_id in tqdm_notebook(submission.index):\n    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n    X = seg['acoustic_data'].values.reshape(1, Generator.sample_size, 1)\n    y = model.predict(X)\n    submission.loc[seg_id]['time_to_failure'] = y\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}