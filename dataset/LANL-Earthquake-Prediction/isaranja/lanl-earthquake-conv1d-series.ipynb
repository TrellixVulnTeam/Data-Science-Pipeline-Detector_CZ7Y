{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\n\nimport os\n\nfrom statistics import mean\n\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nfrom tqdm import tqdm_pandas\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nK.tensorflow_backend._get_available_gpus()","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"['/job:localhost/replica:0/task:0/device:GPU:0']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import backend as K\nfrom keras.models import Sequential\n\nfrom keras.layers import Conv1D,MaxPooling1D,GlobalAveragePooling1D,Flatten,AveragePooling1D\nfrom keras.layers.core import Dense, Dropout\nfrom keras.optimizers import Adam","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv1D(filters=4 , kernel_size=16, strides=8, activation='relu', input_shape=(150000, 2)))\nmodel.add(Conv1D(filters=4, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(3))\n\nmodel.add(Conv1D(filters=8, kernel_size=8, activation='relu'))\nmodel.add(Conv1D(filters=8, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(3))\n\nmodel.add(Conv1D(filters=16, kernel_size=8, activation='relu'))\nmodel.add(Conv1D(filters=16, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(3))\n\nmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\nmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(3))\n\nmodel.add(Flatten())\nmodel.add(Dropout(rate=0.4))\nmodel.add(Dense(1, activation='linear'))\n\nprint(model.summary())","execution_count":4,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_1 (Conv1D)            (None, 18749, 4)          132       \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 18742, 4)          132       \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 6247, 4)           0         \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 6240, 8)           264       \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 6233, 8)           520       \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 2077, 8)           0         \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 2070, 16)          1040      \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 2063, 16)          2064      \n_________________________________________________________________\nmax_pooling1d_3 (MaxPooling1 (None, 687, 16)           0         \n_________________________________________________________________\nconv1d_7 (Conv1D)            (None, 680, 32)           4128      \n_________________________________________________________________\nconv1d_8 (Conv1D)            (None, 673, 32)           8224      \n_________________________________________________________________\nmax_pooling1d_4 (MaxPooling1 (None, 224, 32)           0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 7168)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 7168)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 7169      \n=================================================================\nTotal params: 23,673\nTrainable params: 23,673\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mean_absolute_error',optimizer='adam')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling the acousting signals\n\ndef prepareAd(x):\n    x = np.sign(x)*np.log(1 + np.abs(x))/8.7\n    #x = np.sign(x)*np.log(1 + np.sqrt(np.abs(x)))/4.4\n    return x","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTrainBatch(dfl):\n    batch_size = 1024\n    \n    x = np.empty([batch_size,150000,2])\n    y = np.empty([batch_size,1])\n    \n    for i,rn in enumerate(np.random.randint(dfl.shape[0]-150000, size=batch_size)):\n        df = dfl.loc[rn:rn+149999,:]\n        x[i,:,:] = df.loc[:,['acoustic_data_p','acoustic_data_n']].values\n        y[i] = df.time_to_failure.values[-1]\n\n    return(x,y)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"srows = [5656574,50085878,104677356,138772453,187641820,218652630,245829585,307838917,\n 338276287,375377848,419368880,461811623,495800225,528777115,585568144]\n\nnrows = [44429304,54591478,34095097,48869367,31010810,27176955,62009332,30437370,\n         37101561,43991032,42442743,33988602,32976890,56791029,36417529]\n\nloss = []\nval_loss = [] \n\nfor epoch in range(10):\n    for i, (s,n) in enumerate(zip(srows,nrows)):\n        print('epoch : ' , epoch,'\\t file chunck :',i, end = '\\t')\n\n        train_df = pd.read_csv(\"../input/train.csv\",\n                           skiprows = s,\n                           nrows = n,\n                          )\n        train_df.columns = ['acoustic_data','time_to_failure']\n\n        print('  max_time_to_failure : ',np.round(train_df.time_to_failure.values[0],2) , end = '\\t')\n\n        # scaling\n        train_df.acoustic_data = prepareAd(train_df.acoustic_data.values)\n        train_df.time_to_failure = train_df.time_to_failure\n\n        # two series\n        train_df['acoustic_data_p'] = np.where(train_df['acoustic_data']>=0, np.abs(train_df['acoustic_data']), 0)\n        train_df['acoustic_data_n'] = np.where(train_df['acoustic_data']<0, np.abs(train_df['acoustic_data']), 0)\n\n        x_train,y_train = getTrainBatch(train_df)\n\n        history = model.fit(x_train,\n                         y_train,\n                         batch_size=16,\n                         epochs=10,\n                         validation_split=0.1,\n                         verbose=0)\n        \n        loss = loss + history.history['loss']\n        val_loss = val_loss + history.history['val_loss']\n        \n        print('  loss : ',np.round(mean(loss[-150:]),2), '\\t val_loss : ', np.round(mean(val_loss[-150:]),2))\n        \n        gc.collect()","execution_count":9,"outputs":[{"output_type":"stream","text":"epoch :  0 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.48 \t val_loss :  1.32\nepoch :  0 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.56 \t val_loss :  1.53\nepoch :  0 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.31 \t val_loss :  1.26\nepoch :  0 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.28 \t val_loss :  1.27\nepoch :  0 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.17 \t val_loss :  1.18\nepoch :  0 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.1 \t val_loss :  1.11\nepoch :  0 \t file chunck : 6\t","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-3e96e5269881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         train_df = pd.read_csv(\"../input/train.csv\",\n\u001b[1;32m     15\u001b[0m                            \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                            \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                           )\n\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acoustic_data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time_to_failure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the submission\ndef predictSubmission(seg_id):\n    test_df = pd.read_csv('../input/test/' + seg_id + '.csv')\n    \n    test_df.acoustic_data =prepareAd(test_df.acoustic_data.values) \n\n    # two series\n    test_df['acoustic_data_p'] = np.where(test_df['acoustic_data']>=0, np.abs(test_df['acoustic_data']), 0)\n    test_df['acoustic_data_n'] = np.where(test_df['acoustic_data']<0, np.abs(test_df['acoustic_data']), 0)\n\n    # reshaping\n    x_test = test_df.loc[:,['acoustic_data_p','acoustic_data_n']].values.reshape(-1,150000,2)\n    \n    y = model.predict(x_test)\n    return y[0][0]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm_pandas(tqdm())\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission.loc[:,'time_to_failure']=submission.loc[:,'seg_id'].progress_apply(predictSubmission)","execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37f2801789c74f7683163434cb6f3421"}},"metadata":{}},{"output_type":"stream","text":"\nTqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.describe()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"       time_to_failure\ncount      2624.000000\nmean          2.815842\nstd           2.057844\nmin          -0.884025\n25%           1.139528\n50%           2.301691\n75%           4.441627\nmax           7.371971","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_to_failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2624.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.815842</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.057844</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.884025</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.139528</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.301691</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.441627</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.371971</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.loc[submission.time_to_failure <0,'time_to_failure'] = 0","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission_15.csv',index=False)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission_15.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}