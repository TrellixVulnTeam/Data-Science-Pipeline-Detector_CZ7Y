{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nfrom statistics import mean\n\nimport os\n\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nfrom tqdm import tqdm_pandas\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"step = 100000000\nstop = 600000000\nX = pd.DataFrame(dtype = np.float32,columns = ['mean','std','99quat','50quat','25quat','1quat','time_to_failure'])\nj = 0\nfor i in tqdm(range(0, stop, step)):\n    train_df = pd.read_csv(\"../input/train.csv\",\n                           skiprows = i,\n                           nrows = step,\n                           dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32}\n                          )\n    train_df.columns = ['acoustic_data','time_to_failure']\n    seg_len = 5000\n    segments = int(np.floor(train_df.shape[0] / seg_len))\n    for segment in range(segments):\n        x = train_df.acoustic_data[segment*seg_len:segment*seg_len+seg_len]\n        X.loc[j,'mean'] = np.mean(x)\n        X.loc[j,'std']  = np.std(x)\n        X.loc[j,'99quat'] = np.quantile(x,0.99)\n        X.loc[j,'50quat'] = np.quantile(x,0.5)\n        X.loc[j,'25quat'] = np.quantile(x,0.25)\n        X.loc[j,'1quat'] =  np.quantile(x,0.01)\n        X.loc[j,'time_to_failure'] = train_df.time_to_failure.values[segment*seg_len+seg_len-1]\n        j +=1\n    del train_df\n    gc.collect()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler() \nX.iloc[:,:-1] = scaler.fit_transform(X.iloc[:,:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTrainBatch(dfl,seg_len,batch_size):\n    x = np.empty([batch_size,seg_len,6])\n    y = np.empty([batch_size,1])\n    for i,rn in enumerate(np.random.randint(dfl.shape[0]-seg_len, size=batch_size)):\n        df = dfl.loc[rn:rn+seg_len-1,:]\n        x[i,:,:] = df.iloc[:,:-1]\n        y[i] = df.iloc[-1,-1]\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, CuDNNLSTM\nfrom keras.optimizers import Adam\nfrom keras.losses import mean_squared_error\nfrom keras.callbacks import History","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(CuDNNLSTM(64 ,return_sequences=True ,input_shape=(30, 6)))\nmodel.add(CuDNNLSTM(64,return_sequences=True))\nmodel.add(CuDNNLSTM(64))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(1, activation='linear'))\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = []\nval_loss = []\nfor j in tqdm(range(501)):\n        #print('Generating training batch :',j)\n        x_train,y_train = getTrainBatch(X,30,batch_size=1024)\n        history = model.fit(x_train,\n                            y_train,\n                            batch_size=16,\n                            epochs=10,\n                            validation_split=0.1,\n                            verbose=0)\n        loss = loss + history.history['loss']\n        val_loss = val_loss + history.history['val_loss']\n\n        if (j%10==0):\n            print('loss :',mean(loss[-10:]),' val_loss :',mean(val_loss[-10:]))\n        del x_train, y_train\n        gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the submission\ndef predictSubmission(seg_id):\n    X_test = pd.DataFrame(dtype = np.float32,columns = ['mean','std','99quat','50quat','25quat','1quat'])\n    test_df = pd.read_csv('../input/test/' + seg_id + '.csv')\n    seg_len = 5000\n    segments = int(np.floor(test_df.shape[0] / seg_len))\n    for i,segment in enumerate(range(segments)):\n        x = test_df.acoustic_data[segment*seg_len:segment*seg_len+seg_len]\n        X_test.loc[i,'mean'] = np.mean(x)\n        X_test.loc[i,'std']  = np.std(x)\n        X_test.loc[i,'99quat'] = np.quantile(x,0.99)\n        X_test.loc[i,'50quat'] = np.quantile(x,0.5)\n        X_test.loc[i,'25quat'] = np.quantile(x,0.25)\n        X_test.loc[i,'1quat'] =  np.quantile(x,0.01)\n    y = model.predict(scaler.transform(X_test).reshape(1,30,6))\n    return y[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm_pandas(tqdm())\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission.loc[:,'time_to_failure']=submission.loc[:,'seg_id'].progress_apply(predictSubmission)\nsubmission.to_csv('submission_11.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}