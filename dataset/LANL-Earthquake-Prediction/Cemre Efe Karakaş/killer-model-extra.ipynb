{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\nfrom keras.models import model_from_json\nimport time\nstart_time = time.time()\nkernel_timeout = start_time + 10000\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import random\nimport sys\nimport io\nimport os\nimport glob\nimport IPython\nimport matplotlib.pyplot as plt\nimport gc\nimport keras\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Model, load_model, Sequential\nfrom keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D, Conv2D, Conv3D\nfrom keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_data=False\nsample_per=100\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c75301d09d58cf412d580d789c52c0eef29912"},"cell_type":"code","source":"#this one is high def data\n\n#%%time\nrowcount = 1000000\n    \nif(not sample_data):\n    #kernel supports >6m <60m \n    train = pd.read_csv(\"../input/train.csv\"\n                        ,dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32}\n                        #, nrows=rowcount\n                       ) \n    train.rename({\"acoustic_data\": \"acd\", \"time_to_failure\": \"ttf\"}, axis=\"columns\", inplace=True)    \n    rowcount=int(train.shape[0])\n\nif(sample_data):\n    train = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\n    train.rename({\"acoustic_data\": \"acd\", \"time_to_failure\": \"ttf\"}, axis=\"columns\", inplace=True)    \n    acd_small = train['acd'].values[::sample_per]\n    ttf_small = train['ttf'].values[::sample_per]\n    del train\n    gc.collect()\n    acd=acd_small\n    ttf=ttf_small\n    \n    rowcount=int(train.shape[0]/sample_per)\n    \ngc.collect()\n\n#CHANGE THIS TO ROW BY ROW READING, TO GET ALL THE DATA AT ONCE. USE PYTHON READ CSV\n#https://docs.python.org/2/library/csv.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"post_input_time = time.time()\nprint(\"Read the input in {0:.2f} seconds.\".format(post_input_time-start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#takes the segmented data frame and returns its features\n#data frame should have size 1500\ndef feature_generate(x):\n\n    features = np.c_[x.mean(axis=1), x.min(axis=1), x.max(axis=1), x.std(axis=1)]\n    return (features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(x, n_steps = 100, step_length = 1500):\n    x = np.array(x)\n    temp = x.reshape(n_steps,-1)\n    return np.c_[feature_generate(temp), feature_generate(temp[:, -step_length//10:]),feature_generate(temp[:, -step_length//100:])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = prepare_data(train[0:150000]).shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_generator(data, start_index, end_index, n_features=n_features, batch_size=32, n_steps=100, step_length=1500):\n    \n    assert end_index - n_steps*step_length >= 0\n    \n    while True:\n        rows = np.random.randint(start_index + n_steps * step_length, end_index, size=batch_size)\n        \n        samples = np.zeros((batch_size, n_steps, n_features))\n        targets = np.zeros(batch_size,)\n        \n        for i, row in enumerate(rows):\n            samples[i] = prepare_data(data[row-(n_steps * step_length):row,0])\n          \n            targets[i] = data[row-1,1]\n        targets = np.reshape(targets,(batch_size,1,1))\n        yield samples, targets\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split = train.shape[0]*9//10\ntrain_gen = data_generator(train, start_index=0, end_index = split)\nvalid_gen = data_generator(train, start_index = split+1, end_index = train.shape[0]-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a78d6f076f42f6c8a397455d08b4800d5dc6acad"},"cell_type":"code","source":"def model(input_shape):\n    \n    X_input = Input(shape = input_shape)\n    \n    # Step 1: CONV layer (≈4 lines)\n    X = Conv1D(64, kernel_size=1, strides=1)(X_input)                                 # CONV1D\n    X = BatchNormalization()(X)                                 # Batch normalization\n    X = Activation('relu')(X)                                 # ReLu activation\n    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n\n    # Step 2: First GRU Layer (≈4 lines)\n    X = GRU(units = 64, return_sequences = True)(X) # GRU (use 128 units and return the sequences)\n    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n    X = BatchNormalization()(X)                                 # Batch normalization\n    \n    # Step 3: Second GRU Layer (≈4 lines)\n    X = GRU(units = 64, return_sequences = True)(X)   # GRU (use 128 units and return the sequences)\n    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n    X = BatchNormalization()(X)                                  # Batch normalization\n    X = Dropout(0.8)(X)                                  # dropout (use 0.8)\n    \n    # Step 4: Time-distributed dense layer (≈1 line)\n    X = Dense(1, activation = \"relu\")(X) # time distributed\n    #X = TimeDistributed(Dense(1),activation=\"sigmoid\")(X) # time distributed  (sigmoid)\n    \n    model = Model(inputs = X_input, outputs = X)\n    \n    return model\n\n#sauce: https://github.com/Gurupradeep/deeplearning.ai-Assignments/blob/master/Sequence%20Models/Week3/Trigger%2Bword%2Bdetection%2B-%2Bv1.ipynb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model(input_shape = (None,12))\n\nopt = Adam(lr=0.0006)\nmodel.compile(loss='mae', optimizer=opt, metrics=[\"mae\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"his = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten = lambda l: [item for sublist in l for item in sublist]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath=\"model_checkpointfile.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_mean_absolute_error', verbose=1, save_best_only=False, mode='min')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory = model.fit_generator(train_gen, steps_per_epoch = 1000, epochs =15, callbacks=callbacks_list,validation_data=valid_gen, validation_steps=200) \nhis.append(history.history['val_mean_absolute_error'])\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"his_flattened = flatten(his)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(16,9))\nplt.subplot(1,1,1)\nplt.plot(his_flattened)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}