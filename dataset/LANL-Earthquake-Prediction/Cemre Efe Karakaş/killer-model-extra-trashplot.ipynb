{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\nfrom keras.models import model_from_json\nimport time\nstart_time = time.time()\nkernel_timeout = start_time + 10000\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/killer-model-extra\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import random\nimport sys\nimport io\nimport os\nimport glob\nimport IPython\nimport matplotlib.pyplot as plt\nimport gc\nimport keras\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Model, load_model, Sequential\nfrom keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D, Conv2D, Conv3D\nfrom keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_data=False\nsample_per=100\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c75301d09d58cf412d580d789c52c0eef29912"},"cell_type":"code","source":"#this one is high def data\n\n#%%time\nrowcount = 1000000\n    \nif(not sample_data):\n    #kernel supports >6m <60m \n    train = pd.read_csv(\"../input/LANL-Earthquake-Prediction/train.csv\"\n                        ,dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32}\n                        #, nrows=rowcount\n                       ) \n    train.rename({\"acoustic_data\": \"acd\", \"time_to_failure\": \"ttf\"}, axis=\"columns\", inplace=True)    \n    rowcount=int(train.shape[0])\n\nif(sample_data):\n    train = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\n    train.rename({\"acoustic_data\": \"acd\", \"time_to_failure\": \"ttf\"}, axis=\"columns\", inplace=True)    \n    acd_small = train['acd'].values[::sample_per]\n    ttf_small = train['ttf'].values[::sample_per]\n    del train\n    gc.collect()\n    acd=acd_small\n    ttf=ttf_small\n    \n    rowcount=int(train.shape[0]/sample_per)\n    \ngc.collect()\n\n#CHANGE THIS TO ROW BY ROW READING, TO GET ALL THE DATA AT ONCE. USE PYTHON READ CSV\n#https://docs.python.org/2/library/csv.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"post_input_time = time.time()\nprint(\"Read the input in {0:.2f} seconds.\".format(post_input_time-start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train[\"ttf\"][::150000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#takes the segmented data frame and returns its features\n#data frame should have size 1500\ndef feature_generate(x):\n\n    features = np.c_[x.mean(axis=1), x.min(axis=1), x.max(axis=1), x.std(axis=1)]\n    return (features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(x, n_steps = 100, step_length = 1500):\n    x = np.array(x)\n    temp = x.reshape(n_steps,-1)\n    return np.c_[feature_generate(temp), feature_generate(temp[:, -step_length//10:]),feature_generate(temp[:, -step_length//100:])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#takes the segmented data frame and returns its features\n#data frame should have size 1500\ndef feature_generate_test(x):\n\n    features = np.c_[x.mean(axis=0), x.min(axis=0), x.max(axis=0), x.std(axis=0)]\n    return (features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data_test(x, n_steps = 100, step_length = 1500):\n    x = np.array(x)\n    temp = x.reshape(n_steps,-1)\n    return np.c_[feature_generate_test(temp), feature_generate_test(temp[:, -step_length//10:]),feature_generate_test(temp[:, -step_length//100:])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = prepare_data(train[0:150000]).shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train[]\n#prepare_data(train[0:150000])\nrow=1000\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_generator(data, start_index, end_index, n_features=n_features, batch_size=32, n_steps=100, step_length=1500):\n    \n    assert end_index - n_steps*step_length >= 0\n    \n    while True:\n        rows = np.random.randint(start_index + n_steps * step_length, end_index, size=batch_size)\n        \n        samples = np.zeros((batch_size, n_steps, n_features))\n        targets = np.zeros(batch_size,)\n        \n        for i, row in enumerate(rows):\n            samples[i] = prepare_data(data[row-(n_steps * step_length):row,0])\n          \n            targets[i] = data[row-1,1]\n        targets = np.reshape(targets,(batch_size,1,1))\n        yield samples, targets\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split = train.shape[0]*9//10\ntrain_gen = data_generator(train, start_index=0, end_index = split)\nvalid_gen = data_generator(train, start_index = split+1, end_index = train.shape[0]-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a78d6f076f42f6c8a397455d08b4800d5dc6acad"},"cell_type":"markdown","source":"def model(input_shape):\n    \n    X_input = Input(shape = input_shape)\n    \n    # Step 1: CONV layer (≈4 lines)\n    X = Conv1D(64, kernel_size=1, strides=1)(X_input)                                 # CONV1D\n    X = BatchNormalization()(X)                                 # Batch normalization\n    X = Activation('relu')(X)                                 # ReLu activation\n    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n\n    # Step 2: First GRU Layer (≈4 lines)\n    X = GRU(units = 64, return_sequences = True)(X) # GRU (use 128 units and return the sequences)\n    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n    X = BatchNormalization()(X)                                 # Batch normalization\n    \n    # Step 3: Second GRU Layer (≈4 lines)\n    X = GRU(units = 64, return_sequences = True)(X)   # GRU (use 128 units and return the sequences)\n    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n    X = BatchNormalization()(X)                                  # Batch normalization\n    X = Dropout(0.8)(X)                                  # dropout (use 0.8)\n    \n    # Step 4: Time-distributed dense layer (≈1 line)\n    X = Dense(1, activation = \"relu\")(X) # time distributed\n    #X = TimeDistributed(Dense(1),activation=\"sigmoid\")(X) # time distributed  (sigmoid)\n    \n    model = Model(inputs = X_input, outputs = X)\n    \n    return model\n\n#sauce: https://github.com/Gurupradeep/deeplearning.ai-Assignments/blob/master/Sequence%20Models/Week3/Trigger%2Bword%2Bdetection%2B-%2Bv1.ipynb"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model = model(input_shape = (None,12))\n\nopt = Adam(lr=0.0006)\nmodel.compile(loss='mae', optimizer=opt, metrics=[\"mae\"])"},{"metadata":{"trusted":true},"cell_type":"code","source":"his = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten = lambda l: [item for sublist in l for item in sublist]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(\"../input/killer-model-extra/model9.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath=\"model_checkpointfile9.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_mean_absolute_error', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\nhistory = model.fit_generator(train_gen, steps_per_epoch = 1000, epochs =30, callbacks=callbacks_list,validation_data=valid_gen, validation_steps=200) \nhis.append(history.history['val_mean_absolute_error'])\n   "},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"s=0\ni1=int(s*15e4)\ni2=int(i1+15e4)\nprint(i1,i2)\ntraino=train.values\nnp.array(traino[i1:i2])\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#temptrain=train[\"ttf\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[:,1][:][:].mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = len(train)%15e4\ntemp=prepare_data_test(train[:,1][:-l])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=[]\nn_steps=100\nstepsize=1500\nrow=150000\nsegmentscount=int(len(train)//15e4)\nfor s in range(segmentscount):\n    dat=prepare_data(train[s*(n_steps*stepsize):(s+1)*(n_steps*stepsize),0])\n    datex=np.expand_dims(dat,0)\n    predictions.extend(model.predict(datex))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = np.concatenate(predictions).ravel().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out)\nplt.plot(train[:,1][::1500][:-l])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out[:100000])\nplt.plot(train[:,1][::1500][:-l][:100000])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out[100000:200000])\nplt.plot(train[:,1][::1500][:-l][100000:200000])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out[200000:300000])\nplt.plot(train[:,1][::1500][:-l][200000:300000])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out[300000:400000])\nplt.plot(train[:,1][::1500][:-l][300000:400000])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out[150000:200000])\nplt.plot(train[:,1][::1500][:-l][150000:200000])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\nplt.plot(out[:50000])\nplt.plot(train[:,1][::1500][:-l][:50000])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\noutmean=np.mean(out.reshape(-1, 50), axis=1)\nplt.plot(out[:50000])\nplt.plot(train[:,1][::75000][:-l][:50000])\nplt.show\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=len(train[:,1][::1500])%100\nplt.figure(figsize=(20,6))\noutmean=np.mean(out.reshape(-1, 50), axis=1)\nplt.plot(out)\nplt.plot(train[:,1][::75000][:-l])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model.save(\"model9.h5\")\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"his_flattened = flatten(his)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(16,9))\nplt.subplot(1,1,1)\nplt.plot(his_flattened)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}