{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.csv'deki datayı okur, ilk data tipi acoustic_data, integer, ikincisi time to failure float. \ntrain_data = pd.read_csv('/kaggle/input/LANL-Earthquake-Prediction/train.csv', nrows=6000000, dtype = {'acoustic_data': np.int16, 'time_to_failure': np.float32})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.precision = 15\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize of 1% of dataset (her 100 elemanda bir veri alıyor.)\ntrain_ad_sample_df = train_data['acoustic_data'].values[::100]\ntrain_ttf_sample_df = train_data['time_to_failure'].values[::100]\n\ndef plot_acc_ttf_data(train_ad_sample_df, train_ttf_sample_df, title = \"Acoustic data and time to failure: 1% sampled data\"):\n    fig, ax1 = plt.subplots(figsize=(12, 8))\n    plt.title(title)\n    plt.plot(train_ad_sample_df, color='r')\n    ax1.set_ylabel('acoustic data', color='r')\n    plt.legend(['acoustic data'], loc=(0.01, 0.95))\n    ax2 = ax1.twinx()\n    plt.plot(train_ttf_sample_df, color='b')\n    ax2.set_ylabel('time to failure', color='b')\n    plt.legend(['time to failure'], loc=(0.01, 0.9))\n    plt.grid(True)\n\nplot_acc_ttf_data(train_ad_sample_df, train_ttf_sample_df)\ndel train_ad_sample_df\ndel train_ttf_sample_df\n\n#There is a point before the actual earthquake \n#where there's a spike in acoustic activity seismographic activity.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import\ntrain_data = pd.read_csv('/kaggle/input/LANL-Earthquake-Prediction/train.csv',dtype = {'acoustic_data':np.int16,'time_to_failure':np.float32})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = 150_000\nsegments = int(np.floor(train_data.shape[0] / rows))  #630 milyon / 150000 = 4194\n\nX_train = pd.DataFrame(index = range(segments),dtype = np.float32,columns = ['mean','std','99quat','50quat','25quat','1quat'])\ny_train = pd.DataFrame(index = range(segments),dtype = np.float32,columns = ['time_to_failure'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for segment in tqdm(range(segments)):\n    x = train_data[segment*rows:segment*rows+rows]\n    y = x['time_to_failure'].values[-1]\n    x = x['acoustic_data'].values\n    X_train.loc[segment,'mean'] = np.mean(x)\n    X_train.loc[segment,'std']  = np.std(x)\n    X_train.loc[segment,'99quat'] = np.quantile(x,0.99)\n    X_train.loc[segment,'50quat'] = np.quantile(x,0.5)\n    X_train.loc[segment,'25quat'] = np.quantile(x,0.25)\n    X_train.loc[segment,'1quat'] =  np.quantile(x,0.01)\n    y_train.loc[segment,'time_to_failure'] = y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_scaler = scaler.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.core import Dropout\n\nmodel = Sequential()\nmodel.add(Dense(256, activation=\"relu\", input_shape=(6,)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(96, activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation=\"linear\"))\n\noptimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer=optimizer, loss='mae')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_scaler,y_train.values.flatten(),epochs = 500, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\n\n#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()     #256(neurons in the first layer) * 6(input) + 256 (bias)  for layer1\n                    #256 * 128 + 128(bias) for layer2\n                    #96 * 128 + 96 for layer 3\n                    #1 * 96 + 1 for layer 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_data = pd.read_csv('/kaggle/input/LANL-Earthquake-Prediction/sample_submission.csv',index_col = 'seg_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.DataFrame(columns = X_train.columns,dtype = np.float32,index = sub_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for seq in tqdm(X_test.index):\n    test_data = pd.read_csv('/kaggle/input/LANL-Earthquake-Prediction/test/'+seq+'.csv')     #2624 .csv file and each of them has 150000 segments(row)\n    x = test_data['acoustic_data'].values\n    X_test.loc[seq,'mean'] = np.mean(x)\n    X_test.loc[seq,'std']  = np.std(x)\n    X_test.loc[seq,'99quat'] = np.quantile(x,0.99)\n    X_test.loc[seq,'50quat'] = np.quantile(x,0.5)\n    X_test.loc[seq,'25quat'] = np.quantile(x,0.25)\n    X_test.loc[seq,'1quat'] =  np.quantile(x,0.01)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_scaler = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test_scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_data['time_to_failure'] = pred\nsub_data['seg_id'] = sub_data.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_data.to_csv('sub_earthquake.csv',index = False)\nsub_data.time_to_failure.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv('sub_earthquake.csv', nrows=1000, dtype = {'acoustic_data': np.int16, 'time_to_failure': np.float32})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.plot(kind='hist',color='blue', bins= 100, figsize=(15, 5), alpha=0.5)\nplt.plot(ss['time_to_failure'].values[::100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['time_to_failure'].plot(kind='hist',color='green', bins= 100, figsize=(15, 5), alpha=0.5)\nplt.plot(train_data['time_to_failure'].values[::100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}