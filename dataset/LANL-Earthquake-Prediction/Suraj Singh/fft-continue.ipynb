{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm #Makes iterations look better\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import GradientBoostingRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa59564840025d9eef7b55b97857231d7bc5f0f1"},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv',dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d252360432cb64c46e1d68d267eedd8927e0272"},"cell_type":"code","source":"# Display the head of the dataframe\npd.options.display.precision = 10\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8d0dd7a444b26d922ac5daf33d752ca90bee785"},"cell_type":"code","source":"# Dimensions of the given training data\nprint(\"Rows: {}, Columns: {}\".format(train_data.shape[0],train_data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af4115631fc6ee4654b2913241dc7c1c3807b171"},"cell_type":"code","source":"def features(df):\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0bbaeb057dc6ad5cdab5152f1c14b9c6818a387"},"cell_type":"code","source":"# Create segments of 150000 data points as mentioned by the competition organisers.\nfrom scipy.fftpack import fft\nsegment_size = 150000\nnum_segments = int(np.floor(train_data.shape[0]/segment_size))\nfeatures = []\nbucket_size = 1500\nnum_features = int(np.floor(segment_size/bucket_size));\nfor i in range(num_features):\n    features.append(\"feature\" + str(i+1))\nX_train = pd.DataFrame(index=range(num_segments),columns=features,dtype=np.float64)\ny_train = pd.DataFrame(index=range(num_segments),columns=['time_to_failure'],dtype=np.float64)\n\nfor i in tqdm(range(num_segments)):\n    segment_i = train_data.iloc[i*segment_size:i*segment_size+segment_size]\n    x = segment_i['acoustic_data'].values\n    y = segment_i['time_to_failure'].values[-1]\n    yf = fft(x)\n    for j in range(num_features):\n        bucket = yf[j*bucket_size:min(segment_size, ((j+1)*bucket_size))]\n        bucket = np.abs(bucket)\n        X_train.loc[i, features[j]] = bucket.mean()\n    \n    \n#     X_train.loc[i,'std'] = x.std()\n#     X_train.loc[i,'max'] = x.max()\n#     X_train.loc[i,'min'] = x.min()\n    \n    y_train.loc[i,'time_to_failure'] = y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8916aea4f9637dfab6566209d5db5cb2c1c3e460"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00348088142685ab2aa454e3c3ea53f5c0c40552"},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"445ae0767bf732e68a78fcf44ea138e5339e6aed"},"cell_type":"code","source":"print(\"X_train Shape: {}, y_train Shape: {}\".format(X_train.shape,y_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c2401a33a61c29001511be954dcbebf5aafa06b"},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_train_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcb1d367ae2f881539d1e421a0a60b4ba6de69c8"},"cell_type":"code","source":"model = GradientBoostingRegressor(learning_rate=0.1,n_estimators=200,loss='ls').fit(X_train_scaled,y_train.values.flatten())\ny_predictions = model.predict(X_train_scaled)\ny_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb142cfdada8b6a46e50dc149ed795af9dfc6618"},"cell_type":"code","source":"mean_absolute_error(y_train.values.flatten(),y_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38cb0afe3a149d4d7dd58933bb75a2b4eda02f57"},"cell_type":"code","source":"# Create testing data / handle the testing part\n\nsubmission_files = pd.read_csv('../input/sample_submission.csv',index_col='seg_id')\nsegment_size = 150000\nbucket_size = 1500\nnum_features = int(np.floor(segment_size/bucket_size))\nX_test = pd.DataFrame(columns=X_train.columns,index=submission_files.index,dtype=np.float64)\n\nfor seg_id in tqdm(X_test.index):\n    segment = pd.read_csv('../input/test/'+seg_id+'.csv')\n    x = segment['acoustic_data'].values\n    yf = fft(x)\n    for j in range(num_features):\n        bucket = yf[j*bucket_size:min(segment_size, ((j+1)*bucket_size))]\n        bucket = np.abs(bucket)\n        X_test.loc[seg_id, features[j]] = bucket.mean()\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6efde10174c642371b58404836a281ba09b8064"},"cell_type":"code","source":"X_test_scaled = scaler.transform(X_test)\nX_test_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a94e8e52b7fc3bce961bb3685f06850554903e27"},"cell_type":"code","source":"y_test_predictions = model.predict(X_test_scaled)\nsubmission_files['time_to_failure'] = y_test_predictions\nsubmission_files.to_csv('submission3.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"037a16687b4a1e30ea240c17a5b7b9d992836588"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}