{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Training notebook.\n* You would need to submit result in the separate one.\n* Unfortunately, I can't reproduce my training -> maybe you would be more lucky...\n\n![image.png](attachment:image.png)","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{},"cell_type":"markdown","source":"### imports"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import gc\nimport os\nimport pickle\nimport random\nimport time\nfrom collections import Counter, defaultdict\nfrom operator import itemgetter\nfrom functools import partial\nfrom pathlib import Path\nfrom psutil import cpu_count\n\nimport numpy as np\nimport pandas as pd\n\nimport librosa\nfrom PIL import Image, ImageOps\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import transforms\n\nfrom fastprogress import master_bar, progress_bar","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### utils"},{"metadata":{"trusted":false},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 666\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"N_JOBS = cpu_count()\nos.environ['MKL_NUM_THREADS'] = str(N_JOBS)\nos.environ['OMP_NUM_THREADS'] = str(N_JOBS)\nDataLoader = partial(DataLoader, num_workers=N_JOBS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\ndef _one_sample_positive_class_precisions(scores, truth):\n    \"\"\"Calculate precisions for each true class for a single sample.\n\n    Args:\n      scores: np.array of (num_classes,) giving the individual classifier scores.\n      truth: np.array of (num_classes,) bools indicating which classes are true.\n\n    Returns:\n      pos_class_indices: np.array of indices of the true classes for this sample.\n      pos_class_precisions: np.array of precisions corresponding to each of those\n        classes.\n    \"\"\"\n    num_classes = scores.shape[0]\n    pos_class_indices = np.flatnonzero(truth > 0)\n    # Only calculate precisions if there are some true classes.\n    if not len(pos_class_indices):\n        return pos_class_indices, np.zeros(0)\n    # Retrieval list of classes for this sample.\n    retrieved_classes = np.argsort(scores)[::-1]\n    # class_rankings[top_scoring_class_index] == 0 etc.\n    class_rankings = np.zeros(num_classes, dtype=np.int)\n    class_rankings[retrieved_classes] = range(num_classes)\n    # Which of these is a true label?\n    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n    retrieved_class_true[class_rankings[pos_class_indices]] = True\n    # Num hits for every truncated retrieval list.\n    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n    precision_at_hits = (\n            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n            (1 + class_rankings[pos_class_indices].astype(np.float)))\n    return pos_class_indices, precision_at_hits\n\n\ndef calculate_per_class_lwlrap(truth, scores):\n    \"\"\"Calculate label-weighted label-ranking average precision.\n\n    Arguments:\n      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n        of presence of that class in that sample.\n      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n        test's real-valued score for each class for each sample.\n\n    Returns:\n      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n        class.\n      weight_per_class: np.array of (num_classes,) giving the prior of each\n        class within the truth labels.  Then the overall unbalanced lwlrap is\n        simply np.sum(per_class_lwlrap * weight_per_class)\n    \"\"\"\n    assert truth.shape == scores.shape\n    num_samples, num_classes = scores.shape\n    # Space to store a distinct precision value for each class on each sample.\n    # Only the classes that are true for each sample will be filled in.\n    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n    for sample_num in range(num_samples):\n        pos_class_indices, precision_at_hits = (\n            _one_sample_positive_class_precisions(scores[sample_num, :],\n                                                  truth[sample_num, :]))\n        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n            precision_at_hits)\n    labels_per_class = np.sum(truth > 0, axis=0)\n    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n    # Form average of each column, i.e. all the precisions assigned to labels in\n    # a particular class.\n    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n                        np.maximum(1, labels_per_class))\n    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n    #                = np.sum(per_class_lwlrap * weight_per_class)\n    return per_class_lwlrap, weight_per_class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"dataset_dir = Path('../input/freesound-audio-tagging-2019')\npreprocessed_dir = Path('../input/fat2019_prep_mels1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"csvs = {\n    'train_curated': dataset_dir / 'train_curated.csv',\n    #'train_noisy': dataset_dir / 'train_noisy.csv',\n    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n    'sample_submission': dataset_dir / 'sample_submission.csv',\n}\n\ndataset = {\n    'train_curated': dataset_dir / 'train_curated',\n    'train_noisy': dataset_dir / 'train_noisy',\n    'test': dataset_dir / 'test',\n}\n\nmels = {\n    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_curated = pd.read_csv(csvs['train_curated'])\ntrain_noisy = pd.read_csv(csvs['train_noisy'])\ntrain_df = train_curated #pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n#train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df = pd.read_csv(csvs['sample_submission'])\n#test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"labels = test_df.columns[1:].tolist()\n#labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"num_classes = len(labels)\n#num_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train = np.zeros((len(train_df), num_classes)).astype(int)\nfor i, row in enumerate(train_df['labels'].str.split(',')):\n    for label in row:\n        idx = labels.index(label)\n        y_train[i, idx] = 1\n\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n#     x_train = pickle.load(curated)\n#     x_train.extend(pickle.load(noisy))\nwith open(mels['train_curated'], 'rb') as curated:\n    x_train = pickle.load(curated)\n\nwith open(mels['test'], 'rb') as test:\n    x_test = pickle.load(test)\n    \nlen(x_train), len(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class FATTrainDataset(Dataset):\n    def __init__(self, mels, labels, transforms, crop=True):\n        super().__init__()\n        self.mels = mels\n        self.labels = labels\n        self.transforms = transforms\n        self.crop = crop\n        \n    def __len__(self):\n        return len(self.mels)\n    \n    def __getitem__(self, idx):\n        image = Image.fromarray(self.mels[idx], mode='RGB')      \n\n        if self.crop:\n            time_dim, base_dim = image.size\n            crop = random.randint(0, time_dim - base_dim)\n            image = image.crop([crop, 0, crop + base_dim, base_dim])\n\n        image = self.transforms(image).div_(255)\n        \n        label = self.labels[idx]\n        label = torch.from_numpy(label).float()\n        \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class FATTestDataset(Dataset):\n    def __init__(self, fnames, mels, transforms):\n        super().__init__()\n        self.fnames = fnames\n        self.mels = mels\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        new_idx = idx % len(self.fnames)\n        \n        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n        image = self.transforms(image).div_(255)\n\n        fname = self.fnames[new_idx]\n        \n        return image, fname","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"transforms_dict = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(0.5),\n        transforms.ToTensor(),\n    ]),\n    'test': transforms.Compose([\n        #transforms.RandomHorizontalFlip(0.5),\n        transforms.ToTensor(),\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### model"},{"metadata":{"trusted":false},"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n        self._init_weights()\n        \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.zeros_(m.bias)\n        \n    def forward(self, x):\n        x_conv1 = self.conv1(x)\n        x = self.conv2(x_conv1)\n        x = F.avg_pool2d(x + x_conv1, 2)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv = nn.Sequential(\n            ConvBlock(in_channels=3, out_channels=64),\n            ConvBlock(in_channels=64, out_channels=128),\n            ConvBlock(in_channels=128, out_channels=256),\n            ConvBlock(in_channels=256, out_channels=512),\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(512, 128),\n            nn.PReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.1),\n            nn.Linear(128, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.mean(x, dim=3)\n        x, _ = torch.max(x, dim=2)\n        x = self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Classifier(num_classes=num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_image = Image.fromarray(x_train[0], mode='RGB')\nprint(test_image.size)\ntest_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del test_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import math\nimport torch\nfrom torch.optim import Optimizer\n\n\nclass AdamW(Optimizer):\n    \"\"\"Implements AdamW algorithm.\n\n    It has been proposed in `Fixing Weight Decay Regularization in Adam`_.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n\n    .. Fixing Weight Decay Regularization in Adam:\n    https://arxiv.org/abs/1711.05101\n    \"\"\"\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay)\n        super(AdamW, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError('AdamW does not support sparse gradients, please consider SparseAdam instead')\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    # Exponential moving average of gradient values\n                    state['exp_avg'] = torch.zeros_like(p.data)\n                    # Exponential moving average of squared gradient values\n                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                state['step'] += 1\n\n                # according to the paper, this penalty should come after the bias correction\n                # if group['weight_decay'] != 0:\n                #     grad = grad.add(group['weight_decay'], p.data)\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n                denom = exp_avg_sq.sqrt().add_(group['eps'])\n\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n\n                p.data.addcdiv_(-step_size, exp_avg, denom)\n\n                if group['weight_decay'] != 0:\n                    p.data.add_(-group['weight_decay'], p.data)\n\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(x_trn, x_val, y_trn, y_val, train_transforms, model, num_epochs=100, lr=1e-3, batch_size=71, fine_tune=False, weight_file_name='weight_best.pt'):\n    test_batch_size = 1\n    eta_min = 1e-6\n    t_max = 10\n    mixup_alpha = 1.0\n    \n    num_classes = y_train.shape[1]\n    \n    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms, crop=False)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n\n    criterion = nn.BCEWithLogitsLoss().cuda()\n    optimizer = AdamW(params=model.parameters(), lr=lr, weight_decay=lr/10)\n    if fine_tune:\n        scheduler = ReduceLROnPlateau(optimizer, mode='min')\n    else:\n        scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n    \n\n    best_epoch = -1\n    best_lwlrap = 0.\n\n    for epoch in range(num_epochs):\n        start_time = time.time()\n        model.train()\n        avg_loss = 0.\n\n        for x_batch, y_batch in train_loader:\n            x_batch = x_batch.cuda()\n            y_batch = y_batch.cuda()\n            \n            x_batch, targets_a, targets_b, lam = mixup_data(x_batch, y_batch, mixup_alpha)\n            x_batch, targets_a, targets_b = map(Variable, (x_batch, targets_a, targets_b))\n\n            preds = model(x_batch)\n            loss = mixup_criterion(criterion, preds, targets_a, targets_b, lam)\n            #loss = criterion(preds, y_batch)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            avg_loss += loss.item() / len(train_loader)\n\n        model.eval()\n        valid_preds = np.zeros((len(x_val), num_classes))\n        avg_val_loss = 0.\n\n        for i, (x_batch, y_batch) in enumerate(valid_loader):\n            preds = model(x_batch.cuda()).detach()\n            loss = criterion(preds, y_batch.cuda())\n\n            preds = torch.sigmoid(preds)\n            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n\n            avg_val_loss += loss.item() / len(valid_loader)\n            \n        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n        lwlrap = (score * weight).sum()\n        \n        log_epoch = epoch % 5 == 0\n        if lwlrap > best_lwlrap:\n            log_epoch = True\n            best_epoch = epoch + 1\n            best_lwlrap = lwlrap\n            torch.save(model.state_dict(), weight_file_name)\n            \n        if log_epoch:\n            elapsed = time.time() - start_time\n            print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n            \n        if fine_tune:\n            scheduler.step(avg_val_loss)\n        else:\n            scheduler.step()\n            \n    return {\n        'best_epoch': best_epoch,\n        'best_lwlrap': best_lwlrap,\n        'weight_file_name' : weight_file_name,\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def pick_best_result(result1, result2):\n    if result2['best_lwlrap'] > result1['best_lwlrap']:\n        return result2\n    else:\n        return result1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_loader = DataLoader(FATTestDataset(test_df['fname'], x_test, transforms_dict['test']), batch_size=1, shuffle=False)\n\nkf = KFold(n_splits=5, random_state=SEED, shuffle=True)\npredictions = []\nresults = []\nfor train_index, test_index in kf.split(np.arange(len(train_df))):\n    fold = str(len(predictions) + 1)\n    \n    x_trn = list(itemgetter(*train_index)(x_train))\n    y_trn = np.array(list(itemgetter(*train_index)(y_train)))\n    \n    x_val = list(itemgetter(*test_index)(x_train))\n    y_val = np.array(list(itemgetter(*test_index)(y_train)))\n    \n    model = Classifier(num_classes=num_classes).cuda()\n    result1 = train_model(x_trn, x_val, y_trn, y_val, transforms_dict['train'], model.cuda(), num_epochs=75, batch_size=10, weight_file_name=fold + 'weight_best.pt')\n    print(\"Rough annealing:\")\n    print(result1)\n\n    model = Classifier(num_classes=num_classes)\n    model.load_state_dict(torch.load(result1['weight_file_name']))\n    result2 = train_model(x_trn, x_val, y_trn, y_val, transforms_dict['train'], model.cuda(), num_epochs=35, lr=4e-4, weight_file_name=fold + 'weight_best_tune_stage1.pt')\n    print(\"Fine annealing:\")\n    print(result2)\n\n    best_result = pick_best_result(result1, result2)\n\n    model = Classifier(num_classes=num_classes)\n    model.load_state_dict(torch.load(best_result['weight_file_name']))\n    result3 = train_model(x_trn, x_val, y_trn, y_val, transforms_dict['train'], model.cuda(), lr=5e-5, num_epochs=60, fine_tune=True, weight_file_name=fold + 'weight_best_tune_stage2.pt')\n    print(\"Fine tuning:\")\n    print(result3)\n\n    best_result = pick_best_result(best_result, result3)\n    results.append(best_result)\n    model = Classifier(num_classes=num_classes)\n    model.load_state_dict(torch.load(best_result['weight_file_name']))\n    model.cuda()\n    model.eval()\n    \n    all_outputs = []\n    for images, _ in test_loader:\n        preds = torch.sigmoid(model(images.cuda()).detach())\n        all_outputs.append(preds.cpu().numpy())\n    fold_preds = np.concatenate(all_outputs)\n    predictions.append(fold_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df[labels] = np.mean(np.array(predictions), axis=0)\ntest_df.to_csv('submission_mean.csv', index=False)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### predict"},{"metadata":{"trusted":false},"cell_type":"code","source":"def predict_model(test_fnames, x_test, test_transforms, num_classes, model):\n    batch_size = 1\n\n    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    model.cuda()\n    model.eval()\n\n    all_outputs, all_fnames = [], []\n\n    pb = progress_bar(test_loader)\n    for images, fnames in pb:\n        preds = torch.sigmoid(model(images.cuda()).detach())\n        all_outputs.append(preds.cpu().numpy())\n        all_fnames.extend(fnames)\n\n    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n                              index=all_fnames,\n                              columns=map(str, range(num_classes)))\n    test_preds = test_preds.groupby(level=0).mean()\n\n    return test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def lwlrap_key(result):\n    return result['best_lwlrap']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"best_result = max(results, key=lwlrap_key)\nprint(best_result)\n\nmodel = Classifier(num_classes=num_classes)\nmodel.load_state_dict(torch.load(best_result['weight_file_name']))\nmodel.cuda()\nmodel.eval()\n\ntest_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, model)\ntest_df[labels] = test_preds.values\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}