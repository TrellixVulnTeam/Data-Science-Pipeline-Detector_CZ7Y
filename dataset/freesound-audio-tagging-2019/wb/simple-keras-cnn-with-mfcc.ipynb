{"cells":[{"metadata":{},"cell_type":"markdown","source":"- とりあえず、MFCCをCNNで学習する\n- 教師データへのノイズの追加でデータaugumentation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport librosa\nimport IPython.display as ipd\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(os.listdir(\"../input/train_curated\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_NOISY_PATH = \"../input/train_noisy.csv\"\nTRAIN_CURATED_PATH = \"../input/train_curated.csv\"\nTRAIN_NOISY = \"../input/train_noisy/\"\nTRAIN_CURATED = \"../input/train_curated/\"\nTEST = \"../input/test/\"\nSUB_PATH = \"../input/sample_submission.csv\"\n\ntrain_noisy = pd.read_csv(TRAIN_NOISY_PATH)\ntrain_curated = pd.read_csv(TRAIN_CURATED_PATH)\nsub = pd.read_csv(SUB_PATH)\n\nSAMPLING_RATE = 44100\nMFCC_NUM = 20\nMFCC_MAX_LEN = 2000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_labels = ['Accelerating_and_revving_and_vroom','Accordion','Acoustic_guitar','Applause','Bark','Bass_drum','Bass_guitar','Bathtub_(filling_or_washing)','Bicycle_bell','Burping_and_eructation','Bus','Buzz','Car_passing_by','Cheering','Chewing_and_mastication','Child_speech_and_kid_speaking','Chink_and_clink','Chirp_and_tweet','Church_bell','Clapping','Computer_keyboard','Crackle','Cricket','Crowd','Cupboard_open_or_close','Cutlery_and_silverware','Dishes_and_pots_and_pans','Drawer_open_or_close','Drip','Electric_guitar','Fart','Female_singing','Female_speech_and_woman_speaking','Fill_(with_liquid)','Finger_snapping','Frying_(food)','Gasp','Glockenspiel','Gong','Gurgling','Harmonica','Hi-hat','Hiss','Keys_jangling','Knock','Male_singing','Male_speech_and_man_speaking','Marimba_and_xylophone','Mechanical_fan','Meow','Microwave_oven','Motorcycle','Printer','Purr','Race_car_and_auto_racing','Raindrop','Run','Scissors','Screaming','Shatter','Sigh','Sink_(filling_or_washing)','Skateboard','Slam','Sneeze','Squeak','Stream','Strum','Tap','Tick-tock','Toilet_flush','Traffic_noise_and_roadway_noise','Trickle_and_dribble','Walk_and_footsteps','Water_tap_and_faucet','Waves_and_surf','Whispering','Writing','Yell','Zipper_(clothing)']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_labels(labels):\n    array_lbs = labels.split(\",\")\n    return len(array_lbs)\n\ndef count_target_labels(labels):\n    count = 0\n    array_lbs = labels.split(\",\")\n    for lb in array_lbs:\n        if lb in target_labels:\n            count += 1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_noisy[\"label_count\"] = train_noisy[\"labels\"].apply(count_labels)\ntrain_noisy[\"target_label_count\"] = train_noisy[\"labels\"].apply(count_target_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_noisy.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Count train_noisy:\" + str(train_noisy.shape[0]))\nprint(\"Count records without target label in train_noisy:\" + str(train_noisy.query(\"target_label_count == 0\").shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(TRAIN_NOISY + train_noisy[\"fname\"][8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated[\"label_count\"] = train_curated[\"labels\"].apply(count_labels)\ntrain_curated[\"target_label_count\"] = train_curated[\"labels\"].apply(count_target_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Count train_curated:\" + str(train_curated.shape[0]))\nprint(\"Count records without target label in train_curated:\" + str(train_curated.query(\"target_label_count == 0\").shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(TRAIN_CURATED + train_curated[\"fname\"][8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Count test:\" + str(sub.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(TEST + sub[\"fname\"][4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated.groupby(\"labels\").size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare MFCC data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nimport numpy as np\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test, sr = librosa.load(TRAIN_CURATED + train_curated[\"fname\"][3], sr=SAMPLING_RATE)\n# librosa.feature.mfcc(test, n_mfcc=128, sr=44100).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def wav2mfcc(file_path, max_len=11):\ndef wav2mfcc(wave, max_len=MFCC_MAX_LEN):\n#     mfcc = librosa.feature.mfcc(wave, sr=16000)\n    mfcc = librosa.feature.mfcc(wave, n_mfcc=MFCC_NUM, sr=SAMPLING_RATE)\n\n    # If maximum length exceeds mfcc lengths then pad the remaining ones\n    if (max_len > mfcc.shape[1]):\n        pad_width = max_len - mfcc.shape[1]\n        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n\n    # Else cutoff the remaining parts\n    else:\n        mfcc = mfcc[:, :max_len]\n    \n    return mfcc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_label_num(labels):\n    lbs = labels.split(\",\")\n#     target_lb = \"Accelerating_and_revving_and_vroom\"\n    target_arr = np.zeros(80)\n    for lb in lbs:\n        if(lb in target_labels):\n            i = target_labels.index(lb)\n            target_arr[i] = 1\n            break\n    return target_arr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train_curated"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ny = []\n\ndef append_X_Y(labels, wave):\n    y.append(get_label_num(labels))\n    mfcc = wav2mfcc(wave)\n    X.append(mfcc)\n\nfor index, row in tqdm(train_curated.iterrows()):\n    labels = row[\"labels\"]\n    wave, sr = librosa.load(TRAIN_CURATED + row[\"fname\"], mono=True, sr=44100)\n    wave = wave[::3]\n    \n#     if(len(labels.split(\",\")) == 1):\n    append_X_Y(labels, wave)\n        \n# for index, row in tqdm(train_noisy.iterrows()):\n#     labels = row[\"labels\"]\n#     wave, sr = librosa.load(TRAIN_NOISY + row[\"fname\"], mono=True, sr=None)\n#     wave = wave[::3]\n#     append_X_Y(labels, wave)\n\n# np.save('train_augumented_mfcc_vectors.npy', X)\n# np.save('train_augumented_labels.npy', y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)\nX.shape[0] == len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_hot = to_categorical(y)\ny_hot = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y_hot, test_size= 0.2, random_state=True, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature dimension\nfeature_dim_1 = MFCC_NUM\n# Second dimension of the feature is dim2\nfeature_dim_2 = MFCC_MAX_LEN\nchannel = 1\nepochs = 70\nbatch_size = 100\nverbose = 1\nnum_classes = len(target_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshaping to perform 2D convolution\nX_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\nX_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n\ny_train_hot = y_train\ny_test_hot = y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(num_classes, activation='softmax'))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_model()\n\noptimizer = optimizers.SGD(lr=0.002, decay=1e-6, momentum=0.9, nesterov=True)\n# optimizer = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=optimizer,\n              metrics=['accuracy'])\nmodel.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submittion"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/sample_submission.csv\")\n\nfor index, row in tqdm(sub.iterrows()):\n    wave, sr = librosa.load(TEST + row[\"fname\"], mono=True, sr=None)\n    wave = wave[::2]\n    \n    mfcc = wav2mfcc(wave)\n    X_test = mfcc.reshape(1, feature_dim_1, feature_dim_2, channel)\n    preds = model.predict(X_test)[0]\n    \n    for i, col in enumerate(target_labels):\n        sub.loc[index, col] = preds[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}