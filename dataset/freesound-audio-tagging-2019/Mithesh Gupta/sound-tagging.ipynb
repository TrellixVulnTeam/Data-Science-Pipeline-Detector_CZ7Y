{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport librosa\nimport gc \nimport time \nfrom tqdm import tqdm, tqdm_notebook; tqdm.pandas\n\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf \nfrom keras import backend\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"seed = 1321\nnp.random.seed(seed)\ntf.set_random_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Creating config file "},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated =Path('../input/train_curated.csv')\ndata_test = Path()\ndata_train_noisy = Path('../input/train_noisy.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated = pd.read_csv('../input/train_curated.csv')\ndata_test = pd.read_csv('../input/sample_submission.csv')\ndata_train_noisy = pd.read_csv('../input/train_noisy.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of class in training data\",len(set(data_train_curated.labels)))\nprint(\"Number of class in test data\", len(set(data_test.columns[1:])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_noisy.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_noisy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catagory_train = data_train_curated.groupby(['labels']).count()\ncatagory_train.columns = ['counts']\nprint(len(catagory_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_group = data_train_curated.groupby(['labels']).count()\ncategory_group.columns = ['counts']\nprint(len(category_group))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (28,8))\ntemp = data_train_curated['labels'].value_counts()\nx = temp.index\ny = temp.values\nsns.barplot(x,y)\nplt.xlabel('Catagory',color = 'Red',size =15)\nplt.ylabel('No of sample', color = 'red', size =15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's listen to the audio  "},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as ipd\nsound = ('../input/train_curated/0019ef41.wav')\nipd.Audio(sound)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io import wavfile\nrate, data = wavfile.read(sound)\nplt.plot(data , '-',color ='r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#zooming the wave\nplt.figure(figsize=(10,5))\nplt.plot(data[:300],'.',color ='b');plt.plot(data[:300],'-',color ='r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wave\n\ndata_train_curated['frames'] = data_train_curated['fname'].apply(lambda x: wave.open('../input/train_curated/' + x).getnframes())\ndata_test['frames'] = data_test['fname'].apply(lambda x: wave.open('../input/test/' + x).getnframes())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (18,9))\nplt.hist(bins= 150  , color ='r', x =data_train_curated['frames'], rwidth= 0.6, );\nplt.xlabel('No of frames', color = 'white',size = 20)\nplt.ylabel('counts of fname ', color = 'white', size =20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_curated[data_train_curated['frames']>2500000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound = ('../input/train_curated/77b925c2.wav')\nipd.Audio(sound)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import *\nwordcloud = WordCloud(width = 1000, height = 600, \n                background_color ='black', \n                min_font_size = 5).generate(''.join(data_train_curated.labels)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (13, 12), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we have to crop the audio segments as to take only the information and leave the rest \n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def audio_norm(data):\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data-min_data)/(max_data-min_data+1e-6)\n    return data - 0.5\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten,\n                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\nfrom keras.utils import Sequence, to_categorical\nfrom keras.optimizers import Adam\nfrom keras.losses import categorical_crossentropy\nfrom keras.models import Model\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config(object):\n    def __init__(self,\n                 sampling_rate=18000, audio_duration=2, \n                 n_classes=len(category_group),\n                 use_mfcc=False, n_folds=10, learning_rate=0.0002, \n                 max_epochs=20, n_mfcc=20):\n        self.sampling_rate = sampling_rate\n        self.audio_duration = audio_duration\n        self.n_classes = n_classes\n        self.use_mfcc = use_mfcc\n        self.n_mfcc = n_mfcc\n        self.n_folds = n_folds\n        self.learning_rate = learning_rate\n        self.max_epochs = max_epochs\n\n        self.audio_length = self.sampling_rate * self.audio_duration\n        if self.use_mfcc:\n            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n        else:\n            self.dim = (self.audio_length, 1)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to keras ;)\n\nclass DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, config,data_dirs,data_dir, list_IDs, labels=None, \n                 batch_size=64, preprocessing_fn=lambda x: x):\n        'Initialization'\n        self.config = config\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            X[i,] = np.load('data/' + ID + '.npy')\n\n            # Store class\n            y[i] = self.labels[ID]\n\n        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to get dummy 1D dummy model\ndef get_dummy(config):\n    nclass = config.n_classes\n    input_length = config.audio_length\n    inp = Input(shape =(input_length,1))\n    x = GlobalMaxPool1D()(inp)\n    out = Dense(nclass, activation=softmax)(x)\n    model = models.Model(inputs = inp, outputs = out)\n    optimizer = optimizers.Adam(config.learning_rate)\n    model.compile(optimizer = optimizer, loss = losses.categorical_crossentropy,metrics=['Accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def_conv_model(config):\n    nclass = config.n_classes\n    input_length = config.audio_length\n    inp = Input(shape = (input_length, 1))\n    x = Convolution1D(16,9,activation=relu, padding = 'valid')(inp)\n    x = Convolution1D(16,9, activation= relu, padding = 'valid')(x)\n    x = MaxPool1D(16)(x)\n    x =Dropout(rate = 0.1)(x)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Stay Tuned","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}