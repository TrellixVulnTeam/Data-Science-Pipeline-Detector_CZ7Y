{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport IPython as ipt  #naumually listen and check audio after process \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport glob\n\nfrom scipy.io import wavfile\nimport scipy.signal as sps\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport librosa   #down sample the wave \n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import losses, models, optimizers\nfrom keras.activations import relu, softmax\nfrom keras.callbacks import (EarlyStopping, LearningRateScheduler,\n                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\nfrom keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, \n                          GlobalMaxPool1D, Input, MaxPool1D, concatenate)\nfrom keras.utils import Sequence, to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASEPATH='../input/'\nMAX_FRAME=44100*3\nMAX_LEN=3\nSR=16000\nLR=0.0006\nEPOCHS=200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  voice tags representation\n# input: original train set\n# output: transfer voice tags into sparse matrix\n# out of 4790 examples, more than 700 have mutli tags\n\n#find unique tag form list\ndef sparse_df(train_set,label_list):\n\n    #train_set=train_curated\n    #labels_list=[]\n    #for label in train_set['labels']:\n    #    label=label.split(',')\n    #    labels_list.extend(label)\n    #labels_set=sorted(list(set(labels_list)))\n\n    #form dict map the unique tags to numbers\n    label_dict={}\n    label_nr=0\n    for label in label_list:\n        label_dict[label]=label_nr\n        label_nr=label_nr+1\n\n    #transfer tags into sparse matrix\n    tags_matrix=np.zeros([len(train_set),len(label_list)])\n    for i,label in enumerate(train_set['labels']):\n        for label_word in label.split(','):\n            tags_matrix[i,label_dict[label_word]]=1\n    tags_df=pd.DataFrame(data=tags_matrix,columns=label_dict.keys())\n\n    assert len(tags_df)==len(train_set)\n\n    return pd.concat([train_set,tags_df],axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read the train data and re-represent as sparse matrix \nsample_submission=pd.read_csv(BASEPATH+'sample_submission.csv')\ntrain_curated=sparse_df(pd.read_csv(BASEPATH+'train_curated.csv'),sample_submission.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_audio0(fname,max_frame):\n    file_path=BASEPATH+'/train_curated/'+fname\n    _,wave=wavfile.read(file_path)\n    w_max=np.max(wave)\n    w_min=np.min(wave)\n    wave=(wave-w_min)/(w_max-w_min+1e-8)\n    if len(wave)>max_frame:\n        start_point=np.random.randint(len(wave)-max_frame)\n        wave=wave[start_point:start_point+max_frame]\n    else:\n        wave=np.append(np.zeros(max_frame-len(wave)),wave)\n    return wave,file_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_audio(path,fname,max_len,sr):\n    file_path=BASEPATH+path+fname\n    wave,_=librosa.load(file_path,sr=sr,res_type='kaiser_fast')\n    max_frame=max_len*sr\n    w_max=np.max(wave)\n    w_min=np.min(wave)\n    wave=(wave-w_min)/(w_max-w_min+1e-8)\n    if len(wave)>max_frame:\n        start_point=np.random.randint(len(wave)-max_frame)\n        wave=wave[start_point:start_point+max_frame]\n    else:\n        wave=np.append(np.zeros(max_frame-len(wave)),wave)\n    return wave,file_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test read_audio \nwave_sample,sample_file=read_audio('train_curated/',train_curated['fname'][6],MAX_LEN,SR)\nplt.plot(wave_sample)\nipt.display.Audio(sample_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_1d_conv_model(input_length,output_length):\n    \n    nclass = output_length\n#   input_length = MAX_FRAME\n    \n    inp = Input(shape=(input_length,1))\n    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n    x = MaxPool1D(16)(x)\n    x = Dropout(rate=0.1)(x)\n    \n    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n    x = MaxPool1D(4)(x)\n    x = Dropout(rate=0.1)(x)\n    \n    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n    x = MaxPool1D(4)(x)\n    x = Dropout(rate=0.1)(x)\n    \n    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n    x = GlobalMaxPool1D()(x)\n    x = Dropout(rate=0.2)(x)\n\n    x = Dense(64, activation=relu)(x)\n    x = Dense(1028, activation=relu)(x)\n    out = Dense(nclass, activation=softmax)(x)\n\n    model = models.Model(inputs=inp, outputs=out)\n    opt = optimizers.Adam(LR)    \n\n    model.compile(optimizer=opt,loss=losses.categorical_crossentropy, metrics=['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare the train set \ndef prepare_train_set(path,df,max_len,sr):\n    shape0=len(df)\n    train_set=np.zeros((shape0,max_len*SR))\n    for i,file in enumerate(df['fname']):\n        wave,_=read_audio(path,file,max_len,sr)\n        if i%500==0:\n            print(i,file)\n        train_set[i,:]=wave\n    return train_set\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set=prepare_train_set('train_curated/',train_curated,MAX_LEN,SR)\ntrain_set=train_set.reshape(train_set.shape+(1,))\ntrain_set_label=train_curated.drop(['fname','labels'],axis=1).values\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=get_1d_conv_model(train_set.shape[1],80)\nmodel.fit(x=train_set,y=train_set_label,epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##test set preparation\nimport glob\nfiles=glob.glob(BASEPATH+'test/*.wav')\ntest_set=np.zeros((len(files),MAX_LEN*SR,1))\ntest_file=[]\nfor i,file in enumerate(files):\n    file=file[-12:]\n    test_file.append(file)\n    wave,_=read_audio('test/',file,MAX_LEN,SR)\n    test_set[i,:,0]=wave","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##predict and submission\nsubmission=model.predict(test_set)\nsubmission_df=pd.DataFrame(data=submission,columns=sample_submission.columns[1:])\nsubmission_df.insert(0,'fname',test_file)\nsubmission_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}