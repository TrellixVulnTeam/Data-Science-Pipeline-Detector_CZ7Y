{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom scipy.io import wavfile as wav\nprint(os.listdir(\"../input\"))\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom scipy import signal\nimport numpy as np\nimport librosa\nfrom keras.preprocessing.sequence import pad_sequences\nimport sklearn.metrics\nimport glob\nimport json\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['train_curated.csv', 'train_noisy.csv', 'test', 'sample_submission.csv', 'train_curated', 'train_noisy']\n","name":"stdout"},{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_c = pd.read_csv('../input/train_curated.csv')\ndf_c.info()","execution_count":2,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4970 entries, 0 to 4969\nData columns (total 2 columns):\nfname     4970 non-null object\nlabels    4970 non-null object\ndtypes: object(2)\nmemory usage: 77.7+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_c['labels'].describe()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"count        4970\nunique        213\ntop       Printer\nfreq           75\nName: labels, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature extraction \ndef extract_feature(path):\n    X, sample_rate = librosa.load(path)\n    stft = np.abs(librosa.stft(X))\n    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n    return mfccs,chroma,mel,contrast,tonnetz\n\ndef parse_audio_files(df, loc='../input/train_curated/'):\n    # n: number of classes\n    features = np.empty((0,193))\n    for idx, row in tqdm(df.iterrows()):\n        f = loc + row['fname']\n        mfccs, chroma, mel, contrast,tonnetz = extract_feature(f)\n        ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n        features = np.vstack([features,ext_features])\n    return np.array(features)\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = parse_audio_files(df_c)","execution_count":7,"outputs":[{"output_type":"stream","text":"\n0it [00:00, ?it/s]\u001b[A\n1it [00:00,  1.08it/s]\u001b[A\n2it [00:01,  1.36it/s]\u001b[A","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\ntry:\n    with open('data.pkl', 'wb') as file:\n        pickle.dump(d,file)\nexcept Exception as e:\n    print(e)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.dump('d.pkl')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one hot encoding\ny = []\nfor index, row in df_c.iterrows():\n    labels = row['labels'].split(',')\n    y.append(labels)\n\n# Create MultiLabelBinarizer object\none_hot = MultiLabelBinarizer()\n\n# One-hot encode label data\ny = one_hot.fit_transform(y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}