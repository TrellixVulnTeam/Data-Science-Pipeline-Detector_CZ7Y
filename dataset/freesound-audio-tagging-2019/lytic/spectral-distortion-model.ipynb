{"cells":[{"metadata":{},"cell_type":"markdown","source":"In the case of phase-sensitive multi-microphone neural network models, there is a simple augmentation called [Spectral Distortion Model](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/78ea22a4a1cdfda4103237812fc92b9642b52109.pdf).\n\nI assume that this type of augmentation should also work in this [challenge](https://www.kaggle.com/c/dcase2019-task1b-leaderboard) with a different type of devices.\n\nIn this kernel, I will demonstrate how to apply the phase distortion augmentation."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import librosa\nimport numpy as np\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load original signal"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"x, sr = librosa.load('../input/freesound-audio-tagging-2019/train_curated/f5342540.wav', sr=44100)\nx = x[:len(x) // 7]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a random phase distortion model with sigma equal to 0.4"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(2019)\nPDM = np.array([np.complex(np.cos(p), np.sin(p)) for p in np.random.normal(0, 0.4, size=513)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform the original signal and apply augmentation for each frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = librosa.stft(x, window='hanning', hop_length=512, n_fft=1024)\nf *= PDM.reshape((-1, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reconstruct transformed signal"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = librosa.istft(f, window='hanning', hop_length=512)\nx = x[:len(y)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the figure below, you can see a small difference between the two signals"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 1, 1)\nplt.plot(x)\n\nplt.subplot(2, 1, 2)\nplt.plot(y)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Signals sound equally"},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(x, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(y, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to mention paper, this augmentation also worked with Multistyle-TRaining (MTR).\n\nIt would be interesting to test this approach for the acoustic scene classification or event detection tasks."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}