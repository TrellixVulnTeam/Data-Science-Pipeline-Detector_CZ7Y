{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Intro\nThis is an attemp to apply some features from **LANL Earthquake prediction competition**.\n\nAll feature engeneering was borrowed from kernel by @Ilu:\n[#1 private LB kernel LANL lgbm](https://www.kaggle.com/ilu000/1-private-lb-kernel-lanl-lgbm/code)\n\nSome other approaches was inspired (borrowed:)) from kernels:\n* [FAT19: MixUp Keras on PreProcessedData LB632](https://www.kaggle.com/ratthachat/fat19-mixup-keras-on-preprocesseddata-lb632) @Neuron Engineer\n* [Beginner's Guide to Audio Data 2](https://www.kaggle.com/maxwell110/beginner-s-guide-to-audio-data-2) by @Maxwell\n\nthank you, guys)\n\nPS. Just simple copy-paste-few-debug)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# from tqdm import tqdm_notebook as tqdm\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport shutil\nimport warnings\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nfrom tsfresh.feature_extraction import feature_calculators\nimport librosa\nimport pywt\nimport wave\nimport random\n\nfrom joblib import Parallel, delayed\nimport scipy as sp\nimport itertools\nimport gc\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nSEED = 2205\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated = pd.read_csv(\"../input/train_curated.csv\")\ntrain_noisy = pd.read_csv(\"../input/train_noisy.csv\")\ntrain = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n\ntest = pd.read_csv(\"../input/sample_submission.csv\")\n\nLABELS = test.columns[1:].tolist()\nnum_classes = len(LABELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config(object):\n    def __init__(self,\n                 sampling_rate=16000, audio_duration=2, \n                 n_classes=num_classes,\n                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n                 max_epochs=50, n_mfcc=20):\n        self.sampling_rate = sampling_rate\n        self.audio_duration = audio_duration\n        self.n_classes = n_classes\n        self.use_mfcc = use_mfcc\n        self.n_mfcc = n_mfcc\n        self.n_folds = n_folds\n        self.learning_rate = learning_rate\n        self.max_epochs = max_epochs\n\n        self.audio_length = self.sampling_rate * self.audio_duration\n        self.noise = np.random.normal(0, 0.5, self.audio_length)\n        if self.use_mfcc:\n            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n        else:\n            self.dim = (self.audio_length, 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index(\"fname\", inplace=True)\n# test.set_index(\"fname\", inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated.index = train_curated.fname\ntrain_noisy.index = train_noisy.fname  \ntest.index = test.fname ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = Config(sampling_rate=44100, audio_duration=3, n_folds=7, \n                learning_rate=0.001, use_mfcc=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def denoise_signal_simple(x, wavelet='sym5', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    #univeral threshold\n    uthresh = 10\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    # Reconstruct the signal using the thresholded coefficients\n    return pywt.waverec(coeff, wavelet, mode='per')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_gen(z,noise):\n    X = pd.DataFrame(index=[0], dtype=np.float64)\n    \n    z = z + noise\n    z = z - np.median(z)\n\n    den_sample_simple = denoise_signal_simple(z)\n    mfcc = librosa.feature.mfcc(z)\n    mfcc_mean = mfcc.mean(axis=1)\n    percentile_roll77_std_30 = np.percentile(pd.Series(z).rolling(77).std().dropna().values, 30)\n    \n    X['var_num_peaks_3_denoise_simple'] = feature_calculators.number_peaks(den_sample_simple, 3)\n    X['var_percentile_roll77_std_30'] = percentile_roll77_std_30\n    X['var_mfcc_mean13'] = mfcc_mean[13]\n    X['var_mfcc_mean7'] = mfcc_mean[7]\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_sample(sample, config, data_dir):\n    input_length = config.audio_length\n    file_path = data_dir + sample.fname    \n    data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n    # Random offset / Padding\n    if len(data) > input_length:\n        max_offset = len(data) - input_length\n        offset = np.random.randint(max_offset)\n        data = data[offset:(input_length+offset)]\n    else:\n        if input_length > len(data):\n            max_offset = input_length - len(data)\n            offset = np.random.randint(max_offset)\n        else:\n            offset = 0\n        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n               \n    return feature_gen(data, config.noise)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_gen(df, config, data_dir):\n    X = pd.DataFrame()\n    result = Parallel(n_jobs=4, temp_folder=\"/tmp\", max_nbytes=None, backend=\"multiprocessing\")(delayed(parse_sample)(df.iloc[i], config, data_dir) for i in range(len(df))) \n    data = [r.values for r in result]\n    data = np.vstack(data)\n    X = pd.DataFrame(data,columns=result[0].columns)\n    return X\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_curated = sample_gen(train_curated, config,'../input/train_curated/')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_noisy = sample_gen(train_noisy, config,'../input/train_noisy/')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([X_train_curated, X_train_noisy], sort=True, ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = sample_gen(test, config,'../input/test/')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.zeros((len(train), num_classes)).astype(int)\nfor i, row in enumerate(train['labels'].str.split(',')):\n    for label in row:\n        idx = LABELS.index(label)\n        y_train[i, idx] = 1\n\nprint('Y_train',y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['var_num_peaks_3_denoise_simple','var_percentile_roll77_std_30','var_mfcc_mean7',  'var_mfcc_mean13']\ntrain_X = X_train[features].values\ntest_X = X_test[features].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nskf = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=SEED)\n# kf = list(kf.split(np.arange(len(X_train))))\n\noof = np.zeros((len(train_X),num_classes))\nprediction = np.zeros((len(test_X),num_classes))\n\nfor fold_n, (train_index, valid_index) in enumerate(skf.split(train.index, train.labels)):\n    print('Fold', fold_n)\n    trn_data = lgb.Dataset(train_X[train_index], label=y_train[train_index,0])\n    val_data = lgb.Dataset(train_X[valid_index], label=y_train[valid_index,0])\n    \n    params = {'num_leaves': 128,\n      'min_data_in_leaf': 79,\n      'num_class': num_classes,\n      'objective':'multiclass',\n      'max_depth': -1,\n      'learning_rate': config.learning_rate,\n      \"boosting\": \"gbdt\",\n      'boost_from_average': True,\n      \"feature_fraction\": 0.9,\n      \"bagging_freq\": 7,\n      \"bagging_fraction\": 0.8126672064208567,\n      \"bagging_seed\": SEED,\n#       \"metric\": 'mae',\n      \"verbosity\": -1,\n      'max_bin': 500,\n      'reg_alpha': 0.1302650970728192,\n      'reg_lambda': 0.3603427518866501,\n      'seed': SEED,\n      'n_jobs': 4\n      }\n\n    clf = lgb.train(params, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n\n    oof[valid_index] += clf.predict(train_X[valid_index], num_iteration=clf.best_iteration)\n    prediction += clf.predict(test_X, num_iteration=clf.best_iteration)\n\nprediction /= config.n_folds\n\n# print('\\nMAE: ', mean_absolute_error(y_train, oof))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a submission file\ntest_df = pd.read_csv('../input/sample_submission.csv')\nprint(test_df.head())\ntest_df[LABELS] = prediction\ntest_df.to_csv('submission.csv', index=False)\nprint(test_df.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}