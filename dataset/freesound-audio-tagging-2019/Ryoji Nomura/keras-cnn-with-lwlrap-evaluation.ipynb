{"cells":[{"metadata":{},"cell_type":"markdown","source":"submission test.\n\nI'd like to generate format for submission. I've struggled to find nice network for learning which does not get the same output for every X."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport glob\nimport pickle\nfrom sklearn.model_selection import train_test_split \nimport librosa","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Reshape\nfrom keras.layers import Activation\nfrom keras.layers import concatenate\nfrom keras import optimizers\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nimport tensorflow as tf","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_FOLDER = \"../input/freesound-audio-tagging-2019/\"\nprint(os.listdir(INPUT_FOLDER))","execution_count":3,"outputs":[{"output_type":"stream","text":"['train_noisy.csv', 'test', 'train_curated', 'train_noisy', 'sample_submission.csv', 'train_curated.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_CURATED_PATH = INPUT_FOLDER + \"train_curated.csv\"\nTRAIN_NOISY_PATH = INPUT_FOLDER + \"train_noisy.csv\"\nSAMPLE_SUBMISSION_PATH = INPUT_FOLDER + \"sample_submission.csv\"\nTRAIN_CURATED = INPUT_FOLDER + \"train_curated/\"\nTRAIN_NOISY = INPUT_FOLDER + \"train_noisy/\"\nTEST = INPUT_FOLDER + \"test/\"\n\ntrain_curated = pd.read_csv(TRAIN_CURATED_PATH)\ntrain_noisy = pd.read_csv(TRAIN_NOISY_PATH)\nsample = pd.read_csv(SAMPLE_SUBMISSION_PATH)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(labels, src_dict):\n    ar = np.zeros([len(labels), len(src_dict)])\n    for i, label in enumerate(labels):\n        label_list = label.split(',')\n        for la in label_list:\n            ar[i, src_dict[la]] = 1\n    return ar","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_names = sample.columns[1:]\nnum_targets = len(target_names)\n\nsrc_dict = {target_names[i]:i for i in range(num_targets)}\nsrc_dict_inv = {i:target_names[i] for i in range(num_targets)}","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image size, normalized\nnum_freq = 128\nlen_div = 256","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you know, every data has different length for time dim. I like cut data at the same length (ex. 256 pixels). The last cut might not be bad with being filled with zeros."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # get normarized images (num_freq, len_div). zero padding for last cut\n# X_proc_ = np.zeros([1, num_freq, len_div]) # dummy of normalized image (templete)\n# y_proc_ = np.zeros([1,80]) # dummy of label (templete)\n# y_proc_tmp = one_hot(train_curated['labels'], src_dict)\n\n# file_name = train_curated['fname'].values\n\n# for i, file in enumerate(file_name):\n#     wavfile = TRAIN_CURATED + file\n#     y_proc, sr = librosa.load(wavfile)\n#     S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n#     log_S = librosa.power_to_db(S, ref=np.max)\n#     X_proc = (log_S + 80) / 40 - 1 # fit signal range (-80, 0) -> (-1, 1)\n    \n#     num_div = X_proc.shape[1] // len_div\n#     num_pad = len_div - X_proc.shape[1] % len_div\n#     redidual_amp = np.zeros([num_freq, num_pad])\n#     dum = np.hstack([X_proc, redidual_amp])\n#     X_proc_ = np.vstack([X_proc_, np.array(np.split(dum, num_div+1,1))])\n#     for _ in range(num_div+1):\n#         y_proc_ = np.vstack([y_proc_, y_proc_tmp[i]])\n\n# X = X_proc_[1:] # del templete\n# y = y_proc_[1:] # del templete\n# X = X.reshape([-1, num_freq, len_div, 1])\n\n# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I guess spectram may have long term feature which means that fine feature is not important. That's why I've tried to obtain more than 10 pixel feature. A kernel with small size such as (3, 3) might be not important, for example. At this moment, I've found below is not bad. Deep and precise such as VGG is not good that predicts the same output for all X_test."},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/preprocessed-train-data-2/train_arr.pickle', 'rb') as f:\n    X_train = pickle.load(f)\n    y_train = pickle.load(f)","execution_count":27,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(num_freq,len_div,1), name='input')\n\ndense_list = []\n\n## Block 1\nconv1 = Conv2D(4, (19, 19),activation='relu',padding='same',name='conv1')(inputs)\npool1 = MaxPooling2D((19, 19),strides=(1, 1),padding='same',name='pool1')(conv1)\nnorm1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm1')(pool1)\ndrop1 = Dropout(0.05)(norm1)\n\nconv1_1 = Conv2D(4, (11, 11),activation='relu',padding='same',name='conv1_1')(drop1)\npool1_1 = MaxPooling2D((5, 5),strides=(5, 5),padding='same',name='pool1_1')(conv1_1)\nnorm1_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm1_1')(pool1_1)\ndrop1_1 = Dropout(0.05)(norm1_1)\n\nflatten1 = Flatten(name='flatten1')(drop1)\ndense1 = Dense(16, name='dense1')(flatten1)\nact1 = Activation('relu',name='act1')(dense1)\ndense_list.append(act1)\n\n## Block 2\nconv2 = Conv2D(4, (13, 13),activation='relu',padding='same',name='conv2')(inputs)\npool2 = MaxPooling2D((13, 13), strides=(1, 1), padding='same',name='pool2')(conv2)\nnorm2 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm2')(pool2)\ndrop2 = Dropout(rate=0.05)(norm2)\n\nconv2_1 = Conv2D(4, (7, 7),activation='relu',padding='same',name='conv2_1')(drop2)\npool2_1 = MaxPooling2D((7, 7), strides=(5, 5), padding='same',name='pool2_1')(conv2_1)\nnorm2_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm2_1')(pool2_1)\ndrop2_1 = Dropout(rate=0.05)(norm2_1)\n\nflatten2 = Flatten(name='flatten2')(drop2_1)\ndense2 = Dense(16, name='dense2')(flatten2)\nact2 = Activation('relu',name='act2')(dense2)\ndense_list.append(act2)\n\n## Block 3\nconv3 = Conv2D(8, (11, 11), activation='relu',padding='same',name='conv3')(inputs)\npool3 = MaxPooling2D((11, 11), strides=(2, 2), padding='same',name='pool3')(conv3)\nnorm3 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm3')(pool3)\ndrop3 = Dropout(rate=0.05)(norm3)\n\nconv3_1 = Conv2D(8, (5, 5), activation='relu',padding='same',name='conv3_1')(drop3)\npool3_1 = MaxPooling2D((5, 5), strides=(2, 2), padding='same',name='pool3_1')(conv3_1)\nnorm3_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm3_1')(pool3_1)\ndrop3_1 = Dropout(rate=0.05)(norm3_1)\n\nflatten3 = Flatten(name='flatten3')(drop3_1)\ndense3 = Dense(16, name='dense3')(flatten3)\nact3 = Activation('relu',name='act3')(dense3)\ndense_list.append(act3)\n\n## Block 4\nconv4 = Conv2D(8, (9, 9),activation='relu',padding='same',name='conv4')(inputs)\npool4 = MaxPooling2D((9, 9), strides=(2, 2), padding='same',name='pool4')(conv4)\nnorm4 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm4')(pool4)\ndrop4 = Dropout(rate=0.05)(norm4)\n\nconv4_1 = Conv2D(8, (3, 3),activation='relu',padding='same',name='conv4_1')(drop4)\npool4_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',name='pool4_1')(conv4_1)\nnorm4_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm4_1')(pool4_1)\ndrop4_1 = Dropout(rate=0.05)(norm4_1)\n\nflatten4 = Flatten(name='flatten4')(drop4_1)\ndense4 = Dense(16, name='dense4')(flatten4)\nact4 = Activation('relu',name='act4')(dense4)\ndense_list.append(act4)\n\nconcat = concatenate(dense_list, name='concat', axis=1)\n\ndense2 = Dense(80, name='dense_all')(concat)\npred = Activation('softmax',name='pred')(dense2)\n\nadam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel = Model(inputs=inputs, outputs=pred)","execution_count":9,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Below is definition of LWLRAP evaluation for Keras(tensorflow). Some outputs of this function are different from output of numpy version definition. To my understanding, ranking order causes the difference. For example, if there are two label (A, B) in one sound, we can count ranking both ways from A and from B."},{"metadata":{"trusted":true},"cell_type":"code","source":"def tf_one_sample_positive_class_precisions(y_true, y_pred) :\n    num_samples, num_classes = y_pred.shape\n    \n    # find true labels\n    pos_class_indices = tf.where(y_true > 0) \n    \n    # put rank on each element\n    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n    sample_range = tf.transpose(sample_range)\n    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n    retrieved_class_map = tf.transpose(retrieved_class_map)\n    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n    \n    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n    \n    class_rankings = tf.scatter_nd(retrieved_class_map,\n                                          class_range,\n                                          tf.shape(y_pred))\n    \n    #pick_up ranks\n    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n\n    # add one for division for \"presicion_at_hits\"\n    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n    \n    # generate tensor [num_sample, predict_rank], \n    # top-N predicted elements have flag, N is the number of positive for each sample.\n    sample_label = pos_class_indices[:, 0]   \n    sample_label = tf.reshape(sample_label, (-1, 1))\n    sample_label = tf.cast(sample_label, tf.int32)\n    \n    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n    retrieved_class_true_position = tf.concat((sample_label, \n                                               num_correct_until_correct), axis=1)\n    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n                                         retrieved_pos, \n                                         tf.shape(y_pred))\n    # cumulate predict_rank\n    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n\n    # find positive position\n    pos_ret_indices = tf.where(retrieved_class_true > 0)\n\n    # find cumulative hits\n    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n    correct_rank = tf.cast(correct_rank, tf.float32)\n\n    # compute presicion\n    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n\n    return pos_class_indices, precision_at_hits\n\ndef tf_lwlrap(y_true, y_pred):\n    num_samples, num_classes = y_pred.shape\n    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n    pos_flgs = tf.cast(y_true > 0, tf.int32)\n    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n    class_label = pos_class_indices[:,1]\n    sum_precisions_by_classes = tf.unsorted_segment_sum(precision_at_hits,\n                                                        class_label,\n                                                       num_classes)\n    labels_per_class = tf.cast(labels_per_class, tf.float32)\n    labels_per_class = tf.add(labels_per_class, 1e-7)\n    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n                                  tf.cast(labels_per_class, tf.float32))\n    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n    return out","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=[tf_lwlrap])","execution_count":23,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":24,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              (None, 128, 256, 1)  0                                            \n__________________________________________________________________________________________________\nconv2 (Conv2D)                  (None, 128, 256, 4)  680         input[0][0]                      \n__________________________________________________________________________________________________\nconv3 (Conv2D)                  (None, 128, 256, 8)  976         input[0][0]                      \n__________________________________________________________________________________________________\nconv4 (Conv2D)                  (None, 128, 256, 8)  656         input[0][0]                      \n__________________________________________________________________________________________________\npool2 (MaxPooling2D)            (None, 128, 256, 4)  0           conv2[0][0]                      \n__________________________________________________________________________________________________\npool3 (MaxPooling2D)            (None, 64, 128, 8)   0           conv3[0][0]                      \n__________________________________________________________________________________________________\npool4 (MaxPooling2D)            (None, 64, 128, 8)   0           conv4[0][0]                      \n__________________________________________________________________________________________________\nnorm2 (BatchNormalization)      (None, 128, 256, 4)  16          pool2[0][0]                      \n__________________________________________________________________________________________________\nnorm3 (BatchNormalization)      (None, 64, 128, 8)   32          pool3[0][0]                      \n__________________________________________________________________________________________________\nnorm4 (BatchNormalization)      (None, 64, 128, 8)   32          pool4[0][0]                      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 128, 256, 4)  0           norm2[0][0]                      \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 64, 128, 8)   0           norm3[0][0]                      \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 64, 128, 8)   0           norm4[0][0]                      \n__________________________________________________________________________________________________\nconv1 (Conv2D)                  (None, 128, 256, 4)  1448        input[0][0]                      \n__________________________________________________________________________________________________\nconv2_1 (Conv2D)                (None, 128, 256, 4)  788         dropout_3[0][0]                  \n__________________________________________________________________________________________________\nconv3_1 (Conv2D)                (None, 64, 128, 8)   1608        dropout_5[0][0]                  \n__________________________________________________________________________________________________\nconv4_1 (Conv2D)                (None, 64, 128, 8)   584         dropout_7[0][0]                  \n__________________________________________________________________________________________________\npool1 (MaxPooling2D)            (None, 128, 256, 4)  0           conv1[0][0]                      \n__________________________________________________________________________________________________\npool2_1 (MaxPooling2D)          (None, 26, 52, 4)    0           conv2_1[0][0]                    \n__________________________________________________________________________________________________\npool3_1 (MaxPooling2D)          (None, 32, 64, 8)    0           conv3_1[0][0]                    \n__________________________________________________________________________________________________\npool4_1 (MaxPooling2D)          (None, 32, 64, 8)    0           conv4_1[0][0]                    \n__________________________________________________________________________________________________\nnorm1 (BatchNormalization)      (None, 128, 256, 4)  16          pool1[0][0]                      \n__________________________________________________________________________________________________\nnorm2_1 (BatchNormalization)    (None, 26, 52, 4)    16          pool2_1[0][0]                    \n__________________________________________________________________________________________________\nnorm3_1 (BatchNormalization)    (None, 32, 64, 8)    32          pool3_1[0][0]                    \n__________________________________________________________________________________________________\nnorm4_1 (BatchNormalization)    (None, 32, 64, 8)    32          pool4_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 128, 256, 4)  0           norm1[0][0]                      \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 26, 52, 4)    0           norm2_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 32, 64, 8)    0           norm3_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_8 (Dropout)             (None, 32, 64, 8)    0           norm4_1[0][0]                    \n__________________________________________________________________________________________________\nflatten1 (Flatten)              (None, 131072)       0           dropout_1[0][0]                  \n__________________________________________________________________________________________________\nflatten2 (Flatten)              (None, 5408)         0           dropout_4[0][0]                  \n__________________________________________________________________________________________________\nflatten3 (Flatten)              (None, 16384)        0           dropout_6[0][0]                  \n__________________________________________________________________________________________________\nflatten4 (Flatten)              (None, 16384)        0           dropout_8[0][0]                  \n__________________________________________________________________________________________________\ndense1 (Dense)                  (None, 16)           2097168     flatten1[0][0]                   \n__________________________________________________________________________________________________\ndense2 (Dense)                  (None, 16)           86544       flatten2[0][0]                   \n__________________________________________________________________________________________________\ndense3 (Dense)                  (None, 16)           262160      flatten3[0][0]                   \n__________________________________________________________________________________________________\ndense4 (Dense)                  (None, 16)           262160      flatten4[0][0]                   \n__________________________________________________________________________________________________\nact1 (Activation)               (None, 16)           0           dense1[0][0]                     \n__________________________________________________________________________________________________\nact2 (Activation)               (None, 16)           0           dense2[0][0]                     \n__________________________________________________________________________________________________\nact3 (Activation)               (None, 16)           0           dense3[0][0]                     \n__________________________________________________________________________________________________\nact4 (Activation)               (None, 16)           0           dense4[0][0]                     \n__________________________________________________________________________________________________\nconcat (Concatenate)            (None, 64)           0           act1[0][0]                       \n                                                                 act2[0][0]                       \n                                                                 act3[0][0]                       \n                                                                 act4[0][0]                       \n__________________________________________________________________________________________________\ndense_all (Dense)               (None, 80)           5200        concat[0][0]                     \n__________________________________________________________________________________________________\npred (Activation)               (None, 80)           0           dense_all[0][0]                  \n==================================================================================================\nTotal params: 2,720,148\nTrainable params: 2,720,060\nNon-trainable params: 88\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n           rotation_range=0,\n           width_shift_range=16,\n           height_shift_range=0,\n           shear_range=0,\n           zoom_range=0,\n           horizontal_flip=False,\n           vertical_flip=False)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen.fit(X_train)\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n                    steps_per_epoch=len(X_train) / 32, epochs=30)","execution_count":28,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/30\n294/293 [==============================] - 35s 119ms/step - loss: 7.0925 - tf_lwlrap: 0.1092\nEpoch 2/30\n294/293 [==============================] - 32s 107ms/step - loss: 5.5613 - tf_lwlrap: 0.1849\nEpoch 3/30\n294/293 [==============================] - 32s 107ms/step - loss: 4.7404 - tf_lwlrap: 0.2502\nEpoch 4/30\n294/293 [==============================] - 32s 107ms/step - loss: 4.1814 - tf_lwlrap: 0.3081\nEpoch 5/30\n294/293 [==============================] - 31s 107ms/step - loss: 3.9232 - tf_lwlrap: 0.3444\nEpoch 6/30\n294/293 [==============================] - 31s 106ms/step - loss: 3.6990 - tf_lwlrap: 0.3867\nEpoch 7/30\n294/293 [==============================] - 32s 109ms/step - loss: 3.5454 - tf_lwlrap: 0.4113\nEpoch 8/30\n294/293 [==============================] - 31s 105ms/step - loss: 3.4095 - tf_lwlrap: 0.4392\nEpoch 9/30\n294/293 [==============================] - 31s 105ms/step - loss: 3.3209 - tf_lwlrap: 0.4557\nEpoch 10/30\n294/293 [==============================] - 31s 105ms/step - loss: 3.2336 - tf_lwlrap: 0.4754\nEpoch 11/30\n263/293 [=========================>....] - ETA: 3s - loss: 3.1607 - tf_lwlrap: 0.4829","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-81d536a5f4bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n\u001b[0;32m----> 3\u001b[0;31m                     steps_per_epoch=len(X_train) / 32, epochs=30)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_test_list = []\n\n# filename = glob.glob(TEST + \"*\")\n\n# for file in filename:\n#     wavfile = file\n#     y_proc, sr = librosa.load(wavfile)\n#     S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n#     log_S = librosa.power_to_db(S, ref=np.max)\n#     X_proc = (log_S + 80) / 40 - 1\n    \n#     num_div = X_proc.shape[1] // len_div\n#     num_pad = len_div - X_proc.shape[1] % len_div\n#     redidual_amp = np.zeros([num_freq, num_pad])\n#     dum = np.hstack([X_proc, redidual_amp])\n#     X_test_list.append(np.array(np.split(dum, num_div+1,1)))\n    \n# with open('../input/preprocessed-test-data-2/test_arr.pickle', 'wb') as f:\n#     pickle.dump(X_test_list, f)\n#     pickle.dump(filename, f)\n    \nwith open('../input/preprocessed-test-data-2/test_arr.pickle', 'rb') as f:\n    X_test_list = pickle.load(f)\n    filename = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each X_test has different length. That means each prediction has several predictions. Here, simply, those are averaged."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_list = []\nfor X_test in X_test_list:\n    pred = model.predict(X_test.reshape([-1, num_freq, len_div,1])).sum(axis=0) / len(X_test)\n    pred_list.append(pred)\ny_pred = np.array(pred_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = []\nfor f in filename:\n    names.append(f.split(\"\\\\\")[-1])\n    \nse_file = pd.Series(names, name='fname')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_names = sample.columns[1:]\nlabel = pd.DataFrame(y_pred, columns=sound_names)\n\nsub_df = pd.concat([se_file, label], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}