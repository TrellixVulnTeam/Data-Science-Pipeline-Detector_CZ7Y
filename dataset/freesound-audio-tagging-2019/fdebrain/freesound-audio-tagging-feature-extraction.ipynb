{"cells":[{"metadata":{},"cell_type":"markdown","source":"Handling the noisy train dataset on Google Colab:\nhttps://colab.research.google.com/drive/1uTEdXfazhonVHxP4vmuYAgG2BexzHfcu?usp=sharing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport librosa\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom tqdm import tqdm\nfrom functools import partial\nimport multiprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p ../data/train/curated\n!unzip -q /kaggle/input/freesound-audio-tagging-2019/train_curated.zip -d ../data/train/curated/wav\n\n# Takes very long and a lot of memory\n# !mkdir -p ../data/train/noisy\n# !unzip -q /kaggle/input/freesound-audio-tagging-2019/train_noisy.zip -d ../data/train/noisy/wav\n\n!mkdir -p ../data/test\n!unzip -q /kaggle/input/freesound-audio-tagging-2019/test.zip -d ../data/test/wav","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def load_train_data_df(mode='curated'):\n    # Load training data filenames and labels (raw -> multilabels are represented as a string with comma separated values)\n    data_folder = '/kaggle/input/freesound-audio-tagging-2019' \n    csv_path = f'{data_folder}/train_{mode}.csv'\n    raw_df = pd.read_csv(csv_path, index_col='fname')\n        \n    # Extract list of expected labels\n    sub = pd.read_csv('/kaggle/input/freesound-audio-tagging-2019/sample_submission.csv', index_col='fname')\n    labels_list = sub.columns.values \n\n    # Encode multi-labels in a binary vector\n    splitted_labels = [ labels.split(',') for labels in raw_df['labels'].values ]\n    encoder = MultiLabelBinarizer()\n    encoded_labels = encoder.fit_transform(splitted_labels)\n\n    # Create a new pandas Dataframe to represent training labels as binary vectors\n    labels_df = pd.DataFrame(data=encoded_labels, index=list(raw_df.index), columns=labels_list)\n    \n    return labels_df\n\ndef extract_mfcc(sample, n_mfcc=20, sr=44100):\n    \"\"\" Return a matrix of shape (n_mfcc, int(seconds*sr/1024)). \"\"\"\n    mfccs = librosa.feature.mfcc(sample, sr=sr, n_mfcc=n_mfcc)\n    return mfccs.astype(np.float32)\n\ndef extract_log_mel(sample, n_mels=128, sr=44100, hop=347):\n    mel = librosa.feature.melspectrogram(sample, sr=sr, n_fft=20*n_mels, hop_length=hop, n_mels=n_mels, fmin=20, fmax=sr//2)\n    logmel = librosa.core.power_to_db(mel, ref=1.0, amin=1e-10, top_db=None)\n    return logmel.astype(np.float32)\n\ndef extract_features(path, save_folder='../data/train/curated', feat_type='logmel', n_feats=128, hop=347, sr=44100, save=False):\n    start_time = time.time()\n\n    sample, _ = librosa.load(path, sr=None)\n    x, _ = librosa.effects.trim(sample)\n\n    if feat_type == 'mfcc':\n        x = extract_mfcc(x, n_feats, sr)\n    elif feat_type == 'logmel':\n        x = extract_log_mel(x, n_feats, sr, hop)\n        \n    if save:\n        if not os.path.exists(f'{save_folder}/{feat_type}'):\n            os.makedirs(f'{save_folder}/{feat_type}')\n        filename = path.split('/')[-1].split('.')[0]\n        np.save(f\"{save_folder}/{feat_type}/{filename}.npy\", x)\n    \ndef extract_serie(wav_paths, save_folder='../data/train/curated', feat_type='logmel', n_feats=128, hop=347, sr=44100, save=False):\n    start_time = time.time()\n    \n    with tqdm(total=len(curated_train_wav_paths)) as bar:\n        for path in wav_paths:\n            extract_features(path, save_folder, feat_type, n_feats, hop, sr, save)\n            bar.update(1)\n            \n    print(f'Successfully extracted {feat_type} features in {save_folder} ! (took {time.time() - start_time:.2f}s).')\n    \ndef extract_parallel(wav_paths, save_folder='../data/train/curated', feat_type='logmel', n_feats=128, hop=347, sr=44100, save=False):\n    start_time = time.time()\n    \n    n_cores = multiprocessing.cpu_count()\n    print(f'Extracting {feat_type} using {n_cores} cores...')\n    \n    with tqdm(total=len(wav_paths)) as bar, multiprocessing.Pool(processes=n_cores) as pool:\n        function = partial(extract_features, save_folder=save_folder, feat_type=feat_type, n_feats=n_feats, hop=hop, sr=sr, save=save)\n        for _ in pool.map(function, wav_paths):        \n            bar.update(1)\n        \n    print(f'Successfully extracted {feat_type} features in {save_folder} ! (took {time.time() - start_time:.2f}s).')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load data filenames and labels\ncurated_train_labels = load_train_data_df(mode='curated')\nnoisy_train_labels = load_train_data_df(mode='noisy')\ntest_labels = pd.read_csv('/kaggle/input/freesound-audio-tagging-2019/sample_submission.csv', index_col='fname')\n\n# Main info about the training/testing sets\nprint(f'{curated_train_labels.shape[1]} possible classes.')\nprint(f'{curated_train_labels.shape[0]} curated training samples.')\nprint(f'{noisy_train_labels.shape[0]} noisy training samples.')\nprint(f'{test_labels.shape[0]} test samples.')\n\ncurated_train_wav_paths = '../data/train/curated/wav/' + curated_train_labels.index.values\nnoisy_train_wav_paths = '../data/train/noisy/wav/' + noisy_train_labels.index.values\ntest_wav_paths = '../data/test/wav/' + test_labels.index.values\n\nuse_parallel = True\n\nif use_parallel:\n    extract_parallel(curated_train_wav_paths, save_folder='../data/train/curated', save=True)\n#     extract_parallel(noisy_train_wav_paths, save_folder='../data/train/noisy', save=True)\n    extract_parallel(test_wav_paths, save_folder='../data/test', save=True)   \nelse:\n    extract_serie(curated_train_wav_paths, save_folder='../data/train/curated', save=True)\n#     extract_serie(noisy_train_wav_paths, save_folder='../data/train/noisy', save=True)\n    extract_serie(test_wav_paths, save_folder='../data/test', save=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!zip -rq curated_train_logmel.zip ../data/train/curated/logmel\n# !zip -r noisy_train_logmel.zip ../data/train/noisy/logmel\n!zip -rq test_logmel.zip ../data/test/logmel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!du -m curated_train_logmel.zip\n# !du -m noisy_train_logmel.zip\n!du -m test_logmel.zip","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}