{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir('../input/sc2datawithoutaug')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf_noisy=pd.read_csv('../input/freesound-audio-tagging-2019/train_noisy.csv',dtype=str)\n\ntraindf_curated=pd.read_csv('../input/freesound-audio-tagging-2019/train_curated.csv',dtype=str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf_noisy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_label=[]\ntemp_fname=[]\n\nfor file in os.listdir(\"../input/sc2datawithoutaug/Curated without AUG/Curated without AUG/curated_train\"):\n    temp_fname.append(file)\n    if len(file.split(\"_\"))==1:\n         temp=file.split(\".\")[0]+\".wav\"\n    elif len(file.split(\"_\"))==2:  \n        temp=file.split(\"_\")[0]+\".wav\" \n    try:   \n        label=traindf_noisy[traindf_noisy[\"fname\"]==temp].iloc[0][\"labels\"]\n    except IndexError:    \n        label=traindf_curated[traindf_curated[\"fname\"]==temp].iloc[0][\"labels\"]\n    temp_label.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.DataFrame({'fname':temp_fname, 'labels':temp_label})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_label=[]\ntemp_fname=[]\n\nfor file in os.listdir(\"../input/sc2datawithoutaug/Curated without AUG/Curated without AUG/curated_cv\"):\n    temp_fname.append(file)\n    if len(file.split(\"_\"))==1:\n         temp=file.split(\".\")[0]+\".wav\"\n    elif len(file.split(\"_\"))==2:  \n        temp=file.split(\"_\")[0]+\".wav\" \n    try:   \n        label=traindf_noisy[traindf_noisy[\"fname\"]==temp].iloc[0][\"labels\"]\n    except IndexError:    \n        label=traindf_curated[traindf_curated[\"fname\"]==temp].iloc[0][\"labels\"]\n    temp_label.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_df = pd.DataFrame({'fname':temp_fname, 'labels':temp_label})\ncv_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_label=[]\ntemp_fname=[]\n\nfor file in os.listdir(\"../input/sc2datawithoutaug/Curated without AUG/Curated without AUG/curated_test\"):\n    temp_fname.append(file)\n    if len(file.split(\"_\"))==1:\n         temp=file.split(\".\")[0]+\".wav\"\n    elif len(file.split(\"_\"))==2:  \n        temp=file.split(\"_\")[0]+\".wav\" \n    try:   \n        label=traindf_noisy[traindf_noisy[\"fname\"]==temp].iloc[0][\"labels\"]\n    except IndexError:    \n        label=traindf_curated[traindf_curated[\"fname\"]==temp].iloc[0][\"labels\"]\n    temp_label.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \ntest_df = pd.DataFrame({'fname':temp_fname, 'labels':temp_label})    \ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb_train = MultiLabelBinarizer()\n\n\nlabels_train = mlb_train.fit_transform([ i.split(\",\") for i in list(train_df[\"labels\"])])\n\n\nlabels_test = mlb_train.transform([ i.split(\",\") for i in list(test_df[\"labels\"])])\n\n\n#mlb_cv = MultiLabelBinarizer()\nlabels_cv = mlb_train.transform([ i.split(\",\") for i in list(cv_df[\"labels\"])])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainmultidf=pd.DataFrame(data=labels_train,columns=list(mlb_train.classes_))\ntrainmultidf[\"fname\"]=list(train_df[\"fname\"])\n\ntestmultidf=pd.DataFrame(data=labels_test,columns=list(mlb_train.classes_))\ntestmultidf[\"fname\"]=list(test_df[\"fname\"])\n\n\ncvmultidf=pd.DataFrame(data=labels_cv,columns=list(mlb_train.classes_))\ncvmultidf[\"fname\"]=list(cv_df[\"fname\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We change the ids for the images in the csv files to reflect their new status as jpgs\n#https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\nfrom keras_preprocessing.image import ImageDataGenerator\n\n\n\ndatagen=ImageDataGenerator(rescale=1./255.)\n\n\ntrain_generator=datagen.flow_from_dataframe(\n    dataframe=trainmultidf,\n    directory=\"../input/sc2datawithoutaug/Curated without AUG/Curated without AUG/curated_train\",\n    x_col=\"fname\",\n    y_col=list(mlb_train.classes_),\n    subset=\"training\",\n    batch_size=64,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\",\n    #color_mode=\"grayscale\",\n    target_size=(64,64))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvmultidf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvmultidf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvalid_datagen=ImageDataGenerator(rescale=1./255.)\n\nvalid_generator=valid_datagen.flow_from_dataframe(\n    dataframe=cvmultidf,\n    directory=\"../input/sc2datawithoutaug/Curated without AUG/Curated without AUG/curated_cv\",\n    x_col=\"fname\",\n    y_col=list(mlb_train.classes_),\n   # subset=\"validation\",\n    batch_size=64,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\",\n    #color_mode=\"grayscale\",\n    target_size=(64,64))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvmultidf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen=ImageDataGenerator(rescale=1./255.)\ntest_generator=test_datagen.flow_from_dataframe(\n    dataframe=testmultidf,\n    directory=\"../input/sc2datawithoutaug/Curated without AUG/Curated without AUG/curated_test\",\n    x_col=\"fname\",\n    y_col=None,\n    batch_size=64,\n    seed=42,\n    shuffle=False,\n    class_mode=None,\n   # color_mode=\"grayscale\",\n    target_size=(64,64))\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\n\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import sequence\n\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n#from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping \nfrom tensorflow.keras.layers import Dense, Flatten, LSTM, Conv2D, MaxPooling2D, Dropout, Activation, Input,BatchNormalization, AveragePooling2D,GlobalMaxPool2D,PReLU\n\nfrom tensorflow.keras.models import model_from_json  \nfrom tensorflow.keras.applications import DenseNet169\n\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#last_layer = model.get_layer('avg_pool').output\n\nimage_input = Input(shape=(64, 64, 3))\nmodel = DenseNet169(input_tensor=image_input, include_top=True)\nlast_layer = model.get_layer('avg_pool').output\nx= Flatten(name='flatten')(last_layer)\n#model=\n\n\n#output = Dense(80, activation='sigmoid', name='output_layer')(model.layers[-2].output)\nx= Dense(80)(x)\noutput = Activation('sigmoid')(x)\n#out = Dense(num_classes, activation='softmax', name='output_layer')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[-4:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[-4:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_densenet169_model = Model(inputs=image_input,outputs= output)\ncustom_densenet169_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_densenet169_model.load_weights(\"../input/sc2newfinalweights/NoisyTotal.best_weights_loss.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from tensorflow.keras.utils import plot_model\n#plot_model(custom_densenet169_model, 'model_resnet50.png', show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(lr=0.0009)#tf.keras.optimizers.RMSprop(lr=0.3, decay=1e-6) \n#tf.keras.optimizers.Adam(lr=0.001)#RMSprop(lr=0.0001, decay=1e-6)\n\n# Let's train the model using RMSprop\ncustom_densenet169_model.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM,label_smoothing=0.2),#label_smoothing=0.7#'categorical_crossentropy',\n              optimizer=opt,\n               metrics=['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting keras model, no test gen for now\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# simple early stopping\n#earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100,)\n#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n\n\n#model_checkpoint = ModelCheckpoint('weights_cnn_lstm.best.hdf5', monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n\n\ncsv_logger = CSVLogger(filename='../working/training_log.csv',\n                       separator=',',\n                       append=True)\n#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.6,\n                              patience=6, min_lr=0,verbose=1)\n\n\nmodel_checkpoint = ModelCheckpoint(\"NoisyTotal.best_weights.hdf5\", monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n\n# fit model\n\n#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.001 )\nes = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=30, min_delta=0.001 )\n\ncallbacks_list = [model_checkpoint, csv_logger, reduceLROnPlat,es]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#custom_densenet169_model.load_weights(\"../input/sc2weights/total.best_weights.hdf5\")\n#custom_densenet169_model.load_weights(\"../input/sc2weights/total.best_weights_iter2.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=custom_densenet169_model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=300,\n                    callbacks=callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\n#epochs = np.range(1,1)\nplt.plot(loss_train, 'g', label='Training loss')\nplt.plot(loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = history.history['categorical_accuracy']\nloss_val = history.history['val_categorical_accuracy']\nepochs = range(1,41)\nplt.plot(loss_train, 'g', label='Training accuracy')\nplt.plot(loss_val, 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = custom_densenet169_model.predict_generator(valid_generator, verbose=1)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\nres_test=custom_densenet169_model.predict_generator(test_generator,\n#steps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator.reset()\nres_cv=custom_densenet169_model.predict_generator(valid_generator,\n#steps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.reset()\nres_train=custom_densenet169_model.predict_generator(train_generator,\n#steps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting taget and identity columns to booleans\n\ntarget_columns=list(trainmultidf.columns)[:-1]\n\ndef convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n    \ndef convert_dataframe_to_bool(df):\n    bool_df = df.copy()\n    for col in target_columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\ntest_bool = convert_dataframe_to_bool(testmultidf) \ntest_lable_bool=test_bool[list(test_bool.columns)[:-1]].to_numpy()\n\ntrain_bool = convert_dataframe_to_bool(trainmultidf) \ntrain_lable_bool=train_bool[list(train_bool.columns)[:-1]].to_numpy()\n\ncv_bool = convert_dataframe_to_bool(cvmultidf) \ncv_lable_bool=cv_bool[list(cv_bool.columns)[:-1]].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_lable_bool.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Metric","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport sklearn.metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Core calculation of label precisions for one test sample.\n\ndef _one_sample_positive_class_precisions(scores, truth):\n  \"\"\"Calculate precisions for each true class for a single sample.\n  \n  Args:\n    scores: np.array of (num_classes,) giving the individual classifier scores.\n    truth: np.array of (num_classes,) bools indicating which classes are true.\n\n  Returns:\n    pos_class_indices: np.array of indices of the true classes for this sample.\n    pos_class_precisions: np.array of precisions corresponding to each of those\n      classes.\n  \"\"\"\n  num_classes = scores.shape[0]\n  pos_class_indices = np.flatnonzero(truth > 0)\n  # Only calculate precisions if there are some true classes.\n  if not len(pos_class_indices):\n    return pos_class_indices, np.zeros(0)\n  # Retrieval list of classes for this sample. \n  retrieved_classes = np.argsort(scores)[::-1]\n  # class_rankings[top_scoring_class_index] == 0 etc.\n  class_rankings = np.zeros(num_classes, dtype=np.int)\n  class_rankings[retrieved_classes] = range(num_classes)\n  # Which of these is a true label?\n  retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n  retrieved_class_true[class_rankings[pos_class_indices]] = True\n  # Num hits for every truncated retrieval list.\n  retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n  # Precision of retrieval list truncated at each hit, in order of pos_labels.\n  precision_at_hits = (\n      retrieved_cumulative_hits[class_rankings[pos_class_indices]] / \n      (1 + class_rankings[pos_class_indices].astype(np.float)))\n  return pos_class_indices, precision_at_hits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All-in-one calculation of per-class lwlrap.\n\ndef calculate_per_class_lwlrap(truth, scores):\n  \"\"\"Calculate label-weighted label-ranking average precision.\n  \n  Arguments:\n    truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n      of presence of that class in that sample.\n    scores: np.array of (num_samples, num_classes) giving the classifier-under-\n      test's real-valued score for each class for each sample.\n  \n  Returns:\n    per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each \n      class.\n    weight_per_class: np.array of (num_classes,) giving the prior of each \n      class within the truth labels.  Then the overall unbalanced lwlrap is \n      simply np.sum(per_class_lwlrap * weight_per_class)\n  \"\"\"\n  assert truth.shape == scores.shape\n  num_samples, num_classes = scores.shape\n  # Space to store a distinct precision value for each class on each sample.\n  # Only the classes that are true for each sample will be filled in.\n  precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n  for sample_num in range(num_samples):\n    pos_class_indices, precision_at_hits = (\n      _one_sample_positive_class_precisions(scores[sample_num, :], \n                                            truth[sample_num, :]))\n    precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n        precision_at_hits)\n  labels_per_class = np.sum(truth > 0, axis=0)\n  weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n  # Form average of each column, i.e. all the precisions assigned to labels in\n  # a particular class.\n  per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) / \n                      np.maximum(1, labels_per_class))\n  # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n  #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n  #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n  #                = np.sum(per_class_lwlrap * weight_per_class)\n  return per_class_lwlrap, weight_per_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the overall lwlrap using sklearn.metrics function.\n\ndef calculate_overall_lwlrap_sklearn(truth, scores):\n  \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n  # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n  sample_weight = np.sum(truth > 0, axis=1)\n  nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n  overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n      truth[nonzero_weight_sample_indices, :] > 0, \n      scores[nonzero_weight_sample_indices, :], \n      sample_weight=sample_weight[nonzero_weight_sample_indices])\n  return overall_lwlrap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accumulator object version.\n\nclass lwlrap_accumulator(object):\n  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"  \n\n  def __init__(self):\n    self.num_classes = 0\n    self.total_num_samples = 0\n  \n  def accumulate_samples(self, batch_truth, batch_scores):\n    \"\"\"Cumulate a new batch of samples into the metric.\n    \n    Args:\n      truth: np.array of (num_samples, num_classes) giving boolean\n        ground-truth of presence of that class in that sample for this batch.\n      scores: np.array of (num_samples, num_classes) giving the \n        classifier-under-test's real-valued score for each class for each\n        sample.\n    \"\"\"\n    assert batch_scores.shape == batch_truth.shape\n    num_samples, num_classes = batch_truth.shape\n    if not self.num_classes:\n      self.num_classes = num_classes\n      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n      self._per_class_cumulative_count = np.zeros(self.num_classes, \n                                                  dtype=np.int)\n    assert num_classes == self.num_classes\n    for truth, scores in zip(batch_truth, batch_scores):\n      pos_class_indices, precision_at_hits = (\n        _one_sample_positive_class_precisions(scores, truth))\n      self._per_class_cumulative_precision[pos_class_indices] += (\n        precision_at_hits)\n      self._per_class_cumulative_count[pos_class_indices] += 1\n    self.total_num_samples += num_samples\n\n  def per_class_lwlrap(self):\n    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n    return (self._per_class_cumulative_precision / \n            np.maximum(1, self._per_class_cumulative_count))\n\n  def per_class_weight(self):\n    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n    return (self._per_class_cumulative_count / \n            float(np.sum(self._per_class_cumulative_count)))\n\n  def overall_lwlrap(self):\n    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n    return np.sum(self.per_class_lwlrap() * self.per_class_weight())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/voglinio/keras-2d-model-5-fold-log-specgram-curated-only\ntruth = test_lable_bool\nscores = res_test\nprint(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"truth = train_lable_bool\nscores = res_train\nprint(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"truth = cv_lable_bool\nscores = res_cv\nprint(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SUBMISSION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_dataframe = pd.DataFrame({'fname':os.listdir('../input/sc2datawithoutaug/sub2/sub2')})\n\nsub_datagen=ImageDataGenerator(rescale=1./255.)\nsub_generator=sub_datagen.flow_from_dataframe(\n    dataframe=sub_dataframe,\n    directory=\"../input/sc2datawithoutaug/sub2/sub2\",\n    x_col=\"fname\",\n    y_col=None,\n    batch_size=64,\n    seed=42,\n    shuffle=False,\n    class_mode=None,\n    target_size=(64,64))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_SUB=sub_generator.n//sub_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_generator.reset()\nres_sub=custom_densenet169_model.predict_generator(sub_generator,\n#steps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data=pd.DataFrame(res_sub.astype(\"float64\"), columns=list(mlb_train.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data.insert(0, 'fname', os.listdir('../input/sc2datawithoutaug/sub2/sub2'))\nsubmit_data[\"fname\"]=submit_data[\"fname\"].apply(lambda x: x.split(\".\")[0]+\".wav\")\nsubmit_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data.to_csv(\"submissionCurated.csv\",index=False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}