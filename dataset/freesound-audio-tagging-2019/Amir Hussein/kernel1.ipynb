{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np  \nimport pandas as pd \nimport numpy as np \nimport pandas as pd \nimport os\nimport glob\nimport pickle\nfrom sklearn.model_selection import train_test_split \nimport librosa as lbr\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\nimport os\nimport librosa.display\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"INPUT_FOLDER = \"../input/\"\ntrain_files = glob.glob(\"../input/train_curated/*.wav\")\nprint(os.listdir(INPUT_FOLDER))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nTRAIN_CURATED_PATH = INPUT_FOLDER + \"train_curated.csv\"\nTRAIN_NOISY_PATH = INPUT_FOLDER + \"train_noisy.csv\"\nSAMPLE_SUBMISSION_PATH = INPUT_FOLDER + \"sample_submission.csv\"\nTRAIN_CURATED = INPUT_FOLDER + \"train_curated/\"\nTRAIN_NOISY = INPUT_FOLDER + \"train_noisy/\"\nTEST = INPUT_FOLDER + \"test/\"\n\ntrain_curated = pd.read_csv(TRAIN_CURATED_PATH)\ntrain_noisy = pd.read_csv(TRAIN_NOISY_PATH)\ntest = pd.read_csv(SAMPLE_SUBMISSION_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of train examples=\", train_curated.shape[0], \"  Number of classes=\", len(set(train_curated.labels)))\nprint(\"Number of test examples=\", test.shape[0], \"  Number of classes=\", len(set(test.columns[1:])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that the number of classes in training curated is much larger than in testing file"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load both train_curated and noisy\n# train_curated['is_curated'] = True\n# train_noisy = pd.read_csv('../input/train_noisy.csv')\n# train_noisy['is_curated'] = False\n#train = pd.concat([train_curated, train_noisy], axis=0)\n#del train_noisy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get only the lables that are in the testing file\n#train is for one lable per class data, train_curated is the multilabel dataset\ntrain = train_curated[train_curated.labels.isin(test.columns[1:])]\nprint(len(train))\ncategory_group = train.groupby(['labels']).count()['fname']\ncategory_group.columns = ['counts']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = category_group.sort_values(ascending=True).plot(\n    kind='barh', \n    title=\"Number of Audio Samples per Category\", \n    figsize=(20,20))\nplot.set_xlabel(\"Category\")\nplot.set_ylabel(\"Number of Samples\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Minimum samples per category = ', min(train.labels.value_counts()))\nprint('Maximum samples per category = ', max(train.labels.value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using wave library\nimport wave\nfname = '../input/train_curated/0164cba5.wav'   # Raindrop\nwav = wave.open(fname)\nprint(\"Sampling (frame) rate = \", wav.getframerate())\nprint(\"Total samples (frames) = \", wav.getnframes())\nprint(\"Duration = \", wav.getnframes()/wav.getframerate())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(labels, src_dict):\n    ar = np.zeros([len(labels), len(src_dict)])\n    invalid=['77b925c2.wav','f76181c4.wav', '6a1f682a.wav', 'c7db12aa.wav', '7752cc8a.wav','1d44b0bd.wav']\n    for i, label in enumerate(labels): \n        if label not in invalid:\n            label_list = label.split(',')\n            for la in label_list:\n                ar[i, src_dict[la]] = 1\n    return ar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#chacking the multilables\n[label.split(',') for i, label in enumerate(train['labels']) if len(label.split(',')) >=2] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get target names from test \ntarget_names = test.columns[1:]\ntarget_names.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_targets = len(target_names)\n\nsrc_dict = {target_names[i]:i for i in range(num_targets)}\nsrc_dict_inv = {i:target_names[i] for i in range(num_targets)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyze the lengths of the audio files in our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['nframes'] = train['fname'].apply(lambda f: wave.open('../input/train_curated/' + f).getnframes())\n# test1 = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n# test1['nframes'] = test1['fname'].apply(lambda f: wave.open('../input/test/' + f).getnframes())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('maximum track duration: ', train['nframes'].max()/44100)\nprint('minimum track duration: ', train['nframes'].min()/44100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of top 25 categories\nimport seaborn as sns\nidx_sel = category_group.sort_values(ascending=True).index[-25:]\n_, ax = plt.subplots(figsize=(20, 4))\nsns.violinplot(ax=ax, x=\"labels\", y=\"nframes\", data=train[(train.labels.isin(idx_sel).values)])\nplt.xticks(rotation=90)\nplt.title('Distribution of audio frames, per label', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyze the frame length distribution in train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(16,8))\ntrain.nframes.hist(bins=100, grid=True, rwidth=0.5, ax=ax[0], color='deeppink')\ntest.nframes.hist(bins=100, grid=True, rwidth=0.5, ax=ax[1], color='darkslateblue')\nax[0].set_xlim(0, 2700000)\nax[1].set_xlim(0, 2700000)\nplt.suptitle('Frame Length Distribution in train and test', ha='center', fontsize='large');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Note:\nMajority of the audio files are short."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.query(\"nframes > 2500000\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Listen to the audio"},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as ipd  # To play sound in the notebook\nfname = '../input/train_curated/77b925c2.wav'   # Abnormal\nipd.Audio(fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the files with label \"Stream\" and compare to abnormal\ntrain[train[\"labels\"]==\"Stream\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding\ny_proc_tmp = one_hot(train_curated['labels'], src_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Spectrogram Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"song='../input/train_curated/ca5c5f2c.wav'\naudio, sample_rate=lbr.load(song,sr=44100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fft = int(0.025 * sample_rate) #25ms window length\nhop_length =  n_fft//2\nN_MELS = 128 #frequency bins\n#X = lbr.stft(audio[0], n_fft=n_fft, hop_length=hop_length)\nX=lbr.feature.melspectrogram(audio,n_fft=n_fft, hop_length=hop_length,n_mels=N_MELS )\nS = lbr.amplitude_to_db(abs(X))\n#S=np.log(X)\nplt.figure(figsize=(15, 5))\nlbr.display.specshow(S, sr=44100, hop_length=hop_length, x_axis='time',cmap='magma')\nplt.colorbar(format='%+2.0f dB')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"signal = audio[0:int(1 * sample_rate)] #5 secs of audio\nplt.plot(signal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load data and extract spectrogram features"},{"metadata":{"trusted":true},"cell_type":"code","source":"WINDOW_SIZE = int(0.025 * sample_rate) #window size 25ms             \nWINDOW_STRIDE = WINDOW_SIZE // 2 #overlap 50%\nN_MELS = 128  #frequencies\n\nMEL_KWARGS = {\n    'n_fft': WINDOW_SIZE,\n    'hop_length': WINDOW_STRIDE,\n    'n_mels': N_MELS \n}\n\ndef load_track(filename, enforce_shape=None):\n    new_input, sample_rate = lbr.load(filename, mono=True,sr= 44100)\n    features = lbr.feature.melspectrogram(new_input, **MEL_KWARGS).T\n    if enforce_shape is not None:\n        if features.shape[0] < enforce_shape[0]:\n            delta_shape = (enforce_shape[0] - features.shape[0],\n                    enforce_shape[1])\n            features = np.append(features, np.zeros(delta_shape), axis=0)\n        elif features.shape[0] > enforce_shape[0]:\n            features = features[: enforce_shape[0], :]\n\n    features[features == 0] = 1e-6\n    return (features, float(new_input.shape[0]) / sample_rate)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building a model using MFCC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Dropout, Activation, \\\n         Convolution1D, MaxPooling1D, BatchNormalization, Flatten,GlobalAveragePooling1D\nimport scipy\nfrom keras import losses\nfrom keras import backend as K\nfrom keras.activations import relu, softmax\nfrom keras.callbacks import (EarlyStopping, LearningRateScheduler,\n                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\nfrom keras.utils import Sequence\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config(object):\n    def __init__(self,\n                 sampling_rate=44100, audio_duration=2, #audio duration: specify length of the track in sec\n                 n_classes=target_names,\n                 use_mfcc=True, n_folds=1, learning_rate=0.0001, \n                 max_epochs=30, n_mfcc=64):\n        self.sampling_rate = sampling_rate\n        self.audio_duration = audio_duration\n        self.n_classes = n_classes\n        self.use_mfcc = use_mfcc\n        self.n_mfcc = n_mfcc\n        self.n_folds = n_folds\n        self.learning_rate = learning_rate\n        self.max_epochs = max_epochs\n        self.win_len= int(0.025 * sample_rate) #10ms window length\n\n        self.audio_length = self.sampling_rate * self.audio_duration\n        if self.use_mfcc:\n            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/self.win_len)*2))\n        else:\n            self.dim = (self.audio_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lwrap implementation for keras\ndef tf_one_sample_positive_class_precisions(y_true, y_pred) :\n    num_samples, num_classes = y_pred.shape\n    \n    # find true labels\n    pos_class_indices = tf.where(y_true > 0) \n    \n    # put rank on each element\n    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n    sample_range = tf.transpose(sample_range)\n    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n    retrieved_class_map = tf.transpose(retrieved_class_map)\n    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n    \n    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n    \n    class_rankings = tf.scatter_nd(retrieved_class_map,\n                                          class_range,\n                                          tf.shape(y_pred))\n    \n    #pick_up ranks\n    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n\n    # add one for division for \"presicion_at_hits\"\n    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n    \n    # generate tensor [num_sample, predict_rank], \n    # top-N predicted elements have flag, N is the number of positive for each sample.\n    sample_label = pos_class_indices[:, 0]   \n    sample_label = tf.reshape(sample_label, (-1, 1))\n    sample_label = tf.cast(sample_label, tf.int32)\n    \n    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n    retrieved_class_true_position = tf.concat((sample_label, \n                                               num_correct_until_correct), axis=1)\n    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n                                         retrieved_pos, \n                                         tf.shape(y_pred))\n    # cumulate predict_rank\n    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n\n    # find positive position\n    pos_ret_indices = tf.where(retrieved_class_true > 0)\n\n    # find cumulative hits\n    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n    correct_rank = tf.cast(correct_rank, tf.float32)\n\n    # compute presicion\n    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n    return pos_class_indices, precision_at_hits\n\ndef tf_lwlrap(y_true, y_pred):\n    num_samples, num_classes = y_pred.shape\n    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n    pos_flgs = tf.cast(y_true > 0, tf.int32)\n    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n    class_label = pos_class_indices[:,1]\n    sum_precisions_by_classes = tf.unsorted_segment_sum(precision_at_hits,\n                                                        class_label,\n                                                       num_classes)\n    labels_per_class = tf.cast(labels_per_class, tf.float32)\n    labels_per_class = tf.add(labels_per_class, 1e-7)\n    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n                                  tf.cast(labels_per_class, tf.float32))\n    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def audio_norm(data):\n#     max_data = np.max(data)\n#     min_data = np.min(data)\n#     data = (data-min_data)/(max_data-min_data+1e-6)\n#     return data - 0.5\n    data = ( data - np.mean(data) ) / np.std(data)\n   # data /= np.max(data)\n    return data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = Config(sampling_rate=44100, audio_duration=3, n_folds=1, learning_rate=0.001, use_mfcc=True, n_mfcc=128,max_epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(config):\n    \n    nclass = len(config.n_classes)\n    input_length = config.audio_length\n    input_shape = (config.dim[1],config.dim[0])\n    print(input_shape)\n    rate=0.2\n    model_input = Input(input_shape, name='input')\n    layer = model_input\n    layer = Convolution1D(filters= 32, kernel_size= 5 ,activation=tf.nn.leaky_relu,name='convolution_1' , strides=2,padding='same')(layer)\n#     layer = BatchNormalization()(layer) #momentum=0.9\n    layer=MaxPooling1D(2, strides=2,padding='same')(layer)\n    layer = Dropout(rate)(layer)\n    \n    layer = Convolution1D(filters= 64, kernel_size= 3 ,activation=tf.nn.leaky_relu,name='convolution_2' , strides=2 ,padding='same')(layer)\n#     layer = BatchNormalization()(layer)\n    layer=MaxPooling1D(2, strides=2,padding='same')(layer)\n    layer = Dropout(rate)(layer)\n    \n    \n    layer = Convolution1D(filters= 128, kernel_size= 3 ,activation=tf.nn.leaky_relu,name='convolution_4', strides=1,padding='same' )(layer)\n#     layer = BatchNormalization()(layer)\n    layer=MaxPooling1D(2, strides=2,padding='same')(layer)\n    layer = Dropout(rate)(layer)\n    \n    layer = Convolution1D(filters= 256, kernel_size= 3,activation=tf.nn.leaky_relu,name='convolution_5',strides=1,padding='same')(layer)\n#     layer = BatchNormalization()(layer)\n    layer=MaxPooling1D(2, strides=2,padding='same')(layer)\n    layer = Dropout(rate)(layer)\n    layer = Flatten()(layer)\n    \n    layer = Dense(256)(layer)\n    layer = Dense(nclass)(layer)\n    \n    output = Activation('softmax', name='Final_output')(layer)\n    model = Model(model_input, output)\n   # opt = Adam(lr=config.learning_rate)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf_lwlrap])\n    return model\n\n  \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"preparing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(df, config, data_dir):\n    WINDOW_SIZE = int(0.025 * sample_rate) #window size 10ms             \n    WINDOW_STRIDE = WINDOW_SIZE // 2 #overlap 50%\n    N_MELS = 128  #frequencies\n\n    MEL_KWARGS = {\n        'n_fft': WINDOW_SIZE,\n        'hop_length': WINDOW_STRIDE,\n        'n_mels': N_MELS \n    }\n    X = np.empty(shape=(df.shape[0], config.dim[1], config.dim[0]))\n    input_length = config.audio_length\n   # print(X.shape)\n    n_fft = int(0.025 * sample_rate) #10ms window length\n    hop_length =  n_fft//2\n    N_MELS = 128 #frequency bins\n    \n \n    invalid=['77b925c2.wav','f76181c4.wav', '6a1f682a.wav', 'c7db12aa.wav', '7752cc8a.wav','1d44b0bd.wav']\n    for i, fname in enumerate(df.index):\n            \n            if fname not in invalid:\n                \n                file_path = data_dir + fname\n                data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n\n               # print('data_shape: ',data.shape)\n                # Random offset / Padding\n                if len(data) > input_length:\n                    max_offset = len(data) - input_length\n                    offset = np.random.randint(max_offset)\n                    data = data[offset:(input_length+offset)]\n                else:\n                    if input_length > len(data):\n                        max_offset = input_length - len(data)\n                        offset = np.random.randint(max_offset)\n                    else:\n                        offset = 0\n                    #pad with zeros\n                    data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n                #print('before spec: ',data.shape)\n               # data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc,**MEL_KWARGS).T\n                data = librosa.feature.melspectrogram(data,**MEL_KWARGS).T\n                data = lbr.amplitude_to_db(abs(data))\n                #print('after padding')\n               # print(data.shape)\n                X[i,] = data\n            else:\n                print(fname)\n    return X\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated.set_index(\"fname\", inplace=True)\ntest.set_index('fname',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nX_train = prepare_data(train_curated, config, '../input/train_curated/')\nX_test = prepare_data(test, config, '../input/test/')\ny = one_hot(train_curated['labels'], src_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = audio_norm(X_train)\nX_test = audio_norm(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PREDICTION_FOLDER = \"predictions_1d_conv\"\nif not os.path.exists(PREDICTION_FOLDER):\n    os.mkdir(PREDICTION_FOLDER)\nif os.path.exists('logs/' + PREDICTION_FOLDER):\n    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n    \nK.clear_session()\ncheckpoint = ModelCheckpoint('best.h5', monitor='val_loss', verbose=1, save_best_only=True)\n#early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=7)\ntb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold', write_graph=True)\ncallbacks_list = [checkpoint, tb]\nmodel = build_model(config)\nhistory = model.fit(X, y, callbacks=callbacks_list,batch_size=128, epochs=50)\n#model.load_weights('best.h5')\n\n# # Save train predictions\n# predictions = model.predict(X_train, batch_size=64, verbose=1)\n# np.save(PREDICTION_FOLDER + \"/train_predictions.npy\", predictions)\n\n# # Save test predictions\n# predictions = model.predict(X_test, batch_size=64, verbose=1)\n# np.save(PREDICTION_FOLDER + \"/test_predictions.npy\", predictions)\n\n# # Make a submission file\n# top_3 = np.array(config.n_classes)[np.argsort(-predictions, axis=1)[:, :3]]\n# predicted_labels = [' '.join(list(x)) for x in top_3]\n# test['label'] = predicted_labels\n# test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions.csv\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission= model.predict(X_test, batch_size=64, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output all random to see a baseline\nsample_sub = pd.read_csv('../input/sample_submission.csv')\nsample_sub.iloc[:,1:] = submission\nsample_sub.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"working_dir='../working/predictions_1d_conv/'\nos.listdir(working_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv(working_dir+'sample_submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=pd.read_csv(working_dir+'predictions.csv')\npred1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.load(working_dir+'test_predictions.npy')\npred.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ignore the following code"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\nclass DataGenerator(Sequence):\n    def __init__(self, config, data_dir, list_IDs, labels=None, \n                 batch_size=64, preprocessing_fn=lambda x: x):\n        self.config = config\n        self.data_dir = data_dir\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.preprocessing_fn = preprocessing_fn\n        self.on_epoch_end()\n        self.dim = self.config.dim\n\n    def __len__(self):\n        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        return self.__data_generation(list_IDs_temp)\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n\n    def __data_generation(self, list_IDs_temp):\n        cur_batch_size = len(list_IDs_temp)\n        X = np.empty((cur_batch_size, *self.dim))\n\n        input_length = self.config.audio_length\n        for i, ID in enumerate(list_IDs_temp):\n            file_path = self.data_dir + ID\n            \n            # Read and Resample the audio\n            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate,\n                                        res_type='kaiser_fast')\n\n            # Random offset / Padding\n            if len(data) > input_length:\n                max_offset = len(data) - input_length\n                offset = np.random.randint(max_offset)\n                data = data[offset:(input_length+offset)]\n            else:\n                if input_length > len(data):\n                    max_offset = input_length - len(data)\n                    offset = np.random.randint(max_offset)\n                else:\n                    offset = 0\n                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n                \n            # Normalization + Other Preprocessing\n            if self.config.use_mfcc:\n                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate,\n                                                   n_mfcc=self.config.n_mfcc)\n                data = np.expand_dims(data, axis=-1)\n            else:\n                data = self.preprocessing_fn(data)[:, np.newaxis]\n            X[i,] = data\n\n        if self.labels is not None:\n            y = np.empty(cur_batch_size, dtype=int)\n            for i, ID in enumerate(list_IDs_temp):\n                y[i] = self.labels[ID]\n            return X, to_categorical(y, num_classes=self.config.n_classes)\n        else:\n            return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"working_dir='../working/predictions_1d_conv/'\nos.listdir(working_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=pd.read_csv(working_dir+'predictions_1.csv')\npred1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.load(working_dir+'test_predictions_0.npy')\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(config, '../input/train_curated/', train_set.index, \n                                    train_set.label_idx, batch_size=64,\n                                    preprocessing_fn=audio_norm)\n    val_generator = DataGenerator(config, '../input/train_curated/', val_set.index, \n                                  val_set.label_idx, batch_size=64,\n                                  preprocessing_fn=audio_norm)\n    \n    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n                                  epochs=config.max_epochs, use_multiprocessing=True, max_queue_size=20)\n    \n#     model.load_weights('../working/best_%d.h5'%i)\n    \n    # Save train predictions\n    train_generator = DataGenerator(config, '../input/train_curated/', train.index, batch_size=128,\n                                    preprocessing_fn=audio_norm)\n    predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n                                          max_queue_size=20, verbose=1)\n    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n    \n    # Save test predictions\n    test_generator = DataGenerator(config, '../input/test/', test.index, batch_size=128,\n                                    preprocessing_fn=audio_norm)\n    predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n                                          max_queue_size=20, verbose=1)\n    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n    \n    # Make a submission file\n    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n    predicted_labels = [' '.join(list(x)) for x in top_3]\n    test['label'] = predicted_labels\n    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions.csv\"%)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_list = []\nfor i in range(config.n_folds):\n    pred_list.append(np.load(\"../working/predictions_1d_conv/test_predictions_%d.npy\"%i))\nprediction = np.ones_like(pred_list[0])\nfor pred in pred_list:\n    prediction = prediction*pred\nprediction = prediction**(1./len(pred_list))\n# Make a submission file\ntop_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\npredicted_labels = [' '.join(list(x)) for x in top_3]\ntest = pd.read_csv('../input/sample_submission.csv')\ntest['label'] = predicted_labels\ntest[['fname', 'label']].to_csv(\"1d_conv_ensembled_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building a model using MFCC"},{"metadata":{},"cell_type":"markdown","source":"Preparing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PREDICTION_FOLDER = \"predictions_2d_conv\"\nif not os.path.exists(PREDICTION_FOLDER):\n    os.mkdir(PREDICTION_FOLDER)\nif os.path.exists('logs/' + PREDICTION_FOLDER):\n    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n\nskf = StratifiedKFold(n_splits=config.n_folds)\n\nfor i, (train_split, val_split) in enumerate(skf.split(train.index, train.label_idx)):\n    K.clear_session()\n    X, y, X_val, y_val = X_train[train_split], y_train[train_split], X_train[val_split], y_train[val_split]\n    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%i'%i, write_graph=True)\n    callbacks_list = [checkpoint, early, tb]\n    print(\"#\"*50)\n    print(\"Fold: \", i)\n    model = get_2d_dummy_model(config)\n    history = model.fit(X, y, validation_data=(X_val, y_val), callbacks=callbacks_list,  batch_size=64, epochs=config.max_epochs)\n    model.load_weights('best_%d.h5'%i)\n\n    # Save train predictions\n    predictions = model.predict(X_train, batch_size=64, verbose=1)\n    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n\n    # Save test predictions\n    predictions = model.predict(X_test, batch_size=64, verbose=1)\n    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n\n    # Make a submission file\n    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n    predicted_labels = [' '.join(list(x)) for x in top_3]\n    test['label'] = predicted_labels\n    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_list = []\nfor i in range(config.n_folds):\n    pred_list.append(np.load(\"../working/predictions_2d_conv/test_predictions_%d.npy\"%i))\nprediction = np.ones_like(pred_list[0])\nfor pred in pred_list:\n    prediction = prediction*pred\nprediction = prediction**(1./len(pred_list))\n# Make a submission file\ntop_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\npredicted_labels = [' '.join(list(x)) for x in top_3]\ntest = pd.read_csv('../input/sample_submission.csv')\ntest['label'] = predicted_labels\ntest[['fname', 'label']].to_csv(\"2d_conv_ensembled_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"working_dir='../working/predictions_2d_conv/'\nos.listdir(working_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.load(working_dir+'test_predictions_1.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}