{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport wave, IPython\nfrom sklearn import *\nfrom scipy.io import wavfile\nimport gc; gc.enable()\n\ntrain = pd.read_csv('../input/train_curated.csv')\ntrainn = pd.read_csv('../input/train_noisy.csv')\ntest = pd.read_csv('../input/sample_submission.csv')\ntrain.shape, trainn.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train['path'] = train['fname'].map(lambda x: '../input/train_curated/'+x)\ntrainn['path'] = trainn['fname'].map(lambda x: '../input/train_noisy/'+x)\ntest['path'] = test['fname'].map(lambda x: '../input/test/'+x)\n\ntrain['noisy'] = 0; trainn['noisy'] = 1\ntrain = pd.concat((train, trainn), sort=False).reset_index(drop=True)\n\nlabels = [c for c in test.columns if c not in ['path','fname']]\ntrain = train[train['labels'].isin(labels)].reset_index(drop=True)\ntest = test[['path', 'fname']]\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_labels = []\ncut = 100\nfor l in train.labels.unique():\n    norm_labels.append(train[train.labels == l][:cut])\ntrain = pd.concat(norm_labels, sort=False).sample(frac=1).reset_index(drop=True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bumblebee Radio **"},{"metadata":{"trusted":true},"cell_type":"code","source":"waves = \"\"\"3a5b14ee.wav 404712 423984\n7a9cf335.wav 501072 520344\nc421d4a2.wav 289080 308352\naa28de21.wav 231264 250536\n703ac398.wav 19272 38544\n3cbb9c24.wav 57813 77084\n7c20368d.wav 616672 635943\nc6cb06d9.wav 481775 501046\n7f0af3bb.wav 481775 501046\n76caa793.wav 385420 404691\n767b8f3a.wav 635943 655214\na98c3157.wav 231252 250523\n8ddb4c26.wav 0 19271\n3e1d0af4.wav 635943 655214\naca0ce49.wav 578130 597401\"\"\".split('\\n')\nwavesc = []\nfor w in waves:\n    w1, c1, c2 = w.split(' ')\n    c1 = int(c1); c2 = int(c2)\n    nrate, ndata = wavfile.read('../input/train_noisy/'+w1)\n    wavesc.append(ndata[c1:c2])\nwavesc = np.concatenate(wavesc)\nwavfile.write('one_step.wav', 44100, wavesc)\nIPython.display.display(IPython.display.Audio('one_step.wav'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets create some simple features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_short_wave(w, size=1200):\n    rate, data = wavfile.read(w)\n    if len(data) > size:\n        return data[:size]\n    else:\n        print(int((size / len(data))+1), len(data))\n        return np.repeat(data, int((size / len(data))+1))[:size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['nframes'] = train['path'].map(lambda x: wave.open(x).getnframes())\ntrain['short_wave'] = train['path'].map(lambda x: get_short_wave(x))\n\ntest['nframes'] = test['path'].map(lambda x: wave.open(x).getnframes())\ntest['short_wave'] = test['path'].map(lambda x: get_short_wave(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features(df, col='short_wave'):\n    for agg in ['min', 'max', 'sum', 'median', 'mean', 'std', 'skew', 'kurtosis']:\n        df[col+agg] = df[col].map(lambda x: eval('pd.DataFrame(x).' + agg + '(axis=0)')[0])\n        df[col+'a'+agg] = df[col].map(lambda x: eval('pd.DataFrame(x).abs().' + agg + '(axis=0)')[0])\n        \n    df[col+'max_diff'] = df[col+'max'] - df[col+'mean']\n    df[col+'amax_diff'] = df[col+'amax'] - df[col+'amean']\n    \n    df[col+'min_diff'] = df[col+'mean'] - df[col+'min']\n    df[col+'amin_diff'] = df[col+'amean'] - df[col+'amin']\n    \n    df[col+'max_diff2'] = df[col+'max'] - df[col+'median']\n    df[col+'amax_diff2'] = df[col+'amax'] - df[col+'amedian']\n    \n    df[col+'min_diff2'] = df[col+'median'] - df[col+'min']\n    df[col+'amin_diff2'] = df[col+'amedian'] - df[col+'amin']\n    return df\n\ntrain = features(train).fillna(-999)\ntest = features(test).fillna(-999)\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = [c for c in train.columns if c not in ['path','fname', 'noisy', 'labels', 'short_wave']]\nle = preprocessing.LabelEncoder()\ntrain['labels'] = le.fit_transform(train['labels'])\n\nclf1 = ensemble.ExtraTreesClassifier(n_jobs=-1, n_estimators=400, max_features=0.9, random_state=10)\nclf2 = ensemble.RandomForestClassifier(n_jobs=-1, n_estimators=400, max_features=0.9, random_state=9)\n\nsplit = 3000\nclf1.fit(train[col][:split], train['labels'][:split])\nclf2.fit(train[col][:split], train['labels'][:split])\ndef LOL_WRAP(y_true, y_score): return metrics.label_ranking_average_precision_score(y_true, y_score)\n\nprint('ETR LOL_WRAP', LOL_WRAP(pd.get_dummies(train['labels'])[split:], clf1.predict_proba(train[col][split:])))\nprint('RFR LOL_WRAP', LOL_WRAP(pd.get_dummies(train['labels'])[split:], clf2.predict_proba(train[col][split:])))\n\nclf1.fit(train[col], train['labels'])\nclf2.fit(train[col], train['labels'])\n\nsub = clf1.predict_proba(test[col])\nsub += clf2.predict_proba(test[col])\nsub /= 2\n\nsub = pd.DataFrame(sub, columns=le.classes_)\nsub['fname'] = test['fname']\nmissing = [c for c in labels if c not in sub.columns]\nfor c in missing:\n    sub[c] = 0.0\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}