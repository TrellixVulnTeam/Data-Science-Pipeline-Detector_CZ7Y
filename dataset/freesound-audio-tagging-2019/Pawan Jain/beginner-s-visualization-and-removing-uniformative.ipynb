{"cells":[{"metadata":{},"cell_type":"markdown","source":"**If there are any suggestions/changes you would like to see in the Kernel please let me know :). Appreciate every ounce of help!**<br>\n\n<p>Please leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated!. If you like it or it helps you , you can upvote and/or leave a comment :).|"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nfrom tqdm import tqdm\nimport wave\nfrom scipy.io import wavfile\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train_curated.csv\")\ntest = pd.read_csv(\"../input/train_noisy.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of Categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\naudio_type = train['labels'].value_counts().head(30)\nsns.barplot(audio_type.values, audio_type.index)\nfor i, v in enumerate(audio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"Top 30 labels with their frequencies in training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Audio Length\nWe shall now analyze the lengths of the audio files in our dataset of some categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = train.sort_values('labels').reset_index()\ntrain_new['nframes'] = train_new['fname'].apply(lambda f: wave.open('../input/train_curated/' + f).getnframes())\n\ntrain_fname = train_new.head(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(figsize=(16, 4))\nsns.violinplot(ax=ax, x=\"labels\", y=\"nframes\", data=train_fname)\nplt.xticks(rotation=90)\nplt.title('Distribution of audio frames, per label', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Frame lenght distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/train_curated/\"\nfig, axes = plt.subplots(figsize=(16,5))\ntrain_new.nframes.hist(bins=100)\nplt.suptitle('Frame Length Distribution in Train Curated', ha='center', fontsize='large');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now look at some labels waveform "},{"metadata":{"trusted":true},"cell_type":"code","source":"show_df = train.sort_values('labels')\nlabels = show_df['labels'].unique()\n\nfor label in labels[:5]:\n    \n    train_files_inds = show_df['labels'] == label\n\n    rand_inds = np.random.randint(0,show_df['fname'][train_files_inds].count(),5)\n    fnames = show_df['fname'].iloc[rand_inds]\n\n    _, axs = plt.subplots(figsize=(17,4),nrows=1,ncols=5)\n\n    for i,fname in enumerate(fnames):\n        rate, data = wavfile.read(path + fname)\n        axs[i].plot(data, '-', label=fname)\n        axs[i].legend()\n    plt.suptitle(label,x=0.04,y=0.5,horizontalalignment='center', fontsize=15)\n    del rate\n    del data\ndel axs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wordcloud for Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=50, width=600, height=300).generate(' '.join(train.labels))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Labels\", fontsize=35)\nplt.axis(\"off\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove uninformative Part"},{"metadata":{},"cell_type":"markdown","source":"We will look on one example"},{"metadata":{"trusted":true},"cell_type":"code","source":"##https://www.kaggle.com/ilyamich/remove-uninformative-parts-from-the-audio-files\nimport os\n\nTRAIN_PATH = '../input/train_curated/'\ntrain_ids = next(os.walk(TRAIN_PATH))[2]\ntrain_ids[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as ipd\nipd.Audio(TRAIN_PATH + \"8a8110c2.wav\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_rate, audio = wavfile.read(TRAIN_PATH + \"8a8110c2.wav\")\nplt.plot(audio);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the idea is to crop and segment the audio files and leave only the part that contain information.<br>\nFirst wi will normalize the data to be between -1 and 1:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_audio(audio):\n    audio = audio / max(np.abs(audio))\n    return audio","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It measures the power in each segment and based on that decides if this part is a noise.<br>\nAnd returns the start and stop of each segment in the audio"},{"metadata":{"trusted":true},"cell_type":"code","source":"def divide_audio(audio, resolution=100, window_duration=0.1, minimum_power=0.001, sample_rate=44100):    \n    duration = len(audio) / sample_rate #in seconds\n    itterations = int(duration * resolution)\n    step = int(sample_rate / resolution)\n    window_length = np.floor(sample_rate*window_duration)\n    audio_power = np.square(normalize_audio(audio)) / window_length #Normalized power to window duration\n    \n    start = np.array([])\n    stop = np.array([])\n    is_started = False\n    \n    for n in range(itterations):\n        power = np.sum(audio_power[n*step : int(n*step+window_length)])\n        if not is_started and power > minimum_power:\n            start = np.append(start, n*step+window_length/2)\n            is_started = True\n        elif is_started and (power <= minimum_power or n == itterations-1):\n            stop = np.append(stop, n*step+window_length/2)\n            is_started = False\n    \n    if start.size == 0:\n        start = np.append(start, 0)\n        stop = np.append(stop, len(audio))\n        \n    start = start.astype(int)\n    stop = stop.astype(int)\n    return start, stop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start, stop =  divide_audio(audio)\nprint(start)\nprint(stop)\nplt.plot(audio[start[0]:stop[0]]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After some manual tunning it seems that the it works<br>\nNow lets briefly look on more examples:"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['File Name', 'Audio Duration', 'Segment Number']\naudio_segments = pd.DataFrame(columns=columns)\n\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in tqdm(range(40), total=40):\n    random_audio_idxs = np.random.randint(len(train_ids)+1, size=1)[0]\n    _, tmp = wavfile.read(TRAIN_PATH + train_ids[random_audio_idxs])\n    start, stop = divide_audio(tmp)\n    \n    audio_segments = audio_segments.append({'File Name': train_ids[random_audio_idxs],\n                                            'Audio Duration': len(tmp)/sample_rate,\n                                            'Segment Number': len(start)}, ignore_index=True)\n    \n    ax[i//4, i%4].plot(tmp)\n    ax[i//4, i%4].set_title(train_ids[random_audio_idxs])\n    ax[i//4, i%4].get_xaxis().set_ticks([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_segments.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# More To Come. Stayed Tuned !!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}