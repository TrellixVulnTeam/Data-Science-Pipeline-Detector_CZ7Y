{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Freesound Audio Tagging Challenge - 2019**"},{"metadata":{},"cell_type":"markdown","source":"## **Inspired from these Kernels**\n### **https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data?scriptVersionId=3061527**\n### **https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis**\n### **https://www.kaggle.com/dude431/beginner-s-visualization-and-removing-uniformative**"},{"metadata":{},"cell_type":"markdown","source":"## **References**\n### **https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport shutil\nimport wave\nimport IPython\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\nimport sklearn\nfrom scipy.fftpack import fft\nfrom scipy import signal\nfrom scipy.io import wavfile\nSAMPLE_RATE = 44100\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nmatplotlib.style.use('ggplot')\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train_curated.csv\")\ntrain_noisy = pd.read_csv(\"../input/train_noisy.csv\")\ntest = pd.read_csv(\"../input/sample_submission.csv\")\n\ndef explode_str(df, col, sep):\n    s = df[col]\n    i = np.arange(len(s)).repeat(s.str.count(sep) + 1)\n    return df.iloc[i].assign(**{col: sep.join(s).split(sep)})\n\n# def explode_list(df, col):\n#     s = df[col]\n#     i = np.arange(len(s)).repeat(s.str.len())\n#     return df.iloc[i].assign(**{col: np.concatenate(s)})\n\ndef load_wav_file(name, path):\n    _, b = wavfile.read(path + name)\n    assert _ == SAMPLE_RATE\n    return b","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"## **# Train Curated EDA**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"print('Train Curated :')\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# %%time\n# pd.concat([pd.Series(row['fname'], row['labels'].split(','))              \n#                     for _, row in train.iterrows()]).reset_index()\n# CPU times: user 2.27 s, sys: 76 ms, total: 2.35 s\n# Wall time: 2.33 s\nntrain = explode_str(train, 'labels', ',')\nprint('Train Curated after exploding :')\nntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print(\"Number of curated training examples=\", train.shape[0], \"  Number of curated training classes=\", len(train.labels.unique()))\nprint(\"Number of curated training examples after exploding=\", ntrain.shape[0], \"  Number of curated training classes after exploding=\", len(ntrain.labels.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **train_curated.csv unique labels**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# pd.DataFrame({'unique_train_labels':ntrain.labels.unique()})\n# ntrain.labels.unique()\nprint(\"Total number of labels in curated training data : \",len(ntrain['labels'].value_counts()))\nprint(\"Labels are : \", ntrain['labels'].unique())\nplt.figure(figsize=(10,6))\naudio_type = ntrain['labels'].value_counts().head(10)\nsns.barplot(audio_type.values, audio_type.index)\nfor i, v in enumerate(audio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"First few labels based on their frequencies in curated training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nnaudio_type = ntrain['labels'].value_counts().tail(10)\nsns.barplot(naudio_type.values, naudio_type.index)\nfor i, v in enumerate(naudio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"Last few labels based on their frequencies in curated training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"INPUT_LIB = '../input/'\nnew_train = ntrain.sort_values('labels').reset_index()\nnew_train['nframes'] = new_train['fname'].apply(lambda f: wave.open('../input/train_curated/' + f).getnframes())\n\nnew_train['series'] = new_train['fname'].apply(load_wav_file, \n                                                      path=INPUT_LIB + 'train_curated/')\n\n_, ax = plt.subplots(figsize=(18, 5))\nsns.violinplot(ax=ax, x=\"labels\", y=\"nframes\", data=new_train)\nplt.xticks(rotation=90)\nplt.title('Distribution of audio frames, per label in train curated', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print('Histogram of nframes with respect to Train Curated :')\nplt.figure(figsize=(12,8))\nsns.distplot(new_train.nframes.values, bins=50, kde=False)\nplt.xlabel('nframes', fontsize=12)\nplt.title(\"Histogram of #frames\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print('We can see an outlier in the above plot which belongs to the label - Stream')\nnew_train.loc[new_train['nframes'] > 2000000]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print('Temporary data for series plotting :')\ntemp = new_train.sort_values(by='labels')\ntemp.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print(\"Accelerating_and_revving_and_vroom : \")\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in range(40):\n    ax[i//4, i%4].plot(temp['series'][i])\n    ax[i//4, i%4].set_title(temp['fname'][i][:-4])\n    ax[i//4, i%4].get_xaxis().set_ticks([])\nfig.savefig(\"Accelerating_and_revving_and_vroom\", dpi=900) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=50, width=800, height=500).generate(' '.join(new_train.labels))\nplt.figure(figsize=(18,10))\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Labels in Train Curated\", fontsize=25)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **# Train Noisy EDA**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"print('Train Noisy :')\ntrain_noisy.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print('Train Noisy after exploding :')\nntrain_noisy = explode_str(train_noisy, 'labels', ',')\nntrain_noisy.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print(\"Number of noisy training examples=\", train_noisy.shape[0], \"  Number of noisy training classes=\", len(train_noisy.labels.unique()))\nprint(\"Number of noisy training examples after exploding=\", ntrain_noisy.shape[0], \"  Number of noisy training classes after exploding=\", len(ntrain_noisy.labels.unique()))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"### **train_noisy.csv unique labels**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# pd.DataFrame({'unique_noisytrain_labels':ntrain_noisy.labels.unique()})\n# ntrain_noisy.labels.unique()\nprint(\"Total number of labels in curated training data : \",len(ntrain_noisy['labels'].value_counts()))\nprint(\"Labels are : \", ntrain_noisy['labels'].unique())\nplt.figure(figsize=(10,6))\naudio_type = ntrain_noisy['labels'].value_counts().head(10)\nsns.barplot(audio_type.values, audio_type.index)\nfor i, v in enumerate(audio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"First few labels based on their frequencies in noisy training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nnaudio_type = ntrain_noisy['labels'].value_counts().tail(10)\nsns.barplot(naudio_type.values, naudio_type.index)\nfor i, v in enumerate(naudio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"Last few labels based on their frequencies in noisy training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"new_noisytrain = ntrain_noisy.sort_values('labels').reset_index()\nnew_noisytrain['nframes'] = new_noisytrain['fname'].apply(lambda f: wave.open('../input/train_noisy/' + f).getnframes())\n# new_noisytrain['series'] = new_noisytrain['fname'].apply(load_wav_file, \n#                                                       path=INPUT_LIB + 'train_noisy/')\n# new_noisytrain['nframes'] = new_noisytrain['series'].apply(len)\n_, ax = plt.subplots(figsize=(18, 5))\nsns.violinplot(ax=ax, x=\"labels\", y=\"nframes\", data=new_noisytrain)\nplt.xticks(rotation=90)\nplt.title('Distribution of audio frames, per label in train noisy', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(new_noisytrain.nframes.values, bins=50, kde=False)\nplt.xlabel('nframes', fontsize=12)\nplt.title(\"Histogram of #frames\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"#### **In Noisy data most of the wav files have the same frame count. I am doubting that if we combine these data while training, the nframes won't be of much use to us.**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=50, width=800, height=500).generate(' '.join(new_noisytrain.labels))\nplt.figure(figsize=(18,10))\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Labels in Train Curated\", fontsize=30)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <center>SPECTROGRAM PLOTS AND MODEL BUILDING - IN PROGRESS</center>\n## <center>STAY TUNED!</center>\n### <center>THANK YOU</center>\n# <center>😊😎😄</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}