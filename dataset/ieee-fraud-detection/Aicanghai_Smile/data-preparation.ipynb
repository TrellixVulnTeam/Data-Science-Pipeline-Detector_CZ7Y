{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"print('loading libs...')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport gc\nimport datetime\nimport time\nfrom tqdm import tqdm\nfrom scipy import stats\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nprint('done')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the funcs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# func for loading data\ndef DataLoading(path, df_name):\n    files = os.listdir(f'{path}')\n    for i in range(len(files)):\n        s0 = files[i]\n        s1 = files[i][:-4]\n        s2 = files[i][-4:]\n        if s2 =='.csv':\n            print('loading:'+ s1 + '...')\n            globals()[s1] = pd.read_csv(f'{path}'+ s0)\n            df_name.append(s1)\n        elif s2 == '.pkl':\n            print('loading:'+ s1 + '...')\n            globals()[s1] = pd.read_pickle(f'{path}'+ s0)\n            df_name.append(s1)\n        else:\n            pass\n    print('successfully loading: ')\n    print(df_name)\n    print('done')\n    return df_name\n\n    \n# func for data analysis(based on https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt)\ndef DataStatistics(df):   \n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values \n    summary['Missing_percentage'] = round((summary['Missing']/df.shape[0])*100, 1)\n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n       \n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n    summary.set_index('Name',inplace=True)\n    summary = summary.T\n    return summary\n\n\n# func for showing data\ndef DataShowing(df_name, start=0, end=20, seeall = False):\n    if seeall:\n        pd.set_option('display.max_rows', None)\n        pd.set_option('display.max_columns', None)   \n    df_name.sort(reverse=True)\n    for i in range(len(df_name)):\n        s = df_name[i]\n        df = globals()[s]\n        print('data shape of ' + s + ':' + f'{df.shape}')\n        df = df.iloc[:,start:end]\n        if df.empty:\n            pass\n        else:\n            print('looking over the statistics of all features of ' + s + '...')\n            display(DataStatistics(df))\n            print('looking over the statistics of the num_type_features of ' + s + '...')\n            display(df.describe())\n   \n                    \n                    \n# func for merging data\ndef DataMerging(df1, df2, on='TransactionID', how='left'):\n    print('merging data...')\n    df = pd.merge(df1, df2, on=on, how=how)\n    print('done')\n    return df\n                    \n                    \n# func for processing data pipeline\ndef DataProcessing(df1, df2):\n    print('translate DT...')\n    ProcessDT(df1)\n    ProcessDT(df2)\n    df3 = df1['isFraud'].copy()\n    df1 = df1.drop('isFraud', axis=1)\n    colsnum =  df1.dtypes.reset_index()\n    colsnum = colsnum[colsnum[0]!='object'].index\n    print('translate number features in train...')\n    colsnum = tqdm(colsnum) \n    for idx in colsnum:\n        ProcessNumt2Obj(df1,idx)\n    print('translate number features in test...')\n    colsnum = tqdm(colsnum) \n    for idx in colsnum:\n        ProcessNumt2Obj(df2,idx)\n    print('reduce memory...')\n    df1 = ReduceMemUsage(df1)\n    df2 = ReduceMemUsage(df2)\n    print('translate all features...')\n    df1['isFraud'] = df3\n    colsnum = range(len(df1.columns)-1)\n    colsnum = tqdm(colsnum)\n    for idx in colsnum:\n        ProcessObj(df1,df2,idx)\n    print('fillna...')\n    df1 = df1.fillna(0)\n    df2 = df2.fillna(0)\n    print('reducing memory...')\n    df1 = ReduceMemUsage(df1)\n    df2 = ReduceMemUsage(df2)\n    print('dropping target...')\n    df4 = df1.drop('isFraud', axis=1)\n    df5 = df2.copy()\n    train_cols = list(df1.columns)\n    print('Done')\n    return df3, df4, df5      \n\n# convert number type to object\ndef ProcessNumt2Obj(df,idx,sp=20):\n    temp = df.iloc[:,idx]\n    df.iloc[:,idx] = pd.qcut(temp,sp,labels=False,duplicates='drop')\n    return df\n                                     \n                    \n# func for processing object(using the percentage of isFraud to repalce the object)\ndef ProcessObj(df1,df2,idx):\n    temp = df1.iloc[:,idx]\n    temp_t = df2.iloc[:,(idx)]\n    L = temp.unique().tolist()\n    L1 = temp_t.unique().tolist()\n    L.extend(L1)\n    L  = list(set(L))\n    if temp.isnull().any(): \n        temp_0 = df1[temp.isna()]\n        temp_t_0 = df2[temp_t.isna()]\n        temp_1 = temp_0[temp_0.isFraud == 1]\n        rep = temp_1.shape[0]/(temp_0.shape[0]+0.0001)\n        rep = round(rep, 4)\n        #print(rep)\n        df1.iloc[temp_0.index,idx]=rep\n        df2.iloc[temp_t_0.index,idx]=rep\n        for i in range(len(L)):\n            #print(L[i])\n            temp_0 = df1[temp == L[i]]\n            temp_t_0 = df2[temp_t == L[i]]\n            temp_1 = temp_0[temp_0.isFraud == 1]\n            rep = temp_1.shape[0]/(temp_0.shape[0]+0.0001)\n            rep = round(rep, 4)\n            #print(rep)\n            df1.iloc[temp_0.index,idx]=rep\n            df2.iloc[temp_t_0.index,idx]=rep\n    else:\n        for i in range(len(L)):\n            #print(L[i])\n            temp_0 = df1[temp == L[i]]\n            temp_t_0 = df2[temp_t == L[i]]\n            temp_1 = temp_0[temp_0.isFraud == 1]\n            rep = temp_1.shape[0]/(temp_0.shape[0]+0.0001)\n            rep = round(rep, 4)\n            #print(rep)\n            df1.iloc[temp_0.index,idx]=rep\n            df2.iloc[temp_t_0.index,idx]=rep\n    df1.iloc[:,idx]=df1.iloc[:,idx].astype('float16')\n    df2.iloc[:,(idx-1)]=df2.iloc[:,idx].astype('float16')\n    \n    \n    \n# func for processing datetime data(based on https://www.kaggle.com/kyakovlev/ieee-fe-with-some-eda)\ndef ProcessDT(df):\n    START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n    dates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\n    us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n    \n\n    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n    df['DT_M'] = ((df['DT'].dt.year-2017)*12 + df['DT'].dt.month).astype(np.int8)\n    df['DT_W'] = ((df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear).astype(np.int8)\n    df['DT_D'] = ((df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear).astype(np.int16)\n    \n    df['DT_hour'] = (df['DT'].dt.hour).astype('object')\n    df['DT_day_week'] = (df['DT'].dt.dayofweek).astype('object')\n    df['DT_day_month'] = (df['DT'].dt.day).astype('object')\n        \n    # Possible solo feature\n    df['is_december'] = df['DT'].dt.month\n    df['is_december'] = (df['is_december']==12).astype('object')\n\n    # Holidays\n    df['is_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype('object')\n    df.drop(['DT','DeviceInfo'],axis=1,inplace=True)\n    \n    \n# reduce memory usage\ndef ReduceMemUsage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n                                       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting the params\nDF_NAME= []\nPATH = '../input/ieee-fraud-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading data\ndf_name = DataLoading(PATH, DF_NAME)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# looking at the original data\n# DataShowing(df_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging data\ntrain = DataMerging(train_transaction, train_identity)\ntest = DataMerging(test_transaction, test_identity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_transaction, train_identity, test_transaction, test_identity\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking at the merged data\ndf_name = ['X_train','X_test']\nDataShowing(df_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# processing data\ny_train, X_train, X_test = DataProcessing(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saving processed data\nX_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\ny_train.to_pickle('y_train.pkl')\nsample_submission.to_pickle('sample_submission.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}