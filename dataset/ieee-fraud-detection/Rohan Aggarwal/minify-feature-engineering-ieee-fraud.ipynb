{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ntest_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\ntest_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest_dataset = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity\ndel train_transaction\ndel test_identity\ndel test_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TransactionID = test_dataset['TransactionID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset.drop(['TransactionID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.drop(['TransactionID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_dataset['isFraud']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.drop(['isFraud'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing infinite values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# by https://www.kaggle.com/dimartinot\n\ndef clean_inf_nan(df):\n    return df.replace([np.inf, -np.inf], np.nan)   \n\n# Cleaning infinite values to NaN\ntrain_dataset = clean_inf_nan(train_dataset)\ntest_dataset = clean_inf_nan(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_num = []\nlist_of_obj = []\nfor i in train_dataset.columns :\n    if train_dataset[i].dtypes == 'object':\n        list_of_obj.append(i)\n    else:\n        list_of_num.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in list_of_num :\n    train_dataset[i] = train_dataset[i].fillna(0)\n    test_dataset[i] = test_dataset[i].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in list_of_obj :\n    temp = str('no_'+i)\n    train_dataset[i] = train_dataset[i].fillna(temp)\n    test_dataset[i] = test_dataset[i].fillna(temp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data minify and Reduce mem usage"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def minify_identity_df(df):\n    df['M1']  = df['M1'].map({'T':2, 'F':1, 'no_M1':0})\n    df['M2']  = df['M2'].map({'T':2, 'F':1, 'no_M2':0})\n    df['M3']  = df['M3'].map({'T':2, 'F':1, 'no_M3':0})\n    df['M5']  = df['M5'].map({'T':2, 'F':1, 'no_M5':0})\n    df['M6']  = df['M6'].map({'T':2, 'F':1, 'no_M6':0})\n    df['M7']  = df['M7'].map({'T':2, 'F':1, 'no_M7':0})\n    df['M8']  = df['M8'].map({'T':2, 'F':1, 'no_M8':0})\n    df['M9']  = df['M9'].map({'T':2, 'F':1, 'no_M9':0})\n    df['id_12'] = df['id_12'].map({'Found':1, 'NotFound':2, 'no_id_12':0})\n    df['id_15'] = df['id_15'].map({'New':3, 'Found':2, 'Unknown':1, 'no_id_15':0})\n    df['id_16'] = df['id_16'].map({'Found':2, 'NotFound':1, 'no_id_16':0})\n    df['id_23'] = df['id_23'].map({'IP_PROXY:TRANSPARENT':3, 'no_id_23':0,\n                                   'IP_PROXY:ANONYMOUS':2, 'IP_PROXY:HIDDEN':1})\n    df['id_27'] = df['id_27'].map({'Found':1, 'NotFound':2, 'no_id_27':0})\n    df['id_28'] = df['id_28'].map({'New':2, 'Found':1, 'no_id_28':0})\n    df['id_29'] = df['id_29'].map({'Found':1, 'NotFound':2, 'no_id_29':0})\n    df['id_35'] = df['id_35'].map({'T':1, 'F':2, 'no_id_35':0})\n    df['id_36'] = df['id_36'].map({'T':1, 'F':2, 'no_id_36':0})\n    df['id_37'] = df['id_37'].map({'T':1, 'F':2, 'no_id_37':0})\n    df['id_38'] = df['id_38'].map({'T':1, 'F':2, 'no_id_38':0})\n    df['DeviceType'].map({'desktop':2, 'mobile':1, 'no_DeviceType':0})\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/kyakovlev/ieee-internal-blend\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset =  minify_identity_df(train_dataset)\ntest_dataset = minify_identity_df(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset =  reduce_mem_usage(train_dataset)\ntest_dataset = reduce_mem_usage(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def convert_id31(val):\n    try:\n        val = val.lower()\n        x = val.split()\n        if 'chrome' in x:\n            return 'chrome'\n        elif 'safari' in x:\n            return 'safari'\n        elif 'ie' in x:\n            return 'ie'\n        elif 'edge' in x:\n            return 'edge'\n        elif 'firefox' in x:\n            return 'firefox'\n        elif 'samsung' in x:\n            return 'samsung'\n        else:\n            return 'no_id_31'\n    except:\n        return 'no_id_31'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling column 'id_31'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset['id_31'] = train_dataset['id_31'].apply(convert_id31)\ntest_dataset['id_31'] = test_dataset['id_31'].apply(convert_id31)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def convert_id30(val):\n            try:\n                val = val.lower()\n                x = val.split()[0]\n                if x == 'ios':\n                    return 'ios'\n                elif x == 'android':\n                    return 'android'\n                elif x == 'mac':\n                    return 'mac'\n                elif x == 'windows':\n                    return 'windows'\n                elif x == 'linux':\n                    return 'linux'\n                else:\n                    return 'no_id_30'\n            except:\n                return 'no_id_30'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling column 'id_30'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset['id_30'] = train_dataset['id_30'].apply(convert_id30)\ntest_dataset['id_30'] = test_dataset['id_30'].apply(convert_id30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling column 'DeviceInfo'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for X in [train_dataset,test_dataset]:\n    X['device_name'] = X['DeviceInfo'].str.split('/', expand=True)[0]\n\n    X.loc[X['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n    X.loc[X['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n    X.loc[X['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n    X.loc[X['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n    X.loc[X['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n    X.loc[X['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n    X.loc[X['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n    X.loc[X['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n    X.loc[X['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n    X.loc[X['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n    X.loc[X['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n    X.loc[X['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n    X.loc[X['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n    X.loc[X['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n    X.loc[X['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n    X.loc[X['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n    X.loc[X['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n    X.loc[X.device_name.isin(X.device_name.value_counts()[X.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n    X.drop(['DeviceInfo'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling columns 'P_emaildomain' and 'R_emaildomain'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train_dataset['P_emaildomain'].str.split('.', expand=True)\ntrain_dataset['P_emailF'] = temp[0]\ntrain_dataset['P_emailL'] = temp[1]\ntemp = train_dataset['R_emaildomain'].str.split('.', expand=True)\ntrain_dataset['R_emailF'] = temp[0]\ntrain_dataset['R_emailL'] = temp[1]\ntemp = test_dataset['P_emaildomain'].str.split('.', expand=True)\ntest_dataset['P_emailF'] = temp[0]\ntest_dataset['P_emailL'] = temp[1]\ntemp = test_dataset['R_emaildomain'].str.split('.', expand=True)\ntest_dataset['R_emailF'] = temp[0]\ntest_dataset['R_emailL'] = temp[1]\ndel temp\ndel train_dataset['P_emaildomain']\ndel test_dataset['P_emaildomain']\ndel train_dataset['R_emaildomain']\ndel test_dataset['R_emaildomain']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset['P_emailF'] = train_dataset['P_emailF'].fillna('no_P_F')\ntrain_dataset['P_emailL'] = train_dataset['P_emailL'].fillna('no_P_L')\ntrain_dataset['R_emailF'] = train_dataset['R_emailF'].fillna('no_R_F')\ntrain_dataset['R_emailL'] = train_dataset['R_emailL'].fillna('no_R_L')\n\ntest_dataset['P_emailF'] = test_dataset['P_emailF'].fillna('no_P_F')\ntest_dataset['P_emailL'] = test_dataset['P_emailL'].fillna('no_P_L')\ntest_dataset['R_emailF'] = test_dataset['R_emailF'].fillna('no_R_F')\ntest_dataset['R_emailL'] = test_dataset['R_emailL'].fillna('no_R_L')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Label encoding for  object type column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train_dataset.select_dtypes(include=['category', 'object']).columns.values:\n        encoder = LabelEncoder()\n        encoder.fit(list(train_dataset[i].values) + list(test_dataset[i].values))\n        train_dataset[i] = encoder.transform(list(train_dataset[i].values))\n        test_dataset[i] = encoder.transform(list(test_dataset[i].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fixing TransactionDT column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nSTART_DATE = '1800-01-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code from https://www.kaggle.com/kimchiwoong/simple-eda-ensemble-for-xgboost-and-lgbm\ntrain_dataset[\"Date\"] = train_dataset['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\ntrain_dataset['TransactionDT_Weekdays'] = train_dataset['Date'].dt.dayofweek\ntrain_dataset['TransactionDT_Days'] = train_dataset['Date'].dt.day\ntrain_dataset['TransactionDT_Hours'] = train_dataset['Date'].dt.hour\ntrain_dataset.drop(columns='Date', inplace=True)\n\ntest_dataset[\"Date\"] = test_dataset['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\ntest_dataset['TransactionDT_Weekdays'] = test_dataset['Date'].dt.dayofweek\ntest_dataset['TransactionDT_Days'] = test_dataset['Date'].dt.day\ntest_dataset['TransactionDT_Hours'] = test_dataset['Date'].dt.hour\ntest_dataset.drop(columns='Date', inplace=True)\ntrain_dataset.drop(['TransactionDT'],axis=1,inplace=True)\ntest_dataset.drop(['TransactionDT'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Looking for quasi-constant features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def quasi_constant(data):\n    quasi = [col for col in train_dataset.columns if train_dataset[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n    return quasi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quasi_features = quasi_constant(train_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.drop(quasi_features,axis=1,inplace=True)\ntest_dataset.drop(quasi_features,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset =  reduce_mem_usage(train_dataset)\ntest_dataset = reduce_mem_usage(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Saving our converted data as pickle format, so that we can use it to train model and find best parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset['isFraud'] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.to_pickle('Train.pkl')\ntest_dataset.to_pickle('Test.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}