{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Read Me Please!\n### 1. Here, I only worked with one Dataset (Transaction) and built an end to end model with XGBoost, Light GBM, CatBoost. I still managed to achieve a significant score!\n### 2. Dataframes are memory optimized to run GridSearchCV computations. Remember, optimize memory just before training the model. Otherwise, you can have errors while target encoding/ Catboost encoding with the optimized dfs.\n### 3. Hyperparameter tuning is important but trust me that won't improve your Accuracy or AUC substantially. But it's very important to tune the model in case of over fitting and calculating efficiently so that run time is less and we don't suffer from our available resources.\n### 4. The highest submission score 92.1% is a LGBMC in default parameters! As this is an imbalanced dataset problem, we may need few other tricks that I'm exploring."},{"metadata":{},"cell_type":"markdown","source":"### ***My goal is to make this Notebook an End to End Pipeline for a Novice ML Engineer to understand what are the steps are taken typically in a classification problem! If you can contribute, you are welcome! ***"},{"metadata":{},"cell_type":"markdown","source":"## *** Please upvote if you like it!***"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV,KFold,train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom category_encoders import CatBoostEncoder, TargetEncoder\n\nfrom sklearn.linear_model import SGDClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\n\nfrom hyperopt import hp\nfrom hyperopt import tpe\nfrom hyperopt import Trials\nfrom hyperopt import fmin\nfrom hyperopt.pyll.stochastic import sample\nfrom hyperopt import STATUS_OK\nimport csv\nimport ast\nfrom timeit import default_timer as timer\n\n\nfrom time import time\nimport datetime\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,roc_curve,classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Data sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_id_tr=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\n#df_id_ts=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_identity.csv\")\ndf_tran_tr=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\ndf_tran_ts=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_transaction.csv\")\n#df_sample=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Aanalysis\n## Some Burning Questions to answer before we start building models...\n### 1. What types of data are there? how many categorical & numeric features?\n### 2. how much missing values?\n### 3. is it a balanced or imbalanced classification problem?\n### 4. how are the features related with the labelled classification (output)?\n### 5. should we merge transaction and identity datasets? if yes/not, how do we proceed?\n### 6. which features to give it a try?\n### 7. to what extent we preprocess the data? how do we deal nulls?\n### 8. how is the data distribution? Skewed? normal dist?"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Exploring data about the nature and types with memory consumption\ndf_tran_tr.info(verbose=True, null_counts=True, memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_kg_hide-output":true},"cell_type":"code","source":"df_tran_ts.info(verbose=True, null_counts=True, memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# #making a joint dataframe: tran+id\n# df_joint_tr=pd.merge(df_tran_tr,df_id_tr,on='TransactionID')\n# df_joint_ts=pd.merge(df_tran_ts, df_id_ts, on=\"TransactionID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the missing values"},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib notebook\n%matplotlib inline\nplt.figure(figsize=(18,9))\ntrain_full_num = df_tran_tr.filter(regex='isFraud|TransactionDT|TransactionAmt|dist|C|D')\nsns.heatmap(train_full_num.isnull(), cbar= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib notebook\n%matplotlib inline\nplt.figure(figsize=(18,9))\ntrain_full_num = df_tran_tr.filter(regex='M')\nsns.heatmap(train_full_num.isnull(), cbar= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# #this can be avoided as most often this gives memory error\n# %matplotlib notebook\n# %matplotlib inline\n# train_full_Vesta = df_tran_tr.filter(regex='V')\n# plt.figure(figsize=(18,9))\n# sns.heatmap(train_full_Vesta.isnull(), cbar= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %matplotlib notebook\n# %matplotlib inline\n# train_full_id = df_id_tr.filter(regex='id')\n# plt.figure(figsize=(18,9))\n# sns.heatmap(train_full_id.isnull(), cbar= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#balanced/imbalanced?\n%matplotlib notebook\n%matplotlib inline\nplt.figure(figsize=(10,5))\nsns.countplot(x='isFraud',data=df_tran_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# pd.options.display.max_rows=500\n# df_joint_tr.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical features and their co-relation with predictor"},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking each feature count relation with fraud\ndf_tran_tr.groupby('ProductCD')['isFraud'].value_counts(normalize=True).unstack()[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('P_emaildomain')['isFraud'].value_counts(normalize=True).unstack().fillna(0)[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('R_emaildomain')['isFraud'].value_counts(normalize=True).unstack().fillna(0)[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('card4')['isFraud'].value_counts(normalize=True).unstack()[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('card6')['isFraud'].value_counts(normalize=True).unstack().fillna(0)[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('M8')['isFraud'].value_counts(normalize=True).unstack().dropna()[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('M9')['isFraud'].value_counts(normalize=True).unstack().dropna()[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_tran_tr.groupby('M7')['isFraud'].value_counts(normalize=True).unstack().dropna()[1].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Co-relating numeric features through Heat Maps"},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib notebook\n%matplotlib inline\ndef cor_heat(df):\n    cor=df.corr()\n    plt.figure(figsize=(20,10),dpi=100)\n    sns.heatmap(data=cor,annot=True,square=True,linewidths=0.1,cmap='YlGnBu')\n    plt.title(\"Pearson Co-relation: Heat Map\")\ncor_heat(df_tran_tr.filter(regex='C|isFraud'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib notebook\n%matplotlib inline\ndef cor_heat(df):\n    cor=df.corr()\n    plt.figure(figsize=(20,7),dpi=100)\n    sns.heatmap(data=cor,annot=True,square=True,linewidths=0.1,cmap='YlGnBu')\n    plt.title(\"Pearson Co-relation: Heat Map\")\ncor_heat(df_tran_tr.filter(regex='Tran|isFraud'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.set_option('display.max_rows',400)\n#using absolute to figure out features with higher co-relation irrespective of their +/- value\nabs(df_tran_tr.filter(regex='V|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abs(df_tran_tr.filter(regex='D[0-9]|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"abs(df_tran_tr.filter(regex='C|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)[0:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"abs(df_tran_tr.filter(regex='add|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abs(df_tran_tr.filter(regex='dist|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abs(df_tran_tr.filter(regex='card1|card2|card3|card5|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insights so far from EDA to build initial Model...\n### 1. M values are to be ignored for initial model due to very high number of null values and relate to fraud lesser comparatively\n### 2. joining the transaction and identity (on TransactionID) leaves very small dataset (~144k). so, we will drop identity dataset as of now and work only with Transaction Dataset\n### 3. Vxxx features are very good co-relator of fraud.need to maximize their utilization in model building\n### 4. D features need to be considered due to their high correlation [needs imputations though] (top 3 initially); We drop D9,D2 even though they show high correlation due to high null values\n### 5. TransactionDT, TransactionAMT will be considered\n### 6. Top 5 C features (sorted by the co-relation) will be considered as no null values\n### 7. From categorical features ProductCD, card (excluding card2), P_emaildomain (R_emaildomain excluded due to high null values) will be included and need category encoding\n### 8. dist1,dist2 features are excluded due to high null & low co-relation\n### 9. addr1, addr2 features should be included\n### 10. P_emaildoamin has very high correlation and we will drop all the null values of it from main Dataset\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing & Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This code will save your memory which will be required to run SVC/KNN within allocated memory and grid_search\n## This cell is for advanced model building with D features selected from their null counts and correlation values\ndf_tran_tr=df_tran_tr.filter(regex='V|addr|C2|C8|C12|C1|C4|C10|C11|C6|C7|Tran|card1|card3|card4|card5|card6|ProductCD|P_emaildomain|R_emaildomain|isFraud|D[0-9]')\n#dropping these columns due to their very low correlation with target\ndf_tran_tr=df_tran_tr.drop(['D7','D13','D8'],axis=1)\n#df_tran_tr.info(verbose=True, null_counts=True)\ndf_tran_ts=df_tran_ts.filter(regex='V|addr|C2|C8|C12|C1|C4|C10|C11|C6|C7|Tran|card1|card3|card4|card5|card6|ProductCD|P_emaildomain|R_emaildomain|D[0-9]')\ndf_tran_ts=df_tran_ts.drop(['D7','D13','D8'],axis=1)\nprint(\"Train data set shape: {0}\".format(df_tran_tr.shape))\nprint(\"Test data set shape: {0}\".format(df_tran_ts.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use below cells if you want to manually impute the numeric missing features for models other than XGBoost/LGBM/CatBoost"},{"metadata":{},"cell_type":"markdown","source":"## Just set manual_imputation= True to impute manually wherever needed"},{"metadata":{"trusted":true},"cell_type":"code","source":"manual_imputation= False\n#manual_imputation=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if manual_imputation==True:\n    # use it when you don't want auto imputation for missing values\n    #imputing D features missing values with median\n    for p in df_tran_tr.filter(regex='D[0-9]'):\n        df_tran_tr[p]=df_tran_tr[p].fillna(df_tran_tr[p].median())\n\n    for q in df_tran_ts.filter(regex='D[0-9]'):\n        df_tran_ts[q]=df_tran_ts[q].fillna(df_tran_ts[q].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if manual_imputation==True:\n    # use it when you don't want auto imputation for missing values\n    #imputing V features missing values with median\n    for x in df_tran_tr.filter(regex='V'):\n        df_tran_tr[x]=df_tran_tr[x].fillna(df_tran_tr[x].median())\n\n    for y in df_tran_ts.filter(regex='V'):\n        df_tran_ts[y]=df_tran_ts[y].fillna(df_tran_ts[y].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #checking the co-relation after imputations\n# pd.set_option('display.max_rows',400)\n# abs(df_tran_tr.filter(regex='V|isFraud').fillna(0).corr())['isFraud'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if manual_imputation==True:\n    # use it when you don't want auto imputation for missing values\n    #filling numerical card features with median\n    for a in df_tran_tr.filter(regex='card1|card3|card5'):\n        df_tran_tr[a]=df_tran_tr[a].fillna(df_tran_tr[a].median())\n\n    for b in df_tran_ts.filter(regex='card1|card3|card5'):\n        df_tran_ts[b]=df_tran_ts[b].fillna(df_tran_ts[b].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if manual_imputation==True:\n    #filling null C values in test tran dataset with median\n    for c in df_tran_ts.filter(regex='C2|C8|C12|C1|C4|C10|C11|C6|C7'):\n        df_tran_ts[c]=df_tran_ts[c].fillna(df_tran_ts[c].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if manual_imputation==True:\n    # use it when you don't want auto imputation for missing values\n    #filling null addr values with median\n    df_tran_tr.addr1=df_tran_tr.addr1.fillna(df_tran_tr.addr1.median())\n    df_tran_tr.addr2=df_tran_tr.addr2.fillna(df_tran_tr.addr2.median())\n\n    df_tran_ts.addr1=df_tran_ts.addr1.fillna(df_tran_ts.addr1.median())\n    df_tran_ts.addr2=df_tran_ts.addr2.fillna(df_tran_ts.addr2.median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imputing and transforming Categorical features"},{"metadata":{},"cell_type":"markdown","source":"### Missing values imputations with most common values. Catboost Encoding auto fills these."},{"metadata":{},"cell_type":"markdown","source":"## Just set the category encoding you want to proceed with "},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_encoding=\"catboost\"\n#cat_encoding=\"label\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"label\":\n    # If you want to R_emaildomain in your model\n    #dropping null values for R_emaildomain; this is a very critical indicator to fruad; so have to utilize it\n    ##df_tran_tr=df_tran_tr.dropna(subset=['R_emaildomain'])\n    df_tran_tr['R_emaildomain']=df_tran_tr['R_emaildomain'].fillna('gmail.com')\n    #as we can't drop any row from test data, filling it with mode\n    df_tran_ts['R_emaildomain']=df_tran_ts['R_emaildomain'].fillna('gmail.com')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"label\":\n    #df_tran_tr=df_tran_tr.dropna(subset=['P_emaildomain'])\n    df_tran_tr['P_emaildomain']=df_tran_tr['P_emaildomain'].fillna('gmail.com')\n    #as we can't drop any row from test data, filling it with mode\n    df_tran_ts['P_emaildomain']=df_tran_ts['P_emaildomain'].fillna('gmail.com')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"label\":\n    #checking max present card4 type to fill in null values\n    df_tran_tr.groupby('card4')['isFraud'].value_counts().unstack()\n    print(df_tran_tr.card4.mode())\n    print(df_tran_ts.card4.mode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"label\":\n    df_tran_tr.groupby('card6')['isFraud'].value_counts().unstack()\n    print(df_tran_tr.card6.mode())\n    print(df_tran_ts.card6.mode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"label\":\n    df_tran_tr.card4=df_tran_tr.card4.fillna('visa')\n    df_tran_tr.card6=df_tran_tr.card6.fillna('debit')\n\n    df_tran_ts.card4=df_tran_ts.card4.fillna('visa')\n    df_tran_ts.card6=df_tran_ts.card6.fillna('debit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for x in df_tran_tr.filter(regex='M'):\n#     df_tran_tr[x]=df_tran_tr[x].fillna(df_tran_tr[x].value_counts().index[0])\n# for y in df_tran_ts.filter(regex='M'):\n#     df_tran_ts[y]=df_tran_ts[y].fillna(df_tran_ts[y].value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"label\":\n    #Label Encoding R_emaildomain\n    df_tran_tr.R_emaildomain=LabelEncoder().fit_transform(df_tran_tr.R_emaildomain)\n    df_tran_ts.R_emaildomain=LabelEncoder().fit_transform(df_tran_ts.R_emaildomain)\n\n    #Label Encoding P_emaildomain\n    df_tran_tr.P_emaildomain=LabelEncoder().fit_transform(df_tran_tr.P_emaildomain)\n    df_tran_ts.P_emaildomain=LabelEncoder().fit_transform(df_tran_ts.P_emaildomain)\n\n    #Label Encoding ProductCD\n    df_tran_tr.ProductCD=LabelEncoder().fit_transform(df_tran_tr.ProductCD)\n    df_tran_ts.ProductCD=LabelEncoder().fit_transform(df_tran_ts.ProductCD)\n\n    #Label encoding card features\n    df_tran_tr.card4=LabelEncoder().fit_transform(df_tran_tr.card4)\n    df_tran_tr.card6=LabelEncoder().fit_transform(df_tran_tr.card6)\n    df_tran_ts.card4=LabelEncoder().fit_transform(df_tran_ts.card4)\n    df_tran_ts.card6=LabelEncoder().fit_transform(df_tran_ts.card6)\n\n\n    # for z in df_tran_tr.filter(regex=\"M\"):\n    #     df_tran_tr[z]=LabelEncoder().fit_transform(df_tran_tr[z])\n\n    # for a in df_tran_ts.filter(regex=\"M\"):\n    #     df_tran_ts[a]=LabelEncoder().fit_transform(df_tran_ts[a])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CatBoost Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cat_encoding==\"catboost\":\n    cat_features=['R_emaildomain','P_emaildomain','ProductCD','card4','card6']\n\n    cbe=CatBoostEncoder(cols=cat_features)\n    # X= df_tran_tr.drop(['isFraud'],axis=1)\n    # y= df_tran_tr[['isFraud']]\n    cbe.fit(df_tran_tr[cat_features],df_tran_tr[['isFraud']])\n\n    # #Train & Test Set transforming\n    df_tran_tr=df_tran_tr.join(cbe.transform(df_tran_tr[cat_features]).add_suffix('_target'))\n    df_tran_tr.drop(['R_emaildomain','P_emaildomain','ProductCD','card4','card6'],axis=1,inplace=True)\n\n    df_tran_ts=df_tran_ts.join(cbe.transform(df_tran_ts[cat_features]).add_suffix('_target'))\n    df_tran_ts.drop(['R_emaildomain','P_emaildomain','ProductCD','card4','card6'],axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#don't do this before category encoding\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reducing memory without any data loss\ndf_tran_tr=reduce_mem_usage(df_tran_tr)\ndf_tran_ts=reduce_mem_usage(df_tran_ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting Train & Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df_tran_tr.drop(['isFraud'],axis=1)\ny=df_tran_tr[['isFraud']]\n## as this is an imbalanced problem, we need to stratify the splitting so that training is well distributed\n#no need for LGB hyper model selection\n# X_train, X_test, y_train, y_test = train_test_split(df_tran_tr.drop(['isFraud'],axis=1), df_tran_tr[['isFraud']], test_size=0.2, random_state=0,stratify=df_tran_tr[['isFraud']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameters Tuning"},{"metadata":{},"cell_type":"markdown","source":"## Details of XGB classifier hyper parameters\n\nhttps://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# this gives memory error; so I will be trying to iterate manually with parameter values\n# param_test = {'n_estimators':np.arange(2,100,1), \n#               'max_depth':np.arange(3,10,1),\n#               'gamma':np.arange(0,0.5,0.1),\n#               'learning_rate':np.arange(0,0.1,0.01),\n#              'min_child_weight':np.arange(1,10,1)\n#              }\n\n\n# gs=GridSearchCV(estimator=XGBClassifier(),scoring='roc_auc',param_grid=param_test,cv=3)\n# gs.fit(X_train,np.ravel(y_train)) #used ravel to convert to 1-D array\n# print(\"best parameters are: {0} for the best score of {1}\".format(gs.best_params_,gs.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Details of Light GBM hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyper_tuning=\"hyperopt\"\nhyper_tuning=\"grid_search\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy\n\nhttps://www.kaggle.com/nroman/lgb-single-model-lb-0-9419\n\nhttps://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\n\nhttps://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a\n\nhttps://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Bayesian%20Hyperparameter%20Optimization%20of%20Gradient%20Boosting%20Machine.ipynb"},{"metadata":{},"cell_type":"markdown","source":"### with lgb.cv which will require model in test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# #you can try cv using below method\n# params_lgb={'boosting_type':'gbdt',\n#            'objective': 'binary',\n#            'random_state':42}\n# k_fold=10\n# train_data=lgb.Dataset(X_train,label=y_train)\n# validation_data=lgb.Dataset(X_test,label=y_test)\n# time_to_train=time()\n# lgbmc=lgb.cv(params_lgb,train_data,num_boost_round=10000,nfold=k_fold,metrics='auc',\n#              verbose_eval=True, early_stopping_rounds=500)\n# print(\"Training is completed!\")\n# print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - time_to_train))))\n# print('-',30)\n# print(lgbmc.best_score_)\n# print(lgbmc.best_params)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bayesian optimization method with Hyperopt\n\nIt's advantage over Grid_search is that it won't iterate over some discrete values rather all the values within the search domain!"},{"metadata":{},"cell_type":"markdown","source":"https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a"},{"metadata":{"trusted":true},"cell_type":"code","source":"#look carefully the default parameter; we will circle around the default values to find the optimum ones\nLGBMClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if hyper_tuning==\"hyperopt\":\n    \n#     MAX_EVALS = 500\n#     N_FOLDS=5\n#     train_set=lgb.Dataset(X,label=y)\n#     #Objective function: part-1\n\n#     def objective(params, n_folds = N_FOLDS):\n#         \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n\n#         # Keep track of evals\n#         global ITERATION\n\n#         ITERATION += 1\n\n#         # Retrieve the subsample if present otherwise set to 1.0\n#         subsample = params['boosting_type'].get('subsample', 1.0)\n\n#         # Extract the boosting type\n#         params['boosting_type'] = params['boosting_type']['boosting_type']\n#         params['subsample'] = subsample\n\n#         # Make sure parameters that need to be integers are integers\n#         for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n#             params[parameter_name] = int(params[parameter_name])\n\n#         start = timer()\n\n#         # Perform n_folds cross validation\n#         cv_results = lgb.cv(params, train_set=train_set, num_boost_round = 10000, nfold = n_folds, \n#                             early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n\n#         run_time = timer() - start\n\n#         # Extract the best score\n#         best_score = np.max(cv_results['auc-mean'])\n\n#         # Loss must be minimized\n#         loss = 1 - best_score\n\n#         # Boosting rounds that returned the highest cv score\n#         n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n\n#         # Write to the csv file ('a' means append)\n#         of_connection = open(out_file, 'a')\n#         writer = csv.writer(of_connection)\n#         writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n\n#         # Dictionary with information for evaluation\n#         return {'loss': loss, 'params': params, 'iteration': ITERATION,\n#                 'estimators': n_estimators, \n#                 'train_time': run_time, 'status': STATUS_OK}\n    \n#     #defining search space: part-2\n#     space = {\n#         'class_weight': hp.choice('class_weight', [None, 'balanced']),\n#         'boosting_type': hp.choice('boosting_type', \n#                                    [{'boosting_type': 'gbdt', \n#                                         'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n#                                      {'boosting_type': 'dart', \n#                                          'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n#                                      {'boosting_type': 'goss'}]),\n#         'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n#         'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n#         'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n#         'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n#         'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n#         'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n#         'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n#     }\n    \n#     # boosting type domain \n#     boosting_type = {'boosting_type': hp.choice('boosting_type', \n#                                                 [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n#                                                  {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n#                                                  {'boosting_type': 'goss', 'subsample': 1.0}])}\n\n#     # Draw a sample\n#     params = sample(boosting_type)\n    \n#     # Retrieve the subsample if present otherwise set to 1.0\n#     subsample = params['boosting_type'].get('subsample', 1.0)\n\n#     # Extract the boosting type\n#     params['boosting_type'] = params['boosting_type']['boosting_type']\n#     params['subsample'] = subsample\n    \n    \n#     # File to save first results\n#     out_file = 'gbm_trials.csv'\n#     of_connection = open(out_file, 'w')\n#     writer = csv.writer(of_connection)\n\n#     # Write the headers to the file\n#     writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n#     of_connection.close()\n\n\n\n#     # Algorithm: part-3\n#     tpe_algorithm = tpe.suggest\n#     # Trials object to track progress\n#     bayes_trials = Trials()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# %%capture\n# #capture results: part-4\n# # Global variable\n# global  ITERATION\n\n# ITERATION = 0\n\n# # Run optimization\n# best = fmin(fn = objective, space = space, algo = tpe.suggest, \n#             max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50),\n#             verbose=50,show_progressbar=True)\n\n# results = pd.read_csv('gbm_trials.csv')\n\n# # Sort with best scores on top and reset index for slicing\n# results.sort_values('loss', ascending = True, inplace = True)\n# results.reset_index(inplace = True, drop = True)\n# results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# # Convert from a string to a dictionary\n# ast.literal_eval(results.loc[0, 'params'])\n\n# # Extract the ideal number of estimators and hyperparameters\n# best_bayes_estimators = int(results.loc[0, 'estimators'])\n# best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n# print(\"Best Estimator is:{}\".format(best_bayes_estimators))\n# print(\"-\"* 30)\n# print(\"Best Parameters are {}\".format(best_bayes_params))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Randomized Searching\nhttps://www.kaggle.com/willkoehrsen/intro-to-model-tuning-grid-and-random-search"},{"metadata":{"trusted":true},"cell_type":"code","source":"k_fold=5\nkf=StratifiedKFold(n_splits=k_fold,shuffle=True, random_state=42)\nif hyper_tuning==\"grid_search\":\n    \n    params_lgb_grid={\n    'boosting_type': ['gbdt', 'dart'],'num_leaves': list(range(30, 150)),\n    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n    'subsample_for_bin': list(range(20000, 300000, 20000)),'min_child_samples': list(range(20, 500, 5)),\n    'reg_alpha': list(np.linspace(0, 1)),'reg_lambda': list(np.linspace(0, 1)),'colsample_bytree': list(np.linspace(0.6, 1, 10)),\n    'n_estimators':list(np.arange(100,2000,50))\n    }\n    \n    lgb_estimator=LGBMClassifier(objective='binary',random_state=42,max_depth=-1,num_boost_rounds=1000)\n    rs=RandomizedSearchCV(estimator=lgb_estimator,scoring='roc_auc',param_distributions=params_lgb_grid,cv=kf,verbose=100, n_iter=20,n_jobs=2)\n    rs.fit(X,np.ravel(y)) #used ravel to convert to 1-D array\n    bs_score=rs.best_score_\n    bs_params=rs.best_params_\n    bs_est=rs.best_estimator_\n    print(\"best parameters are: {0} for the best score of {1}\".format(rs.best_params_,rs.best_score_))\n    print(\"-\"*30)\n    print(\"best estimator is:{}\".format(rs.best_estimator_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train and validation in same iteration with lgb.train"},{"metadata":{"trusted":true},"cell_type":"code","source":"# k_fold=5\n# kf=StratifiedKFold(n_splits=k_fold,shuffle=True, random_state=42)\n# training_start_time = time()\n# aucs=[]\n# for fold, (trn_idx,val_idx) in enumerate(kf.split(X,y)):\n#     start_time = time()\n#     print('Training on fold {}'.format(fold + 1))\n#     trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n#     val_data = lgb.Dataset(X.iloc[val_idx], label=y.iloc[val_idx])\n#     clf = lgb.train(params_lgb, trn_data, num_boost_round=10000, valid_sets = [trn_data, val_data], \n#                     verbose_eval=200, early_stopping_rounds=100)\n#     aucs.append(clf.best_score['valid_1']['auc'])\n#     print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n# print('-' * 30)\n# print('Training is completed!.')\n# print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n# print(clf.best_params_)\n# print('-' * 30)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing tuned model in Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def testing_model(my_model):\n#     my_model.fit(X_train,np.ravel(y_train))\n#     my_model_pred=my_model.predict(X_test)\n#     print(\"accuracy score is {0}% and roc \n#     print(classification_report(y_test,my_model_pred))\n#     print(my_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgbc_test=XGBClassifier(gamma=0.5,learning_rate=0.03,max_depth=9,n_estimators=200,min_child_weight=3, reg_alpha=0.005)\n# testing_model(xgbc_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_tran_tr.shape)\nprint(df_tran_ts.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #saving the model parameters\n# params=clf.best_params_\n# best_iter=clf.best_iteration","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tuning model with best parameters\n\nHardcoding model for minimum Loss 0.0441241 learnt from Bayesian hyperopt searching "},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuned_lgb=LGBMClassifier(boosting_type='gbdt',class_weight='balanced', colsample_bytree=0.8970523178797932,\n#                learning_rate=0.8970523178797932, min_child_samples=45,n_estimators=3323, n_jobs=-1, \n#                 num_leaves=138, objective='binary',random_state=42, reg_alpha=0.5005020213127344, \n#                 reg_lambda= 0.45121616279208887, silent=True,\n#                subsample=0.6614743075688195, subsample_for_bin=260000)\ntuned_lgb=LGBMClassifier(objective='binary',random_state=42,**bs_params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Which algorithm to tune finally?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_output(your_model):\n    #training the model with inp and out df\n    your_model.fit(df_tran_tr.drop(['isFraud'],axis=1),np.ravel(df_tran_tr[['isFraud']]))\n    your_model_pred= your_model.predict_proba(df_tran_ts)[:,1]\n    your_model_df= pd.DataFrame({'TransactionID':df_tran_ts['TransactionID'],'isFraud': your_model_pred.astype(float)})\n    your_model_df.to_csv('submission_fraud.csv',index=False)\n\nrdf_model=RandomForestClassifier(warm_start=True)\nxgb_model=XGBClassifier()\nnbg_model=GaussianNB()\nmplc_model=MLPClassifier()\nadb_model= AdaBoostClassifier()\ngbb_model=GradientBoostingClassifier()\nsvc_model= SVC()\nknn_model=KNeighborsClassifier()\nsgd_model=SGDClassifier()\nlgbmc_model= LGBMClassifier()\ncatb_model=CatBoostClassifier(eval_metric = 'AUC')\nmodel_output(tuned_lgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations and findings after Iterations on Model Score on test data\n### 1. XGBoost and RandomForest give 89.3% and 83.4% accuracy on default parameters run. Seems Ensemble(checked AdaBoost, GradientBoosting) has a good prediction on this data.\n### 2. Missing values for P & R emaildomain can be imputed by mode and missing values for numeric features can be imputed through XGBoost auto imputation (auto imputation gave .03% higher score for me. so I'm following that).\n### 3. we will check if the id dataset can add values to prediction through Heatmap correlation\n### 4. We can try out MLPC, KNN, SVC, NB algos. but ensemble seems to a winner here.\n### 5. are all V rich features needed to be included in the model? which columns can we drop? we can set a certain co-relation score and allow all V features meeting that threshold...\n### 6. tried with 137k train set ( size of R_emaildomain non-null values) and got a score of 86.5% which is less than our auto imputed XGBoost classifier score of 89.6%."},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}