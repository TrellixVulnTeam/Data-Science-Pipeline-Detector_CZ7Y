{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Read the data\n\nRead both the transactions and the identity datasets:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_transaction = pd.read_csv(\"../input/train_transaction.csv\")\ntrain_identity = pd.read_csv(\"../input/train_identity.csv\")\ntrain_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The identity dataset looks like:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_identity.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Joining the two datasets on key $\\mathrm{TransactionID}$:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_transaction.join(train_identity, on=\"TransactionID\", lsuffix=\"_leftid\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame({\n    \"Columns\": train.columns,\n    \"Types\": train.dtypes\n})\nprint(temp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only columns without missing values are considered for a first model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"column_not_contains_missing = train.isna().sum() == 0\ntrain.loc[:, train.columns[column_not_contains_missing]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the columns containing the IDs and getting the dummy encoded variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.loc[:, train.columns[column_not_contains_missing]].drop([\"TransactionID_leftid\", \"TransactionDT\"], axis=1)\n\nY = df[\"isFraud\"].copy()\nX = pd.get_dummies(df.drop([\"isFraud\"], axis=1)).copy()\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fraction of frauds is the following:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nnp.mean(Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deleting the unused datasets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\ndel train_transaction, train_identity, train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncv=9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\nmodel = RandomForestClassifier(n_estimators=100)\nscores_rf = cross_val_score(model, X, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_rf), \"+/-\", np.std(scores_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\n\nmodel = XGBClassifier()\nscores_xgb = cross_val_score(model, X, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_xgb), \"+/-\", np.std(scores_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\n\nmodel = LGBMClassifier()\nscores_gbm = cross_val_score(model, X, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_gbm), \"+/-\", np.std(scores_gbm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n\nX2 = (df.drop([\"isFraud\"], axis=1)).copy()\n\nmodel = CatBoostClassifier(cat_features=[\"ProductCD\"])\nscores_cat = cross_val_score(model, X2, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_cat), \"+/-\", np.std(scores_cat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = [\"Random forest\"] * cv + [\"Xgboost\"] * cv + [\"Lightgbm\"] * cv + [\"Catboost\"] * cv\nperformance = pd.DataFrame({\n    \"classifier\": classifier,\n    \"scores\": list(scores_rf) + list(scores_xgb) + list(scores_gbm) + list(scores_cat)\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\nsns.boxplot(y=\"classifier\", x=\"scores\", data=performance).set(xlabel='', ylabel='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considering the model training time and the performances:\n    \n| **Classifier** | **Training time** | **Performance** |\n|  :- |    :-: | :-: |\n| Random Forest  | 6m 59s | $0.857 \\pm 0.016$ |\n| Xgboost | 3m 12s | $0.848 \\pm 0.011$ |\n| Lightgbm| 26.8s | $0.882 \\pm 0.013$ |\n| Catboost| 39m 41s | $0.879 \\pm 0.016$ |\n\nThe next iterations for designing features will be done only on the Lightgbm classifier."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}