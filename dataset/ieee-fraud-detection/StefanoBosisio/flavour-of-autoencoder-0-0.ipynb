{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nimport json\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom pylab import rcParams\nimport tensorflow as tf\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras import regularizers\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve\nfrom sklearn.metrics import recall_score, classification_report, auc, roc_curve\nfrom sklearn.metrics import precision_recall_fscore_support, f1_score\nfrom numpy.random import seed\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.manifold import TSNE\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)\nSEED = 123 #used to help randomly select the data points\nDATA_SPLIT_PCT = 0.2\nrcParams['figure.figsize'] = 8, 6\nLABELS = [\"Normal\",\"Break\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nt1 = time.time()\nfolder_path = '../input/ieee-fraud-detection/'\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')\ntest_identity = pd.read_csv(f'{folder_path}test_identity.csv')\ntrain_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\ntest_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\nt2 = time.time()\nprint(\"Time to parse: %f\" % (t2 - t1))\n\ntrain_df = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest_df = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity,train_transaction,test_identity, test_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.fillna(0, inplace=True)\ntest_df.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [\"ProductCD\",\"card4\",\"card6\",\"P_emaildomain\",\"R_emaildomain\",\\\n           \"M1\",\"M2\",\"M3\",\"M4\",\"M5\",\"M6\",\"M7\",\"M8\",\"M9\",\\\n           \"id_12\",\"id_15\",\"id_16\",\"id_23\",\"id_27\",\"id_28\",\"id_29\",\"id_30\",\"id_31\",\"id_33\",\"id_34\",\"id_35\",\"id_36\",\"id_37\",\\\n           \"id_38\",\"DeviceType\",\"DeviceInfo\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in cat_cols:\n    if f in train_df.columns:\n        lbl = LabelEncoder()\n        lbl.fit(list(train_df[f].values)+ list(test_df[f].values))\n        train_df[f] = lbl.transform(list(train_df[f].values))\n        test_df[f] = lbl.transform(list(test_df[f].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(labels=[\"TransactionDT\"],axis=1,inplace=True)\ntest_df.drop(labels=[\"TransactionDT\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(labels=[\"TransactionID\"],axis=1,inplace=True)\ntest_df.drop(labels=[\"TransactionID\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the V variables -- Lightgbm of V only got low predictive power\nV_cols = []\nfor cols in train_df.columns:\n    if cols.startswith(\"V\"):\n        V_cols.append(cols)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(labels=V_cols,axis=1,inplace=True)\ntest_df.drop(labels=V_cols,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_valid = train_test_split(train_df, test_size=DATA_SPLIT_PCT, random_state=SEED)\ndf_train_0 = df_train.loc[df_train['isFraud'] == 0] #this is not fraud\ndf_train_1 = df_train.loc[df_train['isFraud'] == 1]\ndf_train_0_x = (df_train_0.drop(['isFraud'], axis=1))\ndf_train_1_x = (df_train_1.drop(['isFraud'], axis=1))\ndf_valid_0 = df_valid.loc[df_valid['isFraud'] == 0]\ndf_valid_1 = df_valid.loc[df_valid['isFraud'] == 1]\ndf_valid_0_x = (df_valid_0.drop(['isFraud'], axis=1))\ndf_valid_1_x = (df_valid_1.drop(['isFraud'], axis=1))\n\nscaler = StandardScaler().fit(df_train_0_x)\ndf_train_0_x_rescaled = scaler.transform(df_train_0_x)\ndf_valid_0_x_rescaled = scaler.transform(df_valid_0_x)\n\ndf_valid_x_rescaled = scaler.transform(df_valid.drop([\"isFraud\"],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_x_rescaled = scaler.transform(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_0_x_rescaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epoch = 100\nbatch_size = 32 #32\ninput_dim = df_train_0_x_rescaled.shape[1] #num of predictor variables, \nencoding_dim = int(input_dim/2)\nhidden_dim = int(encoding_dim / 2)\nlearning_rate = 1e-5\nprint(encoding_dim)\nprint(hidden_dim)\ninput_layer = Input(shape=(input_dim, ))\n#encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n#encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n#decoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n#decoder = Dense(encoding_dim, activation=\"relu\")(decoder)\n#decoder = Dense(input_dim, activation=\"tanh\")(decoder)\n#autoencoder = Model(inputs=input_layer, outputs=decoder)\n#autoencoder.summary()\n\n\n\nencoder = Dense(encoding_dim, activation=\"selu\", activity_regularizer=regularizers.l1(learning_rate),\\\n                kernel_initializer='lecun_normal')(input_layer)\nencoder = Dense(200, activation=\"relu\")(encoder)\ndecoder = Dense(hidden_dim, activation='selu',kernel_initializer='lecun_normal')(encoder)\ndecoder = Dense(input_dim, activation='relu')(decoder)\nautoencoder = Model(inputs=input_layer, outputs=decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.compile(metrics=['accuracy'],\n                    loss='mean_squared_error',\n                    optimizer='adam')\n\ncp = ModelCheckpoint(filepath=\"A_autoencoder_classifier_1.h5\",\n                               save_best_only=True,\n                               verbose=0)\ntb = TensorBoard(log_dir='./logs',\n                histogram_freq=0,\n                write_graph=True,\n                write_images=True)\n\nhistory = autoencoder.fit(df_train_0_x_rescaled, df_train_0_x_rescaled,\n                    epochs=nb_epoch,\n                    batch_size=batch_size,\n                    shuffle=True,\n                    validation_data=(df_valid_0_x_rescaled, df_valid_0_x_rescaled),\n                    verbose=10,\n                    callbacks=[cp, tb]).history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_x_predictions = autoencoder.predict(df_valid_x_rescaled)\nmse = np.mean(np.power(df_valid_x_rescaled - valid_x_predictions, 2), axis=1)\nerror_df = pd.DataFrame({'Reconstruction_error': mse,\n                        'True_class': df_valid['isFraud']})\nprecision_rt, recall_rt, threshold_rt = precision_recall_curve(error_df.True_class, error_df.Reconstruction_error)\nplt.plot(threshold_rt, precision_rt[1:], label=\"Precision\",linewidth=5)\nplt.plot(threshold_rt, recall_rt[1:], label=\"Recall\",linewidth=5)\nplt.title('Precision and recall for different threshold values')\nplt.xlabel('Threshold')\nplt.ylabel('Precision/Recall')\n#plt.xlim(100, 130)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = error_df.groupby('True_class')\nfig, ax = plt.subplots()\n\nthreshold = 100 #to be fixed!\nfor name, group in groups:\n    ax.plot(group.index, group.Reconstruction_error, marker='o', ms=3.5, linestyle='',\n            label= \"Fraud\" if name == 1 else \"Normal\")\nax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\nax.legend()\nplt.title(\"Reconstruction error for different classes\")\nplt.ylabel(\"Reconstruction error\")\nplt.xlabel(\"Data point index\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x_predictions = autoencoder.predict(df_test_x_rescaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = np.mean(np.power(df_test_x_rescaled - test_x_predictions, 2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(np.linspace(0,len(mse),len(mse)),mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/ieee-fraud-detection/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tresholds = [1,2, 100,110]\n\nnew_res = []\nfor tres in tresholds:\n    for res in mse:\n        if res> tres:\n            new_res.append(1)\n        else:\n            new_res.append(0)\n    sample[\"isFraud\"] = new_res \n    new_res = []\n    filename = \"A_submission_0_\" + str(tres) + \".csv\"\n    sample.to_csv(filename, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}