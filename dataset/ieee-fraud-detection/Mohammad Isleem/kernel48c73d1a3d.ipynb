{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport multiprocessing\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport gc\nfrom time import time\nimport datetime\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, TimeSeriesSplit\nfrom sklearn.metrics import roc_auc_score\nwarnings.simplefilter('ignore')\nsns.set()\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\ntrain_transaction=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\ntest_identity=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_identity.csv\")\ntest_transaction=pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_transaction.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.merge(train_transaction,train_identity,how=\"left\",on=\"TransactionID\")\ntest=pd.merge(test_transaction,test_identity,how=\"left\",on=\"TransactionID\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=reduce_mem_usage(train)\ntest=reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity\ndel test_identity\ndel train_transaction\ndel test_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_than_90_NA_or_same_value_train=[]\nmore_than_90_NA_or_same_value_test=[]\nmany_na_train=[]\nmany_na_test=[]\nfor col in train.columns:\n    if train[col].isna().sum()/train.shape[0] >=0.90:\n        many_na_train.append(col) # full of NAs in train\nfor col in test.columns:\n    if test[col].isna().sum()/test.shape[0]>=0.90:\n        many_na_test.append(col) # full of NAs in test\nfor col in train.columns:\n  #  print(col,train[col].value_counts(dropna=False,normalize=True).values[0])\n    if train[col].value_counts(dropna=False,normalize=True).values[0] >= 0.90:\n      #  print(\"More than 90% is NA's or same value so we can delete that columns\")\n        more_than_90_NA_or_same_value_train.append(col) # more unique values in train\nfor col in test.columns:\n    if test[col].value_counts(dropna=False,normalize=True).values[0]>=0.90:\n        more_than_90_NA_or_same_value_test.append(col) #more unique values in test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store the columns to be dropped separately in train and test\ncols_drop_at_train=list(set(more_than_90_NA_or_same_value_train+many_na_train))\ncols_drop_at_test=list(set(more_than_90_NA_or_same_value_test+many_na_test))\nprint(\"Columns to be dropped in train\",len(cols_drop_at_train))\nprint(\"Columns to be dropped in test\",len(cols_drop_at_test))\nprint(\"columns are @ train:\",cols_drop_at_train)\nprint(\"columns are @ test:\", cols_drop_at_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_drop_cols=list(set(cols_drop_at_train+cols_drop_at_test))\nprint(\"Total no of columns to be deleted to increase your model performance\",len(total_drop_cols))\nprint(\"They are:\",total_drop_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the isFraud\ntotal_drop_cols.remove('isFraud')\nprint(\"You can check thta column is removed:\",total_drop_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(total_drop_cols, axis=1)\ntest.drop(total_drop_cols, axis=1)\nprint(len(train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['TransactionDT'], hist=True, kde=True,bins=40) # its shows histogram along with the density plot\nsns.distplot(test['TransactionDT'],hist=True,kde=True,bins=40)\nplt.title('Density Plot of  TransactionDT  in training data')\nplt.xlabel(' TransactionDT')\nplt.ylabel('Counts')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}