{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold,KFold\nfrom datetime import datetime\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n# Suppr warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport itertools\nfrom scipy import interp\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import rcParams\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest_df = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(\"Train shape : \"+str(train_df.shape))\nprint(\"Test shape  : \"+str(test_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop sequence...\ntrain_df = train_df.reset_index()\ntest_df = test_df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['nulls1'] = train_df.isna().sum(axis=1)\ntest_df['nulls1'] = test_df.isna().sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop([\"TransactionDT\"], axis = 1)\ntest_df = test_df.drop([\"TransactionDT\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KISS\ntrain_df = train_df.iloc[:, :53]\ntest_df = test_df.iloc[:, :52]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_transaction, train_identity, test_transaction, test_identity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']\n#https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499#latest_df-579654\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    train_df[c + '_bin'] = train_df[c].map(emails)\n    test_df[c + '_bin'] = test_df[c].map(emails)\n    \n    train_df[c + '_suffix'] = train_df[c].map(lambda x: str(x).split('.')[-1])\n    test_df[c + '_suffix'] = test_df[c].map(lambda x: str(x).split('.')[-1])\n    \n    train_df[c + '_suffix'] = train_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    test_df[c + '_suffix'] = test_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c1, c2 in train_df.dtypes.reset_index().values:\n    if c2=='O':\n        train_df[c1] = train_df[c1].map(lambda x: str(x).lower())\n        test_df[c1] = test_df[c1].map(lambda x: str(x).lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [\"TransactionAmt\", \"nulls1\", \"dist1\", \"dist2\"] + [\"C\" + str(i) for i in range(1, 15)] + \\\n            [\"D\" + str(i) for i in range(1, 16)] + \\\n            [\"V\" + str(i) for i in range(1, 340)]\ncategorical = [\"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n               \"P_emaildomain_bin\", \"P_emaildomain_suffix\", \"R_emaildomain_bin\", \"R_emaildomain_suffix\",\n               \"P_emaildomain\", \"R_emaildomain\",\n              \"DeviceInfo\", \"DeviceType\"] + [\"id_0\" + str(i) for i in range(1, 10)] +\\\n                [\"id_\" + str(i) for i in range(10, 39)] + \\\n                 [\"M\" + str(i) for i in range(1, 10)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [col for col in numerical if col in train_df.columns]\ncategorical = [col for col in categorical if col in train_df.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nan2mean(df):\n    for x in list(df.columns.values):\n        if x in numerical:\n            #print(\"___________________\"+x)\n            #print(df[x].isna().sum())\n            df[x] = df[x].fillna(0)\n           #print(\"Mean-\"+str(df[x].mean()))\n    return df\ntrain_df=nan2mean(train_df)\ntest_df=nan2mean(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding\ncategory_counts = {}\nfor f in categorical:\n    train_df[f] = train_df[f].replace(\"nan\", \"other\")\n    train_df[f] = train_df[f].replace(np.nan, \"other\")\n    test_df[f] = test_df[f].replace(\"nan\", \"other\")\n    test_df[f] = test_df[f].replace(np.nan, \"other\")\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n    train_df[f] = lbl.transform(list(train_df[f].values))\n    test_df[f] = lbl.transform(list(test_df[f].values))\n    category_counts[f] = len(list(lbl.classes_)) + 1\n# train_df = train_df.reset_index()\n# test_df = test_df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfor column in numerical:\n    scaler = StandardScaler()\n    if train_df[column].max() > 100 and train_df[column].min() >= 0:\n        train_df[column] = np.log1p(train_df[column])\n        test_df[column] = np.log1p(test_df[column])\n    scaler.fit(np.concatenate([train_df[column].values.reshape(-1,1), test_df[column].values.reshape(-1,1)]))\n    train_df[column] = scaler.transform(train_df[column].values.reshape(-1,1))\n    test_df[column] = scaler.transform(test_df[column].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.tabular import *\nfrom sklearn.metrics import roc_auc_score\n\ndef auroc_score(input, target):\n    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n    return roc_auc_score(target, input)\n\nclass AUROC(Callback):\n    _order = -20 #Needs to run before the recorder\n\n    def __init__(self, learn, **kwargs): self.learn = learn\n    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n    \n    def on_batch_end(self, last_target, last_output, train, **kwargs):\n        if not train:\n            self.output.append(last_output)\n            self.target.append(last_target)\n                \n    def on_epoch_end(self, last_metrics, **kwargs):\n        if len(self.output) > 0:\n            output = torch.cat(self.output)\n            target = torch.cat(self.target)\n            preds = F.softmax(output, dim=1)\n            metric = auroc_score(preds, target)\n            return add_metrics(last_metrics, [metric])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dep_var='isFraud' \nprocs = [FillMissing, Categorify, Normalize]\ntest_all = TabularList.from_df(test_df, cat_names=categorical,cont_names=numerical,procs=procs)\ndata = (TabularList.from_df(train_df, cat_names=categorical, cont_names=numerical,procs=procs)\n                           .split_subsets(train_size=0.85, valid_size=0.15, seed=34)\n                           .label_from_df(cols=dep_var)\n                           .add_test(test_all)\n                           .databunch())       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = tabular_learner(data, layers=[200,100],metrics=accuracy, callback_fns=AUROC)\n#learn = tabular_learner(data, layers=[1000,500,100],emb_drop=0.04,ps=(0.001, 0.01, 0.1),metrics=accuracy, callback_fns=AUROC,wd=1e-2)#.to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit(10,lr=1e-2)\n#learn.fit(30,lr=3e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\n#learn.fit_one_cycle(10,max_lr=1e-6)\nlearn.fit_one_cycle(10,max_lr=5e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.freeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\n#learn.fit_one_cycle(10,max_lr=1e-6)\nlearn.fit_one_cycle(1,max_lr=1e-8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample_submission.isFraud = test_pred[0][:,1].numpy()\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample_submission.to_csv('simple_fastai_v3.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}