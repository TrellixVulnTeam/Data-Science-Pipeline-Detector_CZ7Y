{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install graphviz;\n#!pip uninstall dtreeviz","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## look into the dater\n#from fastbook import *\n#from kaggle import api\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.tree import DecisionTreeRegressor\n#!pip install dtreeviz\n#from dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_auc_score, plot_confusion_matrix, precision_score, recall_score, classification_report, plot_roc_curve, roc_curve\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## pandas\npd.options.display.max_rows = 20\npd.options.display.max_columns = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_path = \"../input/ieee-fraud-detection-joined-tables/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"## 1. Create df from 100k sample and then go to random 50k sample\ndf = pd.read_csv(main_path+\"tr_sample-100k.csv\")\ndf = df.sample(50000, random_state=42)\n# #df_te= pd.read_csv(main_path + \"te_tran_iden.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Undersampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## 2. Take all samples of isFraud=True and Random Samples of isFraud=False\n# df = pd.read_csv(main_path+\"tr_tran_iden.csv\")\n# ### ratio of true and false\n# print(df.isFraud.value_counts()[1]/len(df.isFraud) *100)\n# print(df[\"isFraud\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df1 = df[df[\"isFraud\"]==False].sample(50000, random_state=42)\n# df2 = df[df[\"isFraud\"]==True]\n# df = pd.concat([df1,df2], ignore_index=True)\n# df.shape, df1.shape, df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ### ratio of true and false\n# df.isFraud.value_counts()[1]/len(df.isFraud) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## oversampling (with replacement)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## Get dataset\n# df = pd.read_csv(main_path+\"tr_sample-100k.csv\")\n# ### ratio of true and false\n# df = df.sample(50000,random_state=42)\n# df.isFraud.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## sort by time\n# df.sort_values(\"TransactionDT\", inplace=True)\n# df.reset_index(drop=True, inplace=True)\n# df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## split the data into train and valid\n# df1 = df.iloc[0:int(0.8*len(df)),]\n# df2 = df.iloc[int(0.8*len(df)):len(df),]\n# df1.shape,df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## Mix both the ROSed train dater and valid dater\n# from imblearn.over_sampling import RandomOverSampler\n# ros = RandomOverSampler(random_state=42)\n\n# X,Y = ros.fit_resample(df1,df1[\"isFraud\"])\n# df=pd.concat([X,df2], ignore_index=True)\n# df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(X)/len(df), df.isFraud.value_counts(), df2.isFraud.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check Dater "},{"metadata":{"trusted":true},"cell_type":"code","source":"## check tables for missing values in join column\ncol = \"shape\", \"columns with nans \", \"nans in TransactioniD\"\nind = \"train\",\"test\"\nlst1 = [df.shape, sum(df.isna().sum()>0), df.TransactionID.isna().sum()]\n#lst2 = [df_te.shape, sum(df_te.isna().sum()>0), df_te.TransactionID.isna().sum()]\n#pd.DataFrame([lst1,lst2], columns=col,index=ind)\nlst1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Class imbalance? Might need to upsample or downsample???? Isn't usage of false positves and true positives overcoming imbalance?\nsum(df[\"isFraud\"]==True)/len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trimming col from the dater"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"## remove columns with nans>300k\n##[((df.isna().sum()>n/2*1e5).sum(),n/2) for n in range(1,13)]\n#to_drop = df.columns[df.isna().sum()>300000].to_list()\nto_drop=[] # forcing to use all variables\ndf.drop(to_drop,1, inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tabular Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"## sort by time\ndf.sort_values(\"TransactionDT\", inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## split to train and valid ind linearly\nmsk = np.arange(len(df))<0.8*len(df) #usually 0.8, 0.8851 for the oversampling case\nsplits = (list(np.where(msk)[0]),list(np.where(~msk)[0]))\nlen(splits[0])+len(splits[1]), len(df), len(splits[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## variables for TP\ndep_var = \"isFraud\"\nprocs = [Categorify,FillMissing]\n## Cont and Cat variables\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check if cont variables in test have nans where train doesn't\n#def na_check(col): return df.loc[:,col].isna().sum()>0,df_te.loc[:,col].isna().sum()>0\n#na_col = {col: na_check(col) for col in cont}\n#na_col_te = [col for col in cont if df.loc[:,col].isna().sum()==0 and df_te.loc[:,col].isna().sum()>0]\nna_col_te = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isFraud.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add a last row with nans for col:na_col_te\n#df.insert(0,df.columns,df.median())\n\ndf = pd.concat([df.median().to_frame().T, df], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.index[0],na_col_te] = np.nan\ndf.loc[df.index[0],\"isFraud\"]=1 ## forcing it to be an int rather than in between like 0.5\ndf.loc[df.index[0],na_col_te]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isFraud.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\nlen(to.train)+len(to.valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.items.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.valid.show(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = to.valid.items\ntemp.isFraud.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##vocab\nto.classes[\"ProductCD\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_pickle(\"to.pkl\",to)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_pickle(\"to.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rf(xs, y, n_estimators=40, max_samples=0.6,#20_000,#200_000,\n       max_features=0.8, min_samples_leaf=5, sample_weight=None, **kwargs):\n    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True,random_state=42).fit(xs, y,sample_weight)#, class_weight=\"balanced_subsample\").fit(xs, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\nxs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## Oversampling SMOTE\n# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(random_state=42, n_jobs=-1,k_neighbors=15)\n\n# X,Y = sm.fit_resample(xs,y)\n# m = rf(X,Y)\n#Y.value_counts(), y.value_counts(),","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #oversampling\n# from imblearn.over_sampling import RandomOverSampler\n# ros = RandomOverSampler(random_state=42)\n\n# X,Y = ros.fit_resample(xs,y)\n# m = rf(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Weighting the samples\n# wt = y.value_counts()[0]/y.value_counts()[1]\n# y.value_counts(),wt\n#sample_weight = np.array([0.88 if i == 0 else 23 for i in y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## m = DecisionTreeRegressor(max_leaf_nodes=4)\n## m.fit(xs, y);\nm = rf(xs,y)#,sample_weight=sample_weight)\n#Y=y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m1 = m.estimators_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check the leaves are much lesser than the length of samples.\nmax([t.get_n_leaves() for t in m.estimators_]), m.max_samples*len(xs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(m.feature_importances_).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = rf_feat_importance(m,xs)\nfi[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi[:50]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_keep = fi[fi.imp>0.005].cols\nlen(to_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi.imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xs_cp = xs.copy()\nvalid_xs.cp = valid_xs.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xs= xs[to_keep]\nvalid_xs = valid_xs[to_keep]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xs_imp.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=rf(xs,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RF metrics deep dive"},{"metadata":{"trusted":true},"cell_type":"code","source":"## checking if mean of all estimators gives the random forest results\npreds_p = np.stack([t.predict_proba(valid_xs)[:,1] for t in m.estimators_])\nr_mse(m.predict_proba(valid_xs)[:,1],preds_p.mean(0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## how AUC score changes with n_estimators_\nplt.plot([roc_auc_score(valid_y, preds_p[:i+1].mean(0)) for i in range(len(m.estimators_))]); # n_estimators seems fine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.max_samples","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OUT OF BAGs"},{"metadata":{"trusted":true},"cell_type":"code","source":"## predict proba of OOB\ny_oob = m.oob_decision_function_[:,1]\ny_oob.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oob_auc = roc_auc_score(y,m.oob_decision_function_[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr,tpr,_ = roc_curve(y,y_oob)\nplt.plot(fpr,tpr, label='AUC = ' + str(round(roc_auc_score(y,m.oob_decision_function_[:,1]), 2)))\nplt.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y,y_oob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{},"cell_type":"markdown","source":"## STD across trees gives confidence in the readings"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_p.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_p_std = preds_p.std(0)\npreds_p_std[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(preds_p_std).describe() ## Can look at individual rows prediction std from different trees.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Output of Valid dater"},{"metadata":{"trusted":true},"cell_type":"code","source":"## how unbalanced is the train and the valid, they look the same to me. :)\ny.value_counts()[1]/y.value_counts()[0] *100, valid_y.value_counts()[1]/valid_y.value_counts()[0] *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Metrics functions\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n#def m_accuracy(m,xs,y): return sum(m.predict(xs)==y)/len(xs)\ndef m_accuracy2(m,xs,y): return m.score(xs,y)\ndef m_conf(m,xs,y): \n    plot_confusion_matrix(m,xs,y)\n    return confusion_matrix(y, m.predict(xs))\ndef m_prec(m,xs,y): return precision_score(y,m.predict(xs), average=None, labels=[1,0])\ndef m_recall(m,xs,y): return recall_score(y,m.predict(xs), average=None, labels=[1,0])\ndef m_rep(m,xs,y): return classification_report(y, m.predict(xs), labels=[1,0], digits=4, output_dict=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## See predicted column. Does it match expectations\npd.DataFrame(m.predict(xs)).describe() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## prec recal train\ntr_rep = m_rep(m,xs,y)\nprint(tr_rep[\"1\"][\"recall\"]) ## sensitivity TPR\nprint(tr_rep[\"0\"][\"recall\"]) ## TNR\nprint(1- tr_rep[\"0\"][\"recall\"]) ## 1-specificity FPR\nprint(tr_rep[\"1\"][\"precision\"])\nprint(tr_rep[\"0\"][\"precision\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## prec recal valid\nvd_rep = m_rep(m,valid_xs,valid_y)\nprint(vd_rep[\"1\"][\"recall\"]) ## sensitivity TPR\nprint(vd_rep[\"0\"][\"recall\"]) ## TNR\nprint(1- vd_rep[\"0\"][\"recall\"]) ## 1-specificity FPR\nprint(vd_rep[\"1\"][\"precision\"])\nprint(vd_rep[\"0\"][\"precision\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_roc_curve(m,xs,y,response_method=\"decision_function\") not working \nplt.plot(fpr,tpr, label='AUC = ' + str(round(roc_auc_score(y,m.oob_decision_function_[:,1]), 2)))\nplt.legend(loc='lower right')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## plot ROC\nplot_roc_curve(m,xs,y)\nplot_roc_curve(m,valid_xs,valid_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## AUC score\nprint(roc_auc_score(y,m.predict_proba(xs)[:,1]), roc_auc_score(valid_y,m.predict_proba(valid_xs)[:,1]))\n## recall\nprint(\"\\n\",tr_rep[\"1\"][\"recall\"]) ## sensitivity TPR\nprint(tr_rep[\"0\"][\"recall\"]) ## TNR\n##valid\nprint(vd_rep[\"1\"][\"recall\"]) ## sensitivity TPR\nprint(vd_rep[\"0\"][\"recall\"]) ## TNR\n## precision\nprint(tr_rep[\"1\"][\"precision\"])\nprint(tr_rep[\"0\"][\"precision\"])\n## valid precision\nprint(vd_rep[\"1\"][\"precision\"])\nprint(vd_rep[\"0\"][\"precision\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(round(roc_auc_score(y,m.predict_proba(xs)[:,1]),4),\";\",round(roc_auc_score(y,m.oob_decision_function_[:,1]),4),\";\",round(roc_auc_score(valid_y,m.predict_proba(valid_xs)[:,1]),4),\";\",\n      round(tr_rep[\"1\"][\"recall\"],4),\",\", round(tr_rep[\"0\"][\"recall\"],4),\";\",\n      round(vd_rep[\"1\"][\"recall\"],4), \",\",round(vd_rep[\"0\"][\"recall\"],4),\";\",\n      round(tr_rep[\"1\"][\"precision\"],4),\",\",round(tr_rep[\"0\"][\"precision\"],4),\";\",\n      round(vd_rep[\"1\"][\"precision\"],4),\",\",round(vd_rep[\"0\"][\"precision\"],4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_score(y,m.predict(xs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resources\nMore info on the dater\n1. https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203 \n1. [Notebook on RF](https://www.kaggle.com/raviolli77/random-forest-in-python#Training-Algorithm)\n2. [searching hyperparameters](https://www.kaggle.com/raviolli77/random-forest-in-python#Creating-Training-and-Test-Sets)\n3. [8 tactics to combat unbalanced datersets](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n4. [Kaggle notebook on unbalanced datersets](https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets)\n5. [Survey of predictive modeling with imbalnced datersets](https://arxiv.org/abs/1505.01658)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}