{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install graphviz;\n#!pip uninstall dtreeviz","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## look into the dater\n#from fastbook import *\n#from kaggle import api\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.tree import DecisionTreeRegressor\n#!pip install dtreeviz\n#from dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## pandas\npd.options.display.max_rows = 20\npd.options.display.max_columns = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_path = \"../input/ieee-fraud-detection-joined-tables/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(main_path+\"tr_sample-100k.csv\")\ndf_te= pd.read_csv(main_path + \"te_tran_iden.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## ratio of true and false\ndf.isFraud.value_counts()[1]/df.isFraud.value_counts()[0] *100","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"df = df.sample(50000, random_state=42)\n#df_te = df_te.sample(50000, random_state=42)\ndf.isFraud.value_counts()[1]/df.isFraud.value_counts()[0] *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check Dater "},{"metadata":{"trusted":true},"cell_type":"code","source":"## check tables for missing values in join column\ncol = \"shape\", \"columns with nans \", \"nans in TransactioniD\"\nind = \"train\",\"test\"\nlst1 = [df.shape, sum(df.isna().sum()>0), df.TransactionID.isna().sum()]\nlst2 = [df_te.shape, sum(df_te.isna().sum()>0), df_te.TransactionID.isna().sum()]\npd.DataFrame([lst1,lst2], columns=col,index=ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## All colaths from test in train\nset(df_te.columns).issubset(set(df.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Class imbalance? Might need to upsample or downsample???? Isn't usage of false positves and true positives overcoming imbalance?\nsum(df[\"isFraud\"]==True)/len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trimming col from the dater"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"## remove columns with nans>300k\n##[((df.isna().sum()>n/2*1e5).sum(),n/2) for n in range(1,13)]\n#to_drop = df.columns[df.isna().sum()>300000].to_list()\nto_drop=[] # forcing to use all variables\ndf.drop(to_drop,1, inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tabular Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"## sort by time\ndf.sort_values(\"TransactionDT\", inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## split to train and valid ind linearly\nmsk = np.arange(len(df))<0.8*len(df)\nsplits = (list(np.where(msk)[0]),list(np.where(~msk)[0]))\nlen(splits[0])+len(splits[1]), len(df), len(splits[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## variables for TP\ndep_var = \"isFraud\"\nprocs = [Categorify,FillMissing]\n## Cont and Cat variables\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check if cont variables in test have nans where train doesn't\n#def na_check(col): return df.loc[:,col].isna().sum()>0,df_te.loc[:,col].isna().sum()>0\n#na_col = {col: na_check(col) for col in cont}\nna_col_te = [col for col in cont if df.loc[:,col].isna().sum()==0 and df_te.loc[:,col].isna().sum()>0]\nna_col_te\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add a last row with nans for col:na_col_te\n#df.insert(0,df.columns,df.median())\n\ndf = pd.concat([df.median().to_frame().T, df], ignore_index=True)\n\ndf.loc[df.index[0],na_col_te] = np.nan\ndf.loc[df.index[0],na_col_te]\n#df.median()\n#df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\nlen(to.train)+len(to.valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.items.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.valid.show(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##vocab\nto.classes[\"ProductCD\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_pickle(\"to.pkl\",to)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_pickle(\"to.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rf(xs, y, n_estimators=40, max_samples=20_000,#200_000,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\nxs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#m = DecisionTreeRegressor(max_leaf_nodes=4)\n#m.fit(xs, y);\nm = rf(xs,y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Output of Test dater"},{"metadata":{},"cell_type":"markdown","source":"Outputs that are interesting are model accuracy, maybe f1score?, model ROC,AOC?-"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Metrics functions\ndef r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\ndef m_rmse_p(m, xs, y): return r_mse(m.predict_proba(xs), y)\n#def m_accuracy(m,xs,y): return sum(m.predict(xs)==y)/len(xs)\ndef m_accuracy2(m,xs,y): return m.score(xs,y)\ndef m_conf(m,xs,y): return confusion_matrix(y, m.predict(xs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## See predicted column. Does it match expectations\npd.DataFrame(m.predict(xs)).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Accuracy\nm_accuracy2(m, xs, y), m_accuracy2(m, valid_xs, valid_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Rmse (probably not useful)\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Confusion Matrix\nm_conf(m,xs,y), m_conf(m,valid_xs,valid_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.predict_proba(valid_xs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_roc_curve\nplot_roc_curve(m,valid_xs,valid_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(m,xs,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ## predict on test dater"},{"metadata":{"trusted":true},"cell_type":"code","source":"## check rows with nan values and compare with train dset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## drop from test dater\ndf_te.drop(to_drop,1, inplace=True)\ndf_te.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## make new Tabular Pandas for test dataset\nto_tst = to.new(df_te)\nto_tst.process()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## \"isFraud\" is a cont variable?\n# to_classes[\"isFraud\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.classes[\"ProductCD\"], to_tst.classes[\"ProductCD\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.items.isFraud.astype(\"category\").describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## make predictions \ntest_xs = to_tst.xs\npred = m.predict_proba(test_xs)\npred[:,1]#1 is the class we are interested in, i.e, 0,1...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(pred).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.classes_[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Make into submission dataframe\nlst_pred = [df_te[\"TransactionID\"].to_list(),pred[:,1]]\nlen(lst_pred)\ndf_pred = pd.DataFrame({\"TransactionID\":lst_pred[0],\"isFraud\":lst_pred[1]})\ndf_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred.to_csv(\"my_subs.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resources\nMore info on the dater\n1. https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203 \n1. [Notebook on RF](https://www.kaggle.com/raviolli77/random-forest-in-python#Training-Algorithm)\n2. [searching hyperparameters](https://www.kaggle.com/raviolli77/random-forest-in-python#Creating-Training-and-Test-Sets)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}