{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Content\n\n- load data\n- Missing Data.\n- Imbalanced problem.\n\n\n- Plots\n    - Taget hist\n    \n    \n- Models\n    - LogisticRegression\n\n----\n\n### References:\n\n- https://www.kaggle.com/jesucristo/fraud-detection-eda-model-kfold"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport warnings\nimport gc\nimport time\nfrom tqdm import tqdm\nimport functools\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n\ndef read_csv(path):\n  # logger.debug('enter')\n  df = pd.read_csv(path)\n  # logger.debug('exit')\n  return df\n\ndef load_train_data():\n  # logger.debug('enter')\n  df = read_csv(SALES_TRAIN_V2)\n  # logger.debug('exit')\n  return df\n\ndef load_test_data():\n  # logger.debug('enter')\n  df = read_csv(TEST_DATA)\n  # logger.debug('exit')\n  return df\n\ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n\ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset,keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    print('After drop shape:', data.shape)\n    after = data.shape[0]\n    print('Total Duplicate:', before-after)\n\ndef unresanable_data(data):\n    print(\"Min Value:\",data.min())\n    print(\"Max Value:\",data.max())\n    print(\"Average Value:\",data.mean())\n    print(\"Center Point of Data:\",data.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SAMPLE_SUBMISSION    = '../input/sample_submission.csv'\nTRAIN_DATA           = '../input/train_identity.csv'\nTRAIN_TR_DATA        = '../input/train_transaction.csv'\nTEST_DATA            = '../input/test_identity.csv'\nTEST_TR_DATA         = '../input/test_transaction.csv'\n\ndf_sample            = read_csv(SAMPLE_SUBMISSION)\ndf_train_id          = read_csv(TRAIN_DATA)\ndf_train_tr          = read_csv(TRAIN_TR_DATA)\ndf_test_id           = read_csv(TEST_DATA)\ndf_test_tr           = read_csv(TEST_TR_DATA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph_insight(df_train_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_tr['isFraud'].hist(bins =4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_tr.query('isFraud==0').shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_tr.query('isFraud==1').shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## data is imbalanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.merge(df_train_tr, df_train_id, how='left', on='TransactionID')\ndf_test = pd.merge(df_test_tr, df_test_id, how='left', on='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.fillna(0)\ndf_test = df_test.fillna(0)\n\ncat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']\nfor col in cat_cols:\n    if col in df_train.columns:\n        le = LabelEncoder()\n        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n        df_test[col] = le.transform(list(df_test[col].astype(str).values))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",df[col].dtype)            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n                NAlist.append(col)\n                df[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)    \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",df[col].dtype)\n            print(\"******************************\")\n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return df, NAlist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, NAlist = reduce_mem_usage(df_train)\ndf_test, NAlist_t = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [c for c in df_train.columns if c not in ['TransactionID', 'isFraud']]\noof = np.zeros(len(df_train))\npreds = np.zeros(len(df_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=25, random_state=42)\nfor train_index, test_index in skf.split(df_train.iloc[:,1:-1], df_train['isFraud']):\n    clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)\n    clf.fit(df_train.loc[train_index][cols],df_train.loc[train_index]['isFraud'])\n    oof[test_index] = clf.predict_proba(df_train.loc[test_index][cols])[:,1]\n    preds += clf.predict_proba(df_test[cols])[:,1] / 25.0\n    \nauc = roc_auc_score(df_train['isFraud'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample['isFraud'] = preds\ndf_sample.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}