{"cells":[{"metadata":{},"cell_type":"markdown","source":"Questions \n"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:18:29.287627Z","start_time":"2019-08-21T02:18:29.277683Z"},"hide_input":false,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom time import time\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:19:17.749993Z","start_time":"2019-08-21T02:18:29.624473Z"},"trusted":true},"cell_type":"code","source":"%%time\n# dataset_path = '../datasets/fraud_datasets/' # Local Notebook\ndataset_path = '../input/ieee-fraud-detection/' # Kaggle Notebook\n\n# sample_submission_df = pd.read_csv(f'{dataset_path}sample_submission.csv')\n\ntrain_transaction_df = pd.read_csv(f'{dataset_path}train_transaction.csv')\ntest_transaction_df = pd.read_csv(f'{dataset_path}test_transaction.csv')\n\ntrain_id_df = pd.read_csv(f'{dataset_path}train_identity.csv')\ntest_id_df = pd.read_csv(f'{dataset_path}test_identity.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After importing our raw datasets, they need to be merged by TransactionID's.\n\n<b>(Note: throughout this notebook, it will be important to delete any dataframes that will not be used again as they take up space in memory and slow our machine down.)</b>"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:19:48.152927Z","start_time":"2019-08-21T02:19:17.756596Z"},"trusted":true},"cell_type":"code","source":"%%time\ntrain = train_transaction_df.merge(train_id_df, on='TransactionID', how='left', left_index=True, right_index=True)\ntest = test_transaction_df.merge(test_id_df, on='TransactionID', how='left', left_index=True, right_index=True)\n\n# Renaming columns for better description\nnames = {\n    'addr1': 'billing zipcode',\n    'addr2': 'country codes',\n    'P_emaildomain': 'Purchaser_email.dom',\n    'R_emaildomain': 'Retailer_email.dom'\n}\n\ntrain.rename(columns=names, inplace=True)\ntest.rename(columns=names, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:19:48.626805Z","start_time":"2019-08-21T02:19:48.169883Z"},"trusted":true},"cell_type":"code","source":"del train_transaction_df, train_id_df, test_transaction_df, test_id_df","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:49.135267Z","start_time":"2019-08-21T02:01:40.879379Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# # This is for local environment\n# eda_output_path = 'eda_output/'\n# feat_over_file = 'feature_overview.txt'\n\n# if os.path.exists(f'{eda_output_path}{feat_over_file}'):\n#     os.remove(f'{eda_output_path}{feat_over_file}')\n\n# with open(f'{eda_output_path}{feat_over_file}', 'a') as overview_file:\n#     for col, values in train.iteritems():\n#         overview_file.write(f'{col}: {values.nunique()} ({values.dtypes})\\n')\n#         overview_file.write(str(values.unique()[:100]))\n#         overview_file.write(\n#             '\\n\\n###########################################################\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we examine the feature_overview.txt file, we notice that there are many continuous features and some categorical features."},{"metadata":{},"cell_type":"markdown","source":"### Missing Values"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:55.742524Z","start_time":"2019-08-21T02:01:49.139141Z"},"trusted":true},"cell_type":"code","source":"train_contains_na = train.isna().any().sum()\ntest_contains_na = test.isna().any().sum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:55.751952Z","start_time":"2019-08-21T02:01:55.745227Z"},"trusted":true},"cell_type":"code","source":"print(f'{train_contains_na} out of {len(train.columns)} columns contain missing values in the train data')\nprint(f'{test_contains_na} out of {len(test.columns)} columns contain missing values in the test data')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.527781Z","start_time":"2019-08-21T02:01:55.753943Z"},"trusted":true},"cell_type":"code","source":"# Calculating percentage of missing values in each column\ntrain_missing_values = train.isna().mean().round(2)\ntest_missing_values = test.isna().mean().round(2)\n\n# Keeping only columns that contain more than 5% missing values\ntrain_missing_values_5 = train_missing_values[train_missing_values.values > 0.05]\ntest_missing_values_5 = test_missing_values[test_missing_values.values > 0.05]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.535761Z","start_time":"2019-08-21T02:01:58.529775Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"print(f'{len(train_missing_values_5)} out of {len(train.columns)} columns in the train data contain more than 5% missing values')\nprint(f'{len(test_missing_values_5)} out of {len(test.columns)} columns in the test data contain more than 5% missing values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are a large number of missing values in the data."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.552715Z","start_time":"2019-08-21T02:01:58.537754Z"},"trusted":true},"cell_type":"code","source":"# Keeping only columns that contain more than 50% missing values\ntrain_missing_values_50 = train_missing_values[train_missing_values.values > 0.5]\ntest_missing_values_50 = test_missing_values[test_missing_values.values > 0.5]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.568672Z","start_time":"2019-08-21T02:01:58.554708Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"print(f'{len(train_missing_values_50)} out of {len(train.columns)} columns in the train data contain more than 50% missing values')\nprint(f'{len(test_missing_values_50)} out of {len(test.columns)} columns in the test data contain more than 50% missing values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Feature: isFraud"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.588619Z","start_time":"2019-08-21T02:01:58.570666Z"},"trusted":true},"cell_type":"code","source":"isFraud = 'isFraud'","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.607569Z","start_time":"2019-08-21T02:01:58.590614Z"},"trusted":true},"cell_type":"code","source":"# Plot Function\ndef PlotFunction(df, feature, title, xLable, yLabel, vertical=False, percentLabels=False, size=[10, 7]):\n    plt.style.use('ggplot')\n\n    f = plt.figure(figsize=size)\n    ax = f.add_subplot(1, 1, 1)\n    ax.title.set_text(title)\n    ax.set_ylabel(yLabel)\n    ax.set_xlabel(xLable)\n\n    plot = ax.bar([str(i) for i in df[feature].value_counts(dropna=False, normalize=True).index],\n                  df[feature].value_counts(dropna=False, normalize=True), 0.40,\n                  color=['cornflowerblue', 'darkorange', 'green', 'brown', 'black'])\n    if vertical:\n        plt.xticks(rotation=90)\n\n    # Add counts above the two bar graphs\n    if percentLabels:\n        percentages = (df[feature].value_counts(\n            dropna=False, normalize=True)*100).round(3)\n        i = 0\n        for rect in plot:\n            height = rect.get_height()\n            plt.text(rect.get_x() + rect.get_width()/2.0, height,\n                     f'{percentages[i]}%', ha='center', va='bottom')\n            i += 1","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.627515Z","start_time":"2019-08-21T02:01:58.609564Z"},"trusted":true},"cell_type":"code","source":"print(f'These are the two types of values for fraud: {train[isFraud].unique()}')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.642474Z","start_time":"2019-08-21T02:01:58.629509Z"},"trusted":true},"cell_type":"code","source":"print(f'isFraud contains {train[isFraud].isna().any() * 1} missing values')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:58.980566Z","start_time":"2019-08-21T02:01:58.644469Z"},"trusted":true},"cell_type":"code","source":"### 'Fraud' Feature\nPlotFunction(train, isFraud, 'isFaud percentages', 'Not fraud | Fraud', 'Number of occurances', percentLabels=True)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A visual examination of the graph reveals an imbalance in the number of fraudulent transactions.\n\nTo correct this imbalanace, the use of a sampling method such as SMOTE or oversampling will be needed."},{"metadata":{},"cell_type":"markdown","source":"### Exploring the Features"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:59.336483Z","start_time":"2019-08-21T02:01:58.982253Z"},"trusted":true},"cell_type":"code","source":"# 'TransactionAmt' feature\nplt.figure(figsize=[12, 5])\nplt.title('Transaction Amounts')\nplt.xlabel('Amount')\nplt.ylabel('Number of transactions')\n_ = plt.hist(train['TransactionAmt'], bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a clear right skew to this data. I will try a log transformation to reduce this effect."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:01:59.988838Z","start_time":"2019-08-21T02:01:59.338478Z"},"trusted":true},"cell_type":"code","source":"# 'TransactionAmt' feature\nplt.figure(figsize=[12, 5])\nplt.title('Transaction Amounts')\nplt.xlabel('Amount')\nplt.ylabel('Number of transactions')\n_ = plt.hist(train['TransactionAmt'].apply(np.log), bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'TransactionAmt' now shows a normal distribution, we can separate which transactions were fraudulent and compare whether they are larger."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:00.62893Z","start_time":"2019-08-21T02:01:59.99183Z"},"trusted":true},"cell_type":"code","source":"# 'TransactionAmt' feature\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 3))\n\n# Not Fraud\nax1.title.set_text('Non-Fraudulent Transaction Amounts')\nax1.set_xlabel('LgAmount')\nax1.set_ylabel('Number of transactions')\n_ = ax1.hist(train['TransactionAmt']\n             [train['isFraud'] == 0].apply(np.log), bins=100)\n\n# Fraud\nax2.title.set_text('Fraudulent Transaction Amounts')\nax2.set_xlabel('LgAmount')\nax2.set_ylabel('Number of transactions')\n_ = ax2.hist(train['TransactionAmt']\n             [train['isFraud'] == 1].apply(np.log), bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, we can see that the fraudulent transaction amounts seem to be higher on average."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:00.904451Z","start_time":"2019-08-21T02:02:00.629928Z"},"trusted":true},"cell_type":"code","source":"### 'ProductCD' feature\nPlotFunction(train, 'ProductCD', 'Product codes for each transaction', 'Product Codes', 'Count', percentLabels=True)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:01.111934Z","start_time":"2019-08-21T02:02:00.908439Z"},"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=[15, 5])\nax = f.add_subplot(1, 1, 1)\nax.title.set_text('Percentage of products from fraudulent transactions')\nax.set_ylabel('Percent')\nax.set_xlabel('Products')\n\nplot = ax.bar([str(i) for i in train['ProductCD'][train['isFraud'] == 1].value_counts(dropna=False, normalize=True).index],\n              train['ProductCD'][train['isFraud'] == 1].value_counts(\n                  dropna=False, normalize=True), 0.40,\n              color=['cornflowerblue', 'darkorange', 'green', 'brown', 'black'])\n\n# Add counts above the two bar graphs\npercentages = (train['ProductCD'][train['isFraud'] == 1].value_counts(\n    dropna=False, normalize=True)*100).round(3)\ni = 0\nfor rect in plot:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/2.0, height,\n             f'{percentages[i]}%', ha='center', va='bottom')\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two main products involved with fraululent transactions, 'W' and 'C'."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:01.164755Z","start_time":"2019-08-21T02:02:01.113891Z"},"trusted":true},"cell_type":"code","source":"# 'card1' feature\nprint('Number of unique values:', len(train['card1'].unique()))\ntrain['card1'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:01.196668Z","start_time":"2019-08-21T02:02:01.166752Z"},"trusted":true},"cell_type":"code","source":"### 'card2' feature\nprint('Number of unique values:', len(train['card2'].unique()))\ntrain['card2'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'card1' & 'card2 have a large number of unique values with no clear dominating catagory."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:01.23058Z","start_time":"2019-08-21T02:02:01.198664Z"},"trusted":true},"cell_type":"code","source":"### 'card3' feature\nprint('Number of unique values:', len(train['card3'].unique()))\ntrain['card3'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'card3' has 88% of its values being 150."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:01.265486Z","start_time":"2019-08-21T02:02:01.232573Z"},"trusted":true},"cell_type":"code","source":"### 'card5' feature\nprint('Number of unique values:', len(train['card5'].unique()))\ntrain['card5'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'card5' has 50% of its values being 226."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:01.754883Z","start_time":"2019-08-21T02:02:01.267479Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"### 'card4' feature\nPlotFunction(train, 'card4', 'Number of card types', 'Card types', 'Number of card occurrences', percentLabels=True)\n\nprint('Number of unique values:', len(train['card4'].unique()))\ntrain['card4'].value_counts(dropna=False, normalize=True).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'visa' cards are have the highest use in this dataset at 65%."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:02.167465Z","start_time":"2019-08-21T02:02:01.756841Z"},"trusted":true},"cell_type":"code","source":"### 'card6' feature\nPlotFunction(train, 'card6', 'Number of account types', 'Account types', 'Number of account type occurrences', percentLabels=True)\n\nprint('Number of unique values:', len(train['card6'].unique()))\ntrain['card6'].value_counts(dropna=False, normalize=True).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'debit' account types have the highest use in this dataset at 75%."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:02.214342Z","start_time":"2019-08-21T02:02:02.16946Z"},"trusted":true},"cell_type":"code","source":"### 'billing zipcode' feature\nprint('Number of unique values:', len(train['billing zipcode'].unique()))\ntrain['billing zipcode'].value_counts(dropna=False, normalize=True).head(10)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:02.248249Z","start_time":"2019-08-21T02:02:02.216335Z"},"trusted":true},"cell_type":"code","source":"### 'country codes' feature\nprint('Number of unique values:', len(train['country codes'].unique()))\ntrain['country codes'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that 88% of transactions have come from <a href='https://en.wikipedia.org/wiki/List_of_UIC_country_codes'>France</a>. 11% of transactions that do not have a country code, however, it is unlikely that all of these transactions belong to the one country."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:03.500883Z","start_time":"2019-08-21T02:02:02.250244Z"},"trusted":true},"cell_type":"code","source":"### 'Purchaser Email' feature\nPlotFunction(train, 'Purchaser_email.dom', 'Number of Purchaser email types', 'Email types',\n             'Number of email type occurrences', vertical=True, percentLabels=False)\n\nprint('Number of unique values:', len(train['Purchaser_email.dom'].unique()))\ntrain['Purchaser_email.dom'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'gmail.com' accounts for 38% of the emails tied with purchaser transactions."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:04.698965Z","start_time":"2019-08-21T02:02:03.502879Z"},"trusted":true},"cell_type":"code","source":"# 'Purchaser Email' feature\nPlotFunction(train, 'Retailer_email.dom', 'Number of Purchaser email types', 'Email types',\n             'Number of email type occurrences', vertical=True, percentLabels=False)\n\nprint('Number of unique values:', len(train['Purchaser_email.dom'].unique()))\ntrain['Retailer_email.dom'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'gmail.com' accounts for 77% of the emails tied with retailer transactions."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:02:06.400645Z","start_time":"2019-08-21T02:02:04.701956Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"feature_names = ['M1', 'M2', 'M4', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']\n\nfig, axes = plt.subplots(3, 3, figsize=(17, 10))\n\nj = 0\nfor row in axes:\n    for ax in row:\n        ax.set_title(feature_names[j])\n        ax.set_ylabel('Count')\n        ax.set_xlabel(feature_names[j])\n\n        plot = ax.bar([str(i) for i in train[feature_names[j]].value_counts(dropna=False, normalize=True).index],\n                      train[feature_names[j]].value_counts(\n                          dropna=False, normalize=True), 0.40,\n                      color=['cornflowerblue', 'darkorange', 'green', 'brown', 'black'])\n        j += 1\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Missing Values\nDue to the large number of NaN values our dataframes contain, it is critical that they are replaced with a meaningful placeholder."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:19:50.640122Z","start_time":"2019-08-21T02:19:48.65154Z"},"trusted":true},"cell_type":"code","source":"y = train['isFraud'].copy()\nX = train.drop(['isFraud', 'TransactionID'], axis=1) # Dropping TransactionID as it is a useless feature\ndel train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To prevent our model from crashing, it is important to replace missing values with so derived value. The replacement values will be are constant value of -999."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:19:55.572369Z","start_time":"2019-08-21T02:19:50.640122Z"},"trusted":true},"cell_type":"code","source":"%%time\nX = X.fillna(-999)\ntest = test.fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As our model can not accept categorical features as object data types, a label transformation must be preformed."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-21T02:20:42.47015Z","start_time":"2019-08-21T02:19:55.581343Z"},"trusted":true},"cell_type":"code","source":"%%time\nfor feature in X.columns:\n    if X[feature].dtype == 'object' or test[feature].dtype == 'object':\n        le = LabelEncoder()\n        le.fit(list(X[feature].values) + list(test[feature].values))\n        X[feature] = le.transform(list(X[feature].values))\n        test[feature] = le.transform(list(test[feature].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import RandomizedSearchCV\n\n# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n\n# # Parameter grid\n# parameter_grid = {\n#     'n_estimators': list(np.linspace(10, 300, dtype=int)),\n#     'max_depth': None + list(np.linspace(1, 30, dtype=int)),\n#     'max_features': ['auto', 'sqrt']\n# }\n\n# model = RandomForestRegressor(random_state=42)\n# rscv = RandomizedSearchCV(model, parameter_grid, cv=5, n_jobs = -1, random_state=42)\n# rscv.fit(X_train, y_train)\n\n# print(rscv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have our parameters we can use them in the RandomForestRegressor on our test data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = rscv.best_estimator_.predict(X_test)\n\n# model_measures(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nmodel = RandomForestRegressor(n_estimators=258, max_features='sqrt', \n                               max_depth=18, n_jobs=-1, verbose=1)\n\nmodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Roc Auc Score:\",metrics.roc_auc_score(y_test,model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred_rf = rscv.best_estimator_.predict(test[features]) # RSCV\ny_pred_rf = model.predict(test.drop('TransactionID', axis=1)) # Single random forest\n\n# result_path = 'results/' # Local Notebook\n\nfinished_df_rf = pd.DataFrame(test['TransactionID'])\nfinished_df_rf['isFraud'] = y_pred_rf\n\nfinished_df_rf.to_csv('predictions_rf.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}