{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"transaction_data = pd.read_csv(\"../input/train_transaction.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identity_data = pd.read_csv(r\"../input/train_identity.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data = transaction_data.merge(identity_data,how = \"left\",on  = \"TransactionID\")\n\ndel transaction_data\n\ndel identity_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n                \n    return col_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data = final_data.query(\"ProductCD == 'C' \")\n\ncorr_features_1 = correlation(final_data, 0.8)\n\nlen(corr_features_1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data.drop(labels=corr_features_1, axis=1, inplace=True)\n\ns = final_data.isnull().mean()*100\n\ns = s.where(s >15).dropna().index\n\nfinal_data.drop(labels=list(s), axis=1, inplace=True)\n\ndel final_data['TransactionID']\n\ndel final_data['ProductCD']\n\nfor col in ['card1',\n 'card2',\n 'card3',\n 'card4',\n 'card5',\n 'card6',\n 'P_emaildomain',\n 'R_emaildomain',\n 'M4',\n  'DeviceType',\n  'id_12',\n 'id_13',\n 'id_15',\n 'id_17',\n 'id_19',\n 'id_20',\n 'id_28',\n 'id_29',\n 'id_31',\n 'id_35',\n 'id_36',\n 'id_37',\n 'id_38']:\n    \n    temp_df = pd.Series(final_data[col].value_counts() / final_data[col].value_counts().sum())\n    \n    grouping_dict = {\n        k: ('rare' if k not in temp_df[temp_df >= 0.1].index else k)\n        for k in temp_df.index\n    }\n\n    final_data[col] = final_data[col].map(grouping_dict)\n\ndef impute_na(final_data, variable):\n    most_frequent_category = final_data.groupby([variable])[variable].count().sort_values(ascending=False).index[0]\n    final_data[variable].fillna(most_frequent_category, inplace=True)\n\nfor variable in ['card1',\n 'card2',\n 'card3',\n 'card4',\n 'card5',\n 'card6',\n 'P_emaildomain',\n 'R_emaildomain',\n 'M4',\n  'DeviceType',\n  'id_12',\n 'id_13',\n 'id_15',\n 'id_17',\n 'id_19',\n 'id_20',\n 'id_28',\n 'id_29',\n 'id_31',\n 'id_35',\n 'id_36',\n 'id_37',\n 'id_38']:\n    \n    impute_na(final_data, variable)\n\ndef impute_na(final_data, variable):\n    \n    final_data[variable] = final_data[variable].fillna(final_data[variable].median())\n\nfor variable in final_data.columns:\n    \n    if variable not in ['card1',\n 'card2',\n 'card3',\n 'card4',\n 'card5',\n 'card6',\n 'P_emaildomain',\n 'R_emaildomain',\n 'M4',\n  'DeviceType',\n  'id_12',\n 'id_13',\n 'id_15',\n 'id_17',\n 'id_19',\n 'id_20',\n 'id_28',\n 'id_29',\n 'id_31',\n 'id_35',\n 'id_36',\n 'id_37',\n 'id_38']:\n        \n        impute_na(final_data,variable)\n        \n\n\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" S = pd.get_dummies(final_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quasi_constant_feat = []\n\nfor feature in S.columns:\n    \n    predominant = (S[feature].value_counts() / np.float(\n        len(S))).sort_values(ascending=False).values[0]\n\n    if predominant > 0.998:\n        quasi_constant_feat.append(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S.drop(labels=quasi_constant_feat, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,precision_score,f1_score,recall_score\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n\nfrom sklearn.feature_selection import VarianceThreshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.pipeline import make_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = make_pipeline(\n    \n    SMOTETomek(random_state=100),\n    \n    RandomForestClassifier(random_state=100,n_estimators= 200,n_jobs = -1)\n\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gsc = GridSearchCV(\n    estimator=pipe,\n    \n    param_grid={\n\n        'smotetomek__ratio': [.8],\n        'randomforestclassifier__max_depth':[25],\n    },\n    \n    scoring='f1',\n    cv=3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = S.isFraud\n\nX = S.drop(\"isFraud\",axis = 1)\n\nx_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =1, stratify =y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" gsc.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gsc.best_estimator_.predict(x_test)\n\nf1_score(y_pred,y_test),precision_score(y_pred,y_test),recall_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import auc,roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probs  = gsc.predict_proba(x_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fp_rate, tp_rate, thresholds = roc_curve(y_test, y_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc(fp_rate, tp_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}