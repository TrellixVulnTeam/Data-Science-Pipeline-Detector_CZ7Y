{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Installing TabNet through PyTorch\n!pip install pytorch-tabnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries for pre-processing and evaluation\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\ntest_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"# Merging transaction data with identity data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_transaction,train_identity,on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train dataset shape', train.shape)\nprint('test dataset shape', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity, train_transaction, test_identity, test_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# solving incosistent naming of columns\n\nfor i in range(1,39):\n    if i < 10:\n          test.rename(columns = {\"id-0\"+str(i) : \"id_0\"+str(i)}, inplace=True)\n    else:\n          test.rename(columns = {\"id-\"+str(i) : \"id_\"+str(i)}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Droping columns having null values greater than 90%"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_lotof_nulls = [c for c in train.columns if (train[c].isnull().sum() / train.shape[0])>0.90]\ncols_lotof_nulls_test = [c for c in test.columns if (test[c].isnull().sum() / test.shape[0])>0.90]\n\n\ncols_to_drop = list(set(cols_lotof_nulls+ cols_lotof_nulls_test))\nlen(cols_to_drop)\n\ntrain = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking categorical colums to give as paratmeter to TabNet classifier\ncat_cols = list(train.select_dtypes(['object']).columns)\n\nlen(cat_cols)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Label encoder to convert categorical to numerical\nfor col in cat_cols:\n  if col in train.columns:\n    le = LabelEncoder()\n    le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n    train[col] = le.transform(list(train[col].astype('str').values))\n    test[col] = le.transform(list(test[col].astype('str').values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing inf values if any\ntrain = train.replace([np.inf, -np.inf], np.nan)\ntest = test.replace([np.inf, -np.inf], np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing columns if they dont have atleast 100000 non-Nan values\ntrain = train.dropna(axis=1, thresh = 250000)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing Unnecessary columsn for traing data\nX = train.drop(['isFraud', 'TransactionID'], axis=1)\ny = train.isFraud\n\n# For saving memory\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom Loss Function\ndef log_loss_score(actual, predicted,  eps=1e-15):\n    p1 = actual * np.log(predicted+eps)\n    p0 = (1-actual) * np.log(1-predicted+eps)\n    loss = p0 + p1\n\n    return -loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling Nan values with -1\nX = X.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training model with kfold strategy\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import TimeSeriesSplit\nstrategy = \"KFOLD\"\nnum_ensembling = 1\ndevice = 'cuda'\nEPOCHS = 5\nSPLITS = 5\nsave_name = 'tabnet'\nif strategy == \"KFOLD\":\n    oof_preds_all = []\n    oof_targets_all = []\n    scores_all =  []\n    scores_auc_all= []\n    for seed in range(num_ensembling):\n        print(\"## SEED : \", seed)\n        skf = TimeSeriesSplit(n_splits=SPLITS)\n        oof_preds = []\n        oof_targets = []\n        scores = []\n        scores_auc = []\n        for j, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n            print(\"FOLDS : \", j)\n\n            X_train = torch.tensor(X.iloc[train_idx].values)\n            y_train = torch.tensor(y[train_idx].values)\n            X_val, y_val = torch.tensor(X.iloc[val_idx].values), torch.tensor(y[val_idx].values)\n            model = TabNetClassifier(n_d=8, n_a=8, n_steps=1, gamma=1.3,\n                                     lambda_sparse=0,optimizer_fn=torch.optim.Adam,\n                                   optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n                                     mask_type='entmax', device_name=device, output_dim=1,\n                                     scheduler_params=dict(milestones=[100,150], gamma=0.9), \n                                     scheduler_fn=torch.optim.lr_scheduler.MultiStepLR)\n            #'sparsemax'\n            \n            model.fit(X_train=X_train, y_train=y_train,  eval_set=[(X_train, y_train), (X_val, y_val)],max_epochs=EPOCHS,\n                      patience=20, batch_size=1024, virtual_batch_size=128, eval_name=['train', 'valid'],)\n\n            preds = model.predict(X_val)\n            score = log_loss_score(y_val, preds)\n            name = save_name + f\"_fold{j}_{seed}\"\n            model.save_model(name)\n            ## save oof to compute the CV later\n            oof_preds.append(preds)\n            oof_targets.append(y_val)\n            scores.append(score)\n            roc_ = roc_auc_score(y_val,preds)\n            scores_auc.append(roc_)\n            print(f\"validation fold {j} : {score}, roc AUC Score: {roc_}\")\n        oof_preds_all.append(np.concatenate(oof_preds))\n        \n        oof_targets_all.append(np.concatenate(oof_targets))\n        scores_all.append(np.array(scores))\n        scores_auc_all.append(np.array(scores_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction on test set\nX_test = test[X.columns].fillna(-1)\nX_test = torch.tensor(X_test.values)\npreds = model.predict_proba(X_test)\n\nsub = pd.DataFrame({'TransactionID': test['TransactionID'].values.tolist(),\n                    'isFraud': preds[:,1].tolist()\n                   })\n\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}