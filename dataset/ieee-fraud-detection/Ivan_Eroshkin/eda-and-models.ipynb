{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IEEE-CIS Fraud Detection\nРешение этой задачи приведено в рамках прохождения курса MADMO (Сбербанк).<br>\nАвтор Ерошкин И.С.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Постановка задачи\nПо данным о транзакциях и идентификационным данным необходимо оценить вероятность мошенничества при проведении операций с пластиковыми картами.<br>\nОписание соревнования приведено по ссылке: https://www.kaggle.com/c/ieee-fraud-detection\n\n# Данные\n\n**Данные содержат:**\n* Transaction Table\n* Identity Table\n\nОписание таблиц приведено по ссылке:\nhttps://www.kaggle.com/c/ieee-fraud-detection/discussion/101203\n\n## Transaction Table<br>\n1. TransactionDT: timedelta from a given reference datetime (not an actual timestamp)<br>\n1. TransactionAMT: transaction payment amount in USD<br>\n1. ProductCD: product code, the product for each transaction<br>\n1. card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.<br>\n1. addr: address<br>\n1. dist: distance<br>\n1. P_ and (R__) emaildomain: purchaser and recipient email domain<br>\n1. C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.<br>\n1. D1-D15: timedelta, such as days between previous transaction, etc.<br>\n1. M1-M9: match, such as names on card and address, etc.<br>\n1. Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.<br>\n<br>\nCategorical Features:\n1. ProductCD\n1. card1 - card6\n1. addr1, addr2\n1. Pemaildomain Remaildomain\n1. M1 - M9\n\n## Identity Table\n\nCategorical Features:\n1. DeviceType\n1. DeviceInfo\n1. id12 - id38\n\n# Результат, метрика оценки, формат результата\n* Для каждой транзакции TransactionID необходимо оценить вероятность мошеничества isFraud.\n* Метрика оценки - ROC AUC.\n* Результирующий файл должен иметь формат:<br>\nTransactionID,isFraud<br>\n3663549,0.5<br>\n3663550,0.5<br>\n3663551,0.5<br>\nи т.д.<br>\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"При подготовке использованы фрагменты из:<br>\n* https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt\n* https://www.kaggle.com/artgor/eda-and-models\n* https://www.kaggle.com/polmast/demin-av-eee-cis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Part_0: Ипморт и загрузка данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install -U vega_datasets notebook vega","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR, SVR\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score\n# pd.options.display.precision = 15\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\nfrom sklearn import linear_model\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# import eli5\n# import shap\nfrom IPython.display import HTML\nimport json\nimport altair as alt\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# alt.renderers.enable('notebook')\n\n# %env JOBLIB_TEMP_FOLDER=/tmp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# from sklearn.datasets import fetch_openml\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_unique(df):\n    uv = []\n    cols = []\n    for col in list(df.columns):\n        uv.append(df[col].unique().shape[0])\n        cols.append(col)\n    df_uv = pd.DataFrame({'predictor': cols, 'uv': uv}  )\n    return df_uv\n\n\n\n## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pathlib\n# pathlib.Path().absolute()\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загрузка датасетов\ntrain_identity = pd.read_csv(r'../input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\ntest_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')\ntest_transaction = pd.read_csv(f'../input/ieee-fraud-detection/test_transaction.csv')\nsub = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part_1: Исследование данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_identity.shape: ', train_identity.shape)\nprint('train_transaction.shape: ', train_transaction.shape)\nprint('test_identity.shape: ', test_identity.shape)\nprint('test_transaction.shape: ', test_transaction.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Поскольку загруженные данные занимают много оперативной памяти, то удалим из памяти первично загруженные датасеты:\ndel train_identity, train_transaction, test_identity, test_transaction\n# дополнительнопринудительно вызывем сборщик мусора, который почистит память (примерно 3 гб):\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Целевая переменная несбалансирована**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_dsb = train.groupby('isFraud')['isFraud'].count()\nprint('Доля хитов целевой переменной: {:.1%}'.format(y_dsb[1]/(y_dsb[1]+y_dsb[0])))\n\nsns.distplot(train.isFraud,kde=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols = pd.DataFrame({'type': train.dtypes}).reset_index()\ntrain_cols['uv'] = get_unique(train).uv\ntrain_cols.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_sum = train.isnull().sum()\nnull_cnt = train.isnull().count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.index = train_cols['index']\ntrain_cols.drop(['index'], axis=1,inplace=True)\ntrain_cols['num_vals'] = null_cnt\ntrain_cols['num_nans'] = null_sum\ntrain_cols['num_nans_perc'] = null_sum / null_cnt\ntrain_cols.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.sort_values(by='num_nans_perc', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Выделим предикторы у которых пропусков менее 50%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols['cat'] = np.nan\ntrain_cols.loc[train_cols.num_nans_perc>0.5, 'cat'] = 'del'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Размечаем числовые и категориальные величины","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols[(train_cols.cat!='del')].groupby('type')['type'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.loc[(train_cols.cat!='del')&(train_cols.type!='object'), 'cat'] = 'num'\ntrain_cols.loc[(train_cols.cat!='del')&(train_cols.type=='object'), 'cat'] = 'cat'\n\ntrain_cols.groupby('cat')['cat'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Проверим, что нет колонок с одним уникльным значением","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.sort_values(by='uv', ascending=True).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols[train_cols.cat=='cat']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in list(train_cols[train_cols.cat=='cat'].index):\n    print(col)\n    plt.subplots(1,2,figsize=(15,5))\n    plt.subplot(1,2,1)\n    sns.countplot(train[col]);\n    plt.subplot(1,2,2)\n    sns.barplot(x=col, y='isFraud', data=train);\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# убираем из предикторов колонку 'M1'\ntrain_cols.loc[train_cols.index=='M1', 'cat']='del'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.loc[train_cols.cat=='num'].sort_values('uv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.loc[train_cols.cat=='num']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# i=0\n# for col in train_cols.loc[train_cols.cat=='num'].index:\n#     print(i)\n#     print(col)\n#     train.hist(col)\n#     i = i + 1\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part_2: Генерация и отбор предикторов","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Генерация предикторов_01","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# преобразуем TransactionDT в стандартную дату и создадим новую фичу Date\nimport datetime\n\ngenesis = datetime.datetime.strptime('2019-01-01', '%Y-%m-%d')\ntrain['Date'] = train['TransactionDT'].apply(lambda x : genesis+datetime.timedelta(seconds=x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим новые фичи:\ntrain['Weekdays'] = train['Date'].dt.dayofweek\ntrain['Days'] = train['Date'].dt.day\ntrain['Hours'] = train['Date'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n\ng = sns.barplot(train.Weekdays, train.isFraud, ax=ax[0])\nax[0].set_title('Fraud Charges by Weekdays')\nplt.setp(g.get_xticklabels(), visible=False)\n\ng = sns.barplot(train.Days, train.isFraud, ax=ax[1])\nax[1].set_title('Fraud Charges by Days')\nplt.setp(g.get_xticklabels(), visible=False)\n\ng = sns.barplot(train.Hours, train.isFraud, ax=ax[2])\nax[2].set_title('Fraud Charges by Hours')\nplt.setp(g.get_xticklabels(), visible=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date'] = test['TransactionDT'].apply(lambda x : genesis+datetime.timedelta(seconds=x))\n# создадим новые фичи:\ntest['Weekdays'] = test['Date'].dt.dayofweek\ntest['Days'] = test['Date'].dt.day\ntest['Hours'] = test['Date'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Date'], axis=1,inplace=True)\ntest.drop(['Date'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Отбор предикторов","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols[train_cols.cat.isnull()].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.loc[train_cols.index=='TransactionDT', :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols.loc[train_cols.index=='isFraud', 'cat']='target'\ntrain_cols.loc[train_cols.index=='TransactionDT', 'cat']='datetime'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = list(train_cols.loc[train_cols.cat=='cat',:].index)\nnumerical_columns = list(train_cols.loc[train_cols.cat=='num',:].index)\ncategorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX = train[categorical_columns + numerical_columns]\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, stratify=y)\n\ncategorical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\nnumerical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean'))\n])\n\npreprocessing = ColumnTransformer(\n    [('cat', categorical_pipe, categorical_columns),\n     ('num', numerical_pipe, numerical_columns)])\n\nrf = Pipeline([\n    ('preprocess', preprocessing),\n    ('classifier', RandomForestClassifier())\n])\n\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RF train accuracy: %0.3f\" % rf.score(X_train, y_train))\nprint(\"RF test accuracy: %0.3f\" % rf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe = (rf.named_steps['preprocess']\n         .named_transformers_['cat']\n         .named_steps['onehot'])\nfeature_names = ohe.get_feature_names(input_features=categorical_columns)\nfeature_names = np.r_[feature_names, numerical_columns]\n\ntree_feature_importances = (\n    rf.named_steps['classifier'].feature_importances_)\nsorted_idx = tree_feature_importances.argsort()\n\ny_ticks = np.arange(0, len(feature_names))\nfig, ax = plt.subplots(figsize=(10,160))\nax.barh(y_ticks, tree_feature_importances[sorted_idx])\nax.set_yticklabels(feature_names[sorted_idx])\nax.set_yticks(y_ticks)\nax.set_title(\"Random Forest Feature Importances\")\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# result = permutation_importance(rf, X_test, y_test, n_repeats=5)\n# sorted_idx = result.importances_mean.argsort()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Сохранение и чтение результата perm_importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_tmp = pd.DataFrame()\n# for i in range(result['importances'].shape[1]):\n#     col_nm = 'col_'+str(i)\n# #     print(col_nm)\n#     df_tmp[col_nm]=result['importances'][:,i]\n# df_tmp.head(3) \n# df_tmp.to_csv('permut_importances.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp2 = pd.read_csv('../input/permut-importances02/permut_importances_02.csv')\ntmp3 = np.array(df_tmp2)\nresult2={'importances': tmp3, 'importances_mean': tmp3.mean(axis=1), 'importances_std': tmp3.std(axis=1)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Анализ результата perm_importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"result = result2\nsorted_idx = result['importances_mean'].argsort()\n\nfig, ax = plt.subplots(figsize=(10,160))\nax.boxplot(result['importances'][sorted_idx].T,\n           vert=False, labels=X_test.columns[sorted_idx])\nax.set_title(\"Permutation Importances (test set)\")\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_importances = pd.DataFrame({'predictor': X_test.columns[sorted_idx], 'importance': result['importances_mean'][sorted_idx]})\ndf_importances['importances_abs'] = df_importances[['importance']].apply(abs)\ndf_importances = df_importances.sort_values(by='importances_abs',ascending=True)\ndf_importances.iloc[-5:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,160))\nplt.barh(df_importances.predictor, df_importances.importances_abs);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_importances.iloc[-5:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols2=train_cols.reset_index()\ntrain_cols2=train_cols2.rename(columns={'index': 'predictor1'})\ntrain_cols2 = train_cols2.merge(df_importances, how='left', left_on='predictor1', right_on='predictor')\ntrain_cols2 = train_cols2.sort_values(by='importances_abs',ascending=False).reset_index(drop=True)\ntrain_cols2['importances_abs'] = train_cols2[['importances_abs']].apply(lambda x: x/x.max()*100)\ntrain_cols2[100:160]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_cat_top = list(train_cols2[:30].loc[train_cols2.cat=='cat','predictor'])\ncol_num_top = list(train_cols2[:30].loc[train_cols2.cat=='num','predictor'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in col_cat_top:\n    print(col)\n    plt.subplots(1,2,figsize=(15,5))\n    plt.subplot(1,2,1)\n    sns.countplot(train[col]);\n    plt.subplot(1,2,2)\n    sns.barplot(x=col, y='isFraud', data=train);\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in col_num_top:\n    print(col)\n#     plt.subplots(1,1,figsize=(15,5))\n#     plt.subplot(1,2,1)\n#     sns.countplot(train[col]);\n#     plt.subplot(1,2,2)\n#     sns.barplot(x=col, y='isFraud', data=train);\n    sns.distplot(train[col],kde=False);\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols2.groupby('cat')['cat'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols2.loc[train_cols2.predictor=='TransactionID','cat']='del'\ntrain_cols2.loc[train_cols2.predictor=='TransactionID',:]\n\ntrain_cols2.loc[train_cols2.importances_abs<=3,'cat']='del2'\ntrain_cols2.groupby('cat')['cat'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols = train_cols2\ntrain_cols.index = train_cols['predictor1']\ntrain_cols.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Генерация предикторов_02","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\ntrain['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntest['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\ntest['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n\n\ntrain['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\ntrain['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\ntrain['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\ntrain['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n\ntest['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\ntest['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\ntest['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\ntest['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n\ntrain['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\ntrain['D15_to_mean_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('mean')\ntrain['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\ntrain['D15_to_std_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('std')\n\ntest['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\ntest['D15_to_mean_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('mean')\ntest['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\ntest['D15_to_std_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_02 = ['TransactionAmt_to_mean_card1','TransactionAmt_to_mean_card4','TransactionAmt_to_std_card1','TransactionAmt_to_std_card4','D15_to_mean_card1','D15_to_mean_card4','D15_to_std_card1','D15_to_std_card4','D15_to_mean_addr1','D15_to_mean_addr2','D15_to_std_addr1','D15_to_std_addr2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# by https://www.kaggle.com/dimartinot\ndef clean_inf_nan(df):\n    return df.replace([np.inf, -np.inf], np.nan)   \n\n# Cleaning infinite values to NaN\ntrain = clean_inf_nan(train)\ntest = clean_inf_nan(test )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part_3: Моделирование","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_tmp = pd.DataFrame({'col': categorical_columns + numerical_columns})\n# df_tmp.groupby('col')['col'].count().sort_values( ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part_3: Моделирование: 01_RandomForest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = list(train_cols.loc[train_cols.cat=='cat',:].index)\nnumerical_columns = list(train_cols.loc[train_cols.cat=='num',:].index) + numerical_columns_02\n\nX = train[categorical_columns + numerical_columns]\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, stratify=y)\n\ncategorical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\nnumerical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean'))\n])\n\npreprocessing = ColumnTransformer(\n    [('cat', categorical_pipe, categorical_columns),\n     ('num', numerical_pipe, numerical_columns)])\n\npipe = Pipeline([\n    ('preprocess', preprocessing),\n    ('classifier', RandomForestClassifier())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'classifier__max_depth': [2, 5, 20]\n}\n\ngrid_search_01 = GridSearchCV(pipe, param_grid, scoring='roc_auc',cv=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngrid_search_01.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_01.best_score_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = grid_search_01.predict(X_test)\ny_pred_proba = grid_search_01.predict_proba(X_test)[:,1]\nauc_res_01 = roc_auc_score(y_test,y_pred_proba)\nauc_res_01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_01.best_estimator_ ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part_3: Моделирование: 02_XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = list(train_cols.loc[train_cols.cat=='cat',:].index)\nnumerical_columns = list(train_cols.loc[train_cols.cat=='num',:].index) + numerical_columns_02\n\nX = train[categorical_columns + numerical_columns]\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, stratify=y)\n\ncategorical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\nnumerical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean'))\n])\n\npreprocessing = ColumnTransformer(\n    [('cat', categorical_pipe, categorical_columns),\n     ('num', numerical_pipe, numerical_columns)])\n\npipe = Pipeline([\n    ('preprocess', preprocessing),\n    ('classifier', xgb.XGBClassifier())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'classifier__max_depth': [20,30]\n}\n\ngrid_search_02 = GridSearchCV(pipe, param_grid, scoring='roc_auc',cv=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngrid_search_02.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_02.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = grid_search_02.predict(X_test)\ny_pred_proba = grid_search_02.predict_proba(X_test)[:,1]\nauc_res_02 = roc_auc_score(y_test,y_pred_proba)\nauc_res_02","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part_3: Моделирование: 03_LogisticRegression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = list(train_cols.loc[train_cols.cat=='cat',:].index)\nnumerical_columns = list(train_cols.loc[train_cols.cat=='num',:].index) + numerical_columns_02\n\nsc = StandardScaler()\n\nX = train[categorical_columns + numerical_columns]\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, stratify=y)\n\ncategorical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\nnumerical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean'))\n])\n\npreprocessing = ColumnTransformer(\n    [('cat', categorical_pipe, categorical_columns),\n     ('num', numerical_pipe, numerical_columns)])\n\npipe = Pipeline([\n    ('preprocess', preprocessing),\n    ('sc', sc),\n    ('classifier', LogisticRegression(penalty='l2'))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'classifier__C': [0.01,0.5,0.99]\n}\n\ngrid_search_03 = GridSearchCV(pipe, param_grid, scoring='roc_auc',cv=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngrid_search_03.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_03.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = grid_search_03.predict(X_test)\ny_pred_proba = grid_search_03.predict_proba(X_test)[:,1]\nauc_res_03 = roc_auc_score(y_test,y_pred_proba)\nauc_res_03","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part_04: Подготавливаю результирующие файлы","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_res = grid_search_01\ny_pred_res = mod_res.predict(test[categorical_columns + numerical_columns])\nsub['isFraud'] = y_pred_res\nsub.to_csv('Result_v01.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_res = grid_search_02\ny_pred_res = mod_res.predict(test[categorical_columns + numerical_columns])\nsub['isFraud'] = y_pred_res\nsub.to_csv('Result_v02.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_res = grid_search_03\ny_pred_res = mod_res.predict(test[categorical_columns + numerical_columns])\nsub['isFraud'] = y_pred_res\nsub.to_csv('Result_v03.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}