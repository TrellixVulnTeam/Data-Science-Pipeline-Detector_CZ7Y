{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Imputer\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_i = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\ntrain_t = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\n\ntest_i = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')\ntest_t = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_i['is_in_identity'] = 1\n\ntrain = pd.merge(\n    train_t,\n    train_i,\n    on = 'TransactionID',\n    how = 'left'\n)\n\ntrain['is_in_identity'] = train['is_in_identity'].fillna(value = 0)\n\ntest_i['is_in_identity'] = 1\n\ntest = pd.merge(\n    test_t,\n    test_i,\n    on = 'TransactionID',\n    how = 'left'\n)\n\ntest['is_in_identity'] = test['is_in_identity'].fillna(value = 0)\n\n\ndel train_i, train_t, test_i, test_t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"o_types = train.dtypes.to_frame().reset_index()\no_types.columns = ['col', 'type']\no_types = o_types[o_types['type'] == 'object']\no_types_counts = train[o_types['col']].nunique().to_frame().reset_index()\no_types_counts.columns = ['col', 'cnt']\no_types_one_hot = o_types_counts['col'][o_types_counts.cnt <= 10]\no_types_label_encode = o_types_counts['col'][o_types_counts.cnt > 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_one_hot = pd.get_dummies(train[o_types_one_hot])\n\ntrain = pd.concat(\n    [\n        train,\n        train_one_hot\n    ],\n    axis = 1\n)\n\ntrain = train.drop(columns = train[o_types_one_hot])\n\ndel train_one_hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_one_hot = pd.get_dummies(test[o_types_one_hot])\n\ntest = pd.concat(\n    [\n        test,\n        test_one_hot\n    ],\n    axis = 1\n)\n\ntest = test.drop(columns = test[o_types_one_hot])\n\ndel test_one_hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_emaildomain_encoder =  preprocessing.LabelEncoder()\nid_30_encoder =  preprocessing.LabelEncoder()\nid_33_encoder =  preprocessing.LabelEncoder()\nDeviceInfo_encoder =  preprocessing.LabelEncoder()\n\ntrain['P_emaildomain'].fillna(value = '0', inplace = True)\ntrain['id_30'].fillna(value = '0', inplace = True)\ntrain['id_33'].fillna(value = '0', inplace = True)\ntrain['DeviceInfo'].fillna(value = '0', inplace = True)\n\ntest['P_emaildomain'].fillna(value = '0', inplace = True)\ntest['id_30'].fillna(value = '0', inplace = True)\ntest['id_33'].fillna(value = '0', inplace = True)\ntest['DeviceInfo'].fillna(value = '0', inplace = True)\n\nP_emaildomain_encoder.fit(list(train['P_emaildomain']) + list(test['P_emaildomain']))\nid_30_encoder.fit(list(train['id_30']) + list(test['id_30']))\nid_33_encoder.fit(list(train['id_33']) + list(test['id_33']))\nDeviceInfo_encoder.fit(list(train['DeviceInfo']) + list(test['DeviceInfo']))\n\ntrain['P_emaildomain_encoder'] = P_emaildomain_encoder.transform(train['P_emaildomain'])\ntrain['id_30_encoder'] = id_30_encoder.transform(train['id_30'])\ntrain['id_33_encoder'] = id_33_encoder.transform(train['id_33'])\ntrain['DeviceInfo_encoder'] = DeviceInfo_encoder.transform(train['DeviceInfo'])\n\ntest['P_emaildomain_encoder'] = P_emaildomain_encoder.transform(test['P_emaildomain'])\ntest['id_30_encoder'] = id_30_encoder.transform(test['id_30'])\ntest['id_33_encoder'] = id_33_encoder.transform(test['id_33'])\ntest['DeviceInfo_encoder'] = DeviceInfo_encoder.transform(test['DeviceInfo'])\n\ntrain = train.drop(columns = train[o_types_label_encode])\ntest = test.drop(columns = test[o_types_label_encode])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = Imputer(strategy = 'mean')\ntrain = pd.DataFrame(\n    data = imputer.fit_transform(train),\n    columns = train.columns\n)\n\ntest = pd.DataFrame(\n    data = imputer.fit_transform(test),\n    columns = test.columns\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta\ntrain['day_diff'] = ((train['TransactionDT'] - 86400) / (3600 * 24)).astype(int)\ntrain['as_of_date'] = pd.to_datetime('2017-12-01') + pd.to_timedelta(train['day_diff'], unit = 'd')\ntrain['month'] = train['as_of_date'].dt.month\ntrain['day'] = train['as_of_date'].dt.day\ntrain['weekofyear'] = train['as_of_date'].dt.weekofyear\ntrain['weekday'] = train['as_of_date'].dt.weekday\ntrain['dayofyear'] = train['as_of_date'].dt.dayofyear\ntrain['week'] = train['as_of_date'].dt.week\ntrain['dayofweek'] = train['as_of_date'].dt.dayofweek\ntrain['dist_from_xmas'] = (pd.to_datetime('2017-12-25') - train['as_of_date']).dt.days\n\ntest['day_diff'] = ((test['TransactionDT'] - 86400) / (3600 * 24)).astype(int)\ntest['as_of_date'] = pd.to_datetime('2017-12-01') + pd.to_timedelta(test['day_diff'], unit = 'd')\ntest['month'] = test['as_of_date'].dt.month\ntest['day'] = test['as_of_date'].dt.day\ntest['weekofyear'] = test['as_of_date'].dt.weekofyear\ntest['weekday'] = test['as_of_date'].dt.weekday\ntest['dayofyear'] = test['as_of_date'].dt.dayofyear\ntest['week'] = test['as_of_date'].dt.week\ntest['dayofweek'] = test['as_of_date'].dt.dayofweek\ntest['dist_from_xmas'] = (pd.to_datetime('2017-12-25') - test['as_of_date']).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = train.dtypes.to_frame().reset_index()\nt.columns = ['col', 'type']\n\ntrain = train.drop(columns = t['col'][(t.type == 'object') | (t.type == 'datetime64[ns]')], axis = 1)\n\nte = test.dtypes.to_frame().reset_index()\nte.columns = ['col', 'type']\n\ntest = test.drop(columns = te['col'][(te.type == 'object') | (te.type == 'datetime64[ns]')], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in ['card1','card2','addr1']:\n    for feature_2 in ['card1','card2','addr1']:\n        if feature == feature_2:\n            continue\n        train[f'{feature}_{feature_2}'] = train[feature].astype(str) + '_' + train[feature_2].astype(str)\n        test[f'{feature}_{feature_2}'] = test[feature].astype(str) + '_' + test[feature_2].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/nroman/recursive-feature-elimination\nuseful_features = ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1',\n                   'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13',\n                   'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M2', 'M3',\n                   'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V17',\n                   'V19', 'V20', 'V29', 'V30', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V40', 'V44', 'V45', 'V46', 'V47', 'V48',\n                   'V49', 'V51', 'V52', 'V53', 'V54', 'V56', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V69', 'V70', 'V71',\n                   'V72', 'V73', 'V74', 'V75', 'V76', 'V78', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V87', 'V90', 'V91', 'V92',\n                   'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140',\n                   'V143', 'V145', 'V146', 'V147', 'V149', 'V150', 'V151', 'V152', 'V154', 'V156', 'V158', 'V159', 'V160', 'V161',\n                   'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V169', 'V170', 'V171', 'V172', 'V173', 'V175', 'V176', 'V177',\n                   'V178', 'V180', 'V182', 'V184', 'V187', 'V188', 'V189', 'V195', 'V197', 'V200', 'V201', 'V202', 'V203', 'V204',\n                   'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V219', 'V220',\n                   'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V231', 'V233', 'V234', 'V238', 'V239',\n                   'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V249', 'V251', 'V253', 'V256', 'V257', 'V258', 'V259', 'V261',\n                   'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276',\n                   'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294', 'V303',\n                   'V304', 'V306', 'V307', 'V308', 'V310', 'V312', 'V313', 'V314', 'V315', 'V317', 'V322', 'V323', 'V324', 'V326',\n                   'V329', 'V331', 'V332', 'V333', 'V335', 'V336', 'V338', 'id_01', 'id_02', 'id_03', 'id_05', 'id_06', 'id_09',\n                   'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_17', 'id_19', 'id_20', 'id_30', 'id_31', 'id_32', 'id_33',\n                   'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'device_name', 'device_version', 'OS_id_30', 'version_id_30',\n                   'browser_id_31', 'version_id_31', 'screen_width', 'screen_height', 'had_id', \n                   'day_diff', 'month', 'day', 'day_of_week', 'dist_from_xmas','weekofyear','weekday','dayofyear','week',\n                  'card1_card2', 'card1_addr1', 'card2_addr1',  'TransactionAmt_squared', 'TransactionAmt_log']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_col = train.columns\n\nuse_feat = pd.Series(useful_features).to_frame().reset_index()\nuse_feat.columns = ['index', 'col']\nt_df = t_col.to_frame().reset_index()\nt_df.columns = ['index','col']\n\ncols_to_keep = pd.merge(\n    use_feat,\n    t_df,\n    on = 'col',\n    how = 'inner'\n)\n \ncols = cols_to_keep['col'].append(pd.Series('isFraud'))\ntrain = train[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te_col = test.columns\n\nuse_feat_t = pd.Series(useful_features).to_frame().reset_index()\nuse_feat_t.columns = ['index', 'col']\nt_df_t = te_col.to_frame().reset_index()\nt_df_t.columns = ['index','col']\n\ncols_to_keep_t = pd.merge(\n    use_feat_t,\n    t_df_t,\n    on = 'col',\n    how = 'inner'\n)\n\ntest = test[cols_to_keep_t['col']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card1_card2_encoder =  preprocessing.LabelEncoder()\ncard1_addr1_encoder =  preprocessing.LabelEncoder()\ncard2_addr1_encoder =  preprocessing.LabelEncoder()\n\ntrain['card1_card2'].fillna(value = '0', inplace = True)\ntrain['card1_addr1'].fillna(value = '0', inplace = True)\ntrain['card2_addr1'].fillna(value = '0', inplace = True)\n\ntest['card1_card2'].fillna(value = '0', inplace = True)\ntest['card1_addr1'].fillna(value = '0', inplace = True)\ntest['card2_addr1'].fillna(value = '0', inplace = True)\n\ncard1_card2_encoder.fit(list(train['card1_card2']) + list(test['card1_card2']))\ncard1_addr1_encoder.fit(list(train['card1_addr1']) + list(test['card1_addr1']))\ncard2_addr1_encoder.fit(list(train['card2_addr1']) + list(test['card2_addr1']))\n\ntrain['card1_card2_encoder'] = card1_card2_encoder.transform(train['card1_card2'])\ntrain['card1_addr1_encoder'] = card1_addr1_encoder.transform(train['card1_addr1'])\ntrain['card2_addr1_encoder'] = card2_addr1_encoder.transform(train['card2_addr1'])\n\ntest['card1_card2_encoder'] = card1_card2_encoder.transform(test['card1_card2'])\ntest['card1_addr1_encoder'] = card1_addr1_encoder.transform(test['card1_addr1'])\ntest['card2_addr1_encoder'] = card2_addr1_encoder.transform(test['card2_addr1'])\n\ntrain = train.drop(columns = ['card1_card2', 'card1_addr1','card2_addr1'])\ntest = test.drop(columns = ['card1_card2', 'card1_addr1','card2_addr1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['isFraud']\ntrain, test = train.align(test, join = 'inner', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ntrain['TransactionAmt_squared'] = train['TransactionAmt'] ** 2 \ntest['TransactionAmt_squared'] = test['TransactionAmt'] ** 2 \n\ntrain['TransactionAmt_log'] = np.log(train['TransactionAmt'])\ntest['TransactionAmt_log'] = np.log(test['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nx = train\ny = y\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 0)\n\nparam= {'num_leaves': 491,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 106,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.006883242363721497,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47,\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NFOLDS = 5\nfolds = KFold(n_splits=NFOLDS)\n\ncolumns = x.columns\nsplits = folds.split(x, y)\ntest_predictions = np.zeros(test.shape[0])\ny_oof = np.zeros(x.shape[0])\nscore = 0\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = columns\n\nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    x_train, x_valid = x[columns].iloc[train_index], x[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    dtrain = lgb.Dataset(x_train, label=y_train)\n    dvalid = lgb.Dataset(x_valid, label=y_valid)\n\n    clf = lgb.train(param, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)\n    \n    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(x_valid, num_iteration=clf.best_iteration)\n    y_oof[valid_index] = y_pred_valid\n    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n    \n    score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n    test_predictions += clf.predict(test) / NFOLDS\n    \n    del x_train, x_valid, y_train, y_valid\n    \nprint(f\"\\nMean AUC = {score}\")\nprint(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfeature_importances['avg'] = (\n    feature_importances['fold_1'] + \n    feature_importances['fold_2'] + \n    feature_importances['fold_3'] + \n    feature_importances['fold_4'] + \n    feature_importances['fold_5']\n) / 5\n\nplt.figure(figsize=(16, 16))\nsns.barplot(\n    data = feature_importances.sort_values(by = 'avg', ascending = False).head(50),\n    x = 'avg',\n    y = 'feature'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_t = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')\n\nsubmit = pd.concat([test_t['TransactionID'].astype(int), pd.Series(test_predictions)], axis = 1)\nsubmit.columns = ['TransactionID', 'isFraud']\n\nsubmit.to_csv('submit.csv', index = False) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}