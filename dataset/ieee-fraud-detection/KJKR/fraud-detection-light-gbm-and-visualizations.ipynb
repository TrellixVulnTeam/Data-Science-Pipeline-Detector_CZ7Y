{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,KFold\nimport lightgbm as lgb\nimport itertools\nfrom sklearn.metrics import roc_auc_score\nimport gc\nfrom bayes_opt import BayesianOptimization\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MEMORY REDUCATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Loading and Merging"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_trains = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv', index_col = 'TransactionID')\ntrain_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv', index_col = 'TransactionID')\ntest_trains = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv', index_col = 'TransactionID')\ntest_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv', index_col = 'TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_trains = reduce_mem_usage(train_trains)\ntrain_id = reduce_mem_usage(train_id)\ntest_trains = reduce_mem_usage(test_trains)\ntest_id = reduce_mem_usage(test_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_trains, train_id, on ='TransactionID', how = 'left')\ntest = pd.merge(test_trains, test_id, on = 'TransactionID', how = 'left')\ntrain = train.reset_index()\ntest = test.reset_index()\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_id, train_trains, test_id, test_trains\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('This might be an imbalanced class problem from what we can see')\ntrain['isFraud'].value_counts(normalize = True)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> THIS IS A BEAUTIFUL CLASS IMBALANCE PROBLEM"},{"metadata":{},"cell_type":"markdown","source":"> MISSING VALUE COUNT"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('THERE ARE {0} MISSING VALUES IN TRAIN'.format(train.isnull().any().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['isFraud'].value_counts(normalize = True, dropna = False).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Some Overbiased Columns that might be removed later"},{"metadata":{"trusted":true},"cell_type":"code","source":"for cols in train.columns[2:]:\n    if train[cols].value_counts(normalize = True, dropna = False).values[0]> 0.9:\n        print(train[cols].value_counts(normalize = True, dropna = False)*100)\n        print('-'*90)\n        print('-'*90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VISUALIZATIONS"},{"metadata":{"trusted":true},"cell_type":"code","source":"card_fraud = train[['isFraud', 'card4']].groupby(by = 'card4').count()\ncard_fraud = card_fraud.reset_index()\nplt.figure(figsize = (10,6))\naxes = plt.bar(x = card_fraud['card4'], height = card_fraud['isFraud'], color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\nplt.tick_params(labelsize = 13)\nplt.xlabel('CARD TYPE', fontdict = {'fontsize':15})\nplt.ylabel('NO OF FRAUDS', fontdict = {'fontsize':15})\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.27, ax.get_height() + 5000, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card_fraud = train[['isFraud', 'card6']].groupby(by = 'card6').count()\ncard_fraud = card_fraud.reset_index()\nplt.figure(figsize = (10,6))\naxes = plt.bar(x = card_fraud['card6'], height = card_fraud['isFraud'], color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\nplt.tick_params(labelsize = 13)\nplt.xlabel('CARD TYPE', fontdict = {'fontsize':15})\nplt.ylabel('NO OF FRAUDS', fontdict = {'fontsize':15})\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.27, ax.get_height() + 5000, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> FROM THIS WE CAN SEE THAT IT MIGHT BE EASIER TO SCAM THE DEBIT CARD USERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,4))\naxes = plt.barh(train['DeviceType'].unique()[1:], train['DeviceType'].value_counts().values, color = ['orange', 'green'], \n               edgecolor = 'black')\nplt.tick_params(labelsize = 12)\nfor ax in axes.patches:\n    plt.text(ax.get_width()- 10500, ax.get_y() + 0.34, str(round(ax.get_width(), 2)), fontdict= {'fontsize':13})\nplt.title('Total Fraud Occurance on different platforms', fontdict = {'fontsize':16})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id31_fruad = train['id_31'][train['isFraud'] == 0].value_counts()\nid31 = train['id_31'][train['isFraud'] == 1].value_counts()\nfig, axes = plt.subplots(2,1, figsize = (10,8), sharex = False, sharey = False)\naxes[0].barh(id31.keys()[:10], width = id31.values[:10])\naxes[1].barh(id31_fruad.keys()[:10], width = id31_fruad.values[:10])\naxes[0].tick_params(labelsize = 12)\naxes[1].tick_params(labelsize = 12)\naxes[0].set_title('Browsers from where most frad cases happened', fontdict = {'fontsize':15})\naxes[1].set_title('Browsers from where least fraud cases happened',fontdict = {'fontsize':15})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_fruad = train['DeviceInfo'][train['isFraud'] == 0].value_counts()\ndev = train['DeviceInfo'][train['isFraud'] == 1].value_counts()\nfig, axes = plt.subplots(2,1, figsize = (10,8), sharex = False, sharey = False)\naxes[0].barh(dev.keys()[:10], width = id31.values[:10])\naxes[1].barh(dev_fruad.keys()[:10], width = id31_fruad.values[:10])\naxes[0].tick_params(labelsize = 12)\naxes[1].tick_params(labelsize = 12)\naxes[0].set_title('Handsets from where most fraud cases happened', fontdict = {'fontsize':15})\naxes[1].set_title('Handsets from where least fraud cases happened',fontdict = {'fontsize':15})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"dev_fruad = train['P_emaildomain'][train['isFraud'] == 0].value_counts()\ndev = train['P_emaildomain'][train['isFraud'] == 1].value_counts()\nfig, axes = plt.subplots(2,1, figsize = (10,8), sharex = False, sharey = False)\naxes[0].barh(dev.keys()[:10], width = id31.values[:10])\naxes[1].barh(dev_fruad.keys()[:10], width = id31_fruad.values[:10])\naxes[0].tick_params(labelsize = 12)\naxes[1].tick_params(labelsize = 12)\naxes[0].set_title('email platforms from where most fraud cases happened', fontdict = {'fontsize':15})\naxes[1].set_title('email platforms from where least fraud cases happened',fontdict = {'fontsize':15})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize = (15,6))\nfrd_amt = train[['TransactionAmt', 'card4']][train['isFraud'] == 1].groupby(by = 'card4').mean().reset_index()\nfrd_amt1 = train[['TransactionAmt', 'card4']][train['isFraud'] == 0].groupby(by = 'card4').mean().reset_index()\na = axes[0].bar(x = frd_amt['card4'], height = frd_amt['TransactionAmt'],  color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\naxes[0].tick_params(labelsize = 13)\naxes[0].set_xlabel('Card Type', fontdict = {'fontsize':15})\naxes[0].set_ylabel('Average Fraud Amount', fontdict = {'fontsize':15})\nfor ax in a.patches:\n    axes[0].text(ax.get_x() + 0.27, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\n    \nb = axes[1].bar(x = frd_amt1['card4'], height = frd_amt1['TransactionAmt'],  color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\naxes[1].tick_params(labelsize = 13)\naxes[1].set_xlabel('Card Type', fontdict = {'fontsize':15})\naxes[1].set_ylabel('Average Non-Fraud Amount', fontdict = {'fontsize':15})\nfor ax in b.patches:\n    axes[1].text(ax.get_x() + 0.27, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Is Resolution related to Fraud"},{"metadata":{"trusted":true},"cell_type":"code","source":"res_fraud = train[['isFraud', 'id_33']].groupby(by = 'id_33').sum().reset_index()\nres_fraud = res_fraud.sort_values(by = 'isFraud', ascending = False)\nres_fraud = res_fraud[:15][:]\nplt.figure(figsize = (15,8))\nplt.plot(res_fraud['id_33'], res_fraud['isFraud'],'*', color = 'red', markersize = 15)\nplt.plot(res_fraud['id_33'], res_fraud['isFraud'], color = 'black') \nplt.xticks(rotation = 45)\nplt.xlabel('Resolutions', fontdict = {'fontsize':14})\nplt.ylabel('Total Fraud occured', fontdict = {'fontsize':14})\nplt.title('Total Fraud occured VS Resolutions', fontdict = {'fontsize':18})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(6,2, figsize = (13,25), sharex = False, sharey = False)\nsns.distplot(train['D1'].dropna().astype(int), ax = axes[0,0])\nsns.distplot(train['D2'].dropna().astype(int), ax = axes[0,1])\nsns.distplot(train['D3'].dropna().astype(int), ax = axes[1,0])\nsns.distplot(train['D4'].dropna().astype(int), ax = axes[1,1])\nsns.distplot(train['D5'].dropna().astype(int), ax = axes[2,0])\nsns.distplot(train['D6'].dropna().astype(int), ax = axes[2,1])\nsns.distplot(train['D7'].dropna().astype(int), ax = axes[3,0])\nsns.distplot(train['D8'].dropna().astype(int), ax = axes[3,1])\nsns.distplot(train['D9'].dropna().astype(int), ax = axes[4,0])\nsns.distplot(train['D10'].dropna().astype(int), ax = axes[4,1])\nsns.distplot(train['D11'].dropna().astype(int), ax = axes[5,0])\nsns.distplot(train['D12'].dropna().astype(int), ax = axes[5,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_collector(string):\n    label = string.split('.')[0]\n    return label\n\ntemp = train['P_emaildomain'].astype(str)\ntrain['label_encode'] = temp.apply(label_collector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card_cost = train[['label_encode', 'TransactionAmt','isFraud']][train['isFraud']==1].groupby(by = 'label_encode').mean().reset_index()\ncard_cost = card_cost.sort_values(by = 'TransactionAmt', ascending = False)\nplt.figure(figsize = (14,7))\nplt.xticks(rotation = 45)\nplt.xlabel('E-mail domain', fontdict = {'fontsize':13})\nplt.ylabel('Average Fraud Amount', fontdict = {'fontsize':13})\nplt.tick_params(labelsize = 12)\naxes = plt.bar(x = card_cost['label_encode'].iloc[0:10], height = card_cost['TransactionAmt'].iloc[0:10], color = ['red','green', 'blue', 'yellow', 'pink', 'black', 'orange','purple', 'brown', 'white'], edgecolor = 'black')\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.2, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.title('E-Mail domain vs Fraud Amount', fontdict = {'fontsize':15})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card_cost = train[['label_encode', 'TransactionAmt','isFraud']][train['isFraud']==0].groupby(by = 'label_encode').mean().reset_index()\ncard_cost = card_cost.sort_values(by = 'TransactionAmt', ascending = False)\nplt.figure(figsize = (14,7))\nplt.xticks(rotation = 45)\nplt.xlabel('E-mail domain', fontdict = {'fontsize':13})\nplt.ylabel('Average Non-Fraud Amount', fontdict = {'fontsize':13})\nplt.tick_params(labelsize = 12)\naxes = plt.bar(x = card_cost['label_encode'].iloc[0:10], height = card_cost['TransactionAmt'].iloc[0:10], color = ['red','green', 'blue', 'yellow', 'pink', 'black', 'orange','purple', 'brown', 'white'], edgecolor = 'black')\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.2, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.title('E-Mail domain vs Fraud Amount', fontdict = {'fontsize':15})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop('label_encode', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd_fault = train[['ProductCD', 'isFraud']][train['isFraud']==1].groupby(by = 'ProductCD').sum().reset_index()\nplt.figure(figsize = (10,6))\naxes = plt.bar(x = cd_fault['ProductCD'], height = cd_fault['isFraud'],  color = ['red', 'yellow', 'green', 'blue', 'pink'], edgecolor = 'Black')\nplt.tick_params(labelsize = 13)\nplt.xlabel('ProductCD', fontdict = {'fontsize':15})\nplt.ylabel('Total Fraudulent cases', fontdict = {'fontsize':15})\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.2, ax.get_height() + 100, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 1. FROM THE ABOVE PLOTS WE CAN SEE THE  MOST USED PLATFORMS AND THEIR FRAUD EXPECTANCY\n> 2. WE CAN SEE THAT MOST AND LEAST FRAUD CAUSING PLATFORMS ARE SAME THIS IS JUST BECAUSE OF THEIR HUGE POPULARITY"},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Values And Encoding Necessary Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_drop_train = [cols for cols in train.columns if train[cols].isnull().sum()/ train.shape[0] > 0.9]\ncols_drop_test = [cols for cols in test.columns if test[cols].isnull().sum()/ test.shape[0]> 0.9]\nbig_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\ndrop_cols = list(set(cols_drop_train + cols_drop_test + big_top_value_cols + big_top_value_cols_test))\ndrop_cols.remove('isFraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(drop_cols, axis = 1, inplace = True)\ntest.drop(drop_cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del cols_drop_test, cols_drop_train, big_top_value_cols, big_top_value_cols_test, drop_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\ntrain[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\ntest[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\ntest[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print([cols for cols in train.columns if train[cols].dtype == 'O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def labelencode(train,test):\n    for col in train.drop(['TransactionID','isFraud','TransactionDT'],axis = 1).columns:\n        if train[col].dtype == 'O' or test[col].dtype == 'O':\n            le = LabelEncoder()\n            le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n            train[col] = le.transform(list(train[col].astype(str).values))\n            test[col] = le.transform(list(test[col].astype(str).values))\n    return train,test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = labelencode(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = train['isFraud']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_drops = ['TransactionID','isFraud','TransactionDT']\ntrain = train.drop(cols_drops, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(['TransactionID','TransactionDT'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(-999)\ntest = test.fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_m, val_m_train, val1, val2 = train_test_split(train,y_test, test_size = 0.3, random_state = 10, stratify = y_test)\ntrain_m_index = train_m.index\nval_m_index = val_m_train.index\nval1_index = val1.index\nval2_index = val2.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_m_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bayesian Optimization for Hyperparameter Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(num_leaves,min_child_weight,feature_fraction,bagging_fraction,\n              max_depth,learning_rate,reg_alpha,reg_lambda,min_data_in_leaf):\n    global train_m\n    global val_m\n    global y_test\n    global train_m_index\n    global val_m_index\n    global val1,val2, val1_index, val2_index\n    num_leaves = int(num_leaves)\n    max_depth = int(max_depth)\n    min_data_in_leaf = int(min_data_in_leaf)\n    assert type(num_leaves) == int\n    assert type(min_data_in_leaf) == int\n    assert type(max_depth) == int\n    params = {'num_leaves': num_leaves,\n          'min_child_weight': min_child_weight,\n          'feature_fraction': feature_fraction,\n          'bagging_fraction': bagging_fraction,\n          'min_data_in_leaf': min_data_in_leaf,\n          'objective': 'binary',\n          'max_depth': max_depth,\n          'learning_rate': learning_rate,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': reg_alpha,\n          'reg_lambda': reg_lambda,\n          'random_state':42,\n         }\n    oof = np.zeros(len(train_m))\n    early_stopping_rounds = 50\n    xgtrain = lgb.Dataset(train_m, label=val1[val1_index])\n    xgvalid = lgb.Dataset(val_m_train, label=val2[val2_index])\n    num_boost_round = 200\n    model_lgb = lgb.train(params, xgtrain , valid_sets = [xgtrain, xgvalid], num_boost_round = num_boost_round,\n                            early_stopping_rounds = early_stopping_rounds, verbose_eval = 0)\n    score  = roc_auc_score(val2, model_lgb.predict(val_m_train))\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bound_lgb = {'num_leaves': (70,600),\n              'min_child_weight': (0.001, 0.07),\n              'feature_fraction': (0.1,0.9),\n              'bagging_fraction': (0.1,0.9),\n              'max_depth': (-1,50),\n              'learning_rate': (0.2,0.9),\n              'reg_alpha': (0.3,0.9),\n              'reg_lambda': (0.3,0.9),\n              'min_data_in_leaf':(50,300)\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LGB_BO = BayesianOptimization(objective, bound_lgb, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LGB_BO.space.keys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init_points = 10\nn_iter = 15\nprint('-' * 130)\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings('ignore')\n    LGB_BO.maximize(init_points=init_points, n_iter=n_iter,acq='ucb', xi=0.0, alpha=1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LGB_BO.max['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LGB_BO.max['params']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''params = {'num_leaves': int(LGB_BO.max['params']['num_leaves']),\n          'min_child_weight': LGB_BO.max['params']['min_child_weight'],\n          'bagging_fraction': LGB_BO.max['params']['bagging_fraction'],\n          'feature_fraction':LGB_BO.max['params']['feature_fraction'],\n          'min_data_in_leaf': int(LGB_BO.max['params']['min_data_in_leaf']),\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': LGB_BO.max['params']['learning_rate'],\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha':LGB_BO.max['params']['reg_alpha'],\n          'reg_lambda': LGB_BO.max['params']['reg_lambda'],\n          'random_state':42\n         }'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'num_leaves': 491,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 106,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.006883242363721497,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47,\n         }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lightgbm Implementation"},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = lgb.Dataset(train, label=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = lgb.train(params, d_train, verbose_eval=False, num_boost_round = 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''v_results = lgb.cv(params, d_train, nfold = 5, num_boost_round = 1000, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50, verbose_eval=100)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = clf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_important(model, X , num = 50):\n    feature_import = pd.DataFrame(sorted(zip(model.feature_importance(), X.columns)), columns = ['values', 'columns'])\n    plt.figure(figsize = (12,15))\n    sns.barplot(x = 'values', y = 'columns', data = feature_import.sort_values(by = 'values', ascending = False)[:num])\n    plt.show()\n    \nfeature_important(clf, train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submitss = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"TransactionID\": submitss['TransactionID'],\n        \"isFraud\": predict\n    })\n\nsubmission.TransactionID = submission.TransactionID.astype(int)\n\nsubmission.to_csv(\"submit.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}