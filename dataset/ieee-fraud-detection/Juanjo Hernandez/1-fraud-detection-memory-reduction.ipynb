{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Memory Reduction of our datasets\n\nThis notebook process both train and test dataframes downcasting the data types, allowing to work them safely in kaggle without running out of the assigned RAM memory. Also exports these files to binary, in order to speed their load in subsequent uses.\n\n> For this task, we use the function created by Alexey Kupershtokh (https://www.kaggle.com/alexeykupershtokh/safe-memory-reduction)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom memory_reduction_script import reduce_mem_usage_sd as mr # we are using the memory reduction by our utility script","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This script will perform the following tasks:\n\n* Creates the columns `DT`: the `TransactionDT` (Delta time) from seconds to days.\n* Creates the columns `Dxachr` referenced to the `DT` Delta days. These columns are days from a specific date or point in the past, so substracting the days passed since the begining of the dataset (`DT`), we can get that specific \"date\" delta.\n\nWe initially were not intended to work with test data, and we were partitioning or own test data from train for our final bootcamp project purposes.\n**Finally we decide to use full train for train and validation and test with test file, submitting the results to kaggle as we were participating in the competition.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Download of files.\n\nprint('Downloading datasets...')\nprint(' ')\ntrain = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\nprint('Train has been downloaded... (1/2)')\ntest = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\nprint('Test has been downloaded... (2/2)')\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Transforming the columns D en Dxachr (D anchored).\n# D1, D2, D4, D6, D10, D11 - D15.\n# D3, D5, D7 are differences between a transaction of a card and his previous one. Does not have sense to do the same thing.\n# D8, D9 are probably hr. We keep them untouched.\n\ntrain['DT'] = np.floor(train.TransactionDT/(60*60*24))\ntest['DT']  = np.floor(test.TransactionDT/(60*60*24))\n\ncolumns_D = ['D' + str(i) for i in range(1,16) if i not in [3, 5, 7, 8, 9]]\n\nfor col in columns_D:\n    train[col+'achr'] = train['DT'] - train[col]\n    test[col+'achr']  = test['DT']  - test[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Reducing memory with safe downcast function.\n\ntrain = mr(train, verbose=True)\ntest  = mr(test, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Saving both DataFrames into binary files to speed next uploadings.\n\nprint('Saving datasets...')\ntrain.to_pickle('train_mred.pkl')\nprint('Train has been saved... (1/2)')\ntest.to_pickle('test_mred.pkl')\nprint('Test has been saved... (2/2)')\nprint('Done!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}