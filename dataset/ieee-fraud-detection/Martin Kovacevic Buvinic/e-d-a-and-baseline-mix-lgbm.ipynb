{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"The ideas and a lot of code was copied from other scripts. It's a mix!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\npd.set_option('display.max_columns', 1000)\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport gc\nimport datetime\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data and Merge"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv', index_col = 'TransactionID')\nprint('Successfully loaded train_identity')\n\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv', index_col = 'TransactionID')\nprint('Successfully loaded train_transaction')\n\ntest_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv', index_col = 'TransactionID')\nprint('Successfully loaded test_identity')\n\ntest_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv', index_col = 'TransactionID')\nprint('Successfully loaded test_transaction')\n\nsub = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\nprint('Successfully loaded sample_submisssion')\n\nprint('Data was successfully loades!')\n\nprint('Merging data....')\ntrain = train_transaction.merge(train_identity, how = 'left', left_index = True, right_index = True)\ntest = test_transaction.merge(test_identity, how = 'left', left_index = True, right_index = True)\n\nprint('Data was successfully merged!')\n\ndel train_identity, train_transaction, test_identity, test_transaction\n\nprint('Train dataset has {} rows and {} columns'.format(train.shape[0], train.shape[1]))\nprint('Test dataset has {} rows and {} columns'.format(test.shape[0], test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a lot of features, let's start exploring our dataset."},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# target variable\n\ntrain['TransactionAmt'] = train['TransactionAmt'].astype(float)\ntotal = len(train)\ntotal_amt = train.groupby(['isFraud'])['TransactionAmt'].sum().sum()\nplt.figure(figsize=(12,5))\n\nplt.subplot(121)\nplot_tr = sns.countplot(x='isFraud', data=train)\nplot_tr.set_title(\"Fraud Transactions Distribution \\n 0: No Fraud | 1: Fraud\", fontsize=18)\nplot_tr.set_xlabel(\"Is fraud?\", fontsize=16)\nplot_tr.set_ylabel('Count', fontsize=16)\nfor p in plot_tr.patches:\n    height = p.get_height()\n    plot_tr.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=15) \n    \npercent_amt = (train.groupby(['isFraud'])['TransactionAmt'].sum())\npercent_amt = percent_amt.reset_index()\nplt.subplot(122)\nplot_tr_2 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=percent_amt)\nplot_tr_2.set_title(\"% Total Amount in Transaction Amt \\n 0: No Fraud | 1: Fraud\", fontsize=18)\nplot_tr_2.set_xlabel(\"Is fraud?\", fontsize=16)\nplot_tr_2.set_ylabel('Total Transaction Amount Scalar', fontsize=16)\nfor p in plot_tr_2.patches:\n    height = p.get_height()\n    plot_tr_2.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total_amt * 100),\n            ha=\"center\", fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a very unbalance dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values(df):\n    df1 = pd.DataFrame(df.isnull().sum()).reset_index()\n    df1.columns = ['features', 'freq']\n    df1['percentage'] = df1['freq']/df.shape[0]\n    df1.sort_values('percentage', ascending = False, inplace = True)\n    return df1\n\nmissing_train = missing_values(train)\nmissing_train.columns = ['features', 'freq_tr', 'percentage_tr']\nmissing_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have a lot of missing values in our train set. Let's check our test set and compare them."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_test = missing_values(test)\nmissing_test.columns = ['features', 'freq_te', 'percentage_te']\nmissing_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = missing_train.merge(missing_test, on = 'features')\nmissing.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_24 and others"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['id_24'].value_counts(normalize = True, dropna = False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test['id_24'].value_counts(normalize = True, dropna = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all the values are NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features = []\ndrop_features.append('id_24')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The same for 'id_24', 'id_25', 'id_08', 'id_07', 'id_21', 'id_26', 'id_27', 'id_23', 'id_22'"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['id_24', 'id_25', 'id_08', 'id_07', 'id_21', 'id_26', 'id_27', 'id_23', 'id_22']:\n    drop_features.append(i)\ndrop_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dist 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['dist2'].value_counts(normalize = True, dropna = False).head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test['dist2'].value_counts(normalize = True, dropna = False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature(train, test, feature, log = False):\n    df1_0 = train[train['isFraud']==0]\n    df1_1 = train[train['isFraud']==1]\n    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(13,9))\n    if log == True:\n        sns.kdeplot(np.log(df1_0[feature]), shade = True, label = 'Not Fraud', ax = ax1)\n        sns.kdeplot(np.log(df1_1[feature]), shade = True, label = 'Fraud', ax = ax1)\n    else:\n        sns.kdeplot(df1_0[feature], shade = True, label = 'Not Fraud', ax = ax1)\n        sns.kdeplot(df1_1[feature], shade = True, label = 'Fraud', ax = ax1)\n        \n    \n    if log == True:\n        sns.kdeplot(np.log(train[feature]), shade = True, label = 'Train', ax = ax2)\n        sns.kdeplot(np.log(test[feature]), shade = True, label = 'Test', ax = ax2)\n    else:\n        sns.kdeplot(train[feature], shade = True, label = 'Train', ax = ax2)\n        sns.kdeplot(test[feature], shade = True, label = 'Test', ax = ax2)\n        \nplot_feature(train, test, 'dist2', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Distribution are different, maybee this feature can be usefull so it's not a good idea to drop it\n* The distribution between train and test are little different.\n* Let's store it in a list of features that we need to experiment with"},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features = ['dist2']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D7"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D7']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This feature have more missing values in the train set. Very difficult to impute it."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D7', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This feature can help us, let's store it in the check list"},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('D7')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_18"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_18']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same as D7, more missing values in the train train set\n\nThis is a time series problem so maybee with time, this feature have less NaN's"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'id_18', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Have a lot of missing values and the distribution are not that different, let's drop it"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features.append('id_18')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D13"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D13']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D13', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Good feature\n* The distribution of the training and the test set are different"},{"metadata":{},"cell_type":"markdown","source":"# D14"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D14']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D14', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D12"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D12']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D12', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_04"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_04']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def plot_c_feature(train, feature):\n    tmp = pd.crosstab(train[feature], train['isFraud'], normalize = 'index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    plt.figure(figsize=(13,9))\n    plot_1 = sns.countplot(x = feature, hue = 'isFraud', data = train)\n    plt.legend(title = 'Fraud', loc = 'best', labels = ['No', 'Yes'])\n    plot_1_1 = plot_1.twinx()\n    plot_1_1 = sns.pointplot(x = feature, y = 'Fraud', data = tmp, color = 'black', \n                         order = list(tmp[feature].values), legend = False)\n    plot_1_1.set_ylabel('% of Fraud Transactions', fontsize = 16)\n    plot_1.set_ylabel(\"Count\", fontsize=16)\n    \n    \nplot_c_feature(train, 'id_04')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some value have a lot of isFraud, maybee this feature is helpfull."},{"metadata":{},"cell_type":"markdown","source":"# id_03"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_03']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_03')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same as id_04"},{"metadata":{},"cell_type":"markdown","source":"# D6"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D6']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D6', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Different distributions, helpfull"},{"metadata":{},"cell_type":"markdown","source":"# id_33"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_33']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_33')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Helpfull, a lot of categories have 100% prob to be Fraud"},{"metadata":{},"cell_type":"markdown","source":"# id_09"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_09']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_09')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Helpfull"},{"metadata":{},"cell_type":"markdown","source":"# id_10"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_10']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_10')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D9"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D9', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D8"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='D8']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D8', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_30, id_32, id_34, id_14"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_30']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_30')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_32']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_34']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_34')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features.append('id_34')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='id_14']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_14')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V141"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='V141']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'V141', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features.append('V141')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V157"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='V157']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'V157', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('V157')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V162"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing[missing['features']=='V162']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'V162', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V161"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"missing[missing['features']=='V161']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'V161', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V158"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"missing[missing['features']=='V158']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'V158', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('V158')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V156"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"missing[missing['features']=='V156']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'V156', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('V156')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting tired :), let's make some multiplots. We already analyze the features that have a lot of NaN values so we are good to go"},{"metadata":{},"cell_type":"markdown","source":"# Others V"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_distribution(df1, df2, label1, label2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(10,5,figsize=(18,22))\n\n    for feature in features:\n        i += 1\n        plt.subplot(10,5,i)\n        sns.kdeplot(np.log(df1[feature]), bw=0.5,label=label1)\n        sns.kdeplot(np.log(df2[feature]), bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n        plt.tick_params(axis='y', which='major', labelsize=6)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V = ['V142', 'V155', 'V154', 'V140', 'V149', 'V148', 'V147', 'V146', 'V153', 'V163', 'V139', 'V138', 'V151', 'V152', \n     'V145','V144', 'V143', 'V160', 'V159', 'V164', 'V165', 'V166', 'V150', 'V337', 'V333', 'V336', 'V335', 'V334', 'V338', \n     'V339', 'V325', 'V332', 'V324', 'V330', 'V329', 'V328', 'V327', 'V326', 'V322', 'V323', 'V331', 'V278', 'V277', 'V252', \n     'V253', 'V254', 'V257', 'V258', 'V260', 'V243', 'V262', 'V263', 'V264', 'V249', 'V266', 'V267', 'V268', 'V269', 'V273', \n     'V274', 'V275', 'V276', 'V265', 'V261', 'V247', 'V246', 'V241', 'V240', 'V237', 'V236', 'V235', 'V233', 'V232', \n     'V231', 'V230', 'V229', 'V228', 'V226', 'V225', 'V224', 'V223', 'V219', 'V218', 'V217', 'V244', 'V248', 'V242', 'V211', \n     'V214', 'V213', 'V212', 'V196', 'V205', 'V183', 'V216', 'V206', 'V186', 'V187', 'V192', 'V207', 'V215', 'V182', 'V191',\n     'V181', 'V167', 'V168', 'V199', 'V193', 'V172', 'V173', 'V202', 'V203', 'V176', 'V177', 'V178', 'V179', 'V204', 'V190',\n     'V194', 'V201', 'V189', 'V188', 'V185', 'V184', 'V180', 'V175', 'V174', 'V171', 'V170', 'V169', 'V195', 'V200', 'V197', \n     'V198', 'V208', 'V210', 'V209', 'V272', 'V234', 'V222', 'V238', 'V239', 'V227', 'V251', 'V250', 'V271', 'V270', 'V221',\n     'V220', 'V255', 'V256', 'V259', 'V245', 'V3', 'V1', 'V2', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V46', 'V42',\n     'V44', 'V43', 'V47', 'V41', 'V40', 'V39', 'V38', 'V37', 'V36', 'V35', 'V52', 'V51', 'V50', 'V49', 'V48', 'V45', 'V88', \n     'V93', 'V85', 'V87', 'V84', 'V83', 'V82', 'V81', 'V90', 'V91', 'V92', 'V94', 'V80', 'V79', 'V78', 'V77', 'V76',\n     'V75', 'V86', 'V53', 'V74', 'V73', 'V72', 'V66', 'V54', 'V67', 'V64', 'V63', 'V62', 'V61', 'V71', 'V69', 'V55',\n     'V60', 'V59', 'V58', 'V57', 'V65', 'V56', 'V70', 'V22', 'V23', 'V24', 'V34', 'V33', 'V32', 'V31', 'V30', 'V29',\n     'V26', 'V25', 'V15', 'V21', 'V14', 'V16', 'V17', 'V18', 'V19', 'V12', 'V20', 'V13', 'V282', 'V301', 'V300', 'V296',\n     'V289', 'V288', 'V283', 'V281', 'V315', 'V314', 'V313', 'V114', 'V110', 'V105', 'V104', 'V103', 'V102', 'V101', 'V100',\n     'V95', 'V99', 'V98', 'V97', 'V107', 'V111', 'V96', 'V112', 'V106', 'V113', 'V137', 'V136', 'V108', 'V135', 'V134', 'V133', \n     'V132', 'V131', 'V130', 'V129', 'V128', 'V127', 'V126', 'V125', 'V124', 'V123', 'V122', 'V121', 'V120', 'V119', 'V118',\n     'V117', 'V116', 'V115', 'V109', 'V312', 'V321', 'V294', 'V306', 'V305', 'V304', 'V303', 'V302', 'V299', 'V298', 'V297', \n     'V295', 'V293', 'V308', 'V292', 'V291', 'V290', 'V287', 'V286', 'V285', 'V284', 'V280', 'V279', 'V320', 'V307', 'V309',\n     'V316', 'V310', 'V318', 'V317', 'V319', 'V311']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train[train['isFraud']==0]\nt1 = train[train['isFraud']==1]\nfirst = V[0:50]\nplot_feature_distribution(t0, t1, '0', '1', first)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's analyze them and complete the list"},{"metadata":{"trusted":true},"cell_type":"code","source":"V1drop = ['V142', 'V146', 'V138', 'V151', 'V152', 'V333', 'V338', 'V339', 'V325', 'V332', 'V324', 'V330', 'V329', 'V322', \n          'V323', 'V278', 'V277', 'V252', 'V253', 'V254', 'V260']\n\nfor i in V1drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"second = V[50:100]\nplot_feature_distribution(t0, t1, '0', '1', second)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V2drop = ['V263', 'V249', 'V266', 'V267', 'V268', 'V273', 'V276', 'V275', 'V247', 'V241', 'V240', 'V237', 'V235', 'V225', \n          'V224', 'V224', 'V248', 'V211', 'V213', 'V196', 'V205', 'V183', 'V206', 'V192']\nfor i in V2drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"third = V[100:150]\nplot_feature_distribution(t0, t1, '0', '1', third)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V3drop = ['V191', 'V181', 'V193', 'V172', 'V173', 'V202', 'V203', 'V177', 'V179', 'V194', 'V185', 'V184', 'V175', 'V174', \n          'V195', 'V197', 'V198', 'V208', 'V210', 'V227', 'V251', 'V250', 'V271', 'V270', 'V225']\nfor i in V3drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forth = V[150:200]\nplot_feature_distribution(t0, t1, '0', '1', forth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V4drop = ['V89', 'V256', 'V3', 'V1', 'V2', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V46', 'V42', 'V43', 'V47', \n         'V41', 'V39', 'V36', 'V35', 'V51', 'V50', 'V49', 'V48', 'V88', 'V93', 'V85', 'V84', 'V83', 'V81', 'V90', 'V91', \n         'V92', 'V94', 'V80', 'V79', 'V75', 'V75']\nfor i in V4drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fifth = V[200:250]\nplot_feature_distribution(t0, t1, '0', '1', fifth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V5drop = ['V68', 'V27', 'V28', 'V53', 'V74', 'V73', 'V72', 'V66', 'V54', 'V67', 'V64', 'V63', 'V62', 'V61', 'V71', 'V69', \n          'V55', 'V60', 'V59', 'V58', 'V57', 'V65', 'V56', 'V70', 'V22', 'V23', 'V24', 'V34', 'V33', 'V32', 'V31', 'V30', \n          'V29', 'V26', 'V25', 'V15', 'V21', 'V14', 'V16', 'V17', 'V18', 'V19', 'V12', 'V20', 'V13', 'V301', 'V300', 'V296', \n          'V289', 'V288']\nfor i in V5drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sixth = V[250:300]\nplot_feature_distribution(t0, t1, '0', '1', sixth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V6drop = ['V114', 'V110', 'V105', 'V104', 'V103', 'V102', 'V101', 'V100', 'V95', 'V99', 'V98', 'V107', 'V111', 'V112', 'V106',\n         'V113', 'V108', 'V134', 'V133', 'V135', 'V132', 'V131', 'V130', 'V129', 'V126', 'V125', 'V124', 'V123', 'V122', \n          'V121', 'V120', 'V119', 'V118', 'V117', 'V116', 'V115', 'V109', 'V294']\nfor i in V6drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seventh = V[300:350]\nplot_feature_distribution(t0, t1, '0', '1', seventh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V7drop = ['V305', 'V304', 'V303', 'V302', 'V299', 'V298', 'V297', 'V295', 'V293', 'V292', 'V291', 'V290', 'V287', 'V286',\n         'V285', 'V289', 'V279', 'V309', 'V316', 'V318', 'V319']\nfor i in V7drop:\n    drop_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Other D"},{"metadata":{"trusted":true},"cell_type":"code","source":"D_done = ['D7', 'D13', 'D14', 'D12', 'D6', 'D9', 'D8']\nD_not_done = missing['features'].apply(lambda x: x if x[0]=='D' else 0)\nD_not_done = pd.DataFrame(D_not_done)\nD_not_done = D_not_done[D_not_done['features']!=0]\nD_not_done = D_not_done[~D_not_done['features'].isin(D_done)]\nD_not_done = D_not_done[~D_not_done['features'].isin(['DeviceInfo', 'DeviceType'])]\nD = list(D_not_done['features'])\nD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D5', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usefull"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D2', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usefull"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D11', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D3', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D4', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D15', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D10', True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'D1', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I believe all the features starting with D are usefull, the only one that i am not sure is D7. "},{"metadata":{},"cell_type":"markdown","source":"# C"},{"metadata":{"trusted":true},"cell_type":"code","source":"C_not_done = missing['features'].apply(lambda x: x if x[0]=='C' else 0)\nC_not_done = pd.DataFrame(C_not_done)\nC_not_done = C_not_done[C_not_done['features']!=0]\nC_not_done = list(C_not_done['features'])\nC_not_done","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C1', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C2', True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C3', False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features.append('C3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C4', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C5', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C6', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C7', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C8', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C9', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C10', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C11', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C12', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C13', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'C14', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the c features are usefull except C3. I am not totally sure because non linear models behave in misterious ways so we need to experiment"},{"metadata":{},"cell_type":"markdown","source":"# Other id"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"id_done = ['id_24', 'id_25', 'id_08', 'id_07', 'id_21', 'id_26', 'id_27', 'id_23', 'id_22', 'id_18', 'id_04', 'id_03', \n           'id_33', 'id_09', 'id_30', 'id_32', 'id_32', 'id_34', 'id_14']\nid_not_done = missing['features'].apply(lambda x: x if x[0]=='i' else 0)\nid_not_done = pd.DataFrame(id_not_done)\nid_not_done = id_not_done[id_not_done['features']!=0]\nid_not_done = id_not_done[~id_not_done['features'].isin(id_done)]\nid_not_done","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_13')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_05')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_06')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_20')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_19')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_17')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_31')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'id_02', False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_11')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_28')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_28')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_29')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_29')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_38')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_38')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_37')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_37')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_36')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_36')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_35')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('id_35')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_15')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'id_01', False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'id_12')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# c"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_not_done = missing['features'].apply(lambda x: x if x[0]=='c' else 0)\nc_not_done = pd.DataFrame(c_not_done)\nc_not_done = c_not_done[c_not_done['features']!=0]\nlist(c_not_done['features'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'card1', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'card2', False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'card3', True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'card4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('card4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(train, test, 'card5', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'card6')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('card6')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# M"},{"metadata":{"trusted":true},"cell_type":"code","source":"M_not_done = missing['features'].apply(lambda x: x if x[0]=='M' else 0)\nM_not_done = pd.DataFrame(M_not_done)\nM_not_done = M_not_done[M_not_done['features']!=0]\nlist(M_not_done['features'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'M1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features.append('M1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'M2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('M2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'M3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('M3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'M4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'M5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('M5')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_c_feature(train, 'M6')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_features.append('M6')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model and Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_copy = train.copy()\ntest_copy = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def id_split(dataframe):\n    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n\n    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n\n    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n\n    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n\n    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n\n    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n    \n    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = 'Others'\n    gc.collect()\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split some features and replace values\ntrain = id_split(train)\ntest = id_split(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter usefull features with the e.d.a\nusefull_features = [col for col in train.columns if col not in drop_features]\ntrain = train[usefull_features]\nusefull_features.remove('isFraud')\ntest = test[usefull_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New feature - log of transaction amount. ()\ntrain['TransactionAmt_Log'] = np.log(train['TransactionAmt'])\ntest['TransactionAmt_Log'] = np.log(test['TransactionAmt'])\n\n# New feature - decimal part of the transaction amount.\ntrain['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\ntest['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)\n\n# Some arbitrary features interaction\nfor feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n\n    f1, f2 = feature.split('__')\n    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n\n    le = LabelEncoder()\n    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n    train[feature] = le.transform(list(train[feature].astype(str).values))\n    test[feature] = le.transform(list(test[feature].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', \n          'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', \n          'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', \n          'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', \n          'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', \n          'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', \n          'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', \n          'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', \n          'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', \n          'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', \n          'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', \n          'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', \n          'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', \n          'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', \n          'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', \n          'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', \n          'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', \n          'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in ['P_emaildomain', 'R_emaildomain']:\n    train[c + '_bin'] = train[c].map(emails)\n    test[c + '_bin'] = test[c].map(emails)\n    \n    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n    test[c + '_suffix'] = test[c].map(lambda x: str(x).split('.')[-1])\n    \n    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    test[c + '_suffix'] = test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\ndef setTime(df):\n    df['TransactionDT'] = df['TransactionDT'].fillna(df['TransactionDT'].median())\n    # Temporary\n    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n    df['DT_M'] = (df['DT'].dt.year-2017)*12 + df['DT'].dt.month\n    df['DT_W'] = (df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear\n    df['DT_D'] = (df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear\n    \n    df['DT_hour'] = df['DT'].dt.hour\n    df['DT_day_week'] = df['DT'].dt.dayofweek\n    df['DT_day'] = df['DT'].dt.day\n    \n    # Lets transform D8 and D9 column\n    # As we almost sure it has connection with hours\n    df['D9_not_na'] = np.where(df['D9'].isna(),0,1)\n    df['D8_not_same_day'] = np.where(df['D8']>=1,1,0)\n    df['D8_D9_decimal_dist'] = df['D8'].fillna(0)-df['D8'].fillna(0).astype(int)\n    df['D8_D9_decimal_dist'] = ((df['D8_D9_decimal_dist']-df['D9'])**2)**0.5\n    df['D8'] = df['D8'].fillna(-1).astype(int)\n\n    return df\n    \ntrain=setTime(train)\ntest=setTime(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def addNewFeatures(data): \n    data['uid'] = data['card1'].astype(str)+'_'+data['card2'].astype(str)\n\n    data['uid2'] = data['uid'].astype(str)+'_'+data['card3'].astype(str)+'_'+data['card5'].astype(str)\n\n    data['uid3'] = data['uid2'].astype(str)+'_'+data['addr1'].astype(str)+'_'+data['addr2'].astype(str)\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = addNewFeatures(train)\ntest = addNewFeatures(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i_cols = ['card2','card3','card5','uid','uid2','uid3']\n\nfor col in i_cols:\n    for agg_type in ['mean','std']:\n        new_col_name = col+'_TransactionAmt_'+agg_type\n        temp_df = pd.concat([train[[col, 'TransactionAmt']], test[[col,'TransactionAmt']]])\n        #temp_df['TransactionAmt'] = temp_df['TransactionAmt'].astype(int)\n        temp_df = temp_df.groupby([col])['TransactionAmt'].agg([agg_type]).reset_index().rename(\n                                                columns={agg_type: new_col_name})\n\n        temp_df.index = list(temp_df[col])\n        temp_df = temp_df[new_col_name].to_dict()   \n\n        train[new_col_name] = train[col].map(temp_df)\n        test[new_col_name]  = test[col].map(temp_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.replace(np.inf,999)\ntest = test.replace(np.inf,999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i_cols = ['card1','card2','card3','card5',\n          'C1','C2','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n          'D1','D2','D3','D4','D5','D6','D7','D8',\n          'addr1','addr2',\n          'dist1','dist2',\n          'P_emaildomain', 'R_emaildomain',\n          'DeviceInfo','device_name',\n          'id_30','id_33',\n          'uid','uid2','uid3',\n         ]\n\nfor col in i_cols:\n    temp_df = pd.concat([train[[col]], test[[col]]])\n    fq_encode = temp_df[col].value_counts(dropna=False).to_dict()   \n    train[col+'_fq_enc'] = train[col].map(fq_encode)\n    test[col+'_fq_enc']  = test[col].map(fq_encode)\n\n\nfor col in ['DT_M','DT_W','DT_D']:\n    temp_df = pd.concat([train[[col]], test[[col]]])\n    fq_encode = temp_df[col].value_counts().to_dict()\n            \n    train[col+'_total'] = train[col].map(fq_encode)\n    test[col+'_total']  = test[col].map(fq_encode)\n\nperiods = ['DT_M','DT_W','DT_D']\ni_cols = ['uid']\nfor period in periods:\n    for col in i_cols:\n        new_column = col + '_' + period\n            \n        temp_df = pd.concat([train[[col,period]], test[[col,period]]])\n        temp_df[new_column] = temp_df[col].astype(str) + '_' + (temp_df[period]).astype(str)\n        fq_encode = temp_df[new_column].value_counts().to_dict()\n            \n        train[new_column] = (train[col].astype(str) + '_' + train[period].astype(str)).map(fq_encode)\n        test[new_column]  = (test[col].astype(str) + '_' + test[period].astype(str)).map(fq_encode)\n        \n        train[new_column] /= train[period+'_total']\n        test[new_column]  /= test[period+'_total']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop noisy columns    \ntrain.drop(['TransactionDT', 'uid','uid2','uid3', 'DT','DT_M','DT_W','DT_D', 'DT_hour','DT_day_week','DT_day',\n            'DT_D_total','DT_W_total','DT_M_total', 'id_30','id_31','id_33', 'D1', 'D2', 'D9'], axis = 1, inplace = True)\ntest.drop(['TransactionDT', 'uid','uid2','uid3', 'DT','DT_M','DT_W','DT_D', 'DT_hour','DT_day_week','DT_day',\n            'DT_D_total','DT_W_total','DT_M_total', 'id_30','id_31','id_33', 'D1', 'D2', 'D9'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if train[col].dtype == 'object':\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def agg_features(df):\n    columns_a = ['TransactionAmt', 'id_02', 'D15']\n    columns_b = ['card1', 'card4', 'addr1']\n    for col_a in columns_a:\n        for col_b in columns_b:\n            df[f'{col_a}_to_mean_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('mean')\n            df[f'{col_a}_to_std_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('std')\n    return df\n\ntest = agg_features(test)\ntrain = agg_features(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['isFraud'], axis = 1)\ny = train['isFraud']\n\nprint('Our train set have {} columns'.format(train.shape[1]))\nprint('Our test set have {} columns'.format(test.shape[1]))\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n                    'objective':'binary',\n                    'boosting_type':'gbdt',\n                    'metric':'auc',\n                    'n_jobs':-1,\n                    'learning_rate':0.005,\n                    'num_leaves': 2**8,\n                    'max_depth':-1,\n                    'tree_learner':'serial',\n                    'colsample_bytree': 0.7,\n                    'subsample_freq':1,\n                    'subsample':0.7,\n                    'n_estimators':100000,\n                    'max_bin':255,\n                    'verbose':-1,\n                    'random_state': 47,\n                    'early_stopping_rounds':100, \n                }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NFOLDS = 10\nfolds = KFold(n_splits=NFOLDS)\n\n\nsplits = folds.split(X, y)\ny_preds = np.zeros(test.shape[0])\ny_oof = np.zeros(X.shape[0])\nscore = 0\n\nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    dtrain = lgb.Dataset(X_train, label = y_train)\n    dvalid = lgb.Dataset(X_valid, label = y_valid)\n    \n    clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], \n                    verbose_eval = 200, early_stopping_rounds = 500)\n    \n    y_pred_valid = clf.predict(X_valid)\n    y_oof[valid_index] = y_pred_valid\n    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n    \n    score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n    y_preds += clf.predict(test) / NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    gc.collect()\n    \nprint(\"Mean AUC: \", score)\nprint(\"Out of folds AUC: \", roc_auc_score(y, y_oof))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['isFraud'] = y_preds\nsub.to_csv('submission_v1.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}