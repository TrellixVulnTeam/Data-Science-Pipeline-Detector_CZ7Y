{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Credit Card Fraud Detection  \nAccording to [Competition Discussion](http://https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203#latest-643955) the Categorical Features are:   \n* ProductCD   \n* card1 - card6 \n* addr1, addr2\n* Pemaildomain \n* Remaildomain  \n* M1 - M9     \n* DeviceType\n* DeviceInfo  \n* id12 - id38    \nHowever, some of these look like they have been preprocessed into a numerical values. \nThese columns are:  \n* card1 - card3, card5\n* addr1, addr2\n* id13, id14, id17-id22, id24-id26, id32   "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Load packages\nimport numpy as np   # linear algebra\nimport pandas as pd  # data processing\n\n# Input data files are available in the \"../input/\" directory.\n# List all files under the input directory\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Path to data files\npath = '../input/ieee-fraud-detection/'\n\n# Load transaction data\ntrain_transaction = pd.read_csv(path + 'train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv(path + 'test_transaction.csv', index_col='TransactionID')\n\n# Load identity data\ntrain_identity = pd.read_csv(path + 'train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv(path + 'test_identity.csv', index_col='TransactionID')\n\n# These merges will keep the data in the left dataframe. Data from the right \n# dataframe will only be kept if the index appears in the left dataframe.\ntrn = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntst = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\n# Delete dataframes no longer needed to free up RAM\ndel train_transaction, train_identity, test_transaction, test_identity\n\n# Get target, remove it from training data\ny = trn['isFraud']\ntrn = trn.drop('isFraud', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data processing  \nRemove cols that are missing \"large\" amounts of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# If pct of missing data in a col > pct_thresh then remove col \npct_thresh = 0.45\n# 47% = 228 dropped cols\n# 46% = 228 dropped cols\n# 45% = 231 dropped cols\n# 40% = 232 dropped cols\n\nnumRows = trn.shape[0]\ncol_list = trn.columns.values.tolist()\n\n# Determine which cols to keep\nnew_cols = []\nfor col in col_list:\n    missing_ratio = trn[trn[col].isnull()].shape[0] / numRows\n    if missing_ratio < pct_thresh:\n        new_cols.append(col)\n        \nprint('Num cols dropped:', len(col_list) - len(new_cols))\nprint('Remaining cols:', len(new_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update train and test dataframes.\ntrn = trn[new_cols]\ntst = tst[new_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Process categorical variables  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get list of categorical variables\ncat_cols = (trn.dtypes == 'object')\ncat_cols = cat_cols[cat_cols].index.tolist()\nprint(cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Process P_emaildomain  \nThere are a few 'gmail' domains. I assume these should be 'gmail.com'.   \nIt might make sense to combine them. Occurs in both trn and tst data.  "},{"metadata":{},"cell_type":"markdown","source":"Testing set contains one domain that does not appear in the trn set: 'scranton.edu'.   \nThere are only 2 instances of this category.  \nNeed to deal with this carefully when implementing one-hot encoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputation - Replace missing values with 'missingP_email'\ntrn.loc[ trn['P_emaildomain'].isnull(), 'P_emaildomain'] = 'missingP_email'\ntst.loc[ tst['P_emaildomain'].isnull(), 'P_emaildomain'] = 'missingP_email'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change 'gmail' to 'gmail.com'\ntrn.loc[trn.P_emaildomain == 'gmail', 'P_emaildomain'] = 'gmail.com'\ntst.loc[tst.P_emaildomain == 'gmail', 'P_emaildomain'] = 'gmail.com'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find all domains that have no fraud\nfraud_count = trn.P_emaildomain.value_counts().to_frame()\nfraud_count['frauds'] = 0\nfraud_count['pct'] = 0\n\nfor domain in fraud_count.index:\n    num_frauds = trn['P_emaildomain'].loc[(trn.P_emaildomain == domain) & (y == True)].count()\n    pct = num_frauds / fraud_count.loc[domain, 'P_emaildomain']\n    fraud_count.loc[domain, 'frauds'] = num_frauds\n    fraud_count.loc[domain, 'pct'] = pct\n    \nno_fraud = fraud_count.loc[fraud_count['frauds'] == 0].index.to_list() \n\n# Rename all no-fraud domains to 'zero_fraud'\nfor domain in no_fraud:\n    trn.loc[trn.P_emaildomain == domain, 'P_emaildomain'] = 'zero_fraud'\n    tst.loc[tst.P_emaildomain == domain, 'P_emaildomain'] = 'zero_fraud'    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(trn.columns)\nprint(len(trn.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#############\n# Count occurances of each email domain. Store results in dataframe.\n#fraud_count = trn.P_emaildomain.value_counts().to_frame()\n\n# Determine num frauds and pct frauds for each domain. \n# Replace each email domain with pct fraud\n#fraud_count['frauds'] = 0\n#fraud_count['pct'] = 0\n\n# Imputation: add new column for pct fraud for each email domain\n#trn.loc['P_email_pct_fraud'] = 0\n#tst.loc['P_email_pct_fraud'] = 0\n\n#for domain in fraud_count.index:\n#    trn.loc[trn.P_emaildomain == domain, 'P_email_pct_fraud'] = fraud_count.loc[domain, 'pct']\n#    tst.loc[tst.P_emaildomain == domain, 'P_email_pct_fraud'] = fraud_count.loc[domain, 'pct']\n\n# Note that tst has an email domain 'scranton.edu' that does not appear in \n# the trn data. Have to deal with this case seperately\n#tst.loc[tst.P_emaildomain == 'scranton.edu', 'P_email_pct_fraud'] = fraud_count.pct.mean()\n\n# Drop P_emaildomain \n#trn = trn.drop('P_emaildomain', axis=1)\n#tst = tst.drop('P_emaildomain', axis=1)\n\n#no_fraud = fraud_count.loc[fraud_count['frauds'] == 0].index.to_list() \n\n# Rename all no-fraud domains to 'zero_fraud'\n#for domain in no_fraud:\n#    trn.loc[trn.P_emaildomain == domain, 'P_emaildomain'] = 'zero_fraud'\n#    tst.loc[tst.P_emaildomain == domain, 'P_emaildomain'] = 'zero_fraud'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'ProductCD' has an 'S' category in the testing data that does not appear in the training data, so let's skip this feature for now.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'ProductCD' will take a little more massaging to process. \n# For now let's drop it. Can come back to later.\ntrn = trn.drop(['ProductCD'], axis=1)\ntst = tst.drop(['ProductCD'], axis=1)\n\n# Replace missing entries (NaN) with marker string\ntrn.loc[trn['card4'].isnull(), ['card4']] = 'missing4'\ntrn.loc[trn['card6'].isnull(), ['card6']] = 'missing6'\n#trn.loc[trn['M1'].isnull(), ['M1']] = 'missingM1'\n#trn.loc[trn['M2'].isnull(), ['M2']] = 'missingM2'\n#trn.loc[trn['M3'].isnull(), ['M3']] = 'missingM3'\ntrn.loc[trn['M6'].isnull(), ['M6']] = 'missingM6'\ntst.loc[tst['card4'].isnull(), ['card4']] = 'missing4'\ntst.loc[tst['card6'].isnull(), ['card6']] = 'missing6'\n#tst.loc[tst['M1'].isnull(), ['M1']] = 'missingM1'\n#tst.loc[tst['M2'].isnull(), ['M2']] = 'missingM2'\n#tst.loc[tst['M3'].isnull(), ['M3']] = 'missingM3'\ntst.loc[tst['M6'].isnull(), ['M6']] = 'missingM6'\n\n# trn['card6'] contains the category 'debit or credit'. \n# As these are the only two possiblities, this info is not helpful. \n# Change 'debit or credit' to 'missing'\n# tst['card6'] does not have this category\ntrn.loc[trn['card6'] == 'debit or credit', ['card6']] = 'missing6'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One-hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update list of categorical variables\ncat_cols = (trn.dtypes == 'object')\ncat_cols = cat_cols[cat_cols].index.tolist()\n\ndummy_cols = []\nfor col in cat_cols:\n    print(col)\n    # Process training data\n    # Get dummies, add to trn\n    dummy = pd.get_dummies(trn[col])\n    dummy_cols.extend(dummy.columns.tolist())\n    trn = pd.concat([trn, dummy], axis = 1)\n    # Now process test data. As mentioned above, tst has an extra category in \n    # P_emaildomain: 'scranton.edu'. But there are only 2 instances. This will\n    # will result in an extra dummy col in the tst dataframe.\n    dummy = pd.get_dummies(tst[col])\n    tst = pd.concat([tst, dummy], axis = 1)\n\n# Now perform an inner join on the two dataframes. This (hopefully) removes\n# cols that do not appear in both dataframes. In particular, this should remove\n# the dummy col for 'scranton.edu' from the tst dataframe.\ntrn, tst = trn.align(tst, join='inner', axis=1)\n\n# Drop categorical columns\ntrn = trn.drop(cat_cols, axis=1)\ntst = tst.drop(cat_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(trn.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imputation  \nUse **imputation** on missing data. I.e. fill in missing data with *some* value.<br>\nCan use column mean, median, etc. for missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all cols in a list\ncols = trn.columns.values.tolist()\n\n# Remove dummy cols from list, since they will not have missing values.\nfor col in dummy_cols:\n    print(col)\n    cols.remove(col)\n    \n# Perform imputation. This will run through the one-hot cols as well. It's probably best to skip those,\n# but shouldn't cause a problem if you don't, as they should not be missing data.\n\nfor col in cols:\n    #print(col)\n    mean = trn[col].mean()\n    trn[col] = trn[col].fillna(mean)\n    tst[col] = tst[col].fillna(mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure columns are in the same order for train and test\ncols = trn.columns.values.tolist()\ntst = tst[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try XGBoost\nimport xgboost as xgb\n\n# Specify Model: Random Forest\n#from sklearn.ensemble import RandomForestRegressor\n#seed = 1\n#clf = RandomForestRegressor(n_estimators=250, max_depth=30, random_state = seed)\n\nclf = xgb.XGBClassifier(\n    bagging_fraction = 0.9,\n    objective = 'binary:logistic', # Did not change results\n    n_estimators = 300,\n    max_depth=16,\n    learning_rate=0.014,\n    subsample=0.5,\n    colsample_bytree = 0.75,\n    num_leaves = 220,    # Did not change results\n    #missing=-999,\n    random_state=1,\n    tree_method='exact'  # Did not change results # THE MAGICAL PARAMETER\n)\n\nclf.fit(trn, y)\n\n# Make predictions\npredictions = clf.predict(tst)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Submission - write predictions to .csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(index = tst.index)\nsubmission['isFraud'] = predictions\nsubmission.to_csv('nov14.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#trn['P_emaildomain'].isnull().sum()\n#myList = list(set(tst.P_emaildomain.value_counts().index.to_list()) - \n#              set(trn.P_emaildomain.value_counts().index.to_list()))\n#print(myList)\n#email.sort_values(by=['pct','frauds'])\n\nemail_counts = trn.P_emaildomain.value_counts()\nemail = email_counts.to_frame()\n#print(email_counts)\nemail['frauds'] = 0\nemail['pct'] = 0\nemail\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for domain in email.index:\n    numFraud = y.loc[trn['P_emaildomain'] == domain].sum() \n    email.loc[email.index == domain, 'frauds'] = numFraud\n#totFraud = email.frauds.sum()\nemail['pct'] = 100 * email['frauds'] / email['P_emaildomain']\nemail","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tst['P_emaildomain'].loc[tst.P_emaildomain == 'gmail.com']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#cols = trn.columns.values.tolist()\n#list = list(set(dummy_cols) - set(cols))\n#print(list)\n#trn.P_emaildomain\n\ncat_cols = (trn.dtypes == 'object')\ncat_cols = cat_cols[cat_cols].index.tolist()\ncat_cols\n#trn.dtypes\n#trn.astype({'P_emaildomain': 'float64'}).dtypes","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}