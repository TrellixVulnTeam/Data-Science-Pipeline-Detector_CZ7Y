{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, warnings, random\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\n\n\nfrom tqdm import tqdm\n\nimport datetime\nimport math\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-10T20:26:21.356558Z","iopub.execute_input":"2021-06-10T20:26:21.356944Z","iopub.status.idle":"2021-06-10T20:26:22.175554Z","shell.execute_reply.started":"2021-06-10T20:26:21.356846Z","shell.execute_reply":"2021-06-10T20:26:22.174621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:22.176971Z","iopub.execute_input":"2021-06-10T20:26:22.177315Z","iopub.status.idle":"2021-06-10T20:26:22.184088Z","shell.execute_reply.started":"2021-06-10T20:26:22.17728Z","shell.execute_reply":"2021-06-10T20:26:22.183294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nseed_everything(SEED)\nTARGET = 'isFraud'\nSTART_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:22.187325Z","iopub.execute_input":"2021-06-10T20:26:22.187638Z","iopub.status.idle":"2021-06-10T20:26:22.192626Z","shell.execute_reply.started":"2021-06-10T20:26:22.187614Z","shell.execute_reply":"2021-06-10T20:26:22.19187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################### DATA LOAD\n#################################################################################\nprint('Load Data')\ntrain_df = pd.read_pickle('../input/ieee-data-minification/train_transaction.pkl')\ntest_df = pd.read_pickle('../input/ieee-data-minification/test_transaction.pkl')\ntrain_identity = pd.read_pickle('../input/ieee-data-minification/train_identity.pkl')\ntest_identity = pd.read_pickle('../input/ieee-data-minification/test_identity.pkl')\n    \nbase_columns = list(train_df) + list(train_identity)\nprint('Shape control:', train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:22.204527Z","iopub.execute_input":"2021-06-10T20:26:22.20496Z","iopub.status.idle":"2021-06-10T20:26:32.455413Z","shell.execute_reply.started":"2021-06-10T20:26:22.204927Z","shell.execute_reply":"2021-06-10T20:26:32.454553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################### Merge Identity columns\ntemp_df = train_df[['TransactionID']]\ntemp_df = temp_df.merge(train_identity, on=['TransactionID'], how='left')\ndel temp_df['TransactionID']\ntrain_df = pd.concat([train_df,temp_df], axis=1)\n    \ntemp_df = test_df[['TransactionID']]\ntemp_df = temp_df.merge(test_identity, on=['TransactionID'], how='left')\ndel temp_df['TransactionID']\ntest_df = pd.concat([test_df,temp_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:32.458215Z","iopub.execute_input":"2021-06-10T20:26:32.458466Z","iopub.status.idle":"2021-06-10T20:26:36.820091Z","shell.execute_reply.started":"2021-06-10T20:26:32.458441Z","shell.execute_reply":"2021-06-10T20:26:36.819211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_df['isFraud'].copy()\nX_train = train_df.drop('isFraud' , axis = 1)\nX_test = test_df.copy()\nprint(X_train.shape, y_train.shape)\n\ndel train_df, test_df, train_identity, test_identity\nx =gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:36.824077Z","iopub.execute_input":"2021-06-10T20:26:36.824347Z","iopub.status.idle":"2021-06-10T20:26:38.49782Z","shell.execute_reply.started":"2021-06-10T20:26:36.824322Z","shell.execute_reply":"2021-06-10T20:26:38.496953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def frequency_encoding(train_df, test_df, columns, self_encoding=True):\n    for col in columns:\n        temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n        fq_encode = temp_df[col].value_counts(dropna=False).to_dict()\n        train_df[col] = train_df[col].map(fq_encode)\n        test_df[col]  = test_df[col].map(fq_encode)\n    return train_df, test_df","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:38.499387Z","iopub.execute_input":"2021-06-10T20:26:38.499871Z","iopub.status.idle":"2021-06-10T20:26:38.506149Z","shell.execute_reply.started":"2021-06-10T20:26:38.499833Z","shell.execute_reply":"2021-06-10T20:26:38.505343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def uid_aggregation(train_df, test_df, main_columns, uids, aggregations):\n    for main_column in main_columns:  \n        for col in uids:\n            for agg_type in aggregations:\n                new_col_name = col+'_'+main_column+'_'+agg_type\n                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n                                                        columns={agg_type: new_col_name})\n\n                temp_df.index = list(temp_df[col])\n                temp_df = temp_df[new_col_name].to_dict()   \n\n                train_df[new_col_name] = train_df[col].map(temp_df)\n                test_df[new_col_name]  = test_df[col].map(temp_df)\n    return train_df, test_df\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:38.507362Z","iopub.execute_input":"2021-06-10T20:26:38.50771Z","iopub.status.idle":"2021-06-10T20:26:38.517152Z","shell.execute_reply.started":"2021-06-10T20:26:38.507676Z","shell.execute_reply":"2021-06-10T20:26:38.51638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lấy log cho các thuộc tính TransactionAmt, card1, card2","metadata":{}},{"cell_type":"code","source":"X_train['TransactionAmt'] = np.log(X_train['TransactionAmt'])\nX_train['card1'] = np.log(X_train['card1'])\nX_train['card2'] = np.log(X_train['card2'])\n\nX_test['TransactionAmt'] = np.log(X_test['TransactionAmt'])\nX_test['card1'] = np.log(X_test['card1'])\nX_test['card2'] = np.log(X_test['card2'])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:38.518523Z","iopub.execute_input":"2021-06-10T20:26:38.518874Z","iopub.status.idle":"2021-06-10T20:26:38.564988Z","shell.execute_reply.started":"2021-06-10T20:26:38.51884Z","shell.execute_reply":"2021-06-10T20:26:38.564242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xóa bỏ các thuộc tính D có số lượng missing values lớn (>=90%)","metadata":{}},{"cell_type":"code","source":"print(X_train.shape)\ncols = ['D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14']\nX_train = X_train.drop(cols, axis=1)\nprint(X_train.shape)\n\nprint(X_test.shape)\ncols = ['D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14']\nX_test = X_test.drop(cols, axis=1)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:38.566118Z","iopub.execute_input":"2021-06-10T20:26:38.566582Z","iopub.status.idle":"2021-06-10T20:26:40.346438Z","shell.execute_reply.started":"2021-06-10T20:26:38.566547Z","shell.execute_reply":"2021-06-10T20:26:40.345592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalize giá trị các thuộc tính P_emaildomain và R_emaildomain để tránh overfit cho mô hình, giúp mô hình tổng quát hóa tốt hơn","metadata":{}},{"cell_type":"code","source":"# Normalize X_train.P_emaildomain\nX_train.loc[X_train['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\nX_train.loc[X_train['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es', 'ymail.com']), 'P_emaildomain'] = 'Yahoo Mail'\nX_train.loc[X_train['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\nX_train.loc[X_train.P_emaildomain.isin(X_train.P_emaildomain\\\n                                         .value_counts()[X_train.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\nX_train.P_emaildomain.fillna(\"NoInf\", inplace=True)\n\n\n# Normalize X_train.R_emaildomain\nX_train.loc[X_train['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\nX_train.loc[X_train['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jR', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es', 'ymail.com']), 'R_emaildomain'] = 'Yahoo Mail'\nX_train.loc[X_train['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\nX_train.loc[X_train.R_emaildomain.isin(X_train.R_emaildomain\\\n                                         .value_counts()[X_train.R_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\nX_train.R_emaildomain.fillna(\"NoInf\", inplace=True)\n\n# Normalize X_test.P_emaildomain\nX_test.loc[X_test['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\nX_test.loc[X_test['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es', 'ymail.com']), 'P_emaildomain'] = 'Yahoo Mail'\nX_test.loc[X_test['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\nX_test.loc[X_test.P_emaildomain.isin(X_test.P_emaildomain\\\n                                         .value_counts()[X_test.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\nX_test.P_emaildomain.fillna(\"NoInf\", inplace=True)\n\n# Normalize X_test.R_emaildomain\nX_test.loc[X_test['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\nX_test.loc[X_test['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jR', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es', 'ymail.com']), 'R_emaildomain'] = 'Yahoo Mail'\nX_test.loc[X_test['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\nX_test.loc[X_test.R_emaildomain.isin(X_test.R_emaildomain\\\n                                         .value_counts()[X_test.R_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\nX_test.R_emaildomain.fillna(\"NoInf\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:40.347836Z","iopub.execute_input":"2021-06-10T20:26:40.348212Z","iopub.status.idle":"2021-06-10T20:26:41.794506Z","shell.execute_reply.started":"2021-06-10T20:26:40.348174Z","shell.execute_reply":"2021-06-10T20:26:41.793559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xóa bỏ các cột V redundancy","metadata":{}},{"cell_type":"code","source":"v =  [1, 3, 4, 6, 8, 11] \nv += [13, 14, 17, 20, 23, 26, 27, 30]\nv += [36, 37, 40, 41, 44, 47, 48]\nv += [54, 56, 59, 62, 65, 67, 68, 70]\nv += [76, 78, 80, 82, 86, 88, 89, 91]\nv += [96, 98, 99, 104]\nv += [107, 108, 111, 115, 117, 120, 121, 123]\nv += [124, 127, 129, 130, 136]\nv += [138, 139, 142, 147, 156, 162]\nv += [165, 160, 166]\nv += [178, 176, 173, 182]\nv += [187, 203, 205, 207, 215]\nv += [169, 171, 175, 180, 185, 188, 198, 210, 209]\nv += [218, 223, 224, 226, 228, 229, 235]\nv += [240, 258, 257, 253, 252, 260, 261]\nv += [264, 266, 267, 274, 277]\nv += [220, 221, 234, 238, 250, 271]\nv += [294, 284, 285, 286, 291, 297]\nv += [303, 305, 307, 309, 310, 320]\nv += [281, 283, 289, 296, 301, 314]\nv += [332, 325, 335, 338]\n\nv_remove = []\nfor item in range(1, 340):\n    if item not in v:\n        v_remove.append('V'+str(item))\n        \nprint(X_train.shape)\nX_train = X_train.drop(v_remove, axis=1)\nprint(X_train.shape)\n\nprint(X_test.shape)\nX_test = X_test.drop(v_remove, axis=1)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:41.800244Z","iopub.execute_input":"2021-06-10T20:26:41.802343Z","iopub.status.idle":"2021-06-10T20:26:42.475372Z","shell.execute_reply.started":"2021-06-10T20:26:41.802304Z","shell.execute_reply":"2021-06-10T20:26:42.473969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bỏ các giá trị có số lần xuất hiện ít (<2) cho card1","metadata":{}},{"cell_type":"code","source":"########################## Reset values for \"noise\" card1\ni_cols = ['card1']\n\nfor col in i_cols: \n    valid_card = pd.concat([X_train[[col]], X_test[[col]]])\n    valid_card = valid_card[col].value_counts()\n    valid_card = valid_card[valid_card>2]\n    valid_card = list(valid_card.index)\n\n    X_train[col] = np.where(X_train[col].isin(X_test[col]), X_train[col], np.nan)\n    X_test[col]  = np.where(X_test[col].isin(X_train[col]), X_test[col], np.nan)\n\n    X_train[col] = np.where(X_train[col].isin(valid_card), X_train[col], np.nan)\n    X_test[col]  = np.where(X_test[col].isin(valid_card), X_test[col], np.nan)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:42.477471Z","iopub.execute_input":"2021-06-10T20:26:42.477722Z","iopub.status.idle":"2021-06-10T20:26:42.541079Z","shell.execute_reply.started":"2021-06-10T20:26:42.477698Z","shell.execute_reply":"2021-06-10T20:26:42.540238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tạo ra thuộc tính mới uid","metadata":{}},{"cell_type":"code","source":"X_train['uid'] = X_train['card1'].astype(str)+'_'+X_train['card2'].astype(str)+'_'+X_train['card3'].astype(str)+'_'+X_train['addr1'].astype(str)\nX_test['uid'] = X_test['card1'].astype(str)+'_'+X_test['card2'].astype(str)+'_'+X_test['card3'].astype(str)+'_'+X_test['addr1'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:42.542484Z","iopub.execute_input":"2021-06-10T20:26:42.542829Z","iopub.status.idle":"2021-06-10T20:26:46.655593Z","shell.execute_reply.started":"2021-06-10T20:26:42.542794Z","shell.execute_reply":"2021-06-10T20:26:46.654713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i_cols = ['TransactionAmt']","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:46.656976Z","iopub.execute_input":"2021-06-10T20:26:46.657326Z","iopub.status.idle":"2021-06-10T20:26:46.661982Z","shell.execute_reply.started":"2021-06-10T20:26:46.657291Z","shell.execute_reply":"2021-06-10T20:26:46.661012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Group các transaction theo uid và normalize theo mean và std của từng group","metadata":{}},{"cell_type":"code","source":"aggregations = ['mean','std']\nX_train, X_test = uid_aggregation(X_train, X_test, i_cols, ['uid'], aggregations)\nX_train = X_train.drop(['uid'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:46.663433Z","iopub.execute_input":"2021-06-10T20:26:46.663815Z","iopub.status.idle":"2021-06-10T20:26:49.466539Z","shell.execute_reply.started":"2021-06-10T20:26:46.663765Z","shell.execute_reply":"2021-06-10T20:26:49.465672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop thuộc tính uid để tránh hiện tượng overfitting","metadata":{}},{"cell_type":"code","source":"X_test = X_test.drop(['uid'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:49.467857Z","iopub.execute_input":"2021-06-10T20:26:49.468217Z","iopub.status.idle":"2021-06-10T20:26:49.746571Z","shell.execute_reply.started":"2021-06-10T20:26:49.468181Z","shell.execute_reply":"2021-06-10T20:26:49.745708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Frequency encoding đối với một số thuộc tính","metadata":{}},{"cell_type":"code","source":"X_train, X_test = frequency_encoding(X_train, X_test, ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain'])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:49.74795Z","iopub.execute_input":"2021-06-10T20:26:49.748326Z","iopub.status.idle":"2021-06-10T20:26:52.54172Z","shell.execute_reply.started":"2021-06-10T20:26:49.748292Z","shell.execute_reply":"2021-06-10T20:26:52.540209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label encoding với các thuộc tính object còn lại","metadata":{}},{"cell_type":"code","source":"for i in X_train.columns:\n    if X_train[i].dtype == 'object' or X_test[i].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(X_train[i].values) + list(X_test[i].values))\n        X_train[i] = lbl.transform(list(X_train[i].values))\n        X_test[i] = lbl.transform(list(X_test[i].values))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:26:52.543305Z","iopub.execute_input":"2021-06-10T20:26:52.543627Z","iopub.status.idle":"2021-06-10T20:27:49.040911Z","shell.execute_reply.started":"2021-06-10T20:26:52.543594Z","shell.execute_reply":"2021-06-10T20:27:49.040032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill NA","metadata":{}},{"cell_type":"code","source":"X_train.fillna(-999, inplace=True)\nX_test.fillna(-999, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:27:49.042136Z","iopub.execute_input":"2021-06-10T20:27:49.042474Z","iopub.status.idle":"2021-06-10T20:27:50.15116Z","shell.execute_reply.started":"2021-06-10T20:27:49.042439Z","shell.execute_reply":"2021-06-10T20:27:50.150229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## We need Divide Train Set by Time blocks\n## Convert TransactionDT to Months\ntrain_df = X_train.copy()\ntrain_df['groups'] = train_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\ntrain_df['groups'] = (train_df['groups'].dt.year-2017)*12 + train_df['groups'].dt.month \n\nsplit_groups = train_df['groups']","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:27:50.160712Z","iopub.execute_input":"2021-06-10T20:27:50.161134Z","iopub.status.idle":"2021-06-10T20:27:51.168678Z","shell.execute_reply.started":"2021-06-10T20:27:50.161088Z","shell.execute_reply":"2021-06-10T20:27:51.167825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GroupKFold Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold,TimeSeriesSplit\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import plot_importance\nfrom sklearn.metrics import make_scorer\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nimport xgboost as xgb\n\nimport time\ndef objective(params):\n    time1 = time.time()\n    params = {\n        'max_depth': int(params['max_depth']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'subsample': \"{:.2f}\".format(params['subsample']),\n        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n        'reg_lambda': \"{:.3f}\".format(params['reg_lambda']),\n        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n        'num_leaves': '{:.3f}'.format(params['num_leaves']),\n        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n        'min_child_samples': '{:.3f}'.format(params['min_child_samples']),\n        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n    }\n\n    print(\"\\n############## New Run ################\")\n    print(f\"params = {params}\")\n    N_SPLITS = 6\n    folds = GroupKFold(n_splits=N_SPLITS)\n    score_mean = 0\n    count=1\n\n    score_mean = 0\n    for tr_idx, val_idx in folds.split(X_train, y_train, groups=split_groups):\n        clf = xgb.XGBClassifier(\n            n_estimators=600, random_state=4, verbose=True, \n            tree_method='gpu_hist', \n            **params\n        )\n\n        X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n        \n        clf.fit(X_tr, y_tr)\n        score = make_scorer(roc_auc_score, needs_proba=True)(clf, X_vl, y_vl)\n        # plt.show()\n        score_mean += score\n        print(f'{count} CV - score: {round(score, 4)}')\n        count += 1\n    time2 = time.time() - time1\n    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n    gc.collect()\n    print(f'Mean ROC_AUC: {score_mean / N_SPLITS}')\n    del X_tr, X_vl, y_tr, y_vl, clf, score\n    return -(score_mean / N_SPLITS)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:28:37.270555Z","iopub.execute_input":"2021-06-10T20:28:37.270868Z","iopub.status.idle":"2021-06-10T20:28:37.283493Z","shell.execute_reply.started":"2021-06-10T20:28:37.270839Z","shell.execute_reply":"2021-06-10T20:28:37.282664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"space = {\n    # The maximum depth of a tree, same as GBM.\n    # Used to control over-fitting as higher depth will allow model \n    # to learn relations very specific to a particular sample.\n    # Should be tuned using CV.\n    # Typical values: 3-10\n    'max_depth': hp.quniform('max_depth', 7, 23, 1),\n    \n    # reg_alpha: L1 regularization term. L1 regularization encourages sparsity \n    # (meaning pulling weights to 0). It can be more useful when the objective\n    # is logistic regression since you might need help with feature selection.\n    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n    \n    # reg_lambda: L2 regularization term. L2 encourages smaller weights, this\n    # approach can be more useful in tree-models where zeroing \n    # features might not make much sense.\n    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n    \n    # eta: Analogous to learning rate in GBM\n    # Makes the model more robust by shrinking the weights on each step\n    # Typical final values to be used: 0.01-0.2\n    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n    \n    # colsample_bytree: Similar to max_features in GBM. Denotes the \n    # fraction of columns to be randomly samples for each tree.\n    # Typical values: 0.5-1\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n    \n    # A node is split only when the resulting split gives a positive\n    # reduction in the loss function. Gamma specifies the \n    # minimum loss reduction required to make a split.\n    # Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n    'gamma': hp.uniform('gamma', 0.01, .7),\n    \n    # more increases accuracy, but may lead to overfitting.\n    # num_leaves: the number of leaf nodes to use. Having a large number \n    # of leaves will improve accuracy, but will also lead to overfitting.\n    'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n    \n    # specifies the minimum samples per leaf node.\n    # the minimum number of samples (data) to group into a leaf. \n    # The parameter can greatly assist with overfitting: larger sample\n    # sizes per leaf will reduce overfitting (but may lead to under-fitting).\n    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n    \n    # subsample: represents a fraction of the rows (observations) to be \n    # considered when building each subtree. Tianqi Chen and Carlos Guestrin\n    # in their paper A Scalable Tree Boosting System recommend \n    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n    \n    # randomly select a fraction of the features.\n    # feature_fraction: controls the subsampling of features used\n    # for training (as opposed to subsampling the actual training data in \n    # the case of bagging). Smaller fractions reduce overfitting.\n    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n    \n    # randomly bag or subsample training data.\n    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n    \n    # bagging_fraction and bagging_freq: enables bagging (subsampling) \n    # of the training data. Both values need to be set for bagging to be used.\n    # The frequency controls how often (iteration) bagging is used. Smaller\n    # fractions and frequencies reduce overfitting.\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:28:37.674098Z","iopub.execute_input":"2021-06-10T20:28:37.674395Z","iopub.status.idle":"2021-06-10T20:28:37.683255Z","shell.execute_reply.started":"2021-06-10T20:28:37.674368Z","shell.execute_reply":"2021-06-10T20:28:37.682389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Set algoritm parameters\n# best = fmin(fn=objective,\n#             space=space,\n#             algo=tpe.suggest,\n#             max_evals=27)\n\n# # Print best parameters\n# best_params = space_eval(space, best)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T20:28:38.512372Z","iopub.execute_input":"2021-06-10T20:28:38.512693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optimized hyper parameters","metadata":{}},{"cell_type":"code","source":"best_params =  {'max_depth': 12, 'gamma': '0.338', 'subsample': '0.80', 'reg_alpha': '0.199', 'reg_lambda': '0.125', 'learning_rate': '0.023', 'num_leaves': '70.000', 'colsample_bytree': '0.571', 'min_child_samples': '140.000', 'feature_fraction': '0.410', 'bagging_fraction': '0.828'}\nbest_params['max_depth'] = int(best_params['max_depth'])\nprint(\"best_params: \", best_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nprint(best_params)\n\nclf = xgb.XGBClassifier(\n    n_estimators=600,\n    **best_params,\n    tree_method='gpu_hist'\n)\n\nclf.fit(X_train, y_train)\n\ny_preds = clf.predict_proba(X_test)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T19:47:10.008972Z","iopub.execute_input":"2021-06-10T19:47:10.009318Z","iopub.status.idle":"2021-06-10T19:47:10.141624Z","shell.execute_reply.started":"2021-06-10T19:47:10.009284Z","shell.execute_reply":"2021-06-10T19:47:10.140771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['isFraud'] = clf.predict_proba(X_test)[:,1]\nsample_submission.to_csv('simple_xgboost.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T19:50:08.018337Z","iopub.execute_input":"2021-06-10T19:50:08.018673Z","iopub.status.idle":"2021-06-10T19:50:31.094754Z","shell.execute_reply.started":"2021-06-10T19:50:08.018641Z","shell.execute_reply":"2021-06-10T19:50:31.093811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}