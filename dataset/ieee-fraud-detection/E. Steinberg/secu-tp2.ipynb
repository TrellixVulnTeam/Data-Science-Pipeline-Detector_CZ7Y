{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Protection and Complex System Security\n\n## Lab session 2: Anomaly detection"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading data\n    1. Open a new Jupyter notebook and name it ‘PDSSC - Lab session – anomaly detection’\n    2. Include the IEEE-CIS Fraud Detection context 2019 dataset from https://www.kaggle.com/c/ieeefraud-detection/data\n    3. Load the CSV files as ‘train_transaction.csv’ using Pandas\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.columns.drop(list(df.filter(regex=\"V\\d+\")))]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.R_emaildomain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    4. From train_transaction keep 10000 entries: the first 9700 non-fraud entries and the first 300 fraud entries in dataset reduced_transaction_df\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_transaction_df = pd.concat((df[df.isFraud==0].head(9700), df[df.isFraud==1].head(300)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data set observation\n\n    5. Print the head of the dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_transaction_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    6. List following information for the training set\n        6.1. Column number\n        6.2. Column names\n        6.3. Size of the data set\n        6.4. Column types\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# nombre de colonnes\nlen(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nom des colonnes\nlist(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taille du dataset\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# types des colonnes\nlist(zip(df.columns, df.dtypes))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    7. Control the correct extraction of transaction: \n        number of non-fraudulent transactions, \n        number of fraudulent transactions, \n        rate of fraudulent transactions"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} / {} = {} % de fraude\".format(len(reduced_transaction_df[reduced_transaction_df.isFraud==1]), len(reduced_transaction_df[reduced_transaction_df.isFraud==0]), len(reduced_transaction_df[reduced_transaction_df.isFraud==1])/len(reduced_transaction_df[reduced_transaction_df.isFraud==0]) ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    8. Which columns are categories? List them; extract existing values.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes('object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in reduced_transaction_df.select_dtypes('object').columns:\n    print(i)\n    print(reduced_transaction_df[i].unique())\n    print ('#'*80)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    9. Which columns are numeric? List them; extract min, max, mean, median and standard deviation values."},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_transaction_df._get_numeric_data().columns[0:45]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in reduced_transaction_df._get_numeric_data().columns:\n    print (i)\n    print (\"mean = \", df[i].mean(), \"median = \", df[i].median(),\"std = \",df[i].std() )\n    print(\"#\"*60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    10. For each column, print the rate of undefined values (NaN for numeric)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in reduced_transaction_df.columns:\n    print (i,' : ', end='')\n    print ( reduced_transaction_df[i].isna().sum()/len(reduced_transaction_df), '%' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    11. For each numerical column, print the rate of zero (0) value\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in reduced_transaction_df.columns:\n    print (i,' : ', end='')\n    print ( (reduced_transaction_df[i]==0).sum()/len(reduced_transaction_df), '%' )\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data set visualisation\n    12. Visualise the dataset using dimensions: 'TransactionAmt', 'card1','addr1'.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show3D_transation_data(transac_dataset, x_axis_name, y_axis_name, z_axis_name):\n    X = transac_dataset.drop(columns=['isFraud'])\n    Y = transac_dataset['isFraud']\n    \n    x = x_axis_name\n    y = y_axis_name\n    z = z_axis_name\n\n    zOffset = 0.02\n    limit = len(X)\n\n    sb.reset_orig()\n\n    fig = plt.figure(figsize = ( 10, 12))\n    ax = fig.add_subplot(111, projection='3d')\n\n    ax.scatter(X.loc[Y == 0, x][:limit], X.loc[Y == 0, y][:limit], -np.log10(X.loc[Y == 0, z][:limit] + zOffset), c = 'g', marker = '.', s = 1, label = 'genuine')\n    \n    ax.scatter(X.loc[Y == 1, x][:limit], X.loc[Y == 1, y][:limit], -np.log10(X.loc[Y == 1, z][:limit] + zOffset), c = 'r', marker = '.', s = 1, label = 'fraudulent')\n    \n    ax.set_xlabel(x, size = 16)\n    ax.set_ylabel(y + ' [hour]', size = 16)\n    ax.set_zlabel('- log$_{10}$ (' + z + ')', size = 16)\n    ax.set_title('Error-based features separate out genuine and fraudulent transactions', size = 20)\n    \n    plt.axis('tight')\n    ax.grid(1)\n    \n    noFraudMarker = Line2D([], [], linewidth = 0, color = 'g', marker = '.', markersize = 10, label = 'genuine')\n    fraudMarker = Line2D([], [], linewidth = 0, color = 'r', marker = '.', markersize = 10, label = 'fraudulent')\n    \n    plt.legend(handles = [noFraudMarker, fraudMarker], bbox_to_anchor = (1.20, 0.38), frameon = False, prop = {'size': 16})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show3D_transation_data(reduced_transaction_df, 'card1', 'addr1', 'TransactionAmt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13. Create an alternate visualisation function for visualising fraud entries only, in red"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show3D_transation_data_f(transac_dataset, x_axis_name, y_axis_name, z_axis_name):\n    X = transac_dataset.drop(columns=['isFraud'])\n    Y = transac_dataset['isFraud']\n    \n    x = x_axis_name\n    y = y_axis_name\n    z = z_axis_name\n\n    zOffset = 0.02\n    limit = len(X)\n\n    sb.reset_orig()\n\n    fig = plt.figure(figsize = ( 10, 12))\n    ax = fig.add_subplot(111, projection='3d')\n\n#    ax.scatter(X.loc[Y == 0, x][:limit], X.loc[Y == 0, y][:limit], -np.log10(X.loc[Y == 0, z][:limit] + zOffset), c = 'g', marker = '.', s = 1, label = 'genuine')\n    \n    ax.scatter(X.loc[Y == 1, x][:limit], X.loc[Y == 1, y][:limit], -np.log10(X.loc[Y == 1, z][:limit] + zOffset), c = 'r', marker = '.', s = 1, label = 'fraudulent')\n    \n    ax.set_xlabel(x, size = 16)\n    ax.set_ylabel(y + ' [hour]', size = 16)\n    ax.set_zlabel('- log$_{10}$ (' + z + ')', size = 16)\n    ax.set_title('Features separate for fraudulent transactions', size = 20)\n    \n    plt.axis('tight')\n    ax.grid(1)\n    \n #   noFraudMarker = Line2D([], [], linewidth = 0, color = 'g', marker = '.', markersize = 10, label = 'genuine')\n    fraudMarker = Line2D([], [], linewidth = 0, color = 'r', marker = '.', markersize = 10, label = 'fraudulent')\n    \n    plt.legend(bbox_to_anchor = (1.20, 0.38), frameon = False, prop = {'size': 16})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show3D_transation_data_f(reduced_transaction_df, 'card1', 'addr1', 'TransactionAmt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{},"cell_type":"markdown","source":"14. Perform one-hot encoding of categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df = pd.get_dummies(reduced_transaction_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"15. Remove NaN (Not a number) values by imputation of the mean of the column"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ohe_reduced_transaction_df:\n    ohe_reduced_transaction_df[i]= ohe_reduced_transaction_df[i].fillna(ohe_reduced_transaction_df[i].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"16. Control that no NaN value remain in the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outlier detection"},{"metadata":{},"cell_type":"markdown","source":"## Isolation Forests"},{"metadata":{},"cell_type":"markdown","source":"17. Extract outliers using sklearn.ensemble.IsolationForests, using and\noutliers_fraction = 0.03. Control the numbers of outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i_f = IsolationForest(contamination=0.03)\ni_f.fit(ohe_reduced_transaction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier = ohe_reduced_transaction_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier['is_outlier'] = [i == -1 for i in  i_f.predict(ohe_reduced_transaction_df) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier.groupby(by=['is_outlier', 'isFraud']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"36/300","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"264/9700","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il y a une plus forte probabilité d'être une fraude pour un outlier, mais ce n'est pas systématique."},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier[(ohe_reduced_transaction_df_outlier.isFraud==1) & (ohe_reduced_transaction_df_outlier.is_outlier==True)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"18. Create yet another visualisation function for visualising IsolationForest outliers entries only, in red"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show3D_transation_data_outlier(transac_dataset, x_axis_name, y_axis_name, z_axis_name):\n    X = transac_dataset.drop(columns=['is_outlier'])\n    Y = transac_dataset['is_outlier']\n    \n    x = x_axis_name\n    y = y_axis_name\n    z = z_axis_name\n\n    zOffset = 0.02\n    limit = len(X)\n\n    sb.reset_orig()\n\n    fig = plt.figure(figsize = ( 10, 12))\n    ax = fig.add_subplot(111, projection='3d')\n\n#    ax.scatter(X.loc[Y == 0, x][:limit], X.loc[Y == 0, y][:limit], -np.log10(X.loc[Y == 0, z][:limit] + zOffset), c = 'g', marker = '.', s = 1, label = 'genuine')\n    \n    ax.scatter(X.loc[Y == 1, x][:limit], X.loc[Y == 1, y][:limit], -np.log10(X.loc[Y == 1, z][:limit] + zOffset), c = 'r', marker = '.', s = 1, label = 'fraudulent')\n    \n    ax.set_xlabel(x, size = 16)\n    ax.set_ylabel(y + ' [hour]', size = 16)\n    ax.set_zlabel('- log$_{10}$ (' + z + ')', size = 16)\n    ax.set_title('Features separate for fraudulent transactions', size = 20)\n    \n    plt.axis('tight')\n    ax.grid(1)\n    \n #   noFraudMarker = Line2D([], [], linewidth = 0, color = 'g', marker = '.', markersize = 10, label = 'genuine')\n    fraudMarker = Line2D([], [], linewidth = 0, color = 'r', marker = '.', markersize = 10, label = 'is_outlier')\n    \n    plt.legend(bbox_to_anchor = (1.20, 0.38), frameon = False, prop = {'size': 16})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show3D_transation_data_outlier(ohe_reduced_transaction_df_outlier, 'card1', 'addr1', 'TransactionAmt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Local Outlier Factor (LOF)"},{"metadata":{},"cell_type":"markdown","source":"19. Extract outliers using sklearn.neighbors.LocalOutlierFactor, using and outliers_fraction = 0.03. Control the numbers of outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lof = LocalOutlierFactor(contamination=0.03)\nlof.fit(ohe_reduced_transaction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"is_lof=lof.fit_predict(ohe_reduced_transaction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier['lof_outlier'] = [i==-1 for i in is_lof]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"20. Create yet another visualisation function for visualising LOF outliers entries only, in red show3D_transation_data_lof_outliers_only(transac_dataset, x_axis_name, y_axis_name, z_axis_name)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show3D_transation_data_lof_outliers_only(transac_dataset, x_axis_name, y_axis_name, z_axis_name):\n    X = transac_dataset.drop(columns=['lof_outlier'])\n    Y = transac_dataset['lof_outlier']\n    \n    x = x_axis_name\n    y = y_axis_name\n    z = z_axis_name\n\n    zOffset = 0.02\n    limit = len(X)\n\n    sb.reset_orig()\n\n    fig = plt.figure(figsize = ( 10, 12))\n    ax = fig.add_subplot(111, projection='3d')\n\n#    ax.scatter(X.loc[Y == 0, x][:limit], X.loc[Y == 0, y][:limit], -np.log10(X.loc[Y == 0, z][:limit] + zOffset), c = 'g', marker = '.', s = 1, label = 'genuine')\n    \n    ax.scatter(X.loc[Y == 1, x][:limit], X.loc[Y == 1, y][:limit], -np.log10(X.loc[Y == 1, z][:limit] + zOffset), c = 'r', marker = '.', s = 1, label = 'lof')\n    \n    ax.set_xlabel(x, size = 16)\n    ax.set_ylabel(y + ' [hour]', size = 16)\n    ax.set_zlabel('- log$_{10}$ (' + z + ')', size = 16)\n    ax.set_title('Features separate for lof transactions', size = 20)\n    \n    plt.axis('tight')\n    ax.grid(1)\n    \n #   noFraudMarker = Line2D([], [], linewidth = 0, color = 'g', marker = '.', markersize = 10, label = 'genuine')\n    fraudMarker = Line2D([], [], linewidth = 0, color = 'r', marker = '.', markersize = 10, label = 'lof_outlier')\n    \n    plt.legend(bbox_to_anchor = (1.20, 0.38), frameon = False, prop = {'size': 16})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show3D_transation_data_lof_outliers_only(ohe_reduced_transaction_df_outlier, 'card1', 'addr1', 'TransactionAmt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparison of IsolationForest and LOF"},{"metadata":{},"cell_type":"markdown","source":"21. Control the complementarity between the 2 algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier.groupby(by = ['is_outlier', 'lof_outlier']).count()[\"isFraud\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier.groupby(by = ['lof_outlier', 'is_outlier']).count()[\"isFraud\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"21.1. How many outliers are common to IsolationForest and LOF?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier.groupby(by = ['lof_outlier', 'is_outlier']).count().loc[True,True]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"=> 21"},{"metadata":{},"cell_type":"markdown","source":"21.2. How many fraudulent outliers are common to IsolationForest and LOF?"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_reduced_transaction_df_outlier.groupby(by = ['lof_outlier', 'is_outlier', 'isFraud']).count().loc[True,True,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"=> Seulement 2"},{"metadata":{},"cell_type":"markdown","source":"21.3. What do you deduce for building unsupervised outlier detectors?"},{"metadata":{},"cell_type":"markdown","source":"Je suppose que les modèles sont assez faibles individuellements, puisque ne se recoupants pas, mais apportent une certaine information tout de même, puisqu'il y a corrélation entre outliers et fraud. Peut être alors qu'en utilisant plusieurs algorithmes de detections d'outliers permettant de faire du feature engineering en ajoutant ces informations aux données pour un classificateur supervisé est la bonne solution ? "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}