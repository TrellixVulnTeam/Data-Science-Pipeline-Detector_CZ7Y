{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install missingpy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/t0biK/data_science_utils.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\nfrom IPython.core.display import HTML\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nimport graphviz\nimport lightgbm as lgb\nimport warnings\nfrom tqdm.notebook import tqdm\nimport data_science_utils.feature_extraction_util as fe\nfrom data_science_utils.plot_util import *\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom missingpy import MissForest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\ntest_identity.columns = test_identity.columns.str.replace(\"-\", \"_\")\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntest_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_identity, train_transaction, on='TransactionID', how='right')\ntest = pd.merge(test_identity, test_transaction, on='TransactionID', how='right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clear unused data to free up some memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity, train_identity, test_transaction, train_transaction = [None]*4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fill missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = ['id_0'+str(i) for i in range(1,10)]+['id_10', 'id_11']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Data with -999"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[:,~test.columns.isin(numerical_columns)] = test.loc[:,~test.columns.isin(numerical_columns)].fillna(-999)\ntrain.loc[:,~train.columns.isin(numerical_columns)] = train.loc[:,~train.columns.isin(numerical_columns)].fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill numerical with imputation (missForest)"},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = MissForest()\ntest.loc[:,test.columns.isin(numerical_columns)] = imputer.fit_transform(test.loc[:,test.columns.isin(numerical_columns)])\ntrain.loc[:,train.columns.isin(numerical_columns)] = imputer.fit_transform(train.loc[:,train.columns.isin(numerical_columns)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fix covariate shift"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'objective': 'binary', \"boosting_type\": \"gbdt\", \"subsample\": 1, \"bagging_seed\": 11, \"metric\": 'auc', 'num_boost_round':100, 'verbose':-1}\n#train, test = fe.correct_features_with_covariate_shift(train, test, params, train.columns.drop(['isFraud', 'TransactionID', 'TransactionDT']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add more features"},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_features = ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1',\n                   'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13',\n                   'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M2', 'M3',\n                   'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V17',\n                   'V19', 'V20', 'V29', 'V30', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V40', 'V44', 'V45', 'V46', 'V47', 'V48',\n                   'V49', 'V51', 'V52', 'V53', 'V54', 'V56', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V69', 'V70', 'V71',\n                   'V72', 'V73', 'V74', 'V75', 'V76', 'V78', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V87', 'V90', 'V91', 'V92',\n                   'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140',\n                   'V143', 'V145', 'V146', 'V147', 'V149', 'V150', 'V151', 'V152', 'V154', 'V156', 'V158', 'V159', 'V160', 'V161',\n                   'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V169', 'V170', 'V171', 'V172', 'V173', 'V175', 'V176', 'V177',\n                   'V178', 'V180', 'V182', 'V184', 'V187', 'V188', 'V189', 'V195', 'V197', 'V200', 'V201', 'V202', 'V203', 'V204',\n                   'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V219', 'V220',\n                   'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V231', 'V233', 'V234', 'V238', 'V239',\n                   'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V249', 'V251', 'V253', 'V256', 'V257', 'V258', 'V259', 'V261',\n                   'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276',\n                   'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294', 'V303',\n                   'V304', 'V306', 'V307', 'V308', 'V310', 'V312', 'V313', 'V314', 'V315', 'V317', 'V322', 'V323', 'V324', 'V326',\n                   'V329', 'V331', 'V332', 'V333', 'V335', 'V336', 'V338', 'id_01', 'id_02', 'id_03', 'id_05', 'id_06', 'id_09',\n                   'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_17', 'id_19', 'id_20', 'id_30', 'id_31', 'id_32', 'id_33',\n                   'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\ntest['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)\n\n# Count encoding for card1 feature. \n# Explained in this kernel: https://www.kaggle.com/nroman/eda-for-cis-fraud-detection\ntrain['card1_count_full'] = train['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))\ntest['card1_count_full'] = test['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))\n\n# https://www.kaggle.com/fchmiel/day-and-time-powerful-predictive-feature\ntrain['Transaction_day_of_week'] = np.floor((train['TransactionDT'] / (3600 * 24) - 1) % 7)\ntest['Transaction_day_of_week'] = np.floor((test['TransactionDT'] / (3600 * 24) - 1) % 7)\ntrain['Transaction_hour'] = np.floor(train['TransactionDT'] / 3600) % 24\ntest['Transaction_hour'] = np.floor(test['TransactionDT'] / 3600) % 24\n\n# Some arbitrary features interaction\nfor feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n\n    f1, f2 = feature.split('__')\n    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n\n    le = LabelEncoder()\n    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n    train[feature] = le.transform(list(train[feature].astype(str).values))\n    test[feature] = le.transform(list(test[feature].astype(str).values))\n    \nfor feature in ['id_34', 'id_36']:\n    if feature in useful_features:\n        # Count encoded for both train and test\n        train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n        test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n        \nfor feature in ['id_01', 'id_31', 'id_33', 'id_35', 'id_36']:\n    if feature in useful_features:\n        # Count encoded separately for train and test\n        train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n        test[feature + '_count_dist'] = test[feature].map(test[feature].value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train lightgbm"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'num_leaves': 491,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 106,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.0066,\n          'n_estimators': 1000,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train.drop(columns=['isFraud', 'TransactionID', 'TransactionDT']), train['isFraud'], test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X_train.select_dtypes(include='object').columns:\n    le = LabelEncoder()\n    le.fit(list(X_train[col].astype(str).values) + list(X_test[col].astype(str).values) + list(test[col].astype(str).values))\n    X_train[col] = le.transform(list(X_train[col].astype(str).values))\n    X_test[col] = le.transform(list(X_test[col].astype(str).values))\n    test[col] = le.transform(list(test[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop = ['TransactionID', 'TransactionDT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\nsub['isFraud'] = clf.predict_proba(test.drop(columns=cols_to_drop))[:, 1]\nsub['TransactionID'] = test.TransactionID\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}