{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CatBoost Baseline"},{"metadata":{},"cell_type":"markdown","source":"This is baseline notebook, which implements basic boosting classification with CatBoost."},{"metadata":{},"cell_type":"markdown","source":"## Table of contents\n[Loading data](#p-load) <br>\n[Dealing with categorical features](#p-cat-features) <br>\n[Feature selection](#p-fselection) <br>\n[Parameters](#p-params) <br>\n[Training with cross-validation](#p-cv) <br>\n[Feature importances](#p-imp) <br>\n[Submission](#p-sub)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier\n\nfrom tqdm import tqdm_notebook\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data <a name=\"p-load\"></a>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntest_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\ntest_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n# train_transaction = pd.read_csv('train_transaction.csv')\n# train_identity = pd.read_csv('train_identity.csv')\n# test_transaction = pd.read_csv('test_transaction.csv')\n# test_identity = pd.read_csv('test_identity.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_transaction.merge(train_identity, how='left', left_on='TransactionID', right_on='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_transaction\ndel train_identity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test_transaction.merge(test_identity, how='left', left_on='TransactionID', right_on='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_transaction\ndel test_identity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_value_cols = [col for col in train_df.columns if train_df[col].nunique() <= 1]\none_value_cols_test = [col for col in test_df.columns if test_df[col].nunique() <= 1]\n\nmany_null_cols = [col for col in train_df.columns if train_df[col].isnull().sum() / train_df.shape[0] > 0.9]\nmany_null_cols_test = [col for col in test_df.columns if test_df[col].isnull().sum() / test_df.shape[0] > 0.9]\n\nbig_top_value_cols = [col for col in train_df.columns if train_df[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in test_df.columns if test_df[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n\ncols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols + one_value_cols_test))\ncols_to_drop.remove('isFraud')\nprint('{} features are going to be dropped for being useless'.format(len(cols_to_drop)))\n\ntrain_df = train_df.drop(cols_to_drop, axis=1)\ntest_df = test_df.drop(cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dealing with categorical features <a name=\"p-cat-features\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's examine all categorical features which are given by default"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['ProductCD', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'DeviceType', 'DeviceInfo'] \\\n                + [x for x in train_df.columns if 'card' in x] \\\n                + [x for x in train_df.columns if 'M' in x] \\\n                + [x for x in train_df.columns if ('id_' in x) and (int(x[-2:]) > 11)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in cat_features:\n    s = {y for y in set(train_df[x].unique()).symmetric_difference(set(test_df[x].unique())) if y==y}\n    l = train_df[x].nunique()\n    d = train_df[x].dtypes\n    if (len(s)/l > 0.1) and (l > 10) and (d in numerics):\n        print('Feature %s; Type %s; Diff %d; Train len %d; Percent diff %.3f' % (x, d, len(s), l, 100*len(s)/l))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is too many unique values in some column, which are not of type object. Let's assume it is continuous variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features= [x for x in cat_features if x not in ['addr1', 'addr2', 'card1', 'card3',\\\n                                                    'card5', 'id_13', 'id_14', 'id_17', 'id_19', 'id_20']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection <a name=\"p-fselection\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We try to exclude correlated features, because they can worsen accuracy of boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrs = train_df.drop(cat_features+['isFraud', 'TransactionID'], axis=1).corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = corrs.abs().mask(np.eye(len(corrs), dtype=bool))\ntmp = tmp[tmp > 0.8]\ns = tmp.unstack().dropna()\n\ncorr_df = pd.DataFrame(s.index.tolist(), columns=['feature1', 'feature2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_features = corr_df.feature1.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggr_corr_df = corr_df.groupby('feature1').apply(lambda x:frozenset(list(x['feature1'])[:1]+list(x['feature2']))).reset_index()\naggr_corr_df.columns = ['feature1', 'features']\naggr_corr_df.drop_duplicates(subset='features', inplace=True)\naggr_corr_df['features'] = aggr_corr_df['features'].apply(list)\naggr_corr_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To find best feature among correlated, we use one-factor logistic regression, and calculate Gini coefficient. The better it is - the better is feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(solver='lbfgs')\nfeature_gini = {}\n\nfor col in tqdm_notebook(train_df[corr_features].columns):\n    tmp = pd.concat([train_df[[col]], train_df.isFraud], axis=1)\n    tmp.dropna(inplace=True)\n    lr.fit(tmp.drop('isFraud', axis=1), tmp.isFraud)\n    y_pred_col = lr.predict_proba(tmp.drop('isFraud', axis=1))[:,1]\n    roc_auc_col = roc_auc_score(tmp.isFraud, y_pred_col)\n    feature_gini[col] = np.abs((2*roc_auc_col - 1)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def max_in_list(list_):\n    return list_.index(max(list_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggr_corr_df['feature_gini'] = aggr_corr_df.features.apply(lambda x: x[max_in_list([feature_gini.get(i, 0) for i in x])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"good_features = aggr_corr_df.feature_gini.unique().tolist() + [x for x in train_df.columns if x not in corr_features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parameters <a name=\"p-params\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in cat_features:\n    if train_df[x].dtypes in numerics:\n        train_df.loc[train_df[x].isnull(), x] = train_df[x].min() - 1000\n        test_df.loc[test_df[x].isnull(), x] = train_df[x].min() - 1000\n    else:\n        train_df.loc[train_df[x].isnull(), x] = 'undefined'\n        test_df.loc[test_df[x].isnull(), x] = 'undefined'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in cat_features:\n    le = LabelEncoder()\n    le.fit(list(train_df[x].astype(str).values) + list(test_df[x].astype(str).values))\n    train_df[x] = le.transform(list(train_df[x].astype(str).values))\n    test_df[x] = le.transform(list(test_df[x].astype(str).values)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data is unbalanced, hence we should initialize class weights\nclass_weights = [1, train_df.isFraud.value_counts()[0]/train_df.isFraud.value_counts()[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb = CatBoostClassifier(eval_metric='AUC',\\\n                        class_weights=class_weights,\\\n                        n_estimators=1500,\\\n                        random_seed=42,\\\n                        one_hot_max_size=10,\\\n                        silent=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training with cross-validation <a name=\"p-cv\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_scores = []\ni = 0\nfor train_index, val_index in skf.split(train_df[good_features].drop('isFraud', axis=1), train_df.isFraud):\n    X_train, X_val = train_df[good_features].drop('isFraud', axis=1).iloc[train_index], train_df[good_features].drop('isFraud', axis=1).iloc[val_index]\n    y_train, y_val = train_df.isFraud.iloc[train_index], train_df.isFraud.iloc[val_index]\n    cb.fit(X_train, y_train, cat_features=cat_features)\n    y_pred = cb.predict_proba(X_val)[:,1]\n    roc_auc = roc_auc_score(y_val, y_pred)\n    roc_auc_scores.append(roc_auc)\n    print('AUC in Fold #' + str(i) + ': ' + str(roc_auc))\n    i+=1\nprint('Mean AUC: ' + str(np.mean(roc_auc_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importances <a name=\"p-imp\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_dict = {'Features': cb.feature_names_, 'Importance': cb.feature_importances_}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp = pd.DataFrame(feature_dict).sort_values(by=['Importance'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\ndf_imp = feature_imp.head(20)\nsns.barplot(y=df_imp['Features'], x=df_imp['Importance'], palette='coolwarm_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission <a name=\"p-sub\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"cb.fit(train_df.drop('isFraud', axis=1), train_df.isFraud, cat_features=cat_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = cb.predict_proba(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission['isFraud'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}