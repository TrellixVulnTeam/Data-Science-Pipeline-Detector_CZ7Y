{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    # Loading\n    df_trans = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv', index_col='TransactionID')\n    df_test_trans = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv', index_col='TransactionID')\n\n    df_id = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv', index_col='TransactionID')\n    df_test_id = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv', index_col='TransactionID')\n    # Merging\n    df_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)\n    df_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True)\n    \n    return df_train,df_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test = load_data()\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reducing Memory Usage"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train = reduce_mem_usage(df_train)\n#df_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resumetable(df_trans)[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyze Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train dataset has {df_train.shape[0]} rows and {df_train.shape[1]} columns.')\nprint(f'Test dataset has {df_test.shape[0]} rows and {df_test.shape[1]} columns.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(df_train['isFraud'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#sel_features=['isFraud','TransactionDT','TransactionAmt']\n#features = sel_features+num_id+sel_cards\n# Selecting numeric columns in df_train\ndef stratified_sampling(input_df):\n    print(input_df.select_dtypes('number').columns)\n    sel_train = input_df.select_dtypes('number').columns.values\n    print(type(sel_train))\n\n    train = input_df[sel_train]\n    print(train.describe())\n    y = train['isFraud']\n    X = train\n    X.drop([\"isFraud\"],axis=1,inplace=True)\n    ### Train-test split with Stratification\n    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,  test_size=0.25)\n    return X_train, X_test, y_train, y_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def numeric_cols(input_df):\n    # Selecting numeric columns in df_train\n    print(input_df.select_dtypes('number').columns)\n    sel_train = input_df.select_dtypes('number').columns.values\n    print(type(sel_train))\n\n    train = input_df[sel_train]\n    print(train.describe())\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Returns list of categorical columns, and part of dataset with only categorical columns\ndef categorical_cols(input_df):\n    # Selecting numeric columns in df_train\n    print(input_df.select_dtypes('object').columns)\n    sel_train = input_df.select_dtypes('object').columns.values\n    #print(type(sel_train))\n\n    train = input_df[sel_train]\n    #print(train.describe())\n    return sel_train, train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encoding selected categorical columns, while leaving other columns as it is\nfrom sklearn.preprocessing import LabelEncoder\ndef label_encoding(sel_cat,inpX):\n    for col in sel_cat:\n        if col in inpX.columns:\n            le = LabelEncoder()\n            le.fit(list(inpX[col].astype(str).values))\n            inpX[col] = le.transform(list(inpX[col].astype(str).values))\n    return inpX\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#features = sel_features+num_id+sel_cards\n#train = df_train[features]\ndef balanced_sampling(input_df): \n    \n    train = numeric_cols(input_df)\n    y= train['isFraud']\n    # Selecting fraud and no fraud  \n    X_fraud= train[train.isFraud==1]\n    X_nofraud= train[train.isFraud==0]\n    total_fraud = X_fraud.shape\n    print(total_fraud,total_fraud[0])\n    \n    scale_factor = 3\n    X_nofraud1=X_nofraud.sample(scale_factor * total_fraud[0])\n    \n    X=pd.concat([X_fraud,X_nofraud1], ignore_index=True)\n    \n    y= X['isFraud']\n    print(X.shape)\n    print(X.sample(10))\n\n    #dropping isFraud column from X\n    X.drop([\"isFraud\"],axis=1,inplace=True)\n    \n    ### Train-test split with Stratification\n    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,  test_size=0.25)\n    return X_train, X_test, y_train, y_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(inp):\n# Filling 0.0 in place of NaN\n    inp.fillna(0.0, inplace=True)\n    inp.sample(10)\n    return inp ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndef scaling(unscaled_data):\n    #unscaled_data.reset_index()\n    ss = StandardScaler()\n    #preprocessing to remove NaN's\n    processed_data=preprocess(unscaled_data)\n    #scaling\n    scaled_data = ss.fit_transform(processed_data)\n    #print('Unscaled Data:\\n',X)\n    #print(\"Scaled Data :\\n\",scaled_data)\n    return scaled_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\ndef randomforest(inpX,inpy):\n    #Create a Gaussian Classifier\n    clf=RandomForestClassifier(n_estimators=500)\n\n    #Train the model using the training sets y_pred=clf.predict(X_test)\n    clf.fit(X_train,y_train)\n    return clf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Driver with scaling\n\n#### Step 1 : Load Data\n#### Step 2 : Balanced sampling with numeric columns\n#### Step 3 : Pre-Process\n#### Step 4 : Normalize\n#### Step 5 : Classify and validate\n#### Step 6 : Submission\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1 : Load Data\ndf_train,df_test = load_data()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2 : Balanced sampling with numeric columns\nX_train, X_test, y_train, y_test = balanced_sampling(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaledX_train = scaling(X_train)\nscaledX = pd.DataFrame(scaledX_train)\nscaledX.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = randomforest(scaledX,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaledX_test = scaling(X_test)\nscaledX_test = pd.DataFrame(scaledX_test)\ny_pred=clf.predict(scaledX_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup test data with numeric cols only\ntest = numeric_cols(df_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaledX_test = scaling(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use df_test with selected columns for final submission\ny_preds = clf.predict_proba(scaledX_test)[:,1] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')\nsample_submission['isFraud'] = y_preds\nsample_submission.to_csv('submission_scaled.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest without scaling with numeric columns only"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2 : Balanced sampling with numeric columns\nX_train, X_test, y_train, y_test = balanced_sampling(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_X =  preprocess(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = randomforest(processed_X,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_testX=preprocess(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=clf.predict(processed_testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\ndef eval2(y_test,y_pred):\n    # Model Accuracy, how often is the classifier correct?\n    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval2(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub2(inp,clf):\n    # Setup test data with numeric cols only\n    test = numeric_cols(inp)\n    processed_testX=preprocess(test)\n    #test = df_test[sel_train]\n    # Use df_test with selected columns for final submission\n    y_preds = clf.predict_proba(processed_testX)[:,1] \n    sample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')\n    sample_submission['isFraud'] = y_preds\n    sample_submission.to_csv('RandomForest_model.csv')\n    return 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub2(df_test, clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest without scaling with all columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1 : Load Data\ndf_train,df_test = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sel_cat,X = categorical_cols(df_train)\nX = pd.DataFrame(X)\nX.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select Categorical Columns\nsel_cat,X = categorical_cols(df_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sel_cat2,XX = categorical_cols(df_test)\ndf_test[sel_cat2].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode Catorical Columns in training dataset\ndf_train = label_encoding(sel_cat,df_train)\ndf_test = label_encoding(sel_cat2,df_test)\ndf_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.sample(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pre-process train and test datasets to remove NaNs\nprocessed_trainX =  preprocess(df_train)\nprocessed_testX = preprocess(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Balanced sampling with train-test split\nX_train, X_test, y_train, y_test = balanced_sampling(processed_trainX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification\nclf = randomforest(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction\ny_pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ndef eval2(y_test,y_pred):\n    # Model Accuracy, how often is the classifier correct?\n    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval2(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub3(inpt,clf):\n    y_preds = clf.predict_proba(processed_testX)[:,1] \n    sample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')\n    sample_submission['isFraud'] = y_preds\n    sample_submission.to_csv('RandomForest_3x.csv')\n    return 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub3(processed_testX,clf)\n#df_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \ndef performance_analysis(y_test,y_pred):\n    results = confusion_matrix(y_test, y_pred) \n    print('Confusion Matrix :')\n    print(results) \n    print('Accuracy Score :',accuracy_score(y_test, y_pred))\n    print ('Report : ')\n    print (classification_report(y_test, y_pred))\n    return\n\nperformance_analysis(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle competitions submit -c ieee-fraud-detection -f RandomForest_3x.csv -m \"Message\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}