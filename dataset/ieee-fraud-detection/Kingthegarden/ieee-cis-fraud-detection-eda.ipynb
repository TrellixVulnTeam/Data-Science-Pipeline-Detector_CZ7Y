{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Reference**\n\n* Introduction\n\n 1. https://www.kaggle.com/robikscube/ieee-fraud-detection-first-look-and-eda\n 2. https://www.kaggle.com/haataa/complete-eda-with-background-knowledge\n \n \n* EDA\n\n 1. https://www.kaggle.com/robikscube/ieee-fraud-detection-first-look-and-eda\n 2. https://www.kaggle.com/artgor/eda-and-models \n 3. https://www.kaggle.com/nroman/eda-for-cis-fraud-detection\n 4. https://www.kaggle.com/jesucristo/fraud-complete-eda\n 5. https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt\n 6. https://www.kaggle.com/rajeshcv/understanding-v-columns"},{"metadata":{},"cell_type":"markdown","source":"# **Introduction**\n\n* **Why We Should Care About Payment Fraud?**\n\nPayment card fraud is a serious and long-term threat to society with an economic impact forecast to be $416bn in 2017.\n\nBesides financial losses, it has been identified that criminal enterprises and Organised Crime Groups (OCGs) use payment card fraud to fund their activities including arms, drugs and terrorism. The activities of these criminals include violence and murder--individual acts of fraud have a human cost.\n\nFraud is increasing dramatically with the progression of modern technology and global communication. As a result, fighting fraud has become an important issue to be explored. As presented in the following figure, the detection and prevention mechanisms are used mostly to combat fraud.\n\n\n\n* **What is Fraud Detection ?**\n\nFraud detection tries to discover and identify fraudulent activities as they enter the systems and report them to a system administrator\n\n\n* **Credit card fraud detection**\n\nMostly, the strategy of credit card fraud detection is pattern recognition by analyzing user spending behavior automatically. Customer spending behavior contains information about the transaction amount, time gap since last purchase, day of the week, item category, customer address, etc. Anomaly based fraud detection is mostly used for credit card fraud detection system in which the cardholder's profile is made up by analyzing the cardholder spending behavior pattern. In doing so, any incoming transaction that is inconsistent with the cardholder's profile would be considered as suspicious\n\n\n* **From the competition overview**\n\nIn this competition, youâ€™ll benchmark machine learning models on a challenging large-scale dataset. The data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results."},{"metadata":{},"cell_type":"markdown","source":"# **EDA for CIS Fraud Detection**"},{"metadata":{},"cell_type":"markdown","source":"* **Data loading and overview**\n\n\nIn the competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\nData is separated into two datasets: information about the identity of the customer and transaction information. Not all transactions belong to identities, which are available. Maybe it would be possible to use additional transactions to generate new features."},{"metadata":{},"cell_type":"markdown","source":"1. **Import necessary librairies for EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")\nplt.style.use('ggplot')\ncolor_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. **Data road**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\ntest_transaction = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')\ntrain_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\ntest_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.shape, test_transaction.shape, train_identity.shape,  test_identity.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.info(), test_transaction.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test data and train data have **393 columns** excluding isFraud data. Based on the TransactionDT, the test data is assumed to have been created after the train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identity CSVs - These will be merged onto the transactions to create additional features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transaction.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All datasets have missing values, which are interpreted as common in the real world."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['TransactionID'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity['TransactionID'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transaction['TransactionID'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity['TransactionID'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reference**\n\nisin : https://3months.tistory.com/283 \\\nunique, value_counts : https://rfriend.tistory.com/267"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sum(train_transaction['TransactionID'].isin(train_identity['TransactionID'].unique())))\nprint(np.sum(test_transaction['TransactionID'].isin(test_identity['TransactionID'].unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"24.4% of TransactionIDs in train (144233 / 590540) have an associated train_identity.  \\\n28.0% of TransactionIDs in test (141907 / 506691) have an associated train_identity."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\n\nx = train_transaction['isFraud'].value_counts().index\ny = train_transaction['isFraud'].value_counts().values\n\ntrace2 = go.Bar(\n     x=x ,\n     y=y,\n     marker=dict(\n         color='blue',\n         colorscale = 'Viridis',\n         reversescale = True\n     ),\n     name=\"Imbalance\",    \n )\nlayout = dict(\n     title=\"Data imbalance - isFraud\",\n     width = 600, height = 400,\n     xaxis=go.layout.XAxis(\n     automargin=True),\n     yaxis=dict(\n         showgrid=False,\n         showline=False,\n         showticklabels=True,\n #         domain=[0, 0.85],\n     ), \n)\nfig1 = go.Figure(data=[trace2], layout=layout)\niplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, Most transaction data is non-fraud. Fraud transaction is 3.5%, which is unbalanced. Therefore, attention should be paid to overfitting problems during the analysis process."},{"metadata":{},"cell_type":"markdown","source":"* **Transaction DT**\n\nAccording to official time, TransactionDT feature is a timedelta from a given reference datetime, not a real time stamp. and Most people estimate the start time as December 1, 2017."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nstartdate = datetime.datetime.strptime('2017-12-01', '%Y-%m-%d')\ntrain['TransactionDT'] = train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\ntest['TransactionDT'] = test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reference**\n\nset_index : https://kongdols-room.tistory.com/123 \\\nresample : https://rfriend.tistory.com/494"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=axes, color='blue').set_ylabel('isFraud mean', fontsize=14);\naxes.set_title('Mean of isFraud by day', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(16, 6))\ntrain['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=axes, color='blue').set_xlabel('Date', fontsize=14);\ntest['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=axes, color='tab:orange').set_ylabel('Number of training examples', fontsize=14);\naxes.set_title('Number of training examples by day', fontsize=16);\naxes.legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\nax1.tick_params(axis='y', labelcolor='blue')\nax1.set_ylabel('isFraud mean', color='blue', fontsize=14)\nax2 = ax1.twinx()\ntrain['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=ax2, color='tab:orange');\nax2.tick_params(axis='y', labelcolor='tab:orange');\nax2.set_ylabel('Number of training examples', color='tab:orange', fontsize=14);\nax2.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = train.plot(x='TransactionDT',\n                       y='TransactionAmt',\n                       kind='scatter',\n                       alpha=0.01,\n                       label='TransactionAmt-train',\n                       title='Train and test Transaction Ammounts by Time (TransactionDT)',\n                       color='blue',\n                       ylim=(0, 5000),\n                       figsize=(15, 5))\ntest.plot(x='TransactionDT',\n                      y='TransactionAmt',\n                      kind='scatter',\n                      label='TransactionAmt-test',\n                      alpha=0.01,\n                      color='tab:orange',\n                       ylim=(0, 5000),\n                      ax=ax)\n\ntrain.loc[train_transaction['isFraud'] == 1] \\\n    .plot(x='TransactionDT',\n         y='TransactionAmt',\n         kind='scatter',\n         alpha=0.01,\n         label='TransactionAmt-train',\n         title='Train and test Transaction Ammounts by Time (TransactionDT)',\n         ylim=(0, 5000),\n         color='yellow',\n         figsize=(15, 5),\n         ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **TransactionAmt**\n\nData representing the amount of transactions. To avoid skwness of the transaction distribution, it is represented using log transformations Because of the log transfrom, any values between 0 and 1 will appear to be negative."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,6))\n\ntime_val = train['TransactionAmt'].values\n\nsns.distplot(time_val, ax=ax[0], color='blue')\nax[0].set_title('Distribution of TransactionAmt', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])\n\nsns.distplot(np.log(time_val), ax=ax[1], color='tab:orange')\nax[1].set_title('Distribution of LOG TransactionAmt', fontsize=14)\nax[1].set_xlim([min(np.log(time_val)), max(np.log(time_val))])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,6))\n\ntime_val = train_transaction.loc[train_transaction['isFraud'] == 1]['TransactionAmt'].values\n\nsns.distplot(np.log(time_val), ax=ax[0], color='blue')\nax[0].set_title('Distribution of LOG TransactionAmt, isFraud=1', fontsize=14)\nax[1].set_xlim([min(np.log(time_val)), max(np.log(time_val))])\n\ntime_val = train_transaction.loc[train_transaction['isFraud'] == 0]['TransactionAmt'].values\n\nsns.distplot(np.log(time_val), ax=ax[1], color='tab:orange')\nax[1].set_title('Distribution of LOG TransactionAmt, isFraud=0', fontsize=14)\nax[1].set_xlim([min(np.log(time_val)), max(np.log(time_val))])\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fraudulent charges appear to have a higher average transaction ammount"},{"metadata":{},"cell_type":"markdown","source":"* **ProductCD**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(20,5))\n\nsns.countplot(x=\"ProductCD\", ax=ax[0], hue = \"isFraud\", data=train)\nax[0].set_title('ProductCD train', fontsize=14)\nsns.countplot(x=\"ProductCD\", ax=ax[1], data=test)\nax[1].set_title('ProductCD test', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calcul(val):\n    X = train[train['ProductCD'] == val]['ProductCD'].value_counts()\n    Y = train[(train['ProductCD'] == val) & (train['isFraud'] == 1)]['ProductCD'].value_counts()\n    return np.around(Y/X * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calcul('W')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calcul('C')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For now we don't know exactly what these values represent.\n\nW has the most number of observations, S the least.\n\nProductCD C has the most fraud with >12%\n\nProductCD W has the least with ~2%"},{"metadata":{},"cell_type":"markdown","source":"* **Card**"},{"metadata":{},"cell_type":"markdown","source":"**card1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values do not exist in this data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card1'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.kdeplot(train[train['isFraud']==1]['card1'], label='isFraud 1', color = 'blue');\nsns.kdeplot(train[train['isFraud']==0]['card1'], label='isFraud 0', color = 'tab:orange');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, Card1 column is given as Categorical but it is behaving like Continuous Data. It has 13553 unique values."},{"metadata":{},"cell_type":"markdown","source":"**card2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card2'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card2'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.kdeplot(train[train['isFraud']==1]['card2'], label='isFraud 1', color = 'blue');\nsns.kdeplot(train[train['isFraud']==0]['card2'], label='isFraud 0', color = 'tab:orange');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**card3**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card3'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card3'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.kdeplot(train[train['isFraud']==1]['card3'], label='isFraud 1', color = 'blue');\nsns.kdeplot(train[train['isFraud']==0]['card3'], label='isFraud 0', color = 'tab:orange');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.card3.isin(train.card3.value_counts()[train.card3.value_counts() < 200].index), 'card3'] = \"Others\"\ntrain.loc[train.card5.isin(train.card5.value_counts()[train.card5.value_counts() < 300].index), 'card5'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in Card 3, as we have many values with low frequencies, I decided to set value to \"Others\". Also, in Card 3 I set the % of Fraud ratio in yaxis2\n"},{"metadata":{},"cell_type":"markdown","source":"**Reference**\n\ncrosstab : https://twinstarinfo.blogspot.com/2018/10/python-pandascrosstab.html \\\ntwinx : https://www.delftstack.com/ko/howto/matplotlib/how-to-add-y-axis-label-to-secondary-y-axis-in-matplotlib/"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = pd.crosstab(train['card3'], train['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\ntotal = len(train_transaction)\n\nplt.figure(figsize=(18, 6))\ng2 = sns.countplot(x = 'card3', data=train, order=list(tmp.card3.values))\ng22 = g2.twinx()\ngg2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n                    color='black', order=list(tmp.card3.values))\ngg2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng2.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng2.set_xlabel(\"Card 3 Values\", fontsize=18)\ng2.set_ylabel(\"Count\", fontsize=18)\nfor p in g2.patches:\n    height = p.get_height()\n    g2.text(p.get_x()+p.get_width()/2.,\n            height + 25,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\") \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In Card3 we can see that 150 and 185 are the most common values in the column.\nWe have 9.54% of Frauds in 185. The values with highest Fraud Transactions are 185, 119 and 144."},{"metadata":{},"cell_type":"markdown","source":"**card4**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card4'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card4'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(25,10))\n\nsns.countplot(x=\"card4\", ax=ax[0], data=train_transaction.loc[train_transaction['isFraud'] == 0])\nax[0].set_title('card4 isFraud=0', fontsize=14)\nsns.countplot(x=\"card4\", ax=ax[1], data=train_transaction.loc[train_transaction['isFraud'] == 1])\nax[1].set_title('card4 isFraud=1', fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most fraudulent transactions were detected on the visa card, with the least American express.\n"},{"metadata":{},"cell_type":"markdown","source":"**card5**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card5'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card5'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp2 = pd.crosstab(train['card5'], train['isFraud'], normalize='index') * 100\ntmp2 = tmp2.reset_index()\ntmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\ntotal = len(train_transaction)\n\nplt.figure(figsize=(18, 6))\ng3 = sns.countplot(x='card5', data=train, order=list(tmp2.card5.values))\ng3t = g3.twinx()\ng3t = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n                    color='black', order=list(tmp2.card5.values))\ng3t.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng3.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng3.set_xticklabels(g3.get_xticklabels(),rotation=90)\ng3.set_xlabel(\"Card 5 Values\", fontsize=18)\ng3.set_ylabel(\"Count\", fontsize=18)\nfor p in g3.patches:\n    height = p.get_height()\n    g3.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=11) \n    \nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In Card5 the most frequent values are 226, 224, 166 that represents 73% of data. Also is posible to see high % of frauds in 137, 147, 141 that has few entries for values."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card6'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['card6'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(25,10))\n\nsns.countplot(x=\"card6\", ax=ax[0], data=train_transaction.loc[train_transaction['isFraud'] == 0])\nax[0].set_title('card6 isFraud=0', fontsize=14)\nsns.countplot(x=\"card6\", ax=ax[1], data=train_transaction.loc[train_transaction['isFraud'] == 1])\nax[1].set_title('card6 isFraud=1', fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There were no fraudulent transaction data except debit and credit cards, and debit cards had more normal transactions than credit cards, but there were also more fraudulent transactions."},{"metadata":{},"cell_type":"markdown","source":"* **addr**\n\nAccording to the name of the feature we can assume that it contains some kind of users address, but in an encoded way. and The data description states that these are categorical even though they look numeric. "},{"metadata":{"trusted":true},"cell_type":"code","source":"addr_cols = [a for a in train.columns if 'addr' in a]\ntrain[addr_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['addr1'].plot(kind='hist',\n                                bins=50,\n                                figsize=(15, 2),\n                                title='addr1',\n                                color = 'blue')\nplt.show()\ntrain['addr2'].plot(kind='hist',\n                                bins=50,\n                                figsize=(15, 2),\n                                title='addr2',\n                                color = 'blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.addr1.isin(train.addr1.value_counts()[train.addr1.value_counts() <= 5000 ].index), 'addr1'] = \"Others\"\ntrain.loc[train.addr2.isin(train.addr2.value_counts()[train.addr2.value_counts() <= 50 ].index), 'addr2'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_amt = train.groupby(['isFraud'])['TransactionAmt'].sum().sum()\n\ndef ploting_cnt_amt(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    \n    plt.figure(figsize=(16,14))    \n    plt.suptitle(f'{col} Distributions ', fontsize=24)\n    \n    plt.subplot(211)\n    g = sns.countplot( x=col,  data=df, order=list(tmp[col].values))\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,tmp['Fraud'].max()*1.1)\n    gt.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n    g.set_title(f\"Most Frequent {col} values and % Fraud Transactions\", fontsize=20)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    sizes = []\n    for p in g.patches:\n        height = p.get_height()\n        sizes.append(height)\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=12) \n        \n    g.set_ylim(0,max(sizes)*1.15)\n    \n    #########################################################################\n    perc_amt = (df.groupby(['isFraud',col])['TransactionAmt'].sum() \\\n                / df.groupby([col])['TransactionAmt'].sum() * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    amt = df.groupby([col])['TransactionAmt'].sum().reset_index()\n    perc_amt = perc_amt.fillna(0)\n    plt.subplot(212)\n    g1 = sns.barplot(x=col, y='TransactionAmt', \n                       data=amt, \n                       order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, \n                        order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    g1.set_title(f\"{col} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n    g1.set_xticklabels(g.get_xticklabels(),rotation=45)    \n    \n    for p in g1.patches:\n        height = p.get_height()\n        g1.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total_amt*100),\n                ha=\"center\",fontsize=12) \n        \n    plt.subplots_adjust(hspace=.4, top = 0.9)\n    plt.show()\n    \nploting_cnt_amt(train, 'addr1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'addr2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all entries in Addr2 are in the same value.\nInterestingly in the value 65 , the percent of frauds are almost 60%\nAltought the value 87 has 88% of total entries, it has 96% of Total Transaction Amounts"},{"metadata":{},"cell_type":"markdown","source":"* **dist**\n\nPerhaps this could be the distance between the cardholder's home/work address and the transaction."},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_cols = [d for d in train.columns if 'dist' in d]\ntrain[dist_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['dist1'].isna().sum(), train['dist2'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen that dist1-2 contains many missing values.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['dist1'].plot(kind='hist',\n                                bins=5000,\n                                figsize=(15, 2),\n                                title='dist1 distribution',\n                                color='blue',\n                                logx=True)\nplt.show()\ntrain['dist2'].plot(kind='hist',\n                                bins=5000,\n                                figsize=(15, 2),\n                                title='dist2 distribution',\n                                color= 'blue',\n                                logx=True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use logx to plot the distribution better."},{"metadata":{},"cell_type":"markdown","source":"* **emaildomain**"},{"metadata":{},"cell_type":"markdown","source":"**P emaildomain**\n\nI will group all e-mail domains by the respective enterprises.\nAlso, I will set as \"Others\" all values with less than 500 entries."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\ntrain.loc[train['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ntrain.loc[train['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\ntrain.loc[train.P_emaildomain.isin(train.P_emaildomain\\\n                                         .value_counts()[train.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\ntrain.P_emaildomain.fillna(\"NoInf\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'P_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distributions**\n\nI will group all e-mail domains by the respective enterprises.\nI will set as \"Others\" all values with less than 300 entries."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\ntrain.loc[train['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\ntrain.loc[train['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                             'outlook.es', 'live.com', 'live.fr',\n                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\ntrain.loc[train.R_emaildomain.isin(train.R_emaildomain\\\n                                         .value_counts()[train.R_emaildomain.value_counts() <= 300 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\ntrain.R_emaildomain.fillna(\"NoInf\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'R_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most transactions were made through gmail, and fraudulent transaction detection was also the most common in gmail. What's unusual is that iCloud has a high value."},{"metadata":{},"cell_type":"markdown","source":"* **C1~C14**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\ndef resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_cols = [c for c in train if c[0] == 'C']\ntrain[c_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(train[c_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[c_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.C1.isin(train.C1\\\n                              .value_counts()[train.C1.value_counts() <= 400 ]\\\n                              .index), 'C1'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'C1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.C2.isin(train.C2\\\n                              .value_counts()[train.C2.value_counts() <= 350 ]\\\n                              .index), 'C2'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'C2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.C4.isin(train.C4\\\n                              .value_counts()[train.C4.value_counts() <= 400 ]\\\n                              .index), 'C4'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'C4')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **D1~D5**"},{"metadata":{"trusted":true},"cell_type":"code","source":"d_cols = [c for c in train if (c[0] == 'D') and (c[1] != 'e')]\ntrain[d_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(train[d_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[d_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['D1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.D1.isin(train.D1.value_counts()[train.D1.value_counts() <= 2000 ].index), 'D1'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'D1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.D2.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.D2.isin(train.D2.value_counts()[train.D2.value_counts() <= 2000 ].index), 'D2'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'D2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.D8.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.D8.isin(train.D8.value_counts()[train.D8.value_counts() <= 250 ].index), 'D8'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'D8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['D8'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **M1~M9**"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_cols = [c for c in train if c[0] == 'M']\ntrain[m_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(train[m_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[m_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is the value of T, F, or NaN except for M4."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.M1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.M4.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reference**\n\nsubplots_adjust : https://www.delftstack.com/ko/howto/matplotlib/how-to-improve-subplot-size-or-spacing-with-many-subplots-in-matplotlib/"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in m_cols:\n    train[col] = train[col].fillna(\"Miss\")\n    \ndef ploting_dist_ratio(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(20,5))\n    plt.suptitle(f'{col} Distributions ', fontsize=22)\n\n    plt.subplot(121)\n    g = sns.countplot(x=col, data=df, order=list(tmp[col].values))\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n    g.set_title(f\"{col} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n    g.set_ylim(0,400000)\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,20)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    for p in gt.patches:\n        height = p.get_height()\n        gt.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=14) \n        \n    perc_amt = (train.groupby(['isFraud',col])['TransactionAmt'].sum() / total_amt * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.subplot(122)\n    g1 = sns.boxplot(x=col, y='TransactionAmt', hue='isFraud', \n                     data=df[df['TransactionAmt'] <= lim], order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,5)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g1.set_title(f\"{col} by Transactions dist\", fontsize=18)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n        \n    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since many NaN values exist, we visualize them by replacing them with Miss."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in m_cols:\n    ploting_dist_ratio(train, col, lim=2500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Except for M4, the remaining M values show a high fraud detection rate in missing values."},{"metadata":{},"cell_type":"markdown","source":"* **V1~V339**\n\nEach of the 339 V columns has a low importance and is usually eliminated. To make V columns more useful, understand this column."},{"metadata":{"trusted":true},"cell_type":"code","source":"v_cols = [c for c in train if c[0] == 'V']\ntrain[v_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(train[v_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[v_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train.isFraud[train.isFraud==1])/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper functions\n# 1. For calculating % na values in  columns\ndef percent_na(df):\n    percent_missing = df.isnull().sum() * 100 / len(df)\n    missing_value_df = pd.DataFrame({'column_groups': percent_missing.index,\n                                 'percent_missing': percent_missing.values})\n    return missing_value_df\n# 2. For plotting grouped histograms \ndef sephist(col):\n    yes = train_transaction[train_transaction['isFraud'] == 1][col]\n    no = train_transaction[train_transaction['isFraud'] == 0][col]\n    return yes, no","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first grouping is based on the percentage of missing values in the columns . The columns can be divided into 15 groups as below."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_colwidth =300\nVcols=train_transaction.columns[train_transaction.columns.str.startswith('V')]\ntrain_transaction_vcol_na = percent_na(train_transaction[Vcols])\ntrain_transaction_vcol_na_group= train_transaction_vcol_na.groupby('percent_missing')['column_groups'].unique().reset_index()\nnum_values_per =[]\nfor i in range(len(train_transaction_vcol_na_group)):\n    num_values_per.append(len(train_transaction_vcol_na_group['column_groups'][i]))\ntrain_transaction_vcol_na_group['num_columns_group'] = num_values_per\ntrain_transaction_vcol_na_group","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_colwidth =300\nVcols=test_transaction.columns[test_transaction.columns.str.startswith('V')]\ntest_transaction_vcol_na = percent_na(test_transaction[Vcols])\ntest_transaction_vcol_na_group= test_transaction_vcol_na.groupby('percent_missing')['column_groups'].unique().reset_index()\nnum_values_per =[]\nfor i in range(len(test_transaction_vcol_na_group)):\n    num_values_per.append(len(test_transaction_vcol_na_group['column_groups'][i]))\ntest_transaction_vcol_na_group['num_columns_group'] = num_values_per\ntest_transaction_vcol_na_group","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at how each V column creates 96.5% of the data in a non-fraud transaction ratio."},{"metadata":{"trusted":true},"cell_type":"code","source":"def column_value_freq(sel_col,cum_per):\n    dfpercount = pd.DataFrame(columns=['col_name','num_values_'+str(round(cum_per,2))])\n    for col in sel_col:\n        col_value = train_transaction[col].value_counts(normalize=True)\n        colpercount = pd.DataFrame({'value' : col_value.index,'per_count' : col_value.values})\n        colpercount['cum_per_count'] = colpercount['per_count'].cumsum()\n        if len(colpercount.loc[colpercount['cum_per_count'] < cum_per,] ) < 2:\n            num_col_99 = len(colpercount.loc[colpercount['per_count'] > (1- cum_per),])\n        else:\n            num_col_99 = len(colpercount.loc[colpercount['cum_per_count']< cum_per,] )\n        dfpercount=dfpercount.append({'col_name': col,'num_values_'+str(round(cum_per,2)): num_col_99},ignore_index = True)\n    dfpercount['unique_values'] = train_transaction[sel_col].nunique().values\n    dfpercount['unique_value_to_num_values'+str(round(cum_per,2))+'_ratio'] = 100 * (dfpercount['num_values_'+str(round(cum_per,2))]/dfpercount.unique_values)\n    dfpercount['percent_missing'] = percent_na(train_transaction[sel_col])['percent_missing'].round(3).values\n    return dfpercount\n\ndef column_value_details(sel_col,cum_per):\n    dfpercount = pd.DataFrame(columns=['col_name','values_'+str(round(cum_per,2)),'values_'+str(round(1-cum_per,2))])\n    for col in sel_col:\n        col_value = train_transaction[col].value_counts(normalize=True)\n        colpercount = pd.DataFrame({'value' : col_value.index,'per_count' : col_value.values})\n        colpercount['cum_per_count'] = colpercount['per_count'].cumsum()\n        if len(colpercount.loc[colpercount['cum_per_count'] < cum_per,] ) < 2:\n            values_freq = colpercount.loc[colpercount['per_count'] > (1- cum_per),'value'].tolist()\n        else:\n            values_freq = colpercount.loc[colpercount['cum_per_count']< cum_per,'value'].tolist() \n        values_less_freq =  [item for item in colpercount['value'] if item not in values_freq]\n        dfpercount=dfpercount.append({'col_name': col,'values_'+str(round(cum_per,2)) : values_freq ,'values_'+str(round(1-cum_per,2)): values_less_freq},ignore_index = True)\n    num_values_per =[]\n    for i in range(len(dfpercount)):\n        num_values_per.append(len(dfpercount['values_'+str(round(cum_per,2))][i]))\n    dfpercount['num_values_per'] = num_values_per\n    return dfpercount","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vcol_multiplot(col,cum_per,ax1):\n    col_freq = column_value_freq(col,cum_per)      \n    plot1=col_freq.plot(x='col_name',y=['unique_values','num_values_'+str(round(cum_per,2))],kind='bar',rot=90,ax = ax1)\n    for p in plot1.patches[1:]:\n        h = p.get_height()\n        x = p.get_x()+p.get_width()/2.\n        if h != 0:\n            plot1.annotate(\"%g\" % p.get_height(), xy=(x,h), xytext=(0,4), rotation=90, \n                   textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n    plot1.set(ylabel='Count')\n    plot1= plot1.set(title='Data Details  in each V columns with ' + str(round(col_freq.percent_missing.mean(),4)) +'% missing values')\n    \ndef vcol_plot(col,cum_per):\n    col_freq = column_value_freq(col,cum_per)      \n    plot1=col_freq.plot(x='col_name',y=['unique_values','num_values_'+str(round(cum_per,2))],kind='bar',rot=90)\n    for p in plot1.patches[1:]:\n        h = p.get_height()\n        x = p.get_x()+p.get_width()/2.\n        if h != 0:\n            plot1.annotate(\"%g\" % p.get_height(), xy=(x,h), xytext=(0,4), rotation=90, \n                   textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n    plot1.set(ylabel='Count')\n    plot1= plot1.set(title='Data Details  in each V columns with ' + str(round(col_freq.percent_missing.mean(),4)) +'% missing values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cum_per = 0.965\nfig, axs = plt.subplots(2,1, figsize=(15, 16), facecolor='w', edgecolor='k',squeeze=False)\naxs=axs.ravel()\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[0],cum_per,axs[0])\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[1],cum_per,axs[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(4,2, figsize=(15,16), facecolor='w', edgecolor='k',squeeze=False)\n#fig.subplots_adjust(hspace = 0.75, wspace=.001)\naxs = axs.ravel()\nfor i in range(2,10):\n    vcol_multiplot(train_transaction_vcol_na_group.column_groups[i],cum_per,axs[i-2])\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(5,1, figsize=(15,16), facecolor='w', edgecolor='k',squeeze=False)\naxs=axs.ravel()\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[10],cum_per,axs[0])\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[11],cum_per,axs[1])\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[12],cum_per,axs[2])\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[13],cum_per,axs[3])\nvcol_multiplot(train_transaction_vcol_na_group.column_groups[14],cum_per,axs[4])\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the data distribution columns can be divided into 5 types.\n\n 1. **Boolean** - columns with only two unique values\n\n 2. **Pseudo- Boolean** - columns with 96.5% data covered by maximum two unique values. Within this there are two types.\n \n    Pseudo-Boolean-categorical - Columns with 15 or less unique values but 96.5% data covered by  maximum two unique values\\\n    Pseudo-Boolean-numerical - Columns with more than 15 unique values but 96.5% data covered by  maximum two unique values\n    \n 3. **Pseudo-Categorical** - Columns with 96.5% data covered by 15 or less unique values\n\n 4. **Numerical** - All Other columns"},{"metadata":{},"cell_type":"markdown","source":"**Boolean Columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"colfreq=column_value_freq(Vcols,cum_per)\ncolfreqbool = colfreq[colfreq.unique_values==2]\nif len(colfreqbool)%3 == 0:\n    nrow = len(colfreqbool)/3\nelse:\n    nrow = len(colfreqbool) // 3 + 1 \nsns.set(rc={'figure.figsize':(14,16)})\nfor num, alpha in enumerate(colfreqbool.col_name):\n    plt.subplot(nrow, 3, num+1)\n    plot1= sns.countplot(data=train_transaction,x=alpha,hue='isFraud')\n    for p in plot1.patches[1:]:\n        h = p.get_height()\n        x = p.get_x()+p.get_width()/2.\n        if h != 0:\n            plot1.annotate(\"%g\" % p.get_height(), xy=(x,h), xytext=(0,4), rotation=90, \n                   textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n    plt.legend(title='isFraud',loc='upper right')\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the exception of V305, it has values of 0 and 1, with most values of 1."},{"metadata":{},"cell_type":"markdown","source":"**Pseudo Booleans**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cum_value_count(col):\n    col_value = train_transaction[col].value_counts(normalize=True)\n    colpercount = pd.DataFrame({'value' : col_value.index,'per_count' : col_value.values})\n    colpercount['cum_per_count'] = colpercount['per_count'].cumsum()\n    return colpercount","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def V_doublecat_plot(cols,cum_per,limit):\n    Vcol_details=column_value_details(cols,cum_per)\n    V_cat = Vcol_details[Vcol_details['num_values_per'] <= limit].reset_index()\n    sns.set(rc={'figure.figsize':(14,len(V_cat)*2)})\n    x=1\n    for num, alpha in enumerate(V_cat.col_name):\n        plt.subplot(len(V_cat),2,x)\n        sns.countplot(data=train_transaction[train_transaction[alpha].isin (V_cat['values_'+str(round(cum_per,2))][num])],y=alpha,hue='isFraud')\n        plt.legend(loc='lower right')\n        plt.title('Count of unique values which make '+str(round(cum_per*100,3))+'% of data in column ' + str(alpha) )\n        plt.subplot(len(V_cat),2,x+1)\n        sns.countplot(data=train_transaction[train_transaction[alpha].isin (V_cat['values_'+str(round(1-cum_per,2))][num])],y=alpha,hue='isFraud')\n        plt.legend(loc='lower right')\n        plt.title('Count of unique values which make only '+str(round((1-cum_per)*100,3))+'% of data in column ' + str(alpha) )\n        x= x+2\n    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def V_cat_plot(cols,cum_per,limit):\n    Vcol_details=column_value_details(cols,cum_per)\n    V_cat = Vcol_details[Vcol_details['num_values_per'] <= limit].reset_index()\n    sns.set(rc={'figure.figsize':(14,len(V_cat)*2)})\n    x=1\n    for num, alpha in enumerate(V_cat.col_name):\n        plt.subplot(len(V_cat),2,x)\n        sns.countplot(data=train_transaction[train_transaction[alpha].isin (V_cat['values_'+str(round(cum_per,2))][num])],y=alpha,hue='isFraud')\n        plt.legend(loc='lower right')\n        plt.title('Count of unique values which make '+str(round(cum_per*100,3))+'% of data in column ' + str(alpha) )\n        plt.subplot(len(V_cat),2,x+1)\n        yes = train_transaction[(train_transaction['isFraud'] == 1) & (train_transaction[alpha].isin (V_cat['values_'+str(round(1-cum_per,2))][num]))][alpha]\n        no = train_transaction[(train_transaction['isFraud'] == 0) & (train_transaction[alpha].isin (V_cat['values_'+str(round(1-cum_per,2))][num]))][alpha]\n        plt.hist(yes, alpha=0.75, label='Fraud', color='r')\n        plt.hist(no, alpha=0.25, label='Not Fraud', color='g')\n        plt.legend(loc='upper right')\n        plt.title('Histogram of values which make '+str(round((1-cum_per)*100,3))+'% of data in column ' + str(alpha) )\n        x= x+2\n    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def V_num_plot(cols,cum_per,limit):\n    Vcol_details=column_value_details(cols,cum_per)\n    V_num = Vcol_details[Vcol_details['num_values_per'] > limit].reset_index()\n    sns.set(rc={'figure.figsize':(14,len(V_num)*2)})\n    x=1\n    for num, alpha in enumerate(V_num.col_name):\n        plt.subplot(len(V_num),2,x)\n        yes = train_transaction[(train_transaction['isFraud'] == 1) & (train_transaction[alpha].isin (V_num['values_'+str(round(cum_per,2))][num]))][alpha]\n        no = train_transaction[(train_transaction['isFraud'] == 0) & (train_transaction[alpha].isin (V_num['values_'+str(round(cum_per,2))][num]))][alpha]\n        plt.hist(yes, alpha=0.75, label='Fraud', color='r')\n        plt.hist(no, alpha=0.25, label='Not Fraud', color='g')\n        plt.legend(loc='upper right')\n        plt.title('Histogram of  values which make '+str(round(cum_per*100,3))+'% of data in column ' + str(alpha) )\n        plt.subplot(len(V_num),2,x+1)\n        yes = train_transaction[(train_transaction['isFraud'] == 1) & (train_transaction[alpha].isin (V_num['values_'+str(round(1-cum_per,2))][num]))][alpha]\n        no = train_transaction[(train_transaction['isFraud'] == 0) & (train_transaction[alpha].isin (V_num['values_'+str(round(1-cum_per,2))][num]))][alpha]\n        plt.hist(yes, alpha=0.75, label='Fraud', color='r')\n        plt.hist(no, alpha=0.25, label='Not Fraud', color='g')\n        plt.legend(loc='upper right')\n        plt.title('Histogram of values which make '+str(round((1-cum_per)*100,3))+'% of data in column ' + str(alpha) )\n        x= x+2\n    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colfreqpseudobool = colfreq[(colfreq.unique_values !=2) & (colfreq['num_values_'+str(round(cum_per,2))] <= 2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pseudoboolcat = colfreqpseudobool[colfreqpseudobool.unique_values <=15]['col_name'].values\nV_doublecat_plot(pseudoboolcat,cum_per,15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen that some unique values belong to 3.5%."},{"metadata":{"trusted":true},"cell_type":"code","source":"pseudoboolnum = colfreqpseudobool[colfreqpseudobool.unique_values >15]['col_name'].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V_cat_plot(pseudoboolnum,cum_per,15)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The histograms of values less than 3.5% of the column data shows a higher proportion of fraud transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"colfreqcat = colfreq[(colfreq.unique_values <=15) & (colfreq['num_values_'+str(round(cum_per,2))] > 2)]\ncolfreqcat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colfreqpseudocat = colfreq[(colfreq.unique_values >15) & (colfreq['num_values_'+str(round(cum_per,2))] <= 15) & (colfreq['num_values_'+str(round(cum_per,2))]> 2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V_cat_plot(colfreqpseudocat.col_name,cum_per,15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In some of these columns a higher proportion of fraud cases are seen for values which form less than 3.5% of the column data"},{"metadata":{"trusted":true},"cell_type":"code","source":"colfreqnum = colfreq[colfreq['num_values_'+str(round(cum_per,2))]>15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"V_num_plot(colfreqnum.col_name,cum_per,15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like the Pseudo Boolean and Pseudo Categorical columns are important as in both tpes there is a higher proportion of fraud cases when the values fall with less than 3.5% of column data unique values"},{"metadata":{},"cell_type":"markdown","source":"* **id_1 ~ id_38**\n\nid data including customer ID information.\n\n  * Categorical Features\n  * DeviceType\n  * DeviceInfo\n  * id_12 - id_38"},{"metadata":{},"cell_type":"markdown","source":"**DeviceType**"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_cols = [c for c in train if c[0] == 'i']\ntrain[id_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[id_cols].describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('DeviceType') \\\n    .mean()['isFraud'] \\\n    .sort_values() \\\n    .plot(kind='barh',\n          figsize=(15, 5),\n          title='Percentage of Fraud by Device Type')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('DeviceInfo') \\\n    .count()['TransactionID'] \\\n    .sort_values(ascending=False) \\\n    .head(20) \\\n    .plot(kind='barh', figsize=(15, 5), title='Top 20 Devices in Train')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ploting columns with few unique id values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cat_feat_ploting(df, col):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(14,10))\n    plt.suptitle(f'{col} Distributions', fontsize=22)\n\n    plt.subplot(221)\n    g = sns.countplot(x=col, data=df, order=tmp[col].values)\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\n    g.set_title(f\"{col} Distribution\", fontsize=19)\n    g.set_xlabel(f\"{col} Name\", fontsize=17)\n    g.set_ylabel(\"Count\", fontsize=17)\n    # g.set_ylim(0,500000)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\", fontsize=14) \n\n    plt.subplot(222)\n    g1 = sns.countplot(x=col, hue='isFraud', data=df, order=tmp[col].values)\n    plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n    gt = g1.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, color='black', order=tmp[col].values, legend=False)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\n    g1.set_title(f\"{col} by Target(isFraud)\", fontsize=19)\n    g1.set_xlabel(f\"{col} Name\", fontsize=17)\n    g1.set_ylabel(\"Count\", fontsize=17)\n\n    plt.subplot(212)\n    g3 = sns.boxenplot(x=col, y='TransactionAmt', hue='isFraud', \n                       data=df[df['TransactionAmt'] <= 2000], order=tmp[col].values )\n    g3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\n    g3.set_xlabel(\"ProductCD Name\", fontsize=17)\n    g3.set_ylabel(\"Transaction Values\", fontsize=17)\n\n    plt.subplots_adjust(hspace = 0.4, top = 0.85)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29']:\n    train[col] = train[col].fillna('NaN')\n    cat_feat_ploting(train, col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**id_30**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\ntrain.loc[train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\ntrain.loc[train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\ntrain.loc[train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\ntrain['id_30'].fillna(\"NaN\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'id_30')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**id_31**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\ntrain.loc[train['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\ntrain.loc[train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\ntrain.loc[train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\ntrain.loc[train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\ntrain.loc[train['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\ntrain.loc[train['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\ntrain['id_31'].fillna(\"NaN\", inplace=True)\ntrain.loc[train.id_31.isin(train.id_31.value_counts()[train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(train, 'id_31')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['id_31']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}