{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_feat_imps=pd.read_csv('../input/feature-selection-ieee/Null_imp.csv')\nactual_feat_imp=pd.read_csv('../input/feature-selection-ieee/Actual_imp.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity=pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\n# test_identity=pd.read_csv('../input/test_identity.csv')\ntrain_transaction=pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\n# test_transaction=pd.read_csv('../input/test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.merge(train_transaction,train_identity,how='left',on='TransactionID')\n# test=pd.merge(test_transaction,test_identity,how='left',on='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity,train_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=train['isFraud']\ntrain=train.drop(['isFraud','TransactionID'],axis=1)\n# test=test.drop('TransactionID',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain,val,target,val_y=train_test_split(train,target,test_size=0.5,random_state=5,stratify=target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del val,val_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.fillna(-999)\n# test=test.fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ncat_cols=[col for col in train.columns if train[col].dtype=='object']\nfor col in cat_cols:\n    le=LabelEncoder()\n    le.fit(list(train[col].values))\n    train[col]=le.transform(list(train[col].values))\n#     test[col]=le.transform(list(test[col].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n# WARNING! THIS CAN DAMAGE THE DATA \ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=reduce_mem_usage(train)\n# test=reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"correlation_scores=[]\n\nfor feature in train.columns:\n    null_imp=null_feat_imps[null_feat_imps['features']==feature]['importances'].values\n    actual_imp=actual_feat_imp[actual_feat_imp['features']==feature]['importances'].values\n    corr_score=100*(null_imp < actual_imp).sum()/null_imp.size\n    correlation_scores.append((feature,corr_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_df=pd.DataFrame(correlation_scores,columns=['Feature','Score']).sort_values('Score',ascending=False).reset_index(drop=True)\nplt.figure(figsize=(10,10))\nsns.barplot(x='Score',y='Feature',data=correlation_df.iloc[:50,:])\nplt.title('Scores of all features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_distdf=[]\n\nfor feature in actual_feat_imp['features'].values:\n    dist=np.abs(actual_feat_imp[actual_feat_imp['features']==feature]['importances'].values - np.mean(null_feat_imps[null_feat_imps['features']==feature]['importances'].values))\n    feature_distdf.append((feature,dist[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_df=pd.DataFrame(feature_distdf,columns=['Feature','Distance_from_Mean']).sort_values('Distance_from_Mean',ascending=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.barplot(x='Distance_from_Mean',y='Feature',data=feature_df[:50])\nplt.title('Distance of Actual Importance from Mean of Null Importances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_selection_score(data=train,target=target):\n    xgb_params=dict(\n                    verbosity=0,\n                    tree_method='gpu_hist',\n                    colsample_bytree=0.8,\n               subsample=0.8,\n               learning_rate=0.05,\n               max_depth=5,\n                   objective='binary:logistic',\n                   metric='auc')\n    \n    train_d=xgb.DMatrix(data,label=target)\n    result=xgb.cv(xgb_params,train_d,num_boost_round=1000,nfold=3,stratified=True,shuffle=True,early_stopping_rounds=50,verbose_eval=0,\n                 seed=5,metrics=('auc'))\n    \n    \n    return (list(result['test-auc-mean'].values)[-1], list(result['test-auc-std'].values)[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for threshold in [0, 10, 20, 30 , 40, 50 ,60 , 70, 80 , 90, 95, 99]:  \n#     print('Result for threshold ',threshold)\n#     worthy_features=[feature for feature in correlation_df['Feature'].values if correlation_df.loc[correlation_df['Feature']==feature,'Score'].values>=threshold]\n#     score=get_selection_score(train[worthy_features],target)\n#     print('Test AUC Mean :',score[0])\n#     print('Test AUC Std:',score[1])\n#     del score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for threshold in [0,0.0001,0.0003,0.0005,0.0008,0.001,0.003,0.005,0.008,0.01,0.015,0.025,0.05]:  \n    print('Result for threshold ',threshold)\n    worthy_features=[feature for feature in feature_df['Feature'].values if feature_df.loc[feature_df['Feature']==feature,'Distance_from_Mean'].values>=threshold]\n    score=get_selection_score(train[worthy_features],target)\n    print('Test AUC Mean :',score[0])\n    print('Test AUC Std:',score[1])\n    del score","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}