{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom datetime import datetime\nimport os\nimport time\nfrom datetime import datetime\nimport pandas as pd\nimport random\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, recall_score, precision_score, average_precision_score, precision_recall_curve\nfrom imblearn.under_sampling import TomekLinks, NearMiss, RandomUnderSampler\nfrom sklearn import tree\nimport sklearn.metrics as metric\nfrom imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\nfrom tabulate import tabulate\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\nfrom warnings import simplefilter\nfrom sklearn.metrics import roc_curve, roc_auc_score\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud = df[df[\"isFraud\"] == 1]\nnonfraud = df[df[\"isFraud\"] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average of frauds: \\n\",fraud.TransactionAmt.mean())\nprint(\"Average of nonfrauds: \\n\", nonfraud.TransactionAmt.mean())\nprint(\"Maximum frauds: \\n\",fraud.TransactionAmt.max())\nprint(\"Minimum frauds: \\n\",fraud.TransactionAmt.min())\nprint(\"Maximum nonfrauds: \\n\", nonfraud.TransactionAmt.max())\nprint(\"Minimum nonfrauds: \\n\", nonfraud.TransactionAmt.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catFeatures=['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1',\t'M2',\t'M3',\t'M4',\t'M5',\t'M6',\t'M7',\t'M8',\t'M9', 'C1','V12','V13','V14','V15','V16']\n\nnumFeatures=list(df)\nfor x in catFeatures:\n  numFeatures.remove(x)\n\nnumFeatures.remove('isFraud')\ndf['isFraud'] = df['isFraud'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for catFeatures_val in catFeatures:\n    f, ax = plt.subplots(1, 2, figsize=(10, 5))\n    colors=['red', 'orange', 'yellow', 'green', 'blue', 'pink']\n    (df[catFeatures_val].value_counts().head(6)).plot(kind='bar', title=catFeatures_val,  ax=ax[0], color=colors)\n    ((fraud[catFeatures_val].value_counts()*100/df[catFeatures_val].count()).head(6)).plot(kind='barh', title='Percent of frauds', ax=ax[1],color=colors)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missings = df.isnull().sum()\nall_data = np.product(df.shape)\nall_missings = missings.sum()\nprint (\"Percent of missings \",(all_missings/all_data) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"('Percent of frauds:', (len(fraud)/len(df))*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"legend = df['isFraud'].replace({0: \"Nonfraud\", 1: \"Fraud\"})\ncolors=['green', 'red']\n(legend.value_counts().head(6)).plot(kind='barh', title=('Number of transactions'), color=colors,figsize=(20, 5), )\ndel legend","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Variable transformation and prepare data to training</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"hours = df['TransactionDT'] / (3600) #Preparation of a variable showing hours based on variable TransactionDT\nhours_ = np.floor(hours) % 24\ndf['hours'] = hours_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missings = [df[col].isnull().sum() / df.shape[0] for col in df.columns] #Delete columns with 50% of missings values\ncols_to_out = [df.columns[i] for i in range(df.shape[1]) if missings[i] > 0.5]\ndf = df.drop(cols_to_out, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identical = [c for c in df.columns if df[c].value_counts(normalize=True).values[0] > 0.9] #Delete columns with 90% the same values\nthrow_away = identical\nthrow_away.remove('isFraud')\ndf = df.drop(throw_away, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['TransactionID', 'TransactionDT'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndf.head(10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before transformations: ') #Reduction number of categories in P_emaildomain\nprint('Number of lvls P_emaildomain : ',len(df['P_emaildomain'].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['P_emaildomain'].replace({'aim.com' :  'other' ,\n 'anonymous.com' :  'anonymous' ,\n 'aol.com' :  'aol' ,\n 'att.net' :  'other' ,\n 'bellsouth.net' :  'other' ,\n 'cableone.net' :  'other' ,\n 'centurylink.net' :  'other' ,\n 'cfl.rr.com' :  'other' ,\n 'charter.net' :  'other' ,\n 'comcast.net' :  'other' ,\n 'cox.net' :  'other' ,\n 'earthlink.net' :  'other' ,\n 'embarqmail.com' :  'other' ,\n 'frontier.com' :  'frontier' ,\n 'frontiernet.net' :  'frontier' ,\n 'gmail' :  'gmail' ,\n 'gmail.com' :  'gmail' ,\n 'gmx.de' :  'other' ,\n 'hotmail.co.uk' :  'hotmail' ,\n 'hotmail.com' :  'hotmail' ,\n 'hotmail.de' :  'hotmail' ,\n 'hotmail.es' :  'hotmail' ,\n 'hotmail.fr' :  'hotmail' ,\n 'icloud.com' :  'other' ,\n 'juno.com' :  'other' ,\n 'live.com' :  'live' ,\n 'live.com.mx' :  'live' ,\n 'live.fr' :  'live' ,\n 'mac.com' :  'other' ,\n 'mail.com' :  'other' ,\n 'me.com' :  'other' ,\n 'msn.com' :  'msn' ,\n 'netzero.com' :  'netzero' ,\n 'netzero.net' :  'netzero' ,\n 'optonline.net' :  'other' ,\n 'outlook.com' :  'outlook' ,\n 'outlook.es' :  'outlook' ,\n 'prodigy.net.mx' :  'other' ,\n 'protonmail.com' :  'other' ,\n 'ptd.net' :  'other' ,\n 'q.com' :  'other' ,\n 'roadrunner.com' :  'other' ,\n 'rocketmail.com' :  'other' ,\n 'sbcglobal.net' :  'other' ,\n 'sc.rr.com' :  'other' ,\n 'servicios-ta.com' :  'other' ,\n 'suddenlink.net' :  'other' ,\n 'twc.com' :  'other' ,\n 'verizon.net' :  'other' ,\n 'web.de' :  'other' ,\n 'windstream.net' :  'other' ,\n 'yahoo.co.jp' :  'yahoo' ,\n 'yahoo.co.uk' :  'yahoo' ,\n 'yahoo.com' :  'yahoo' ,\n 'yahoo.com.mx' :  'yahoo' ,\n 'yahoo.de' :  'yahoo' ,\n 'yahoo.es' :  'yahoo' ,\n 'yahoo.fr' :  'yahoo' ,\n 'ymail.com' :  'other' ,},inplace=True)\nprint('After transformations: ')\nprint('Number of lvls P_emaildomain : ',len(df['P_emaildomain'].value_counts()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catFeatures=['ProductCD', 'card4', 'card6', 'P_emaildomain',\t'M2',\t'M3',\t'M4','M6', 'C1','V12','V13','V15','V16']\n\nnumFeatures=list(df)\ntry:\n    \n    for x in catFeatures:\n      numFeatures.remove(x)\nexcept:\n    pass\n\nnumFeatures.remove('isFraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(-999, inplace=True)\nfor x in catFeatures:\n    df[x] = df[x].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapy={}\nfor feature in catFeatures:\n    le = preprocessing.LabelEncoder()\n    df[feature] = le.fit_transform(df[feature])\n    mapy[feature] = le","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(df)\nfeatures.remove('isFraud')\ntarget='isFraud'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE(n_jobs=-1, random_state=2020)\nadas = ADASYN(random_state=2020)\nros = RandomOverSampler( random_state=2020)\ntom = TomekLinks()\nrus = RandomUnderSampler(random_state=2020)\nnm=NearMiss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Prepare wrapper and AUPRplot</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def wrapper(nFolds = 5, randomState=2020, debug=False, features=features, df=df, sampling=False, sampler=False, *args, **kwargs):\n    kf = KFold(n_splits=nFolds, shuffle=True, random_state=randomState)\n\n    TestResults=[]\n    TrainResults=[]\n    predictions=[]\n    indices = []\n    for train, test in kf.split(df.index.values):\n        clf = DecisionTreeClassifier(*args, **kwargs, random_state=randomState)\n        if debug:\n            print(clf)\n        \n        X_train, y_train = df.iloc[train][features], df.iloc[train][target] \n        X_test, y_test = df.iloc[test][features], df.iloc[test][target]\n\n        if sampling:\n          X_train, y_train = sampler.fit_sample(X_train, y_train)\n\n        clf.fit(X_train, y_train)\n        predsTrain = clf.predict_proba(X_train)[:,1]\n        preds = clf.predict_proba(X_test)[:,1]\n                              \n        predictions.append(preds.tolist().copy())\n        \n        indices.append(df.iloc[test].index.tolist().copy())\n        \n        TrainScore = average_precision_score((y_train==1).astype(int), predsTrain)\n        TestScore = average_precision_score((y_test==1).astype(int), preds)\n        TrainResults.append(TrainScore)\n        TestResults.append(TestScore)\n\n\n    return  predictions, indices, TestResults, TrainResults\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotAUPR(results):\n\n\tfig, ax = plt.subplots(figsize=(10,9))\n\n\tfor true, pred, label in results:\n\t\tprecision, recall, thresholds = precision_recall_curve(true, pred)\n\t\taverage_precision = average_precision_score(true, pred)\n\t\taverage_precision = round(average_precision, 4)\n\t\tlw=2\n\t\tax.plot(recall, precision, lw=lw, label=f'{label}: {average_precision}')\n  \n\n\tax.set_xlim([0, 1])\n\tax.set_ylim([0.0, 1.01])\n\tax.set_xlabel('Recall')\n\tax.set_ylabel('Precision')\n\tax.set_title(f'Precision Recall Curve ')\n\tax.legend(loc=\"lower right\")\n\tplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Training</h1>\n\nSampling methods was training on the best hiperparameters for main Decision Tree model.\nAUPR is better to predicting fraud, because better shows the difference of models for unbalanced data"},{"metadata":{"trusted":true},"cell_type":"code","source":"rec2plot=[]\n\nstd=[]\nvalid_train=[]\nvalid_test=[]\n\npredictions, indices, TestResults, TrainResults = wrapper(df=df,max_depth=21,\n                                                                    min_samples_split=60, min_samples_leaf=50, max_features=37)\nprint( \"std: \", np.std(predictions), 'train AUPR:', np.mean(TrainResults), 'test AUPR: ',np.mean(TestResults) )\nstd.append(np.std(predictions))\nvalid_train.append(np.mean(TrainResults))\nvalid_test.append(np.mean(TestResults))\n\n\ntrue = (df[target]==1).astype(int).sort_index()\npred = pd.Series(sum(predictions, []), index=sum(indices, [])).sort_index()\nrec2plot.append((true, pred, \"DT\"))\n\n\n\nprint('-----------------DT END')\nn=''\n\nfor k in [rus,nm,tom,ros,smote,adas]:\n\n  if k==rus:\n    n='RandomUnderSampler'\n  elif k==ros :\n    n='RandomOverSampler'\n  elif k==smote:\n    n='SMOTE'\n  elif k==nm:\n    n='NearMiss'\n  elif k==tom:\n    n='TomekLinks'\n  else:\n    n='ADASYN'\n\n  predictions, indices, TestResults, TrainResults = wrapper(df=df, max_depth=21,\n                                                                    min_samples_split=60, min_samples_leaf=50, max_features=37, sampling=True, sampler=k)\n  print( \"std: \", np.std(predictions), 'train AUPR:', np.mean(TrainResults), 'test AUPR: ',np.mean(TestResults))\n  valid_train.append(np.mean(TrainResults))\n  valid_test.append(np.mean(TestResults))\n  std.append(np.std(predictions))\n  \n  name = 'modelDT+'+  n\n\n\n  true = (df[target]==1).astype(int).sort_index()\n  pred = pd.Series(sum(predictions, []), index=sum(indices, [])).sort_index()\n  rec2plot.append((true, pred, name))\n\n\n  print('------------------------')\n\nplotAUPR(rec2plot)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotAUPR(rec2plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oversampling and undersampling method doesn't work for this example of dataset"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}