{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, gc, warnings, random, math\nfrom datetime import datetime, timedelta\nfrom joblib import Parallel, delayed\nimport multiprocessing\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport time\n\nwarnings.filterwarnings('ignore')\ndata_folder = \"../input/ieee-fraud-detection/\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('Reading data...')\n\ntrain_identity = pd.read_csv(f'{data_folder}train_identity.csv', index_col='TransactionID')\ntrain_transaction = pd.read_csv(f'{data_folder}train_transaction.csv', index_col='TransactionID')\ntest_identity = pd.read_csv(f'{data_folder}test_identity.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv(f'{data_folder}test_transaction.csv', index_col='TransactionID')\nsub = pd.read_csv(f'{data_folder}sample_submission.csv')\n\nprint('Merging data...')\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\nprint(\"Done\")\n\ndel train_identity, train_transaction, test_identity, test_transaction\ngc.collect()\n\ntest['isFraud'] = -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Generating day of first transaction from D1\nfor df in [train, test]:\n    for col in ['D1']:\n        df[col+'_shift'] = (df[col] - df.TransactionDT // 24 // 3600).fillna(-400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# First userid based on existing and generated features\nfor df in [train, test]:\n    df['uid'] = df['D1_shift'].astype(str)+'_'+df['card1'].astype(str)+'_'+df['addr1'].astype(str)+'_'+df['ProductCD'].astype(str)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"START_DATE = datetime.strptime('2017-11-30', '%Y-%m-%d')\ntrain['DT'] = train['TransactionDT'].apply(lambda x: (START_DATE + timedelta(seconds = x)))\ntest['DT'] = test['TransactionDT'].apply(lambda x: (START_DATE + timedelta(seconds = x)))\n\ndef applyParallel(dfGrouped, func):\n    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n    return pd.concat(retLst)\n\n# The function tried to split users having the same uid, cheking the following assumptions:\n# - D2 is monotonic for a user\n# V307 is a cumulative sum of TransactionAmt over previous 30 days\n# V308 is a cumulative sum of TransactionAmt over previous 7 days\n# V306 is a cumulative sum of TransactionAmt over previous 24 hours\ndef cal_sub_id(df_base, eps = 1e-2):\n    \n    df = df_base.copy()\n    df.reset_index(level=0, inplace=True)\n    df['sub_id'] = -1\n\n    sub_id = 1\n    start_i = 0\n    \n    while start_i < len(df):\n        if df.loc[start_i, 'sub_id'] > 0:\n            start_i += 1\n            continue\n        df.loc[start_i, 'sub_id'] = sub_id\n        i1 = start_i\n        for i2 in range(i1+1, len(df)):\n            if df.loc[i2, 'sub_id'] > 0:\n                continue\n            cond = (df.index < i2) & (df['sub_id'] == sub_id)\n            sum_month = df.loc[(df['DT'] >= df.loc[i2, 'DT'] - timedelta(days=30) ) & cond, \"TransactionAmt\"].sum()\n            sum_week  = df.loc[(df['DT'] >= df.loc[i2, 'DT'] - timedelta(days=7)  ) & cond, \"TransactionAmt\"].sum()\n            sum_day =   df.loc[(df['DT'] >= df.loc[i2, 'DT'] - timedelta(hours=24)) & cond, \"TransactionAmt\"].sum()\n            \n            if ((abs(df.loc[i2, 'D1'] - df.loc[i1, 'D1'] - df.loc[i2, 'D3']) < 2 or np.isnan(df.loc[i2, 'D3'])) and \\\n                ((df.loc[i2, 'D2'] >= df.loc[i1, 'D2']) or np.isnan(df.loc[i2, 'D2']) or np.isnan(df.loc[i1, 'D2'])) and \\\n                ((df.loc[i2, 'V307'] <= eps + df.loc[i1, 'V307'] + df.loc[i1, 'TransactionAmt'] and df.loc[i2, 'V307'] >= sum_month - eps) or np.isnan(df.loc[i2, 'V307']) or np.isnan(df.loc[i1, 'V307']) ) and \\\n                ((df.loc[i2, 'V308'] <= eps + df.loc[i1, 'V308'] + df.loc[i1, 'TransactionAmt'] and df.loc[i2, 'V308'] >= sum_week - eps) or np.isnan(df.loc[i2, 'V308']) or np.isnan(df.loc[i1, 'V308']) ) and \\\n                ((df.loc[i2, 'V306'] <= eps + df.loc[i1, 'V306'] + df.loc[i1, 'TransactionAmt'] and df.loc[i2, 'V306'] >= sum_day - eps) or np.isnan(df.loc[i2, 'V306']) or np.isnan(df.loc[i1, 'V306']) )):\n                i1 = i2\n                df.loc[i1, 'sub_id'] = sub_id\n        sub_id += 1\n\n    return pd.Series(df['sub_id'].values, index=df_base.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Improving uid, saving to uid2\n\ncols = ['DT', 'isFraud', 'ProductCD', 'D1', 'D2', 'D3', 'D15', 'V306', 'V307', 'V308', 'TransactionAmt', 'uid']\n\nstart_time = time.time()\ntrain2 = train[cols].copy()\ntrain2 = pd.merge(train2, applyParallel(train2.groupby(['uid']), cal_sub_id).rename('sub_id'), on=['TransactionID'], how='inner')\nprint(time.time() - start_time)\n\n\nstart_time = time.time()\ntest2 = test[cols].copy()\ntest2 = pd.merge(test2, applyParallel(test2.groupby(['uid']), cal_sub_id).rename('sub_id'), on=['TransactionID'], how='inner')\nprint(time.time() - start_time)\n\n\nfor df in [train2, test2]:\n    df['uid2'] = df['uid'].astype(str) + '_' + df['sub_id'].astype(str)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The same uid contains multiple uid2 values in train and test.\n# The following lazy wirtten function tries to map uid2 with most similar medians of TransactionAmt\n\ndef closest_val(d, v):\n    res_key = None\n    res_dist = -1\n    for d_key, d_val in d.items():\n        dst = abs(d_val - v)\n        if res_key is None or dst < res_dist:\n            res_key = d_key\n            res_dist = dst\n    return res_key\n\ndef map_ids(df):\n    train_df = df[df['isFraud'] != -1]\n    test_df  = df[df['isFraud'] == -1]\n    \n    res = {}\n    \n    test_match_ids = []\n    test_new_ids = []\n    for i in test_df['uid2'].unique():\n        test_match_ids.append(i)\n    \n    train_avg = train_df.groupby('uid2')['TransactionAmt'].median().to_dict()\n    test_avg  = test_df[test_df['uid2'].isin(test_match_ids)].groupby('uid2')['TransactionAmt'].median().to_dict()\n    \n    for k, v in test_avg.items():\n        if len(train_avg) == 0:\n            test_new_ids.append(k)\n            continue\n        \n        tr_key = closest_val(train_avg, v)\n        res[k] = tr_key\n        del train_avg[tr_key]\n        \n    for i, k in enumerate(test_new_ids):\n        res[k] = k + '_' + f\"x{i}\"\n        \n    temp = df[['isFraud', 'uid2']].copy()\n    temp.loc[temp['isFraud'] == -1, 'uid2'] = temp.loc[temp['isFraud'] == -1, 'uid2'].map(res)\n    \n    return temp['uid2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating uid3, based on uid2 and applying the matching algorithm from above\n\ncols = ['DT', 'isFraud', 'ProductCD', 'D1', 'D3', 'D15', 'V306', 'V307', 'V308', 'TransactionAmt', 'uid', 'sub_id', 'uid2']\n\nstart_time = time.time()\ntemp = train2.append(test2)[cols].copy()\ntemp = pd.merge(temp, applyParallel(temp.groupby(['uid']), map_ids).rename('uid3'), on=['TransactionID'], how='inner')\nprint(time.time() - start_time)\n\ntrain2['uid3'] = temp['uid3'][:len(train2)].values\ntest2['uid3'] = temp['uid3'][len(train2):].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['DT', 'uid3']\n\ntrain2[cols].to_csv(\"train_ids.csv\")\ntest2[cols].to_csv(\"test_ids.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}