{"cells":[{"metadata":{},"cell_type":"markdown","source":"Credits\n\nhttps://www.kaggle.com/nroman/eda-for-cis-fraud-detection"},{"metadata":{},"cell_type":"markdown","source":"# Package Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nimport datetime\nimport gc\nfrom time import time\n\n\nimport numpy as np\nimport pandas as pd\nimport multiprocessing\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\n# from sklearn.preprocessing import LabelEncoder\n# from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, train_test_split\n# from sklearn.metrics import roc_auc_score\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn import tree\n# import graphviz\nwarnings.simplefilter('ignore')\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read in data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use multiprocessing to fast reading files in\nfiles = ['../input/test_identity.csv', \n         '../input/test_transaction.csv',\n         '../input/train_identity.csv',\n         '../input/train_transaction.csv',\n         '../input/sample_submission.csv']\n\ndef load_data(file):\n    return pd.read_csv(file)\n\nwith multiprocessing.Pool() as pool:\n    test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train and Test set\ntrain = pd.merge(train_tr, train_id, on='TransactionID', how='left')\ntest = pd.merge(test_tr, test_id, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"del test_id, test_tr, train_id, train_tr\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"There's a 50-50 split between train and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print Shapes\nprint(\"Train Dataset shape: \", train.shape)\nprint(\"Test Dataset shape: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected the proble is highly unbalanced, but not as much as one would expect from a card fraud dataset. There's a 3.5% probability to incur in a Fraud."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print Y variable distribution For Training Set \ntrain['isFraud'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the categorical features I look at how the levels distributed given Fraud or No Fraud. For example, when looking at the first crosstab, the probability of a ProductCD = C given that isFraud = 1 is 38% vs 10% of No Fraud. \n\nIf we scroll down the print, for example we can see that P(IP_PROXY:ANONYMOUS | is Fraud = 1) = 34%, as one would expect. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print Proportions for categorical variables\n\nfor i in train.select_dtypes('object').columns:\n    \n    print(pd.crosstab(train['isFraud'], train[i], normalize = 'index'))\n    print(\"-----------------------------\")\n    print(\"-----------------------------\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the numerical features we used a different approach. We compared the medians of each normalized numerical feature and reported the features with the highest differences. "},{"metadata":{"trusted":true},"cell_type":"code","source":"median_diffs = []\n\nfor i in train.select_dtypes('number').columns[2:]:\n    \n    # Normalize numerical feature\n    var_m = train[i].mean()\n    var_std = train[i].std()\n    norm_var = (train[i] - var_m) / var_std\n    \n    # Create subset\n    sub = train[[i, 'isFraud']]\n    sub[i] = norm_var\n    \n    # Find absolute difference in normalized median\n    temp = sub.groupby('isFraud').median().reset_index()\n    abs_median_diff = abs(temp.iloc[0][i] - temp.iloc[1][i])\n    \n    median_diffs.append((abs_median_diff, i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 features by absolute normalized median difference\nsorted(median_diffs, reverse = True)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(train['isFraud'], train['V50'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}