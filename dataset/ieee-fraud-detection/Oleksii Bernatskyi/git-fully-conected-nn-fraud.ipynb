{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"_uuid":"4155bfd4-2021-435c-b370-17b47b5aa0aa","_cell_guid":"b342f3fb-d4bb-4d15-9378-db8e6959db0c","trusted":true,"scrolled":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.cuda\nimport torch.optim as optim\nimport torch.utils.data\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.optim import SGD\nfrom torch.nn import BCELoss\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import average_precision_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint('SETUP COMPLETED')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84774c0f-beba-4cf1-8db5-70246a36101a","_cell_guid":"06341537-b273-41b1-a855-0f2a23c24a6b","trusted":true},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Downcasting data types"},{"metadata":{"_uuid":"7c4cbaf3-3cf1-420c-88dc-04c9a483a69a","_cell_guid":"3c5ee835-ae23-454a-9f1b-41e8a80b3eef","trusted":true,"scrolled":false},"cell_type":"code","source":"column_types = {'TransactionID': 'int32', 'isFraud': 'int8', 'TransactionDT': 'int32', 'TransactionAmt': 'float32', 'ProductCD': 'object', 'card1': 'int16', 'card2': 'float32', 'card3': 'float32', 'card4': 'object', 'card5': 'float32', 'card6': 'object', 'addr1': 'float32', 'addr2': 'float32', 'dist1': 'float32', 'dist2': 'float32', 'P_emaildomain': 'object', 'R_emaildomain': 'object', 'C1': 'float32', 'C2': 'float32', 'C3': 'float32', 'C4': 'float32', 'C5': 'float32', 'C6': 'float32', 'C7': 'float32', 'C8': 'float32', 'C9': 'float32', 'C10': 'float32', 'C11': 'float32', 'C12': 'float32', 'C13': 'float32', 'C14': 'float32', 'D1': 'float32', 'D2': 'float32', 'D3': 'float32', 'D4': 'float32', 'D5': 'float32', 'D6': 'float32', 'D7': 'float32', 'D8': 'float32', 'D9': 'float32', 'D10': 'float32', 'D11': 'float32', 'D12': 'float32', 'D13': 'float32', 'D14': 'float32', 'D15': 'float32', 'M1': 'object', 'M2': 'object', 'M3': 'object', 'M4': 'object', 'M5': 'object', 'M6': 'object', 'M7': 'object', 'M8': 'object', 'M9': 'object', 'V1': 'float32', 'V2': 'float32', 'V3': 'float32', 'V4': 'float32', 'V5': 'float32', 'V6': 'float32', 'V7': 'float32', 'V8': 'float32', 'V9': 'float32', 'V10': 'float32', 'V11': 'float32', 'V12': 'float32', 'V13': 'float32', 'V14': 'float32', 'V15': 'float32', 'V16': 'float32', 'V17': 'float32', 'V18': 'float32', 'V19': 'float32', 'V20': 'float32', 'V21': 'float32', 'V22': 'float32', 'V23': 'float32', 'V24': 'float32', 'V25': 'float32', 'V26': 'float32', 'V27': 'float32', 'V28': 'float32', 'V29': 'float32', 'V30': 'float32', 'V31': 'float32', 'V32': 'float32', 'V33': 'float32', 'V34': 'float32', 'V35': 'float32', 'V36': 'float32', 'V37': 'float32', 'V38': 'float32', 'V39': 'float32', 'V40': 'float32', 'V41': 'float32', 'V42': 'float32', 'V43': 'float32', 'V44': 'float32', 'V45': 'float32', 'V46': 'float32', 'V47': 'float32', 'V48': 'float32', 'V49': 'float32', 'V50': 'float32', 'V51': 'float32', 'V52': 'float32', 'V53': 'float32', 'V54': 'float32', 'V55': 'float32', 'V56': 'float32', 'V57': 'float32', 'V58': 'float32', 'V59': 'float32', 'V60': 'float32', 'V61': 'float32', 'V62': 'float32', 'V63': 'float32', 'V64': 'float32', 'V65': 'float32', 'V66': 'float32', 'V67': 'float32', 'V68': 'float32', 'V69': 'float32', 'V70': 'float32', 'V71': 'float32', 'V72': 'float32', 'V73': 'float32', 'V74': 'float32', 'V75': 'float32', 'V76': 'float32', 'V77': 'float32', 'V78': 'float32', 'V79': 'float32', 'V80': 'float32', 'V81': 'float32', 'V82': 'float32', 'V83': 'float32', 'V84': 'float32', 'V85': 'float32', 'V86': 'float32', 'V87': 'float32', 'V88': 'float32', 'V89': 'float32', 'V90': 'float32', 'V91': 'float32', 'V92': 'float32', 'V93': 'float32', 'V94': 'float32', 'V95': 'float32', 'V96': 'float32', 'V97': 'float32', 'V98': 'float32', 'V99': 'float32', 'V100': 'float32', 'V101': 'float32', 'V102': 'float32', 'V103': 'float32', 'V104': 'float32', 'V105': 'float32', 'V106': 'float32', 'V107': 'float32', 'V108': 'float32', 'V109': 'float32', 'V110': 'float32', 'V111': 'float32', 'V112': 'float32', 'V113': 'float32', 'V114': 'float32', 'V115': 'float32', 'V116': 'float32', 'V117': 'float32', 'V118': 'float32', 'V119': 'float32', 'V120': 'float32', 'V121': 'float32', 'V122': 'float32', 'V123': 'float32', 'V124': 'float32', 'V125': 'float32', 'V126': 'float32', 'V127': 'float32', 'V128': 'float32', 'V129': 'float32', 'V130': 'float32', 'V131': 'float32', 'V132': 'float32', 'V133': 'float32', 'V134': 'float32', 'V135': 'float32', 'V136': 'float32', 'V137': 'float32', 'V138': 'float32', 'V139': 'float32', 'V140': 'float32', 'V141': 'float32', 'V142': 'float32', 'V143': 'float32', 'V144': 'float32', 'V145': 'float32', 'V146': 'float32', 'V147': 'float32', 'V148': 'float32', 'V149': 'float32', 'V150': 'float32', 'V151': 'float32', 'V152': 'float32', 'V153': 'float32', 'V154': 'float32', 'V155': 'float32', 'V156': 'float32', 'V157': 'float32', 'V158': 'float32', 'V159': 'float32', 'V160': 'float32', 'V161': 'float32', 'V162': 'float32', 'V163': 'float32', 'V164': 'float32', 'V165': 'float32', 'V166': 'float32', 'V167': 'float32', 'V168': 'float32', 'V169': 'float32', 'V170': 'float32', 'V171': 'float32', 'V172': 'float32', 'V173': 'float32', 'V174': 'float32', 'V175': 'float32', 'V176': 'float32', 'V177': 'float32', 'V178': 'float32', 'V179': 'float32', 'V180': 'float32', 'V181': 'float32', 'V182': 'float32', 'V183': 'float32', 'V184': 'float32', 'V185': 'float32', 'V186': 'float32', 'V187': 'float32', 'V188': 'float32', 'V189': 'float32', 'V190': 'float32', 'V191': 'float32', 'V192': 'float32', 'V193': 'float32', 'V194': 'float32', 'V195': 'float32', 'V196': 'float32', 'V197': 'float32', 'V198': 'float32', 'V199': 'float32', 'V200': 'float32', 'V201': 'float32', 'V202': 'float32', 'V203': 'float32', 'V204': 'float32', 'V205': 'float32', 'V206': 'float32', 'V207': 'float32', 'V208': 'float32', 'V209': 'float32', 'V210': 'float32', 'V211': 'float32', 'V212': 'float32', 'V213': 'float32', 'V214': 'float32', 'V215': 'float32', 'V216': 'float32', 'V217': 'float32', 'V218': 'float32', 'V219': 'float32', 'V220': 'float32', 'V221': 'float32', 'V222': 'float32', 'V223': 'float32', 'V224': 'float32', 'V225': 'float32', 'V226': 'float32', 'V227': 'float32', 'V228': 'float32', 'V229': 'float32', 'V230': 'float32', 'V231': 'float32', 'V232': 'float32', 'V233': 'float32', 'V234': 'float32', 'V235': 'float32', 'V236': 'float32', 'V237': 'float32', 'V238': 'float32', 'V239': 'float32', 'V240': 'float32', 'V241': 'float32', 'V242': 'float32', 'V243': 'float32', 'V244': 'float32', 'V245': 'float32', 'V246': 'float32', 'V247': 'float32', 'V248': 'float32', 'V249': 'float32', 'V250': 'float32', 'V251': 'float32', 'V252': 'float32', 'V253': 'float32', 'V254': 'float32', 'V255': 'float32', 'V256': 'float32', 'V257': 'float32', 'V258': 'float32', 'V259': 'float32', 'V260': 'float32', 'V261': 'float32', 'V262': 'float32', 'V263': 'float32', 'V264': 'float32', 'V265': 'float32', 'V266': 'float32', 'V267': 'float32', 'V268': 'float32', 'V269': 'float32', 'V270': 'float32', 'V271': 'float32', 'V272': 'float32', 'V273': 'float32', 'V274': 'float32', 'V275': 'float32', 'V276': 'float32', 'V277': 'float32', 'V278': 'float32', 'V279': 'float32', 'V280': 'float32', 'V281': 'float32', 'V282': 'float32', 'V283': 'float32', 'V284': 'float32', 'V285': 'float32', 'V286': 'float32', 'V287': 'float32', 'V288': 'float32', 'V289': 'float32', 'V290': 'float32', 'V291': 'float32', 'V292': 'float32', 'V293': 'float32', 'V294': 'float32', 'V295': 'float32', 'V296': 'float32', 'V297': 'float32', 'V298': 'float32', 'V299': 'float32', 'V300': 'float32', 'V301': 'float32', 'V302': 'float32', 'V303': 'float32', 'V304': 'float32', 'V305': 'float32', 'V306': 'float32', 'V307': 'float32', 'V308': 'float32', 'V309': 'float32', 'V310': 'float32', 'V311': 'float32', 'V312': 'float32', 'V313': 'float32', 'V314': 'float32', 'V315': 'float32', 'V316': 'float32', 'V317': 'float32', 'V318': 'float32', 'V319': 'float32', 'V320': 'float32', 'V321': 'float32', 'V322': 'float32', 'V323': 'float32', 'V324': 'float32', 'V325': 'float32', 'V326': 'float32', 'V327': 'float32', 'V328': 'float32', 'V329': 'float32', 'V330': 'float32', 'V331': 'float32', 'V332': 'float32', 'V333': 'float32', 'V334': 'float32', 'V335': 'float32', 'V336': 'float32', 'V337': 'float32', 'V338': 'float32', 'V339': 'float32'}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc6ae3cc-6ebb-413c-a35c-a7a0724dd83d","_cell_guid":"3a200eba-9a95-498a-b018-bfe15ca94ba5","trusted":true,"scrolled":false},"cell_type":"code","source":"train_df = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv',dtype=column_types)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"164ad40b-1712-4b99-bd8f-16169000ed03","_cell_guid":"e24ca7a0-e72a-4f0e-9989-8dfd25ac6d2d","trusted":true,"scrolled":false},"cell_type":"code","source":"train_y = train_df['isFraud']\ntrain_df.drop('isFraud',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imputing NA, scaling, encoding"},{"metadata":{"_uuid":"b90fb077-cf41-44bd-afd4-e8948ca6ca6c","_cell_guid":"6c81d638-86d3-4a1d-8485-ad47cc67f50d","trusted":true,"scrolled":false},"cell_type":"code","source":"# Select categorical columns\ncategorical_cols = [cname for cname in train_df.columns if\n                    train_df[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in train_df.columns if \n                  train_df[cname].dtype in ['int8', 'int16', 'int32', 'float32']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd9b4b2f-c5e3-43da-a5f3-eeea1ed191b2","_cell_guid":"6c0a4691-1cfd-4a07-87e3-87dbcf74533f","trusted":true,"scrolled":false},"cell_type":"code","source":"# Preprocessing for numerical data\nnumerical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')), ('scale', StandardScaler())])\n\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n                                           ('onehot', OneHotEncoder(dtype=np.int8, handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df = preprocessor.fit_transform(train_df)\nprint('DONE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_y = train_y.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-valid split"},{"metadata":{"_uuid":"869d9f09-8064-44f0-b0dc-8f8596a6c88a","_cell_guid":"d78f54a1-1498-4a42-b86b-dc8af43b26f0","trusted":true,"scrolled":false},"cell_type":"code","source":"train_tmp, valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(train_df,train_y, stratify=train_y)\nprint(train_tmp.shape[0])\nprint(valid_tmp.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tensor wraping"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_tmp = torch.from_numpy(train_tmp).type(torch.float).to(device)\ny_train_tmp = torch.from_numpy(y_train_tmp).type(torch.float).type(torch.float).to(device)\nvalid_tmp = torch.from_numpy(valid_tmp).type(torch.float).to(device)\ny_valid_tmp = torch.from_numpy(y_valid_tmp).type(torch.float).to(device)\nprint('DONE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_loader = torch.utils.data.TensorDataset(train_tmp,y_train_tmp)\nvalid_loader = torch.utils.data.TensorDataset(valid_tmp,y_valid_tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_loader, batch_size = 128, shuffle = True)\nvalid_loader = torch.utils.data.DataLoader(valid_loader, batch_size = 128, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c748ac5-fa90-4d1f-8c36-1d221b535c45","_cell_guid":"c6ea6ee0-aaf2-403c-bcbc-d48c4dd6ad0a","trusted":true},"cell_type":"markdown","source":"# Neural network"},{"metadata":{},"cell_type":"markdown","source":"## Building model"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(543, 256)\n        self.fc2 = nn.Linear(256,128)\n        self.fc3 = nn.Linear(128,64)\n        self.fc4 = nn.Linear(64,1)\n        \n        self.dropout = nn.Dropout(p= 0.6, inplace = True)\n        \n    def forward(self, x):\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        x = F.sigmoid(self.fc4(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"net = Net()\nnet.to(device)\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"criterion = BCELoss()\noptimizer = Adam(net.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print            \n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n    def __call__(self, val_loss, model):\n\n        score = val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation accuracy increased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"patience = 2\nearly_stopping = EarlyStopping(patience=patience, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_auroc_list, valid_auroc_list = [], []\nepochs = 20\nprint('CALCULATION STARTED....')\nfor epoch in range(1, epochs+1):\n    train_hat_list, valid_hat_list, train_true_list, valid_true_list = [], [], [], []\n    train_loss_avg = 0\n    valid_loss_avg = 0\n    for (train_samples, train_targets) in train_loader:\n        optimizer.zero_grad()\n        net_out = net(train_samples)\n        train_loss = criterion(net_out, train_targets)\n        train_loss_avg += train_loss\n        train_loss.backward()\n        optimizer.step()\n        for iterrr,ittter in zip(net_out, train_targets):\n            train_hat_list.append(iterrr.item())\n            train_true_list.append(ittter.item())\n    train_loss_avg = train_loss_avg/len(train_loader)\n    with torch.no_grad():\n        net.eval()\n        for (valid_samples, valid_targets) in valid_loader:\n            val_out = net(valid_samples)\n            valid_loss = criterion(val_out,valid_targets)\n            valid_loss_avg += valid_loss\n        \n            for iiiter,iteeer in zip(val_out, valid_targets):\n                valid_hat_list.append(iiiter.item())\n                valid_true_list.append(iteeer.item())\n        valid_loss_avg = valid_loss_avg/len(valid_loader)\n    net.train()\n    train_accuracy_auroc = roc_auc_score(train_true_list, train_hat_list)\n    train_auroc_list.append(train_accuracy_auroc)\n    valid_accuracy_auroc = roc_auc_score(valid_true_list, valid_hat_list)\n    valid_auroc_list.append(valid_accuracy_auroc) \n    print(\"Epoch: {} of {}\".format(epoch,epochs))\n    print(\"TRAIN loss: {} | VALID loss: {}\".format(train_loss_avg, valid_loss_avg))                  \n    print(\"TRAIN roc auc score: {} | VALID roc auc score: {}\".format(train_accuracy_auroc, valid_accuracy_auroc))    \n    early_stopping(valid_accuracy_auroc, net)\n        \n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n            \nnet.load_state_dict(torch.load('checkpoint.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.plot(train_auroc_list, label='Training accuracy')\nplt.plot(valid_auroc_list, label='Validation accuracy')\nplt.legend(frameon=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inference"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submit_np = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv',dtype=column_types)\nsub = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submit_np = preprocessor.transform(submit_np)\nprint('DONE')\nsubmit_np.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submit_np = torch.from_numpy(submit_np).type(torch.float).to(device)\n\nfake_labels = np.zeros(submit_np.shape)\nfake_labels = torch.from_numpy(fake_labels).type(torch.float).to(device)\n\nsubmit_np = torch.utils.data.TensorDataset(submit_np, fake_labels)\n\nsubmit_np = torch.utils.data.DataLoader(submit_np, batch_size = 128, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"submission = []\nwith torch.no_grad():\n    net.eval()\n    for samples, _ in submit_np:\n        log_ps = net(samples.float())\n        for prediction in log_ps:\n            submission.append(prediction.item())\n        \nsubmit_np = pd.Series(submission)\nsub['isFraud'] = submit_np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sub.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)\nprint('NOTEBOOK DONE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}