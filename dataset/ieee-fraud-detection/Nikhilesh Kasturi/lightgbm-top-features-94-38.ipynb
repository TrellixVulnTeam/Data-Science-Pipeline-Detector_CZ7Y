{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm_notebook\nfrom sklearn.metrics import roc_auc_score\nimport gc\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/'\ntrain_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\ntest_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')\ntest_transaction = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')\nsample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def id_split(dataframe):\n    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n\n    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n\n    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n\n    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n\n    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n\n    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n\n    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n    dataframe['had_id'] = 1\n    gc.collect()\n    \n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = id_split(train_identity)\ntest_identity = id_split(test_identity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Merging data...')\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint('Data was successfully merged!\\n')\n\ndel train_identity, train_transaction, test_identity, test_transaction\n\nprint(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\nprint(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"useful_features = ['card1_count_full',\n'addr1__card1',\n'card1',\n'TransactionAmt_to_std_card1',\n'card1__card5',\n'TransactionAmt_to_mean_card1',\n'card2_count_full',\n'card2',\n'card2__dist1',\n'Transaction_hour',\n'TransactionAmt_to_std_card4',\n'addr1',\n'TransactionAmt_to_mean_card4',\n'TransactionAmt',\n'P_emaildomain__C2',\n'card5__P_emaildomain',\n'dist1',\n'card2__id_20',\n'D4',\n'Transaction_day_of_week',\n'D2',\n'D15_to_mean_card1',\n'D10',\n'TransactionAmt_Log',\n'D11',\n'D5',\n'TransactionAmt_decimal',\n'C13',\n'D15_to_std_card1',\n'D3',\n'D1',\n'D15_to_mean_addr1',\n'DeviceInfo__P_emaildomain',\n'D15_to_mean_card4',\n'D15',\n'card5',\n'P_emaildomain',\n'D11__DeviceInfo',\n'D15_to_std_addr1',\n'card5_count_full',\n'D15_to_std_card4',\n'id_02_to_std_card1',\n'V307',\n'P_emaildomain_bin',\n'id_19',\n'id_20',\n'id_02_to_mean_card1',\n'D8',\n'id_02__id_20',\n'V310',\n'C2',\n'V127',\n'C1',\n'id_02_to_std_card4',\n'id_02_to_mean_card4',\n'id_02',\n'C14',\n'C9',\n'id_31',\n'id_31_count_dist',\n'V308',\n'C6',\n'V130',\n'V314',\n'id_13',\n'version_id_31',\n'V313',\n'id_02__D8',\n'C11',\n'V315',\n'D9',\n'id_06',\n'M4',\n'V128',\n'V312',\n'R_emaildomain',\n'id_05',\n'V306',\n'DeviceInfo',\n'C5',\n'V317',\n'M6',\n'M5',\n'R_emaildomain_bin',\n'V285',\n'V96',\n'V131',\n'V126',\n'id_01',\n'screen_height',\n'D6',\n'V35',\n'V5',\n'V36',\n'M8',\n'device_version',\n'V283',\n'id_33_count_dist',\n'D14',\n'card4',\n'version_id_30',\n'V99',\n'id_33',\n'V4',\n'D12',\n'M7',\n'device_name',\n'V282',\n'id_01_count_dist',\n'M9',\n'V62',\n'id_14',\n'id_30',\n'V83',\n'V75',\n'V38',\n'V264',\n'V13',\n'V76',\n'V78',\n'V45',\n'V54',\n'V53',\n'P_emaildomain_suffix',\n'V20',\n'V87',\n'V82',\n'M3',\n'V280',\n'D13',\n'card4_count_full',\n'V291',\n'V12',\n'V61',\n'V294',\n'card6',\n'V44',\n'V19',\n'C10',\n'C12',\n'V37',\n'V56',\n'V49',\n'V11',\n'V265',\n'screen_width',\n'V48',\n'V203',\n'V10',\n'C8',\n'V3',\n'V7',\n'card3',\n'M2',\n'browser_id_31',\n'V97',\n'V221',\n'card6_count_full',\n'V30',\n'V165',\n'ProductCD',\n'V263',\n'V29',\n'V279',\n'card3_count_full',\n'V70',\n'V91',\n'V267',\n'V69',\n'V204',\n'V90',\n'id_38',\n'V160',\n'V150',\n'V6',\n'V222',\n'V52',\n'V143',\n'V292',\n'V202',\n'V274',\n'V287',\n'V289',\n'V159',\n'V40',\n'id_09',\n'V164',\n'V145',\n'V332',\n'V166',\n'V51',\n'V139',\n'V95',\n'C4',\n'V209',\n'V47',\n'V277',\n'id_03',\n'V74',\n'V208',\n'V261',\n'V207',\n'V266',\n'V212',\n'V268',\n'V275',\n'V273',\n'V229',\n'V258',\n'V9',\n'V333',\n'DeviceType',\n'V210',\n'id_11',\n'V100',\n'id_17',\n'V331',\n'V140',\n'V219',\n'V262',\n'V215',\n'V213',\n'V278',\n'V206',\n'V270',\n'V271',\n'V8',\n'V234',\n'R_emaildomain_suffix',\n'V152',\n'V276',\n'V151',\n'V323',\n'id_15',\n'V217',\n'V170',\n'V214',\n'V171',\n'V205',\n'V245',\n'C7',\n'V73',\n'id_37',\n'V81',\n'V34',\n'V288',\n'V272',\n'V216',\n'V224',\n'V338',\n'id_32',\n'V46',\n'V259',\n'V228',\n'V169',\n'V149',\n'V64',\n'V58',\n'OS_id_30',\n'V178',\n'V257',\n'V187',\n'V60',\n'V33',\n'V233',\n'V80',\n'V94',\n'V220',\n'V251',\n'V59',\n'V167',\n'V226',\n'V324',\n'V85',\n'V176',\n'V156',\n'V243',\n'V335',\n'V231',\n'V201',\n'V189',\n'V180',\n'addr2',\n'V71',\n'V63',\n'V72',\n'V177',\n'V225',\n'V322',\n'V17',\n'V256',\n'V246',\n'V93',\n'V200',\n'V182',\n'V329',\n'V184',\n'V303',\n'V84',\n'V92',\n'V336',\n'V244',\n'V158',\n'V238',\n'V223',\n'V326',\n'V173',\n'V172',\n'V147',\n'V188',\n'V239',\n'V253',\n'V175',\n'V242',\n'V146',\n'id_36_count_full',\n'V154',\n'V227',\n'V304',\n'V162',\n'V161',\n'id_12',\n'V249',\n'V163',\n'id_36_count_dist',\n'id_36',\n'V195',\n'V197',\n'V247',\n'V138',\n'had_id'\n\n]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cols_to_drop = [col for col in train.columns if col not in useful_features]\ncols_to_drop.remove('isFraud')\ncols_to_drop.remove('TransactionDT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\ntrain['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntest['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\ntest['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntrain['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\ntrain['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\ntrain['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\ntrain['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n\ntest['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\ntest['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\ntest['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\ntest['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n\ntrain['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\ntrain['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\ntrain['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\ntrain['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n\ntest['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\ntest['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\ntest['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\ntest['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n\ntrain['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\ntrain['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\ntrain['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\ntrain['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n\ntest['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\ntest['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\ntest['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\ntest['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# New feature - log of transaction amount. ()\ntrain['TransactionAmt_Log'] = np.log(train['TransactionAmt'])\ntest['TransactionAmt_Log'] = np.log(test['TransactionAmt'])\n\n# New feature - decimal part of the transaction amount.\ntrain['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\ntest['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)\n\n# New feature - day of week in which a transaction happened.\ntrain['Transaction_day_of_week'] = np.floor((train['TransactionDT'] / (3600 * 24) - 1) % 7)\ntest['Transaction_day_of_week'] = np.floor((test['TransactionDT'] / (3600 * 24) - 1) % 7)\n\n# New feature - hour of the day in which a transaction happened.\ntrain['Transaction_hour'] = np.floor(train['TransactionDT'] / 3600) % 24\ntest['Transaction_hour'] = np.floor(test['TransactionDT'] / 3600) % 24\n\n# Some arbitrary features interaction\nfor feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n\n    f1, f2 = feature.split('__')\n    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n\n    le = LabelEncoder()\n    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n    train[feature] = le.transform(list(train[feature].astype(str).values))\n    test[feature] = le.transform(list(test[feature].astype(str).values))\n\n# Encoding - count encoding for both train and test\nfor feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6']:\n    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n\n# Encoding - count encoding separately for train and test\nfor feature in ['id_01', 'id_31', 'id_33']:\n    train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n    test[feature + '_count_dist'] = test[feature].map(test[feature].value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for c in ['P_emaildomain', 'R_emaildomain']:\n    train[c + '_bin'] = train[c].map(emails)\n    test[c + '_bin'] = test[c].map(emails)\n    \n    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n    test[c + '_suffix'] = test[c].map(lambda x: str(x).split('.')[-1])\n    \n    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    test[c + '_suffix'] = test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in train.columns:\n    if train[col].dtype == 'object':\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\ny = train.sort_values('TransactionDT')['isFraud']\n\nX_test = test.drop(['TransactionDT'], axis=1)\n\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"params = {'num_leaves': 951,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 280,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.020883242363721497,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'max_delta_step' : 1,\n          'is_unbalance': 'True',\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47,\n           'n_jobs':-1,\n           'tree_learner':'serial',\n          'colsample_bytree': 0.7,\n          'subsample_freq':1,\n          'subsample':0.7,\n         }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nNFOLDS = 15\nfolds = KFold(n_splits=NFOLDS)\n\ncolumns = X.columns\nsplits = folds.split(X, y)\ny_preds = np.zeros(X_test.shape[0])\ny_oof = np.zeros(X.shape[0])\nscore = 0\n\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = columns\n  \nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    dtrain = lgb.Dataset(X_train, label=y_train)\n    dvalid = lgb.Dataset(X_valid, label=y_valid)\n\n    clf = lgb.train(params, dtrain, 20000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)\n    \n    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(X_valid)\n    y_oof[valid_index] = y_pred_valid\n    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n    \n    score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n    y_preds += clf.predict(X_test) / NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    gc.collect()\n    \nprint(f\"\\nMean AUC = {score}\")\nprint(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample_submission['isFraud'] = y_preds\nsample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances['average'] = feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\nfeature_importances.to_csv('feature_importances2.csv')\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\nplt.title('50 TOP feature importance over {} folds average'.format(folds.n_splits));","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}