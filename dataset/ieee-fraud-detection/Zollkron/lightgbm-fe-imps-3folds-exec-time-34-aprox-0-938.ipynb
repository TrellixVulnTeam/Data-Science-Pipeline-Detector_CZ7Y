{"cells":[{"metadata":{},"cell_type":"markdown","source":"# LightGBM + FE + Imputations + Mem Optimization + 3 Folds | Execution Time in 34 mins aprox. | Score 0.938"},{"metadata":{},"cell_type":"markdown","source":"### Some modifications from the public kernel https://www.kaggle.com/whitebird/a-method-to-valid-offline-lb-9506"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport random\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_transaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"**Merge, class feature 'y', and categorical features codification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)\n\ny_train = train['isFraud'].copy()\n\n# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\n\ndel train, test\n\n# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features Election"},{"metadata":{},"cell_type":"markdown","source":"**We deal with the numeric features now. We choose for deletion the features with more than 300000 NAs.**"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"col_del = []\nfor i in range(339):\n    col = \"V\" + str(i+1)\n    s = train_transaction[col].fillna(0).map(lambda x:0 if x%1 == 0 else 1).sum()\n    if s > 300000:\n        print(col,s)\n        col_del.append(col)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in X_train.columns if x not in col_del]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Mapping. Seconds in Hour of Day and Day of Week**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['hour'] = train_transaction['TransactionDT'].map(lambda x:(x//3600)%24)\ntest_transaction['hour'] = test_transaction['TransactionDT'].map(lambda x:(x//3600)%24)\ntrain_transaction['weekday'] = train_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)\ntest_transaction['weekday'] = test_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)\n\ndel train_transaction, train_identity, test_transaction, test_identity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Imputations**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp.fit(X_train[features])\nX_train[features] = imp.transform(X_train[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp.fit(X_test[features])\nX_test[features] = imp.transform(X_test[features])\ndel imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[features])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Memory optimization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# WARNING! THIS CAN DAMAGE THE DATA \n\nX_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Garbage Collector**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training model and Predictions"},{"metadata":{},"cell_type":"markdown","source":"**LightGBM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\ncate = [x for x in X_train.columns if (x == 'ProductCD' or  x.startswith(\"addr\") or x.startswith(\"card\") or \n                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") ]\nprint(cate)\nparams = {'application': 'binary',\n          'boosting': 'gbdt',\n          'metric': 'auc',\n          'max_depth': 16,\n          'learning_rate': 0.03,\n          'bagging_fraction': 0.9,\n          'feature_fraction': 0.9,\n          'verbose': -1,\n          'lambda_l1': 0.1,\n          'lambda_l2': 0.01,\n          'num_leaves': 500,\n          'min_child_weight': 3,\n          'data_random_seed': 17,\n          'nthreads':4}\n\nearly_stop = 500\nverbose_eval = 30\nnum_rounds = 600\n# \nfolds = 3\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_preds = np.zeros(X_test.shape[0])\nfeature_importance_df = pd.DataFrame()\ni = 0\nfor tr_idx, val_idx in kf.split(X_train[features], y_train):\n\n    \n    X_tr = X_train.iloc[tr_idx, :]\n    y_tr = y_train.iloc[tr_idx]\n    d_train = lgb.Dataset(X_tr, label=y_tr,categorical_feature = cate)\n    watchlist = []\n    \n    \n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval)\n        \n    \n    y_preds+= model.predict(X_test[features]) / folds\n    \n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = X_tr.columns\n    fold_importance_df[\"importance\"] = model.feature_importance()\n    fold_importance_df[\"fold\"] = i + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    i+=1\n    del X_tr,d_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Writing results"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['isFraud'] = y_preds\nsample_submission.to_csv('LightGBM.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}