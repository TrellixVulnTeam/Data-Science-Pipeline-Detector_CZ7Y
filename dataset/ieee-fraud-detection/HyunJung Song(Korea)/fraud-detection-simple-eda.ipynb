{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Purpose : Predicting the probability that an online transaction is fraudulent\n### Target : isFraud(binary target)**\n\nThe data is broken into two files \"identity\" and \"transaction\", which are joined by \"TransactionID\". \n\nNot all transactions have corresponding identity information."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('fivethirtyeight')\nsns.set(font_scale=2)\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\nsubmission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To save memory, you can use reduce_mem_usage function. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#reference : https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65\n# def reduce_mem_usage(props):\n#     start_mem_usg = props.memory_usage().sum() / 1024**2 \n#     print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n#     NAlist = [] # Keeps track of columns that have missing values filled in. \n#     for col in props.columns:\n#         if props[col].dtype != object:  # Exclude strings\n#             IsInt = False\n#             mx = props[col].max()\n#             mn = props[col].min()\n#             if not np.isfinite(props[col]).all(): \n#                 NAlist.append(col)\n#                 props[col].fillna(mn-1,inplace=True)                     \n#             asint = props[col].fillna(0).astype(np.int64)\n#             result = (props[col] - asint)\n#             result = result.sum()\n#             if result > -0.01 and result < 0.01:\n#                 IsInt = True\n#             if IsInt:\n#                 if mn >= 0:\n#                     if mx < 255:\n#                         props[col] = props[col].astype(np.uint8)\n#                     elif mx < 65535:\n#                         props[col] = props[col].astype(np.uint16)\n#                     elif mx < 4294967295:\n#                         props[col] = props[col].astype(np.uint32)\n#                     else:\n#                         props[col] = props[col].astype(np.uint64)\n#                 else:\n#                     if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n#                         props[col] = props[col].astype(np.int8)\n#                     elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n#                         props[col] = props[col].astype(np.int16)\n#                     elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n#                         props[col] = props[col].astype(np.int32)\n#                     elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n#                         props[col] = props[col].astype(np.int64) \n#             else:\n#                 props[col] = props[col].astype(np.float32)            \n\n#     print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n#     mem_usg = props.memory_usage().sum() / 1024**2 \n#     print(\"Memory usage is: \",mem_usg,\" MB\")\n#     print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n#     return props, NAlist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratoy Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_transaction.shape, test_transaction.shape)\nprint(train_identity.shape, test_identity.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results show that the number of columns in the train_identity and test_identity is the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- imbalanced data set (more than 75% of isFraud is filled with 0).\n- a lot of NaN values.\n"},{"metadata":{},"cell_type":"markdown","source":"# Examine the Distribution of the Target Colum"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(round(train_transaction['isFraud'].value_counts(normalize=True) * 100,2))\ntrain_transaction['isFraud'].astype(int).plot.hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this information, we see this is an imbalanced class problem (Only have 3.5% of positive values). So, we can weight the classes by their representation in the data to reflect this imbalance."},{"metadata":{},"cell_type":"markdown","source":"# Examine Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reference : https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction\ndef missing_values_table(df):    \n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n\n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n\n    # Print some summary information\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n          \" columns that have missing values.\")\n\n    return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_iden = missing_values_table(train_identity)\nmissing_values_iden.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_trans = missing_values_table(train_transaction)\nmissing_values_trans.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many columns with over 90% missing values.\nIt is important to deal with missing values."},{"metadata":{},"cell_type":"markdown","source":"# Column Types"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n', 'Number of each type of column')\nprint(train_identity.dtypes.value_counts())\nprint('\\n', 'Number of unique classes in each object column')\nprint(train_identity.select_dtypes('object').apply(pd.Series.nunique, axis = 0).sort_values(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some categorical variables have a relatively large number of unique entries. \nWe will need to find a way to deal with these categorical variables.\nBecause of the large number of columns, I think it would be better to do frequency encoding or mean encoding than one-hot encoding."},{"metadata":{},"cell_type":"markdown","source":"# features - transaction\n\n* emaildomain\n* card1 - card6\n* addr1, addr2\n* P_emaildomain\n* R_emaildomain\n* M1 - M9\nThe TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp)."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n', 'Number of each type of column')\nprint(train_transaction.dtypes.value_counts())\nprint('\\n', 'Number of unique classes in each int column')\nprint(train_transaction.select_dtypes('int').apply(pd.Series.nunique, axis = 0).sort_values(ascending = False))\nprint('\\n', 'Number of unique classes in each object column')\nprint(train_transaction.select_dtypes('object').apply(pd.Series.nunique, axis = 0).sort_values(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize except float type features.\ndef bar_plot(col, data, hue=None):\n    f, ax = plt.subplots(figsize = (30, 5))\n    sns.countplot(x=col, hue=hue, data=data, alpha=0.5)\n\n#Visualize float type features.\ndef dist_plot(col, data):\n    f, ax = plt.subplots(figsize = (30, 5))\n    sns.distplot(data[col].dropna(), kde=False, bins=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### emaildomain"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(30,15))\n\nsns.countplot(y=\"P_emaildomain\", ax=ax[0], data=train_transaction)\nax[0].set_title('P_emaildomain')\nsns.countplot(y=\"R_emaildomain\", ax=ax[1], data=train_transaction)\nax[1].set_title('R_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Product"},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot('ProductCD', train_transaction, hue='isFraud')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### card1 - card6"},{"metadata":{"trusted":true},"cell_type":"code","source":"card_float = ['card1', 'card2', 'card3', 'card5']\nfor col in card_float:\n    print(col, train_transaction[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card_n_float = ['card4', 'card6']    \n\nfor col in card_n_float:\n    bar_plot(col, train_transaction, hue='isFraud')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### addr1, addr2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"card_float = ['addr1', 'addr2']\nfor col in card_float:\n    dist_plot(col, train_transaction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### C1 - C14"},{"metadata":{"trusted":true},"cell_type":"code","source":"C_col = [c for c in train_transaction if c[0] == 'C']\ncorr = train_transaction[C_col].corr()\n\ncmap = sns.color_palette(\"Blues\")\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(corr, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many variables with a correlation of 1. Therefore, it is necessary to process the correlated variables."},{"metadata":{},"cell_type":"markdown","source":"### D1 - D9"},{"metadata":{"trusted":true},"cell_type":"code","source":"D_col = [c for c in train_transaction if c[0] == 'D']\ncorr = train_transaction[D_col].corr()\n\ncmap = sns.color_palette(\"Blues\")\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(corr, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- D1, D2\n- D4, D12, D6\n- D5, D7"},{"metadata":{},"cell_type":"markdown","source":"### M1 - M9"},{"metadata":{"trusted":true},"cell_type":"code","source":"M_col = [c for c in train_transaction if c[0] == 'M']\nfor col in M_col:\n    bar_plot(col, train_transaction, hue='isFraud')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### V1 - V339"},{"metadata":{"trusted":true},"cell_type":"code","source":"V_col = [c for c in train_transaction if c[0] == 'V']\ntrain_transaction[V_col].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the columns are filled with zero"},{"metadata":{},"cell_type":"markdown","source":"### TransactionDT"},{"metadata":{},"cell_type":"markdown","source":"The following hist shows that train_transaction and test_transaction were split by TransactionDT. So it would be prudent to use time-based split for validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['TransactionDT'].plot(kind='hist', figsize=(15, 5), label='train_transaction', bins=100)\ntest_transaction['TransactionDT'].plot(kind='hist', label='test_transaction', bins=100)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TransactionAMT"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\ntime_val = train_transaction['TransactionAmt'].values\n\nsns.distplot(train_transaction['TransactionAmt'].values, ax=ax[0], color='r')\nax[0].set_title('Distribution of TransactionAmt', fontsize=14)\nax[0].set_xlim([min(train_transaction['TransactionAmt'].values), max(train_transaction['TransactionAmt'].values)])\n\nsns.distplot(np.log(train_transaction['TransactionAmt'].values), ax=ax[1], color='b')\nax[1].set_title('Distribution of LOG TransactionAmt', fontsize=14)\nax[1].set_xlim([min(np.log(train_transaction['TransactionAmt'].values)), max(np.log(train_transaction['TransactionAmt'].values))])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical features - identity\n\n* DeviceType\n* DeviceInfo\n* id_12 - id_38\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n', 'Number of each type of column')\nprint(train_identity.dtypes.value_counts())\nprint('\\n', 'Number of unique classes in each object column')\nprint(train_identity.select_dtypes('object').apply(pd.Series.nunique, axis = 0).sort_values(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be continue..."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}