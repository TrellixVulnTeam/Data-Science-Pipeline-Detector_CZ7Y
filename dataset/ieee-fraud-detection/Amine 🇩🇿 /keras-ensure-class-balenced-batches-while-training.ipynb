{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IEEE-CIS Fraud Detection with Keras\n* Using roc-auc as metric\n* Class Balancing inside batchs with fit_generator so we can compute roc-auc \n* Stratified K-Fold Cross-Validation"},{"metadata":{},"cell_type":"markdown","source":"# Import some libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport scipy as sc\n        \nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.pipeline import Pipeline\nfrom keras.layers import Dense, Input, Dropout\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom sklearn.impute import SimpleImputer\n\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom sklearn.feature_selection import SelectKBest, chi2, SelectPercentile\nfrom sklearn.preprocessing import LabelEncoder\nimport keras.backend as K\nfrom sklearn import metrics\nimport tensorflow as tf\n\nimport seaborn as sns\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_transaction = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\ntrain_identity = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\n\ntest_identity = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_identity.csv\")\ntest_transaction = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_transaction.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Quick EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train_transaction (Nbr Samples/Nbr Columns): \", train_transaction.shape) \nprint(\"train_identity (Nbr Samples/Nbr Columns): \", train_identity.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding the Percentage of Missing Values for each column"},{"metadata":{},"cell_type":"markdown","source":"### Train Transaction DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"nans = train_transaction.isnull().mean(axis = 0).sort_values(ascending=False)*100\nnans.reset_index().rename({\"index\": \"column\", 0: \"NaNs rate\"}, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train identity DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"nans = train_identity.isnull().mean(axis = 0).sort_values(ascending=False)*100\nnans.reset_index().rename({\"index\": \"column\", 0: \"NaNs rate\"}, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check if dataframe is class balanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"isFraud\", data=train_transaction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [\n    'ProductCD',\n    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n    'addr1', 'addr2',\n    'P_emaildomain',\n    'R_emaildomain',\n    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9'\n]\n\ndata = train_transaction.merge(train_identity, on=\"TransactionID\", how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dorp columns with hight NaN numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[:, data.isnull().mean() <= .5]\ncolumns_to_keep = data.columns\ncategorical_cols = [c for c in categorical_features if c in data.columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Class Balancing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class count\ncount_class_0, count_class_1 = data.isFraud.value_counts()\n\n# Divide by class\ndf_class_0 = data[data['isFraud'] == 0]\ndf_class_1 = data[data['isFraud'] == 1]\n\ndf_class_0_under = df_class_0.sample(int(count_class_1 / 2))\nbalenced_df = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nbalenced_df = balenced_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = balenced_df.isFraud\nX = balenced_df.drop([\"TransactionID\", \"isFraud\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building basic DeepNeural Model"},{"metadata":{},"cell_type":"markdown","source":"## RoC AuC metric for Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"def auc(y_true, y_pred):\n    return tf.py_func(metrics.roc_auc_score, (y_true, y_pred), tf.double)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Batch Generator \nWe make sure that every batch has sample from each class so we can compute RoC AuC score\n\n**TO DO:** BatchGenerator(keras.utils.Sequence) class "},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_generator(X, y, batch_size=16, shuffle=True):\n    '''\n    Return a random sample from X, y\n    '''\n    y = np.array(y)\n    list_of_index_0 = np.where(y == 0)[0]\n    list_of_index_1 = np.where(y == 1)[0]\n    batch_0 = int(batch_size / 2)\n    batch_1 = batch_size - batch_0\n    \n    while True:\n        idx_0 = np.random.choice(list_of_index_0, size=batch_0, replace=False,)\n        idx_1 = np.random.choice(list_of_index_1, size=batch_1, replace=False,)\n        idx = np.concatenate((idx_0, idx_1), axis=None)\n\n        if sc.sparse.issparse(X[idx]): \n            sample = X[idx].toarray()\n        else:\n            sample = X[idx]\n        label = y[idx]\n        \n        yield sample, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Keras Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(optimizer=\"adam\", dim=100):\n    model = Sequential()\n    \n    model.add(Dense(50, activation='sigmoid', input_shape=(dim,)))\n    model.add(Dropout(0.5), )\n    \n    model.add(Dense(20, activation='relu'))\n    model.add(Dropout(0.2), )\n \n    model.add(Dense(20, activation='relu'))\n    model.add(Dropout(0.2), )\n    \n    model.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n    \n    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[auc])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating the Model with stratified k-fold cross validation"},{"metadata":{},"cell_type":"markdown","source":"### Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold_splits = 5\nbatch_size = 512\nepochs = 100\noptimizer = \"NAdam\"\nimputing_strategy = \"mean\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = { \"cv_val\": [], \"cv_train\": [],}\n\n# Instantiate the cross validator\nskf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n\n# Loop through the indices the split() method returns\nfor index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n    print (\"Training on fold \" + str(index+1) + \"/\" + str(kfold_splits) + \"...\")\n  \n    #Split \n    xtrain, xval = X.iloc[train_indices], X.iloc[val_indices]\n    ytrain, yval = y.iloc[train_indices], y.iloc[val_indices]\n    \n    #LabelEncoding categorical columns\n    label_encoders = {c: LabelEncoder() for c in categorical_cols}\n    for c in categorical_cols:\n        xtrain.loc[:,c], xval.loc[:,c] = xtrain[c].map(str), xval[c].map(str)\n        #Handling Unknown Labels\n        label_encoders[c].fit(np.concatenate((xtrain[c].values, np.array([\"other\"])), axis=None))\n        xval.loc[:,c] = xval[c].map(lambda s: 'other' if s not in label_encoders[c].classes_ else s)\n        #LabelEncoding\n        xtrain.loc[:,c]  = label_encoders[c].transform(xtrain[c].values)\n        xval.loc[:,c]  = label_encoders[c].transform(xval[c].values)\n \n    #Imputing Missing Values\n    imp = SimpleImputer(missing_values=np.nan, strategy=imputing_strategy).fit(xtrain)\n    xtrain = imp.transform(xtrain)\n    xval = imp.transform(xval) \n    \n    #Normalize\n    dim = xtrain.shape[1]\n    scaler = StandardScaler(with_mean=False).fit(xtrain)\n    xtrain = scaler.transform(xtrain)\n    xval = scaler.transform(xval)\n  \n    # Create generators for fit_generator method\n    train_gen = batch_generator(xtrain, ytrain, batch_size=batch_size)\n    valid_gen = batch_generator(xval, yval, batch_size=batch_size)\n    \n    model = create_model(optimizer=optimizer, dim=dim)\n   \n    history = model.fit_generator(\n            generator=train_gen,\n            epochs=epochs,\n            verbose=1,\n            steps_per_epoch=xtrain.shape[0] // batch_size, #xtrain.shape[0] // batch_size\n            validation_data=valid_gen,\n            validation_steps=xval.shape[0] // batch_size, #xval.shape[0] // batch_size\n        )\n    #Evaluate Model\n    val_score, train_score = metrics.roc_auc_score(yval, [x[0] for x in model.predict(xval,verbose=0)]), metrics.roc_auc_score(ytrain, [x[0] for x in model.predict(xtrain,verbose=0)])\n    print(\"RoC AuC:   train %f val %f \" % (train_score, val_score))\n    results[\"cv_val\"].append(val_score)\n    results[\"cv_train\"].append(train_score)\n\nprint(\"Final Score: train %f (+/- %f) val %f (+/- %f)\" % (np.mean(results[\"cv_train\"]), np.std(results[\"cv_train\"]), np.mean(results[\"cv_val\"]), np.std(results[\"cv_val\"])))    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}