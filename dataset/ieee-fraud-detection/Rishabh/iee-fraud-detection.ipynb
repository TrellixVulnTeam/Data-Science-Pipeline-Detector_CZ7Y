{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n#import plotly.graph_objs as go\n#import plotly.tools as tls\nimport seaborn as sns\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport time\nimport gc\nimport os\n\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom sklearn.model_selection import KFold, TimeSeriesSplit, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score,make_scorer\n#from plotly.offline import iplot, init_notebook_mode\nfrom xgboost import XGBClassifier, plot_importance\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ndf_transactions = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exploratory Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000):\n        with pd.option_context(\"display.max_columns\", 1000):\n            display(df)\n            \ndef reduce_memory_usage(df, verbose=True):\n    \"\"\" \n    Reduces the size of given dataframe by assigning \n    datatype appropriately.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_max = df[col].max()\n            c_min = df[col].min()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose:\n        print(f'Mem. usage decreased to {end_mem} Mb {(((start_mem - end_mem)/start_mem))*100} % reduction.')\n    return df\n                    \ndef describe_table(df):\n    \"\"\"Describes the statistics of given dataframe\"\"\"\n    print(f'Dataset Shape is: {df.shape}')\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary.rename(columns={'index':'Name'}, inplace=True)\n    summary['Missing'] = df.isnull().sum().values\n    summary['Uniques'] = df.nunique().values\n    summary['First Values'] = df.loc[0].values\n    summary['Second Values'] = df.loc[1].values\n    summary['Third Values'] = df.loc[2].values\n    display(summary)\n    \n    return summary\n\ndef countplot(df, x_value='', y_value='', title='',xlabel='', ylabel='', \n              legend=False, legend_title='',legend_labels='', point_plot=False,\n              point_y_label='', point_x_value='', point_y_value='', hue=False):\n    \n    \"\"\"Plot Countplot\"\"\"\n    \n    plt.figure(figsize=(14,22))\n    total = df.shape[0]\n    plt.subplot(413)\n    if hue == True:\n        g = sns.countplot(x=x_value, hue=y_value, data=df, order=df[x_value].dropna().unique())\n    else:\n        g = sns.countplot(x=x_value, data=df, )\n    \n    g.set_title(title, fontsize=16)\n    g.set_xlabel(xlabel, fontsize=15)\n    g.set_ylabel(ylabel, fontsize=15)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\", fontsize=10)\n        \n    if legend == True:\n        plt.legend(title=legend_title, loc='best', labels=legend_labels)\n    \n    if point_plot == True:\n        tmp = pd.crosstab(df[x_value], df[y_value], normalize='index')*100\n        tmp = tmp.reset_index()\n        \n        gt = g.twinx()\n        gt = sns.pointplot(x=point_x_value, y=point_y_value, data=tmp, color='black',\n                          order=df[x_value].dropna().unique(), legend=False)\n        gt.set_ylabel(point_y_label, fontsize=15)\n        \n    plt.show()\n\ndef barplot(df, x_value, y_value, title, xlabel, ylabel, total):\n    \"\"\"Plot Barplot\"\"\"\n    plt.figure(figsize=(14,22))\n    plt.subplot(413)\n    g = sns.barplot(x=x_value, y=y_value, dodge=True, data=df)\n    g.set_title(title, fontsize=20)\n    g.set_xlabel(xlabel,fontsize=18)\n    g.set_ylabel(ylabel, fontsize=18)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()/ 2, height+3, \n                f'{(height/total * 100):.2f}%',ha='center', fontsize=13)\n    plt.show()\n\ndef boxenplot(df, x_value, y_value, legend, title, x_label, y_label):\n    \"\"\"Plot BoxenPlot\"\"\"\n    plt.figure(figsize=(14,10))\n    plt.subplot(212)\n    g = sns.boxenplot(x=x_value, y=y_value, hue=legend,\n                      data=df)\n    g.set_title(title, fontsize=20)\n    g.set_xlabel(x_label, fontsize=17)\n    g.set_ylabel(y_label, fontsize=17)\n\n    plt.subplots_adjust(hspace=0.6, top=0.85)\n    plt.show()\n\ndef calculate_outliers(df_num):\n    \"\"\"Calculate outliers of given column.\"\"\"\n    data_mean, data_std = np.mean(df_num), np.std(df_num)\n    \n    cut = data_std * 3\n    \n    lower, upper = data_mean - cut, data_mean + cut\n    \n    outliers_lower = [x for x in df_num if x < lower]\n    outliers_higher = [x for x in df_num if x > upper]\n    outliers_total = [x for x in df_num if x < lower or x > upper]\n    outliers_removed = [x for x in df_num if x>lower and x< upper]\n    \n    print(f'Identified lowest outliers: {len(outliers_lower)}')\n    print(f'Identified upper outliers: {len(outliers_higher)}')\n    print(f'Total outlier observations: {len(outliers_total)}')\n    print(f'Non-outlier observations: {len(outliers_removed)}')\n    \n    print(f'Total percentual of outliers: {round((len(outliers_total) / len(outliers_removed))*100,4)}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_all(df_id.head().T)\ndisplay_all(df_transactions.head().T)\n\nprint(df_id.shape)\nprint(df_transactions.shape)\n\ndf_id = reduce_memory_usage(df_id)\ndf_transactions = reduce_memory_usage(df_transactions)\n\ndf_transactions['TransactionAmt'] = df_transactions['TransactionAmt'].astype(float)\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fraud Distributions \nperc_amt = df_transactions.groupby(['isFraud'])['TransactionAmt'].sum()\nperc_amt = perc_amt.reset_index()    \ntotal_bar = df_transactions['TransactionAmt'].sum()\ncountplot(df=df_transactions, x_value=\"isFraud\", title=\"Fraud Transactions Distribution \\n# 0: No Fraud | 1: Fraud #\", xlabel=\"Is fraud?\", ylabel=\"Count\") \nbarplot(perc_amt, \"isFraud\", \"TransactionAmt\", \"Total Amount in Transaction Amt \\n# 0: No Fraud | 1: Fraud #\", \"Is fraud?\", \"Total Transaction Amount Scalar\", total_bar)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ProductCD Distribution\ncountplot(df=df_transactions, x_value=\"ProductCD\", title=\"ProductCD Distribution\", xlabel=\"ProductCD Name\", ylabel=\"Count\") \ncountplot(df_transactions, \"ProductCD\", \"isFraud\", \"Product CD by Target(isFraud)\", \"ProductCD Name\", \"Count\", True, \"Fraud\", [\"No\", \"Yes\"], True, \"% of Fraud Transactions\", \"ProductCD\", 1, hue=True)\nboxenplot(df_transactions[df_transactions['TransactionAmt']<=2000], \"ProductCD\", \"TransactionAmt\", \"isFraud\",\n         \"Transaction Amount Distribuition by ProductCD and Target\", \"ProductCD Name\", \"Transaction Values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transaction Amount Quantiles\ndf_transactions['TransactionAmt'] = df_transactions['TransactionAmt'].astype(float)\nprint(\"Transaction Amounts Qantiles:\")\nprint(df_transactions['TransactionAmt'].quantile([.01, 0.025, .1, 0.25, .5,\n                                                 .75, .9, .975, .99]))\nprint(pd.concat([df_transactions[df_transactions['isFraud']==1]['TransactionAmt'].quantile([.01, 0.025, .1, 0.25, .5,\\\n                                                 .75, .9, .975, .99]).reset_index(),\\\n    df_transactions[df_transactions['isFraud']==0]['TransactionAmt'].quantile([.01, 0.025, .1, 0.25, .5,\\\n                                                 .75, .9, .975, .99]).reset_index()], axis=1, keys=['Fraud', 'No Fraud']))\n#Transaction Amount Outliers\ncalculate_outliers(df_transactions['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cards Quantiles\nprint(\"Card Features Quantiles: \")\nprint(df_transactions[['card1', 'card2', 'card3', 'card5']].quantile([0.01, .025, .1, .25, .5, .75, .975, .99]))\n\ndescribe_table(df_transactions[['card1', 'card2', 'card3','card4', 'card5', 'card6']])\n\n#Card3 and Card5 Distributions\ndf_temp = df_transactions['card3'].value_counts()\ndf_transactions.loc[df_transactions['card3'].isin(df_temp[df_temp<200].index), 'card3'] = \"Others\"\n\ndf_temp = df_transactions['card5'].value_counts()\ndf_transactions.loc[df_transactions['card5'].isin(df_temp[df_temp<300].index), 'card5'] = \"Others\"\n\n\ncountplot(df=df_transactions, x_value=\"card3\", y_value=\"isFraud\", title=\"Card3 Values Distribution and % of Fraud Transactions\", \n          xlabel=\"Card3 Values\", ylabel=\"Count\", point_plot=True, point_y_label=\"% of Fraud Transactions\", \n          point_x_value=\"card3\", point_y_value=1)\n\ncountplot(df=df_transactions, x_value=\"card5\", y_value=\"isFraud\", title=\"Card5 Values Distribution and % of Fraud Transactions\", \n          xlabel=\"Card5 Values\", ylabel=\"Count\", point_plot=True, point_y_label=\"% of Fraud Transactions\", \n          point_x_value=\"card5\", point_y_value=1)\n\n#Card 4 and Card6 Distribution\ncountplot(df=df_transactions, x_value=\"card4\", title=\"Card4 Distribution\", xlabel=\"Card4 Values\", ylabel=\"Count\") \ncountplot(df_transactions, \"card4\", \"isFraud\", \"Card4 by Target(isFraud)\", \"Card4 Name\", \"Count\", True, \"Fraud\", [\"No\", \"Yes\"], True, \"% of Fraud Transactions\", \"card4\", 1, hue=True)\nboxenplot(df_transactions[df_transactions['TransactionAmt']<=2000], \"card4\", \"TransactionAmt\", \"isFraud\",\n         \"Transaction Amount Distribuition by Card4 and Target\", \"Card4 Name\", \"Transaction Values\")\n\ncountplot(df=df_transactions, x_value=\"card6\", title=\"Card6 Distribution\", xlabel=\"Card6 Values\", ylabel=\"Count\") \ncountplot(df_transactions, \"card6\", \"isFraud\", \"Card6 by Target(isFraud)\", \"Card6 Name\", \"Count\", True,\n          \"Fraud\", [\"No\", \"Yes\"], True, \"% of Fraud Transactions\", \"card6\", 1, hue=True)\nboxenplot(df_transactions[df_transactions['TransactionAmt']<=2000], \"card6\", \"TransactionAmt\", \"isFraud\",\n         \"Transaction Amount Distribuition by Card6 and Target\", \"Card6 Name\", \"Transaction Values\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#M Features\ndescribe_table(df_transactions[['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']])\n\nfor col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    df_transactions[col] = df_transactions[col].fillna('Miss')\n    \nfor col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    countplot(df_transactions, col, \"isFraud\", col + \" by Target(isFraud)\", col + \" Name\", \"Count\", True,\n              \"Fraud\", [\"No\", \"Yes\"], True, \"% of Fraud Transactions\", col, 1, hue=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Addr Features\nprint('Addr Quantiles: ')\nprint(df_transactions[['addr1', 'addr2']].quantile([0.01,0.025,0.1,\n                                                   .25,.5,.75,.90,.99]))\ndescribe_table(df_transactions[['addr1', 'addr2']])\n\ndf_transactions.loc[df_transactions['addr1'].isin(df_transactions['addr1'].value_counts()[df_transactions['addr1'].value_counts()<=5000].index),'addr1'] = 'Others'\ndf_transactions.loc[df_transactions['addr2'].isin(df_transactions['addr2'].value_counts()[df_transactions['addr2'].value_counts()<=50].index),'addr2'] = 'Others'\n\ncountplot(df=df_transactions, x_value=\"addr1\", y_value=\"isFraud\", title=\"addr1 Distribution\", xlabel=\"addr1 Values\", ylabel=\"Count\",\n          point_plot=True, point_y_label=\"% of Fraud Transactions\", point_x_value=\"addr1\", point_y_value=1)\ncountplot(df=df_transactions, x_value=\"addr2\", y_value=\"isFraud\", title=\"addr2 Distribution\", xlabel=\"addr2 Values\", ylabel=\"Count\", \n         point_plot=True, point_y_label=\"% of Fraud Transactions\", point_x_value=\"addr2\", point_y_value=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Email Distribution\ndf_transactions.loc[df_transactions['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\ndf_transactions.loc[df_transactions['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ndf_transactions.loc[df_transactions['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\ndf_transactions.loc[df_transactions.P_emaildomain.isin(df_transactions.P_emaildomain\\\n                                         .value_counts()[df_transactions.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\ndf_transactions.P_emaildomain.fillna(\"NoInf\", inplace=True)\n\ndf_transactions.loc[df_transactions['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\ndf_transactions.loc[df_transactions['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\ndf_transactions.loc[df_transactions['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                             'outlook.es', 'live.com', 'live.fr',\n                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\ndf_transactions.loc[df_transactions.R_emaildomain.isin(df_transactions.R_emaildomain\\\n                                         .value_counts()[df_transactions.R_emaildomain.value_counts() <= 300 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\ndf_transactions.R_emaildomain.fillna(\"NoInf\", inplace=True)\n\ncountplot(df=df_transactions, x_value=\"P_emaildomain\", y_value=\"isFraud\", title=\"P_emaildomain Distribution\", xlabel=\"P_emaildomain Values\", ylabel=\"Count\",\n         point_plot=True, point_y_label=\"% of Fraud Transactions\", point_x_value=\"P_emaildomain\", point_y_value=1)\ncountplot(df=df_transactions, x_value=\"R_emaildomain\", y_value=\"isFraud\", title=\"R_emaildomain Distribution\", xlabel=\"R_emaildomain Values\", ylabel=\"Count\",\n         point_plot=True, point_y_label=\"% of Fraud Transactions\", point_x_value=\"R_emaildomain\", point_y_value=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    countplot(df=df_transactions, x_value=col, y_value=\"isFraud\", title=col + \" Distribution\", xlabel=col + \" Values\", ylabel=\"Count\",\n         point_plot=True, point_y_label=\"% of Fraud Transactions\", point_x_value=col, point_y_value=1)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_transactions = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#it seems that train and test transaction dates don't overlap, so it would be prudent to use time-based split for validation.\nplt.hist(df_transactions['TransactionDT'], label='train');\nplt.hist(df_test_transactions['TransactionDT'], label='test');\nplt.legend();\nplt.title('Distribution of transactiond dates');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ndf_transactions = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n\n\ndf_test_transactions = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\ndf_test_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df_test_id.columns:\n    if '-' in col:\n        df_test_id.rename(columns={col:col.replace('-','_')}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_transactions.merge(df_id, how='left', left_index=True, right_index=True, on='TransactionID')\ndf_test = df_test_transactions.merge(df_test_id, how='left', left_index=True, right_index=True, on='TransactionID')\n\nprint(df_train.shape)\nprint(df_test.shape)\n\ndel df_transactions, df_id, df_test_transactions, df_test_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = reduce_memory_usage(df_train)\ndf_test = reduce_memory_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n\nus_emails = ['gmail', 'net', 'edu']\n\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    df_train[c+'_bin'] = df_train[c].map(emails)\n    df_test[c+'_bin'] = df_test[c].map(emails)\n    \n    df_train[c+'_suffix'] = df_train[c].map(lambda x: str(x).split('.')[-1])\n    df_test[c+'_suffix'] = df_test[c].map(lambda x: str(x).split('.')[-1])\n    \n    df_train[c+'_suffix'] = df_train[c+'_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    df_test[c+'_suffix'] = df_test[c+'_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TransactionAmt'] = df_train['TransactionAmt'].astype(float)\n\ndf_train['Trans_min_mean'] = df_train['TransactionAmt'] - df_train['TransactionAmt'].mean()\ndf_train['Trans_min_mean'] = df_train['Trans_min_mean'] / df_train['TransactionAmt'].std()\n\ndf_test['Trans_min_mean'] = df_test['TransactionAmt'] - df_test['TransactionAmt'].mean()\ndf_train['Trans_min_mean'] = df_test['Trans_min_mean'] / df_test['TransactionAmt'].std()\n\ndf_train['TransactionAmt_to_mean_card1'] = df_train['TransactionAmt']/ \\\ndf_train.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_mean_card4'] = df_train['TransactionAmt']/ \\\ndf_train.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_std_card1'] = df_train['TransactionAmt']/ \\\ndf_train.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_train['TransactionAmt_to_std_card4'] = df_train['TransactionAmt']/ \\\ndf_train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ndf_test['TransactionAmt_to_mean_card1'] = df_test['TransactionAmt']/ \\\ndf_test.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_mean_card4'] = df_test['TransactionAmt']/ \\\ndf_test.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_std_card1'] = df_test['TransactionAmt']/ \\\ndf_test.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_test['TransactionAmt_to_std_card4'] = df_test['TransactionAmt']/ \\\ndf_test.groupby(['card4'])['TransactionAmt'].transform('std')\n\ndf_train['TransactionAmt'] = np.log(df_train['TransactionAmt'])\ndf_test['TransactionAmt'] = np.log(df_test['TransactionAmt'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Cleaning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_columns_null(df, null_per=0.9, target=''):\n    \"\"\"Remove columns from dataframe which have null values greater than null_per\"\"\"\n    drop_cols = [col for col in df if df[col].isnull().sum() / df.shape[0] > null_per]\n    if target and target in drop_cols:\n        drop_cols.remove(target)\n    df.drop(columns=drop_cols, inplace=True)\n    return df\n    \ndef remove_columns_top_values(df, top_values_per=0.9, target=''):\n    \"\"\"Remove columns from dataframe which have top_values greater than top_values_per\"\"\"\n    drop_cols = [col for col in df.columns if df[col].value_counts(dropna=False, normalize=True).values[0] > top_values_per]\n    if target and target in drop_cols:\n        drop_cols.remove(target)\n    df.drop(columns=drop_cols, inplace=True)\n    return df\n\ndef convert_categorical(df, target=''):\n    \"\"\"Convert categorical to labels\"\"\"\n    for col in df.columns:\n        if df[col].dtype=='object' and col != target:\n            le = preprocessing.LabelEncoder()\n            col_val = list(df[col].values)\n            le.fit(col_val)\n            df[col] = le.transform(col_val)\n    return df\n\ndef pca(df, cols, n_components, prefix='PCA_', rand_seed=4):\n    pca = PCA(n_components=n_components, random_state=rand_seed)\n    principal_components = pca.fit_transform(df[cols])\n    principal_df = pd.DataFrame(principal_components)\n    df.drop(col, axis=1, inplace=True)\n    principal_df.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n    df = pd.concat([df, principal_df], axis=1)\n    return df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['isFraud'] = 'test'\ndf = pd.concat([df_train, df_test], axis=0, sort=False)\ndf = df.reset_index()\ndf = df.drop('index', axis=1)\n\ndf = remove_columns_null(df, target='isFraud')\ndf = remove_columns_top_values(df, target='isFraud')\ndf = convert_categorical(df, 'isFraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mass_v = []\nfor col in df.columns:\n    if 'V' in col:\n        df[col] = df[col].fillna((df[col].min()-2))\n        df[col] = (minmax_scale(df[col], feature_range=(0, 1)))\n        mass_v.append(col)\ndf = pca(df, cols=mass_v, n_components=30, prefix='PCA_V')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = reduce_memory_usage(df)\ndf_train, df_test = df[df['isFraud'] != 'test'], df[df['isFraud'] == 'test'].drop('isFraud', axis=1)\nx_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\ny_train = df_train.sort_values('TransactionDT')['isFraud'].astype(bool)\nx_test = df_test.sort_values('TransactionDT').drop(['TransactionDT'], axis=1)\n\ndel df_train\ndel df_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.fillna(-1, inplace=True)\nx_test.fillna(-1, inplace=True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Parameter Tuning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(params):\n    time1 = time.time()\n    params = {\n        'max_depth': int(params['max_depth']),\n        'gamma': f\"{params['gamma']:.3f}\",\n        'subsample': f\"{params['subsample']:.3f}\",\n        'reg_alpha': f\"{params['reg_alpha']:.3f}\",\n        'reg_lambda': f\"{params['reg_lambda']:.3f}\",\n        'learning_rate': f\"{params['learning_rate']:.3f}\",\n        'colsample_bytree': f\"{params['colsample_bytree']:.3f}\"\n#         'num_leaves': f\"{params['num_leaves']:.3f}\",\n#         'colsample_bytree': f\"{params['colsample_bytree']:.3f}\",\n#         'min_child_sample': f\"{params['min_child_sample']:.3f}\",\n#         'feature_fraction': f\"{params['feature_fraction']:.3f}\",\n#         'bagging_fraction': f\"{params['bagging_fraction']:.3f}\"\n    }\n    print(f'Params={params}')\n    FOLDS = 5\n    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n    #tss = TimeSeriesSplit(n_splits=FOLDS)\n    #y_preds = np.zeros(sample_submission.shape[0])\n    #y_oof = np.zeros(x_train.shape[0])\n    score_mean = 0\n    count = 1\n    for tr_idx, val_idx in skf.split(x_train, y_train):\n        clf = xgb.XGBClassifier(\n            n_estimators=600, random_state=4,\n            tree_method='gpu_hist', **params\n        )\n        x_tr, x_vl = x_train.iloc[tr_idx, :], x_train.iloc[val_idx, :]\n        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n        clf.fit(x_tr, y_tr)\n        score = make_scorer(roc_auc_score, needs_proba=True)(clf, x_vl, y_vl)\n        #score2 = roc_auc_score(x_vl, y_vl)\n        print(score)\n        #print(score2)\n        score_mean += score\n        print(f'{count} CV - score: {round(score, 4)}')\n        count += 1\n    time2 = time.time() - time1    \n    print(f'Total Time taken to Run:{round(time2/60, 2)}')\n    gc.collect()\n    print(f'Mean ROC_AUC: {score_mean/FOLDS}')\n    del x_tr, x_vl, y_tr, clf, score\n    return -(score_mean / FOLDS)\n\nspace = {\n    'max_depth': hp.quniform('max_depth', 7, 23, 1),\n    'gamma': hp.uniform('gamma', 0.01, 0.7),\n    'reg_alpha': hp.uniform('reg_alpha', 0.01, 0.4),\n    'reg_lambda': hp.uniform('reg_lambda', 0.01, 0.4),\n    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 0.9),\n    'subsample': hp.choice('subsample', [0.2,0.4,0.5,0.6,0.7,0.8,0.9])\n    \n#     'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n#     'min_child_sample': hp.choice('min_child_samples', list(range(100,250,10))),\n#     'feature_fraction': hp.uniform('feature_fraction', 0.4, 0.8),\n#     'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 0.9)\n}\n\nbest = fmin(fn=objective,\n           space=space,\n           algo=tpe.suggest,\n           max_evals=20)\nbest_params = space_eval(space, best)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Modeling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = {'colsample_bytree': 0.7119660671941589, 'gamma': 0.33522898802386575, 'learning_rate': 0.056727824029570835, 'max_depth': 20.0, 'reg_alpha': 0.23710032808707382, 'reg_lambda': 0.25699791703652, 'subsample': 0.9}\nprint('Best Params:', best_params)\nbest_params['max_depth'] = int(best_params['max_depth'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier(\n    n_estimators=600,\n    **best_params,\n    tree_method='gpu_hist'\n)\nclf.fit(x_train, y_train)\ny_preds = clf.predict_proba(x_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = clf.predict_proba(x_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_important = clf.get_booster().get_score(importance_type='weight')\nkeys = list(feature_important.keys())\nvalues = list(feature_important.values())\ndata = pd.DataFrame(data=values, index=keys, columns=['score']).sort_values(by='score', ascending=False)\ndata.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.DataFrame()\nsample_submission['TransactionID'] = x_test['TransactionID']\nsample_submission['isFraud'] = y_preds\nsample_submission.to_csv('XGB_model.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}