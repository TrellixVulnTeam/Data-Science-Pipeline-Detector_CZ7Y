{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#EEE-CIS обнаружение мошенничества\n# Reboot. DS -75. Первый поток\n# Выпускная работа Демина А.В","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Задача поставлена в соревновании:  https://www.kaggle.com/c/ieee-fraud-detection/overview\n# За основу взяты нотебуки: \n#                                    https://www.kaggle.com/artgor/eda-and-models \n#                                    https://www.kaggle.com/jesucristo/fraud-complete-eda\n#                                    https://www.kaggle.com/cybercat/naive-modeling-using-minimum-analysis  \n#                                    https://www.kaggle.com/dejavu23/titanic-survival-seaborn-and-ensembles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Лучший способ участия в соревновании — найти чужое ядро с хорошим результатом в таблице лидеров, скопировать его и попытаться улучшить результат. \n# (c) https://tproger.ru/translations/kaggle-competitions-introduction/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Постановка задачи:\n\nПредставьте себе, что вы стоите у кассы в продуктовом магазине с длинной очередью за вами, и кассир не так тихо объявляет, что ваша карта была отклонена. В этот момент вы, вероятно, не думаете о науке о данных, которая определила вашу судьбу.\n\nСмущенный, и, наверняка, у вас есть средства, чтобы покрыть все необходимое для эпической вечеринки начо для 50 ваших самых близких друзей, вы пробуете свою карту снова. Тот же результат. Отойдя в сторону и разрешив кассиру ухаживать за следующим клиентом, вы получите текстовое сообщение от своего банка. «Нажмите 1, если вы действительно пытались потратить 500 долларов на сыр чеддер».\n\nХотя эта система предотвращения мошенничества может быть громоздкой (и зачастую смущающей) на данный момент, она на самом деле экономит потребителям миллионы долларов в год. Исследователи из Общества вычислительной разведки IEEE (IEEE-CIS) хотят улучшить эту цифру, одновременно улучшая качество обслуживания клиентов. Благодаря более высокой точности обнаружения мошенничества вы можете без проблем справиться со своими чипами.\n\nIEEE-CIS работает во множестве областей искусственного интеллекта и машинного обучения, включая глубокие нейронные сети, нечеткие системы, эволюционные вычисления и интеллектуальный рой. Сегодня они сотрудничают с ведущей в мире платежной компанией Vesta Corporation, ища лучшие решения для индустрии предотвращения мошенничества, и теперь вы приглашены присоединиться к этой задаче.\n\nВ этом конкурсе вы будете тестировать модели машинного обучения в сложном крупномасштабном наборе данных. Данные поступают из реальных транзакций электронной коммерции Vesta и содержат широкий спектр функций от типа устройства до функций продукта. У вас также есть возможность создавать новые функции для улучшения ваших результатов.\n\nВ случае успеха вы повысите эффективность предупреждений о мошеннических транзакциях для миллионов людей во всем мире, помогая сотням тысяч компаний сократить потери от мошенничества и увеличить свои доходы. И, конечно же, вы избавите тусовщиков, как и вы, от хлопот ложных срабатываний.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Материалы оцениваются с помощью ROC AUC между прогнозируемой вероятностью и наблюдаемой целью.\n\n# Хотя интуитивно кажется, что нужно использовать точность для задачи бинарной классификации, \n# это будет плохим решением, потому что мы имеем дело с проблемой несбалансированного класса. \n# Вместо точности, решения оцениваются с помощью ROC AUC (Receiver Operating Characteristic curve Area Under the Curve). \n# Чем выше результат, тем лучше. Чтобы вести подсчёты с помощью ROC AUC, нужно делать прогнозы в терминах вероятностей, а не бинарные — 0 или 1. \n# ROC показывает истинную положительную оценку по сравнению с ложно положительной оценкой, как функцию порога, согласно которому мы классифицируем экземпляр как положительный.\n\n# Обычно нравится делать наивное базовое предсказание, но в этом случае мы уже знаем, что случайные догадки по задаче будут равны 0,5 по ROC AUC. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Файл представления\n# Для каждого TransactionID в наборе тестов вы должны предсказать вероятность для переменной isFraud. Файл должен содержать заголовок и иметь следующий формат:\n# TransactionID,isFraud\n# 3663549,0.5\n# 3663550,0.5\n# 3663551,0.5\n# и т.д.\n\n# Categorical Features - Transaction \n# Функция TransactionDT представляет собой временную дельту из заданной контрольной даты и времени (не фактическая временная метка)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Таблица транзакций (описание https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203)\n# TransactionDT: timedelta из заданной контрольной даты и времени (не фактическая временная метка)\n# TransactionAMT: сумма оплаты транзакции в долларах США\n# ProductCD: код товара, товар для каждой транзакции\n# card1 - card6: информация о платежной карте, такая как тип карты, категория карты, банк-эмитент, страна и т. д.\n# addr: адрес\n# dist: расстояние\n# P_ и (R__) emaildomain: домен электронной почты покупателя и получателя\n# C1-C14: подсчет, например, количество найденных адресов, связанных с платежной картой, и т. Д. Фактическое значение маскируется.\n# D1-D15: интервал времени, например дни между предыдущими транзакциями и т. Д.\n# M1-M9: совпадение, например имена на карте и адрес и т. Д.\n# Vxxx: Vesta разработала богатые возможности, включая ранжирование, подсчет и другие отношения сущностей.\n\n# Категориальные признаки:\n# ProductCD\n# card1 - card6\n# addr1, addr2\n# P emaildomain R emaildomain\n# M1 - M9\n\n# Идентификационная таблица *\n# Переменные в этой таблице представляют собой информацию об идентичности - информацию о сетевом соединении (IP, ISP, Proxy и т. Д.) И цифровую подпись (UA / browser / os / version и т. Д.), Связанную с транзакциями.\n# Они собраны системой защиты от мошенничества Vesta и партнерами по цифровой безопасности.\n# (Имена полей замаскированы и парный словарь не будет предоставлен для защиты конфиденциальности и заключения договора)\n\n# Категориальные признаки:\n# DeviceType\n# DeviceInfo\n# ID 12 - ID 38","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Файлы\n# train_{transaction, identity}.csv - the training set\n# test_{transaction, identity}.csv - the test set (you must predict the isFraud value for these observations)\n# sample_submission.csv - a sample submission file in the correct format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загрузка библиотек\nimport pandas as pd\nimport numpy as np\nimport warnings\n#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n#warnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR, SVR\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn import preprocessing\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost\n\nimport time\n\npd.options.display.precision = 15\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\n# plotly library\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# просмотр содержимого входной директории https://www.kaggle.com/c/ieee-fraud-detection/data\nfrom subprocess import check_output\nfolder_path = \"../input/ieee-fraud-detection/\"\nprint(check_output([\"ls\", folder_path]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загрузка первичных датасетов\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')\ntrain_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\ntest_identity = pd.read_csv(f'{folder_path}test_identity.csv')\ntest_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\nsub = pd.read_csv(f'{folder_path}sample_submission.csv')   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Наменование столбцов в train_identity\n\n# TransactionID,\n# id_01,id_02,id_03,id_04,id_05,id_06,id_07,id_08,id_09,id_10,id_11,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_23,id_24,id_25,id_26,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,id_35,id_36,id_37,id_38,\n# DeviceType,DeviceInfo\n\n# Первая строка: 2987004,0.0,70787.0,,,,,,,,,100.0,NotFound,,-480.0,New,NotFound,166.0,,542.0,144.0,,,,,,,,New,NotFound,Android 7.0,samsung browser 6.2,32.0,2220x1080,match_status:2,T,F,T,T,mobile,SAMSUNG SM-G892A Build/NRD90M\n\n# Наменование столбцов в train_transaction\n\n# TransactionID,isFraud,TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,dist1,dist2,P_emaildomain,R_emaildomain,\n\n# C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,\n# D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12,D13,D14,D15,\n# M1,M2,M3,M4,M5,M6,M7,M8,M9,\n# V1,V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20,V21,V22,V23,V24,V25,V26,V27,V28,V29,V30,V31,V32,V33,V34,V35,V36,V37,V38,V39,V40,V41,V42,V43,V44,V45,V46,V47,V48,V49,V50,\n# V51,V52,V53,V54,V55,V56,V57,V58,V59,V60,V61,V62,V63,V64,V65,V66,V67,V68,V69,V70,V71,V72,V73,V74,V75,V76,V77,V78,V79,V80,V81,V82,V83,V84,V85,V86,V87,V88,V89,V90,V91,V92,V93,V94,V95,V96,V97,V98,V99,V100,\n# V101,V102,V103,V104,V105,V106,V107,V108,V109,V110,V111,V112,V113,V114,V115,V116,V117,V118,V119,V120,V121,V122,V123,V124,V125,V126,V127,V128,V129,V130,V131,V132,V133,V134,V135,V136,V137,V138,V139,V140,\n# V141,V142,V143,V144,V145,V146,V147,V148,V149,V150,V151,V152,V153,V154,V155,V156,V157,V158,V159,V160,V161,V162,V163,V164,V165,V166,V167,V168,V169,V170,V171,V172,V173,V174,V175,V176,V177,V178,V179,V180,\n# V181,V182,V183,V184,V185,V186,V187,V188,V189,V190,V191,V192,V193,V194,V195,V196,V197,V198,V199,V200,V201,V202,V203,V204,V205,V206,V207,V208,V209,V210,V211,V212,V213,V214,V215,V216,V217,V218,V219,V220,\n# V221,V222,V223,V224,V225,V226,V227,V228,V229,V230,V231,V232,V233,V234,V235,V236,V237,V238,V239,V240,V241,V242,V243,V244,V245,V246,V247,V248,V249,V250,V251,V252,V253,V254,V255,V256,V257,V258,V259,V260,\n# V261,V262,V263,V264,V265,V266,V267,V268,V269,V270,V271,V272,V273,V274,V275,V276,V277,V278,V279,V280,V281,V282,V283,V284,V285,V286,V287,V288,V289,V290,V291,V292,V293,V294,V295,V296,V297,V298,V299,V300,\n# V301,V302,V303,V304,V305,V306,V307,V308,V309,V310,V311,V312,V313,V314,V315,V316,V317,V318,V319,V320,V321,V322,V323,V324,V325,V326,V327,V328,V329,V330,V331,V332,V333,V334,V335,V336,V337,V338,V339\n# Первая строка:2987000,0,86400,68.5,W,13926,,150.0,discover,142.0,credit,315.0,87.0,19.0,,,,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,2.0,0.0,1.0,1.0,14.0,,13.0,,,,,,,13.0,13.0,,,,0.0,T,T,T,M2,F,T,,,,\n# 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,,,,,,,,,,,,,,,,,,,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,\n# 0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,\n# 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,117.0,0.0,0.0,0.0,0.0,0.0,117.0,0.0,0.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n# 0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,117.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,117.0,0.0,0.0,0.0,0.0,,,,,,,,,,,,,,,,,,\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_transaction.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_identity.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Комбинация данных с помощью функции merge(), которая соединяет два набора данных (аналог join в SQL)\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\nprint(f'Датасет Train содержит {train.shape[0]} строк and {train.shape[1]} столбцов')\nprint(f'Датасет Test содержит {test.shape[0]} строк and {test.shape[1]} столбцов')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Итак, у нас есть два набора данных среднего размера с большим количеством столбцов. Train и test имеют примерно одинаковое количество строк","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Поскольку загруженные данные занимают много оперативной памяти, то удалим из памяти первично загруженные датасеты:\ndel train_identity, train_transaction, test_identity, test_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# дополнительнопринудительно вызывем сборщик мусора, который почистит память (примерно 3 гб):\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ✔ Исследование данных","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Из всех {train.shape[1]} столбцов датасета Train {train.isnull().any().sum()} столбцов с хотя бы одним пустым значением')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Подсчет различных наблюдений по каждому столбцу (по умолчанию игнорируем значения NaN, если нужно их учитывать, то nunique( self , axis = 0 , dropna = False)\none_value_cols = [col for col in train.columns if train[col].nunique() <= 1] \none_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]    \none_value_cols == one_value_cols_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Всего {len(one_value_cols)} столбцов в train с одним уникальным значением.')\nprint(f'Всего {len(one_value_cols_test)} столбцов в test с одним уникальным значением')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_count = train.isnull().sum()\nprint (missing_values_count[0:10])\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% пропущенных данных = \",(total_missing/total_cells) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del missing_values_count, total_cells, total_missing, one_value_cols, one_value_cols_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Промежуточные выводы:\n#   В большинстве столбцов отсутствуют данные \n#   Также есть столбцы с одним уникальным значением (или все отсутствуют). \n#   Есть много непрерывных переменных и некоторые категориальные. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Поиск категориальных и числовых признаков\n# Справочно типы в pandas: https://pbpython.com/pandas_dtypes.html\nnumerical_feats = train.dtypes[ (train.dtypes != \"object\") & (train.dtypes != \"category\") ].index\nnumerical_feats_kol = len(numerical_feats)\nprint(\"Количество числовых фичей в датасете train: \", numerical_feats_kol)\n\ncategorical_feats = train.dtypes[ (train.dtypes == \"object\") | (train.dtypes == \"category\") ].index\ncategorical_feats_kol = len(categorical_feats)\nprint(\"Количество категореальных фичей в датасете train: \", categorical_feats_kol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# установим формат, чтобы вывести на экран все названия фич (без ..)\n# Более подробный формат https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html\n#pd.set_option('display.max_rows', 1000)\n#pd.set_option('display.max_columns', 1000)\n\npd.set_option('display.width', 200)  # ширина выводимого экрана\npd.set_option('max_seq_items', 500)  # то из-чего перестало автоматически пропускать и ставить ..\n\nprint(\"Имена числовых фичей в датасете train:\")\nprint(train[numerical_feats].columns)\nprint(\"*\"*100)\nprint(\"Имена категореальных столбцов в датасете train:\")\nprint(train[categorical_feats].columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#для всех числовых фичей рассчитаем describe(), фичей много, поэтому сделаем разбивку:\ngr_kol = 50 # кол-во фичей за 1 проход\nn1 = 0\nfor i in tqdm_notebook(range (1,numerical_feats_kol // gr_kol + 2)):\n    n2 = i * gr_kol \n    if n2 > (numerical_feats_kol - 1):\n        n2 =  numerical_feats_kol - 1\n    cols = [numerical_feats[j] for j in range (n1,n2+1) ]\n    #print (cols)\n    \n    plot_data = pd.DataFrame(train[cols])\n\n    if 0: # для тестирования можно ограничить кол-во строк для экономии памяти и увеличения быстродействия\n        max_rows =1000    \n        plot_data = pd.DataFrame(plot_data[:max_rows])\n    \n    print(plot_data.describe())   \n    n1 = n2 +1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#для всех числовых фичей построим гистограммы. Фичей много, но при разбивке сделанной выше графики подключивыют, поэтому разбивать не будем (просчитывает долго)\nplot_data = pd.DataFrame(train[numerical_feats])\nif 0: # для тестрования можно ограничить кол-во строк для экономии памяти и увеличения быстродействия\n    max_rows =1000    \n    plot_data = pd.DataFrame(plot_data[:max_rows])\n\n_ = plot_data.hist(plot_data.columns, figsize=(60, 40))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Анализ отдельных фичей","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\ntime_val = train['TransactionDT'].values\n\nsns.distplot(time_val, ax=ax[0], color='r')\nax[0].set_title('Распределение TransactionDT', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])\n\nsns.distplot(np.log(time_val), ax=ax[1], color='b')\nax[1].set_title('Распеределение логарифма TransactionDT', fontsize=14)\nax[1].set_xlim([min(np.log(time_val)), max(np.log(time_val))])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\ntime_val = train.loc[train['isFraud'] == 1]['TransactionDT'].values\n\nsns.distplot(np.log(time_val), ax=ax[0], color='r')\nax[0].set_title('Распеределение логарифма TransactionDT, isFraud=1', fontsize=14)\nax[1].set_xlim([min(np.log(time_val)), max(np.log(time_val))])\n\ntime_val = train.loc[train['isFraud'] == 0]['TransactionDT'].values\n\nsns.distplot(np.log(time_val), ax=ax[1], color='b')\nax[1].set_title('Распеределение логарифма TransactionDT, isFraud=0', fontsize=14)\nax[1].set_xlim([min(np.log(time_val)), max(np.log(time_val))])\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TransactionDT'].plot(kind='hist',\n                                        figsize=(15, 5),\n                                        label='train',\n                                        bins=50,\n                                        title='Train против Test TransactionDT распределения')\ntest['TransactionDT'].plot(kind='hist',\n                                       label='test',\n                                       bins=50)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 10))\nc_features = [col for col in train[numerical_feats].columns if (col[:1] == \"c\") | (col[:1] == \"C\")] \nuniques = [len(train[col].unique()) for col in c_features]\nsns.set(font_scale=1.2)\nax = sns.barplot(c_features, uniques, log=True)\nax.set(xlabel='Признаки', ylabel='логарифм(кол-во уникальных)', title='Число уникальных значений фичей TRAIN')\nfor p, uniq in zip(ax.patches, uniques):\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height + 10,\n            uniq,\n            ha=\"center\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['id_01'].unique())\nprint(len(train['id_01'].unique())-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train['id_01'], bins=77); #bins - если задано целое число, бины + 1 ребро бина рассчитываются и возвращаются в соответствии с numpy.histogram\nplt.title('Распределение значений признака id_01');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# id_01 имеет интересное распределение: у него 77 уникальных неположительных значений.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим список из количеств уникальных значений признка id_03\n# полученный список будет в порядке убывания, так что первый элемент является наиболее часто встречающимся элементом. Исключает значения NA по умолчанию.\n# normalize: логический, по умолчанию False, Если True, то возвращаемый объект будет содержать относительные частоты уникальных значений\ntrain['id_03'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# d_03 содержит 88% пропущенных значений, а 98% значений либо отсутствуют, либо равны 0.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['id_11'].value_counts(dropna=False, normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 22% значений в id_11 равны 100, а 76% отсутствуют. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train['id_07']);\nplt.title('Распределение значений признака id_07');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# за основу взята функция из ноутбука https://www.kaggle.com/jesucristo/fraud-complete-eda\n# который в свою очередь ссылается на ноутбук https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n# ПРЕДУПРЕЖДЕНИЕ! Это может повредить данные\ndef reduce_mem_usage2(df):\n    # переберите все столбцы кадра данных и измените тип данных чтобы уменьшить использование памяти.      \n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Использование памяти датафрейма составляет {:.2f} MB'.format(start_mem))\n    \n    for col in tqdm_notebook(df.columns):\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Использование памяти после оптимизации составляет: {:.2f} MB'.format(end_mem))\n    print('Экономия составила {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# для дальнейшего анализа обработаем оба датасета train и test для сокращения пямяти и создадим один объедененный датасет для преобразования фичей и создания новых","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для чистоты удалим ранее созданные датасеты и загрузим из первичных файлов\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загрузка из первичных файлов\n\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')\ntrain_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\ntest_identity = pd.read_csv(f'{folder_path}test_identity.csv')\ntest_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# клеточная магия %% должна начинаться с первой строки по соглашению. Вот почему она называются клеточной магией 😊\n# Выполнение пунктов ниже займет некоторое время но сократит использование памяти\ngc.collect()\ntrain_tr = reduce_mem_usage2(train_transaction)\ntrain_id = reduce_mem_usage2(train_identity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngc.collect()\ntest_tr = reduce_mem_usage2(test_transaction)\ntest_id = reduce_mem_usage2(test_identity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity,train_transaction, test_identity, test_transaction\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим три датасета: train, test и их объединение dataset\ntrain = pd.merge(train_tr, train_id, on='TransactionID', how='left')\ntest = pd.merge(test_tr, test_id, on='TransactionID', how='left')\ndataset = pd.concat([train, test], axis=0, sort=False).reset_index(drop=True)\ntrain_len = len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_tr, train_id, test_tr, test_id\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Числовые фичи\nnum_cols = [col for col in dataset.columns if dataset[col].dtype in ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']]\ndataset[num_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Категориальные фичи\ncat_cols = [col for col in dataset.columns if dataset[col].dtype not in ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']]\ndataset[cat_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# по всем категориальным фичам сгруппируем значения и посчитаем среднее isFraud \nfor col in cat_cols:\n    print('-'*25+'['+col+']'+'-'*25)\n    print(dataset[[col, 'isFraud']].groupby(col).mean()*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразования фичей и создания новых","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# преобразуем TransactionDT в стандартную дату и создадим новую фичу Date\nimport datetime\n\ngenesis = datetime.datetime.strptime('2019-01-01', '%Y-%m-%d')\ndataset['Date'] = dataset['TransactionDT'].apply(lambda x : genesis+datetime.timedelta(seconds=x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим новые фичи:\ndataset['Weekdays'] = dataset['Date'].dt.dayofweek\ndataset['Days'] = dataset['Date'].dt.day\ndataset['Hours'] = dataset['Date'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n\ng = sns.barplot(dataset[dataset.index<train_len].Weekdays, train.isFraud, ax=ax[0])\nax[0].set_title('Fraud Charges by Weekdays')\nplt.setp(g.get_xticklabels(), visible=False)\n\ng = sns.barplot(dataset[dataset.index<train_len].Days, train.isFraud, ax=ax[1])\nax[1].set_title('Fraud Charges by Days')\nplt.setp(g.get_xticklabels(), visible=False)\n\ng = sns.barplot(dataset[dataset.index<train_len].Hours, train.isFraud, ax=ax[2])\nax[2].set_title('Fraud Charges by Hours')\nplt.setp(g.get_xticklabels(), visible=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# можно увидидеть явную зависимость от часов и дней недели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop('Date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обработка редких или пропущенных почтовых доменов","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset['P_emaildomain'].value_counts().head())\nprint('Data type : {}'.format(dataset['P_emaildomain'].dtype))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# объеденим значения нескольких почтовых доменов в значение другие (etc)\ndataset.loc[(dataset.P_emaildomain!='gmail.com')&(dataset.P_emaildomain!='yahoo.com')&(dataset.P_emaildomain!='hotmail.com')&(dataset.P_emaildomain!='anonymous.com')&(dataset.P_emaildomain!='aol.com'), 'P_emaildomain'] = 'etc'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(dataset['P_emaildomain'])\nfig = plt.gcf()\nfig.set_size_inches(10, 4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset['R_emaildomain'].value_counts().head())\nprint('Data type : {}'.format(dataset['P_emaildomain'].dtype))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(dataset['R_emaildomain'])\nfig = plt.gcf()\nfig.set_size_inches(10, 4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Анализ операционок","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_os = dataset[['id_30', 'isFraud']].groupby(['id_30']).mean().sort_values(by=['isFraud'], ascending=False).head(10)\ntop_os.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вывод: обвинения в мошенничестве в основном использовались мобильными устройствами или устройствами, работающими под управлением редких операционных систем (обозначенных другими)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_os = list(top_os.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_os = list(dataset['id_30'].unique())\nsafe_os = [os for os in all_os if os not in top_os]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.id_30.replace(safe_os, 'etc', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['id_30', 'isFraud']].groupby(['id_30']).mean().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Анализ браузеров","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_browsers = dataset[['id_31', 'isFraud']].groupby(['id_31']).mean().sort_values(by=['isFraud'], ascending=False).head(10)\ntop_browsers.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_browsers = list(top_browsers.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_browsers = list(dataset['id_31'].unique())\nsafe_browsers = [brw for brw in all_browsers if brw not in top_browsers]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.id_31.replace(safe_browsers, 'etc', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['id_31', 'isFraud']].groupby('id_31').mean().sort_values(by='isFraud', ascending=False).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Анализ размер экрана\n# размеры экрана могут быть факторами для отслеживания определенных типов устройств","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_scrsz = dataset[['id_33', 'isFraud']].groupby(['id_33']).mean().sort_values(by=['isFraud'], ascending=False).head(15)\ntop_scrsz.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_scrsz = list(top_scrsz.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_scrsz = dataset['id_33'].unique()\nsafe_scrsz = [s for s in all_scrsz if s not in top_scrsz]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.id_33.replace(safe_scrsz, 'etc', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['id_33', 'isFraud']].groupby('id_33').mean().sort_values(by='isFraud', ascending=False).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Анализ информации об устройстве","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_dev = dataset[['DeviceInfo', 'isFraud']].groupby(['DeviceInfo']).mean().sort_values(by='isFraud', ascending=False).head(10)\ntop_dev.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_dev = list(top_dev.loc[top_dev.isFraud>0.5].index)\ntop_dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_dev = dataset['DeviceInfo'].unique()\nsafe_dev = [dev for dev in all_dev if dev not in top_dev]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.DeviceInfo.replace(safe_dev, 'etc', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['DeviceInfo', 'isFraud']].groupby('DeviceInfo').mean().sort_values(by=['isFraud'], ascending=False).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Векторизация: one-hot\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_num = dataset.select_dtypes(exclude=['object'])\ndataset_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_cat = dataset.select_dtypes(include=['object'])\ndataset_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Added Columns : {}'.format(sum(dataset_cat.nunique().values)-len(dataset_cat.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_cat_new = pd.get_dummies(dataset_cat) #Преобразовать категориальные признаки\ndataset = pd.concat([dataset_num, dataset_cat_new], axis=1) #сформируем новый датасет\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop('TransactionID', axis=1, inplace=True) # удалим TransactionID\ndel dataset_num, dataset_cat\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Моделирование","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подготовка данных","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# из обработанного датасета сформируем train и test\ntrain = dataset[:train_len]\ntest = dataset[train_len:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сформируем датасеты для моделирования\ny = train.isFraud\nX = train.drop('isFraud', axis=1)\ntest_y = test.isFraud\ntest_X = test.drop('isFraud', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in X.columns:\n    if X[f].dtype=='object' or test_X[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X[f].values) + list(test_X[f].values))\n        X[f] = lbl.transform(list(X[f].values))\n        test_X[f] = lbl.transform(list(test_X[f].values))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Light Gradient Boosting Machine(LGBM) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport lightgbm as lgbm\n\nhyper = {\n    'num_leaves' : 500,\n    'min_child_weight': 0.03,\n    'feature_fraction': 0.4,\n    'bagging_fraction': 0.4,\n    'min_data_in_leaf': 100,\n    'objective': 'binary',\n    'max_depth': 6,\n    'learning_rate': 0.05,\n    'boosting_type': 'gbdt',\n    'bagging_seed': 10,\n    'metric': 'auc',\n    'verbosity': 0,\n    'reg_alpha': 0.4,\n    'reg_lambda': 0.6,\n    'random_state': 0\n}\n\ndtrain = lgbm.Dataset(train_X, label=train_y)\ndvalid = lgbm.Dataset(val_X, label=val_y)\nmodel = lgbm.train(hyper, dtrain, 10000, valid_sets=[dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500) #лучший резльтат дает 10000, для ускорения можно зададим 200\n# model = lgbm.train(hyper, dtrain, 200, valid_sets=[dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500) #лучший резльтат дает 10000, для ускорения можно зададим 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_lgb = model.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_X, val_X, train_y, val_y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LGBM дает отличные результаты, применение других методов вряд ли их улучшат + они выполняются очень долго\n\nPr_Other = 0 # 0 - не применять другие методы, 1 - применять","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pr_Test = 0\nif Pr_Test:\n    del y, X, test_y, test_X \n    gc.collect()\n    y = train.isFraud\n    X = train.drop('isFraud', axis=1)\n    test_y = test.isFraud\n    test_X = test.drop('isFraud', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Pr_Other:\n    # применение других методов требует более глубокую подготовку данных\n    \n    #дропнем оставшиеся категориальные фичи\n    categorical_feats = X.dtypes[ (train.dtypes == \"object\") | (train.dtypes == \"category\") ].index\n    categorical_feats_kol = len(categorical_feats)\n    X.drop(categorical_feats, axis=1, inplace=True)\n    test_X.drop(categorical_feats, axis=1, inplace=True)\n    \n    missing_values_count = X.isnull().sum()\n    print (missing_values_count[0:10])\n    total_cells = np.product(X.shape)\n    total_missing = missing_values_count.sum()\n    print (\"% до fillna пропущенных данных = \",(total_missing/total_cells) * 100)\n    \n    X.fillna(-1,inplace=True)\n    test_X.fillna(-1,inplace=True)\n    \n    missing_values_count = X.isnull().sum()\n    print (missing_values_count[0:10])\n    total_cells = np.product(X.shape)\n    total_missing = missing_values_count.sum()\n    print (\"% после fillna пропущенных данных = \",(total_missing/total_cells) * 100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Pr_Other:\n    # Нормулизуем D фичи\n    for i in tqdm_notebook(range(1,16)):\n        if i in [1,2,3,5,9]: continue\n        X['D'+str(i)] =  X['D'+str(i)] - X.TransactionDT/np.float32(24*60*60)\n        test_X['D'+str(i)] = test_X['D'+str(i)] - test_X.TransactionDT/np.float32(24*60*60) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 0 & Pr_Other:\n    # для других методов дропнем часть информации для освобождения памяти\n    print(f\"До удаления, посмотрим топ фичей с пропущенными значениями:\\n{X.isna().sum().sort_values(ascending = False).head(5)}\\n\")\n    thresh = 0.80 #Из-за множества значений NA (%), то что больше 80% - это слишком много - шум\n    X_less_nas = X.dropna(thresh=X.shape[0]*(1-thresh), axis='columns')\n    cols_dropped  = list(set(X.columns)-set(X_less_nas.columns))\n    test_X.drop(cols_dropped, axis=1, inplace=True)\n    print(f\"После удаления, топ фичей с пропущенными значениями:\\n{X_less_nas.isna().sum().sort_values(ascending = False).head(5)}\")\n    print(f\"\\nКол-во удаленных фичей = {len(set(X.columns)-set(X_less_nas.columns))}, or {len(set(X.columns)-set(X_less_nas.columns))/len(X.columns)*100:.2f}% фичей\")\n    X = X_less_nas\n    del X_less_nas\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 0 & Pr_Other:\n    cols = ['ProductCD', 'card4', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType']\n    for col in cols:\n        print('-'*25+'['+col+']'+'-'*25)\n        print(dataset[[col, 'isFraud']].groupby(col).mean()*100)\n    X.drop(cols,axis=1, inplace=True)\n    test_X.drop(cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pr_SVC = 0\nif Pr_SVC & Pr_Other: # очень долго выполняется\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.svm import SVC\n    param_grid = {'C': [0.1,10, 100, 1000,5000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n    svc_grid = GridSearchCV(SVC(), param_grid, cv=10, refit=True, verbose=1, scoring='roc_auc')\n    svc_grid.fit(X,y)\n    sc_svc = get_best_score(svc_grid)\n    pred_all_svc = svc_grid.predict(test_X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pr_knn = 0 # очень долго выполняется, память переполняется\nif Pr_knn & Pr_Other:\n    from sklearn.neighbors import KNeighborsClassifier\n    knn = KNeighborsClassifier()\n    #leaf_range = list(range(3, 15, 1))\n    #k_range = list(range(1, 15, 1))\n    leaf_range = list(range(3, 4, 1))\n    k_range = list(range(1, 2, 1))\n    weight_options = ['uniform', 'distance']\n    param_grid = dict(leaf_size=leaf_range, n_neighbors=k_range, weights=weight_options)\n    print(param_grid)\n\n    knn_grid = GridSearchCV(knn, param_grid, cv=10, verbose=1, scoring='roc_auc')\n    knn_grid.fit(X, y)\n    sc_knn = get_best_score(knn_grid)\n    pred_all_knn = knn_grid.predict(test_X)\n    print('KNN: ', roc_auc_score(test_y, pred_all_knn))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pr_Tree = 0 # очень долго выполняется, память не переполняется\nif Pr_Tree & Pr_Other:\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.model_selection import GridSearchCV\n\n    dtree = DecisionTreeClassifier()\n    param_grid = {'min_samples_split': [4,7,10,12]}\n    dtree_grid = GridSearchCV(dtree, param_grid, cv=10, refit=True, verbose=1)\n    dtree_grid.fit(X,y)\n    pred_all_dtree = dtree_grid.predict(test_X)\n    print('Tree: ', roc_auc_score(test_y, pred_all_dtree))    \n    #print(dtree_grid.best_score_)\n    #print(dtree_grid.best_params_)\n    #print(dtree_grid.best_estimator_)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sub \nsubmission['isFraud'] = np.nan\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['isFraud'] = preds_lgb\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission_demin_3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[ sub['isFraud']>0.99 , 'isFraud'] = 1\nb = plt.hist(sub['isFraud'], bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del sub\ngc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}