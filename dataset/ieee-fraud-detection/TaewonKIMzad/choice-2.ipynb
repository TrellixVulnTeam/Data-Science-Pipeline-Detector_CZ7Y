{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 서론 : EDA를 시작하기에 앞서서 \n본 프로젝트의 목적은 EDA를 통해 거래 데이터를 분석 파악한 뒤, 적절한 데이터 전처리를 통해 데이터에서 유의미한 인사이트를 얻을 수 있도록 가공하고, 머신러닝 모델 학습을 통해 unseen data의 거래 사기 예측을 효과적으로 수행하는 것이다.\n\n해당 데이터셋은 개우 많은 column, 즉 차원을 지니고 있으므로 적절한 판단을 통해 결측치를 처리하고 분석에 필요 없는 column을 버려야 한다.\n따라서 EDA의 목적은 위에 기재한 것으로 둔다.","metadata":{"papermill":{"duration":0.044436,"end_time":"2021-09-12T16:57:45.435921","exception":false,"start_time":"2021-09-12T16:57:45.391485","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 라이브러리 임포트","metadata":{"papermill":{"duration":0.043737,"end_time":"2021-09-12T16:57:45.524624","exception":false,"start_time":"2021-09-12T16:57:45.480887","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install -U vega_datasets notebook vega\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy as sp\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Standard plotly imports\n#import plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\n#import cufflinks\n#import cufflinks as cf\nimport plotly.figure_factory as ff\n\n# Using plotly + cufflinks in offline mode\ninit_notebook_mode(connected=True)\n#cufflinks.go_offline(connected=True)\n\n# Preprocessing, modelling and evaluating\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n## Hyperopt modules\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn import metrics\nimport time\nimport lightgbm as lgb\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR, SVR\n\nfrom sklearn.metrics import mean_absolute_error\npd.options.display.precision = 15\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\nfrom sklearn import linear_model\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport eli5\nimport shap\nfrom IPython.display import HTML\nimport json\nimport altair as alt\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nalt.renderers.enable('notebook')\n\n%env JOBLIB_TEMP_FOLDER=/tmp\n\nimport json\nfrom numba import jit\n\n\nfrom tqdm import tqdm_notebook\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\n\nfrom itertools import product\n\nimport altair as alt\nfrom IPython.display import HTML\n\n\nimport os\nimport gc\nprint(os.listdir(\"../input\"))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":4.849997,"end_time":"2021-09-12T16:57:50.417646","exception":false,"start_time":"2021-09-12T16:57:45.567649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:06:15.144836Z","iopub.execute_input":"2021-09-13T11:06:15.145862Z","iopub.status.idle":"2021-09-13T11:06:40.838993Z","shell.execute_reply.started":"2021-09-13T11:06:15.145728Z","shell.execute_reply":"2021-09-13T11:06:40.838056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 임포트","metadata":{"papermill":{"duration":0.044289,"end_time":"2021-09-12T16:57:50.506617","exception":false,"start_time":"2021-09-12T16:57:50.462328","status":"completed"},"tags":[]}},{"cell_type":"code","source":"folder_path = '../input/ieee-fraud-detection/'\ndf_id = pd.read_csv(f'{folder_path}/train_identity.csv')\ndf_trans = pd.read_csv(f'{folder_path}train_transaction.csv')\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')\ntest_transaction = pd.read_csv(f'{folder_path}test_transaction.csv' )\ntest_identity = pd.read_csv(f'{folder_path}test_identity.csv')\n\ntrain = pd.merge(df_trans, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","metadata":{"papermill":{"duration":49.697515,"end_time":"2021-09-12T16:58:40.248172","exception":false,"start_time":"2021-09-12T16:57:50.550657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:06:40.840944Z","iopub.execute_input":"2021-09-13T11:06:40.841671Z","iopub.status.idle":"2021-09-13T11:07:54.568353Z","shell.execute_reply.started":"2021-09-13T11:06:40.841638Z","shell.execute_reply":"2021-09-13T11:07:54.567642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(f'{folder_path}sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:07:54.569536Z","iopub.execute_input":"2021-09-13T11:07:54.570342Z","iopub.status.idle":"2021-09-13T11:07:54.746066Z","shell.execute_reply.started":"2021-09-13T11:07:54.570295Z","shell.execute_reply":"2021-09-13T11:07:54.74533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 함수 해석\ndef resumetable(df):\n* 데이터셋의 Shape를 확인하고, 데이터 type를 확인하며, 인덱스를 재정렬하고, 결측치 Null값의 개수를 확인하고, unique한 value의 갯수를 확인하고, 첫번째에서부터 세번째까지의 value를 확인한다. 이렇게 우리는 개괄적인 데이터셋의 형태를 확인할 수 있다. \n\n\ndef reduce_mem_usage(df, verbose=True):\n* verbose=True 는 함수 수행시 발생하는 상세한 정보들을 표준 출력으로 자세히 내보낼 것인가를 나타낸다. 이 함수의 for col in df.columns: 를 통해 df[col]의 min 과 max를 확인하고, 적절한 대소 비교를 통해 데이터타입을 변환한다.\n\ndef CalcOutliers(df_num): \n* 아웃라이어를 계산하는 함수를 만든다. array를 전달받아 평균값과 표준편차 값을 확인하고, 그것을 upper과 lower로 나누어 각각 계산한다. cut line의 값을 임의로 설정할 수도 있지만, 일단은 3으로 둔다.","metadata":{"papermill":{"duration":0.04326,"end_time":"2021-09-12T16:58:40.335972","exception":false,"start_time":"2021-09-12T16:58:40.292712","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# datatype shape 찍는 함수\ndef resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary\n\n\n## Dataframe size 줄이는 함수\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n\n### 아웃라이어 관리 함수\ndef CalcOutliers(df_num): \n\n    # array의 평균 및 표준 계산\n    data_mean, data_std = np.mean(df_num), np.std(df_num)\n\n    # cut line 값을 설정한다.\n    # 이 value값을 임의로 변경할 수도 있다.\n    cut = data_std * 3\n\n    #더 높은 cut 및 더 낮은 cut 계산\n    lower, upper = data_mean - cut, data_mean + cut\n\n    # lower, higher and total 아웃라이어 값이 담긴 array를 만든다. \n    outliers_lower = [x for x in df_num if x < lower]\n    outliers_higher = [x for x in df_num if x > upper]\n    outliers_total = [x for x in df_num if x < lower or x > upper]\n\n    # 아웃라이어를 제외한 array\n    outliers_removed = [x for x in df_num if x > lower and x < upper]\n    \n    print('Identified lowest outliers: %d' % len(outliers_lower)) \n    print('Identified upper outliers: %d' % len(outliers_higher)) \n    print('Total outlier observations: %d' % len(outliers_total)) \n    print('Non-outlier observations: %d' % len(outliers_removed)) \n    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4))\n    \n    return","metadata":{"papermill":{"duration":0.066219,"end_time":"2021-09-12T16:58:40.445666","exception":false,"start_time":"2021-09-12T16:58:40.379447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:07:54.748354Z","iopub.execute_input":"2021-09-13T11:07:54.74869Z","iopub.status.idle":"2021-09-13T11:07:54.7743Z","shell.execute_reply.started":"2021-09-13T11:07:54.748651Z","shell.execute_reply":"2021-09-13T11:07:54.773206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"앞서 만든 함수를 활용해 데이터셋의 메모리를 축소한다.","metadata":{"papermill":{"duration":0.042954,"end_time":"2021-09-12T16:58:40.532038","exception":false,"start_time":"2021-09-12T16:58:40.489084","status":"completed"},"tags":[]}},{"cell_type":"code","source":"## 메모리 축소\ndf_trans = reduce_mem_usage(df_trans)\ndf_id = reduce_mem_usage(df_id)\ntest_transaction = reduce_mem_usage(test_transaction)\ntest_identity = reduce_mem_usage(test_identity)","metadata":{"papermill":{"duration":183.161681,"end_time":"2021-09-12T17:01:43.736917","exception":false,"start_time":"2021-09-12T16:58:40.575236","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:07:54.775636Z","iopub.execute_input":"2021-09-13T11:07:54.775918Z","iopub.status.idle":"2021-09-13T11:11:05.750591Z","shell.execute_reply.started":"2021-09-13T11:07:54.775852Z","shell.execute_reply":"2021-09-13T11:11:05.749553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resumetable(df_trans)[:25]","metadata":{"papermill":{"duration":12.22167,"end_time":"2021-09-12T17:01:56.006439","exception":false,"start_time":"2021-09-12T17:01:43.784769","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:05.752011Z","iopub.execute_input":"2021-09-13T11:11:05.752279Z","iopub.status.idle":"2021-09-13T11:11:16.869918Z","shell.execute_reply.started":"2021-09-13T11:11:05.752251Z","shell.execute_reply":"2021-09-13T11:11:16.869052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 위를 통해 얻을 수 있는 인사이트 \nresumetable 앞서 만든 함수를 통해 데이터의 개괄을 확인해보았다.\n어떤 인사이트를 가지고 알 수 있는지 가볍게 정리해보자.\n\n* resumetable 함수를 통해,  column의 데이터타입에 object type이 섞여 있다는 것을 알 수 있다. \n* 또한 missing 항목을 보면, TransactionID, isFraud, TransactionDT, TransactionAmt, ProductCD, card1, 마스킹된 Cn 피쳐들에 결측치가 없다는 것도 알 수 있다.\n* TransactionID의 모든 value는 전부 unique하다는 것을 알 수 있다.\n* ProductCD의 경우, 데이터가 무엇을 뜻하는지 알기 어렵다는 것, 즉 실효성 있는 데이터가 아니라는 추측을 할 수 있다.\n* P_emaildomain과 R_emaildomain의 경우, 적절한 Value값 통일이 필요하다는 것을 알 수 있다.\n* 하지만 column의 수가 매우 많으므로, 이런 방식으로 모든 피쳐에 대해 확인하기에는 어려움이 있다고 사료된다.","metadata":{"papermill":{"duration":0.047136,"end_time":"2021-09-12T17:01:56.101874","exception":false,"start_time":"2021-09-12T17:01:56.054738","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#위를 통해 알 수 있는 문제점\n데이터에서 얻을 수 있는 모든 거래정보(transactions) 에 대해, 1:1로 해당되는 identity 정보가 있지 않다.","metadata":{"papermill":{"duration":0.046291,"end_time":"2021-09-12T17:01:56.195073","exception":false,"start_time":"2021-09-12T17:01:56.148782","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Target 값의 분포 확인하기\n본 프로젝트값을 통해 예측해내야 하는 y값. Target 에 대해 몇 개의 플롯을 그려 확인해본다. 해당 데이터셋에서는 IsFraud와 동일하다.","metadata":{"papermill":{"duration":0.046931,"end_time":"2021-09-12T17:01:56.28816","exception":false,"start_time":"2021-09-12T17:01:56.241229","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans['TransactionAmt'] = df_trans['TransactionAmt'].astype(float)\ntotal = len(df_trans)\ntotal_amt = df_trans.groupby(['isFraud'])['TransactionAmt'].sum().sum()\nplt.figure(figsize=(16,6))\n\nplt.subplot(121)\ng = sns.countplot(x='isFraud', data=df_trans, )\ng.set_title(\"Fraud Transactions Distribution \\n# 0: No Fraud | 1: Fraud #\", fontsize=22)\ng.set_xlabel(\"Is fraud?\", fontsize=18)\ng.set_ylabel('Count', fontsize=18)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=15) \n\nperc_amt = (df_trans.groupby(['isFraud'])['TransactionAmt'].sum())\nperc_amt = perc_amt.reset_index()\nplt.subplot(122)\ng1 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=perc_amt)\ng1.set_title(\"% Total Amount in Transaction Amt \\n# 0: No Fraud | 1: Fraud #\", fontsize=22)\ng1.set_xlabel(\"Is fraud?\", fontsize=18)\ng1.set_ylabel('Total Transaction Amount Scalar', fontsize=18)\nfor p in g1.patches:\n    height = p.get_height()\n    g1.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total_amt * 100),\n            ha=\"center\", fontsize=15) \n    \nplt.show()","metadata":{"papermill":{"duration":0.476404,"end_time":"2021-09-12T17:01:56.810986","exception":false,"start_time":"2021-09-12T17:01:56.334582","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:16.871372Z","iopub.execute_input":"2021-09-13T11:11:16.871642Z","iopub.status.idle":"2021-09-13T11:11:17.420484Z","shell.execute_reply.started":"2021-09-13T11:11:16.871613Z","shell.execute_reply":"2021-09-13T11:11:17.419779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 가볍게 얻을 수 있는 인사이트\n\n* 데이터셋 자체에서 불균형을 확인할 수 있다. 다시 말해, Isfraud 값이 압도적으로 적다.\n* 전체 거래 분포도에서 데이터셋의 fraud 분포는 3.5%이다.\n* 백분율의 금액이 총 거래량 금액의 3.5%보다 높은지 낮은지를 알아보는 것이 흥미로울 것 같다.\n* % Total Transactions Amount의 fraud와 전체 거래에서의 fraud를 살펴보면, 비슷한 %를 가지고 있다는 것을 알 수 있다.\n* 여러모로 거래량 항목에 대해 더 자세히 살펴볼 필요가 있다.","metadata":{"papermill":{"duration":0.04785,"end_time":"2021-09-12T17:01:56.90735","exception":false,"start_time":"2021-09-12T17:01:56.8595","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 문제점 하나 더\n\n우리가 제공받은 것은 Class imbalance한 데이터셋이다.\n이 데이터 프레임을 예측 모델 및 분석의 기반으로 사용할 경우 많은 오류가 발생할 수 있으며, 대부분의 거래가 Fraud가 아니라고 예측할 확률이 높다. ","metadata":{"papermill":{"duration":0.047757,"end_time":"2021-09-12T17:01:57.002887","exception":false,"start_time":"2021-09-12T17:01:56.95513","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Transaction Amount의 분위 확인\n거래 금액을 Ploting 하기 전에 Transaction Amount의 분위수를 확인해보자.","metadata":{"papermill":{"duration":0.047385,"end_time":"2021-09-12T17:01:57.097937","exception":false,"start_time":"2021-09-12T17:01:57.050552","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans['TransactionAmt'] = df_trans['TransactionAmt'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(df_trans['TransactionAmt'].quantile([.01, .025, .1, .25, .5, .75, .9, .975, .99]))","metadata":{"papermill":{"duration":0.080246,"end_time":"2021-09-12T17:01:57.225866","exception":false,"start_time":"2021-09-12T17:01:57.14562","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:17.421736Z","iopub.execute_input":"2021-09-13T11:11:17.422746Z","iopub.status.idle":"2021-09-13T11:11:17.454768Z","shell.execute_reply.started":"2021-09-13T11:11:17.4227Z","shell.execute_reply":"2021-09-13T11:11:17.453788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_trans['TransactionDT'].plot(kind='hist',\n                                        figsize=(15, 5),\n                                        label='train',\n                                        bins=50,\n                                        title='Train vs Test TransactionDT distribution')\ntest_transaction['TransactionDT'].plot(kind='hist',\n                                       label='test',\n                                       bins=50)\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.510876,"end_time":"2021-09-12T17:01:57.787075","exception":false,"start_time":"2021-09-12T17:01:57.276199","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:17.456076Z","iopub.execute_input":"2021-09-13T11:11:17.45632Z","iopub.status.idle":"2021-09-13T11:11:18.068188Z","shell.execute_reply.started":"2021-09-13T11:11:17.456294Z","shell.execute_reply":"2021-09-13T11:11:18.06711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train 과 test의 거래 일수 (transaction dates) 가 겹치지 않는 것 같으며, 이 데이터셋을 제대로 파악하고 validation 하기 위해서시간 기반으로 데이터셋을 분할해야 한다. 이 내용은 https://www.kaggle.com/robikscube/ieee-fraud-detection-first-look-and-eda 에서도 확인할 수 있다. 두 데이터셋 사이에는 대략 30일의 간격이 있음을 알 수 있다.","metadata":{"papermill":{"duration":0.047119,"end_time":"2021-09-12T17:01:57.882519","exception":false,"start_time":"2021-09-12T17:01:57.8354","status":"completed"},"tags":[]}},{"cell_type":"code","source":"del  train_identity,test_identity, test_transaction","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:11:18.071211Z","iopub.execute_input":"2021-09-13T11:11:18.071488Z","iopub.status.idle":"2021-09-13T11:11:18.101597Z","shell.execute_reply.started":"2021-09-13T11:11:18.071457Z","shell.execute_reply":"2021-09-13T11:11:18.10063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transaction Amount의 value값 분포 확인","metadata":{"papermill":{"duration":0.046735,"end_time":"2021-09-12T17:01:57.977077","exception":false,"start_time":"2021-09-12T17:01:57.930342","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize=(16,12))\nplt.subplot(222)\ng1 = sns.distplot(np.log(df_trans['TransactionAmt']))\ng1.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Probability\", fontsize=15)\n\nplt.figure(figsize=(16,12))\nplt.subplot(212)\ng4 = plt.scatter(range(df_trans[df_trans['isFraud'] == 0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng4 = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                 label='Fraud', alpha=.2)\ng4= plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\ng4 = plt.xlabel(\"Index\")\ng4 = plt.ylabel(\"Amount Distribution\", fontsize=15)\ng4 = plt.legend()\n\nplt.figure(figsize=(16,12))\n\nplt.subplot(321)\ng = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]), \n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                label='isFraud', alpha=.4)\nplt.title(\"FRAUD - Transaction Amount ECDF\", fontsize=18)\nplt.xlabel(\"Index\")\nplt.ylabel(\"Amount Distribution\", fontsize=12)\n\nplt.subplot(322)\ng1 = plt.scatter(range(df_trans[df_trans['isFraud'] == 0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng1= plt.title(\"NO FRAUD - Transaction Amount ECDF\", fontsize=18)\ng1 = plt.xlabel(\"Index\")\ng1 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n\nplt.suptitle('Individual ECDF Distribution', fontsize=22)\n\nplt.show()","metadata":{"papermill":{"duration":17.496686,"end_time":"2021-09-12T17:02:15.521702","exception":false,"start_time":"2021-09-12T17:01:58.025016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:18.103078Z","iopub.execute_input":"2021-09-13T11:11:18.103386Z","iopub.status.idle":"2021-09-13T11:11:34.107612Z","shell.execute_reply.started":"2021-09-13T11:11:18.103347Z","shell.execute_reply":"2021-09-13T11:11:34.107024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Transaction Values Distribution 이라는 이름으로 distplot을 생성한다.\n* Transaction Amount에 로그를 취해 본 분포와, 전체적인  FRAUD와 NO FRAUD의 분포 그래프를 그려 확인해본다.\n* FRAUD의 거래 양 분포와 NO FRAUD의 거래 양 분포도 대략적으로 알 수 있었다.\n\n아래의 3 개 그래프는 경험적 누적분포 함수 ECDF를 썼으며, 서로 다른 표본들의 분포를 비교할 때 많이 사용하고, 각 집단의 백분위를 추정할 수 있다는 장점을 가졌다.\n\n# 위를 통해 얻어낼 수 있는 인사이트\n* 거래량에 log를 취한 그래프의 모양이 굉장히 예쁘고 바람직하게 생겼다. 어쩌면, 대회 주최측에서는 어느 정도 가공된 데이터를 제공한 것일지도 모른다.\n* Fraud, 즉 사기 금액의 액수 분포는 꽤 한정적이다. 최고한도가 3000을 조금 웃도는 수준에서 머물고, 가끔 이례적으로 5000까지를 찍고 있다.","metadata":{"papermill":{"duration":0.050125,"end_time":"2021-09-12T17:02:15.622801","exception":false,"start_time":"2021-09-12T17:02:15.572676","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Fraud and No Fraud 의 분위수 보기","metadata":{"papermill":{"duration":0.050356,"end_time":"2021-09-12T17:02:15.723319","exception":false,"start_time":"2021-09-12T17:02:15.672963","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(pd.concat([df_trans[df_trans['isFraud'] == 1]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 df_trans[df_trans['isFraud'] == 0]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Fraud', \"No Fraud\"]))","metadata":{"papermill":{"duration":1.471291,"end_time":"2021-09-12T17:02:17.244671","exception":false,"start_time":"2021-09-12T17:02:15.77338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:34.108852Z","iopub.execute_input":"2021-09-13T11:11:34.109184Z","iopub.status.idle":"2021-09-13T11:11:34.843949Z","shell.execute_reply.started":"2021-09-13T11:11:34.109138Z","shell.execute_reply":"2021-09-13T11:11:34.843385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transaction Amount의 아웃라이어\n앞서 정의한 함수를 통해 위에서 확인한 분포값의 이상치, 다시 말해 아웃라이어 구간을 확인해보기로 한다.\n\n참고로, 평균std이 표준값mean의 3배보다 높은 outlier values값을 가진다.","metadata":{"papermill":{"duration":0.051095,"end_time":"2021-09-12T17:02:17.350416","exception":false,"start_time":"2021-09-12T17:02:17.299321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"CalcOutliers(df_trans['TransactionAmt'])","metadata":{"papermill":{"duration":0.475027,"end_time":"2021-09-12T17:02:17.875701","exception":false,"start_time":"2021-09-12T17:02:17.400674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:34.844946Z","iopub.execute_input":"2021-09-13T11:11:34.845323Z","iopub.status.idle":"2021-09-13T11:11:35.326894Z","shell.execute_reply.started":"2021-09-13T11:11:34.845295Z","shell.execute_reply":"2021-09-13T11:11:35.32575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Identified lowest outliers: 0\n* Identified upper outliers: 10097\n* 총 outlier 관측치: 10097\n* Non-outlier 관측치 : 580443\n* Outlier의 총 백분율:  1.7395\n\n >= 0 to 800  사이의 values들만 고려한다면, outlier를 피하고 분포의 신뢰도를 높일 수 있을 것이다.\n \n >=outlier인 10k row는 전체 행의 1.74%이다. (소수점 3째자리에서 반올림했을 때)","metadata":{"papermill":{"duration":0.051688,"end_time":"2021-09-12T17:02:17.98007","exception":false,"start_time":"2021-09-12T17:02:17.928382","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Product Feature 알아보기\n\n* Product 피쳐의 value값을  분포 확인\n* Product의 Frauds 분포 알아보기\n* Product의 Transaction 과 Amounts에 차이점이 있을까?\n\n스포하자면, 사실 이 Feature은 그리 중요한 가중치를 가지진 않는다.","metadata":{"papermill":{"duration":0.050742,"end_time":"2021-09-12T17:02:18.082712","exception":false,"start_time":"2021-09-12T17:02:18.03197","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tmp = pd.crosstab(df_trans['ProductCD'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('ProductCD Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='ProductCD', data=df_trans)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\ng.set_title(\"ProductCD Distribution\", fontsize=19)\ng.set_xlabel(\"ProductCD Name\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\ng.set_ylim(0,500000)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\ng1.set_title(\"Product CD by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"ProductCD Name\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"ProductCD Name\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","metadata":{"papermill":{"duration":3.712972,"end_time":"2021-09-12T17:02:21.846603","exception":false,"start_time":"2021-09-12T17:02:18.133631","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:35.32828Z","iopub.execute_input":"2021-09-13T11:11:35.328549Z","iopub.status.idle":"2021-09-13T11:11:38.975261Z","shell.execute_reply.started":"2021-09-13T11:11:35.328509Z","shell.execute_reply":"2021-09-13T11:11:38.974177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 위를 통해 가볍게 알아낼 수 있는 것\n* W, C , R 이 가장 빈도가 높은 값들이다. 그 중에서도 W가 혼자서 74.45%의 점유율을 가지며, 압도적인 데이터 분포를 가진다. 하지만 그렇다고 해서 Fraud 값이 다른 것들보다 높은 것도 아니다.\n* W, H, R 의 Fraud값의 분포가 Non-Fraud 보다 약간 더 높다는 것을 알 수 있다.\n* 사실상 ProductCD 마스킹이 되어 있기 때문에, 이렇게 눈으로 보는 것으로는 유의미한 인사이트를 도출하는 데에 한계가 있다.\n* 다만 데이터의 분포를 파악해볼 수는 있었다.","metadata":{"papermill":{"duration":0.052461,"end_time":"2021-09-12T17:02:21.956871","exception":false,"start_time":"2021-09-12T17:02:21.90441","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Card Features 알아보기\n\n*  앞서 가장 먼저 데이터의 전체적인 모양을 파악할 때 알았듯, card features들은 categorical 피쳐들이다.\n*  피쳐 값들의 분포를 알아보도록 하자.\n* 또한 features의 각 밸류값에 대한 transactions과 '% of Fraud'를 알아보자.\n* Card features에는 6개의 열이 있고, 그 중 4개는 numericals 피쳐인 것 같다. 따라서 이것들에 대해서는 분위수와 분포를 확인해보자.\n* 다시 한 번 스포하자면, Card1과 Card2는 Fraud 예측에 높은 가중치를 가진다.","metadata":{"papermill":{"duration":0.052643,"end_time":"2021-09-12T17:02:22.062123","exception":false,"start_time":"2021-09-12T17:02:22.00948","status":"completed"},"tags":[]}},{"cell_type":"code","source":"##  Card Features 들 미리 살펴보기\nresumetable(df_trans[['card1', 'card2', 'card3','card4', 'card5', 'card6']])","metadata":{"papermill":{"duration":0.690182,"end_time":"2021-09-12T17:02:22.80495","exception":false,"start_time":"2021-09-12T17:02:22.114768","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:38.976612Z","iopub.execute_input":"2021-09-13T11:11:38.976847Z","iopub.status.idle":"2021-09-13T11:11:39.55528Z","shell.execute_reply.started":"2021-09-13T11:11:38.976821Z","shell.execute_reply":"2021-09-13T11:11:39.554418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 위를 통해 알아낸 것\n* Card1에는 결측값이 하나도 없다. \n* Card2-Card6들은 결측값이 있다. 이것을 나중에 메워야 한다. \n* Card4와 Card6은 object type이다.","metadata":{"papermill":{"duration":0.053435,"end_time":"2021-09-12T17:02:22.913084","exception":false,"start_time":"2021-09-12T17:02:22.859649","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Card 데이터셋 : Numericals Feature 들의 분위수\n\n object type인 Card4와 Card6은 제외하고 확인해보자.","metadata":{"papermill":{"duration":0.053663,"end_time":"2021-09-12T17:02:23.019891","exception":false,"start_time":"2021-09-12T17:02:22.966228","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"Card Features Quantiles: \")\nprint(df_trans[['card1', 'card2', 'card3', 'card5']].quantile([0.01, .025, .1, .25, .5, .75, .975, .99]))","metadata":{"papermill":{"duration":0.136566,"end_time":"2021-09-12T17:02:23.210288","exception":false,"start_time":"2021-09-12T17:02:23.073722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:39.556719Z","iopub.execute_input":"2021-09-13T11:11:39.55696Z","iopub.status.idle":"2021-09-13T11:11:39.677819Z","shell.execute_reply.started":"2021-09-13T11:11:39.556932Z","shell.execute_reply":"2021-09-13T11:11:39.676592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Card 1 과 Card 2의 값들이 비교적으로  큰 분포도를 가지고 있다는 것을 볼 수 있다. \n\n그러므로 해당 columns들에 대해선 log값을 얻는 것이 더 나을 것이다.","metadata":{"papermill":{"duration":0.054247,"end_time":"2021-09-12T17:02:23.31991","exception":false,"start_time":"2021-09-12T17:02:23.265663","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans.loc[df_trans.card3.isin(df_trans.card3.value_counts()[df_trans.card3.value_counts() < 200].index), 'card3'] = \"Others\"\ndf_trans.loc[df_trans.card5.isin(df_trans.card5.value_counts()[df_trans.card5.value_counts() < 300].index), 'card5'] = \"Others\"","metadata":{"papermill":{"duration":0.403668,"end_time":"2021-09-12T17:02:23.777559","exception":false,"start_time":"2021-09-12T17:02:23.373891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:39.678972Z","iopub.execute_input":"2021-09-13T11:11:39.679233Z","iopub.status.idle":"2021-09-13T11:11:40.043239Z","shell.execute_reply.started":"2021-09-13T11:11:39.679164Z","shell.execute_reply":"2021-09-13T11:11:40.042469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Card 1, Card 2 Card 3의 분포 시각화하기\n\n* Card 1 과 Card 2는 numerical 피쳐들이므로, 분포도를 그릴 수 있다.\n* Card 3은 낮은 빈도를 가진 값이 많이 있기 때문에, 따로 나누어 \"Others\" value에 넣었다.\n* 또한 Card 3에서 % of Fraud 값을 y axis2로 설정했다.","metadata":{"papermill":{"duration":0.054566,"end_time":"2021-09-12T17:02:23.888127","exception":false,"start_time":"2021-09-12T17:02:23.833561","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# card3과 card5를  normalize하고 인덱스를 리셋한다. column명도 직관적으로 바꿔준다.\ntmp = pd.crosstab(df_trans['card3'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\ntmp2 = pd.crosstab(df_trans['card5'], df_trans['isFraud'], normalize='index') * 100\ntmp2 = tmp2.reset_index()\ntmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n\n## 플롯을 그려본다 \n## card1 card2 의 타겟 밸류값의 분포를 distplot로 출력\n\nplt.figure(figsize=(14,22))\n\nplt.subplot(411)\ng = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card1'], label='Fraud')\ng = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card1'], label='NoFraud')\ng.legend()\ng.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\ng.set_xlabel(\"Card 1 Values\", fontsize=18)\ng.set_ylabel(\"Probability\", fontsize=18)\n\nplt.subplot(412)\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card2'].dropna(), label='Fraud')\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card2'].dropna(), label='NoFraud')\ng1.legend()\ng1.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\ng1.set_xlabel(\"Card 2 Values\", fontsize=18)\ng1.set_ylabel(\"Probability\", fontsize=18)\n\n\n##  card3 밸류값의 분포와  Transaction Frauds 비율\n\n\nplt.subplot(413)\ng2 = sns.countplot(x='card3', data=df_trans, order=list(tmp.card3.values))\ng22 = g2.twinx()\ngg2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n                    color='black', order=list(tmp.card3.values))\ngg2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng2.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng2.set_xlabel(\"Card 3 Values\", fontsize=18)\ng2.set_ylabel(\"Count\", fontsize=18)\nfor p in g2.patches:\n    height = p.get_height()\n    g2.text(p.get_x()+p.get_width()/2.,\n            height + 25,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\") \n\nplt.subplot(414)\ng3 = sns.countplot(x='card5', data=df_trans, order=list(tmp2.card5.values))\ng3t = g3.twinx()\ng3t = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n                    color='black', order=list(tmp2.card5.values))\ng3t.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng3.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng3.set_xticklabels(g3.get_xticklabels(),rotation=90)\ng3.set_xlabel(\"Card 5 Values\", fontsize=18)\ng3.set_ylabel(\"Count\", fontsize=18)\nfor p in g3.patches:\n    height = p.get_height()\n    g3.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=11) \n    \nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\n\nplt.show()","metadata":{"papermill":{"duration":10.836969,"end_time":"2021-09-12T17:02:34.778784","exception":false,"start_time":"2021-09-12T17:02:23.941815","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:40.044859Z","iopub.execute_input":"2021-09-13T11:11:40.045484Z","iopub.status.idle":"2021-09-13T11:11:50.986618Z","shell.execute_reply.started":"2021-09-13T11:11:40.045438Z","shell.execute_reply":"2021-09-13T11:11:50.985672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 위를 통해 알아낼 수 있는 인사이트\n\ncard 1에서는 Fraud와 not Fraud의 분포 비율이 상당히 비슷하다는 사실을 알 수 있다. 사기에 상대적으로 취약한 카드인 걸지도 모른다. 이것만 단편적으로 보아도, target값 산출에 상당히 주요한 역할을 할 것임을 짐작할 수 있다.\n\n\ncard 2에서는 상대적으로 not Fraud의 분포 비율이 높다. 하지만,  Fraud 비율도 무시할 수 없을 정도로 확인된다. 역시 target값 산출에 상당히 주요한 역할을 할 것임을 짐작할 수 있다.\n\n\ncard 3에서는 150.0의 value값에 88.27%의 거래량이 몰려 있는 것을 알 수 있다. 하지만 Fraud Transaction의 퍼센트%는 상대적으로 낮음을 알 수 있다. 대략 3%를 조금 웃도는 수준이다. 반대로, 158.0  value값에는 남은 9.54%의 거래량이 몰려 있는데,  Fraud Transaction의 퍼센트%가 매우 높은 것을 확인할 수 있다. 12%를 웃도는 수준이다. 거래량이 거의 없는 119, 144, 185항목이 높은 Frauds 비율을 보인다.\n\n\ncard 5에서는 226.0의 value값에 50.2%의 거래량이 몰려 있다. 하지만 총 거래량 대비 사기율은 낮은 편이다. 오히려 거래량이 적은 137.0에서 가장 높은 Fraud Transaction 퍼센트를 파악할 수 있다. card5 에서 가장 빈도가 높은 values는 데이터의 73%를 차지하는 226, 224, 166이다. values값이 거의 없는 137, 141, 147, 223 항목이 높은 Frauds 비율을 보인다.","metadata":{"papermill":{"duration":0.060651,"end_time":"2021-09-12T17:02:34.90165","exception":false,"start_time":"2021-09-12T17:02:34.840999","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Card 4 :  Categorical Feature","metadata":{"papermill":{"duration":0.061421,"end_time":"2021-09-12T17:02:35.024684","exception":false,"start_time":"2021-09-12T17:02:34.963263","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# card4를 정규화해서 분포를 확인한다.\n\ntmp = pd.crosstab(df_trans['card4'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n\n\nplt.figure(figsize=(14,10))\nplt.suptitle('Card 4 Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='card4', data=df_trans)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\ng.set_title(\"Card4 Distribution\", fontsize=19)\ng.set_ylim(0,420000)\ng.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=14) \n\n\nplt.subplot(222)\ng1 = sns.countplot(x='card4', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card4', y='Fraud', data=tmp, \n                   color='black', legend=False, \n                   order=['discover', 'mastercard', 'visa', 'american express'])\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card4 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='card4', y='TransactionAmt', hue='isFraud', \n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 4 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","metadata":{"papermill":{"duration":4.627932,"end_time":"2021-09-12T17:02:39.713443","exception":false,"start_time":"2021-09-12T17:02:35.085511","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:50.988162Z","iopub.execute_input":"2021-09-13T11:11:50.988442Z","iopub.status.idle":"2021-09-13T11:11:54.986133Z","shell.execute_reply.started":"2021-09-13T11:11:50.988412Z","shell.execute_reply":"2021-09-13T11:11:54.985231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 위를 통해 알 수 있는 인사이트\n\ncard 4에 대한 항목을 살펴보면, visa 카드와 mastercard가 대부분의 거래량을 차지하고 있는 것을 알 수 있다. 각각 65.16%과 32.04%의 점유율을 가진다.\n\n\n타겟값을 가지고 비교를 해 보았을 때, 안정적으로 적은 비율로 거래 사기 Fraud가 발생하고 있음을 알 수 있다. visa 카드가 3%가 덜 되는 사기 거래 퍼센테이지를, master카드는 그것보다 조금 더 적은 퍼센테이지를 가진다.\n\n\n한편 discover 의  Fraud value값은 분포가 높은 것을 확인할 수 있다. 나머지 카드들은 정상거래와 사기거래가 비슷한 분포도를 가지고 있다.\ndiscover의 is Fraud value 값이 가장 높고 (8%) Mastercard와 Visa (3.5%) American Express( 2.87% ) 순이다.","metadata":{"papermill":{"duration":0.063889,"end_time":"2021-09-12T17:02:39.84104","exception":false,"start_time":"2021-09-12T17:02:39.777151","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Card 6 - Categorical Feature","metadata":{"papermill":{"duration":0.062909,"end_time":"2021-09-12T17:02:39.968357","exception":false,"start_time":"2021-09-12T17:02:39.905448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tmp = pd.crosstab(df_trans['card6'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('Card 6 Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='card6', data=df_trans, order=list(tmp.card6.values))\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\ng.set_title(\"Card6 Distribution\", fontsize=19)\ng.set_ylim(0,480000)\ng.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='card6', hue='isFraud', data=df_trans, order=list(tmp.card6.values))\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card6', y='Fraud', data=tmp, order=list(tmp.card6.values),\n                   color='black', legend=False, )\ngt.set_ylim(0,20)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card6 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='card6', y='TransactionAmt', hue='isFraud', order=list(tmp.card6.values),\n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 6 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","metadata":{"papermill":{"duration":3.586417,"end_time":"2021-09-12T17:02:43.618469","exception":false,"start_time":"2021-09-12T17:02:40.032052","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:54.987475Z","iopub.execute_input":"2021-09-13T11:11:54.987709Z","iopub.status.idle":"2021-09-13T11:11:58.2355Z","shell.execute_reply.started":"2021-09-13T11:11:54.987681Z","shell.execute_reply":"2021-09-13T11:11:58.234811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 위를 통해 얻을 수 있는 인사이트\n\ncard 4에 대한 항목을 살펴보면, 신용Credit 거래  에 해당하는 거래량이 74.5% 압도적으로 높은 것을 확인할 수 있다.\n\n인출debit 거래의 경우, 25.23%로 나머지 비율을 거의 다 가져간다.\n\n하지만 반대로 Fraud 거래 비율은 인출debit 거래가 Credit 신용거래보다 낮음을 알 수 있다. \n\nTransaction Amount 분포를 보면, value들 간에 명확한 차이가 나타나지 않는다.\n","metadata":{"papermill":{"duration":0.064293,"end_time":"2021-09-12T17:02:43.748489","exception":false,"start_time":"2021-09-12T17:02:43.684196","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Exploring M1-M9 Features\nM1-M9 : match, such as names on card and address, etc.","metadata":{"papermill":{"duration":0.064416,"end_time":"2021-09-12T17:02:43.877258","exception":false,"start_time":"2021-09-12T17:02:43.812842","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    df_trans[col] = df_trans[col].fillna(\"Miss\")\n    \ndef ploting_dist_ratio(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(20,5))\n    plt.suptitle(f'{col} Distributions ', fontsize=22)\n\n    plt.subplot(121)\n    g = sns.countplot(x=col, data=df, order=list(tmp[col].values))\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n    g.set_title(f\"{col} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n    g.set_ylim(0,400000)\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,20)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    for p in gt.patches:\n        height = p.get_height()\n        gt.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=14) \n        \n    perc_amt = (df_trans.groupby(['isFraud',col])['TransactionAmt'].sum() / total_amt * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.subplot(122)\n    g1 = sns.boxplot(x=col, y='TransactionAmt', hue='isFraud', \n                     data=df[df['TransactionAmt'] <= lim], order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,5)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g1.set_title(f\"{col} by Transactions dist\", fontsize=18)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n        \n    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n    \n    plt.show()","metadata":{"papermill":{"duration":0.480035,"end_time":"2021-09-12T17:02:44.421329","exception":false,"start_time":"2021-09-12T17:02:43.941294","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:58.236673Z","iopub.execute_input":"2021-09-13T11:11:58.237271Z","iopub.status.idle":"2021-09-13T11:11:58.805335Z","shell.execute_reply.started":"2021-09-13T11:11:58.237193Z","shell.execute_reply":"2021-09-13T11:11:58.804588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## M 분포 확인하기 : Count, %Fraud and Transaction Amount distribution\n\nC Feature처럼 마스킹되어 있는 항목들이다. 다시금 스포하자면, 이 항목 또한 taget값 예측에 중요한 가중치를 가지진 않는다.","metadata":{"papermill":{"duration":0.064468,"end_time":"2021-09-12T17:02:44.550821","exception":false,"start_time":"2021-09-12T17:02:44.486353","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    ploting_dist_ratio(df_trans, col, lim=2500)","metadata":{"papermill":{"duration":26.900416,"end_time":"2021-09-12T17:03:11.515613","exception":false,"start_time":"2021-09-12T17:02:44.615197","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:11:58.806743Z","iopub.execute_input":"2021-09-13T11:11:58.807288Z","iopub.status.idle":"2021-09-13T11:12:23.35419Z","shell.execute_reply.started":"2021-09-13T11:11:58.807244Z","shell.execute_reply":"2021-09-13T11:12:23.353251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Addr1 and Addr2\naddr: address \n\n카드 사용자들의 주소지 정보가 담긴 Feature이다.","metadata":{"papermill":{"duration":0.080359,"end_time":"2021-09-12T17:03:11.678953","exception":false,"start_time":"2021-09-12T17:03:11.598594","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#분위수를 살펴본다.\nprint(\"Card Features Quantiles: \")\nprint(df_trans[['addr1', 'addr2']].quantile([0.01, .025, .1, .25, .5, .75, .90,.975, .99]))","metadata":{"papermill":{"duration":0.131018,"end_time":"2021-09-12T17:03:11.890114","exception":false,"start_time":"2021-09-12T17:03:11.759096","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:23.355818Z","iopub.execute_input":"2021-09-13T11:12:23.356095Z","iopub.status.idle":"2021-09-13T11:12:23.419108Z","shell.execute_reply.started":"2021-09-13T11:12:23.356066Z","shell.execute_reply":"2021-09-13T11:12:23.418006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Addr1에서 5000개 미만의 입력 항목을 가진 모든 values값을 \"Others\"로 설정한다. 한편, 전체적으로도 Addr2보다 훨씬 많은 value값을 가지고 있음을 알 수 있다.  \n* Addr2에서 50개 미만의 모든 values값을 \"Others\"로 설정한다.","metadata":{"papermill":{"duration":0.120423,"end_time":"2021-09-12T17:03:12.092151","exception":false,"start_time":"2021-09-12T17:03:11.971728","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans.loc[df_trans.addr1.isin(df_trans.addr1.value_counts()[df_trans.addr1.value_counts() <= 5000 ].index), 'addr1'] = \"Others\"\ndf_trans.loc[df_trans.addr2.isin(df_trans.addr2.value_counts()[df_trans.addr2.value_counts() <= 50 ].index), 'addr2'] = \"Others\"","metadata":{"papermill":{"duration":0.45047,"end_time":"2021-09-12T17:03:12.624041","exception":false,"start_time":"2021-09-12T17:03:12.173571","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:23.420446Z","iopub.execute_input":"2021-09-13T11:12:23.420679Z","iopub.status.idle":"2021-09-13T11:12:23.823682Z","shell.execute_reply.started":"2021-09-13T11:12:23.420652Z","shell.execute_reply":"2021-09-13T11:12:23.822807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Addr1 분포 확인하기","metadata":{"papermill":{"duration":0.081094,"end_time":"2021-09-12T17:03:12.786625","exception":false,"start_time":"2021-09-12T17:03:12.705531","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def ploting_cnt_amt(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    \n    plt.figure(figsize=(16,14))    \n    plt.suptitle(f'{col} Distributions ', fontsize=24)\n    \n    plt.subplot(211)\n    g = sns.countplot( x=col,  data=df, order=list(tmp[col].values))\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,tmp['Fraud'].max()*1.1)\n    gt.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n    g.set_title(f\"Most Frequent {col} values and % Fraud Transactions\", fontsize=20)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    sizes = []\n    for p in g.patches:\n        height = p.get_height()\n        sizes.append(height)\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=12) \n        \n    g.set_ylim(0,max(sizes)*1.15)\n    \n    #########################################################################\n    perc_amt = (df.groupby(['isFraud',col])['TransactionAmt'].sum() \\\n                / df.groupby([col])['TransactionAmt'].sum() * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    amt = df.groupby([col])['TransactionAmt'].sum().reset_index()\n    perc_amt = perc_amt.fillna(0)\n    plt.subplot(212)\n    g1 = sns.barplot(x=col, y='TransactionAmt', \n                       data=amt, \n                       order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, \n                        order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    g1.set_title(f\"{col} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n    g1.set_xticklabels(g.get_xticklabels(),rotation=45)    \n    \n    for p in g1.patches:\n        height = p.get_height()\n        g1.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total_amt*100),\n                ha=\"center\",fontsize=12) \n        \n    plt.subplots_adjust(hspace=.4, top = 0.9)\n    plt.show()\n    \nploting_cnt_amt(df_trans, 'addr1')","metadata":{"papermill":{"duration":2.203331,"end_time":"2021-09-12T17:03:15.071224","exception":false,"start_time":"2021-09-12T17:03:12.867893","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:23.825002Z","iopub.execute_input":"2021-09-13T11:12:23.825237Z","iopub.status.idle":"2021-09-13T11:12:26.368048Z","shell.execute_reply.started":"2021-09-13T11:12:23.82521Z","shell.execute_reply":"2021-09-13T11:12:26.36719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 위에서 얻을 수 있는 인사이트\n\naddr1 항목에서, 흥미로운 사실들을 발견할 수 있다. 주소지의 카테고리 이름에 따라 사기거래 확률의 퍼센트가 확연히 달라진다는 점이다.\n\n첫 번째 그래프는 가장 빈번하게 확인되는 addr1의 value값과 사기거래 Fraud의 퍼센트를 나타내고 있다. 269, others, 330, 476에서 Fraud Transactions의 %가 특히 높게 두드러진다.\n\n두 번째 그래프는 총 거래량과 총 거래량의 %, Fraud Transactions의 %를 확인할 수 있다. 이 그래프에서는 조금 더 명확하게 value별 Fraud Transactions의 %를 확인할 수 있다. 251, 191, others, 472, 512에서 특히 높은 사기 거래 비율을 확인할 수 있다.\n\n이 Feature은 분명히 유의미한 가중치를 가질 것임을 예측할 수 있다.","metadata":{"papermill":{"duration":0.087341,"end_time":"2021-09-12T17:03:15.247554","exception":false,"start_time":"2021-09-12T17:03:15.160213","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Addr2 분포 확인","metadata":{"papermill":{"duration":0.085686,"end_time":"2021-09-12T17:03:15.419585","exception":false,"start_time":"2021-09-12T17:03:15.333899","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'addr2')","metadata":{"papermill":{"duration":1.474519,"end_time":"2021-09-12T17:03:16.980204","exception":false,"start_time":"2021-09-12T17:03:15.505685","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:26.369447Z","iopub.execute_input":"2021-09-13T11:12:26.369805Z","iopub.status.idle":"2021-09-13T11:12:27.995706Z","shell.execute_reply.started":"2021-09-13T11:12:26.369761Z","shell.execute_reply":"2021-09-13T11:12:27.994757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 알 수 있는 인사이트\n\n첫 번째 그래프는 가장 빈번하게 확인되는 addr1의 value값과 사기거래 Fraud의 퍼센트를 나타내고 있다.\nAddr2의 거의 모든 항목이 0.01퍼센트대의 비슷한 value값을 가진다. 87 value는 전체 항목의 88.14% 를 차지하며, 나머지는 어디로 갔는지 모르겠다...\n재미있는 점은, 65 value에서 frauds 의 비율은 거의 60% 에 육박한다는 점이다.\n\n두 번째 그래프는 총 거래량과 총 거래량의 %, Fraud Transactions의 %를 확인할 수 있다. 87 value는 총 Transaction Amounts 의 96%를 차지한다. 여전히 65 value에서 frauds 의 비율은 거의 60% 에 육박한다. \n\n우리는 이 Feature 또한 중요한 가중치를 가지게 될 것임을 알 수 있다.","metadata":{"papermill":{"duration":0.111359,"end_time":"2021-09-12T17:03:17.188655","exception":false,"start_time":"2021-09-12T17:03:17.077296","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# P emaildomain 분포 확인\npurchaser and recipient email domain\n\n모든 전자 메일 도메인을 각 기업별로 그룹화하고, 500개 미만의 값을 모두 \"Others\"로 분류한다.","metadata":{"papermill":{"duration":0.089401,"end_time":"2021-09-12T17:03:17.366743","exception":false,"start_time":"2021-09-12T17:03:17.277342","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans.loc[df_trans['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\ndf_trans.loc[df_trans['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ndf_trans.loc[df_trans['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\ndf_trans.loc[df_trans.P_emaildomain.isin(df_trans.P_emaildomain\\\n                                         .value_counts()[df_trans.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\ndf_trans.P_emaildomain.fillna(\"NoInf\", inplace=True)","metadata":{"papermill":{"duration":0.529376,"end_time":"2021-09-12T17:03:17.98462","exception":false,"start_time":"2021-09-12T17:03:17.455244","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:27.997308Z","iopub.execute_input":"2021-09-13T11:12:27.997625Z","iopub.status.idle":"2021-09-13T11:12:28.44482Z","shell.execute_reply.started":"2021-09-13T11:12:27.997589Z","shell.execute_reply":"2021-09-13T11:12:28.444044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# P-Email Domain 플롯팅 그려보기","metadata":{"papermill":{"duration":0.087706,"end_time":"2021-09-12T17:03:18.161929","exception":false,"start_time":"2021-09-12T17:03:18.074223","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'P_emaildomain')","metadata":{"papermill":{"duration":2.402618,"end_time":"2021-09-12T17:03:20.652765","exception":false,"start_time":"2021-09-12T17:03:18.250147","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:28.44937Z","iopub.execute_input":"2021-09-13T11:12:28.449617Z","iopub.status.idle":"2021-09-13T11:12:30.959385Z","shell.execute_reply.started":"2021-09-13T11:12:28.449591Z","shell.execute_reply":"2021-09-13T11:12:30.95847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# R-Email Domain plot 분포 확인\n\n* 모든 전자 메일 도메인을 각 기업별로 그룹화한다.\n* 300개 미만의 값을 모두 \"Others\"로 설정한다.","metadata":{"papermill":{"duration":0.092621,"end_time":"2021-09-12T17:03:20.840567","exception":false,"start_time":"2021-09-12T17:03:20.747946","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans.loc[df_trans['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\ndf_trans.loc[df_trans['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\ndf_trans.loc[df_trans['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                             'outlook.es', 'live.com', 'live.fr',\n                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\ndf_trans.loc[df_trans.R_emaildomain.isin(df_trans.R_emaildomain\\\n                                         .value_counts()[df_trans.R_emaildomain.value_counts() <= 300 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\ndf_trans.R_emaildomain.fillna(\"NoInf\", inplace=True)","metadata":{"papermill":{"duration":0.408111,"end_time":"2021-09-12T17:03:21.341248","exception":false,"start_time":"2021-09-12T17:03:20.933137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:30.960678Z","iopub.execute_input":"2021-09-13T11:12:30.960913Z","iopub.status.idle":"2021-09-13T11:12:31.318884Z","shell.execute_reply.started":"2021-09-13T11:12:30.960887Z","shell.execute_reply":"2021-09-13T11:12:31.317936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'R_emaildomain')","metadata":{"papermill":{"duration":1.835542,"end_time":"2021-09-12T17:03:23.271206","exception":false,"start_time":"2021-09-12T17:03:21.435664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:31.320256Z","iopub.execute_input":"2021-09-13T11:12:31.320503Z","iopub.status.idle":"2021-09-13T11:12:33.182467Z","shell.execute_reply.started":"2021-09-13T11:12:31.320469Z","shell.execute_reply":"2021-09-13T11:12:33.181723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 얻을 수 있는 인사이트\n\n* email domain features들은 매우 유사한 분포도를 가지고 있다.\n* google과  icloud frauds 의 frauds가 높다는 것을 확인할 수 있다.","metadata":{"papermill":{"duration":0.096601,"end_time":"2021-09-12T17:03:23.4679","exception":false,"start_time":"2021-09-12T17:03:23.371299","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# C1-C14 features 분포 확인하기\n\nC1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n\n실제 의미는 마스킹된, 카드에 연관된 주소 등의 정보이다.","metadata":{"papermill":{"duration":0.096171,"end_time":"2021-09-12T17:03:23.660418","exception":false,"start_time":"2021-09-12T17:03:23.564247","status":"completed"},"tags":[]}},{"cell_type":"code","source":"resumetable(df_trans[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n                      'C9', 'C10', 'C11', 'C12', 'C13', 'C14']])","metadata":{"papermill":{"duration":0.749162,"end_time":"2021-09-12T17:03:24.505845","exception":false,"start_time":"2021-09-12T17:03:23.756683","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:33.18429Z","iopub.execute_input":"2021-09-13T11:12:33.184547Z","iopub.status.idle":"2021-09-13T11:12:33.86679Z","shell.execute_reply.started":"2021-09-13T11:12:33.184517Z","shell.execute_reply":"2021-09-13T11:12:33.865832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"전부 Datatype이 float16 임을 알 수 있다. 결측치는 없고, Value값은 0.0~2.0 사이로 보인다.","metadata":{"papermill":{"duration":0.097129,"end_time":"2021-09-12T17:03:24.701344","exception":false,"start_time":"2021-09-12T17:03:24.604215","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_trans[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n                      'C9', 'C10', 'C11', 'C12', 'C13', 'C14']].describe()","metadata":{"papermill":{"duration":1.401932,"end_time":"2021-09-12T17:03:26.200701","exception":false,"start_time":"2021-09-12T17:03:24.798769","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:33.870049Z","iopub.execute_input":"2021-09-13T11:12:33.870317Z","iopub.status.idle":"2021-09-13T11:12:35.263655Z","shell.execute_reply.started":"2021-09-13T11:12:33.870288Z","shell.execute_reply":"2021-09-13T11:12:35.262206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_trans.loc[df_trans.C1.isin(df_trans.C1\\\n                              .value_counts()[df_trans.C1.value_counts() <= 400 ]\\\n                              .index), 'C1'] = \"Others\"","metadata":{"papermill":{"duration":0.285016,"end_time":"2021-09-12T17:03:26.587216","exception":false,"start_time":"2021-09-12T17:03:26.3022","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:35.264831Z","iopub.execute_input":"2021-09-13T11:12:35.265076Z","iopub.status.idle":"2021-09-13T11:12:35.461033Z","shell.execute_reply.started":"2021-09-13T11:12:35.265047Z","shell.execute_reply":"2021-09-13T11:12:35.460153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TimeDelta Feature\n\nfrauds가 발생하는 비율이 높은 특정 시간이 있는지 확인해 보자.\n\n## 총 요일, 주중 및 시간으로 변환\n\n첫 번째 날짜를 2017-12-01로 사용하고  delta time 을 사용하여 날짜/시간 기능을 계산한다.","metadata":{"papermill":{"duration":0.098504,"end_time":"2021-09-12T17:03:26.786026","exception":false,"start_time":"2021-09-12T17:03:26.687522","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100400#latest-579480\nimport datetime\n\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\ndf_trans[\"Date\"] = df_trans['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ndf_trans['_Weekdays'] = df_trans['Date'].dt.dayofweek\ndf_trans['_Hours'] = df_trans['Date'].dt.hour\ndf_trans['_Days'] = df_trans['Date'].dt.day","metadata":{"papermill":{"duration":1.072302,"end_time":"2021-09-12T17:03:27.95721","exception":false,"start_time":"2021-09-12T17:03:26.884908","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:35.462331Z","iopub.execute_input":"2021-09-13T11:12:35.46258Z","iopub.status.idle":"2021-09-13T11:12:36.618434Z","shell.execute_reply.started":"2021-09-13T11:12:35.462553Z","shell.execute_reply":"2021-09-13T11:12:36.61747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Total Transaction Amount이 가장 높은 상위 일수","metadata":{"papermill":{"duration":0.098779,"end_time":"2021-09-12T17:03:28.154398","exception":false,"start_time":"2021-09-12T17:03:28.055619","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ploting_cnt_amt(df_trans, '_Days')","metadata":{"papermill":{"duration":1.472143,"end_time":"2021-09-12T17:03:29.724578","exception":false,"start_time":"2021-09-12T17:03:28.252435","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:36.619618Z","iopub.execute_input":"2021-09-13T11:12:36.619865Z","iopub.status.idle":"2021-09-13T11:12:38.242872Z","shell.execute_reply.started":"2021-09-13T11:12:36.619837Z","shell.execute_reply":"2021-09-13T11:12:38.24199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 얻어갈 수 있는 인사이트\n전체적으로 고른 분포를 가지고 있지만, 특히 월초와 월에 FRaud Total Amount가 높은 것을 알 수 있다.","metadata":{"papermill":{"duration":0.102265,"end_time":"2021-09-12T17:03:29.931652","exception":false,"start_time":"2021-09-12T17:03:29.829387","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"##  WeekDays 분포도","metadata":{"papermill":{"duration":0.102854,"end_time":"2021-09-12T17:03:30.136931","exception":false,"start_time":"2021-09-12T17:03:30.034077","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ploting_cnt_amt(df_trans, '_Weekdays')","metadata":{"papermill":{"duration":1.00236,"end_time":"2021-09-12T17:03:31.242157","exception":false,"start_time":"2021-09-12T17:03:30.239797","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:38.244692Z","iopub.execute_input":"2021-09-13T11:12:38.245401Z","iopub.status.idle":"2021-09-13T11:12:39.095531Z","shell.execute_reply.started":"2021-09-13T11:12:38.245357Z","shell.execute_reply":"2021-09-13T11:12:39.094652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 얻을 수 있는 인사이트\n날짜의 정보는 없지만 2일 가량의 거래량이 적다는 것을 알 수 있다. 주말임을 추론할 수 있다.\n\n반대로 오히려 Fraud 사기 거래의 총계는 주말에 높다는 것을 알 수 있다.","metadata":{"papermill":{"duration":0.105552,"end_time":"2021-09-12T17:03:31.456356","exception":false,"start_time":"2021-09-12T17:03:31.350804","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 시간 분포도","metadata":{"papermill":{"duration":0.104475,"end_time":"2021-09-12T17:03:31.665499","exception":false,"start_time":"2021-09-12T17:03:31.561024","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ploting_cnt_amt(df_trans, '_Hours')","metadata":{"papermill":{"duration":1.260634,"end_time":"2021-09-12T17:03:33.030698","exception":false,"start_time":"2021-09-12T17:03:31.770064","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-13T11:12:39.097062Z","iopub.execute_input":"2021-09-13T11:12:39.097566Z","iopub.status.idle":"2021-09-13T11:12:40.510686Z","shell.execute_reply.started":"2021-09-13T11:12:39.097524Z","shell.execute_reply":"2021-09-13T11:12:40.510105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 얻을 수 있는 인사이트\n\n아침 5, 6,7,8,9,10시에 거래 빈도수는 적지만, 그에 비해 Fraud 사기거래 총계 비율은 상당히 높은 것을 알 수 있다. \n\n거래 총량 + %총량 + %사기총량 그래프를 봐도 6~10시 사이에 빈도수 대비 Fraud 비율이 높은 것을 알 수 있다.","metadata":{"papermill":{"duration":0.108182,"end_time":"2021-09-12T17:03:33.249349","exception":false,"start_time":"2021-09-12T17:03:33.141167","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 모델링 함수 선언","metadata":{}},{"cell_type":"code","source":"\n@jit\ndef fast_auc(y_true, y_prob):\n    \"\"\"\n    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    nfalse = 0\n    auc = 0\n    n = len(y_true)\n    for i in range(n):\n        y_i = y_true[i]\n        nfalse += (1 - y_i)\n        auc += y_i * nfalse\n    auc /= (nfalse * (n - nfalse))\n    return auc\n\n\ndef eval_auc(y_true, y_pred):\n    \"\"\"\n    Fast auc eval function for lgb.\n    \"\"\"\n    return 'auc', fast_auc(y_true, y_pred), True\n\n\ndef train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3, averaging='usual', n_jobs=-1):\n\n    columns = X.columns if columns is None else columns\n    n_splits = folds.n_splits if splits is None else n_folds\n    X_test = X_test[columns]\n    \n    # to set up scoring parameters\n    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n                        'catboost_metric_name': 'AUC',\n                        'sklearn_scoring_function': metrics.roc_auc_score},\n                    }\n    \n    result_dict = {}\n    if averaging == 'usual':\n        # out-of-fold predictions on train data\n        oof = np.zeros((len(X), 1))\n\n        # averaged predictions on train data\n        prediction = np.zeros((len(X_test), 1))\n        \n    elif averaging == 'rank':\n        # out-of-fold predictions on train data\n        oof = np.zeros((len(X), 1))\n\n        # averaged predictions on train data\n        prediction = np.zeros((len(X_test), 1))\n\n    \n    # list of scores on folds\n    scores = []\n    feature_importance = pd.DataFrame()\n    \n    # split and train on folds\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n        if type(X) == np.ndarray:\n            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n            y_train, y_valid = y[train_index], y[valid_index]\n        else:\n            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            \n        if model_type == 'lgb':\n            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n            \n            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n        \n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            \n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n            print('')\n            \n            y_pred = model.predict_proba(X_test)\n        \n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n                                      loss_function=Logloss)\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test)\n        \n        if averaging == 'usual':\n            \n            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n            \n            prediction += y_pred.reshape(-1, 1)\n\n        elif averaging == 'rank':\n                                  \n            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n                                  \n            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n        \n        if model_type == 'lgb' and plot_feature_importance:\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= n_splits\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    result_dict['oof'] = oof\n    result_dict['prediction'] = prediction\n    result_dict['scores'] = scores\n    \n    if model_type == 'lgb':\n        if plot_feature_importance:\n            feature_importance[\"importance\"] /= n_splits\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n            \n            result_dict['feature_importance'] = feature_importance\n            result_dict['top_columns'] = cols\n        \n    return result_dict\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:12:40.511893Z","iopub.execute_input":"2021-09-13T11:12:40.512184Z","iopub.status.idle":"2021-09-13T11:12:40.549564Z","shell.execute_reply.started":"2021-09-13T11:12:40.512141Z","shell.execute_reply":"2021-09-13T11:12:40.54858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"함수설명 \n- train_model_classification() :파라미터를 입력받아 모델링을 실행하는 함수   \n  lgb, xgb, sklearn, cat, usual, rank 를 고를수 있다.\n","metadata":{}},{"cell_type":"markdown","source":"# Feature engineering\n집계를 생성해 보겠습니다. 그 안에는 논리가 없습니다. 단순히 상위 기능에 대한 집계입니다.","metadata":{}},{"cell_type":"code","source":"for i in range(39):\n    if(i<10 or i == 0):\n        test.rename(columns={f'id-0{i}':f'id_0{i}'},inplace=True)\n    else:\n        test.rename(columns={f'id-{i}':f'id_{i}'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:12:40.550798Z","iopub.execute_input":"2021-09-13T11:12:40.551055Z","iopub.status.idle":"2021-09-13T11:12:40.588576Z","shell.execute_reply.started":"2021-09-13T11:12:40.551025Z","shell.execute_reply":"2021-09-13T11:12:40.587904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\ntrain['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntest['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\ntest['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntrain['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\ntrain['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\ntrain['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\ntrain['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n\ntest['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\ntest['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\ntest['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\ntest['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n\ntrain['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\ntrain['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\ntrain['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\ntrain['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n\ntest['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\ntest['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\ntest['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\ntest['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n\ntrain['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\ntrain['D15_to_mean_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('mean')\ntrain['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\ntrain['D15_to_std_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('std')\n\ntest['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\ntest['D15_to_mean_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('mean')\ntest['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\ntest['D15_to_std_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('std')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:12:40.589827Z","iopub.execute_input":"2021-09-13T11:12:40.5904Z","iopub.status.idle":"2021-09-13T11:12:42.038561Z","shell.execute_reply.started":"2021-09-13T11:12:40.590366Z","shell.execute_reply":"2021-09-13T11:12:42.037625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\ntrain[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\ntest[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\ntest[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:12:42.039883Z","iopub.execute_input":"2021-09-13T11:12:42.040116Z","iopub.status.idle":"2021-09-13T11:12:49.997437Z","shell.execute_reply.started":"2021-09-13T11:12:42.040089Z","shell.execute_reply":"2021-09-13T11:12:49.996595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data for modelling","metadata":{}},{"cell_type":"code","source":"many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\nmany_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:12:49.99892Z","iopub.execute_input":"2021-09-13T11:12:49.999152Z","iopub.status.idle":"2021-09-13T11:12:54.097952Z","shell.execute_reply.started":"2021-09-13T11:12:49.999126Z","shell.execute_reply":"2021-09-13T11:12:54.097059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:12:54.09939Z","iopub.execute_input":"2021-09-13T11:12:54.09963Z","iopub.status.idle":"2021-09-13T11:13:03.937513Z","shell.execute_reply.started":"2021-09-13T11:12:54.099604Z","shell.execute_reply":"2021-09-13T11:13:03.936602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nunique() 데이터 고유값의 총 수를 알고 싶을때 유용한 함수\none_value_cols = [col for col in train.columns if train[col].nunique() <=1]\none_value_cols_test = [col for col in test.columns if test[col].nunique()<=1]\none_value_cols == one_value_cols_test","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:13:03.93882Z","iopub.execute_input":"2021-09-13T11:13:03.939144Z","iopub.status.idle":"2021-09-13T11:13:12.711504Z","shell.execute_reply.started":"2021-09-13T11:13:03.939102Z","shell.execute_reply":"2021-09-13T11:13:12.710576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\ncols_to_drop.remove('isFraud')\nlen(cols_to_drop)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:13:12.712736Z","iopub.execute_input":"2021-09-13T11:13:12.712969Z","iopub.status.idle":"2021-09-13T11:13:12.719376Z","shell.execute_reply.started":"2021-09-13T11:13:12.712943Z","shell.execute_reply":"2021-09-13T11:13:12.718653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:13:12.720405Z","iopub.execute_input":"2021-09-13T11:13:12.721062Z","iopub.status.idle":"2021-09-13T11:13:17.881623Z","shell.execute_reply.started":"2021-09-13T11:13:12.721017Z","shell.execute_reply":"2021-09-13T11:13:17.880578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9',\n            'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']\nfor col in cat_cols:\n    if col in train.columns:\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))   ","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:13:17.883246Z","iopub.execute_input":"2021-09-13T11:13:17.883588Z","iopub.status.idle":"2021-09-13T11:15:07.407052Z","shell.execute_reply.started":"2021-09-13T11:13:17.883556Z","shell.execute_reply":"2021-09-13T11:15:07.40545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\ny = train.sort_values('TransactionDT')['isFraud']\n#X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\nX_test = test.drop(['TransactionDT', 'TransactionID'], axis=1)\ndel train\ntest = test[[\"TransactionDT\", 'TransactionID']]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:15:07.40998Z","iopub.execute_input":"2021-09-13T11:15:07.410396Z","iopub.status.idle":"2021-09-13T11:15:10.980602Z","shell.execute_reply.started":"2021-09-13T11:15:07.410338Z","shell.execute_reply":"2021-09-13T11:15:10.979802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# by https://www.kaggle.com/dimartinot\ndef clean_inf_nan(df):\n    return df.replace([np.inf, -np.inf], np.nan)   \n\n# Cleaning infinite values to NaN\nX = clean_inf_nan(X)\nX_test = clean_inf_nan(X_test )","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:15:10.982055Z","iopub.execute_input":"2021-09-13T11:15:10.982388Z","iopub.status.idle":"2021-09-13T11:15:14.247225Z","shell.execute_reply.started":"2021-09-13T11:15:10.982349Z","shell.execute_reply":"2021-09-13T11:15:14.246398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:15:14.248336Z","iopub.execute_input":"2021-09-13T11:15:14.248567Z","iopub.status.idle":"2021-09-13T11:15:14.662953Z","shell.execute_reply.started":"2021-09-13T11:15:14.248541Z","shell.execute_reply":"2021-09-13T11:15:14.662004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM","metadata":{}},{"cell_type":"code","source":"n_fold = 5\nfolds = TimeSeriesSplit(n_splits=n_fold)\nfolds = KFold(n_splits=5)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:15:14.664515Z","iopub.execute_input":"2021-09-13T11:15:14.664847Z","iopub.status.idle":"2021-09-13T11:15:14.673533Z","shell.execute_reply.started":"2021-09-13T11:15:14.664807Z","shell.execute_reply":"2021-09-13T11:15:14.672667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'num_leaves': 256,\n          'min_child_samples': 79,\n          'objective': 'binary',\n          'max_depth': 13,\n          'learning_rate': 0.03,\n          \"boosting_type\": \"gbdt\",\n          \"subsample_freq\": 3,\n          \"subsample\": 0.9,\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3,\n          'reg_lambda': 0.3,\n          'colsample_bytree': 0.9,\n          #'categorical_feature': cat_cols\n         }\nresult_dict_lgb = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='auc', plot_feature_importance=True,\n                                                      verbose=500, early_stopping_rounds=200, n_estimators=5000, averaging='usual', n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:15:14.674893Z","iopub.execute_input":"2021-09-13T11:15:14.675555Z","iopub.status.idle":"2021-09-13T11:53:23.697335Z","shell.execute_reply.started":"2021-09-13T11:15:14.675515Z","shell.execute_reply":"2021-09-13T11:53:23.696277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_dict_lgb['prediction']","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:53:23.699197Z","iopub.execute_input":"2021-09-13T11:53:23.699487Z","iopub.status.idle":"2021-09-13T11:53:23.707358Z","shell.execute_reply.started":"2021-09-13T11:53:23.699452Z","shell.execute_reply":"2021-09-13T11:53:23.70638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['isFraud'] = result_dict_lgb['prediction']\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:53:23.709043Z","iopub.execute_input":"2021-09-13T11:53:23.709313Z","iopub.status.idle":"2021-09-13T11:53:25.751616Z","shell.execute_reply.started":"2021-09-13T11:53:23.709281Z","shell.execute_reply":"2021-09-13T11:53:25.750692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:53:25.752925Z","iopub.execute_input":"2021-09-13T11:53:25.753164Z","iopub.status.idle":"2021-09-13T11:53:25.763478Z","shell.execute_reply.started":"2021-09-13T11:53:25.753137Z","shell.execute_reply":"2021-09-13T11:53:25.76268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(result_dict_lgb['oof']).to_csv('lgb_oof.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:53:25.765024Z","iopub.execute_input":"2021-09-13T11:53:25.765279Z","iopub.status.idle":"2021-09-13T11:53:27.806669Z","shell.execute_reply.started":"2021-09-13T11:53:25.765252Z","shell.execute_reply":"2021-09-13T11:53:27.805592Z"},"trusted":true},"execution_count":null,"outputs":[]}]}