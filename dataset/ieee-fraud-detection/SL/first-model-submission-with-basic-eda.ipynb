{"cells":[{"metadata":{},"cell_type":"markdown","source":"Let's get done with the shenanigans "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \npd.set_option('display.max_columns',5000)\npd.set_option('display.max_rows',100)\npd.set_option('display.width',10000)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the files "},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"../input/ieee-fraud-detection/sample_submission.csv\")\ntest_identity = pd.read_csv(\"../input/ieee-fraud-detection/test_identity.csv\")\ntest_transaction = pd.read_csv(\"../input/ieee-fraud-detection/test_transaction.csv\")\ntrain_identity = pd.read_csv(\"../input/ieee-fraud-detection/train_identity.csv\")\ntrain_transaction = pd.read_csv(\"../input/ieee-fraud-detection/train_transaction.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start looking at the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look at nulls\n\ntrain_identity.isnull().any()\n\ntrain_identity.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Before we move any further, let's make a basic baseline model and try to see how it performs "},{"metadata":{},"cell_type":"markdown","source":"We are going to join the two dataframes to give us one result set"},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df = pd.merge(left=train_transaction,right=train_identity,how=\"left\",on=\"TransactionID\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test = pd.merge(left=test_transaction,right=test_identity,how=\"left\",on=\"TransactionID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting indexes which would be used later to submit the prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df.set_index(keys='TransactionID',inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test.set_index(keys='TransactionID',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge_df.head(5)\nmerge_df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check how many fraud transactions are there in the dataset\n\nimport seaborn as sns\n\nsns.countplot(x='isFraud',data=merge_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking what percentage of data is actually fraud"},{"metadata":{"trusted":true},"cell_type":"code","source":"# so less then 4 perecent of the transaction is fraud \n## this would be interesting as class distribution has a lot of difference\nround((len(merge_df[merge_df['isFraud']==1])/len(merge_df))*100,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##intutive column selection for now \nmerge_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n         'card6','P_emaildomain','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','DeviceType', 'DeviceInfo']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df['TransactionAmt'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test['TransactionAmt'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets draw the histogram of transaction amount\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n#plt.hist(x=merge_df['TransactionAmt'])\n\n#plt.scatter(x=merge_df['TransactionAmt'])\n\nmerge_df['TransactionAmt']\n\nsns.boxplot(merge_df['TransactionAmt'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import iqr\n\niqr(merge_df['TransactionAmt'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df['ProductCD'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test['ProductCD'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's look at the unique values\n\nmerge_df['ProductCD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot to see if any pattern in product type and fraud \n\nsns.countplot(x='ProductCD',hue='isFraud',data=merge_df)\n\n#doesn't seem like there is a pattern here ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df[['card1','card2','card3','card4','card5','card6']].isnull().any()\n\n#merge_df['card2'].value_counts()\n\n\n# around 1.5% percent values are \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test[['card1','card2','card3','card4','card5','card6']].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assigning these null values the most frequently occuring value in the system"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmerge_df.loc[merge_df['card2'].isna(),'card2']=321","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmerge_df_test.loc[merge_df_test['card2'].isna(),'card2']=321","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df.loc[merge_df['card3'].isna(),'card3']=150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test.loc[merge_df_test['card3'].isna(),'card3']=150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df.loc[merge_df['card4'].isna(),'card4']='visa' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test.loc[merge_df_test['card4'].isna(),'card4']='visa' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df.loc[merge_df['card5'].isna(),'card5']=226","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test.loc[merge_df_test['card5'].isna(),'card5']=226","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df.loc[merge_df['card6'].isna(),'card6']='debit'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test.loc[merge_df_test['card6'].isna(),'card6']='debit'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df[['card1','card2','card3','card4','card5','card6']].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df_test[['card1','card2','card3','card4','card5','card6']].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['TransactionAmt','ProductCD','card1', 'card2', 'card3', 'card4', 'card5',\n          'card6','isFraud']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets get the subset of the columns\n\nmerge_df = merge_df[cols]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets get the subset of the columns\ncols_test = ['TransactionAmt','ProductCD','card1', 'card2', 'card3', 'card4', 'card5',\n          'card6']\nmerge_df_test = merge_df_test[cols_test]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the correlation heat map"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(merge_df)\ncor = merge_df.corr()\n#print(cor)\nsns.heatmap(cor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert stirngs to numerical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle1 = LabelEncoder().fit(merge_df['ProductCD'])\nmerge_df['ProductCD'] = le1.transform(merge_df['ProductCD'])\nmerge_df_test['ProductCD'] = le1.transform(merge_df_test['ProductCD'])\n\nle2 = LabelEncoder().fit(merge_df['card4'])\nmerge_df['card4'] = le2.transform(merge_df['card4'])\nmerge_df_test['card4'] = le2.transform(merge_df_test['card4'])\n\nle3 = LabelEncoder().fit(merge_df['card6'])\nmerge_df['card6'] = le3.transform(merge_df['card6'])\nmerge_df_test['card6'] = le3.transform(merge_df_test['card6'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(merge_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX= merge_df.iloc[:,:-1]\ny = merge_df.iloc[:,-1]\n#print(y)\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets start by applying Random forest classifier , we would be using GridsearchCV to get the best model output "},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.model_selection import GridSearchCV\n\n# rf = RandomForestClassifier()\n# param = {'n_estimators':[150],'max_depth':[9]}\n\n# grid_model = GridSearchCV(rf,param_grid=param,scoring='roc_auc')\n\n# grid_model.fit(X,y)\n\n# print(grid_model.best_estimator_)\n# print(grid_model.best_score_)\n# print(grid_model.best_params_)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we are going to apply GBC next , the paramter values are select by running them through GridSearch for simplicity only placing the apply code here"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngf = GradientBoostingClassifier(learning_rate=0.1,n_estimators=150,max_depth=9).fit(X_train,y_train)\n\ny_pred = gf.predict(X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gf.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Let's predict using GBf\n\nmerge_df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# so we are getting a score of 86%\nfrom sklearn.metrics import roc_auc_score\ny_score = gf.predict_proba(X_test)[:,1]\nprint(roc_auc_score(y_test,y_score))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All done let's get the score now "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_predict = gf.predict_proba(merge_df_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.DataFrame()\nresult_df['TransactionID'] = merge_df_test.index\nresult_df['isFraud'] = y_test_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.to_csv('result1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(result_df[result_df['isFraud']>0.5])/len(result_df)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try appling Neural Network to the problem on hand"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(X_train)\nX_train_scaled =scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\nmerge_df_test_scaled = scaler.transform(merge_df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.neural_network import MLPClassifier\n\n# mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n# mlp.fit(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_test_predict_nlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_test_predict_nlp = mlp.predict_proba(merge_df_test_scaled)[:,1]\n# result_df = pd.DataFrame()\n# result_df['TransactionID'] = merge_df_test.index\n# result_df['isFraud'] = y_test_predict_nlp\n\n# result_df.to_csv('result2.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets try to apply XGBoost and see if results are better"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nmodel = xgb.XGBClassifier(n_estimators=500,\n                        n_jobs=4,\n                        max_depth=9,\n                        learning_rate=0.05,\n                        subsample=0.9,\n                        colsample_bytree=0.9)\n\nmodel.fit(X,y)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp =model.predict_proba(merge_df_test)[:,1]\nresult_df3 = pd.DataFrame()\nresult_df3['TransactionID'] = merge_df_test.index\nresult_df3['isFraud'] = temp\nresult_df3.to_csv('result5.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}