{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Becasue of Kernel uploading Plotly plots limitation, Please uncomment the command lines, you might find something intersting **"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n%matplotlib inline\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Codes\nyou can skip this part if you are just interested in results"},{"metadata":{"trusted":false},"cell_type":"code","source":"import collections\n\nfrom IPython.display import display\n\nclass Exploration(object):\n    \"\"\"\n        How to run:\n                    fa = Exploration(df).DescribeAnalysis(True)\n    \"\"\"\n\n    def __init__(self, dataframe):\n\n        self.dataframe = dataframe\n\n    def _getFirstNumericalColNameIndex(self,tem_df):\n        for col in tem_df.columns:\n            col_type = tem_df[col].dtype\n            if (col_type != 'object') and (col_type != 'datetime64') and (col_type != 'bool'):\n\n                first_numerical_col_name = col\n#                     print(tem_df.columns.get_loc(col))\n                break\n        return tem_df.columns.get_loc(col)\n\n\n    def DescribeAnalysis(self, dis=False):\n\n        \"\"\"\n            Input:\n                    DataFrame\n            Output:\n                    Dataframe:\n                        Features: Name of Features\n                        Dtype: type of data\n                        Nunique: number of unique value\n                        freq1: most frequent value\n                        freq1_val: number of occurance of the most frequent value\n                        freq2: second most frequent value\n                        freq2_val: number of occurance of the second most frequent value\n                        freq3: 3rd most frequent value, if available\n                        freq3_val: number of occurance of the thrid most frequent value, if available\n                        describe stats: the following ones are the stat offer by our best friend .describe methods.\n        \"\"\"\n\n\n        # get input column dataframe name\n        cols = self.dataframe.columns\n\n        # set name of output dataframe\n        stat_cols= ['Dtype', 'Nunique', 'nduplicate', 'freq1', 'freq1_val', 'freq2', 'freq2_val',\n             'freq3', 'freq3_val'] + self.dataframe[cols[self._getFirstNumericalColNameIndex(self.dataframe)]].describe().index.tolist()[1:]\n        stat_cols = ['Features']+stat_cols\n\n        feature_stat = pd.DataFrame(columns=stat_cols)\n        i = 0\n\n        for col in cols:\n            col_type = self.dataframe[col].dtype\n            if (col_type != 'object') and (col_type != 'datetime64[ns]') and (col_type != 'bool'):\n                stat_vals = []\n\n                # get stat value\n                stat_vals.append(col)\n                # Data type\n                stat_vals.append(self.dataframe[col].dtype)\n                # number of unique\n                stat_vals.append(self.dataframe[col].nunique())\n                # nduplicate\n                stat_vals.append(self.dataframe.shape[0]-self.dataframe[col].nunique())\n                # 'freq1' & freq1_val'\n                stat_vals.append(self.dataframe[col].value_counts().index[0])\n                stat_vals.append(self.dataframe[col].value_counts().iloc[0])\n                #'freq2', 'freq2_val'\n                try:\n                    stat_vals.append(self.dataframe[col].value_counts().index[1])\n                    stat_vals.append(self.dataframe[col].value_counts().iloc[1])\n                except Exception:\n                    stat_vals.append(np.nan)\n                    stat_vals.append(np.nan)\n                # 'freq3', 'freq3_val'\n                if len(self.dataframe[col].value_counts())>2:\n                    stat_vals.append(self.dataframe[col].value_counts().index[2])\n                    stat_vals.append(self.dataframe[col].value_counts().iloc[2])\n                else:\n                    stat_vals.append(np.nan)\n                    stat_vals.append(np.nan)\n\n                stat_vals += self.dataframe[col].describe().tolist()[1:]\n                feature_stat.loc[i] = stat_vals\n                i += 1\n\n        # dipslay dataframe\n        if dis:\n            # display(nunique_duplicate)\n            display(feature_stat)\n\n        return feature_stat\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npy.init_notebook_mode(connected=True)\n\n\n\nclass PlotingMissingValues(object):\n    \"\"\"\n    input:\n    df: dataframe\n    verbosity: show the resul of finding missing values\n    output:\n        list of tuple of missitng value and key: [(key,value)]\n\n    Methods:\n        FindingMissingValue(Ture shows the result)\n        PlotMissingValue: show the plot of miasing value\n    \"\"\"\n\n    def __init__(self, df):\n        self.df =  df\n\n    def FindingMissingValue(self, verbosity =True):\n        df_size = self.df.shape[0]\n\n        if self.df.isnull().values.any():\n            if  verbosity:\n                print(self.df.isnull().sum())\n\n            value, key = [], []\n            for col in self.df.columns:\n                value.append(round(self.df[col].isnull().sum()/df_size *100,2))\n                key.append(col)\n                missingValue = list(zip(key,value))\n\n            return missingValue\n\n        else:\n            print('There is no NAN in dataframe')\n            return None\n\n\n    def __getListofTupleValues(self,listOfTuple):\n        \"\"\"\n         input:\n             [(key,value)]\n         output:\n             list of keys & list of values\n        \"\"\"\n        key = [listOfTuple[i][0] for i in range(len(listOfTuple))]\n        value = [listOfTuple[i][1] for i in range(len(listOfTuple))]\n        return key,value\n\n    def __Plot(self,key, value):\n        data_array = value\n        hist_data = np.histogram(data_array)\n        x = value\n        y = key\n        \"\"\"\n            x: list of value\n            y : list of key\n        \"\"\"\n        data = [go.Bar(\n                x=x,\n                y=y,\n                text=x,\n                orientation = 'h',\n                textposition = 'auto',\n                marker=dict(\n                    color='rgb(227,67,45)',\n                    line=dict(\n                        color='rgb(8,48,107)',\n                        width=2.5),\n                ),\n                opacity=0.6\n            )]\n        layout = go.Layout(\n            title='Missing Values',\n            autosize=False,\n            width=600,\n            height=1200,\n            margin=go.Margin(\n                l=200,\n                r=0,\n                b=100,\n                t=100,\n                pad=4\n            )\n        )\n\n        fig = go.Figure(data=data, layout=layout)\n        py.iplot(fig, filename='bar-direct-labels')\n\n    def PlotMissingValue(self):\n        finding_missing_values= self.FindingMissingValue(False)\n        if finding_missing_values==None:\n            pass\n        else:\n            key, value = self.__getListofTupleValues(finding_missing_values)\n            self.__Plot(key, value)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def wordFrequencyPlot(df,colname):\n    temp = df[colname].value_counts()\n    trace = go.Bar(\n        y=temp.index[::-1],\n        x=(temp / temp.sum() * 100)[::-1],\n        orientation = 'h',\n        marker=dict(\n            color='blue',\n        ),\n    )\n\n    layout = go.Layout(\n        title = colname + \" Top  (%)\",\n        xaxis=dict(\n            title=' count',\n            tickfont=dict(size=14,)),\n        yaxis=dict(\n#             title='',\n            titlefont=dict(size=16),\n            tickfont=dict(\n                size=14)),\n        margin=dict(\n        l=200,\n    ),\n\n    )\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from scipy.stats import skew\nfrom scipy.stats import kurtosis\ndef plotBarCat(df,feature,target,nbins=2):\n    \n    \n    \n    x0 = df[df[target]==0][feature]\n    x1 = df[df[target]==1][feature]\n\n    trace1 = go.Histogram(\n        x=x0,\n        nbinsx =nbins, \n        opacity=0.75\n    )\n    trace2 = go.Histogram(\n        x=x1,\n        nbinsx = nbins, \n        opacity=0.75\n    )\n\n    data = [trace1, trace2]\n    layout = go.Layout(barmode='overlay',\n                      title=feature,\n                       yaxis=dict(title='Count'\n        ))\n    fig = go.Figure(data=data, layout=layout)\n\n    py.iplot(fig, filename='overlaid histogram')\n    \n    def DescribeFloatSkewKurt(df,target):\n        \"\"\"\n            A fundamental task in many statistical analyses is to characterize\n            the location and variability of a data set. A further\n            characterization of the data includes skewness and kurtosis.\n            Skewness is a measure of symmetry, or more precisely, the lack\n            of symmetry. A distribution, or data set, is symmetric if it\n            looks the same to the left and right of the center point.\n            Kurtosis is a measure of whether the data are heavy-tailed\n            or light-tailed relative to a normal distribution. That is,\n            data sets with high kurtosis tend to have heavy tails, or\n            outliers. Data sets with low kurtosis tend to have light\n            tails, or lack of outliers. A uniform distribution would\n            be the extreme case\n        \"\"\"\n        print('-*-'*25)\n        print(\"{0} mean : \".format(feature), np.mean(df[feature]))\n        print(\"{0} var  : \".format(feature), np.var(df[feature]))\n        print(\"{0} skew : \".format(feature), skew(df[feature]))\n        print(\"{0} kurt : \".format(feature), kurtosis(df[feature]))\n        print('-*-'*25)\n    \n    DescribeFloatSkewKurt(df,feature)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def piePlot(sizes,labels,title):\n\n\n    fig1, ax1 = plt.subplots(figsize=(8,8))\n    plt.rcParams.update({'font.size': 22})\n    ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n            shadow=True, startangle=90)\n    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n    plt.title(title)\n    plt.show()\n    \ndef piePlotLables(df,col,target,v_target):\n    select_df = df[[col, target]]\n    \n    col_isFraud =  select_df[select_df[target]==v_target].groupby(col).count().reset_index(drop=False)\n    \n    labels = col_isFraud[col].tolist()\n    sizes =  col_isFraud[target].tolist()\n    \n    return sizes, labels ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading"},{"metadata":{"trusted":false},"cell_type":"code","source":"path = '../input/'\ntrain_identity    = pd.read_csv(path+'train_identity.csv')\ntrain_transaction = pd.read_csv(path+'train_transaction.csv')\n\ntest_identity     = pd.read_csv(path+'test_identity.csv')\ntest_transaction  = pd.read_csv(path+'test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Shape:')\nprint('train_identity.shape {} train_transaction.shape {}'.format(train_identity.shape, train_transaction.shape))\nprint('test_identity.shape {} test_transaction.shape {}'.format(test_identity.shape, test_transaction.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Prepration & Descriptive Analysis"},{"metadata":{},"cell_type":"markdown","source":"## Train Identity"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_identity.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_identity.describe(include=['O']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_identity_col_cat = train_identity.describe(include=['O']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature_info_train_identity  = Exploration(train_identity).DescribeAnalysis(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"PlotingMissingValues(train_identity).PlotMissingValue()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Identity Categorical"},{"metadata":{},"cell_type":"markdown","source":"## id_12"},{"metadata":{"trusted":false},"cell_type":"code","source":"wordFrequencyPlot(train_identity,train_identity_col_cat[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_15"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_16"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_23"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_27"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_28"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_29"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_30"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[7])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_31"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[8])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_33\nBecause of Kernel limitation countinue by yourself"},{"metadata":{},"cell_type":"markdown","source":"## Device Type"},{"metadata":{"trusted":false},"cell_type":"code","source":"wordFrequencyPlot(train_identity,train_identity_col_cat[15])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Device Info"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_identity,train_identity_col_cat[16])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Transaction"},{"metadata":{"trusted":false},"cell_type":"code","source":"col_remain = train_transaction.columns[17:]\nff=set()\nfor col in col_remain:\n    ff.add(col[0])\n    \nprint('Columns: ', ff)\n\n\ncol_remain = train_transaction.columns[17:]\nC_col = []\nD_col = []\nM_col = []\nV_col = []\n\nrest_col = []\n\nfor col in col_remain:\n    if col[0] == 'C':\n        C_col.append(col)\n    elif col[0] == 'D':\n        D_col.append(col)\n    elif col[0] == 'M':\n        M_col.append(col)\n    elif col[0] =='V':\n        V_col.append(col)\n    else:\n        rest_col.append(col)\n        \nprint('len C: {}, D: {}, M: {}, V: {}'.format(len(C_col),len(D_col),len(M_col),len(V_col)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First 16 Columns Train Transaction"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction_16=train_transaction[train_transaction.columns[0:17]]\ntrain_transaction_16.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature_info_train_transaction_16  = Exploration(train_transaction_16).DescribeAnalysis(True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TransactionAmt"},{"metadata":{"trusted":false},"cell_type":"code","source":"# train_transaction_16['log_TransactionAmt'] = train_transaction_16['TransactionAmt'].apply(np.log)\n# plotBarCat(train_transaction_16,'log_TransactionAmt','isFraud',40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = 'TransactionAmt'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = 'TransactionAmt'\nplt.boxplot(train_transaction_16[train_transaction_16[feature]<300][feature].dropna(),vert=False)\nplt.title(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## isFraud"},{"metadata":{"trusted":false},"cell_type":"code","source":"# plotBarCat(train_transaction_16,'isFraud','isFraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('  {:.4f}% of Transactions that are fraud in train '.format(train_transaction['isFraud'].mean() * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transaction DT\nThe TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp)."},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = 'TransactionDT'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Card1"},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = 'card1'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Card2"},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = 'card2'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Card5"},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = 'card5'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction_16.describe(include=['O']).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ProductCD"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_transaction_16,'ProductCD')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col = 'ProductCD'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction_16,col,target,0)\npiePlot(sizes,labels,'Not Fraud(0)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col = 'ProductCD'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction_16,col,target,1)\npiePlot(sizes,labels,'Fraud(1)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Card4"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_transaction_16,'card4')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Card6"},{"metadata":{"trusted":false},"cell_type":"code","source":"wordFrequencyPlot(train_transaction_16,'card6')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## P_emaildomain"},{"metadata":{"trusted":false},"cell_type":"code","source":"wordFrequencyPlot(train_transaction_16,'P_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R_emaildomain"},{"metadata":{"trusted":false},"cell_type":"code","source":"# wordFrequencyPlot(train_transaction_16,'R_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing Value"},{"metadata":{"trusted":false},"cell_type":"code","source":"# PlotingMissingValues(train_transaction_16).PlotMissingValue()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C-columns"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction[C_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"C_col_info = Exploration(train_transaction[C_col]).DescribeAnalysis(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"PlotingMissingValues(train_transaction[C_col]).PlotMissingValue()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## D-Columns"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction[D_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"D_col_info = Exploration(train_transaction[D_col]).DescribeAnalysis(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# PlotingMissingValues(train_transaction[D_col]).PlotMissingValue()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## M-Columns"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction[M_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction[M_col].describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## M4"},{"metadata":{"trusted":false},"cell_type":"code","source":"wordFrequencyPlot(train_transaction[M_col],'M4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col = 'M4'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction,col,target,0)\npiePlot(sizes,labels,'NOT Fraud(0)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col = 'M4'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction,col,target,1)\npiePlot(sizes,labels,'Fraud(1)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Fold Target Encoding"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import base\nfrom sklearn.model_selection import KFold\n\nclass KFoldMeanEncoder(base.BaseEstimator, base.TransformerMixin):\n\n    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n\n        self.colnames = colnames\n        self.targetName = targetName\n        self.n_fold = n_fold\n        self.verbosity = verbosity\n        self.discardOriginal_col = discardOriginal_col\n\n    def fit(self, X, y=None):\n        return self\n\n\n    def transform(self,X):\n\n        assert(type(self.targetName) == str)\n        assert(type(self.colnames) == list)\n\n        mean_of_target = X[self.targetName].mean()\n        kf = KFold(n_splits = self.n_fold, shuffle = False)\n\n        for col in self.colnames:\n\n            col_mean_name = col + '_' + 'KfoldMeanEnc'\n            X[col_mean_name] = np.nan\n\n            for tr_ind, val_ind in kf.split(X):\n                X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n                X.loc[X.index[val_ind], col_mean_name] = X_val[col].map(X_tr.groupby(col)[self.targetName].mean())\n\n            X[col_mean_name].fillna(mean_of_target, inplace = True)\n\n            if self.verbosity:\n                #print correlation\n                encoded_feature = X[col_mean_name].values\n                print('Correlation between the new feature, {} and, {} is {:.4f}.'.format(col_mean_name,\n                                                                                      self.targetName,\n                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n        if self.discardOriginal_col:\n            X = X.drop(self.targetName, axis=1)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"KFME= KFoldMeanEncoder(['ProductCD','card4','card6','P_emaildomain','R_emaildomain',\n                       'M1','M2','M3','M4','M5','M6','M7','M8','M9'],'isFraud')\ntrain_transaction_KFME = KFME.fit_transform(train_transaction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}