{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction = pd.read_csv(\"../input/ieee-fraud-detection/train_transaction.csv\")\ntrain_identity = pd.read_csv(\"../input/ieee-fraud-detection/train_identity.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 500)\ntrain_transaction.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 時刻の変換\ntrain_transaction['Transaction_dow'] = np.floor((train_transaction['TransactionDT'] / (3600 * 24) - 1) % 7)\ntrain_transaction['Transaction_hour'] = np.floor(train_transaction['TransactionDT'] / 3600) % 24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_transaction['Transaction_dow'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_transaction['Transaction_hour'][0:30000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_identifyの中で欠損データが無いのを探す\nna_columns = train_identity.isna().sum()\nna_columns[na_columns==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_transactionの中で欠損データが無いのを探す\nna_columns = train_transaction.isna().sum()\nna_columns[na_columns==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(na_columns[na_columns>0]/train_transaction.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seabornでグラフ描画　pyplotよりもお手軽\nsns.distplot(train_identity['id_01'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#列名を取り出す\ntransaction_columns = train_transaction.columns\n#数値型の列名を取り出す\nnumericCols = train_transaction._get_numeric_data().columns ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#文字列のデータ列だけを取り出す\ncategoricalCols = list(set(transaction_columns) - set(numericCols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#文字列データの空欄（np.nan）missingに置き換える\ntrain_transaction[categoricalCols] = train_transaction[categoricalCols].replace({np.nan:'missing'})\n#数値データの空欄を（np.nan）－１に置き換える\ntrain_transaction[numericCols] = train_transaction[numericCols].replace({np.nan:-1})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#詐欺データの割合をみる　Fraud:詐欺\nsns.countplot(train_transaction['isFraud'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#使われたカードの支払い方法がcredit(後から引き落とし)かdebit（すぐに引き落とし）\nsns.countplot(train_transaction['card6'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カード支払い方法と詐欺件数の対応\ncardTypes = {'credit','debit','debit or credit','charge card'}\nfor i,i_card in enumerate(cardTypes):\n    #eval　文字列を実行文とあつかう\n    cardData = eval('train_transaction.loc[train_transaction[\"card6\"]==\"'+i_card+'\"]')\n    plt.figure(i)\n    sns.countplot(cardData['isFraud']).set_title(i_card)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カード種別\nsns.countplot(train_transaction['card4'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カードの種類と詐欺件数の関係\ncardTypes = ['discover','mastercard','visa','american express','missing']\nfor i,i_card in enumerate(cardTypes):\n    cardData = eval('train_transaction.loc[train_transaction[\"card4\"]==\"'+i_card+'\"]')\n    plt.figure(i)\n    sns.countplot(cardData['isFraud']).set_title(i_card)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#詐欺だったときの払った平均金額と、詐欺じゃないときの払った平均金額\nfalse_Fraud_Amt = np.mean(train_transaction.loc[train_transaction[\"isFraud\"]==0]['TransactionAmt'])\ntrue_Fraud_Amt = np.mean(train_transaction.loc[train_transaction[\"isFraud\"]==1]['TransactionAmt'])\nprint(false_Fraud_Amt)\nprint(true_Fraud_Amt)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#詐欺だったときの払った最大金額と、詐欺じゃないときの払った最大金額\nfalse_Fraud_Amt_max = np.max(train_transaction.loc[train_transaction[\"isFraud\"]==0]['TransactionAmt'])\ntrue_Fraud_Amt_max = np.max(train_transaction.loc[train_transaction[\"isFraud\"]==1]['TransactionAmt'])\nprint(false_Fraud_Amt_max)\nprint(true_Fraud_Amt_max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#詐欺だったときの払った最小金額と、詐欺じゃないときの払った最小金額\nfalse_Fraud_Amt_min = np.min(train_transaction.loc[train_transaction[\"isFraud\"]==0]['TransactionAmt'])\ntrue_Fraud_Amt_min = np.min(train_transaction.loc[train_transaction[\"isFraud\"]==1]['TransactionAmt'])\nprint(false_Fraud_Amt_min)\nprint(true_Fraud_Amt_min)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カードの種類と金額の最大最小平均\nmaxCardData = {}\nminCardData = {}\nmeanCardData = {}\nfor i,i_card in enumerate(cardTypes):\n    cardData = eval('train_transaction.loc[train_transaction[\"card4\"]==\"'+i_card+'\" ]')\n    maxCardData[i_card] = np.max(cardData['TransactionAmt'])\n    minCardData[i_card] = np.min(cardData['TransactionAmt'])\n    meanCardData[i_card] = np.mean(cardData['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The maximum transactions by card are:', maxCardData)\nprint('The minimum transactions by card are:', minCardData)\nprint('The average transactions by card are:', meanCardData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#詐欺だったときの金額情報\nfraudDataTransaction = train_transaction.loc[train_transaction[\"isFraud\"]==1]\nfraudDataTransaction.TransactionAmt.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#詐欺じゃないときの金額情報\nnormalDataTransaction = train_transaction.loc[train_transaction[\"isFraud\"]==0]\nnormalDataTransaction.TransactionAmt.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#製品コード　uniqueで種類をみつける\nprodTypes = train_transaction['ProductCD'].unique()\nfor i,i_prod in enumerate(prodTypes):\n    productData = eval('train_transaction.loc[train_transaction[\"ProductCD\"]==\"'+i_prod+'\"]')\n    plt.figure(i)\n    ax = sns.barplot(x=\"isFraud\", y=\"isFraud\", data=productData, estimator=lambda x: len(x) / len(productData) * 100)\n    ax.set(ylabel=\"Percent\")\n    ax.set_title(i_prod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del fraudDataTransaction,normalDataTransaction,productData,cardData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#identityデータの解析\nidentity_data_columns = train_identity.columns\n\n#数値項目の抜き出し\nnumericCols = train_identity._get_numeric_data().columns\n#文字列項目の抜き出し\ncategoricalCols = list(set(identity_data_columns) - set(numericCols))\nprint('The categorical columns in identity data are: ',categoricalCols)\ntrain_identity[categoricalCols] = train_identity[categoricalCols].replace({ np.nan:'missing'})\ntrain_identity[numericCols] = train_identity[numericCols].replace({ np.nan:-1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#OSのタイプを変換\ntrain_identity.loc[train_identity['id_30'].str.contains('Mac', na=False), 'id_30'] = 'mac'\ntrain_identity.loc[train_identity['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\ntrain_identity.loc[train_identity['id_30'].str.contains('Android', na=False), 'id_30'] = 'android'\ntrain_identity.loc[train_identity['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\ntrain_identity.loc[train_identity['id_30'].str.contains('Linux', na=False), 'id_30'] = 'Linux'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#デバイス名を変換\ntrain_identity['device_name'] = train_identity['DeviceInfo'].str.split('/', expand=True)[0]\n\ntrain_identity.loc[train_identity['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\ntrain_identity.loc[train_identity['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\ntrain_identity.loc[train_identity['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\ntrain_identity.loc[train_identity['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\ntrain_identity.loc[train_identity['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\ntrain_identity.loc[train_identity['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\ntrain_identity.loc[train_identity['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\ntrain_identity.loc[train_identity['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\ntrain_identity.loc[train_identity['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\ntrain_identity.loc[train_identity['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\ntrain_identity.loc[train_identity['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\ntrain_identity.loc[train_identity['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\ntrain_identity.loc[train_identity['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\ntrain_identity.loc[train_identity['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\ntrain_identity.loc[train_identity['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\ntrain_identity.loc[train_identity['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\ntrain_identity.loc[train_identity['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n\ntrain_identity.loc[train_identity.device_name.isin(train_identity.device_name.value_counts()[train_identity.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.unique(train_identity['id_31']))\ntrain_identity['id_31'] = train_identity['id_31'].str.replace('\\d+', '')\nprint(np.unique(train_identity['id_31']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transaction と itentity をTransactionIDを軸に結合\nraw_train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_identity,train_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train_data_columns = raw_train_data.columns\n#数値項目を抜き出す\nnumericCols = raw_train_data._get_numeric_data().columns\n#文字列項目を抜き出す\ncategoricalCols = list(set(raw_train_data_columns) - set(numericCols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#欠損データの置き換え\nraw_train_data[categoricalCols] = raw_train_data[categoricalCols].replace({ np.nan:'missing'})\nraw_train_data[numericCols] = raw_train_data[numericCols].replace({ np.nan:-1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# credit to @guiferviz for the memory reduction \ndef memory_usage_mb(df, *args, **kwargs):\n    \"\"\"Dataframe memory usage in MB. \"\"\"\n    return df.memory_usage(*args, **kwargs).sum() / 1024**2\n\ndef reduce_memory_usage(df, deep=True, verbose=True):\n    # All types that we want to change for \"lighter\" ones.\n    # int8 and float16 are not include because we cannot reduce\n    # those data types.\n    # float32 is not include because float16 has too low precision.\n    numeric2reduce = [\"int16\", \"int32\", \"int64\", \"float64\"]\n    start_mem = 0\n    if verbose:\n        start_mem = memory_usage_mb(df, deep=deep)\n\n    for col, col_type in df.dtypes.iteritems():\n        best_type = None\n        if col_type in numeric2reduce:\n            downcast = \"integer\" if \"int\" in str(col_type) else \"float\"\n            df[col] = pd.to_numeric(df[col], downcast=downcast)\n            best_type = df[col].dtype.name\n        # Log the conversion performed.\n        if verbose and best_type is not None and best_type != str(col_type):\n            print(f\"Column '{col}' converted from {col_type} to {best_type}\")\n    \n    if verbose:\n        end_mem = memory_usage_mb(df, deep=deep)\n        diff_mem = start_mem - end_mem\n        percent_mem = 100 * diff_mem / start_mem\n        print(f\"Memory usage decreased from\"\n              f\" {start_mem:.2f}MB to {end_mem:.2f}MB\"\n              f\" ({diff_mem:.2f}MB, {percent_mem:.2f}% reduction)\")\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#変数を安いやつにしてメモリを節約してる\nraw_train_data = reduce_memory_usage(raw_train_data, deep=True, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#デバイスタイプごとの詐欺率\ndeviceType = raw_train_data['DeviceType'].unique()\nfor i, i_device in enumerate(deviceType):\n    deviceData = eval('raw_train_data.loc[raw_train_data[\"DeviceType\"]==\"'+i_device+'\"]')\n    plt.figure(i)\n    sns.countplot(deviceData['isFraud']).set_title(i_device)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"データのマージしたけど　missingデータ多すぎ\nここから良い特徴量を探してみましょう"},{"metadata":{"trusted":true},"cell_type":"code","source":"deviceType","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = list(numericCols) #数値項目をlistに\nvariables.remove('isFraud')   #詐欺判定を除く\ncorrelationMatrix = raw_train_data.loc[:,variables].corr().abs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ヒートマップを作る\nplt.figure(figsize=(20,20))\nheat = sns.heatmap(data=correlationMatrix)\nplt.title('Heatmap of corr')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#数値項目の欠損データだった割合\nna_vals = np.sum(raw_train_data.loc[:,variables]==-1)/ raw_train_data.shape[0]\n\n#欠損値が少ないデータを集めてリストにする\ngoodNumericVars = []\nfor i_var in variables:\n    if na_vals[i_var] < 0.85:\n        goodNumericVars.append(i_var)\n        \ngoodNumericVars.remove('TransactionDT') #経過時間\ngoodNumericVars.remove('TransactionID') #取引ID\ncorrThresh = 0.9 #相関しきい値？\n\n#対角要素のない三角行列をつくる\nupper = correlationMatrix.where(np.triu(np.ones(correlationMatrix.shape), k=1).astype(np.bool))\n\n#相関の大きすぎる値は除く\nto_drop = [column for column in upper.columns if any(upper[column] > corrThresh) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i_var in to_drop:\n    if i_var in goodNumericVars:\n        goodNumericVars.remove(i_var)\n\n#これで使えそうな数値項目が決まりました","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del to_drop,corrThresh,upper,correlationMatrix,na_vals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = list(categoricalCols) #文字列項目\n\n#欠損データの割合\nna_vals = np.sum(raw_train_data.loc[:,variables] == 'missing') / raw_train_data.shape[0]\n\n#文字列項目でつかえそうなやつ\ngoodCategoricalVars = []\nfor i_var in  variables:\n    if na_vals[i_var] < 0.85:\n        goodCategoricalVars.append(i_var)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureToUse = goodNumericVars + goodCategoricalVars\ntrain_data = raw_train_data.loc[:,featureToUse]\ntarget_data = raw_train_data['isFraud']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureToUse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#特徴量を新たに作る\n\n#項目毎の支払い金額の平均\ntrain_data['TransactionAmt_to_mean_card1'] = train_data['TransactionAmt'] / train_data.groupby(['card1'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_card4'] = train_data['TransactionAmt'] / train_data.groupby(['card4'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_card5'] = train_data['TransactionAmt'] / train_data.groupby(['card5'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_ProductCD'] = train_data['TransactionAmt'] / train_data.groupby(['ProductCD'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_addr1'] = train_data['TransactionAmt'] / train_data.groupby(['addr1'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_id31'] = train_data['TransactionAmt'] / train_data.groupby(['id_31'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_devicename'] = train_data['TransactionAmt'] / train_data.groupby(['device_name'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_dow'] = train_data['TransactionAmt'] / train_data.groupby(['Transaction_dow'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_hour'] = train_data['TransactionAmt'] / train_data.groupby(['Transaction_hour'])['TransactionAmt'].transform('mean')\n\n#数値を文字列に変換して項目を作る\ntrain_data['card1_card2'] = train_data['card1'].astype(str) + '_' + train_data['card2'].astype(str)\ntrain_data['addr1_dist1'] = train_data['addr1'].astype(str) + '_' + train_data['dist1'].astype(str)\ntrain_data['card1_addr1'] = train_data['card1'].astype(str) + '_' + train_data['addr1'].astype(str)\ntrain_data['card1_addr2'] = train_data['card1'].astype(str) + '_' + train_data['addr2'].astype(str)\ntrain_data['card2_addr1'] = train_data['card2'].astype(str) + '_' + train_data['addr1'].astype(str)\ntrain_data['card2_addr2'] = train_data['card2'].astype(str) + '_' + train_data['addr2'].astype(str)\ntrain_data['card4_addr1'] = train_data['card4'].astype(str) + '_' + train_data['addr1'].astype(str)\ntrain_data['card4_addr2'] = train_data['card4'].astype(str) + '_' + train_data['addr2'].astype(str)\ntrain_data['DeviceInfo_P_emaildomain'] = train_data['DeviceInfo'].astype(str) + '_' + train_data['P_emaildomain'].astype(str)\ntrain_data['P_emaildomain_addr1'] = train_data['P_emaildomain'].astype(str) + '_' + train_data['addr1'].astype(str)\ntrain_data['id01_addr1'] = train_data['id_01'].astype(str) + '_' + train_data['addr1'].astype(str)\n\n# std(標準偏差)の値で、支払金額を割っている\n#card1を軸にしたTransactionAmtの標準偏差で割る\ntrain_data['TransactionAmt_to_std_card1'] = train_data['TransactionAmt'] / train_data.groupby(['card1'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_card4'] = train_data['TransactionAmt'] / train_data.groupby(['card4'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_card5'] = train_data['TransactionAmt'] / train_data.groupby(['card5'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_ProductCD'] = train_data['TransactionAmt'] / train_data.groupby(['ProductCD'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_addr1'] = train_data['TransactionAmt'] / train_data.groupby(['addr1'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_id31'] = train_data['TransactionAmt'] / train_data.groupby(['id_31'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_devicename'] = train_data['TransactionAmt'] / train_data.groupby(['device_name'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_dow'] = train_data['TransactionAmt'] / train_data.groupby(['Transaction_dow'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_hour'] = train_data['TransactionAmt'] / train_data.groupby(['Transaction_hour'])['TransactionAmt'].transform('std')\n\n#TransactionAmtの小数点以下を１０００倍\ntrain_data['TransactionAmt_decimal'] = ((train_data['TransactionAmt'] - train_data['TransactionAmt'].astype(int)) * 1000).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#軸として支払金額の平均で割る\ntrain_data['TransactionAmt_to_mean_C1'] = train_data['TransactionAmt'] / train_data.groupby(['C1'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_C3'] = train_data['TransactionAmt'] / train_data.groupby(['C3'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_C5'] = train_data['TransactionAmt'] / train_data.groupby(['C5'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_C13'] = train_data['TransactionAmt'] / train_data.groupby(['C13'])['TransactionAmt'].transform('mean')\ntrain_data['TransactionAmt_to_mean_D15'] = train_data['TransactionAmt'] / train_data.groupby(['D15'])['TransactionAmt'].transform('mean')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#軸として支払金額の標準偏差で割る\ntrain_data['TransactionAmt_to_std_C1'] = train_data['TransactionAmt'] / train_data.groupby(['C1'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_C3'] = train_data['TransactionAmt'] / train_data.groupby(['C3'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_C5'] = train_data['TransactionAmt'] / train_data.groupby(['C5'])['TransactionAmt'].transform('std')\ntrain_data['TransactionAmt_to_std_D15'] = train_data['TransactionAmt'] / train_data.groupby(['D15'])['TransactionAmt'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#支払金額をlogにする\ntrain_data['TransactionAmt'] = np.log(train_data['TransactionAmt'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#aqrt(詐欺なし/詐欺あり)\nscale_pos_weight = np.sqrt(len(target_data.loc[target_data==0])/len(target_data.loc[target_data==1]))\ndel raw_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity_data = pd.read_csv(\"../input/ieee-fraud-detection/test_identity.csv\")\ntest_transaction_data = pd.read_csv(\"../input/ieee-fraud-detection/test_transaction.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_transaction_data の項目ごとの欠損データの数を調べてる\nna_columns = test_transaction_data.isna().sum()\nprint(na_columns[na_columns==0])\nprint(na_columns[na_columns>0] / test_transaction_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/fchmiel/day-and-time-powerful-predictive-feature\n\n#時刻に変換\ntest_transaction_data['Transaction_dow'] = np.floor((test_transaction_data['TransactionDT'] / (3600 * 24) - 1) % 7)\ntest_transaction_data['Transaction_hour'] = np.floor(test_transaction_data['TransactionDT'] / 3600) % 24\n\n#取引データ\ntransaction_data_columns = test_transaction_data.columns\n\n#数値項目をとりだす\nnumericCols = test_transaction_data._get_numeric_data().columns\n\n#文字列項目を取り出す\ncategoricalCols = list(set(transaction_data_columns) - set(numericCols))\n\n#欠損値を変換\ntest_transaction_data[categoricalCols] = test_transaction_data[categoricalCols].replace({ np.nan:'missing'})\ntest_transaction_data[numericCols] = test_transaction_data[numericCols].replace({ np.nan:-1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identity_data_columns = test_identity_data.columns\n\n#数値項目の抜き出し\nnumericCols = test_identity_data._get_numeric_data().columns\n\n#文字列項目の抜き出し\ncategoricalCols = list(set(identity_data_columns) - set(numericCols))\n\n#欠損データの置き換え\ntest_identity_data[categoricalCols] = test_identity_data[categoricalCols].replace({ np.nan:'missing'})\ntest_identity_data[numericCols] = test_identity_data[numericCols].replace({ np.nan:-1})\n\n#ブラウザのバージョン名を消す\ntest_identity_data['id_31'] = test_identity_data['id_31'].str.replace('\\d+', '')\n\n#OS名の整頓\ntest_identity_data.loc[test_identity_data['id_30'].str.contains('Mac', na=False), 'id_30'] = 'mac'\ntest_identity_data.loc[test_identity_data['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\ntest_identity_data.loc[test_identity_data['id_30'].str.contains('Android', na=False), 'id_30'] = 'android'\ntest_identity_data.loc[test_identity_data['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\ntest_identity_data.loc[test_identity_data['id_30'].str.contains('Linux', na=False), 'id_30'] = 'Linux'\n\n#デバイス名の整頓\ntest_identity_data['device_name'] = test_identity_data['DeviceInfo'].str.split('/', expand=True)[0]\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\ntest_identity_data.loc[test_identity_data['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n\n#レアなデバイス名をothersにする\ntest_identity_data.loc[test_identity_data.device_name.isin(test_identity_data.device_name.value_counts()[test_identity_data.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TransactionIDを起点にマージする\nraw_test_data = pd.merge(test_transaction_data, test_identity_data, on='TransactionID', how='left')\n\n#取引ID\ntransactionID = raw_test_data.loc[:,'TransactionID']\ndel test_identity_data,test_transaction_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_test_data_columns = raw_test_data.columns\n\n#数値項目を取り出す\nnumericCols = raw_test_data._get_numeric_data().columns\n\n#文字列項目を取り出す\ncategoricalCols = list(set(raw_test_data_columns) - set(numericCols))\nprint('The categorical columns in training data are: ',categoricalCols)\n\n#欠損値を置き換え\nraw_test_data[categoricalCols] = raw_test_data[categoricalCols].replace({ np.nan:'missing'})\nraw_test_data[numericCols] = raw_test_data[numericCols].replace({ np.nan:-1})\n\n#メモリ節約\nraw_test_data = reduce_memory_usage(raw_test_data, deep=True, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = raw_test_data.loc[:,featureToUse]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/artgor/eda-and-models#Feature-engineering\ntest_data['TransactionAmt_to_mean_card1'] = test_data['TransactionAmt'] / test_data.groupby(['card1'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_card4'] = test_data['TransactionAmt'] / test_data.groupby(['card4'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_card5'] = test_data['TransactionAmt'] / test_data.groupby(['card5'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_ProductCD'] = test_data['TransactionAmt'] / test_data.groupby(['ProductCD'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_addr1'] = test_data['TransactionAmt'] / test_data.groupby(['addr1'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_id31'] = test_data['TransactionAmt'] / test_data.groupby(['id_31'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_devicename'] = test_data['TransactionAmt'] / test_data.groupby(['device_name'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_dow'] = test_data['TransactionAmt'] / test_data.groupby(['Transaction_dow'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_hour'] = test_data['TransactionAmt'] / test_data.groupby(['Transaction_hour'])['TransactionAmt'].transform('mean')\ntest_data['card1_card2'] = test_data['card1'].astype(str) + '_' + test_data['card2'].astype(str)\ntest_data['addr1_dist1'] = test_data['addr1'].astype(str) + '_' + test_data['dist1'].astype(str)\ntest_data['card1_addr1'] = test_data['card1'].astype(str) + '_' + test_data['addr1'].astype(str)\ntest_data['card1_addr2'] = test_data['card1'].astype(str) + '_' + test_data['addr2'].astype(str)\ntest_data['card2_addr1'] = test_data['card2'].astype(str) + '_' + test_data['addr1'].astype(str)\ntest_data['card2_addr2'] = test_data['card2'].astype(str) + '_' + test_data['addr2'].astype(str)\ntest_data['card4_addr1'] = test_data['card4'].astype(str) + '_' + test_data['addr1'].astype(str)\ntest_data['card4_addr2'] = test_data['card4'].astype(str) + '_' + test_data['addr2'].astype(str)\ntest_data['DeviceInfo_P_emaildomain'] = test_data['DeviceInfo'].astype(str) + '_' + test_data['P_emaildomain'].astype(str)\ntest_data['P_emaildomain_addr1'] = test_data['P_emaildomain'].astype(str) + '_' + test_data['addr1'].astype(str)\ntest_data['id01_addr1'] = test_data['id_01'].astype(str) + '_' + test_data['addr1'].astype(str)\ntest_data['TransactionAmt_to_std_card1'] = test_data['TransactionAmt'] / test_data.groupby(['card1'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_card4'] = test_data['TransactionAmt'] / test_data.groupby(['card4'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_card5'] = test_data['TransactionAmt'] / test_data.groupby(['card5'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_ProductCD'] = test_data['TransactionAmt'] / test_data.groupby(['ProductCD'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_addr1'] = test_data['TransactionAmt'] / test_data.groupby(['addr1'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_id31'] = test_data['TransactionAmt'] / test_data.groupby(['id_31'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_devicename'] = test_data['TransactionAmt'] / test_data.groupby(['device_name'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_dow'] = test_data['TransactionAmt'] / test_data.groupby(['Transaction_dow'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_hour'] = test_data['TransactionAmt'] / test_data.groupby(['Transaction_hour'])['TransactionAmt'].transform('std')\n# New feature - decimal part of the transaction amount.\ntest_data['TransactionAmt_decimal'] = ((test_data['TransactionAmt'] - test_data['TransactionAmt'].astype(int)) * 1000).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['TransactionAmt_to_mean_C1'] = test_data['TransactionAmt'] / test_data.groupby(['C1'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_C3'] = test_data['TransactionAmt'] / test_data.groupby(['C3'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_C5'] = test_data['TransactionAmt'] / test_data.groupby(['C5'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_C13'] = test_data['TransactionAmt'] / test_data.groupby(['C13'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_mean_D15'] = test_data['TransactionAmt'] / test_data.groupby(['D15'])['TransactionAmt'].transform('mean')\ntest_data['TransactionAmt_to_std_C1'] = test_data['TransactionAmt'] / test_data.groupby(['C1'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_C3'] = test_data['TransactionAmt'] / test_data.groupby(['C3'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_C5'] = test_data['TransactionAmt'] / test_data.groupby(['C5'])['TransactionAmt'].transform('std')\ntest_data['TransactionAmt_to_std_D15'] = test_data['TransactionAmt'] / test_data.groupby(['D15'])['TransactionAmt'].transform('std')\n\ntest_data['TransactionAmt'] = np.log(test_data['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#使えるデータを追加\ngoodCategoricalVars.append('card1_addr1')\ngoodCategoricalVars.append('card1_addr2')\ngoodCategoricalVars.append('card2_addr1')\ngoodCategoricalVars.append('card2_addr2')\ngoodCategoricalVars.append('card4_addr1')\ngoodCategoricalVars.append('card4_addr2')\ngoodCategoricalVars.append('DeviceInfo_P_emaildomain')\ngoodCategoricalVars.append('P_emaildomain_addr1')\ngoodCategoricalVars.append('id01_addr1')\ngoodCategoricalVars.append('card1_card2')\ngoodCategoricalVars.append('device_name')\ngoodCategoricalVars.append('addr1_dist1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n#LabelEncoder 文字列を数値に変換する\n#['amsterdam', 'paris', 'tokyo']\n#le.transform([\"tokyo\", \"tokyo\", \"paris\"]) \n#array([2, 2, 1]...)\n\nfor i_cat in goodCategoricalVars:\n    le = LabelEncoder()\n    curData = pd.concat([train_data.loc[:,i_cat],test_data.loc[:,i_cat]],axis = 0)\n    le.fit(curData)\n    train_data.loc[:,i_cat] = le.transform(train_data.loc[:,i_cat])   \n    test_data.loc[:,i_cat] = le.transform(test_data.loc[:,i_cat])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The shape of training data is:',np.shape(train_data))\ndel raw_test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold,GroupKFold\nfrom sklearn.metrics import roc_curve, auc\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\n\n#group_kfold = GroupKFold(n_splits=5)\ncv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_roc_auc(clf,index):\n    y_predict = clf.predict_proba(train_data.iloc[index])[:,1]\n    fpr, tpr, thresholds = roc_curve(target_data.iloc[index], y_predict)\n    auc_score = auc(fpr, tpr)\n    return fpr, tpr, auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LBGMには多くのパラメータがあります\nparams = {'bagging_fraction': 0.7982116702024386, \n          'feature_fraction': 0.1785051643813966, \n          'max_depth': int(49.17611603427576), \n          'min_child_weight': 3.2852905549011155, \n          'min_data_in_leaf': int(31.03480802715621), \n          'n_estimators': int(1491.3676131788188), \n          'num_leaves': int(52.851307790411965), \n          'reg_alpha': 0.45963319421692145, \n          'reg_lambda': 0.6591286807489907, \n          'metric':'auc',\n          'boosting_type': 'dart', \n          'colsample_bytree':.8, \n          'subsample':.9, \n          'min_split_gain':.01, \n          'max_bin':127, \n          'bagging_freq':5, \n          'learning_rate':0.1 , \n          'early_stopping_rounds':500 }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fprs_lgb, tprs_lgb, scores_lgb = [], [], []\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = train_data.columns     \npredictions = np.zeros(len(test_data))\nfor (train, test), i in zip(cv.split(train_data, target_data), range(5)):\n    lgb_best = LGBMClassifier(boosting = params['boosting_type'],n_estimators =  params['n_estimators'],\n                     learning_rate =  params['learning_rate'],num_leaves =  params['num_leaves'],\n                     colsample_bytree = params['colsample_bytree'],subsample =  params['subsample'],\n                     max_depth =  params['max_depth'],reg_alpha =  params['reg_alpha'],\n                     reg_lambda =  params['reg_lambda'],min_split_gain =  params['min_split_gain'],\n                     min_child_weight =  params['min_child_weight'],max_bin =  params['max_bin'],\n                     bagging_freq =  params['bagging_freq'],feature_fraction =  params['feature_fraction'],\n                     bagging_fraction =  params['bagging_fraction'],min_data_in_leaf = params['min_data_in_leaf'],\n                             early_stopping_rounds = params['early_stopping_rounds'])\n    lgb_best.fit(train_data.iloc[train,:], target_data.iloc[train],\n                 eval_set = [(train_data.iloc[train,:], target_data.iloc[train]), \n                             (train_data.iloc[test,:], target_data.iloc[test])],eval_metric='auc',verbose = 200)\n    feature_importances['fold_{}'.format(i + 1)] = lgb_best.feature_importances_\n    _, _, auc_score_train = compute_roc_auc(lgb_best,train)\n    fpr, tpr, auc_score = compute_roc_auc(lgb_best,test)\n    scores_lgb.append((auc_score_train, auc_score))\n    fprs_lgb.append(fpr)\n    tprs_lgb.append(tpr) \n    predictions += lgb_best.predict_proba(test_data, num_iteration=lgb_best.best_iteration_)[:,1]/cv.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nlw = 2\ncolors = ['black','red','blue','darkorange','green']\nfor i in range(0,5):\n    plt.plot(fprs_lgb[i], tprs_lgb[i], color=colors[i],\n             lw=lw, label='ROC curve (area = %0.5f)' % scores_lgb[i][1])\n    \nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean AUC:', np.mean(scores_lgb,axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances['average'] = feature_importances[['fold_{}'.format(fold + 1) for fold in range(cv.n_splits)]].mean(axis=1)\nplt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\nplt.title('50 TOP feature importance over {} folds average'.format(cv.n_splits));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'TransactionID':transactionID,'isFraud':predictions}\nsubmissionDF = pd.DataFrame(data)\nsubmissionDF.to_csv('sample_submission2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}