{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Imports and Functions"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom category_encoders import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom catboost import CatBoostClassifier\n\nimport os, gc, warnings, time\n\nrandom_state = 42","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def read_data(debug_mode = False):\n    if debug_mode:\n        nrows = 100000\n    else:\n        nrows = None\n  \n    data_path = '../input/'\n    train_identity = pd.read_csv(os.path.join(data_path, 'train_identity.csv'))\n    train_transaction = pd.read_csv(os.path.join(data_path, 'train_transaction.csv'), nrows = nrows)\n    test_identity = pd.read_csv(os.path.join(data_path, 'test_identity.csv'),)\n    test_transaction =pd.read_csv(os.path.join(data_path, 'test_transaction.csv'), nrows = nrows)\n   \n    train = pd.merge(train_transaction, train_identity, on= 'TransactionID', how = 'left')    \n    test = pd.merge(test_transaction, test_identity, on= 'TransactionID', how = 'left')  \n    del train_identity, train_transaction, test_identity, test_transaction\n    gc.collect()\n    \n    \n    print('Finished Reading Data')\n    return train, test\n    \n\ndef get_cat_num_cols(df):\n    cat_cols = ['DeviceType', 'DeviceInfo', 'ProductCD', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain']\n    cat_cols +=  ['M' + str(i) for i in range(1,10)]\n    cat_cols += ['card' + str(i) for i in range(1,7)]\n    cat_cols += ['id_' + str(i) for i in range(12,39)]\n    \n    all_cols = df.columns.tolist()\n    num_cols = [x for x in all_cols if x not in cat_cols]\n    num_cols.remove('TransactionID')\n    num_cols.remove('isFraud')\n    return cat_cols, num_cols\n\ndef set_ordinal_encoding(train, test, cat_cols):   \n    oe = OrdinalEncoder( cols = cat_cols, handle_missing = 'return_nan')\n    train[cat_cols] = oe.fit_transform(train[cat_cols])\n    test[cat_cols] =   oe.transform(test[cat_cols])\n    print('Finished: Ordinal Encoding')\n    return train, test\n\n\ndef get_train_test(train, test):\n#     X_train =  df[df['isFraud'].notnull()]\n#     X_test  =  df[df['isFraud'].isnull()]\n    y_train = train.isFraud\n    sub = pd.DataFrame()\n    sub['TransactionID'] = test['TransactionID']\n    X_train = train.drop(['TransactionID', 'isFraud'], axis = 1)\n    X_test =  test.drop(['TransactionID'], axis = 1)\n    return X_train, X_test, y_train, sub\n\ndef plot_feature_imp(feature_imp, top_n = 30):\n#     feature_imp = pd.DataFrame()\n#     feature_imp['feature'] = model.feature_name()\n#     feature_imp['importance']  = model.feature_importance()\n    feature_imp = feature_imp.sort_values(['importance'], ascending = False)\n    feature_imp_disp = feature_imp.head(top_n)\n    plt.figure(figsize=(10, 12))\n    sns.barplot(x=\"importance\", y=\"feature\", data=feature_imp_disp)\n    plt.title('LightGBM Features')\n    plt.show() \n    \n    \ndef cv_results(y_valid, y_prob, verbose = True):   \n    scores = {}                      \n    y_pred_class =  [0  if x < 0.5 else 1 for x in y_prob]\n    scores['cv_accuracy']  = accuracy_score(y_valid, y_pred_class)\n    scores['cv_auc']       = roc_auc_score(y_valid, y_prob)\n    scores['cv_f1']      =   f1_score(y_valid, y_pred_class, average = 'binary')\n    if verbose:\n        print('CV accuracy {:0.5f}'.format( scores['cv_accuracy'] ))\n        print('CV AUC  {:0.5f}'.format( scores['cv_auc']   ))\n        print('CV F1 %0.5f' %scores['cv_f1'] )\n    return scores  \n\ndef run_lgb_with_cv(params, X_train, y_train, X_test, verbose_eval = 100):\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, \n                                                      random_state = random_state, stratify = y_train)\n    print('Train shape{} Valid Shape{}, Test Shape {}'.format(X_train.shape, X_valid.shape, X_test.shape))\n\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_valid  = lgb.Dataset(X_valid, y_valid)\n    early_stopping_rounds = 200\n    lgb_results = {}\n    \n#     start_time = time.time()\n    warnings.filterwarnings(\"ignore\", message=\"categorical_feature in Dataset is overridden\")\n    model = lgb.train(params,\n                      lgb_train,\n                      num_boost_round = 10000,\n                      valid_sets =  [lgb_train,lgb_valid],\n                      early_stopping_rounds = early_stopping_rounds,                    \n#                       categorical_feature = cat_cols,\n                      evals_result = lgb_results,\n                      verbose_eval = verbose_eval\n                       )\n    y_prob_valid = model.predict(X_valid)    \n    cv_results(y_valid, y_prob_valid, verbose = True)\n  \n    feature_imp = pd.DataFrame()\n    feature_imp['feature'] = model.feature_name()\n    feature_imp['importance']  = model.feature_importance()\n    return model, feature_imp\n\n\ndef run_lgb_simple(debug_mode = True):\n    \n    data= read_data(debug_mode = debug_mode)\n    \n    cat_cols, num_cols = get_cat_num_cols(data)\n    \n    data = set_ordinal_encoding(data, cat_cols) \n    \n    X_train, X_test, y_train, sub = get_train_test(data)\n    del data\n    gc.collect()\n    \n    params = {}\n    params['learning_rate'] = 0.1 #\n    params['boosting_type'] = 'gbdt'\n    params['objective'] = 'binary'\n    params['seed'] =  random_state\n    params['metric'] =    'auc'\n    params['num_leaves'] =  60\n    # params['bagging_fraction'] = 0.7\n    # params['bagging_freq'] = 1\n    # params['feature_fraction'] = 0.8\n    # params['scale_pos_weight'] = 3\n    # params['max_bin'] = 63\n\n    model, feature_imp =  run_lgb_with_cv(params, X_train, y_train, X_test, cat_cols, verbose_eval = 100)\n    \n    plot_feature_imp(feature_imp, top_n = 50)\n    \n    y_prob_test = model.predict(X_test)\n    sub['isFraud'] = y_prob_test\n    sub.to_csv('lgb_sub.csv', index=False)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain, test = read_data(debug_mode = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# #Frequency Encoding: Create a new column which counts combined occurance of each value in both train and test\n# for col in cat_cols:\n#     train[col + '_count'] = train[col].map(pd.concat([train[col], test[col]], ignore_index=True).value_counts(dropna=False))\n#     test[col + '_count']  = test[col].map(pd.concat([train[col], test[col]], ignore_index=True).value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#For cat boost the categorical columns need not to be encoded to integers but NaN values must be imputed\ncat_cols, num_cols = get_cat_num_cols(train)\nmode = train.filter(cat_cols).mode()\ntrain[cat_cols]= train[cat_cols].fillna(value=mode.iloc[0])\ntest[cat_cols]= test[cat_cols].fillna(value=mode.iloc[0])\ntrain, test = set_ordinal_encoding(train, test, cat_cols)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# freq_cols = ['card1']\n# for col in freq_cols:\n#     cat_cols.remove(col)\n#     train[col + '_count'] = train[col].map(pd.concat([train[col], test[col]], ignore_index=True).value_counts(dropna=False))\n#     test[col + '_count']  = test[col].map(pd.concat([train[col], test[col]], ignore_index=True).value_counts(dropna=False))\n\n# # Decimal part of Transaction Amount\n# train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\n# test['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, sub = get_train_test(train, test)\ndel train, test\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_tr, X_valid, y_tr, y_valid = train_test_split(X_train, y_train, test_size = 0.2, \n                                                      random_state = random_state, shuffle =False)\n\ncat_cols_idx = [ X_train.columns.tolist().index(i) for i in  cat_cols ]\n\nprint('Train shape{} Valid Shape{}, Test Shape {}'.format(X_train.shape, X_valid.shape, X_test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel   =  CatBoostClassifier(  iterations= 20000,\n                                loss_function='Logloss',\n                                eval_metric='AUC',\n                                grow_policy = 'Lossguide',\n                                learning_rate = 0.05,\n                                   max_leaves = 64,\n                                task_type='GPU',\n                                od_type = 'Iter',   #The type of the overfitting detector to use\n                                od_wait = 300,      #Stop after n iterations\n                                verbose = 200,\n#                                 max_ctr_complexity = 1, #To improve Performance\n#                                 border_count = 32, #To improve performance\n                                random_seed = random_state  )\n\nmodel.fit(\n          X =  X_tr,\n          y =  y_tr,\n          cat_features=  cat_cols_idx ,    \n          \n          eval_set= (X_valid, y_valid),                       \n          use_best_model = True ,\n          logging_level = 'Verbose'\n        )  \n\ndel X_tr, y_tr\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_rounds = int(model.best_iteration_ + 0.15 * model.best_iteration_)\nmodel   =  CatBoostClassifier(  iterations= num_rounds,\n                                loss_function='Logloss',\n                                 grow_policy = 'Lossguide',\n                                 max_leaves = 64,\n                                eval_metric='AUC',\n                                learning_rate = 0.05,\n                                task_type='GPU',\n#                                 od_type = 'Iter',   #The type of the overfitting detector to use\n#                                 od_wait = 300,      #Stop after n iterations\n                                verbose = 200,\n#                                 max_ctr_complexity = 1, #To improve Performance\n#                                 border_count = 32, #To improve performance\n                                random_seed = random_state  )\n\nmodel.fit(\n          X =  X_train,\n          y =  y_train,\n          cat_features=  cat_cols_idx ,    \n          \n#           eval_set= (X_valid, y_valid),                       \n          use_best_model = False ,\n          logging_level = 'Verbose'\n        )            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prob_valid = model.predict(X_valid, prediction_type = 'Probability')[:,-1]    \ncv_results(y_valid, y_prob_valid, verbose = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance and submit predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_feature_imp(feature_imp, top_n = 50)\n# feature_imp.to_csv('feature_imp.csv', index = False)\n\ny_prob_test = model.predict(X_test, prediction_type = 'Probability')[:,-1]\nsub['isFraud'] = y_prob_test\nsub.to_csv('cb_sub.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}