{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" **IEEE-CIS Fraud Detection**\n\nThe data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features.\n\n**What is fraud detection?**:  Fraud detection protects person information, assets, accounts and transactions through the real-time, near-real-time analysis of activities by users and other defined entities. It uses background server-based processes that examine users’ and other defined entities’ access and behavior patterns, and typically compares this information to a profile of what’s expected. \n","metadata":{}},{"cell_type":"markdown","source":"**Data Description**\n\n**Transaction Table**\n* TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n* TransactionAMT: transaction payment amount in USD\n* ProductCD: product code, the product for each transaction\n* card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n* addr: address\n* dist: distance\n* P_ and (R__) emaildomain: purchaser and recipient email domain\n* C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n* D1-D15: timedelta, such as days between previous transaction, etc.\n* M1-M9: match, such as names on card and address, etc.\n* Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n* Categorical Features:\nProductCD,\ncard1 - card6,\naddr1, addr2,\nP_emaildomain,\nR_emaildomain,\nM1 - M9\n\n**Identity Table**\nVariables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions.\nThey're collected by Vesta’s fraud protection system and digital security partners.\n(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n\n* Categorical Features:\nDeviceType,\nDeviceInfo,\nid_12 - id_38","metadata":{}},{"cell_type":"markdown","source":"**There is three problems related to datatsets.***\n1. Columns name are masked \n2. Imbalanced dataset\n3. Time series dataset","metadata":{}},{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import datetime\nimport re\nimport gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom sklearn.model_selection import cross_validate, GridSearchCV, validation_curve,RandomizedSearchCV\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import KFold, StratifiedKFold,TimeSeriesSplit, GroupKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, \\\n    roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:46:05.274551Z","iopub.execute_input":"2021-09-01T12:46:05.274936Z","iopub.status.idle":"2021-09-01T12:46:08.524992Z","shell.execute_reply.started":"2021-09-01T12:46:05.274855Z","shell.execute_reply":"2021-09-01T12:46:08.524106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing Train and Test datasets**","metadata":{}},{"cell_type":"code","source":"train_identity= pd.read_csv(\"../input/ieee-fraud-detection/train_identity.csv\")\ntrain_transaction= pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')                           ","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:46:08.526442Z","iopub.execute_input":"2021-09-01T12:46:08.526756Z","iopub.status.idle":"2021-09-01T12:46:43.878997Z","shell.execute_reply.started":"2021-09-01T12:46:08.526722Z","shell.execute_reply":"2021-09-01T12:46:43.878165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.merge(train_transaction, train_identity, on=\"TransactionID\", how=\"left\")\n\ndf_train.columns = [col.lower() for col in df_train.columns]\ndf_train.head(20)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-01T12:46:43.881433Z","iopub.execute_input":"2021-09-01T12:46:43.882023Z","iopub.status.idle":"2021-09-01T12:46:50.605589Z","shell.execute_reply.started":"2021-09-01T12:46:43.881966Z","shell.execute_reply":"2021-09-01T12:46:50.604761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_identity= pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')\ntest_identity=test_identity.set_axis(['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo'], axis=1)\ntest_transaction= pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')\n\ndf_test=pd.merge(test_transaction, test_identity, on=\"TransactionID\", how=\"left\")\n\ndf_test.columns = [col.lower() for col in df_test.columns]\ndf_test.head(20)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-01T12:46:50.607092Z","iopub.execute_input":"2021-09-01T12:46:50.607582Z","iopub.status.idle":"2021-09-01T12:47:23.373744Z","shell.execute_reply.started":"2021-09-01T12:46:50.607545Z","shell.execute_reply":"2021-09-01T12:47:23.37277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:23.37497Z","iopub.execute_input":"2021-09-01T12:47:23.375355Z","iopub.status.idle":"2021-09-01T12:47:23.510904Z","shell.execute_reply.started":"2021-09-01T12:47:23.375319Z","shell.execute_reply":"2021-09-01T12:47:23.510083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function of missing values\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 1)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df , end=\"\\n\")\n    if na_name:\n        return na_columns\n\n#function of one hot encoding\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe    \n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:23.512255Z","iopub.execute_input":"2021-09-01T12:47:23.512594Z","iopub.status.idle":"2021-09-01T12:47:23.519939Z","shell.execute_reply.started":"2021-09-01T12:47:23.51256Z","shell.execute_reply":"2021-09-01T12:47:23.51908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"#deal with missing values\nmissing_values_table(df_train, na_name=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:23.521442Z","iopub.execute_input":"2021-09-01T12:47:23.522049Z","iopub.status.idle":"2021-09-01T12:47:32.093614Z","shell.execute_reply.started":"2021-09-01T12:47:23.521999Z","shell.execute_reply":"2021-09-01T12:47:32.091741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vxx features and id_xx features have high nulity ratio.Since we do not know what these features exactly present, we reduce of Vxx cols. \nreference: https://www.kaggle.com/cdeotte/eda-for-columns-v-and-id\nAlso PCA is usefull method for Vxx features.","metadata":{}},{"cell_type":"code","source":"#Reducing Vxx Columns\n#Determining which columns are related by the number of NANs present\n#Finding groups of Vs with similar NAN structure\n\nnans_df= df_train.isna()\nnans_group={}\ni_cols=[\"v\" + str(i) for i in range (1,340)]\nfor col in df_train.columns:\n    cur_group=nans_df[col].sum()\n    try:\n        nans_group[cur_group].append(col)\n    except:\n        nans_group[cur_group]=[col]\ndel nans_df; x=gc.collect()\n\nfor k, v in nans_group.items():\n    print(\"##NAN count=\", k)\n    print(v)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-01T12:47:32.096509Z","iopub.execute_input":"2021-09-01T12:47:32.096789Z","iopub.status.idle":"2021-09-01T12:47:33.704448Z","shell.execute_reply.started":"2021-09-01T12:47:32.096759Z","shell.execute_reply":"2021-09-01T12:47:33.703659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finding subsets within the groups that are highly correlated\n##NAN count= 1269\n#['d1', 'v281', 'v282', 'v283', 'v288', 'v289', 'v296', 'v300', 'v301', 'v313', 'v314', 'v315']\n#Replacing all groups with one column from each subset.\n\nvs=nans_group[1269]\nvtitle=\"v281-v315, d1 \"\n\ndef make_corr(vs, vtitle=\"\"):\n    cols= [\"transactiondt\"] + vs\n    plt.figure(figsize=(15,15))\n    sns.heatmap(df_train[cols].corr(), cmap=\"RdBu_r\", annot=True, center=0.0)\n    if vtitle!=\"\" : plt.title(vtitle, fontsize=14)\n    else: plt.title(vs[0]+\"\"+vs[-1], fontsize= 14)\n    plt.show()\nmake_corr(vs,vtitle)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:33.706306Z","iopub.execute_input":"2021-09-01T12:47:33.706617Z","iopub.status.idle":"2021-09-01T12:47:34.953293Z","shell.execute_reply.started":"2021-09-01T12:47:33.706582Z","shell.execute_reply":"2021-09-01T12:47:34.952379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grps = [[281],[282,283],[288,289],[296],[300,301],[313,314,315]]\n\ndef reduce_group(grps, c=\"v\"):\n    use=[]\n    for g in grps:\n        mx=0; vx=g[0]\n        for gg in g:\n            n=df_train[c+ str(gg)].nunique()\n            if n> mx:\n                mx=n\n                vx=gg\n        use.append(vx)\n    print(\"Use these\", use)\n    \nreduce_group(grps)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:34.954384Z","iopub.execute_input":"2021-09-01T12:47:34.954705Z","iopub.status.idle":"2021-09-01T12:47:35.045641Z","shell.execute_reply.started":"2021-09-01T12:47:34.954667Z","shell.execute_reply":"2021-09-01T12:47:35.044739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Vcols after reducing\n\nV=  [1, 2, 5, 6, 8, 11]\nV+= [13, 14, 16, 20, 24, 26, 27, 30]\nV+= [36, 37, 40, 41, 45, 47, 49]\nV+= [54, 56, 60, 62, 65, 67, 68, 70]\nV+= [76, 77, 80, 82, 86, 88, 89, 91]\nV+= [96, 98, 99, 104, 107, 114, 111, 115, 117, 120, 121, 123, 124, 127, 129, 130, 136]\nV+= [138, 140, 142, 147, 156, 162]\nV+= [165, 160, 166]\nV+= [178, 176, 173, 182, 190, 203, 205, 207, 215]\nV+= [169, 171, 175, 180, 185, 188, 198, 210, 209]\nV+= [218, 223, 224, 226, 228, 229, 235, 240, 258, 246, 253, 252, 260, 261, 264, 266, 267, 274, 277]\nV+= [220, 222, 234, 238, 250, 271]\nV+= [294, 284, 285, 286, 291, 297, 303, 305, 307, 309, 310, 320]\nV+= [332, 325, 335, 338]\nV+= [281, 283, 289, 296, 300, 314]\n\nprint(\"reduced set has\", len (V), \"columns\")","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:35.046828Z","iopub.execute_input":"2021-09-01T12:47:35.047172Z","iopub.status.idle":"2021-09-01T12:47:35.062326Z","shell.execute_reply.started":"2021-09-01T12:47:35.04714Z","shell.execute_reply":"2021-09-01T12:47:35.061332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#New df_train and df_test\nv_cols=[\"v\" + str(i) for i in range (1,340)]\nnew_v_cols = ['v'+str(x) for x  in V]\ndroped_v_cols = [col for col in v_cols if col not in new_v_cols]\ndf_train.drop(df_train[droped_v_cols], inplace=True, axis=1)\ndf_test.drop(df_test[droped_v_cols], inplace=True, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:35.063699Z","iopub.execute_input":"2021-09-01T12:47:35.064104Z","iopub.status.idle":"2021-09-01T12:47:38.453239Z","shell.execute_reply.started":"2021-09-01T12:47:35.064065Z","shell.execute_reply":"2021-09-01T12:47:38.452352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Drop missing features which have 85% missing value ratio**","metadata":{}},{"cell_type":"code","source":"null_cols= df_train[['id_01',\"id_03\",\"id_04\",'id_07','id_08',\"id_09\",\"id_10\",'id_21', 'id_22', 'id_23',\n                     'id_24', 'id_25', 'id_26', 'id_27','id_33', 'id_13',\"id_34\",\n                     'id_14','id_17', 'id_18','id_19', 'id_20', 'id_32',\"dist2\",\"d7\", \"d13\", \"d14\",\"d12\"]]\n\ndf_train.drop(null_cols, axis=1, inplace=True)\ndf_test.drop(null_cols, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:38.454571Z","iopub.execute_input":"2021-09-01T12:47:38.454947Z","iopub.status.idle":"2021-09-01T12:47:39.226183Z","shell.execute_reply.started":"2021-09-01T12:47:38.454914Z","shell.execute_reply":"2021-09-01T12:47:39.225302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Re-grouping of categorical features**","metadata":{}},{"cell_type":"code","source":"#p_emaildomain_train\n\ndf_train[\"p_emaildomain\"].unique()\ndf_train[\"p_emaildomain\"].value_counts()\n\ndf_train.loc[df_train[\"p_emaildomain\"].isin(['gmail.com', \"gmail\"]), \"p_emaildomain\"]= \"Google\"\ndf_train.loc[df_train[\"p_emaildomain\"].isin(['yahoo.com', \"yahoo.com.mx\", 'yahoo.fr', 'yahoo.de','yahoo.es','yahoo.co.uk','yahoo.co.jp']), \"p_emaildomain\"]= \"Yahoo Mail\"\ndf_train.loc[df_train[\"p_emaildomain\"].isin(['outlook.com', 'msn.com', 'live.com','live.com.mx', 'outlook.es','live.fr','hotmail.com','hotmail.es', 'hotmail.fr', 'hotmail.de', 'hotmail.co.uk' ]), \"p_emaildomain\"]= \"Microsoft\"\ndf_train.loc[df_train[\"p_emaildomain\"].isin(['aol.com' ]), \"p_emaildomain\"]= \"Aol\"\ndf_train.loc[df_train[\"p_emaildomain\"].isin(['anonymous.com' ]), \"p_emaildomain\"]= \"Anonymous\"\ndf_train.loc[df_train[\"p_emaildomain\"].isin(df_train[\"p_emaildomain\"].value_counts()[df_train[\"p_emaildomain\"].value_counts()<=8000].index), \"p_emaildomain\"]= \"Others\"\n#others belirlemek için girdiğimiz değer aldığımız sample a göre değişiyor\ndf_train[\"p_emaildomain\"].fillna(\"NoInf\", inplace=True)\ndf_train[\"p_emaildomain\"].value_counts()\np_email_domain_ratio = (df_train[\"p_emaildomain\"].value_counts() / df_train.shape[0] * 100).sort_values(ascending=False)\n\n\n\n#p_emaildomain_test\n\ndf_test[\"p_emaildomain\"].unique()\ndf_test[\"p_emaildomain\"].value_counts()\n\ndf_test.loc[df_test[\"p_emaildomain\"].isin(['gmail.com', \"gmail\"]), \"p_emaildomain\"]= \"Google\"\ndf_test.loc[df_test[\"p_emaildomain\"].isin(['yahoo.com', \"yahoo.com.mx\", 'yahoo.fr', 'yahoo.de','yahoo.es','yahoo.co.uk','yahoo.co.jp']), \"p_emaildomain\"]= \"Yahoo Mail\"\ndf_test.loc[df_test[\"p_emaildomain\"].isin(['outlook.com', 'msn.com', 'live.com','live.com.mx', 'outlook.es','live.fr','hotmail.com','hotmail.es', 'hotmail.fr', 'hotmail.de', 'hotmail.co.uk' ]), \"p_emaildomain\"]= \"Microsoft\"\ndf_test.loc[df_test[\"p_emaildomain\"].isin(['aol.com' ]), \"p_emaildomain\"]= \"Aol\"\ndf_test.loc[df_test[\"p_emaildomain\"].isin(['anonymous.com' ]), \"p_emaildomain\"]= \"Anonymous\"\ndf_test.loc[df_test[\"p_emaildomain\"].isin(df_test[\"p_emaildomain\"].value_counts()[df_test[\"p_emaildomain\"].value_counts()<=21000].index), \"p_emaildomain\"]= \"Others\"\n#others belirlemek için girdiğimiz değer aldığımız sample a göre değişiyor\ndf_test[\"p_emaildomain\"].fillna(\"NoInf\", inplace=True)\np_email_domain_ratio = (df_test[\"p_emaildomain\"].value_counts() / df_test.shape[0] * 100).sort_values(ascending=False)\n\n#r_emaildomain_train\n\ndf_train[\"r_emaildomain\"].unique()\ndf_train[\"r_emaildomain\"].value_counts()\n\ndf_train.loc[df_train[\"r_emaildomain\"].isin(['gmail.com', \"gmail\"]), \"r_emaildomain\"]= \"Google\"\ndf_train.loc[df_train[\"r_emaildomain\"].isin(['yahoo.com', \"yahoo.com.mx\", 'yahoo.fr', 'yahoo.de','yahoo.es','yahoo.co.uk','yahoo.co.jp']), \"r_emaildomain\"]= \"Yahoo Mail\"\ndf_train.loc[df_train[\"r_emaildomain\"].isin(['outlook.com', 'msn.com', 'live.com','live.com.mx', 'outlook.es','live.fr','hotmail.com','hotmail.es', 'hotmail.fr', 'hotmail.de', 'hotmail.co.uk' ]), \"r_emaildomain\"]= \"Microsoft\"\ndf_train.loc[df_train[\"r_emaildomain\"].isin(['aol.com']), \"r_emaildomain\"]= \"Aol\"\ndf_train.loc[df_train[\"r_emaildomain\"].isin(['anonymous.com']), \"r_emaildomain\"]= \"Anonymous\"\ndf_train.loc[df_train[\"r_emaildomain\"].isin(df_train[\"r_emaildomain\"].value_counts()[df_train[\"r_emaildomain\"].value_counts()<=2000].index), \"r_emaildomain\"]= \"Others\"\ndf_train[\"r_emaildomain\"].fillna(\"NoInf\", inplace=True)\nr_email_domain_ratio = (df_train[\"r_emaildomain\"].value_counts() / df_train.shape[0] * 100).sort_values(ascending=False)\n\n\n#r_emaildomain_test\n\ndf_test[\"r_emaildomain\"].unique()\ndf_test[\"r_emaildomain\"].value_counts()\n\ndf_test.loc[df_test[\"r_emaildomain\"].isin(['gmail.com', \"gmail\"]), \"r_emaildomain\"]= \"Google\"\ndf_test.loc[df_test[\"r_emaildomain\"].isin(['yahoo.com', \"yahoo.com.mx\", 'yahoo.fr', 'yahoo.de','yahoo.es','yahoo.co.uk','yahoo.co.jp']), \"r_emaildomain\"]= \"Yahoo Mail\"\ndf_test.loc[df_test[\"r_emaildomain\"].isin(['outlook.com', 'msn.com', 'live.com','live.com.mx', 'outlook.es','live.fr','hotmail.com','hotmail.es', 'hotmail.fr', 'hotmail.de', 'hotmail.co.uk' ]), \"r_emaildomain\"]= \"Microsoft\"\ndf_test.loc[df_test[\"r_emaildomain\"].isin(['aol.com']), \"r_emaildomain\"]= \"Aol\"\ndf_test.loc[df_test[\"r_emaildomain\"].isin(['anonymous.com']), \"r_emaildomain\"]= \"Anonymous\"\ndf_test.loc[df_test[\"r_emaildomain\"].isin(df_test[\"r_emaildomain\"].value_counts()[df_test[\"r_emaildomain\"].value_counts()<=3000].index), \"r_emaildomain\"]= \"Others\"\ndf_test[\"r_emaildomain\"].fillna(\"NoInf\", inplace=True)\nr_email_domain_ratio = (df_test[\"r_emaildomain\"].value_counts() / df_test.shape[0] * 100).sort_values(ascending=False)\n\n#id_30 train\ndf_train[\"id_30\"].unique()\n\ndf_train.loc[df_train[\"id_30\"].str.contains(\"Windows\", na=False), \"id_30\"] = \"Windows\"\ndf_train.loc[df_train[\"id_30\"].str.contains(\"iOS\", na=False), \"id_30\"] = \"iOS\"\ndf_train.loc[df_train[\"id_30\"].str.contains(\"Mac OS\", na=False), \"id_30\"] = \"Mac\"\ndf_train.loc[df_train[\"id_30\"].str.contains(\"Android\", na=False), \"id_30\"] = \"Android\"\ndf_train[\"id_30\"].fillna(\"NAN\", inplace=True)\n\n\n#id_30 test\ndf_test[\"id_30\"].unique()\n\ndf_test.loc[df_test[\"id_30\"].str.contains(\"Windows\", na=False), \"id_30\"] = \"Windows\"\ndf_test.loc[df_test[\"id_30\"].str.contains(\"iOS\", na=False), \"id_30\"] = \"iOS\"\ndf_test.loc[df_test[\"id_30\"].str.contains(\"Mac OS\", na=False), \"id_30\"] = \"Mac\"\ndf_test.loc[df_test[\"id_30\"].str.contains(\"Android\", na=False), \"id_30\"] = \"Android\"\ndf_test[\"id_30\"].fillna(\"NAN\", inplace=True)\n\n\n#id_31 train\ndf_train[\"id_31\"].unique()\ndf_train[\"id_31\"].value_counts()\n\ndf_train.loc[df_train[\"id_31\"].str.contains(\"chrome\", na=False), \"id_31\"] = \"Chrome\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"firefox\", na=False), \"id_31\"] = \"Firefox\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"safari\", na=False), \"id_31\"] = \"Safari\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"edge\", na=False), \"id_31\"] = \"Edge\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"ie\", na=False), \"id_31\"] = \"IE\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"samsung\", na=False), \"id_31\"] = \"Samsung\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"opera\", na=False), \"id_31\"] = \"Opera\"\ndf_train.loc[df_train[\"id_31\"].str.contains(\"google\", na=False), \"id_31\"] = \"Google Search Application\"\ndf_train[\"id_31\"].fillna(\"NAN\", inplace=True)\ndf_train.loc[df_train[\"id_31\"].isin(df_train[\"id_31\"].value_counts()[df_train[\"id_31\"].value_counts()< 500].index), \"id_31\"]= \"Others\"\n\n\n#id_31 test\n\ndf_test[\"id_31\"].unique()\ndf_test[\"id_31\"].value_counts()\n\ndf_test.loc[df_test[\"id_31\"].str.contains(\"chrome\", na=False), \"id_31\"] = \"Chrome\"\ndf_test.loc[df_test[\"id_31\"].str.contains(\"firefox\", na=False), \"id_31\"] = \"Firefox\"\ndf_test.loc[df_test[\"id_31\"].str.contains(\"safari\", na=False), \"id_31\"] = \"Safari\"\ndf_test.loc[df_test[\"id_31\"].str.contains(\"edge\", na=False), \"id_31\"] = \"Edge\"\ndf_test.loc[df_test[\"id_31\"].str.contains(\"ie\", na=False), \"id_31\"] = \"IE\"\ndf_test.loc[df_test[\"id_31\"].str.contains(\"samsung\", na=False), \"id_31\"] = \"Samsung\"\ndf_test.loc[df_test[\"id_31\"].str.contains(\"opera\", na=False), \"id_31\"] = \"Opera\"\ndf_test[\"id_31\"].fillna(\"NAN\", inplace=True)\ndf_test.loc[df_test[\"id_31\"].isin(df_test[\"id_31\"].value_counts()[df_test[\"id_31\"].value_counts()< 2001].index), \"id_31\"]= \"Others\"\n\n\n#deviceinfo train\n\ndf_train[\"deviceinfo\"].unique()\ndf_train.loc[df_train['deviceinfo'].str.contains('SM', na=False), 'deviceinfo'] = 'Samsung'\ndf_train.loc[df_train['deviceinfo'].str.contains('Moto', na=False), 'deviceinfo'] = 'Motorola'\ndf_train.loc[df_train['deviceinfo'].str.contains('moto', na=False), 'deviceinfo'] = 'Motorola'\ndf_train.loc[df_train['deviceinfo'].str.contains('HUAWEI', na=False), 'deviceinfo'] = 'Huawei'\ndf_train.loc[df_train['deviceinfo'].str.contains('LG', na=False), 'deviceinfo'] = 'LG'\ndf_train.loc[df_train['deviceinfo'].str.contains('GT-', na=False), 'deviceinfo'] = 'Samsung'\ndf_train.loc[df_train['deviceinfo'].str.contains('Trident', na=False), 'deviceinfo'] = 'Trident'\ndf_train.loc[df_train['deviceinfo'].str.contains('BLADE', na=False), 'deviceinfo'] = 'ZTE'\ndf_train.loc[df_train['deviceinfo'].isin(df_train['deviceinfo'].value_counts()[df_train['deviceinfo'].value_counts() < 7570].index), 'deviceinfo'] = \"Others\"\ndf_train[\"deviceinfo\"].fillna(\"NAN\", inplace=True)\n\n#deviceinfo test\n\ndf_test[\"deviceinfo\"].unique()\ndf_test.loc[df_test['deviceinfo'].str.contains('SM', na=False), 'deviceinfo'] = 'Samsung'\ndf_test.loc[df_test['deviceinfo'].str.contains('Moto', na=False), 'deviceinfo'] = 'Motorola'\ndf_test.loc[df_test['deviceinfo'].str.contains('moto', na=False), 'deviceinfo'] = 'Motorola'\ndf_test.loc[df_test['deviceinfo'].str.contains('HUAWEI', na=False), 'deviceinfo'] = 'Huawei'\ndf_test.loc[df_test['deviceinfo'].str.contains('LG', na=False), 'deviceinfo'] = 'LG'\ndf_test.loc[df_test['deviceinfo'].str.contains('GT-', na=False), 'deviceinfo'] = 'Samsung'\ndf_test.loc[df_test['deviceinfo'].str.contains('Trident', na=False), 'deviceinfo'] = 'Trident'\ndf_test.loc[df_test['deviceinfo'].str.contains('BLADE', na=False), 'deviceinfo'] = 'ZTE'\ndf_test.loc[df_test['deviceinfo'].isin(df_test['deviceinfo'].value_counts()[df_test['deviceinfo'].value_counts() < 6000].index), 'deviceinfo'] = \"Others\"\ndf_test[\"deviceinfo\"].fillna(\"NAN\", inplace=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:39.227758Z","iopub.execute_input":"2021-09-01T12:47:39.228111Z","iopub.status.idle":"2021-09-01T12:47:51.128648Z","shell.execute_reply.started":"2021-09-01T12:47:39.228075Z","shell.execute_reply":"2021-09-01T12:47:51.127828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Extraction**\nTaking the start date ‘2017-12-01’, constructed time variables. In discussions tab you should read an excellent solutions.","metadata":{}},{"cell_type":"code","source":"START_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n\n#train\ndf_train[\"Date\"] = df_train['transactiondt'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ndf_train['New_months'] = df_train['Date'].dt.month\ndf_train['New_weekdays'] = df_train['Date'].dt.dayofweek\ndf_train['New_hours'] = df_train['Date'].dt.hour\ndf_train['New_days'] = df_train['Date'].dt.day\ndf_train['New_is_month_end'] = df_train[\"Date\"].dt.is_month_end.astype(int)\ndf_train[\"New_is_wknd\"] = df_train[\"Date\"].dt.weekday // 4\ndf_train['New_is_month_start'] = df_train[\"Date\"].dt.is_month_start.astype(int)\ndf_train['New_day_of_year'] = df_train[\"Date\"].dt.dayofyear\n\n#test\ndf_test[\"Date\"] = df_test['transactiondt'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ndf_test['New_months'] = df_test['Date'].dt.month\ndf_test['New_weekdays'] = df_test['Date'].dt.dayofweek\ndf_test['New_hours'] = df_test['Date'].dt.hour\ndf_test['New_days'] = df_test['Date'].dt.day\ndf_test['New_is_month_end'] = df_test[\"Date\"].dt.is_month_end.astype(int)\ndf_test[\"New_is_wknd\"] = df_test[\"Date\"].dt.weekday // 4\ndf_test['New_is_month_start'] = df_test[\"Date\"].dt.is_month_start.astype(int)\ndf_test['New_day_of_year'] = df_test[\"Date\"].dt.dayofyear\n\ndf_train.drop(\"Date\", axis=1, inplace=True)\ndf_test.drop(\"Date\", axis=1, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:51.129966Z","iopub.execute_input":"2021-09-01T12:47:51.13042Z","iopub.status.idle":"2021-09-01T12:47:54.567319Z","shell.execute_reply.started":"2021-09-01T12:47:51.130378Z","shell.execute_reply":"2021-09-01T12:47:54.566437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define categorical cols for both train and test dataframes. Since the types of features are not object and have many categories, we define cat_cols manuel. Also you can add other time variables in cat_cols.","metadata":{}},{"cell_type":"code","source":"cat_cols_train= df_train[['productcd',  'card4', 'card6','p_emaildomain', 'r_emaildomain',\n              'devicetype', 'deviceinfo','id_12','id_15','id_16','id_28',\n              'id_29',\"id_30\", 'id_31', 'id_35', 'id_36', 'id_37', 'id_38',\"m4\",'m1', 'm2', 'm3'\n             , 'm5', 'm6', 'm7', 'm8', 'm9',\"New_months\", \"New_hours\"]]\n\ncat_cols_test= df_test[['productcd',  'card4', 'card6','p_emaildomain', 'r_emaildomain',\n              'devicetype', 'deviceinfo','id_12','id_15','id_16','id_28',\n              'id_29',\"id_30\", 'id_31', 'id_35', 'id_36', 'id_37', 'id_38',\"m4\",'m1', 'm2', 'm3'\n            , 'm5', 'm6', 'm7', 'm8', 'm9']]\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:54.568591Z","iopub.execute_input":"2021-09-01T12:47:54.568943Z","iopub.status.idle":"2021-09-01T12:47:54.807186Z","shell.execute_reply.started":"2021-09-01T12:47:54.568911Z","shell.execute_reply":"2021-09-01T12:47:54.80631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After one hot encoding rename cols name and control the shape of train and test dataframes.","metadata":{}},{"cell_type":"code","source":"# ONE-HOT ENCODING TRAIN\n\nohe_cols_train=cat_cols_train.columns\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first, dtype=\"float\")\n    return dataframe\n\ndf_train=one_hot_encoder(df_train, ohe_cols_train, drop_first=True)\n\n#you should rename columns name after encoding since columns include characteristic name like :/ \n\ncolumns= [df_train.columns]\ndf_train= df_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n\n# ONE-HOT ENCODING TEST\n\nohe_cols_test=cat_cols_test.columns\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first, dtype=\"float\")\n    return dataframe\n\ndf_test=one_hot_encoder(df_test, ohe_cols_test, drop_first=True)\n\ncolumns= [df_test.columns]\ndf_test= df_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n\ndf_train.drop(\"card6_debitorcredit\", axis=1, inplace=True)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:47:54.808503Z","iopub.execute_input":"2021-09-01T12:47:54.808841Z","iopub.status.idle":"2021-09-01T12:48:01.955221Z","shell.execute_reply.started":"2021-09-01T12:47:54.808805Z","shell.execute_reply":"2021-09-01T12:48:01.954361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train- Test Split#\ntrain_index=df_train.index[:450000]\ntest_index=df_train.index[450000:]\n\ntrain_cols=df_train.columns\nX_train=df_train.loc[train_index,train_cols]\nX_train.drop([\"transactionid\", \"isfraud\", \"transactiondt\"], axis=1, inplace=True)\n\nX_test=df_train.loc[test_index,train_cols]\nX_test.drop([\"transactionid\", \"isfraud\", \"transactiondt\"], axis=1, inplace=True)\n\ny_train1 = df_train[\"isfraud\"]\ny_train=y_train1[train_index]\ny_test=y_train1[test_index]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:48:01.956383Z","iopub.execute_input":"2021-09-01T12:48:01.95672Z","iopub.status.idle":"2021-09-01T12:48:03.874529Z","shell.execute_reply.started":"2021-09-01T12:48:01.956687Z","shell.execute_reply":"2021-09-01T12:48:03.873645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=9,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    tree_method='gpu_hist'\n     )\nmodel.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\"], verbose=True)\n\ny_pred = model.predict(X_test)\ntrain_y= model.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:48:03.8757Z","iopub.execute_input":"2021-09-01T12:48:03.876039Z","iopub.status.idle":"2021-09-01T12:48:57.585091Z","shell.execute_reply.started":"2021-09-01T12:48:03.875987Z","shell.execute_reply":"2021-09-01T12:48:57.583219Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train Accuracy score:',accuracy_score(y_train,train_y))\nprint('Train F1 score:',f1_score(y_train,train_y))\nprint('Train Precision score:',precision_score(y_train,train_y))\nprint('Train Recall score:',recall_score(y_train,train_y)) \n\nprint('Test Accuracy score:',accuracy_score(y_test,y_pred))\nprint('Test F1 score:',f1_score(y_test,y_pred))\nprint('Test Precision score:',precision_score(y_test,y_pred))\nprint('Test Recall score:',recall_score(y_test,y_pred)) \n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:48:57.588667Z","iopub.execute_input":"2021-09-01T12:48:57.589036Z","iopub.status.idle":"2021-09-01T12:48:58.210849Z","shell.execute_reply.started":"2021-09-01T12:48:57.588979Z","shell.execute_reply":"2021-09-01T12:48:58.209802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred):\n    acc = round(accuracy_score(y_test, y_pred), 2)\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\".0f\")\n    plt.xlabel('y_pred')\n    plt.ylabel('y_test')\n    plt.title('Accuracy Score: {0}'.format(acc), size=10)\n    plt.show()\n\nplot_confusion_matrix(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:48:58.212299Z","iopub.execute_input":"2021-09-01T12:48:58.212643Z","iopub.status.idle":"2021-09-01T12:48:58.62975Z","shell.execute_reply.started":"2021-09-01T12:48:58.212605Z","shell.execute_reply":"2021-09-01T12:48:58.628979Z"},"trusted":true},"execution_count":null,"outputs":[]}]}