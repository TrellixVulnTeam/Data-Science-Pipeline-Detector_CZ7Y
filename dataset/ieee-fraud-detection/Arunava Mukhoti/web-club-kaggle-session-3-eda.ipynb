{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IEEE Fraud Detection Competition\n![fraud](https://abcountrywide.com.au/wp-content/uploads/2018/04/fraud.jpg)\n\nIn this kernel we do some basic exploratory data analysis on the IEEE Fraud Detection dataset.\n\n\nFrom the [competition overview](https://www.kaggle.com/c/ieee-fraud-detection/overview):\n\n*In this competition, you’ll benchmark machine learning models on a challenging large-scale dataset. The data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results.*\n   \n*If successful, you’ll improve the efficacy of fraudulent transaction alerts for millions of people around the world, helping hundreds of thousands of businesses reduce their fraud loss and increase their revenue. And of course, you will save party people just like you the hassle of false positives.*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.linear_model import LogisticRegression\nwarnings.simplefilter(\"ignore\")\nplt.style.use('ggplot')\ncolor_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data\n\nIn the competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\nThe data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transaction CSVs\ntrain_transaction = pd.read_csv('../input/train_transaction.csv')\ntest_transaction = pd.read_csv('../input/test_transaction.csv')\n# Identity CSVs - These will be merged onto the transactions to create additional features\ntrain_identity = pd.read_csv('../input/train_identity.csv')\ntest_identity = pd.read_csv('../input/test_identity.csv')\n# Sample Submissions\n#ss = pd.read_csv('../input/sample_submission.csv')\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_transaction shape is {}'.format(train_transaction.shape))\nprint('test_transaction shape is {}'.format(test_transaction.shape))\nprint('train_identity shape is {}'.format(train_identity.shape))\nprint('test_identity shape is {}'.format(test_identity.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we confirm that all of the transactions in `train_identity`\nprint(np.sum(train_transaction['TransactionID'].isin(train_identity['TransactionID'].unique())))\nprint(np.sum(test_transaction['TransactionID'].isin(test_identity['TransactionID'].unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 24.4% of TransactionIDs in **train** (144233 / 590540) have an associated train_identity.\n- 28.0% of TransactionIDs in **test** (144233 / 590540) have an associated train_identity."},{"metadata":{},"cell_type":"markdown","source":"**Memory usage reduction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\ntrain_identity = reduce_mem_usage(train_identity)\ntrain_transaction = reduce_mem_usage(train_transaction)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train vs Test are Time Series Split\n\nThe `TransactionDT` feature is a timedelta from a given reference datetime (not an actual timestamp). One early discovery about the data is that the train and test appear to be split by time. There is a slight gap inbetween, but otherwise the training set is from an earlier period of time and test is from a later period of time. This will impact which cross validation techniques should be used.\n\nWe will look into this more when reviewing differences in distribution of features between train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['TransactionDT'].plot(kind='hist',\n                                        figsize=(15, 5),\n                                        label='train',\n                                        bins=50,\n                                        title='Train vs Test TransactionDT distribution')\ntest_transaction['TransactionDT'].plot(kind='hist',\n                                       label='test',\n                                       bins=50)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = train_transaction.plot(x='TransactionDT',\n                       y='TransactionAmt',\n                       kind='scatter',\n                       alpha=0.01,\n                       label='TransactionAmt-train',\n                       title='Train and test Transaction Ammounts by Time (TransactionDT)',\n                       ylim=(0, 5000),\n                       figsize=(15, 5))\ntest_transaction.plot(x='TransactionDT',\n                      y='TransactionAmt',\n                      kind='scatter',\n                      label='TransactionAmt-test',\n                      alpha=0.01,\n                      color=color_pal[1],\n                       ylim=(0, 5000),\n                      ax=ax)\n# Plot Fraud as Orange\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    .plot(x='TransactionDT',\n         y='TransactionAmt',\n         kind='scatter',\n         alpha=0.01,\n         label='TransactionAmt-train',\n         title='Train and test Transaction Ammounts by Time (TransactionDT)',\n         ylim=(0, 5000),\n         color='black',\n         figsize=(15, 5),\n         ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Target in Training Set\n- 3.5% of transacations are fraud"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('  {:.4f}% of Transactions that are fraud in train '.format(train_transaction['isFraud'].mean() * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Discuss precision and recall because of class imbalance\ntrain_transaction.groupby('isFraud') \\\n    .count()['TransactionID'] \\\n    .plot(kind='barh',\n          title='Distribution of Target in Train',\n          figsize=(15, 3))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TransactionAmt\nThe ammount of transaction. I've taken a log transform in some of these plots to better show the distribution- otherwise the few, very large transactions skew the distribution. Because of the log transfrom, any values between 0 and 1 will appear to be negative."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['TransactionAmt'] \\\n    .apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          figsize=(15, 5),\n          title='Distribution of Log Transaction Amt')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    ['TransactionAmt'].apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='Log Transaction Amt - Fraud',\n          color=color_pal[1],\n          xlim=(-3, 10),\n         ax= ax1)\ntrain_transaction.loc[train_transaction['isFraud'] == 0] \\\n    ['TransactionAmt'].apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='Log Transaction Amt - Not Fraud',\n          color=color_pal[2],\n          xlim=(-3, 10),\n         ax=ax2)\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    ['TransactionAmt'] \\\n    .plot(kind='hist',\n          bins=100,\n          title='Transaction Amt - Fraud',\n          color=color_pal[1],\n         ax= ax3)\ntrain_transaction.loc[train_transaction['isFraud'] == 0] \\\n    ['TransactionAmt'] \\\n    .plot(kind='hist',\n          bins=100,\n          title='Transaction Amt - Not Fraud',\n          color=color_pal[2],\n         ax=ax4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Fraudulent charges appear to have a higher average transaction ammount "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean transaction amt for fraud is {:.4f}'.format(train_transaction.loc[train_transaction['isFraud'] == 1]['TransactionAmt'].mean()))\nprint('Mean transaction amt for non-fraud is {:.4f}'.format(train_transaction.loc[train_transaction['isFraud'] == 0]['TransactionAmt'].mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ProductCD\n- For now we don't know exactly what these values represent.\n- `W` has the most number of observations, `C` the least.\n- ProductCD `C` has the most fraud with >11%\n- ProductCD `W` has the least with ~2%"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.groupby('ProductCD') \\\n    ['TransactionID'].count() \\\n    .sort_index() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n         title='Count of Observations by ProductCD')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.groupby('ProductCD')['isFraud'] \\\n    .mean() \\\n    .sort_index() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n         title='Percentage of Fraud by ProductCD')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical Features - Transaction\nWe are told in the data description that the following transaction columns are categorical:\n- ProductCD\n- emaildomain\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9"},{"metadata":{},"cell_type":"markdown","source":"# card1 - card6\n- We are told these are all categorical, even though some appear numeric."},{"metadata":{"trusted":true},"cell_type":"code","source":"card_cols = [c for c in train_transaction.columns if 'card' in c]\ntrain_transaction[card_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_idx = 0\nfor c in card_cols:\n    if train_transaction[c].dtype in ['float64','int64']:\n        train_transaction[c].plot(kind='hist',\n                                      title=c,\n                                      bins=50,\n                                      figsize=(15, 2),\n                                      color=color_pal[color_idx])\n    color_idx += 1\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction_fr = train_transaction.loc[train_transaction['isFraud'] == 1]\ntrain_transaction_nofr = train_transaction.loc[train_transaction['isFraud'] == 0]\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\ntrain_transaction_fr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax1, title='Count of card4 fraud')\ntrain_transaction_nofr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax2, title='Count of card4 non-fraud')\ntrain_transaction_fr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax3, title='Count of card6 fraud')\ntrain_transaction_nofr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax4, title='Count of card6 non-fraud')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# addr1 & addr2\nThe data description states that these are categorical even though they look numeric. Could they be the address value?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' addr1 - has {} NA values'.format(train_transaction['addr1'].isna().sum()))\nprint(' addr2 - has {} NA values'.format(train_transaction['addr2'].isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['addr1'].plot(kind='hist', bins=500, figsize=(15, 2), title='addr1 distribution')\nplt.show()\ntrain_transaction['addr2'].plot(kind='hist', bins=500, figsize=(15, 2), title='addr2 distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dist1 & dist2\nPlotting with logx to better show the distribution. Possibly this could be the distance of the transaction vs. the card owner's home/work address. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['dist1'].plot(kind='hist',\n                                bins=5000,\n                                figsize=(15, 2),\n                                title='dist1 distribution',\n                                color=color_pal[1],\n                                logx=True)\nplt.show()\ntrain_transaction['dist2'].plot(kind='hist',\n                                bins=5000,\n                                figsize=(15, 2),\n                                title='dist2 distribution',\n                                color=color_pal[1],\n                                logx=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C1 - C14\nBecause we are provided many numerical columns, we can create a pairplot to plot feature interactions. I know these plots can be hard to read, but it is helpful for gaining intution about potential feature interactions and if certain features have more variance than others."},{"metadata":{"trusted":true},"cell_type":"code","source":"c_cols = [c for c in train_transaction if c[0] == 'C']\ntrain_transaction[c_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample 500 fraud and 500 non-fraud examples to plot\nsampled_train = pd.concat([train_transaction.loc[train_transaction['isFraud'] == 0].sample(500),\n          train_transaction.loc[train_transaction['isFraud'] == 1].sample(500)])\n\nsns.pairplot(sampled_train, \n             hue='isFraud',\n            vars=c_cols)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D1-D15\nSimilarly for features D1-D15. In these plots we can see some linear and non-linear interactions between features. We may want to create additional features using these interactions if we think it would help our model better find relationship between fraud and non-fraud observations."},{"metadata":{"trusted":true},"cell_type":"code","source":"d_cols = [c for c in train_transaction if c[0] == 'D']\ntrain_transaction[d_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(sampled_train, \n             hue='isFraud',\n            vars=d_cols)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# M1-M9\n- Values are `T` `F` or `NaN`\n- Column `M4` appears to be different with values like `M2` and `M0`"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_cols = [c for c in train_transaction if c[0] == 'M']\ntrain_transaction[m_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_transaction[m_cols] == 'T').sum().plot(kind='bar',\n                                              title='Count of T by M column',\n                                              figsize=(15, 2),\n                                              color=color_pal[3])\nplt.show()\n(train_transaction[m_cols] == 'F').sum().plot(kind='bar',\n                                              title='Count of F by M column',\n                                              figsize=(15, 2),\n                                              color=color_pal[4])\nplt.show()\n(train_transaction[m_cols].isna()).sum().plot(kind='bar',\n                                              title='Count of NaN by M column',\n                                              figsize=(15, 2),\n                                              color=color_pal[0])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at M4 column since it is different than the others\ntrain_transaction.groupby('M4')['TransactionID'] \\\n    .count() \\\n    .plot(kind='bar',\n          title='Count of values for M4',\n          figsize=(15, 3))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V1 - V339\n\n**Features engineered by Vesta**\n\nLots of 1s 0s and Nans, some larger values"},{"metadata":{"trusted":true},"cell_type":"code","source":"v_cols = [c for c in train_transaction if c[0] == 'V']\ntrain_transaction[v_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction[v_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['v_mean'] = train_transaction[v_cols].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 6))\ntrain_transaction.loc[train_transaction['isFraud'] == 1]['v_mean'] \\\n    .apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='log transformed mean of V columns - Fraud',\n          ax=ax1)\ntrain_transaction.loc[train_transaction['isFraud'] == 0]['v_mean'] \\\n    .apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='log transformed mean of V columns - Not Fraud',\n          color=color_pal[5],\n          ax=ax2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Identity Data\nNext we will explore the identity data. These are provided for some, but not all `TransactionID`s. It contains information about the identity of the customer.\n- Categorical Features\n- `DeviceType`\n- `DeviceInfo`\n- `id_12` - `id_38`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add the `isFraud` column for analysis\ntrain_identity_ = train_identity.merge(train_transaction[['TransactionID',\n                                                         'TransactionDT',\n                                                         'isFraud']],\n                                      on=['TransactionID'])\n\ntest_identity_ = test_identity.merge(test_transaction[['TransactionID',\n                                                      'TransactionDT']],\n                                    on=['TransactionID'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DeviceType"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity_.groupby('DeviceType') \\\n    .mean()['isFraud'] \\\n    .sort_values() \\\n    .plot(kind='barh',\n          figsize=(15, 5),\n          title='Percentage of Fraud by Device Type')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity_.groupby('DeviceInfo') \\\n    .count()['TransactionID'] \\\n    .sort_values(ascending=False) \\\n    .head(20) \\\n    .plot(kind='barh', figsize=(15, 5), title='Top 20 Devices in Train')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Identity info as a function of time"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_cols = [c for c in train_identity.columns if 'id' in c]\nid_cols_test = [c for c in test_identity.columns if 'id' in c]\nprint(id_cols)\nfor i in id_cols:\n    try:\n        train_identity_.set_index('TransactionDT')[i].plot(style='.', title=i, figsize=(15, 3))\n        plt.show()\n    except TypeError:\n        pass\nfor i in id_cols:\n    try:\n        test_identity_.set_index('TransactionDT')[i].plot(style='.', title=i, figsize=(15, 3))\n        plt.show()\n    except TypeError:\n        pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating the model "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_trans = pd.read_csv('../input/train_transaction.csv')\ndf_test_trans = pd.read_csv('../input/test_transaction.csv')\n\ndf_id = pd.read_csv('../input/train_identity.csv')\ndf_test_id = pd.read_csv('../input/test_identity.csv')\n\n#sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n\ndf_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True, on='TransactionID')\ndf_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True, on='TransactionID')\n\nprint(df_train.shape)\nprint(df_test.shape)\n\n# y_train = df_train['isFraud'].copy()\ndel df_trans, df_id, df_test_trans, df_test_id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# reducing memory usage"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mapping emails"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nemails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n\nus_emails = ['gmail', 'net', 'edu']\n\n# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499#latest-579654\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    df_train[c + '_bin'] = df_train[c].map(emails)\n    df_test[c + '_bin'] = df_test[c].map(emails)\n    \n    df_train[c + '_suffix'] = df_train[c].map(lambda x: str(x).split('.')[-1])\n    df_test[c + '_suffix'] = df_test[c].map(lambda x: str(x).split('.')[-1])\n    \n    df_train[c + '_suffix'] = df_train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    df_test[c + '_suffix'] = df_test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding\nfrom sklearn import preprocessing\nfor f in df_train.drop('isFraud', axis=1).columns:\n    if df_train[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_train[f].values))\n        df_train[f] = lbl.transform(list(df_train[f].values))\nfor f in df_test.drop('isFraud', axis=1).columns:\n    if df_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_test[f].values))\n        df_test[f] = lbl.transform(list(df_test[f].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Trans_min_mean'] = df_train['TransactionAmt'] - df_train['TransactionAmt'].mean()\ndf_train['Trans_min_std'] = df_train['Trans_min_mean'] / df_train['TransactionAmt'].std()\ndf_test['Trans_min_mean'] = df_test['TransactionAmt'] - df_test['TransactionAmt'].mean()\ndf_test['Trans_min_std'] = df_test['Trans_min_mean'] / df_test['TransactionAmt'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TransactionAmt_to_mean_card1'] = df_train['TransactionAmt'] / df_train.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_mean_card4'] = df_train['TransactionAmt'] / df_train.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_std_card1'] = df_train['TransactionAmt'] / df_train.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_train['TransactionAmt_to_std_card4'] = df_train['TransactionAmt'] / df_train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ndf_test['TransactionAmt_to_mean_card1'] = df_test['TransactionAmt'] / df_test.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_mean_card4'] = df_test['TransactionAmt'] / df_test.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_std_card1'] = df_test['TransactionAmt'] / df_test.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_test['TransactionAmt_to_std_card4'] = df_test['TransactionAmt'] / df_test.groupby(['card4'])['TransactionAmt'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TransactionAmt'] = np.log(df_train['TransactionAmt'])\ndf_test['TransactionAmt'] = np.log(df_test['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Concating dfs to get PCA of V features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['isFraud'] = 'test'\ndf = pd.concat([df_train, df_test], axis=0, sort=False )\ndf = df.reset_index()\ndf = df.drop('index', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def PCA_change(df, cols, n_components, prefix='PCA_', rand_seed=4):\n    pca = PCA(n_components=n_components, random_state=rand_seed)\n\n    principalComponents = pca.fit_transform(df[cols])\n\n    principalDf = pd.DataFrame(principalComponents)\n\n    df.drop(cols, axis=1, inplace=True)\n\n    principalDf.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n\n    df = pd.concat([df, principalDf], axis=1)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mas_v = df_train.columns[55:394]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting PCA "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\nfrom sklearn.decomposition import PCA\n# from sklearn.cluster import KMeans\n\nfor col in mas_v:\n    df[col] = df[col].fillna((df[col].min() - 2))\n    df[col] = (minmax_scale(df[col], feature_range=(0,1)))\n\n    \ndf = PCA_change(df, mas_v, prefix='PCA_V_', n_components=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = reduce_mem_usage(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seting train and test back"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test = df[df['isFraud'] != 'test'], df[df['isFraud'] == 'test'].drop('isFraud', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seting X and y"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train.sort_values('TransactionDT').drop(['isFraud', \n                                                      'TransactionDT', \n                                                      #'Card_ID'\n                                                     ],\n                                                     axis=1)\ny_train = df_train.sort_values('TransactionDT')['isFraud'].astype(bool)\n\nX_test = df_test.sort_values('TransactionDT').drop(['TransactionDT',\n                                                    #'Card_ID'\n                                                   ], \n                                                   axis=1)\ndel df_train\ndf_test = df_test[[\"TransactionDT\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression\n\n[scikit-learn sklearn.linear_model.LogisticRegression documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine\n[scikit-learn sklearn.svm.SVC documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}