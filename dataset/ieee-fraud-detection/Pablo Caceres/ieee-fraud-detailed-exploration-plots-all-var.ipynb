{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Detailed exploration of IEEE-CIS 'Fraud Detection' dataframe\nHere I examine and plot all features/variables from the training dataset, adding notes for all plots for later development\n\n**This kernel is a bit long, so I'm continuining here with missing values analysis:**  \nhttps://www.kaggle.com/pabloinsente/ieee-missing-nan-values-analysis-and-imputation\n\n## Description variables/features:\n(https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203#latest-583068) \n\n### Transaction Table:\n- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n- TransactionAMT: transaction payment amount in USD\n- ProductCD: product code, the product for each transaction\n- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n- addr: address\n- dist: distance\n- P_ and (R__) emaildomain: purchaser and recipient email domain\n- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n- D1-D15: timedelta, such as days between previous transaction, etc.\n- M1-M9: match, such as names on card and address, etc.\n- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n\n\n### Identity Table:\n- Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions. \n- They're collected by Vesta’s fraud protection system and digital security partners.\n- (The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I. Import data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load data\ntrain_tran = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ntrain_iden = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntest_tran = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\ntest_iden = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\nsample_sub = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join training datasets\ntrain = train_tran.merge(train_iden, how='left',left_index=True, right_index=True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join testing datasets\ntest = test_tran.merge(test_iden, how='left',left_index=True, right_index=True)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get target feature\ny_train = train['isFraud'].copy()\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get features matrices\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test, train_tran, train_iden, test_tran, test_iden","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II. Explore data: describe single variables"},{"metadata":{},"cell_type":"markdown","source":"## Plot univariate distributions"},{"metadata":{},"cell_type":"markdown","source":"### Categorical variables according to dataset documentation\n** Categorical Features - Transaction:**  \n- ProductCD\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9\n\n** Categorical Features - Identity:**\n- DeviceType\n- DeviceInfo\n- id_12 - id_38"},{"metadata":{},"cell_type":"markdown","source":"## Plot categorical variables"},{"metadata":{},"cell_type":"markdown","source":"**Plot I:  target, ProductCD, Devicetype, DeviceInfo**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(12, 4))\nisFraud = sns.countplot(x='isFraud', data=train, ax=axes[0])\nProductCD = sns.countplot(x='ProductCD', data=train, ax=axes[1])\nDeviceType = sns.countplot(x='DeviceType', data=train, ax=axes[2])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot I notes:**\n- Very unbalance target (isFraud)\n- Very unbalance product type purchase\n- Most purchases are made on desktop devices"},{"metadata":{},"cell_type":"markdown","source":"**Plot II: DeviceInfo**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create a dataframe with 2 cols: device info and the count by device\ngroup = pd.DataFrame()\ngroup['DeviceCount'] = train.groupby(['DeviceInfo'])['DeviceInfo'].count()\ngroup['DeviceInfo'] = group.index\n\n# There are too many Devices, so we will subset the top 20\ngroup_top = group.sort_values(by='DeviceCount',ascending=False).head(20)\n\nplt.figure(figsize=(25, 10))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=\"DeviceInfo\", y=\"DeviceCount\", data=group_top)\nxt = plt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot II notes:**\n\nThe top devices are:\n1. Windows\n2. iOS\n3. Trident\n4. MacOS"},{"metadata":{},"cell_type":"markdown","source":"**Plot III: cards 1,2,3, and 5**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# These cards are encoded as float64, and since there are too many values\n# we will plot this a distributions (x a# xis is just an id)\nf, axes = plt.subplots(4, 1, figsize=(25, 30))\n\nc1 = sns.distplot(train.card1,kde=False, ax=axes[0])\nc2 = sns.distplot(train.card2.dropna(),kde=False, ax=axes[1])\nc3 = sns.distplot(train.card3.dropna(),kde=False, ax=axes[2])\nc5 = sns.distplot(train.card5.dropna(),kde=False, ax=axes[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot III notes:**  \n- The bulk of the transactions are on card1 and2  \n- Not sure about identity of card3 and card5\n- They may be dollars amount per transaction, or some sort of identifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot IV: cards 4 and 6\nf, axes = plt.subplots(1, 2, figsize=(18, 6))\nsns.set(color_codes=True)\ncard4 = sns.countplot(x='card4', data=train, ax=axes[0])\ncard6 = sns.countplot(x='card6', data=train, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot IV notes:**  \n- Card4 refers to visa brand; most transactions are on Visa and Mastercard \n- Card5 refers to type of card; most transactions are debit "},{"metadata":{},"cell_type":"markdown","source":"**Plot V: addr1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create a dataframe with 2 cols: device info and the count by device\ngroup = pd.DataFrame()\ngroup['addr1Count'] = train.groupby(['addr1'])['addr1'].count()\ngroup['addr1'] = group.index\n\n# There are too many addr, so we will subset the top 20\ngroup_top = group.sort_values(by='addr1Count',ascending=False).head(20)\n\nplt.figure(figsize=(25, 10))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=\"addr1\", y=\"addr1Count\", data=group_top)\nxt = plt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot VI: addr2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create a dataframe with 2 cols: device info and the count by device\ngroup = pd.DataFrame()\ngroup['addr2Count'] = train.groupby(['addr2'])['addr2'].count()\ngroup['addr2'] = group.index\n\n# There are too many addr, so we will subset the top 20\ngroup_top = group.sort_values(by='addr2Count',ascending=False).head(20)\n\nplt.figure(figsize=(25, 10))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=\"addr2\", y=\"addr2Count\", data=group_top)\nxt = plt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's examine addr2 values\ntrain.addr2.value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot V-VI notes:**\n- Transactions on addr1 are more evenly distributed\n- Transactions on addr2 has 1 big outlier "},{"metadata":{},"cell_type":"markdown","source":"**Plot VII: emaildomains**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(18, 12))\n\nsns.set(color_codes=True)\np_email = sns.countplot(y='P_emaildomain', data=train, ax=axes[0])\nr_email = sns.countplot(y='R_emaildomain', data=train, ax=axes[1])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.addr1.nunique()) # 332 unique locations\nprint(train.addr2.nunique()) # 74 unique locations\nprint(train.P_emaildomain.nunique()) # 59 unique domains\nprint(train.R_emaildomain.nunique()) # 59 unique domains","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot VII notes:**\n- As expected, gmail is at the top.\n- There is one interesting 'anonymous.com' domain"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot VIII: M1 - M9 variables\nM1_loc = train.columns.get_loc(\"M1\")\nM9_loc = train.columns.get_loc(\"M9\")\ndf_m = train.iloc[:,M1_loc:M9_loc+1] #subset dataframe M1-M9\n\ncols = df_m.columns\nf, axes = plt.subplots(3, 3, figsize=(16, 12))\ncount = 0\nfor i in range(3): # rows loop\n    for j in range(3): # cols loop\n        mplot = sns.countplot(x=cols[count], data=df_m, ax=axes[i,j])\n        count += 1 # to loop over col-names\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot VIII notes:**\n- Identity of M1-M9 is still unclear\n- Basically boolean variables; M4 seems to be different"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exploration id_12 - id_38\nid12_loc = train.columns.get_loc(\"id_12\")\nid38_loc = train.columns.get_loc(\"id_38\")\ndf_id = train.iloc[:,id12_loc:id38_loc+1] #subset dataframe id12-id19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_id.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_id.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes id12-id38**\n- There is a mix of data types\n- Mostly NaN values\n- id30 is OS again\n- id31 is browser\n"},{"metadata":{},"cell_type":"markdown","source":"**Plot IX: id_30**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create a dataframe with 2 cols: device info and the count by device\ngroup = pd.DataFrame()\ngroup['id_30Count'] = df_id.groupby(['id_30'])['id_30'].count()\ngroup['id_30'] = group.index\n\n# There are too many addr, so we will subset the top 20\ngroup_top = group.sort_values(by='id_30Count',ascending=False).head(20)\n\nplt.figure(figsize=(25, 10))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=\"id_30\", y=\"id_30Count\", data=group_top)\nxt = plt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot X: id_31**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create a dataframe with 2 cols: device info and the count by device\ngroup = pd.DataFrame()\ngroup['id_31Count'] = df_id.groupby(['id_31'])['id_31'].count()\ngroup['id_31'] = group.index\n\n# There are too many addr, so we will subset the top 20\ngroup_top = group.sort_values(by='id_31Count',ascending=False).head(20)\n\nplt.figure(figsize=(25, 10))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=\"id_31\", y=\"id_31Count\", data=group_top)\nxt = plt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot X notes:**\n- Most transactions are done with Windows 7 and 10, and iOS\n- Most transactions are done with chrome and safari"},{"metadata":{},"cell_type":"markdown","source":"**Plot XI: ProductCD**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This variable is NOT listed as categorical, but clearly is\nplt.figure(figsize=(10, 5))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.countplot(x='ProductCD', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot continuous variables "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot XII: TransactionDT, TransactionAmt\nf, axes = plt.subplots(2, 1, figsize=(15, 10))\n\ndt = sns.distplot(train.TransactionDT,kde=False, ax=axes[0])\nam = sns.distplot(train.TransactionAmt,kde=False, hist_kws={'log':True}, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XII notes:**\n- TransactionDT is evenly distributed, unclear identity\n- Transaction amount follows a log distribution, with a few large outliers"},{"metadata":{},"cell_type":"markdown","source":"**Plot XIII: C7 - C14**"},{"metadata":{"trusted":true},"cell_type":"code","source":"C7_loc = train.columns.get_loc(\"C7\")\nC14_loc = train.columns.get_loc(\"C14\")\ndf_c = train.iloc[:,C7_loc:C14_loc+1] #subset dataframe\n\ncols = df_c.columns\n\nrows = 8\nf, axes = plt.subplots(rows, 1, figsize=(15, 20))\nfor i in range(rows):\n    dp = sns.distplot(df_c[cols[i]],kde=False, hist_kws={'log':True}, ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XIII notes:**\n- All variables follow roughly a log distribution \n- Identity is unclear"},{"metadata":{},"cell_type":"markdown","source":"**Plot XIV: D1 - D15**"},{"metadata":{"trusted":true},"cell_type":"code","source":"D1_loc = train.columns.get_loc(\"D1\")\nD15_loc = train.columns.get_loc(\"D15\")\ndf_d = train.iloc[:,D1_loc:D15_loc+1] #subset dataframe\n\ncols = df_d.columns\nrows = 15\nf, axes = plt.subplots(rows, 1, figsize=(15, 25))\nfor i in range(rows):\n    #d = sns.distplot(df_d[cols[i]].dropna(),kde=False, hist_kws={'log':True}, ax=axes[i])\n    d = sns.distplot(df_d[cols[i]].dropna(), ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XIV notes:**\n- D11-D15 have negative values, which may say something about the identity of the feature\n- D9 has a different distribution, kinda binomial\n- The rest roughly a log distribution"},{"metadata":{},"cell_type":"markdown","source":"**Exploration V1 - V339**"},{"metadata":{"trusted":true},"cell_type":"code","source":"V1_loc = train.columns.get_loc(\"V1\")\nV339_loc = train.columns.get_loc(\"V339\")\ndf = train.iloc[:,V1_loc:V339_loc+1] #subset dataframe\n\ndf.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- From V1-V305 & V322-V339 seems to be mostly 0 - 1 values, which may indicate that they are actually a categorical feature \n- From V306-V321 seems to be true continuous variables \n- More interesting insights may come from computing averages by target feature"},{"metadata":{},"cell_type":"markdown","source":"**Plot XV: id_01 - id_11**"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_01_loc = train.columns.get_loc(\"id_01\")\nid_11_loc = train.columns.get_loc(\"id_11\")\ndf = train.iloc[:,id_01_loc:id_11_loc+1] #subset dataframe\n\ncols = df.columns\nrows = 11\nf, axes = plt.subplots(rows, 1, figsize=(15, 25))\nfor i in range(rows):\n    #d = sns.distplot(df[cols[i]].dropna(),kde=False, ax=axes[i])\n    d = sns.distplot(df[cols[i]].dropna(), ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XV: id_01 - id_11 / SAME as LOG distributions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_01_loc = train.columns.get_loc(\"id_01\")\nid_11_loc = train.columns.get_loc(\"id_11\")\ndf = train.iloc[:,id_01_loc:id_11_loc+1] #subset dataframe\n\ncols = df.columns\nrows = 11\nf, axes = plt.subplots(rows, 1, figsize=(15, 25))\nfor i in range(rows):\n    d = sns.distplot(df[cols[i]].dropna(),kde=False, hist_kws={'log':True}, ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XV notes:**\n- id_02 may be dollar amounts, with log distribution\n- id_01 - id_10 have negative values, but it is unlikely to indicate debt given values\n- id_07 - id_08 are kinda normally distributed"},{"metadata":{},"cell_type":"markdown","source":"# III. Explore data: describe variables by target (Fraud/not Not Fraud)"},{"metadata":{},"cell_type":"markdown","source":"## Plot/Explore bivariate relationships"},{"metadata":{},"cell_type":"markdown","source":"**Plot I:  target, ProductCD, Devicetype, DeviceInfo / Target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(15, 8))\nisFraud = sns.countplot(x='isFraud', data=train, ax=axes[0])\nProductCD = sns.countplot(x='ProductCD', hue=\"isFraud\", data=train, ax=axes[1])\nDeviceType = sns.countplot(x='DeviceType', hue=\"isFraud\", data=train, ax=axes[2])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot I as percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(15, 8))\n\nprops = train.groupby(\"ProductCD\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='bar', stacked='True', ax=axes[0])\n\nprops = train.groupby(\"DeviceType\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='bar', stacked='True', ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- ProductCD: C and S types have the highest number AND proportion of Fraud Transactions\n- DeviceType: mobile has the highest number AND proportion of Fraud Transactions (not by much though)"},{"metadata":{},"cell_type":"markdown","source":"**Plot II: Fraud transactions by OS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subset dataframe\nfraud = pd.DataFrame()\nis_fraud = train[train['isFraud']==1]\nfraud['DeviceCount'] = is_fraud.groupby(['DeviceInfo'])['DeviceInfo'].count()\nfraud['DeviceInfo'] = fraud.index\n\n# There are too many Devices, so we will subset the top 20\ngroup_top = fraud.sort_values(by='DeviceCount',ascending=False).head(20)\n\nplt.figure(figsize=(25, 10))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=\"DeviceInfo\", y=\"DeviceCount\", data=group_top)\n\nfont_size= {'size': 'x-large'}\nax.set_title(\"Fraud transactions by OS\", **font_size)\nxt = plt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes**\n- Fraud transaction cases come mostly from Windows and iOS devices. This is predictable given the vast majority of all transactions come from those systems. Still, the problem is this feature will still send the signal to the model that Windos/iOS_Device transactions -> likely fraud relative to other systems\n- Trident OS drop 5 places (3th overall, 8th on Fraud transactions)"},{"metadata":{},"cell_type":"markdown","source":"**Plot III: cards 1,2,3, and 5**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# These cards are encoded as float64, and since there are too many values\n# we will plot this as distributions (x axis is just a class identifier)\n\nis_fraud = train[train['isFraud']==1]\nno_fraud = train[train['isFraud']==0]\n\nf, axes = plt.subplots(4, 1, figsize=(25, 30))\n\nd1 = sns.distplot(no_fraud.card1, color=\"fuchsia\", label=\"No fraud\", ax=axes[0])\nl1 = d1.legend()\nc1 = sns.distplot(is_fraud.card1, color=\"black\", label = \"Fraud\", ax=axes[0])\nl2 = c1.legend()\n\nd2 = sns.distplot(no_fraud.card2.dropna(), color=\"fuchsia\", label=\"No fraud\", ax=axes[1])\nl3 = d2.legend()\nc2 = sns.distplot(is_fraud.card2.dropna(), color=\"black\",  label = \"Fraud\", ax=axes[1])\nl4 = c2.legend()\n\nd3 = sns.distplot(no_fraud.card3.dropna(), color=\"fuchsia\", label=\"No fraud\", ax=axes[2])\nl5 = d3.legend()\nc3 = sns.distplot(is_fraud.card3.dropna(), color=\"black\",  label = \"Fraud\", ax=axes[2])\nl6 = c3.legend()\n\nd5 = sns.distplot(no_fraud.card5.dropna(), color=\"fuchsia\", label=\"No fraud\", ax=axes[3])\nl7 = d5.legend()\nc5 = sns.distplot(is_fraud.card5.dropna(), color=\"black\", label = \"Fraud\", ax=axes[3])\nl8 = c5.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- card1, card2 and card3 show similar distribution patterns fraud/no_fraud\n- card5 reverse proportion around value '225' "},{"metadata":{},"cell_type":"markdown","source":"**Plot IV: cards 4 and 6**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(18, 10))\nsns.set(color_codes=True)\ncard4 = sns.countplot(x='card4', hue=\"isFraud\", data=train, ax=axes[0])\ncard6 = sns.countplot(x='card6', hue=\"isFraud\", data=train, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot IV as percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(18, 10))\n\nprops = train.groupby(\"card4\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='bar', stacked='True', ax=axes[0])\n\nprops = train.groupby(\"card6\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='bar', stacked='True', ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- Visa has the higher NUMBER of Fraud, but such number is a minor proportion of all VISA transactions\n- Discover has very few Fraud transaction, yet as percentage of all Discover transactions is a bit higher\n- Most Fraud transactions are done with Debit, but there is a higher proportion of Fraud Transactions within Credit "},{"metadata":{},"cell_type":"markdown","source":"**Plot V: addr1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subset fraud dataset\naddr = 'addr1'\naddrC = 'addr1Count'\nfraud = pd.DataFrame()\nis_fraud = train[train['isFraud']==1]\nfraud[addrC] = is_fraud.groupby([addr])[addr].count()\nfraud[addr] = fraud.index\n\n# Subset NOT fraud dataset\nNOfraud = pd.DataFrame()\nno_fraud = train[train['isFraud']==0]\nNOfraud[addrC] = no_fraud.groupby([addr])[addr].count()\nNOfraud[addr] = NOfraud.index\n\n# There are too many addr, so we will subset the top 20\ngroup_top_f = fraud.sort_values(by=addrC,ascending=False).head(20)\norder_f = group_top_f.sort_values(by=addrC,ascending=False)[addr]\n\ngroup_top_l = NOfraud.sort_values(by=addrC,ascending=False).head(20)\norder_l = group_top_l.sort_values(by=addrC,ascending=False)[addr]\n\nf, axes = plt.subplots(4, 1, figsize=(18, 20))\n\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=addr, y=addrC, data=group_top_f, order = order_f, ax=axes[0])\nbx = sns.barplot(x=addr, y=addrC, data=group_top_l, order = order_l, ax=axes[1])\n\naz = sns.barplot(x=addr, y=addrC, data=group_top_f, ax=axes[2])\nbz = sns.barplot(x=addr, y=addrC, data=group_top_l, ax=axes[3])\n\nfont_size= {'size': 'x-large'}\nax.set_title(\"Fraud transactions by addr1 (ranked)\", **font_size)\nbx.set_title(\"Legit transactions by addr1 (ranked)\", **font_size)\n\naz.set_title(\"Fraud transactions by addr1\", **font_size)\nbz.set_title(\"Legit transactions by addr1\", **font_size)\n\nxt = plt.xticks(rotation=60)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- Most fraud transactions come from addr1 204; most not fraud come from 299\n- First 5 addr1 are the same, but in different rank-order"},{"metadata":{},"cell_type":"markdown","source":"**Plot VI: addr2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subset fraud dataset\naddr = 'addr2'\naddrC = 'addr2Count'\nfraud = pd.DataFrame()\nis_fraud = train[train['isFraud']==1]\nfraud[addrC] = is_fraud.groupby([addr])[addr].count()\nfraud[addr] = fraud.index\n\n# Subset NOT fraud dataset\nNOfraud = pd.DataFrame()\nno_fraud = train[train['isFraud']==0]\nNOfraud[addrC] = no_fraud.groupby([addr])[addr].count()\nNOfraud[addr] = NOfraud.index\n\n# There are too many addr, so we will subset the top 20\ngroup_top_f = fraud.sort_values(by=addrC,ascending=False).head(20)\norder_f = group_top_f.sort_values(by=addrC,ascending=False)[addr]\n\ngroup_top_l = NOfraud.sort_values(by=addrC,ascending=False).head(20)\norder_l = group_top_l.sort_values(by=addrC,ascending=False)[addr]\n\nf, axes = plt.subplots(4, 1, figsize=(18, 20))\n\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.barplot(x=addr, y=addrC, data=group_top_f, order = order_f, ax=axes[0])\nbx = sns.barplot(x=addr, y=addrC, data=group_top_l, order = order_l, ax=axes[1])\n\naz = sns.barplot(x=addr, y=addrC, data=group_top_f, ax=axes[2])\nbz = sns.barplot(x=addr, y=addrC, data=group_top_l, ax=axes[3])\n\nfont_size= {'size': 'x-large'}\nax.set_title(\"Fraud transactions by addr1 (ranked)\", **font_size)\nbx.set_title(\"Legit transactions by addr1 (ranked)\", **font_size)\n\naz.set_title(\"Fraud transactions by addr1\", **font_size)\nbz.set_title(\"Legit transactions by addr1\", **font_size)\n\nxt = plt.xticks(rotation=60)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot VII: emaildomains by Fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get top 10 \norder_p=train.P_emaildomain.value_counts().iloc[:10].index\norder_r=train.R_emaildomain.value_counts().iloc[:10].index\n\nf, axes = plt.subplots(1, 2, figsize=(16, 8))\n\nsns.set(color_codes=True)\np_email = sns.countplot(y='P_emaildomain',  hue=\"isFraud\", data=train, order = order_p, ax=axes[0])\nr_email = sns.countplot(y='R_emaildomain',  hue=\"isFraud\", data=train, order = order_r, ax=axes[1])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot VII: emaildomains by Fraud status as percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2, 1, figsize=(12, 20))\n\nprops = train.groupby(\"P_emaildomain\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='barh', stacked='True', ax=axes[0])\n\nprops = train.groupby(\"R_emaildomain\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='barh', stacked='True', ax=axes[1])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**  \n- **'Protonmail.com'**,  **'mail.com'**, **'outlook.es'**, and, **'net.zero'** have a high proportion of Fraud transaction, yet they account for an small total number of fraud transactions"},{"metadata":{},"cell_type":"markdown","source":"**Plot VIII: M1 - M9 by Fraud status variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"M1_loc = train.columns.get_loc(\"M1\")\nM9_loc = train.columns.get_loc(\"M9\")\ndf_m = train.iloc[:,M1_loc:M9_loc+1] #subset dataframe M1-M9\ndf_m['isFraud'] = train.isFraud \n\ncols = df_m.columns\nf, axes = plt.subplots(3, 3, figsize=(16, 12))\ncount = 0\nfor i in range(3): # rows loop\n    for j in range(3): # cols loop\n        mplot = sns.countplot(x=cols[count], hue = 'isFraud', data=df_m, ax=axes[i,j])\n        count += 1 # to loop over col-names\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot VIII: M1 - M9 variables by Fraud status as percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ms = df_m.columns.tolist()\nms.pop()\nrows = len(ms)\nf, axes = plt.subplots(rows, 1, figsize=(12, 20))\nfor i,m in enumerate(ms): \n    props = train.groupby(m)['isFraud'].value_counts(normalize=True).unstack()\n    p = props.plot(kind='barh', stacked='True', ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- As frequency is hard to catch meaningful differences between classes\n- As percentage there are some interesting patterns on 'M4' where class M2 get the highest proportion of Fraud transactions, or M1 where 'F' doesn't get any Fraud cases"},{"metadata":{},"cell_type":"markdown","source":"**Plot IX**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subset fraud dataset\naddr = 'id_30'\naddrC = 'id_30Count'\nfraud = pd.DataFrame()\nis_fraud = train[train['isFraud']==1]\nfraud[addrC] = is_fraud.groupby([addr])[addr].count()\nfraud[addr] = fraud.index\n\n# Subset NOT fraud dataset\nNOfraud = pd.DataFrame()\nno_fraud = train[train['isFraud']==0]\nNOfraud[addrC] = no_fraud.groupby([addr])[addr].count()\nNOfraud[addr] = NOfraud.index\n\n# There are too many OS, so we will subset the top 20\ngroup_top_f = fraud.sort_values(by=addrC,ascending=False).head(20)\norder_f = group_top_f.sort_values(by=addrC,ascending=False)[addr]\n\ngroup_top_l = NOfraud.sort_values(by=addrC,ascending=False).head(20)\norder_l = group_top_l.sort_values(by=addrC,ascending=False)[addr]\n\nf, axes = plt.subplots(2, 1, figsize=(18, 20))\n\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\n\nax = sns.barplot(y=addr, x=addrC, data=group_top_f, order = order_f, ax=axes[0])\nbx = sns.barplot(y=addr, x=addrC, data=group_top_l, order = order_l, ax=axes[1])\n\nfont_size= {'size': 'x-large'}\nax.set_title(\"Fraud transactions by OS (ranked)\", **font_size)\nbx.set_title(\"Legit transactions by OS (ranked)\", **font_size)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot IX as percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2, 1, figsize=(12, 20))\n\nprops = train.groupby(\"id_30\")['isFraud'].value_counts(normalize=True).unstack()\nprops = props.sort_values(by=1, ascending = False).head(20) # sort by fraud and get top 20\np = props.plot(kind='barh', stacked='True', ax=axes[0])\n\nprops = train.groupby(\"id_31\")['isFraud'].value_counts(normalize=True).unstack()\nprops = props.sort_values(by=1, ascending = False).head(20) # sort by fraud and get top 20\np = props.plot(kind='barh', stacked='True', ax=axes[1])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's get the frequency of the cases with higher proportion of Fraud\nprops_30 = train.groupby(\"id_30\")['isFraud'].value_counts(normalize=True).unstack()\nprops_30 = props_30.sort_values(by=1, ascending = False).head(20) # sort by fraud and get top 20\nid_30_top = props_30.index.tolist()\nprops_30_c = train.groupby(\"id_30\")['isFraud'].value_counts()\nprops_30_c.loc[id_30_top]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"props_31 = train.groupby(\"id_31\")['isFraud'].value_counts(normalize=True).unstack()\nprops_31 = props_31.sort_values(by=1, ascending = False).head(20) # sort by fraud and get top 20\nid_31_top = props_31.index.tolist()\nprops_31_c = train.groupby(\"id_31\")['isFraud'].value_counts()\nprops_31_c.loc[id_31_top]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes**\n- **id_30**: Other and Android 5.1.1 have the highest proportion of Fraud, **BUT**  negligible frequency: Other have 6 cases and Android 5.1.1, 101 cases\n- **id_31**: Lanix, Mozilla, comodo, and lanix have really high proportions of 'Fraud', *BUT*, negible frequency: Lanix/Ilium 1 fraud, Mozilla/Firefox 5 fraud cases, comodo 2, lanix 1"},{"metadata":{},"cell_type":"markdown","source":"**Plot XI: ProductCD by Fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This variable is NOT listed as categorical, but clearly is\nplt.figure(figsize=(10, 5))\nsns.set(color_codes=True)\nsns.set(font_scale = 1.3)\nax = sns.countplot(x='ProductCD', hue =\"isFraud\", data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XI: ProductCD by fraud status as percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"props = train.groupby(\"ProductCD\")['isFraud'].value_counts(normalize=True).unstack()\np = props.plot(kind='barh', stacked='True')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes**  \n  \n**ProductCD is 'Production code'**   \n- 'C': has both the highest number AND the highest proportion of Fraud transactions\n- 'W': has a similar frequency of Fraud transactions for a minor proportion of the W class"},{"metadata":{},"cell_type":"markdown","source":"**Plot XII: TransactionDT, TransactionAmt by Fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"is_fraud = train[train['isFraud']==1]\nno_fraud = train[train['isFraud']==0]\n\nf, axes = plt.subplots(2, 1, figsize=(15, 10))\n\nd1 = sns.distplot(no_fraud.TransactionDT, color=\"fuchsia\", label=\"No fraud\", ax=axes[0])\nl1 = d1.legend()\nd2 = sns.distplot(is_fraud.TransactionDT, color=\"black\", label = \"Fraud\", ax=axes[0])\nl2 = d1.legend()\n\nt1 = sns.distplot(no_fraud.TransactionAmt.apply(np.log2), color=\"fuchsia\", label=\"No fraud\", ax=axes[1])\nl3 = t1.legend()\nt2 = sns.distplot(is_fraud.TransactionAmt.apply(np.log2), color=\"black\", label = \"Fraud\", ax=axes[1])\nl4 = t2.legend()\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- **TransactionDT (time delta from some reference time)**: Not-Fraud transactions tend to be more close to the 'Time zero reference' for the transactions; Fraud transactions tend to be a bit more evenly distributed. There is a pick around 0.55\n- **TransanctionAmt (on dollars)**: Not-Fraud transactions are concentrated on the middle of the distribution, while Fraud transactions are a bit more concentrated on the tails (really small or really bit). This makes a lot of intuitive sense: micro-frauds and large-amounts-frauds are more likely. "},{"metadata":{},"cell_type":"markdown","source":"**Plot XIII: C7 - C14 by Fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"C7_loc = train.columns.get_loc(\"C7\")\nC14_loc = train.columns.get_loc(\"C14\")\ndf_c = train.iloc[:,C7_loc:C14_loc+1] #subset dataframe\ncols = df_c.columns\n\n# run this to allow np.log to work, i.e., prevent zero division\ndf_c.replace(0, 0.000000001, inplace = True) \n\ndf_c['isFraud'] = train.isFraud \n\nis_fraud = df_c[train['isFraud']==1]\nno_fraud = df_c[train['isFraud']==0]\n\nrows = 8\nf, axes = plt.subplots(rows, 1, figsize=(15, 30))\n\nfor i in range(rows):\n    dp = sns.distplot(no_fraud[cols[i]].apply(np.log), color=\"fuchsia\", ax=axes[i])\n    dp = sns.distplot(is_fraud[cols[i]].apply(np.log), color=\"black\", ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- This is all supossed to be 'counting' data, yet, we get a bunch of negative values\n- The main patter, is that not-fraud transactions have higher values, more tightly concentrated (high kurtosis), while fraud transactions are more evenly spread out (low kurtosis), which means more outliers"},{"metadata":{},"cell_type":"markdown","source":"**Plot XIV: D1 - D15 by Fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"D1_loc = train.columns.get_loc(\"D1\")\nD15_loc = train.columns.get_loc(\"D15\")\ndf_d = train.iloc[:,D1_loc:D15_loc+1] #subset dataframe\ncols = df_d.columns\n\n# run this to allow np.log to work, i.e., prevent zero division\ndf_d.replace(0, 0.000000001, inplace = True) \n\ndf_d['isFraud'] = train.isFraud \n\n# log transfrom for visualization\nis_fraud = df_d[train['isFraud']==1].apply(np.log)\nno_fraud = df_d[train['isFraud']==0].apply(np.log)\n\nrows = 15\nf, axes = plt.subplots(rows, 1, figsize=(15, 30))\nfor i in range(rows):\n    dp = sns.distplot(no_fraud[cols[i]].dropna(), color=\"fuchsia\", ax=axes[i])\n    dp = sns.distplot(is_fraud[cols[i]].dropna(), color=\"black\", ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes** \n- **Main insight**: Fraud transactions tend to be **more spread out over time**, while Not-Fraud transactions tend to be **more clustered around shorter time periods** (from the 0 time-point reference) "},{"metadata":{},"cell_type":"markdown","source":"**Plot XV: id_01 - id_11 by fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_01_loc = train.columns.get_loc(\"id_01\")\nid_11_loc = train.columns.get_loc(\"id_11\")\ndf = train.iloc[:,id_01_loc:id_11_loc+1] #subset dataframe\ncols = df.columns\n\n# run this to allow np.log to work, i.e., prevent zero division\ndf.replace(0, 0.000000001, inplace = True) \n\ndf['isFraud'] = train.isFraud \n\n# log transfrom for visualization\nis_fraud = df[train['isFraud']==1].apply(np.log)\nno_fraud = df[train['isFraud']==0].apply(np.log)\n\n# run this to avoid runtime error (log is undefined for inf/NaN values in 'isFraud')\nis_fraud.drop(columns=['isFraud'], inplace=True)\nno_fraud.drop(columns=['isFraud'], inplace=True)\n\nrows = 11\nf, axes = plt.subplots(rows, 1, figsize=(15, 25))\nfor i in range(rows):\n    dp = sns.distplot(no_fraud[cols[i]].dropna(), color=\"fuchsia\", ax=axes[i])\n    dp = sns.distplot(is_fraud[cols[i]].dropna(), color=\"black\", ax=axes[i])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot XV: id_01 - id_11 by Fraud status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_01_loc = train.columns.get_loc(\"id_01\")\nid_11_loc = train.columns.get_loc(\"id_11\")\ndf = train.iloc[:,id_01_loc:id_11_loc+1] #subset dataframe\ncols = df.columns\n\n# run this to allow np.log to work, i.e., prevent zero division\ndf.replace(0, 0.000000001, inplace = True) \n\ndf['isFraud'] = train.isFraud \n\n# log transfrom for visualization\nis_fraud = df[train['isFraud']==1].apply(np.log)\nno_fraud = df[train['isFraud']==0].apply(np.log)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- In the cases where Fraud/Not-Fraud differ, the pattern is the same: **Fraud more clustered with a higher peak**, and **Not-Fraud more spread out with longer/heavier tails**"},{"metadata":{},"cell_type":"markdown","source":"**Explore 'V' Features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here I subset the dataset by the % difference between Fraud and Not-Fraud transactions\nfrom sklearn import preprocessing\n\n#subset dataframe\nV1_loc = train.columns.get_loc(\"V1\")\nV339_loc = train.columns.get_loc(\"V339\")\ndf = train.iloc[:,V1_loc:V339_loc+1] \ncols = df.columns\n\n#scale values\nscaler = preprocessing.MinMaxScaler()\nscaled_array = scaler.fit_transform(df)\nscaled_df = pd.DataFrame(scaled_array, index=df.index, columns=df.columns)\nscaled_df['isFraud'] = train.isFraud \n\n# compute percentage difference between Fraud/Not-fraud transactions\ngroup_means=scaled_df.groupby('isFraud').mean()\ngroup_means_t = group_means.transpose()\ngroup_means_t['delta_percentage'] = ((group_means_t.iloc[:,1] - group_means_t.iloc[:,0]) / ((group_means_t.iloc[:,1] + group_means_t.iloc[:,0]) / 2)) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's limit the plots to the cases where Fraud differs by 100% to Not-Fraud\n# i.e., values that double \nplus_100 = group_means_t[group_means_t[\"delta_percentage\"] >= 100]\nplus_100_index = plus_100.index.tolist()\nlen(plus_100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will plot and format 52! barplots, so it may take while tu run (few minutes)\ndf['isFraud'] = train.isFraud \ncols = plus_100_index\nrows = 13\ncolumns = 4\nf, axes = plt.subplots(rows, columns, figsize=(20, 35))\ncount = 0\nfor i in range(rows): # rows loop\n    for j in range(columns): # cols loop\n        mplot = sns.barplot(x=\"isFraud\", y=cols[count], data=df, ax=axes[i,j])\n        count += 1 # to loop over col-names\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n- There are so many features with no-identity info that it is hard to get a clear insight. It is clear though that there are A LOT features where Fraud transactions have higher means, which means that these variables are going to be variable for the model to learn to capture Fraud cases"},{"metadata":{},"cell_type":"markdown","source":"**This kernel is a bit long, so I'm continuining here with missing values analysis:**  \nhttps://www.kaggle.com/pabloinsente/ieee-missing-nan-values-analysis-and-imputation"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}