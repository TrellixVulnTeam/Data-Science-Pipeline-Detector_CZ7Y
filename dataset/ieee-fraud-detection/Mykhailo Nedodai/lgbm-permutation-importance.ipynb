{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import category_encoders as ce\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_absolute_error\nfrom tqdm import tqdm\nimport lightgbm as lgb\nimport time\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\nimport gc\nimport seaborn as sns\nimport warnings\nfrom sklearn.metrics import f1_score, average_precision_score, confusion_matrix, precision_score\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline\npd.set_option('display.max_columns', 500)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in tqdm(df.columns):\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"folder_path = '../input/'\ntrain_identity = import_data(f'{folder_path}train_identity.csv')\ntrain_transaction = import_data(f'{folder_path}train_transaction.csv')\ntest_identity = import_data(f'{folder_path}test_identity.csv')\ntest_transaction = import_data(f'{folder_path}test_transaction.csv')\nsub = import_data(f'{folder_path}sample_submission.csv')\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def device_proc(x):\n    if x == 'Windows':\n        return 'win'\n    elif x == 'iOS Device' or x == 'MacOS':\n        return 'Mac'\n    else:\n        return 'Other'\n    \ndef browser_proc(x):\n    try:\n        x = x.split(' ')\n        return x[0]\n    except: \n        return x\n\ndef os_proc(x):\n    try:\n        x = x.split(' ')\n        return x[0]\n    except:\n        return x\n    \ndef email1_proc(x):\n    try:\n        x = x.split('.')\n        return x[0]\n    except:\n        return x\n    \ndef data_proc(train):\n    train['DeviceInfo'] = train.DeviceInfo.apply(lambda x: device_proc(x))\n    train['id_31'] = train.id_31.apply(lambda x: browser_proc(x))\n    train['id_30'] = train.id_30.apply(lambda x: os_proc(x))\n    train['P_emaildomain'] = train.P_emaildomain.apply(lambda x: email1_proc(x))\n    train['R_emaildomain'] = train.R_emaildomain.apply(lambda x: email1_proc(x))\n\n    return train\ntrain = data_proc(train)\ntest = data_proc(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train.isFraud.values\ntrain.drop(['TransactionDT', 'TransactionID', 'isFraud'], axis=1, inplace=True)\ntest.drop(['TransactionDT', 'TransactionID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usecol_feature_permutation = ['C1', 'C13', 'card1', 'card2', 'TransactionAmt', 'C14', 'card6', 'addr1', 'D2', 'D15', 'C11', 'V91', 'V257', 'D1', 'P_emaildomain', 'R_emaildomain', 'card5', 'ProductCD', 'D4', 'C6', 'C2', 'D10', 'M4', 'V294', 'V70', 'V317', 'V283', 'V310', 'card3', 'id_17', 'id_31', 'dist1', 'V48', 'id_33', 'D11', 'M6', 'id_20', 'D8', 'id_19', 'C9', 'C12', 'M5', 'C5', 'id_01', 'C8', 'V281', 'V313', 'card4', 'V308', 'id_13', 'M3', 'V55', 'id_02', 'V288', 'V189', 'V62', 'V280', 'V307', 'C10', 'V223', 'V312', 'id_38', 'V61', 'V314', 'M9', 'V131', 'id_05', 'V87', 'V296', 'V37', 'V130', 'id_06', 'V165', 'V66', 'id_30', 'V76', 'M2', 'V282', 'V322', 'dist2', 'C4', 'V75', 'V67', 'V97', 'V82', 'D9', 'D13', 'D6', 'V187', 'V90', 'V77', 'id_14', 'V277', 'V49', 'V13', 'V78', 'V139', 'V53', 'V128', 'DeviceType', 'V151', 'V5', 'id_37', 'V44', 'V285', 'V166', 'V306', 'addr2', 'id_03', 'V287', 'V266', 'V86', 'V56', 'V38', 'C7', 'V17', 'V264', 'V81', 'M8', 'V207', 'V204', 'V140', 'V99']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = ce.WOEEncoder(verbose=1,  drop_invariant=False, return_df=True, \n                        handle_unknown='value', handle_missing='value', random_state=42, \n                        randomized=False, sigma=0.05, regularization=1.0)\nencoder.fit(train, y)\ntrain = encoder.transform(train)\ntest = encoder.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(0)\ntest = test.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'colsample_bytree': 0.10077042112439025, 'max_depth': 95, 'num_leaves': 481, 'reg_alpha': 0.0038938292050716425, 'reg_lambda': 4.961057796456089, 'bagging_fraction': 0.6057333586649449, 'feature_fraction': 0.6004878444394529, 'min_data_in_leaf': 81, 'min_sum_hessian_in_leaf': 0.11844994003313261, 'min_gain_to_split': 0.5222971942325503, 'feature_fraction_seed': 42, 'bagging_seed': 42, 'drop_seed': 42, 'data_random_seed': 42, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2, 'seed': 42, 'save_binary': True, 'boost_from_average': True}\nimport eli5\nfrom IPython.display import display\nfrom eli5.permutation_importance import get_score_importances\nfrom eli5.sklearn import PermutationImportance\n\nfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\nfor fold_, (trn_idx, val_idx) in enumerate(fold.split(train, target)):\n    print(\"%%%%%%%%%%%%%%Fold idx:{}%%%%%%%%%%%%%%%\".format(fold_ + 1))\n\n    trn, trg = train.iloc[trn_idx], target[trn_idx]\n    trn_data = lgb.Dataset(trn, label = trg)\n    val_data = lgb.Dataset(train.iloc[val_idx], label = target[val_idx])\n    clf = lgb.LGBMClassifier(**params, n_estimators = 1000, silent=-1, verbose=-1)\n    clf.fit(train.iloc[trn_idx], target[trn_idx], verbose=100)    \n    print('Trained')\n    perm = PermutationImportance(clf,scoring=None, n_iter=1, random_state=42, cv=None, refit=False).fit(train.iloc[val_idx], target[val_idx])\n    tmp = eli5.show_weights(perm)\n    display(eli5.show_weights(perm, top = len(list(train.columns)), feature_names = list(train.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[usecol_feature_permutation]\ntest = test[usecol_feature_permutation]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fold = 5\nfold = KFold(n_splits=n_fold, random_state=42, shuffle=True)\nparams = {'colsample_bytree': 0.10077042112439025, 'max_depth': 95, 'num_leaves': 481, 'reg_alpha': 0.0038938292050716425, 'reg_lambda': 4.961057796456089, 'bagging_fraction': 0.6057333586649449, 'feature_fraction': 0.6004878444394529, 'min_data_in_leaf': 81, 'min_sum_hessian_in_leaf': 0.11844994003313261, 'min_gain_to_split': 0.5222971942325503, 'feature_fraction_seed': 42, 'bagging_seed': 42, 'drop_seed': 42, 'data_random_seed': 42, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2, 'seed': 42, 'save_binary': True, 'boost_from_average': True}\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfor fold_, (trn_idx, val_idx) in enumerate(fold.split(train, y)):\n    print(\"Fold idx:{}\".format(fold_ + 1))\n    trn, trg = train.iloc[trn_idx], y[trn_idx]\n    trn_data = lgb.Dataset(trn, label = trg)\n    val_enc = train.iloc[val_idx]\n    val_data = lgb.Dataset(val_enc, label = y[val_idx])\n    clf = lgb.train(params, trn_data, 5_000, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 500)\n    oof[val_idx] = clf.predict(val_enc, num_iteration=clf.best_iteration)\n    predictions += clf.predict(test,  num_iteration=clf.best_iteration) / fold.n_splits #,#scaler.transform(encoder.transform(test))\n    gc.collect()\nprint(\"CV score: {:.6f}\".format(roc_auc_score(y, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\n\ncnf_matrix = confusion_matrix(y,np.round(oof))\nplot_confusion_matrix(cnf_matrix, classes=[\"0\", \"1\"],\n                      title='Confusion matrix, lgbm1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['isFraud'] = predictions\nsub.to_csv('submission.csv', index=False)\n\nsub.isFraud.hist(bins=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}