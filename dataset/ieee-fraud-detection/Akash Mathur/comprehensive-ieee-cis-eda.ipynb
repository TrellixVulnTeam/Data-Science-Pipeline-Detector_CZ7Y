{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-22T11:50:30.126228Z","iopub.execute_input":"2021-05-22T11:50:30.12666Z","iopub.status.idle":"2021-05-22T11:50:30.138616Z","shell.execute_reply.started":"2021-05-22T11:50:30.126626Z","shell.execute_reply":"2021-05-22T11:50:30.137541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option(\"display.max_columns\", 500)\n\n#matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:50:30.140296Z","iopub.execute_input":"2021-05-22T11:50:30.140644Z","iopub.status.idle":"2021-05-22T11:50:33.465095Z","shell.execute_reply.started":"2021-05-22T11:50:30.140611Z","shell.execute_reply":"2021-05-22T11:50:33.463824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handy Functions","metadata":{}},{"cell_type":"code","source":"# To calculate missing values\n\ndef missing_vals(df):\n    missing_vals = df.isnull().sum()\n    missing_per = missing_vals/len(train)*100\n    missing_per = missing_per.sort_values(ascending=False).reset_index()\n    missing_table = missing_per.rename({'index':'Column', 0:'Missing %'}, axis=1)\n    return missing_table\n\n\n# To draw data insights\n\ndef data_insights(df):\n    \n    print(f'Dataset Shape : {df.shape}')\n\n    summary = pd.DataFrame(df.dtypes).reset_index().rename({'index':\"Column\", 0:'DataType'}, axis=1)\n    summary['Missing %'] = round((df.isnull().sum()/df.shape[0])*100,2).values\n    summary['No. of Unique Values'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n\n    return summary\n\n#correlation matrix\n\ndef cormat(df):\n    cols = df.columns\n    corrmat = df[cols].corr()\n    f, ax = plt.subplots(figsize=(14,10))\n    summary = sns.heatmap(corrmat, vmax=.8, square=True, annot=True, fmt='.2f')\n    return summary\n    \n\n# Outliers detection\n\ndef CalcOutliers(df_num): \n\n    # calculating mean and std of the array\n    data_mean, data_std = np.mean(df_num), np.std(df_num)\n\n    # seting the cut line to both higher and lower values\n    # You can change this value\n    cut = data_std * 3\n\n    #Calculating the higher and lower cut values\n    lower, upper = data_mean - cut, data_mean + cut\n\n    # creating an array of lower, higher and total outlier values \n    outliers_lower = [x for x in df_num if x < lower]\n    outliers_higher = [x for x in df_num if x > upper]\n    outliers_total = [x for x in df_num if x < lower or x > upper]\n\n    # array without outlier values\n    outliers_removed = [x for x in df_num if x > lower and x < upper]\n    outliers_removed.sort()\n    \n    print(f\"Lowest Value : {outliers_removed[0]}\") # printing lowest value\n    print(f\"Highest Value : {outliers_removed[-1]}\") # printing highest value\n    print('Identified lowest outliers: %d' % len(outliers_lower)) # printing total number of values in lower cut of outliers\n    print('Identified upper outliers: %d' % len(outliers_higher)) # printing total number of values in higher cut of outliers\n    print('Total outlier observations: %d' % len(outliers_total)) # printing total number of values outliers of both sides\n    print('Non-outlier observations: %d' % len(outliers_removed)) # printing total number of non outlier values\n    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4)) # Percentual of outliers in points\n    \n    return ","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:50:33.46723Z","iopub.execute_input":"2021-05-22T11:50:33.467608Z","iopub.status.idle":"2021-05-22T11:50:33.484673Z","shell.execute_reply.started":"2021-05-22T11:50:33.467554Z","shell.execute_reply":"2021-05-22T11:50:33.483142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Glimpse","metadata":{}},{"cell_type":"code","source":"# Train Dataset\ntrain_trans = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\ntrain_id = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:50:33.487028Z","iopub.execute_input":"2021-05-22T11:50:33.487415Z","iopub.status.idle":"2021-05-22T11:51:13.861069Z","shell.execute_reply.started":"2021-05-22T11:50:33.48738Z","shell.execute_reply":"2021-05-22T11:51:13.859723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Dataset\ntest_trans = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_transaction.csv\")\ntest_id = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/test_identity.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:13.862905Z","iopub.execute_input":"2021-05-22T11:51:13.863195Z","iopub.status.idle":"2021-05-22T11:51:41.130256Z","shell.execute_reply.started":"2021-05-22T11:51:13.863167Z","shell.execute_reply":"2021-05-22T11:51:41.129336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train = [col for col in train_id.columns if \"id\" in col]\nid_test = [col for col in test_id.columns if \"id\" in col]\ncol_map = dict(zip(id_test, id_train))","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:41.131607Z","iopub.execute_input":"2021-05-22T11:51:41.131893Z","iopub.status.idle":"2021-05-22T11:51:41.137208Z","shell.execute_reply.started":"2021-05-22T11:51:41.131856Z","shell.execute_reply":"2021-05-22T11:51:41.135952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_id = test_id.rename(col_map, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:41.139474Z","iopub.execute_input":"2021-05-22T11:51:41.139817Z","iopub.status.idle":"2021-05-22T11:51:41.182189Z","shell.execute_reply.started":"2021-05-22T11:51:41.139788Z","shell.execute_reply":"2021-05-22T11:51:41.181227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_trans.merge(train_id, how='left', on=\"TransactionID\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:41.183958Z","iopub.execute_input":"2021-05-22T11:51:41.184253Z","iopub.status.idle":"2021-05-22T11:51:48.687159Z","shell.execute_reply.started":"2021-05-22T11:51:41.184226Z","shell.execute_reply":"2021-05-22T11:51:48.686344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_trans.merge(test_id, how='left', on=\"TransactionID\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:48.688163Z","iopub.execute_input":"2021-05-22T11:51:48.688424Z","iopub.status.idle":"2021-05-22T11:51:54.968597Z","shell.execute_reply.started":"2021-05-22T11:51:48.688399Z","shell.execute_reply":"2021-05-22T11:51:54.967533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train dataset has {train.shape[0]} rows and {train.shape[1]} columns\")\nprint(f\"There are {train.isnull().any().sum()} columns which contains NULL values\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:54.970183Z","iopub.execute_input":"2021-05-22T11:51:54.970619Z","iopub.status.idle":"2021-05-22T11:51:56.241658Z","shell.execute_reply.started":"2021-05-22T11:51:54.970557Z","shell.execute_reply":"2021-05-22T11:51:56.240475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of columns have missing data, which is normal in real world.","metadata":{}},{"cell_type":"markdown","source":"## Missing Values","metadata":{}},{"cell_type":"code","source":"missing_table = missing_vals(train)\nmissing_table","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:56.24311Z","iopub.execute_input":"2021-05-22T11:51:56.243516Z","iopub.status.idle":"2021-05-22T11:51:57.806896Z","shell.execute_reply.started":"2021-05-22T11:51:56.243476Z","shell.execute_reply":"2021-05-22T11:51:57.805865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_num = missing_table[missing_table['Missing %']>50].shape[0]\n\nprint(f\"There are {missing_num} columns where missing % is greater than 50%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:57.808173Z","iopub.execute_input":"2021-05-22T11:51:57.808789Z","iopub.status.idle":"2021-05-22T11:51:57.815623Z","shell.execute_reply.started":"2021-05-22T11:51:57.808748Z","shell.execute_reply":"2021-05-22T11:51:57.81466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test Distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\ntrain_trans['TransactionDT'].plot(kind='hist',title='Train vs Test TransactionDT distribution',\n                                 xlabel='Train', label='Train')\n\ntest_trans['TransactionDT'].plot(kind='hist',\n                                 xlabel='Test', label='Test')\n\nplt.legend()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:57.816862Z","iopub.execute_input":"2021-05-22T11:51:57.817483Z","iopub.status.idle":"2021-05-22T11:51:58.347227Z","shell.execute_reply.started":"2021-05-22T11:51:57.817441Z","shell.execute_reply":"2021-05-22T11:51:58.346417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp). It seems like the train and test are splitted by time. There is a slight gap inbetween.\nThe training set is from an earlier period of time and test is from a later period of time. This will act as a key reason while choosing the right cross validation techniques later.","metadata":{}},{"cell_type":"markdown","source":"## Target Distribution","metadata":{}},{"cell_type":"code","source":"plt.subplots(1,2, figsize=(14,5))\n\nplt.subplot(1,2,1)\nsns.countplot(x=\"isFraud\", data=train)\nplt.title(\"Target Variable Count Distribution\", fontsize=16, loc='center')\n\nplt.subplot(1,2,2)\ntrain.groupby('isFraud')['TransactionAmt'].sum().plot(kind='bar')\nplt.title(\"Transaction Amount Sum Distribution by Target Variable\", fontsize=16, loc='center')\n\nplt.tight_layout()\nplt.show(),\ntrain.isFraud.value_counts(normalize=True)*100 #Imbalance dataset","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:58.348457Z","iopub.execute_input":"2021-05-22T11:51:58.34907Z","iopub.status.idle":"2021-05-22T11:51:58.791227Z","shell.execute_reply.started":"2021-05-22T11:51:58.349026Z","shell.execute_reply":"2021-05-22T11:51:58.790075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 3.5% of Fraud transactions in our dataset.","metadata":{}},{"cell_type":"markdown","source":"## TransactionAmt Distribution","metadata":{}},{"cell_type":"code","source":"data_insights(train[['TransactionAmt']])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:51:58.792784Z","iopub.execute_input":"2021-05-22T11:51:58.793193Z","iopub.status.idle":"2021-05-22T11:52:03.010812Z","shell.execute_reply.started":"2021-05-22T11:51:58.79315Z","shell.execute_reply":"2021-05-22T11:52:03.009785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(2,2, figsize=(16,12))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\n\nplt.subplot(2,2,1)\ntrain[\"TransactionAmt\"].plot()\nplt.title(\"Transaction Amount Distribution\")\n\nplt.subplot(2,2,2)\nsns.boxplot(y=\"TransactionAmt\", data=train[train[\"TransactionAmt\"]<1000])\nplt.title(\"Transaction Amount <1000 Outliers Check\")\n\nplt.subplot(2,2,3)\nplt.scatter(range(train[train['isFraud'] == 0].shape[0]),\n                 np.sort(train[train['isFraud'] == 0]['TransactionAmt'].values),label='NoFraud')\nplt.title(\"Transaction Amount of Non-Fraud Entries\")\n\nplt.subplot(2,2,4)\nplt.scatter(range(train[train['isFraud'] == 1].shape[0]),\n                 np.sort(train[train['isFraud'] == 1]['TransactionAmt'].values),label='NoFraud')\nplt.title(\"Transaction Amount of Fraud Entries\")\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:03.012084Z","iopub.execute_input":"2021-05-22T11:52:03.012372Z","iopub.status.idle":"2021-05-22T11:52:08.687702Z","shell.execute_reply.started":"2021-05-22T11:52:03.012347Z","shell.execute_reply":"2021-05-22T11:52:08.686942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(2,2, figsize=(14,5))\nplt.suptitle('Train Transaction Amount Distribution', fontsize=16)\n\nplt.subplot(221)\ntrain.loc[train[\"isFraud\"]==1][\"TransactionAmt\"].plot(kind='hist', bins=100, title=\"Fraud Distribution\")\n\nplt.subplot(222)\ntrain.loc[train[\"isFraud\"]==1][\"TransactionAmt\"].apply(np.log)\\\n                        .plot(kind='hist', bins=100, title=\"Log Transaformed Fraud Distribution\")\n\nplt.subplot(223)\ntrain.loc[train[\"isFraud\"]==0][\"TransactionAmt\"]\\\n                        .plot(kind='hist', bins=100, title=\"Non-Fraud Distribution\")\n\nplt.subplot(224)\ntrain.loc[train[\"isFraud\"]==0][\"TransactionAmt\"].apply(np.log)\\\n                        .plot(kind='hist', bins=100, title=\"Log Transaformed Non-Fraud Distribution\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:08.688971Z","iopub.execute_input":"2021-05-22T11:52:08.689459Z","iopub.status.idle":"2021-05-22T11:52:14.424501Z","shell.execute_reply.started":"2021-05-22T11:52:08.689427Z","shell.execute_reply":"2021-05-22T11:52:14.423443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Detection ","metadata":{}},{"cell_type":"code","source":"CalcOutliers(train['TransactionAmt']), train[\"TransactionAmt\"].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:14.425803Z","iopub.execute_input":"2021-05-22T11:52:14.426105Z","iopub.status.idle":"2021-05-22T11:52:15.490032Z","shell.execute_reply.started":"2021-05-22T11:52:14.426078Z","shell.execute_reply":"2021-05-22T11:52:15.488994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we consider only values between >= 0 to 800 we will avoid the outliers and has more confidence in our distribution.\nWe have 10k rows with outliers that represents 1.74% of total rows.","metadata":{}},{"cell_type":"markdown","source":"## Product Code Features","metadata":{}},{"cell_type":"code","source":"data_insights(train[['ProductCD']])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:15.494127Z","iopub.execute_input":"2021-05-22T11:52:15.494459Z","iopub.status.idle":"2021-05-22T11:52:15.667705Z","shell.execute_reply.started":"2021-05-22T11:52:15.494429Z","shell.execute_reply":"2021-05-22T11:52:15.666554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prod = train.groupby(\"ProductCD\")['isFraud'].sum().reset_index()\ndf_prod1 = (pd.crosstab(index=train[\"ProductCD\"], columns=train['isFraud'], normalize='index')*100).reset_index()\n\nfig, ax1 = plt.subplots(figsize=(14,7))\nplt.suptitle(\"Fraud Transactions by Product Code\", fontsize=16)\n\ncolor = 'tab:red'\nax1.set_xlabel('Product Code')\nax1.set_ylabel('Number of Fraud Transactions', color=color)\nax1.plot(df_prod.ProductCD, df_prod['isFraud'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\n\nax2 = ax1.twinx()\nax3 = ax1.twinx() # instantiate a second axes that shares the same x-axis\n\nax3.spines.right.set_position((\"axes\", 1.2))\n\ncolor = 'tab:blue'\nax2.set_ylabel('% of Non Fraud Transactions', color=color)  # we already handled the x-label with ax1\nax2.plot(df_prod1.ProductCD, df_prod1[0], color=color, label=\"Non Fraud\")\nax2.tick_params(axis='y', labelcolor=color)\n\ncolor = 'tab:green'\nax3.set_ylabel('% of Fraud Transactions', color=color)  # we already handled the x-label with ax1\nax3.plot(df_prod1.ProductCD, df_prod1[1], color=color, label=\"Fraud\")\nax3.tick_params(axis='y', labelcolor=color)\n\nax2.legend()\nax3.legend()\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:15.671136Z","iopub.execute_input":"2021-05-22T11:52:15.67166Z","iopub.status.idle":"2021-05-22T11:52:16.345217Z","shell.execute_reply.started":"2021-05-22T11:52:15.671608Z","shell.execute_reply":"2021-05-22T11:52:16.343876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.crosstab(index=train['ProductCD'], columns=train['isFraud'], normalize='columns') * 100\ndf = df.reset_index()\ndf.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df[\"ProductCD\"],\n    y=df[\"NoFraud\"],\n    name='NoFraud',\n    marker_color='indianred',\n    text=df[\"NoFraud\"]\n))\n\nfig.add_trace(go.Bar(\n    x=df[\"ProductCD\"],\n    y=df[\"Fraud\"],\n    name='Fraud',\n    marker_color='lightsalmon',\n    text=df[\"Fraud\"]\n))\n\n# Here we modify the tickangle of the xaxis, resulting in rotated labels.\nfig.update_layout(barmode='group', xaxis_tickangle=-45, title='% of Fraud Transactions by Product')\nfig.update_traces(texttemplate='%{text:.2s}%', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:16.347159Z","iopub.execute_input":"2021-05-22T11:52:16.347639Z","iopub.status.idle":"2021-05-22T11:52:16.576893Z","shell.execute_reply.started":"2021-05-22T11:52:16.347592Z","shell.execute_reply":"2021-05-22T11:52:16.576184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> W has the most Fraud and Non Fraud transactions, followed by C and R.\n\n> ProductCD C has the most fraud with >11%\n\n> ProductCD W has the least with ~2%","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.boxplot(x='ProductCD', y='TransactionAmt', data=train[train['TransactionAmt']<1000], hue='isFraud')\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:16.577938Z","iopub.execute_input":"2021-05-22T11:52:16.578318Z","iopub.status.idle":"2021-05-22T11:52:18.931302Z","shell.execute_reply.started":"2021-05-22T11:52:16.57829Z","shell.execute_reply":"2021-05-22T11:52:18.930302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Card Features","metadata":{}},{"cell_type":"code","source":"card_cols = [c for c in train.columns if 'card' in c]\n\n# Card dataset insights\ndata_insights(train[card_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:18.932752Z","iopub.execute_input":"2021-05-22T11:52:18.93305Z","iopub.status.idle":"2021-05-22T11:52:19.310154Z","shell.execute_reply.started":"2021-05-22T11:52:18.933022Z","shell.execute_reply":"2021-05-22T11:52:19.309126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[card_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:19.311313Z","iopub.execute_input":"2021-05-22T11:52:19.311617Z","iopub.status.idle":"2021-05-22T11:52:19.462884Z","shell.execute_reply.started":"2021-05-22T11:52:19.311588Z","shell.execute_reply":"2021-05-22T11:52:19.461828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Non Numerical Features","metadata":{}},{"cell_type":"code","source":"train_df = pd.crosstab(index=train['card4'], columns=train['isFraud'], normalize='index')\n\nx = np.arange(len(train_df.index))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(12,5))\nrects1 = ax.bar(x - width/2, round(train_df[0]*100,2), width, label='Not Fraud')\nrects2 = ax.bar(x + width/2, round(train_df[1]*100,2), width, label='Fraud')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Percentage')\nax.set_title('Percentage by Card 4 and isFraud')\nax.set_xticks(x)\nax.set_xticklabels(train_df.index)\nax.legend()\n\nax.bar_label(rects1, padding=3)\nax.bar_label(rects2, padding=3)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:19.46412Z","iopub.execute_input":"2021-05-22T11:52:19.464403Z","iopub.status.idle":"2021-05-22T11:52:19.871876Z","shell.execute_reply.started":"2021-05-22T11:52:19.464377Z","shell.execute_reply":"2021-05-22T11:52:19.870956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(2,2, figsize=(18,12))\nplt.suptitle(\"Cards Distribution\", fontsize=22)\n\nplt.subplot(2,2,1)\nsns.countplot(train['card4'])\nplt.title(\"Card 4 Distribution\")\n\nplt.subplot(2,2,2)\ntrain.groupby('card4')['TransactionAmt'].sum().plot(kind='bar')\nplt.title(\"Card 4 Distribution by Transacton Amount\")\n\nplt.subplot(2,2,3)\nsns.countplot(train['card6'])\nplt.title(\"Card 6 Distribution\")\n\nplt.subplot(2,2,4)\ntrain.groupby('card6')['TransactionAmt'].sum().plot(kind='bar')\nplt.title(\"Card 6 Distribution by Transacton Amount\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:19.873268Z","iopub.execute_input":"2021-05-22T11:52:19.873549Z","iopub.status.idle":"2021-05-22T11:52:21.936448Z","shell.execute_reply.started":"2021-05-22T11:52:19.873523Z","shell.execute_reply":"2021-05-22T11:52:21.935279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numerical Features","metadata":{}},{"cell_type":"code","source":"df_c3 = pd.crosstab(index=train['card3'], columns=train['isFraud'], normalize='index').reset_index()\ndf_c3 = df_c3.sort_values(by=1, ascending=False).head(30)\n\ndf_c5 = pd.crosstab(index=train['card5'], columns=train['isFraud'], normalize='index').reset_index()\ndf_c5 = df_c5.sort_values(by=1, ascending=False).head(30)\n\n\nplt.subplots(figsize=(16,7))\n\nplt.subplot(211)\nsns.pointplot(x='card3',y=1, data=df_c3, )\nplt.title('Top 30 Fraudlant Transactons by Card 3', fontsize=16)\nplt.ylabel(\"% of Fraudlant Transactons\", fontsize=14)\nplt.xlabel(\"card 3 Values\", fontsize=14)\n\nplt.subplot(212)\nsns.pointplot(x='card5',y=1, data=df_c5)\nplt.title('Top 30 Fraudlant Transactons by Card 5', fontsize=16)\nplt.ylabel(\"% of Fraudlant Transactons\", fontsize=14)\nplt.xlabel(\"card 5 Values\", fontsize=14)\n\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:21.938017Z","iopub.execute_input":"2021-05-22T11:52:21.938352Z","iopub.status.idle":"2021-05-22T11:52:22.992464Z","shell.execute_reply.started":"2021-05-22T11:52:21.93832Z","shell.execute_reply":"2021-05-22T11:52:22.99147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## C1-C14 Features","metadata":{}},{"cell_type":"code","source":"c_cols = [c for c in train.columns if c[0]=='C']\ndata_insights(train[c_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:22.994652Z","iopub.execute_input":"2021-05-22T11:52:22.995071Z","iopub.status.idle":"2021-05-22T11:52:23.191089Z","shell.execute_reply.started":"2021-05-22T11:52:22.99503Z","shell.execute_reply":"2021-05-22T11:52:23.190168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation matrix\ncormat(train[c_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:23.192191Z","iopub.execute_input":"2021-05-22T11:52:23.192457Z","iopub.status.idle":"2021-05-22T11:52:24.863163Z","shell.execute_reply.started":"2021-05-22T11:52:23.192431Z","shell.execute_reply":"2021-05-22T11:52:24.862245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can observe that there is a high correlation among C3 features. Example below:\n\n> C1, C2, C4, C6, C7, C8, C10, C11, C12, C14 are highly correlated with each other. We can keep one of them and drop the rest.","metadata":{}},{"cell_type":"code","source":"plt.subplots(3,5, figsize=(18,14))\n\nx=1\nfor c in c_cols:\n    plt.subplot(5,3,x)\n    sns.kdeplot(train[c])\n    plt.title(f\"{c}'s Density Distribution\")\n    x+=1\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:24.864423Z","iopub.execute_input":"2021-05-22T11:52:24.864713Z","iopub.status.idle":"2021-05-22T11:52:57.612737Z","shell.execute_reply.started":"2021-05-22T11:52:24.864686Z","shell.execute_reply":"2021-05-22T11:52:57.611664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly there are outliers present in each of the C# columns.","metadata":{}},{"cell_type":"code","source":"train_C = train[c_cols]\ntopC1_index = list(train_C.C1.value_counts(normalize=True, sort=True).head(10).index)\nC1_df = (pd.crosstab(index=train['C1'], columns=train['isFraud'], normalize=True)*100).reset_index()\nC1_df = C1_df[C1_df['C1'].isin(topC1_index)]\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    y=C1_df['C1'],\n    x=C1_df[0],\n    name='Not Fraud',\n    orientation='h',\n    marker=dict(\n        color='rgba(246, 78, 139, 0.6)',\n        line=dict(color='rgba(246, 78, 139, 1.0)', width=3)\n    )\n))\nfig.add_trace(go.Bar(\n    y=C1_df['C1'],\n    x=C1_df[1],\n    name='Fraud',\n    orientation='h',\n    marker=dict(\n        color='rgba(58, 71, 80, 0.6)',\n        line=dict(color='rgba(58, 71, 80, 1.0)', width=3)\n    )\n))\n\nfig.update_layout(barmode='stack', title='Top 10 most frequent values in C1 with their Fraud percentage')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:57.614131Z","iopub.execute_input":"2021-05-22T11:52:57.614463Z","iopub.status.idle":"2021-05-22T11:52:57.765442Z","shell.execute_reply.started":"2021-05-22T11:52:57.61443Z","shell.execute_reply":"2021-05-22T11:52:57.764775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## D1-D15 Features","metadata":{}},{"cell_type":"code","source":"d_cols = [c for c in train.columns if c[0]=='D' and len(c)<5]\ndata_insights(train[d_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:57.76647Z","iopub.execute_input":"2021-05-22T11:52:57.766867Z","iopub.status.idle":"2021-05-22T11:52:57.963774Z","shell.execute_reply.started":"2021-05-22T11:52:57.76684Z","shell.execute_reply":"2021-05-22T11:52:57.962895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(3,5, figsize=(18,14))\n\nx=1\nfor c in d_cols:\n    plt.subplot(5,3,x)\n    sns.kdeplot(train[c])\n    plt.title(f\"{c}'s Density Distribution\")\n    x+=1\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:52:57.965177Z","iopub.execute_input":"2021-05-22T11:52:57.965766Z","iopub.status.idle":"2021-05-22T11:53:19.26693Z","shell.execute_reply.started":"2021-05-22T11:52:57.965723Z","shell.execute_reply":"2021-05-22T11:53:19.266126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cormat(train[d_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:19.268102Z","iopub.execute_input":"2021-05-22T11:53:19.26856Z","iopub.status.idle":"2021-05-22T11:53:21.084395Z","shell.execute_reply.started":"2021-05-22T11:53:19.268529Z","shell.execute_reply":"2021-05-22T11:53:21.083387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- D1, D2 are highly correlated with each other. We can keep one of them and drop the other.\n- Also, a lot of missing values, we will treat them later.","metadata":{}},{"cell_type":"code","source":"train[d_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:21.086075Z","iopub.execute_input":"2021-05-22T11:53:21.086515Z","iopub.status.idle":"2021-05-22T11:53:21.675447Z","shell.execute_reply.started":"2021-05-22T11:53:21.086472Z","shell.execute_reply":"2021-05-22T11:53:21.674484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## M1-M9 Columns","metadata":{}},{"cell_type":"code","source":"m_cols = [c for c in train.columns if c[0]=='M']\ntrain_M = train[m_cols]\ndata_insights(train_M)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:21.67661Z","iopub.execute_input":"2021-05-22T11:53:21.6769Z","iopub.status.idle":"2021-05-22T11:53:22.674303Z","shell.execute_reply.started":"2021-05-22T11:53:21.676873Z","shell.execute_reply":"2021-05-22T11:53:22.673379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[train_M[c].unique() for c in train_M.columns]","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:22.675653Z","iopub.execute_input":"2021-05-22T11:53:22.67593Z","iopub.status.idle":"2021-05-22T11:53:23.194983Z","shell.execute_reply.started":"2021-05-22T11:53:22.675904Z","shell.execute_reply":"2021-05-22T11:53:23.194084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_M_plot = train_M.fillna(\"None\")\n\nplt.subplots(nrows = 3, ncols=3, figsize=(18,14))\n\nx=1\nfor c in list(train_M_plot.columns):\n    \n    plt.subplot(3,3,x)\n    sns.countplot(x = c, data= train_M_plot, label=c)\n    plt.title(\"Distinct Value Counts across \"+ c + \" Column\" )\n    x+=1\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:23.196191Z","iopub.execute_input":"2021-05-22T11:53:23.196498Z","iopub.status.idle":"2021-05-22T11:53:29.91359Z","shell.execute_reply.started":"2021-05-22T11:53:23.19647Z","shell.execute_reply":"2021-05-22T11:53:29.912612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## V1-V339 Columns","metadata":{}},{"cell_type":"code","source":"v_cols = [c for c in train.columns if c[0]=='V']\ntrain_V = train[v_cols]\ndata_insights(train_V).head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:29.914836Z","iopub.execute_input":"2021-05-22T11:53:29.915138Z","iopub.status.idle":"2021-05-22T11:53:33.949588Z","shell.execute_reply.started":"2021-05-22T11:53:29.915108Z","shell.execute_reply":"2021-05-22T11:53:33.948497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_V.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:33.950975Z","iopub.execute_input":"2021-05-22T11:53:33.951275Z","iopub.status.idle":"2021-05-22T11:53:45.727541Z","shell.execute_reply.started":"2021-05-22T11:53:33.951245Z","shell.execute_reply":"2021-05-22T11:53:45.726457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## id# Columns","metadata":{}},{"cell_type":"code","source":"id_cols = [c for c in train.columns if 'id' in c]\ntrain_id = train.loc[:,\"id_01\":\"id_38\"]\ndata_insights(train_id)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:45.729118Z","iopub.execute_input":"2021-05-22T11:53:45.729515Z","iopub.status.idle":"2021-05-22T11:53:47.107273Z","shell.execute_reply.started":"2021-05-22T11:53:45.729473Z","shell.execute_reply":"2021-05-22T11:53:47.106529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of missing values in M# columns. ","metadata":{}},{"cell_type":"code","source":"train_id = pd.DataFrame(train[id_cols].dtypes).reset_index()\\\n        .rename({'index':'column', 0:'Dtype'}, axis=1)\n\ntrain_id.groupby('Dtype')['column'].count()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:47.108332Z","iopub.execute_input":"2021-05-22T11:53:47.108741Z","iopub.status.idle":"2021-05-22T11:53:47.276088Z","shell.execute_reply.started":"2021-05-22T11:53:47.108712Z","shell.execute_reply":"2021-05-22T11:53:47.275266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[:,\"id_01\":\"id_38\"].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:47.277113Z","iopub.execute_input":"2021-05-22T11:53:47.277537Z","iopub.status.idle":"2021-05-22T11:53:48.118909Z","shell.execute_reply.started":"2021-05-22T11:53:47.277509Z","shell.execute_reply":"2021-05-22T11:53:48.117708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_id_plot = train[id_cols]\n\nplt.subplots(6, 4, figsize=(18,14))\n\nx=1\nfor c in list(train_id[train_id[\"Dtype\"]== 'float64'].column.unique()):\n    plt.subplot(6,4,x)\n    plt.hist(train_id_plot[c])\n    plt.title(f'Distribution of {c} variable')\n    x+=1\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:48.120418Z","iopub.execute_input":"2021-05-22T11:53:48.120842Z","iopub.status.idle":"2021-05-22T11:53:52.138534Z","shell.execute_reply.started":"2021-05-22T11:53:48.1208Z","shell.execute_reply":"2021-05-22T11:53:52.137419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst = ['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29','id_34', 'id_35', 'id_36', 'id_37','id_38']\n\nplt.subplots(4, 3, figsize=(18,14))\n\nx=1\nfor c in lst:\n    plt.subplot(4,3,x)\n    sns.countplot(x= c, data = train_id_plot)\n    plt.title(f'Distribution of {c} variable')\n    x+=1\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:52.140004Z","iopub.execute_input":"2021-05-22T11:53:52.140413Z","iopub.status.idle":"2021-05-22T11:53:58.894271Z","shell.execute_reply.started":"2021-05-22T11:53:52.140372Z","shell.execute_reply":"2021-05-22T11:53:58.893504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['id_30'].value_counts().plot(kind='bar', figsize=(18,7))","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:53:58.89551Z","iopub.execute_input":"2021-05-22T11:53:58.896016Z","iopub.status.idle":"2021-05-22T11:54:00.15748Z","shell.execute_reply.started":"2021-05-22T11:53:58.895982Z","shell.execute_reply":"2021-05-22T11:54:00.156237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Identity info as a function of Transaction Date","metadata":{}},{"cell_type":"code","source":"id_colss = [c for c in test.columns if 'id' in c]\nid_colss_ = [c.replace('-','_') for c in id_colss]\n\ndictionary = dict(zip(id_colss, id_colss_))\ntest.rename(columns=dictionary,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:00.158992Z","iopub.execute_input":"2021-05-22T11:54:00.159294Z","iopub.status.idle":"2021-05-22T11:54:00.16671Z","shell.execute_reply.started":"2021-05-22T11:54:00.159265Z","shell.execute_reply":"2021-05-22T11:54:00.165531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = data_insights(train_id)\nlst = list(p[p['DataType']!='object'].Column)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:00.168034Z","iopub.execute_input":"2021-05-22T11:54:00.168376Z","iopub.status.idle":"2021-05-22T11:54:00.195457Z","shell.execute_reply.started":"2021-05-22T11:54:00.168346Z","shell.execute_reply":"2021-05-22T11:54:00.194289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Device Features","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='DeviceType',data=train)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:00.196832Z","iopub.execute_input":"2021-05-22T11:54:00.197096Z","iopub.status.idle":"2021-05-22T11:54:00.765507Z","shell.execute_reply.started":"2021-05-22T11:54:00.197071Z","shell.execute_reply":"2021-05-22T11:54:00.764519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pie_frame = pd.DataFrame((train['DeviceInfo'].value_counts(normalize=True))*100).reset_index()\nfig = px.pie(pie_frame.head(10), values='DeviceInfo', names='index', title='Top 10 Device Infomation %')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:00.766898Z","iopub.execute_input":"2021-05-22T11:54:00.767176Z","iopub.status.idle":"2021-05-22T11:54:02.279694Z","shell.execute_reply.started":"2021-05-22T11:54:00.76715Z","shell.execute_reply":"2021-05-22T11:54:02.278539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R_frame = pd.DataFrame(train['R_emaildomain'].value_counts(normalize=True)*100).reset_index().head()\nP_frame = pd.DataFrame(train['P_emaildomain'].value_counts(normalize=True)*100).reset_index().head()\n\nfig1 = px.pie(R_frame.head(10), values='R_emaildomain', names='index', title='R_emaildomain Distribution %')\nfig2 = px.pie(P_frame.head(10), values='P_emaildomain', names='index', title='P_emaildomain Distribution %')\nfig1.show()\nfig2.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:02.281347Z","iopub.execute_input":"2021-05-22T11:54:02.281828Z","iopub.status.idle":"2021-05-22T11:54:02.580198Z","shell.execute_reply.started":"2021-05-22T11:54:02.28178Z","shell.execute_reply":"2021-05-22T11:54:02.578827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_vals(train[['R_emaildomain','P_emaildomain']])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:02.582307Z","iopub.execute_input":"2021-05-22T11:54:02.582892Z","iopub.status.idle":"2021-05-22T11:54:02.69175Z","shell.execute_reply.started":"2021-05-22T11:54:02.582837Z","shell.execute_reply":"2021-05-22T11:54:02.690649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R_fraud_pct = (pd.crosstab(index=train['R_emaildomain'], columns=train['isFraud'], normalize='index')*100).reset_index()\\\n                .rename({0:'Not Fraud', 1:'Fraud'}, axis=1)\n\nfig = px.bar(R_fraud_pct, x=\"R_emaildomain\", y=['Not Fraud','Fraud'], title=\"Fraud % by R_email domain\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:02.693115Z","iopub.execute_input":"2021-05-22T11:54:02.693414Z","iopub.status.idle":"2021-05-22T11:54:02.949796Z","shell.execute_reply.started":"2021-05-22T11:54:02.693384Z","shell.execute_reply":"2021-05-22T11:54:02.948502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"P_fraud_pct = (pd.crosstab(index=train['P_emaildomain'], columns=train['isFraud'], normalize='index')*100).reset_index()\\\n                .rename({0:'Not Fraud', 1:'Fraud'}, axis=1)\n\nfig = px.bar(P_fraud_pct, x=\"P_emaildomain\", y=['Not Fraud','Fraud'], title=\"Fraud % by P_email domain\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:02.951506Z","iopub.execute_input":"2021-05-22T11:54:02.951912Z","iopub.status.idle":"2021-05-22T11:54:03.167838Z","shell.execute_reply.started":"2021-05-22T11:54:02.951875Z","shell.execute_reply":"2021-05-22T11:54:03.166828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transaction Date","metadata":{}},{"cell_type":"code","source":"# Reference - https://www.kaggle.com/c/ieee-fraud-detection/discussion/100071#latest-577632\n\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\ntrain[\"Date\"] = train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\ntrain['_Weekdays'] = train['Date'].dt.dayofweek\ntrain['_Hours'] = train['Date'].dt.hour\ntrain['_Days'] = train['Date'].dt.day","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:03.172876Z","iopub.execute_input":"2021-05-22T11:54:03.173181Z","iopub.status.idle":"2021-05-22T11:54:04.281761Z","shell.execute_reply.started":"2021-05-22T11:54:03.173154Z","shell.execute_reply":"2021-05-22T11:54:04.280877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering\n\nhttps://www.kaggle.com/artgor/eda-and-models#Data-Exploration\nI have referenced this amazing kernels where I could see some amazing feature transformations.","metadata":{}},{"cell_type":"code","source":"train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\ntrain['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntest['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\ntest['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntrain['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\ntrain['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\ntrain['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\ntrain['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n\ntest['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\ntest['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\ntest['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\ntest['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n\ntrain['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\ntrain['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\ntrain['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\ntrain['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n\ntest['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\ntest['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\ntest['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\ntest['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n\ntrain['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\ntrain['D15_to_mean_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('mean')\ntrain['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\ntrain['D15_to_std_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('std')\n\ntest['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\ntest['D15_to_mean_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('mean')\ntest['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\ntest['D15_to_std_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('std')","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:04.283199Z","iopub.execute_input":"2021-05-22T11:54:04.28349Z","iopub.status.idle":"2021-05-22T11:54:05.62633Z","shell.execute_reply.started":"2021-05-22T11:54:04.283461Z","shell.execute_reply":"2021-05-22T11:54:05.625147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\ntrain[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\ntest[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\ntest[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:54:05.628044Z","iopub.execute_input":"2021-05-22T11:54:05.628448Z","iopub.status.idle":"2021-05-22T11:54:13.951259Z","shell.execute_reply.started":"2021-05-22T11:54:05.628412Z","shell.execute_reply":"2021-05-22T11:54:13.949983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_miss = missing_vals(train)\n# many_null_cols = train_miss[train_miss['Missing %']>90].Column.to_list()\n\n# test_miss = missing_vals(test)\n# many_null_cols_test =  test_miss[test_miss['Missing %']>90].Column.to_list()\n\n# big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n# big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n\n# one_value_cols = [col for col in train.columns if train[col].nunique()<=1]\n# one_value_cols_test = [col for col in test.columns if test[col].nunique()<=1]\n\n# cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols + one_value_cols_test))\n# cols_to_drop.remove(\"isFraud\")\n# print(f\"we will drop {len(cols_to_drop)} columns from our test and train data\")\n\n# train = train.drop(cols_to_drop, axis=1)\n# test = test.drop(cols_to_drop, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:55:00.155097Z","iopub.execute_input":"2021-05-22T11:55:00.1555Z","iopub.status.idle":"2021-05-22T11:55:02.129066Z","shell.execute_reply.started":"2021-05-22T11:55:00.155468Z","shell.execute_reply":"2021-05-22T11:55:02.128114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"*Now, we can use this data to feed into various models.* \n\n## Thank You ##","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}