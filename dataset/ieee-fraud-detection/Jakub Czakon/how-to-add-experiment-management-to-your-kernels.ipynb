{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Experiment management\nThis kernel is a fork of @artgor kernel https://www.kaggle.com/artgor/eda-and-models, thank you so much Andrew!\n\nI figured it would make sense to add experiment management on top of that kernel so that everyone can have a clean experimentation process throughout this competition.\nIn this kernel you will learn how to:\n- track data/feature versions\n\n![image1](https://gist.githubusercontent.com/jakubczakon/f754769a39ea6b8fa9728ede49b9165c/raw/d0c079a7076c2292d38ab78cfa0947bdfc4d35b5/kaggle_properties.png)\n\n- track hyperparameters\n\n![image2](https://gist.githubusercontent.com/jakubczakon/f754769a39ea6b8fa9728ede49b9165c/raw/d0c079a7076c2292d38ab78cfa0947bdfc4d35b5/kaggle_parameters.png)\n\n- track metrics\n\n![image3](https://gist.githubusercontent.com/jakubczakon/f754769a39ea6b8fa9728ede49b9165c/raw/d0c079a7076c2292d38ab78cfa0947bdfc4d35b5/kaggle_metrics.png)\n\n- track diagnostic charts like confusion matrix, roc auc curve, or prediction distributions \n\n![image4](https://gist.githubusercontent.com/jakubczakon/f754769a39ea6b8fa9728ede49b9165c/raw/d0c079a7076c2292d38ab78cfa0947bdfc4d35b5/kaggle_images.png)\n\n- track prediction artifacts \n\n![image5](https://gist.githubusercontent.com/jakubczakon/f754769a39ea6b8fa9728ede49b9165c/raw/d0c079a7076c2292d38ab78cfa0947bdfc4d35b5/kaggle_artifacts.png)\n\n- add live monitoring for lightgbm model\n\n![image8](https://gist.githubusercontent.com/jakubczakon/f754769a39ea6b8fa9728ede49b9165c/raw/d0c079a7076c2292d38ab78cfa0947bdfc4d35b5/kaggle_charts.png)\n\nAll of that is logged and organized in [Neptune](http://bit.ly/2XQYNgl). \nI hope that with this in place it will be easier for you to keep track of your experiments during this competition.\nAlso, I would love to see people collaborate more effectively in a team and if there is.\n\nIf you would like to see all my experiments in my public project [go here](https://ui.neptune.ml/jakub-czakon/ieee-fraud-detection/experiments). \n\nOk, let's do it!\n\nI figured I'd hide all the pieces that were exactly the same as in the original kernel and focus on the extras."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install neptune-client neptune-contrib","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nimport neptune\nfrom neptunecontrib.monitoring.lightgbm import neptune_monitor\nfrom neptunecontrib.versioning.data import log_data_version\nfrom neptunecontrib.monitoring.reporting import send_binary_classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data loading"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"raw_data_path = '../input/'\nnrows = None\n\ntrain_identity = pd.read_csv(f'{raw_data_path}train_identity.csv',nrows=nrows)\ntrain_transaction = pd.read_csv(f'{raw_data_path}train_transaction.csv',nrows=nrows)\ntest_identity = pd.read_csv(f'{raw_data_path}test_identity.csv',nrows=nrows)\ntest_transaction = pd.read_csv(f'{raw_data_path}test_transaction.csv',nrows=nrows)\nsub = pd.read_csv(f'{raw_data_path}sample_submission.csv',nrows=nrows)\n# let's combine the data and work with the whole dataset\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n\nprint(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\nprint(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\ntrain['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\ntrain['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntest['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\ntest['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\ntest['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n\ntrain['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\ntrain['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\ntrain['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\ntrain['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n\ntest['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\ntest['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\ntest['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\ntest['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n\ntrain['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\ntrain['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\ntrain['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\ntrain['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n\ntest['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\ntest['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\ntest['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\ntest['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n\n\ntrain['dist1_to_mean_card1'] = train['dist1'] / train.groupby(['card1'])['dist1'].transform('mean')\ntrain['dist1_to_mean_card4'] = train['dist1'] / train.groupby(['card4'])['dist1'].transform('mean')\ntrain['dist1_to_std_card1'] = train['dist1'] / train.groupby(['card1'])['dist1'].transform('std')\ntrain['dist1_to_std_card4'] = train['dist1'] / train.groupby(['card4'])['dist1'].transform('std')\n\ntest['dist1_to_mean_card1'] = test['dist1'] / test.groupby(['card1'])['dist1'].transform('mean')\ntest['dist1_to_mean_card4'] = test['dist1'] / test.groupby(['card4'])['dist1'].transform('mean')\ntest['dist1_to_std_card1'] = test['dist1'] / test.groupby(['card1'])['dist1'].transform('std')\ntest['dist1_to_std_card4'] = test['dist1'] / test.groupby(['card4'])['dist1'].transform('std')\n\n\ntrain['D4_to_mean_card1'] = train['D4'] / train.groupby(['card1'])['D4'].transform('mean')\ntrain['D4_to_mean_card4'] = train['D4'] / train.groupby(['card4'])['D4'].transform('mean')\ntrain['D4_to_std_card1'] = train['D4'] / train.groupby(['card1'])['D4'].transform('std')\ntrain['D4_to_std_card4'] = train['D4'] / train.groupby(['card4'])['D4'].transform('std')\n\ntest['D4_to_mean_card1'] = test['D4'] / test.groupby(['card1'])['D4'].transform('mean')\ntest['D4_to_mean_card4'] = test['D4'] / test.groupby(['card4'])['D4'].transform('mean')\ntest['D4_to_std_card1'] = test['D4'] / test.groupby(['card1'])['D4'].transform('std')\ntest['D4_to_std_card4'] = test['D4'] / test.groupby(['card4'])['D4'].transform('std')\n\ntrain['card1_count'] = train.groupby(['card1'])['TransactionID'].transform('count')\ntrain['card2_count'] = train.groupby(['card2'])['TransactionID'].transform('count')\ntrain['card4_count'] = train.groupby(['card4'])['TransactionID'].transform('count')\n\ntest['card1_count'] = test.groupby(['card1'])['TransactionID'].transform('count')\ntest['card2_count'] = test.groupby(['card2'])['TransactionID'].transform('count')\ntest['card4_count'] = test.groupby(['card4'])['TransactionID'].transform('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\nmany_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\none_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\none_value_cols == one_value_cols_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\nlen(cols_to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cols_to_drop.remove('isFraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']\nfor col in cat_cols:\n    if col in train.columns:\n        train = train.drop([col], axis=1)\n        test = test.drop([col], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is usually beneficial to save extracted features for future reference.\nAdditional bonus is that calculating feature version ( `md5 hash`) is easier."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_path = 'train_features_v0.csv'\ntest_features_path = 'test_features_v0.csv'\n\ntrain.to_csv(train_features_path, index=None)\ntest.to_csv(test_features_path, index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\ny = train.sort_values('TransactionDT')['isFraud']\nX_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\n\ntrain = train[[\"TransactionDT\", 'TransactionID']]\ntest = test[[\"TransactionDT\", 'TransactionID']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_params = {'seed':1234,\n                     'n_folds':5,\n                     'validation_schema': 'kfold'}\n\nfolds = KFold(n_splits=validation_params['n_folds'], random_state=validation_params['seed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_params = {'num_leaves': 256,\n                  'min_child_samples': 79,\n                  'objective': 'binary',\n                  'max_depth': 15,\n                  'learning_rate': 0.02,\n                  \"boosting_type\": \"gbdt\",\n                  \"subsample_freq\": 3,\n                  \"subsample\": 0.9,\n                  \"bagging_seed\": 11,\n                  \"metric\": 'auc',\n                  \"verbosity\": -1,\n                  'reg_alpha': 0.3,\n                  'reg_lambda': 0.3,\n                  'colsample_bytree': 0.9\n                 }\n\ntraining_params = {'num_boosting_rounds':5000,\n                   'early_stopping_rounds':200\n               }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's combine all the parameters in one big hyperparameter dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperparameters={**model_params, **training_params,**validation_params}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And let's define the `fit_predict` function that will train the model and return predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_predict(X, y, X_test, folds, model_params, training_params):\n    out_of_fold, test_preds = np.zeros(len(X)), np.zeros(len(X_test))\n    for fold_nr, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n        print(\"Fold {}\".format(fold_nr))\n\n        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n\n        trn_data = lgb.Dataset(X_train, y_train)\n        val_data = lgb.Dataset(X_valid, y_valid)\n        \n        # add live monitoring of lightgbm learning curves\n        monitor = neptune_monitor(prefix='fold{}_'.format(fold_nr))\n        clf = lgb.train(model_params, trn_data, \n                        training_params['num_boosting_rounds'], \n                        valid_sets = [trn_data, val_data], \n                        early_stopping_rounds = training_params['early_stopping_rounds'],\n                        callbacks=[monitor])\n        out_of_fold[val_idx] = clf.predict(X.iloc[val_idx], num_iteration=clf.best_iteration)\n        test_preds += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n    return out_of_fold, test_preds    \n\ndef fmt_preds(y_pred):\n    return np.concatenate((1.0-y_pred.reshape(-1,1), y_pred.reshape(-1,1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding Experiment management \n\nOk. now we have everything ready to set-up experiment management.\n\nLet's start by initializing Neptune with the api token and project name.\nFor now I will use open token and public shared project but if you register you can create private project for you and your team (for free)."},{"metadata":{"trusted":true},"cell_type":"code","source":"neptune.init(api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5tbCIsImFwaV9rZXkiOiJiNzA2YmM4Zi03NmY5LTRjMmUtOTM5ZC00YmEwMzZmOTMyZTQifQ==',\n             project_qualified_name='shared/showroom')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can also pass NEPTUNE_PROJECT and NEPTUNE_API_TOKEN as environment variables.\n\nIn notebooks you can do it by running:\n    \n```bash\n% env NEPTUNE_API_TOKEN=eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5tbCIsImFwaV9rZXkiOiJiNzA2YmM4Zi03NmY5LTRjMmUtOTM5ZC00YmEwMzZmOTMyZTQifQ==\n% env NEPTUNE_PROJECT=shared/showroom\n```\n\nand then you will be able run simpler command:\n\n```python\nneptune.init()\n```\n\nWhenever you run `neptune.create_experiment` a link to an experiment is created and you can go and see your experiment.\nExample link looks like this https://ui.neptune.ml/o/shared/org/showroom/e/SHOW-25"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predictions_path = 'train_predictions_v0.csv'\ntest_predictions_path = 'test_predictions_v0.csv'\nsubmission_path = 'submission_v0.csv'\n\nwith neptune.create_experiment(name='model training',\n                               params=hyperparameters,\n                               tags=['lgbm', 'features_v0', 'training']):\n    # log data versions\n    log_data_version(train_features_path, prefix='train_features_')\n    log_data_version(test_features_path, prefix='test_features_')\n\n    out_of_fold, test_preds = fit_predict(X, y, X_test, folds, model_params, training_params)\n    \n    valid_auc = roc_auc_score(y, out_of_fold)\n    # log valid auc metric\n    neptune.send_metric('valid_auc', valid_auc)\n    # log diagnostic charts on the validation\n    send_binary_classification_report(y, fmt_preds(out_of_fold), channel_name='valid_classification_report')\n    \n    train = pd.concat([train, pd.DataFrame(out_of_fold, columns=['prediction'])], axis=1)\n    test = pd.concat([test, pd.DataFrame(test_preds, columns=['prediction'])], axis=1)\n    sub['isFraud'] = pd.merge(sub, test, on='TransactionID')['prediction']\n    train.to_csv(train_predictions_path, index=None)\n    test.to_csv(test_predictions_path, index=None)\n    sub.to_csv(submission_path, index=None)\n    # log out of fold predictions and submission\n    neptune.send_artifact(train_predictions_path)\n    neptune.send_artifact(test_predictions_path)\n    neptune.send_artifact(submission_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's it!\n\nIf you want to go beyond single script you can see how I created a starter cookie-cutter data science project [here](https://ui.neptune.ml/jakub-czakon/ieee-fraud-detection/experiments) with some additional tracking benefits like environment and code.\n\nI would really like to get your feedback on this kernel and experiment management overall so please comment."}],"metadata":{"kernelspec":{"display_name":"py_36","language":"python","name":"py_36"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}