{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\", 500)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import TimeSeriesSplit, StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom hyperopt import fmin, hp, tpe, space_eval\nimport lightgbm as lgb\n\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntrain_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\n\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n\ngc.enable()\ndel train_transaction, train_identity\ngc.collect()\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[: 3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min  and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n    \n    end_mem = df.memory_usage().sum()/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_cols = [c for c in train.columns if 'id' in c]\nC_cols = [c for c in train.columns if 'C' in c]\nD_cols = [c for c in train.columns if c.startswith('D')]\ncard_cols = [c for c in train.columns if 'card' in c]\nid_category_cols = id_cols[11: ]\nid_numeric_cols = id_cols[: 11]\n\nfor col in ['addr1', 'addr2']:\n    train[col] = train[col].astype('object')\nfor col in card_cols:\n    train[col] = train[col].astype('object')\nfor col in id_category_cols:\n    train[col] = train[col].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TransactionAmt'] = train['TransactionAmt'].astype(float)\ntrain['TransAmtLog'] = np.log(train['TransactionAmt'])\ntrain['TransAmtDemical'] = train['TransactionAmt'].astype('str').str.split('.', expand=True)[1].str.len()\n\nplt.figure(figsize=(15, 10))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\nplt.subplot(221)\ng = sns.distplot(train['TransactionAmt'])\ng.set_title('Transaction Amount Distribution')\ng.set_xlabel('')\ng.set_ylabel('Probability', fontsize=15)\n\nplt.subplot(222)\ng1 = sns.distplot(np.log(train['TransactionAmt']))\ng1.set_title('Transaction Amount Log Distribution')\ng1.set_xlabel('')\ng.set_ylabel('Probability', fontsize=15)\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(212)\ng4 = plt.scatter(range(train[train['isFraud'] == 0].shape[0]), \n                np.sort(train[train['isFraud'] == 0]['TransactionAmt'].values), \n                label='NoFraud', alpha=.2)\ng4 = plt.scatter(range(train[train['isFraud'] == 1].shape[0]), \n                np.sort(train[train['isFraud'] == 1]['TransactionAmt'].values), \n                label='Fraud', alpha=.2)\ng4 = plt.title('ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution', fontsize=18)\ng4 = plt.xlabel('Index')\ng4 = plt.ylabel('Amount Distribution', fontsize=15)\ng4 = plt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_email(df):\n    for col in ['R_emaildomain', 'P_emaildomain']:\n        col1 = col.replace('domain', 'Corp')\n        df[col1] = df[col]\n        df.loc[df[col].isin(['gmail.com', 'gmail']), col1] = 'Google'\n        df.loc[df[col].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk', 'yahoo.co.jp', \n                                 'yahoo.de', 'yahoo.fr', 'yahoo.es', 'yahoo.com.mx', \n                                 'ymail.com']), col1] = 'Yahoo'\n        df.loc[df[col].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', 'hotmail.es', \n                                 'hotmail.co.uk', 'hotmail.de', 'outlook.es', 'live.com', 'live.fr', \n                                 'hotmail.fr']), col1] = 'Microsoft'\n        df.loc[df[col].isin(['aol.com', 'verizon.net']), col1] = 'Verizon'\n        df.loc[df[col].isin(['att.net', 'sbcglobal.net', 'bellsouth.net']), col1] = 'AT&T'\n        df.loc[df[col].isin(['icloud.com', 'mac.com', 'me.com']), col1] = 'Apple'\n        df.loc[df[col1].isin(df['R_emailCorp'].value_counts()\\\n                                      [df['R_emailCorp'].value_counts() <= 1000].index), col1] = 'Others'\n\n        col2 = col.replace('domain', 'Google')\n        df[col2] = df[col1].str.contains('Google') * 1\n        \n        col3 = col.replace('domain', '_prefix')\n        df[col3] = df[col].str.split('.').str[0]\n        \n        col4 = col.replace('domain', '_suffix')\n        df[col4] = df[col].str.split('.').str[-1]\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_TransactionDT(df):\n    START_DATE = '2017-12-01'\n    start_date = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n    df['TransactionDT'] = df['TransactionDT'].apply(lambda x: (start_date + datetime.timedelta(seconds=x)))\n\n    df['Year'] = df['TransactionDT'].dt.year\n    df['Weekday'] = df['TransactionDT'].dt.dayofweek\n    df['Hour'] = df['TransactionDT'].dt.hour\n    df['Day'] = df['TransactionDT'].dt.day\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_id_cols(df):\n    # Dealing with id_30\n    df['id_30'] = df['id_30'].replace('nan', np.nan)\n    df['System'] = df['id_30'].astype('str').str.split('.', expand=True)[0].str.split('_', expand=True)[0]\n    df['SystemCorp'] = df['System'].str.split(expand=True)[0]\n    \n    # Dealing with id_31\n    df['Browser'] = df['id_31'].str.replace(r'\\d+.?\\d*', '')\n    \n    df['LastestBrowser'] = df['id_31']\n    df.loc[df['LastestBrowser'].isin(['samsung browser 7.0', 'opera 53.0', 'mobile safari 10.0', 'chrome 63.0 for android', \n                                       'google search application 49.0', 'firefox 60.0', 'edge 17.0', 'chrome 69.0', \n                                       'chrome 67.0 for android', 'chrome 64.0', 'chrome 63.0 for ios', 'chrome 65.0', \n                                       'chrome 64.0 for android', 'chrome 64.0 for ios', 'chrome 66.0', \n                                       'chrome 65.0 for android', 'chrome 65.0 for ios', 'chrome 66.0 for android', \n                                       'chrome 66.0 for ios']), 'LastestBrowser'] = 1\n    df.loc[df['LastestBrowser'].str.len() > 1, 'LastestBrowser'] = 0\n    \n    df['BrowserCorp'] = df['id_31']\n    df.loc[df['BrowserCorp'].str.contains('samsung', case=False, na=False), 'BrowserCorp'] = 'Samsung'\n    df.loc[df['BrowserCorp'].str.contains('safari', case=False, na=False), 'BrowserCorp'] = 'Apple'\n    df.loc[df['BrowserCorp'].str.contains('chrome|google', case=False, na=False), 'BrowserCorp'] = 'Google'\n    df.loc[df['BrowserCorp'].str.contains('firefox', case=False, na=False), 'BrowserCorp'] = 'Mozilla'\n    df.loc[df['BrowserCorp'].str.contains('edge|ie|microsoft', case=False, na=False, regex=True), 'BrowserCorp'] = 'Microsoft'\n    df.loc[df['BrowserCorp'].isin(df['BrowserCorp'].value_counts()\\\n                                  [df['BrowserCorp'].value_counts()< 1000].index), ['BrowserCorp']] = 'other'\n    \n    # Dealing with id_33\n    df['DisplayWidth'] = df['id_33'].str.split('x', expand=True)[0].astype(float)\n    df['DisplayHeight'] = df['id_33'].str.split('x', expand=True)[1].astype(float)\n    \n    # Dealing with DeviceInfo\n    df['DeviceType1'] = df['DeviceInfo'].str.split('-', expand=True)[0]\n    df['DeviceType2'] = df['DeviceType1'].str.split(' ', expand=True)[0]\n           \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_number(df):\n    df['C1_min_C5'] = (df['C1'] - df['C5']).apply(lambda x: 0 if x <= 0 else 1)\n    \n    for col in ['addr1__addr2', 'addr1__card3', 'P_emaildomain__id_33', 'R_emaildomain__id_33', \n                'card6__addr2', 'id_32__V146', 'id_19__id_20']:\n        col1, col2 = col.split('__')\n        df[col] = df[col1].astype('str') + '_' + df[col2].astype('str')\n        df.loc[df[col].str.contains('nan', na=True), col] = np.nan\n       \n    for col in card_cols:\n        df[col] = df[col].fillna(-999)\n    \n    df['count_card3_P_emaildomain'] = df.groupby('card3').P_emaildomain.transform('count')\n    df['count_card3_R_emaildomain'] = df.groupby('card3').R_emaildomain.transform('count')\n    df['count_card6_P_emaildomain'] = df.groupby('card6').P_emaildomain.transform('count')\n    df['count_card6_R_emaildomain'] = df.groupby('card6').R_emaildomain.transform('count')\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\ntest['TransactionAmt'] = test['TransactionAmt'].astype(float)\ntest['TransAmtLog'] = np.log(test['TransactionAmt'])\ntest['TransAmtDemical'] = test['TransactionAmt'].astype('str').str.split('.', expand=True)[1].str.len()\n\nfor col in ['addr1', 'addr2']:\n    test[col] = test[col].astype('object')\nfor col in card_cols:\n    test[col] = test[col].astype('object')\nfor col in id_category_cols:\n    test[col] = test[col].astype('object')\n\ndel test_transaction, test_identity\ngc.collect()\n\nprint(test.info())\n\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = transform_email(train)\ntrain = transform_TransactionDT(train)\ntrain = transform_id_cols(train)\ntrain = transform_number(train)\n\ntest = transform_email(test)\ntest = transform_TransactionDT(test)\ntest = transform_id_cols(test)\ntest = transform_number(test)\n\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding_cols = ['card1','card2','card3','card5', \n#                  'C1','C2','C5','C6','C9','C11','C12','C13','C14', \n#                  'addr1','addr2','dist1', \n#                  'P_emaildomain', 'R_emaildomain',\n#                  'id_01','id_02','id_03','id_05','id_06','id_09', \n#                  'id_11','id_13','id_14','id_17','id_19','id_20','id_30',\n#                  'id_31','id_33','Browser','DeviceInfo','DeviceType1','System']\n# for col in encoding_cols:\n#     temp_df = pd.concat([train[[col]], test[[col]]])\n#     fq_encode = temp_df[col].value_counts().to_dict()   \n#     train[col+'_fq_enc'] = train[col].map(fq_encode)\n#     test[col+'_fq_enc']  = test[col].map(fq_encode)\n    \n#     del temp_df\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop = ['V194', 'V195', 'V247', 'V142', 'V141', 'V191', 'V173', 'M1', 'V325', 'V138', 'V1', 'V41', 'V14','V65', \n                'V27', 'V240', 'V98', 'V105', 'V316', 'V301', 'V123', 'V136', 'V113', 'id_18', 'V110', 'V115', 'V108', \n                'V124', 'V104', 'V241', 'V191', 'V186', 'V252', 'V174', 'V172', 'V181', 'id_36', 'id_29', 'id_28', 'V185', \n                'id_10', 'V223', 'id_04', 'V242', 'V248', 'V223', 'V161', 'V226', 'V276', 'V278', 'id_35', 'id_25', 'V7', \n                'id_21', 'id_24', 'V295', 'V133', 'V299', 'V305', 'V286', 'V319', 'V321', 'V284', 'V116', 'V300', 'id_23', \n                'V311', 'V114', 'V118', 'V121', 'V106', 'V122', 'V125', 'V137', 'id_26', 'V103', 'V318', 'V120', 'id_27', \n                'V119', 'V293', 'V290', 'id_07', 'V132', 'dist2', 'V296', 'D7', 'V135', 'V297', 'V111', 'V298', 'V101', \n                'V309', 'id_08', 'V109', 'C3', 'V102', 'V107', 'V117', 'V112', 'V320', 'V134', 'id_22', 'V129', 'V281',  \n                'V235', 'V159', 'V312', 'V274', 'V263', 'V33', 'V199', 'V327', 'V190', 'V322', 'V266', 'V207', 'V336', \n                'V160', 'V153', 'V157', 'V126', 'V273', 'V28', 'V91']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(cols_to_drop, axis=1, inplace=True)\ntest.drop(cols_to_drop, axis=1, inplace=True)\n\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nfor col in train.select_dtypes(include=['object', 'category']).columns:\n    le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n    train[col] = le.transform(list(train[col].astype(str).values))\n    test[col] = le.transform(list(test[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['isFraud', 'TransactionDT'], axis=1)\ny_train = train['isFraud']\nX_test = test.drop(['TransactionDT'], axis=1)\ndel train\n\nX_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams = {\n    'learning_rate': 0.05, \n    'max_depth': 9, \n    'gamma': 0.1, \n    'alpha': 4, \n    'subsample': 0.9, \n    'colsample_bytree': 0.9, \n    'Missing': -999\n}\n\ncv_scores = []\nsplits = 5\ny_preds = np.zeros(len(X_test))\nXGB_feature_importances = np.zeros(X_train.shape[1])\nskf = StratifiedKFold(n_splits=splits)\nfor fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n    clf = XGBClassifier(\n        n_estimators=500,\n        **params,\n        tree_method='gpu_hist',\n        early_stopping_rounds=100,\n        random_state=4\n    )\n\n    X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n        \n    clf.fit(X_tr, y_tr)\n        \n    y_pred_train = clf.predict_proba(X_vl)[:,1]\n    score = roc_auc_score(y_vl, y_pred_train)\n    print(\"FOLD: \",fold,' AUC {}'.format(score))\n    cv_scores.append(score)\n    \n    y_preds += clf.predict_proba(X_test)[:,1] / splits\n    XGB_feature_importances += clf.feature_importances_ / splits\n    \n    del X_tr, X_vl, y_tr, y_vl, clf, y_pred_train    \n    gc.collect()\n\nprint('CV Score : Mean - %.7g | Std - %.7g |Min - %.7g | Max - %.7g' % (np.mean(cv_scores), np.std(cv_scores),\n                                    np.min(cv_scores), np.max(cv_scores)))\n\nXGB_feature_importances = pd.Series(XGB_feature_importances, X_train.columns).sort_values(ascending=False)\n\nplt.figure(figsize=(12, 6))\nXGB_feature_importances[: 50].plot(kind='bar', title='Feature Importances')\nplt.ylabel('Feature Importances Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_features = XGB_feature_importances[XGB_feature_importances.values == 0.0].index\nprint('There are %d features with 0.0 importance' % len(zero_features))\nprint(zero_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"low_importance = XGB_feature_importances[300: -1]\nlow_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\nXGB_submission['isFraud'] = y_preds\nXGB_submission.to_csv('XGB_fraud_detection.csv')\nXGB_feature_importances.to_csv('XGB_feature_importances.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}