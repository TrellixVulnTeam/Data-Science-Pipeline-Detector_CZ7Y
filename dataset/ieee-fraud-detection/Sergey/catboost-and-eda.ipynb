{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Basic EDA and Catboost - IEEE fraud"},{"metadata":{},"cell_type":"markdown","source":"This kernel shows how to use catboost to get a relatively decent score on this dataset"},{"metadata":{},"cell_type":"markdown","source":"* Credit to https://www.kaggle.com/kyakovlev/ieee-data-minification for the reduction of data\n* Credit to https://www.kaggle.com/artgor/eda-and-models for some helper functions"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, warnings, random\n\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom catboost import CatBoostClassifier, Pool, cv\nfrom sklearn.metrics import auc\nimport shap\n\nfrom tqdm import tqdm\n\nimport math\nwarnings.filterwarnings('ignore')\n\nSEED = 10","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"########################### Helpers\n#################################################################################\n## -------------------\n## Seeder\n# :seed to make all processes deterministic     # type: int\ndef seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n## ------------------- \n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### DATA LOAD\n#################################################################################\nseed_everything(SEED)\n\nprint('Load Data')\ntrain_df = pd.read_pickle('../input/ieee-data-minification/train_transaction.pkl')\n\ntest_df = pd.read_pickle('../input/ieee-data-minification/test_transaction.pkl')\ntrain_identity = pd.read_pickle('../input/ieee-data-minification/train_identity.pkl')\ntest_identity = pd.read_pickle('../input/ieee-data-minification/test_identity.pkl')\n\nbase_columns = list(train_df) + list(train_identity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(train_df,train_identity, how = 'left', on = 'TransactionID',validate = \"many_to_one\")\ntest_df = pd.merge(test_df,test_identity, how = 'left', on = 'TransactionID',validate = \"many_to_one\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop([\"TransactionID\", \"TransactionDT\"],axis=1, inplace=True)\ntest_df.drop([\"TransactionDT\"],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop([\"isFraud\"],axis=1)\ny= train_df[\"isFraud\"]\nX_Test = test_df.copy()\n\nX_Test.drop(['TransactionID', 'isFraud'],axis=1,inplace=True) #getting rid of the trans.ID that is in our submission file anyway\n\n# X = reduce_mem_usage(X)\n# X_Test = reduce_mem_usage(X_Test)\n\n\ndel train_df, test_df, train_identity, test_identity\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### basic data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Before dropna, top missing columns:\\n{X.isna().sum().sort_values(ascending = False).head(5)}\\n\")\n\nthresh = 0.80 #how many NA values (%) I think anything more than 80% is a bit too much. This is of course only my opinion\n\nX_less_nas = X.dropna(thresh=X.shape[0]*(1-thresh), axis='columns')\n\ncols_dropped  = list(set(X.columns)-set(X_less_nas.columns))\n\nX_Test.drop(cols_dropped, axis=1, inplace=True)\n\n# X_less_nas = reduce_mem_usage(X_less_nas)\n# X_Test = reduce_mem_usage(X_Test)\n\nprint(f\"After dropna, top missing columns:\\n{X_less_nas.isna().sum().sort_values(ascending = False).head(5)}\")\n\nprint(f\"\\nNo. of cols dropped = {len(set(X.columns)-set(X_less_nas.columns))}, or {len(set(X.columns)-set(X_less_nas.columns))/len(X.columns)*100:.2f}% of columns\")\n\ndel X ; gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build a dictionary containing the categorical features for *catboost's API*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#according to https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203#latest-607486\n\nCatfeats = ['ProductCD'] + \\\n           [\"card\"+f\"{i+1}\" for i in range(6)] + \\\n           [\"addr\"+f\"{i+1}\" for i in range(2)] + \\\n           [\"P_emaildomain\", \"R_emaildomain\"] + \\\n           [\"M\"+f\"{i+1}\" for i in range(9)] + \\\n           [\"DeviceType\", \"DeviceInfo\"] + \\\n           [\"id_\"+f\"{i}\" for i in range(12, 39)]\n\n# removing columns dropped earlier when we weeded out the empty columns\n\nCatfeats = list(set(Catfeats)- set(cols_dropped))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets define our Numerical Features as well:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Numfeats = list(set(X_less_nas.columns)- set(cols_dropped)-set(Catfeats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_less_nas[Catfeats].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems good :) \n\nAccording to Catboost's official tutorial, it's good transform our NaN values to some number way out their distribution\n\nhttps://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb\n\nlets do that:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_less_nas.fillna(-10000, inplace=True)\nX_Test.fillna(-10000, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_less_nas.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"## quick test with AUC\n\nX_tr, X_val, y_tr, y_val = train_test_split(X_less_nas, y, test_size=0.2, random_state=SEED,stratify = y)\n\ncat_params = {\n    'loss_function': 'Logloss',\n    'custom_loss':['AUC'],\n    'logging_level':'Silent',\n    'task_type' : 'GPU',\n    'early_stopping_rounds' : 100\n}\n\nsimple_model = CatBoostClassifier(**cat_params)\n\nsimple_model.fit(\n    X_tr, y_tr,\n    cat_features=Catfeats,\n    eval_set=(X_val, y_val),plot=True\n);\n\n# cv_params = model.get_params()\n\n# cv_data = cv(\n#     Pool( X.iloc[:2000,:5], y[:2000], `=[1]),\n#     cv_params,nfold=4,\n#     plot=True\n# )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks very promising. Lets train on all available data,\n\nI'll do cross validation later"},{"metadata":{"trusted":true},"cell_type":"code","source":"#final training on whole trianing set\n\n\nsimple_model.fit(\n    X_less_nas, y,\n    cat_features=Catfeats,logging_level = 'Silent'\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv')\nsubmission['isFraud'] = simple_model.predict_proba(X_Test)[:,1] # you must predict a probability for the isFraud variable\nsubmission.to_csv('simple_model_Catboost1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}