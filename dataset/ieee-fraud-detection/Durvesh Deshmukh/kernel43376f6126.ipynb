{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\ndf_test_trans = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')\n\ndf_id = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\ndf_test_id = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')\n\nsample_submission = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')\n\ndf_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True, on='TransactionID')\ndf_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True, on='TransactionID')\n\nprint(df_train.shape)\nprint(df_test.shape)\n\n# y_train = df_train['isFraud'].copy()\ndel df_trans, df_id, df_test_trans, df_test_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    \n    # Removing the extra storage space taken for the columns in the dataframe\n    for col in df.columns:\n#         print(col)\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n                    \n                    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: \n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n\nus_emails = ['gmail', 'net', 'edu']\n\n# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499#latest-579654\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    df_train[c + '_bin'] = df_train[c].map(emails)\n    df_test[c + '_bin'] = df_test[c].map(emails)\n    \n    df_train[c + '_suffix'] = df_train[c].map(lambda x: str(x).split('.')[-1])\n    df_test[c + '_suffix'] = df_test[c].map(lambda x: str(x).split('.')[-1])\n    \n    df_train[c + '_suffix'] = df_train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    df_test[c + '_suffix'] = df_test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in df_train.drop('isFraud', axis=1).columns:\n    if df_train[f].dtype=='object' or df_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_train[f].values) + list(df_test[f].values))\n        df_train[f] = lbl.transform(list(df_train[f].values))\n        df_test[f] = lbl.transform(list(df_test[f].values))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Trans_min_mean'] = df_train['TransactionAmt'] - df_train['TransactionAmt'].mean()\ndf_train['Trans_min_std'] = df_train['Trans_min_mean'] / df_train['TransactionAmt'].std()\ndf_test['Trans_min_mean'] = df_test['TransactionAmt'] - df_test['TransactionAmt'].mean()\ndf_test['Trans_min_std'] = df_test['Trans_min_mean'] / df_test['TransactionAmt'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TransactionAmt_to_mean_card1'] = df_train['TransactionAmt'] / df_train.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_mean_card4'] = df_train['TransactionAmt'] / df_train.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_std_card1'] = df_train['TransactionAmt'] / df_train.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_train['TransactionAmt_to_std_card4'] = df_train['TransactionAmt'] / df_train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ndf_test['TransactionAmt_to_mean_card1'] = df_test['TransactionAmt'] / df_test.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_mean_card4'] = df_test['TransactionAmt'] / df_test.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_std_card1'] = df_test['TransactionAmt'] / df_test.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_test['TransactionAmt_to_std_card4'] = df_test['TransactionAmt'] / df_test.groupby(['card4'])['TransactionAmt'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TransactionAmt'] = np.log(df_train['TransactionAmt'])\ndf_test['TransactionAmt'] = np.log(df_test['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['isFraud'] = 'test'\ndf = pd.concat([df_train, df_test], axis=0, sort=False )\ndf = df.reset_index()\ndf = df.drop('index', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def PCA_change(df, cols, n_components, prefix='PCA_', rand_seed=4):\n    pca = PCA(n_components=n_components, random_state=rand_seed)\n\n    principalComponents = pca.fit_transform(df[cols])\n\n    principalDf = pd.DataFrame(principalComponents)\n\n    df.drop(cols, axis=1, inplace=True)\n\n    principalDf.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n\n    df = pd.concat([df, principalDf], axis=1)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mas_v = df_train.columns[55:394]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\nfrom sklearn.decomposition import PCA\n\nfor col in mas_v:\n    df[col] = df[col].fillna((df[col].min() - 2))\n    df[col] = (minmax_scale(df[col], feature_range=(0,1)))\n\n    \ndf = PCA_change(df, mas_v, prefix='PCA_V_', n_components=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = reduce_mem_usage(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test = df[df['isFraud'] != 'test'], df[df['isFraud'] == 'test'].drop('isFraud', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'],axis=1)\ny_train = df_train.sort_values('TransactionDT')['isFraud'].astype(bool)\n\nX_test = df_test.sort_values('TransactionDT').drop(['TransactionDT'],axis=1)\ndel df_train\ndf_test = df_test[[\"TransactionDT\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport scipy as sp\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n## Hyperopt modules\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold,TimeSeriesSplit\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import plot_importance\nfrom sklearn.metrics import make_scorer\nfrom hyperopt import fmin, hp, tpe\nimport gc\n\nimport time\ndef objective(params):\n    time1 = time.time()\n    params = {\n        'max_depth': int(params['max_depth']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'subsample': \"{:.2f}\".format(params['subsample']),\n        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n        'reg_lambda': \"{:.3f}\".format(params['reg_lambda']),\n        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n        'num_leaves': '{:.3f}'.format(params['num_leaves']),\n        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n        'min_child_samples': '{:.3f}'.format(params['min_child_samples']),\n        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n    }\n\n    print(\"\\n############## New Run ################\")\n    print(f\"params = {params}\")\n    FOLDS = 7\n    count=1\n    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\n    tss = TimeSeriesSplit(n_splits=FOLDS)\n    y_preds = np.zeros(sample_submission.shape[0])\n    y_oof = np.zeros(X_train.shape[0])\n    score_mean = 0\n    for tr_idx, val_idx in tss.split(X_train, y_train):\n        clf = xgb.XGBClassifier(\n            n_estimators=600, random_state=4, verbose=True, \n            tree_method='gpu_hist', \n            **params\n        )\n\n        X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n        \n        clf.fit(X_tr, y_tr)\n        #y_pred_train = clf.predict_proba(X_vl)[:,1]\n        #print(y_pred_train)\n        score = make_scorer(roc_auc_score, needs_proba=True)(clf, X_vl, y_vl)\n        # plt.show()\n        score_mean += score\n        print(f'{count} CV - score: {round(score, 4)}')\n        count += 1\n    time2 = time.time() - time1\n    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n    gc.collect()\n    print(f'Mean ROC_AUC: {score_mean / FOLDS}')\n    fig, ax = plt.subplots(figsize=(20,20))\n    plot_importance(clf, ax=ax)\n    plt.show()\n    del X_tr, X_vl, y_tr, y_vl, score, clf\n    return (score_mean / FOLDS)\n\n\nspace={\n    'max_depth': hp.quniform('max_depth', 7, 23, 1),\n    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n    'gamma': hp.uniform('gamma', 0.01, .7),\n    'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9) \n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=10)\n\n# Print best parameters\nbest_params = space_eval(space, best)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}