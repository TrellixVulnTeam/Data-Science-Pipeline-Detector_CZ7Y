{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#train = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')[:200000]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loaddata():\n    from sklearn import preprocessing\n\n    train_tr = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv', index_col='TransactionID')\n    test_tr = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv', index_col='TransactionID')\n\n    train_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv', index_col='TransactionID')\n    test_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv', index_col='TransactionID')\n    print('files read and merging')\n    #sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n    \n    train = train_identity.merge(train_tr, how='left', left_index=True, right_index=True)\n    test = test_identity.merge(test_tr, how='left', left_index=True, right_index=True)\n    del train_tr, train_identity, test_tr, test_identity\n    \n    total=train.append(test)\n    del test\n    print('train,total',train.shape,total.shape)\n    y_label = train['isFraud']\n    del train\n    coltype=total.dtypes\n    # Drop target, fill in NaNs\n    print('labelencoding')\n    # Label Mean Encoding\n    #sparse>> total = pd.get_dummies(total, columns=total.columns, sparse=True).sparse.to_coo().tocsr()\n\n    for ci in total.columns:\n        if (coltype[ci]==\"object\"):\n            #print(ci)\n            codes=total[[ci,'isFraud']].groupby(ci).mean().sort_values(\"isFraud\")\n            codesdict=codes.isFraud.to_dict()\n            #print(codes)\n            total[ci]=total[ci].map(codesdict) #l_enc.transform(totaal[ci])            \n            \n    #fill target with 50%\n    total.drop('isFraud',axis=1)\n    total['isFraud']=np.concatenate((y_label,[0.5 for x in range(len(total)-len(y_label))]),axis=0)\n    return total.astype('float32').fillna(0),y_label\n\ntotal=loaddata()\nlabel=total[1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total[0].shape,label.shape\ntotal[0].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\nclass classGS():  \n      \n    #defining constructor  \n    def __init__(self, clf=[KNeighborsClassifier(10)],thres=0.1,probtrigger=False,ncomp=5,neighU=5,ncompU=5,midiU=0.3,veld='label',idvld='index',lentrain=30000,scale=True):  \n        self.clf2=clf\n        self.thres=thres\n        self.probtrigger=probtrigger\n        self.ncomp=ncomp\n        self.neighU=neighU\n        self.ncompU=ncompU\n        self.midiU=midiU\n        self.lentrain=lentrain\n        self.veld=veld\n        self.idvld=idvld\n        self.scale=scale\n        \n    def get_params(self, deep=True):\n        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n        return {\"clf\":self.clf2,'thres':self.thres,'probtrigger':self.probtrigger,'ncomp':self.ncomp,'neighU':self.neighU,'ncompU':self.ncompU,'midiU':self.midiU,'lentrain':self.lentrain}\n\n    def set_params(self, **parameters):\n        for parameter, value in parameters.items():\n            setattr(self, parameter, value)\n        return self\n    \n    def fit(self, e__,mtrain_):\n        # e__= pd.dataframe with veld and ivld as labels\n        # mtrain = pd.DataFrame() with veld as label field \n        from umap import UMAP\n        from sklearn.decomposition import PCA\n        from sklearn import preprocessing\n        min_max_scaler = preprocessing.MinMaxScaler()\n\n\n        #klasseerGS(e_,mtrain,mtest,veld,idvld,thres,probtrigger,ncomp,neighU,ncompU,midiU):\n        mtest=pd.DataFrame( e__[self.lentrain:].index,columns=[self.idvld] )\n        mtest[self.veld]=mtrain_[self.lentrain:][self.veld]\n        label = mtrain_[:self.lentrain][self.veld]\n        print('1:',e__.shape,mtrain_.shape,label.shape,self.lentrain,e__[self.lentrain:].shape)\n        if self.scale:\n            e__ = min_max_scaler.fit_transform(e__)\n            e__ = sigmoid(e__) \n        \n        e__ = PCA(n_components=self.ncomp).fit_transform(e__)\n        e__ = UMAP(n_neighbors=self.neighU,n_components=self.ncompU, min_dist=self.midiU,metric='minkowski').fit_transform(e__)\n        self.e__=e__\n        \n        pd.DataFrame(e__[:self.lentrain]).plot(x=0,y=1,c=mtrain_[:self.lentrain][self.veld]+1,kind='scatter',title='classesplot',colormap ='jet')\n        pd.DataFrame(e__).plot.scatter(x=0,y=1,c=['r' for x in range(self.lentrain)] +['g' for x in range(len(e__[self.lentrain:]))])   \n        print('2 Model with threshold',self.thres/1000,mtrain_[:self.lentrain].shape,e__.shape,self.ncomp,self.neighU,self.ncompU,self.midiU,)\n    \n        for clf2 in self.clf2:\n            #train\n            fit=clf2.fit(e__[:self.lentrain],label)\n            print(fit)\n\n            #if clf.__class__.__name__=='DecisionTreeClassifier':\n                #treeprint(clf)\n            pred=fit.predict(e__)\n            #Model.append(self.clf2.__class__.__name__)\n            #Accuracy.append(accuracy_score(mtrain[:self.lentrain][self.veld],pred))\n            #predict\n            print('3:',self.idvld,self.veld,len(mtest))\n            self.sub = pd.DataFrame({self.idvld: mtest[self.idvld],self.veld: pred[-len(mtest):]})\n            self.sub.plot(x=self.idvld,kind='kde',title=clf2.__class__.__name__ +str(( mtrain_[:self.lentrain][self.veld]==pred[:self.lentrain]).mean()) +'prcnt') \n            sub2=pd.DataFrame(pred,columns=[self.veld])\n\n            #estimate sample if  accuracy\n            if False:# self.veld in mtest.columns:\n                print( clf2.__class__.__name__ +str(round( accuracy_score(mtrain_[:self.lentrain][self.veld],pred[:self.lentrain]),2)*100 )+'prcnt accuracy versus unknown',(mtrain_[self.lentrain:][self.veld]==pred[self.lentrain:]).mean() )\n                from sklearn.metrics import confusion_matrix\n                print(confusion_matrix(mtrain_[self.lentrain:][self.veld],pred[self.lentrain:]))\n                #write results\n            if self.probtrigger:\n                pred_prob=fit.predict_proba(e__[-len(mtest):])\n                sub=pd.DataFrame(pred_prob)        \n        #defining class methods  \n            self.f1score=((mtrain_[self.veld]==pred[:len(mtrain_)]).mean())\n            print('4:f1',self.f1score)\n            self.treshold_=pred\n\n            print(self.sub.shape)\n        return self\n        \n    def _meaning(self, _e1):\n        # returns True/False according to fitted classifier\n        # notice underscore on the beginning\n        print('meaning')\n        return( True if _e1 >= self.treshold_ else True )\n\n    def predict(self, e__, mtrain_):\n        try:\n            getattr(self, \"treshold_\")\n        except AttributeError:\n            raise RuntimeError(\"You must train classifer before predicting data!\")\n        print('predict',e__.shape,mtrain_.shape)\n        return(self.treshold_)\n\n    def score(self, e__, mtrain_):\n        # counts number of values bigger than mean\n        print('score',self.e__.shape,mtrain_.shape,self.f1score)\n        return(self.f1score) \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    cGS=classGS(ncomp=30,midiU=0.1,ncompU=7,neighU=5,lentrain=144233,veld='isFraud',scale=True)\n    result=cGS.fit(total[0].drop('isFraud',axis=1).reset_index(),pd.DataFrame( total[0]['isFraud'][:144233] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import division, print_function\n\nimport numpy as np\n\ntry:\n    from pylab import plt\nexcept ImportError:\n    print('Unable to import pylab. R_pca.plot_fit() will not work.')\n\ntry:\n    # Python 2: 'xrange' is the iterative version\n    range = xrange\nexcept NameError:\n    # Python 3: 'range' is iterative - no need for 'xrange'\n    pass\n\n\nclass R_pca:\n\n    def __init__(self, D, mu=None, lmbda=None):\n        self.D = D\n        self.S = np.zeros(self.D.shape)\n        self.Y = np.zeros(self.D.shape)\n\n        if mu:\n            self.mu = mu\n        else:\n            self.mu = np.prod(self.D.shape) / (4 * self.frobenius_norm(self.D))\n\n        self.mu_inv = 1 / self.mu\n\n        if lmbda:\n            self.lmbda = lmbda\n        else:\n            self.lmbda = 1 / np.sqrt(np.max(self.D.shape))\n\n    @staticmethod\n    def frobenius_norm(M):\n        return np.linalg.norm(M, ord='fro')\n\n    @staticmethod\n    def shrink(M, tau):\n        return np.sign(M) * np.maximum((np.abs(M) - tau), np.zeros(M.shape))\n\n    def svd_threshold(self, M, tau):\n        U, S, V = np.linalg.svd(M, full_matrices=False)\n        return np.dot(U, np.dot(np.diag(self.shrink(S, tau)), V))\n\n    def fit(self, tol=None, max_iter=1000, iter_print=100):\n        iter = 0\n        err = np.Inf\n        Sk = self.S\n        Yk = self.Y\n        Lk = np.zeros(self.D.shape)\n\n        if tol:\n            _tol = tol\n        else:\n            _tol = 1E-7 * self.frobenius_norm(self.D)\n\n        while (err > _tol) and iter < max_iter:\n            Lk = self.svd_threshold(\n                self.D - Sk + self.mu_inv * Yk, self.mu_inv)\n            Sk = self.shrink(\n                self.D - Lk + (self.mu_inv * Yk), self.mu_inv * self.lmbda)\n            Yk = Yk + self.mu * (self.D - Lk - Sk)\n            err = self.frobenius_norm(self.D - Lk - Sk)\n            iter += 1\n            if (iter % iter_print) == 0 or iter == 1 or iter > max_iter or err <= _tol:\n                print('iteration: {0}, error: {1}'.format(iter, err))\n\n        self.L = Lk\n        self.S = Sk\n        return Lk, Sk\n\n    def plot_fit(self, size=None, tol=0.1, axis_on=True):\n\n        n, d = self.D.shape\n\n        if size:\n            nrows, ncols = size\n        else:\n            sq = np.ceil(np.sqrt(n))\n            nrows = int(sq)\n            ncols = int(sq)\n        nrows=10\n        ncols =1\n        ymin = np.nanmin(self.D)\n        ymax = np.nanmax(self.D)\n        print('ymin: {0}, ymax: {1}'.format(ymin, ymax))\n\n        numplots = np.min([n, nrows * ncols])\n       \n        plt.figure()\n\n        for n in range(numplots):\n            plt.subplot(nrows, ncols, n + 1)\n            plt.ylim((ymin - tol, ymax + tol))\n            plt.plot(self.L[n, :] + self.S[n, :], 'r')\n            plt.plot(self.L[n, :], 'b')\n            if not axis_on:\n                plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use R_pca to estimate the degraded data as L + S, where L is low rank, and S is sparse\nrpca = R_pca(total[0].values)\nL, S = rpca.fit(max_iter=1000, iter_print=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total[0][total[0].isFraud==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Spd=pd.DataFrame(S[:,:-1])\nSpd['isFraud']=total[0]['isFraud'].values\n\ncGS=classGS(ncomp=30,midiU=0.1,ncompU=7,neighU=5,lentrain=144233,veld='isFraud',scale=True)\nresult=cGS.fit(Spd.drop('isFraud',axis=1).reset_index(),pd.DataFrame( total[0]['isFraud'][:144233] ))\npredi=result.predict(Spd.drop('isFraud',axis=1).reset_index(),pd.DataFrame( total[0]['isFraud'][:144233] ) )\npredi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_identity['isFraud']=predi[144233:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tr = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmit=test_tr[['TransactionDT']].merge(test_identity[['isFraud']], how='left', left_index=True, right_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm = pd.read_csv('../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit[['isFraud']].reset_index().fillna(0).to_csv('sample_submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}