{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Initialization Setting","metadata":{}},{"cell_type":"markdown","source":"- 문제 개요: 카드 기록을 활용한 사기 거래 탐지\n- binary classification 문제로, 온라인 거래가 사기일 확률을 예측하는 것이 목적임\n- 대부분 column이 비식별화(Marsking)되어 있음\n- 결측치가 많음\n- 클래스가 불균형함 (class imbalance 문제)","metadata":{}},{"cell_type":"markdown","source":"## Library Setting","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Visualization Library\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nplt.rcParams['font.size'] = 15\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.style.use('ggplot')\ncolor_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]\n#\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n#ML modeling method\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport catboost as catb\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gc\ngc.enable()\n\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:08:12.021495Z","iopub.execute_input":"2021-10-05T14:08:12.021784Z","iopub.status.idle":"2021-10-05T14:08:15.364468Z","shell.execute_reply.started":"2021-10-05T14:08:12.021753Z","shell.execute_reply":"2021-10-05T14:08:15.36374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard plotly imports\n# %pip install chart_studio\n# import chart_studio.plotly as py\n# import plotly.graph_objs as go\n# import plotly.tools as tls\n# from plotly.offline import iplot, init_notebook_mode\n# import cufflinks\n# import cufflinks as cf\n# import plotly.figure_factory as ff\n\n# #Using plotly + cufflinks in offline mode\n# init_notebook_mode(connected=True)\n# cufflinks.go_offline(connected=True)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-10-05T14:08:15.365965Z","iopub.execute_input":"2021-10-05T14:08:15.366194Z","iopub.status.idle":"2021-10-05T14:08:15.37265Z","shell.execute_reply.started":"2021-10-05T14:08:15.366162Z","shell.execute_reply":"2021-10-05T14:08:15.372031Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Hyperparameter Setting","metadata":{}},{"cell_type":"code","source":"#Loading input data Part\nis_index_TransactionID = False\n#========================================================\n#EDA Part\n\n#========================================================\n#Featrue Engineering Part\n\n#Label Encoding \n#one-hot-encoding/ labelencoderlibrary/ label-encoding\nlabel_encoding_option = 'LabelEncoderLibrary'\n#========================================================\n#Modeling Part\n#1) Dataset Spliting Method for Validation (Just split validation data vs Cross Validation)\n\n#2) Oversmpling of Target data\n\n##2-1) Oversmpling Method (SMOTE vs Borderline SMOTE vs Adaptive Synthetic Sampling(ADASYN))\n\n#3 Modeling Method (Random Forest vs XGBoost vs LightGBM vs CatBoost)\n\n#3-1) Using Ensemble of Ensemble Method (Bagging vs RandomForest vs or not)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:08:15.373811Z","iopub.execute_input":"2021-10-05T14:08:15.374612Z","iopub.status.idle":"2021-10-05T14:08:15.382271Z","shell.execute_reply.started":"2021-10-05T14:08:15.374576Z","shell.execute_reply":"2021-10-05T14:08:15.381611Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load Data","metadata":{}},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"data_path = \"../input/ieee-fraud-detection/\"\n\ndef load_data (data_path, is_index_TransactionID):\n    if is_index_TransactionID:\n        train_identity = pd.read_csv(data_path + \"train_identity.csv\",index_col='TransactionID')\n        test_identity = pd.read_csv(data_path + \"test_identity.csv\",index_col='TransactionID')\n        train_transaction = pd.read_csv(data_path + \"train_transaction.csv\",index_col='TransactionID')\n        test_transaction = pd.read_csv(data_path + \"test_transaction.csv\",index_col='TransactionID')\n    else:\n        train_identity = pd.read_csv(data_path + \"train_identity.csv\")\n        test_identity = pd.read_csv(data_path + \"test_identity.csv\")\n        train_transaction = pd.read_csv(data_path + \"train_transaction.csv\")\n        test_transaction = pd.read_csv(data_path + \"test_transaction.csv\")\n        \n    return train_identity, test_identity, train_transaction, test_transaction","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:08:15.38556Z","iopub.execute_input":"2021-10-05T14:08:15.385765Z","iopub.status.idle":"2021-10-05T14:08:15.396013Z","shell.execute_reply.started":"2021-10-05T14:08:15.385743Z","shell.execute_reply":"2021-10-05T14:08:15.395328Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_identity, test_identity, train_transaction, test_transaction = load_data(data_path, is_index_TransactionID)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:08:15.399085Z","iopub.execute_input":"2021-10-05T14:08:15.399281Z","iopub.status.idle":"2021-10-05T14:09:07.266263Z","shell.execute_reply.started":"2021-10-05T14:08:15.39926Z","shell.execute_reply":"2021-10-05T14:09:07.265534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA 하기전에 info()함수와 head()함수를 통해 데이터에 대해 간단히 살펴본다\n\n#### train_transaction Dataset","metadata":{}},{"cell_type":"code","source":"train_transaction.info()\ntrain_transaction.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:09:07.267487Z","iopub.execute_input":"2021-10-05T14:09:07.267761Z","iopub.status.idle":"2021-10-05T14:09:07.331734Z","shell.execute_reply.started":"2021-10-05T14:09:07.267727Z","shell.execute_reply":"2021-10-05T14:09:07.330964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 590540 개의 data와 394개의 feature가 있음(설명변수 + 반응변수(target))\n- Data type이 object(str)인 feature가 14개 있음(Categorical Variable, 범주형 변수가 총 14개) -> label encoding 필요함\n- 데이터를 1.7GB이상 사용함 -> 각 feature의 범위에 맞게 데이터 타입을 바꿔 데이터 사용량을 낮출 필요가 있음\n- 많은 feature들이 식별이 불가능하고, 결측치(NaN)값이 많이 보임","metadata":{}},{"cell_type":"markdown","source":"#### test_transaction Dataset","metadata":{}},{"cell_type":"code","source":"test_transaction.info()\ntest_transaction.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:09:07.332915Z","iopub.execute_input":"2021-10-05T14:09:07.333226Z","iopub.status.idle":"2021-10-05T14:09:07.383829Z","shell.execute_reply.started":"2021-10-05T14:09:07.333191Z","shell.execute_reply":"2021-10-05T14:09:07.383094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 506691 개의 data와 393개의 feature가 있음(Target feature 없음)\n- Data type이 object(str)인 feature가 train_transaction과 동일하게 14개 있음 -> label encoding 필요함\n- 데이터를 1.5GB이상 사용함 -> 각 feature의 범위에 맞게 데이터 타입을 바꿔 데이터 사용량을 줄일 필요가 있음\n- 많은 feature들이 식별이 불가능하고, 결측치(NaN)값이 많이 보임","metadata":{}},{"cell_type":"markdown","source":"#### train_identity Dataset","metadata":{}},{"cell_type":"code","source":"train_identity.info()\ntrain_identity.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:09:07.384977Z","iopub.execute_input":"2021-10-05T14:09:07.385208Z","iopub.status.idle":"2021-10-05T14:09:07.614047Z","shell.execute_reply.started":"2021-10-05T14:09:07.385185Z","shell.execute_reply":"2021-10-05T14:09:07.613322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 144233 개의 data와 41개의 feature가 있음\n- Data type이 object(str)인 17개 있음 -> label encoding 필요함\n- 데이터를 약 45.1MB 사용함\n- 많은 feature들이 식별이 불가능하고, info함수의 Non-Null Count를 보면 결측치(NaN)값이 데이터 개수와 많이 차이나는 column들이 보임","metadata":{}},{"cell_type":"markdown","source":"#### test_identity Dataset","metadata":{}},{"cell_type":"code","source":"test_identity.info()\ntest_identity.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:09:07.615252Z","iopub.execute_input":"2021-10-05T14:09:07.616843Z","iopub.status.idle":"2021-10-05T14:09:07.83631Z","shell.execute_reply.started":"2021-10-05T14:09:07.616815Z","shell.execute_reply":"2021-10-05T14:09:07.835514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 141907 개의 data와 41개의 feature가 있음\n- Data type이 object(str)인 17개 있음 -> label encoding 필요함\n- 데이터를 약 44.4MB 사용함\n- 많은 feature들이 식별이 불가능하고, info함수의 Non-Null Count를 보면 결측치(NaN)값이 데이터 개수와 많이 차이나는 column들이 보임\n- id column의 id와 숫자사이의 연결문자가 train_identity가 \"_\" 인 것과 달리, test_identity는 \"-\"임","metadata":{}},{"cell_type":"markdown","source":"## Reduce Memory Usage\n\n- transaction의 데이터의 크기가 커서 메모리 사용량이 크므로 각 데이터에서 사용하는 숫자의 범위에 맞게 줄일 필요가 있음\n- 따라서 모든 Dataset에 대해서 각 데이터에서 사용하는 숫자의 범위에 맞게 Data type을 변경해주는 과정을 거침","metadata":{}},{"cell_type":"code","source":"## Memory Reducer Function\n# :df pandas dataframe to reduce size   # type: pd.DataFrame()\ndef reduce_memory_usage(df):\n    # 숫자 데이터 형 리스트\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    # 처음 메모리 사용량\n    start_memory = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        # feature(column)의 데이터 형이 numerics안에 있으면\n        if col_type in numerics:\n            #해당 feature의 최소값, 최대값 찾기 \n            c_min = df[col].min()\n            c_max = df[col].max()\n            # int 형인 경우\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            # float형인 경우\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n                    \n    #줄인 메모리 사용량\n    end_memory = df.memory_usage().sum() / 1024**2\n    print('Memory usage decreased from {:5.2f}MB to {:5.2f}MB ({:.1f}% reduction)'.format(start_memory,end_memory, ((start_memory-end_memory)/start_memory)*100))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:09:07.83958Z","iopub.execute_input":"2021-10-05T14:09:07.840016Z","iopub.status.idle":"2021-10-05T14:09:07.853458Z","shell.execute_reply.started":"2021-10-05T14:09:07.839981Z","shell.execute_reply":"2021-10-05T14:09:07.852401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for df in [train_identity, test_identity, train_transaction, test_transaction]:\n    reduce_memory_usage(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:09:07.85506Z","iopub.execute_input":"2021-10-05T14:09:07.855341Z","iopub.status.idle":"2021-10-05T14:12:10.154527Z","shell.execute_reply.started":"2021-10-05T14:09:07.855307Z","shell.execute_reply":"2021-10-05T14:12:10.15378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA\n- 데이터 전반에 대한 탐색\n- Target feature의 class의 분포(비율) 확인(Class Imbalance 문제여부 확인)\n- Feature별 연속형 / 범주형 여부, 결측치, Unique값 일부와 개수 확인\n- 범주형 변수(Discrete or Categorical Features) 탐색\n- 연속형 변수(Continuous or Numerical Features) 탐색","metadata":{}},{"cell_type":"markdown","source":"## 2.1 About Data and features","metadata":{}},{"cell_type":"markdown","source":"- 'TransactionID', 'TransactionDT'변수는 삭제\n- X: df에서 isFraud가 제거된 DF\n- Y: df에서 isFraud column만 가져온 Series","metadata":{}},{"cell_type":"markdown","source":"train.csv: 모델 학습용 데이터 / test.csv: 모델 평가용 데이터 \n - TransactionID: 거래 ID(비식별화)\n - TransactionDT: 거래 시각(비식별화)\n - TransactionAmt: 거래 금액(단위: US 달러)\n - ProductCD: 상품 또는 제품의 코드\n - addr1 - 2: 주소정보\n - dist: 거리정보\n - card1 - card6: 카드 관련 정보(비식별화)\n - P_emaildomain, R_emaildomain: 이메일 정보\n - C1 - C14: Counting 관련 정보(비식별화)\n - D1 - D15: 거래관련 시간 정보(비식별화)\n - M1 - M9: 기존 거래와의 매칭 정보 (일치 여부정보)\n - V1 - V339: 여러 정보를 포함한 engineered된 정보\n - isFraud: 사기 거래 여부(Target column / Label)\n \n\nCategorical Features\n- ProductCD\n- card4, card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9\n- DeviceType\n- DeviceInfo\n- id_12 - id_38\n ","metadata":{}},{"cell_type":"markdown","source":"### DF.shape 속성을 통해 다시 한 번 각 데이터 셋에 대한 데이터 개수(row수)와 feature 수(column 수) 확인","metadata":{}},{"cell_type":"code","source":"print(f'train_transaction shape is {train_transaction.shape}')\nprint(f'test_transaction shape is {test_transaction.shape}')\nprint(f'train_identity shape is {train_identity.shape}')\nprint(f'test_identity shape is {test_identity.shape}')      ","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:10.155884Z","iopub.execute_input":"2021-10-05T14:12:10.156315Z","iopub.status.idle":"2021-10-05T14:12:10.16258Z","shell.execute_reply.started":"2021-10-05T14:12:10.156278Z","shell.execute_reply":"2021-10-05T14:12:10.161922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- train데이터의 거래데이터 샘플 수가 590540개이고, train데이터의 identity데이터 샘풀 수가 144233개이므로 train data는 144233개의 계정들의 590540번의 거래 데이터라고 이해할 수 있음\n- test데이터의 거래데이터 샘플 수가 506691개이고, train데이터의 identity데이터 샘풀 수가 141907개이므로 train data는 141907개의 계정들의 506691번의 거래 데이터라고 이해할 수 있음","metadata":{}},{"cell_type":"markdown","source":"### 거래 시각 정보 feature인 TransactionDT에 따른 train_transaction과 test_transaction 데이터의 거래횟수 분포확인","metadata":{}},{"cell_type":"code","source":"train_transaction['TransactionDT'].plot(kind='hist', figsize=(15,5), bins=100, label='Train', title='Train vs. Test TransactionDT distribution')\ntest_transaction['TransactionDT'].plot(kind='hist', label='test', bins=100)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:10.163819Z","iopub.execute_input":"2021-10-05T14:12:10.164238Z","iopub.status.idle":"2021-10-05T14:12:10.945763Z","shell.execute_reply.started":"2021-10-05T14:12:10.164198Z","shell.execute_reply":"2021-10-05T14:12:10.944982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 거래 시각 정보 feature인 TransactionDT에 따른 데이터 분포를 확인해본 결과, \n    - train data와 test data가 거래 시각에 대해 데이터들이 서로 섞여 있지 않음\n    - 과거의 일정기간동안 이루어진 거래데이터가 train데이터로 설정됨\n    - train data의 거래 이후 일정 기간이 지난 뒤, 그 이후의 거래 데이터가 tset data로 설정되어 있음을 확인할 수 있음\n\n- 하지만 train data와 test data가 시간의 흐름에 따라 설정되어 있다고 하더라도 이 정보는 Target을 예측하는데 큰 영향이 없을 것으로 판단됨\n    - 해당 문제는 사기거래여부를 예측하는 Binary Classification 문제이므로 어떤 수치값을 예측하는 Regression문제가 아니기 때문임\n    - 따라서 각각의 거래 데이터를 독립적으로 봐야함\n    - 시간 관련 feature에 대해서는 시간의 영향을 없애도록 전처리가 필요할 것으로 판단됨","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Target feature의 class의 분포(비율)를 확인(Class Imbalance 문제여부 확인)","metadata":{}},{"cell_type":"code","source":"target = train_transaction['isFraud']\ntarget.value_counts(normalize = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:10.947561Z","iopub.execute_input":"2021-10-05T14:12:10.948226Z","iopub.status.idle":"2021-10-05T14:12:10.963742Z","shell.execute_reply.started":"2021-10-05T14:12:10.948188Z","shell.execute_reply":"2021-10-05T14:12:10.962688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:10.964829Z","iopub.execute_input":"2021-10-05T14:12:10.96575Z","iopub.status.idle":"2021-10-05T14:12:10.980424Z","shell.execute_reply.started":"2021-10-05T14:12:10.965715Z","shell.execute_reply":"2021-10-05T14:12:10.979723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 종속 변수의 분포 확인(Class imbalance 확인)\nfrom collections import Counter\ntarget_dist_data = Counter(target)\nprint('Distribution of transaction data by target feature =', target_dist_data)\nprint('\\n')\nprint('Ratio of fraud transaction data is %.1f%%'%(target_dist_data[0] / len(train_transaction['isFraud'])*100))\nprint('Ratio of non-fraud transaction data is %.1f%%'%(target_dist_data[1]/ len(train_transaction['isFraud'])*100))\n\ndel target, target_dist_data\nx = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:10.98197Z","iopub.execute_input":"2021-10-05T14:12:10.982238Z","iopub.status.idle":"2021-10-05T14:12:11.209756Z","shell.execute_reply.started":"2021-10-05T14:12:10.982204Z","shell.execute_reply":"2021-10-05T14:12:11.208911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"탐색 내용 정리\n- 사기 거래가 아닌 거래가 전체 거래의 약 96.5%를 차지함 \n- 본 문제는 예측값의 Class 비율이 서로 차이가 많이 나는(불균형한) class imbalance binary classification problem임","metadata":{}},{"cell_type":"markdown","source":"## 2.3 Feature별 연속형 / 범주형 여부, 결측치, Unique값 일부와 개수 확인","metadata":{}},{"cell_type":"code","source":"for column in train_transaction.drop('isFraud', axis=1).columns:\n    col_Series = train_transaction[column]\n    print(f'{column}: DataType: {col_Series.dtype}, 결측치 개수: {col_Series.isnull().sum()}, Unique값 개수: {col_Series.nunique()}, Unique값 일부: {col_Series.unique()[:5]}')\nfor column in train_identity.columns:\n    col_Series = train_identity[column]\n    print(f'{column}: DataType: {col_Series.dtype}, 결측치 개수: {col_Series.isnull().sum()}, Unique값 개수: {col_Series.nunique()}, Unique값 일부: {col_Series.unique()[:5]}')\n    \ndel col_Series\nx= gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:11.211376Z","iopub.execute_input":"2021-10-05T14:12:11.211722Z","iopub.status.idle":"2021-10-05T14:12:23.902945Z","shell.execute_reply.started":"2021-10-05T14:12:11.211687Z","shell.execute_reply":"2021-10-05T14:12:23.901516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"탐색 내용 정리\n- TransactionAmt는 히스토그램 등을 통해 확인한 결과 연속형 변수가 확실함\n- ProductCD, card4, card6은 범주형 변수가 확실함(결측치가 존재함)\n- P_emaildomain, R_emaildomain은 구매자의 이메일 도메인으로 보이며, 두 feature는 서로 관계가 있을 것으로 보임\n- card1, card2, card3, card5는 히스토그램 등으로 확인해본 결과, 연속형 변수가 확실함\n- 많은 feature들에서 많은 결측치가 포함되어 있음 -> 결측치의 분포를 확인할 필요가 있음\n- C3을 제외한 C1 ~ C14는 모두 연속형 변수인 것으로 보이며, 정보가 Masking되어있어 대략적인 의미라도 추측해야 함\n- C3는 float형이지만 전체 Unique값 개수가 27개이므로 범주형으로 봐야할 것 같음\n- M1 ~ M9는 매칭 정보이며, 전부 범주형 범주임 (T는 일치함, F는 일치하지 않는다는 의미로 보이며, 모두 결측치가 존재함)","metadata":{}},{"cell_type":"markdown","source":"## 2.4 범주형 변수(Categorical feature) 탐색\n- 탐색하기 위해서 결측치를 임시로 문자로 변환함\n- barplot을 사용하여 변수(feature)별 분포 확인함\n- groupby를 사용하여 변수와 특징간의 관계를 확인함","metadata":{}},{"cell_type":"markdown","source":"### ProductCD feature","metadata":{}},{"cell_type":"code","source":"#결측치 개수 확인\ntrain_transaction.ProductCD.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:23.904246Z","iopub.execute_input":"2021-10-05T14:12:23.9045Z","iopub.status.idle":"2021-10-05T14:12:23.960821Z","shell.execute_reply.started":"2021-10-05T14:12:23.904468Z","shell.execute_reply":"2021-10-05T14:12:23.959964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 결측치가 없으므로, 문자로 변환할 필요가 없음","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n# ProductCD의 거래 비율에 대한 bar plot 생성\ntrain_transaction.ProductCD.value_counts(normalize=True).plot(kind='bar',ax = ax1)\n# ProductCD별 사기 거래 비율에 대한 bar plot 생성\ntrain_transaction.groupby('ProductCD').isFraud.mean().plot(kind='bar',ax=ax2)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:23.962287Z","iopub.execute_input":"2021-10-05T14:12:23.96259Z","iopub.status.idle":"2021-10-05T14:12:24.474405Z","shell.execute_reply.started":"2021-10-05T14:12:23.962556Z","shell.execute_reply":"2021-10-05T14:12:24.4736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transaction.groupby('ProductCD').isFraud.mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:24.475785Z","iopub.execute_input":"2021-10-05T14:12:24.476042Z","iopub.status.idle":"2021-10-05T14:12:24.528123Z","shell.execute_reply.started":"2021-10-05T14:12:24.476008Z","shell.execute_reply":"2021-10-05T14:12:24.52726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 상품별로 차이가 존재한다는 것을 확인함\n    - W 상품이 0.7이상으로 가장 높은 거래 비율을 차지하고 S 상품이 1%에 가까운 가장 낮은 거래 비율을 보여줌\n    - 사기거래 비율을 보면 두 번째로 높은 거래 비중을 차지하는 C 상품이 약 11.7%로 가장 높은 사기 거래 비율을 보여줌\n    - W상품은 가장 높은 거래 비율을 차지하고 있지만 해당 상품의 사기거래 비율은 약 2% 5개 제품중 가장 적은 사기 거래 비율을 차지함\n    - 전체 사기거래의 비율이 약 3.5%인데 C 상품과 H 상품, S 상품은 각각 11.7%와 4.8%, 5.9%로 전체 비율에 비해 높고 W 상품은 2%로 낮음\n- ProductCD feature는 Unique값의 수가 적기 때문에 one-hot encoding이나 label encodeing을 하기로 결정함","metadata":{}},{"cell_type":"markdown","source":"### card4 feature","metadata":{}},{"cell_type":"code","source":"#결측치 개수 확인\nprint(train_transaction.card4.isnull().sum()) # 결측치 1577개 \nprint(train_transaction.card4.isnull().sum() / train_transaction.shape[0]) #결측치 비율 0.3% 밖에 되지 않음","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:34:39.540788Z","iopub.execute_input":"2021-10-05T14:34:39.541489Z","iopub.status.idle":"2021-10-05T14:34:39.657608Z","shell.execute_reply.started":"2021-10-05T14:34:39.541454Z","shell.execute_reply":"2021-10-05T14:34:39.656763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 결측치를 전부 최빈값으로 대체해도 전체 비율에 크게 영향을 주지 않을 것으로 판단됨\n- 이제 card 4의 결측치데이터가 사기거래 여부에 대해 유의미한지 판단해야함","metadata":{}},{"cell_type":"code","source":"# 결측치에 해당하는 데이터의 사기러래 비율을 확인하고 만약 결측치 데이터가 사거거래 여부에 유의미한 비율을 차지한다면 \n# 결측치를 다른 값으로 채우면 안 되며, 결측치 여부로 새로운 변수를 생성할 수 있음\n# 하지만 결측치 데이터가 사기거래 여부에 별 영향이 없다면 결측치를 최빈값으로 대체해도 문제없다고 판단가능함\ncard4_df = train_transaction[['isFraud','card4']]\n#결측치를 나타내는 feature 생성\ncard4_df['NA_card4'] = card4_df.card4.isnull().astype(int)\nprint(card4_df.groupby('NA_card4')['isFraud'].mean())\n\ndel card4_df\nx= gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:24.764688Z","iopub.execute_input":"2021-10-05T14:12:24.764941Z","iopub.status.idle":"2021-10-05T14:12:24.960853Z","shell.execute_reply.started":"2021-10-05T14:12:24.76491Z","shell.execute_reply":"2021-10-05T14:12:24.960032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 결측치여부에 따른 사기거래 비율을 보게 되면 결측치가 아닐 때 사기거래 비율이 3.5% / 결측치일 때 사기거래 비율이 2.6%로 큰 비율 차이가 없다고 판단함\n- 따라서 결측치를 최빈값으로 대체하기로 결정함","metadata":{}},{"cell_type":"code","source":"#value_counts에 대한 barplot 생성\ntrain_transaction.card4.value_counts(normalize = True).plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:24.962228Z","iopub.execute_input":"2021-10-05T14:12:24.962563Z","iopub.status.idle":"2021-10-05T14:12:25.302503Z","shell.execute_reply.started":"2021-10-05T14:12:24.962526Z","shell.execute_reply":"2021-10-05T14:12:25.301866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- visa와 mastercard가 매우 높은 비율(95%이상)을 차지하며, american express와 discover는 거의 없음","metadata":{}},{"cell_type":"code","source":"#card4 feature에 대해 사기거래 비율을 계산\ntrain_transaction.groupby('card4')['isFraud'].mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:25.303645Z","iopub.execute_input":"2021-10-05T14:12:25.30391Z","iopub.status.idle":"2021-10-05T14:12:25.387358Z","shell.execute_reply.started":"2021-10-05T14:12:25.30387Z","shell.execute_reply":"2021-10-05T14:12:25.386512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 거래의 대다수를 차지하는 visa와 mastercard의 비율 값이 약 0.034로 유사함\n- discover의 사기거래의 비율이 약 0.077로 전체의 약 8%이지만 discover의 거래횟수 자체가 워낙 작기 때문에 사기거래에 영향을 주는 요소라고 판단하기 어려움","metadata":{}},{"cell_type":"markdown","source":"### card6 feature","metadata":{}},{"cell_type":"code","source":"#결측치 개수 확인\nprint(train_transaction.card6.isnull().sum()) # 결측치 1571개 \nprint(train_transaction.card6.isnull().sum() / train_transaction.shape[0]) #결측치 비율 0.3% 밖에 되지 않음","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:33:33.463111Z","iopub.execute_input":"2021-10-05T14:33:33.463428Z","iopub.status.idle":"2021-10-05T14:33:33.575646Z","shell.execute_reply.started":"2021-10-05T14:33:33.463393Z","shell.execute_reply":"2021-10-05T14:33:33.574889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 결측치를 전부 최빈값으로 대체해도 전체 비율에 크게 영향을 주지 않을 것으로 판단됨\n- 이제 card 6의 결측치데이터가 사기거래 여부에 대해 유의미한지 판단해야함","metadata":{}},{"cell_type":"code","source":"# 결측치에 해당하는 데이터의 사기러래 비율을 확인하고 만약 결측치 데이터가 사거거래 여부에 유의미한 비율을 차지한다면 \n# 결측치를 다른 값으로 채우면 안 되며, 결측치 여부로 새로운 변수를 생성할 수 있음\n# 하지만 결측치 데이터가 사기거래 여부에 별 영향이 없다면 결측치를 최빈값으로 대체해도 문제없다고 판단가능함\ncard6_df = train_transaction[['isFraud','card6']]\n#결측치를 나타내는 feature 생성\ncard6_df['NA_card6'] = card6_df.card6.isnull().astype(int)\nprint(card6_df.groupby('NA_card6')['isFraud'].mean())\n\ndel card6_df\nx= gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:25.622917Z","iopub.execute_input":"2021-10-05T14:12:25.623521Z","iopub.status.idle":"2021-10-05T14:12:25.822002Z","shell.execute_reply.started":"2021-10-05T14:12:25.623483Z","shell.execute_reply":"2021-10-05T14:12:25.821126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 결측치여부에 따른 사기거래 비율을 보게 되면 결측치가 아닐 때 사기거래 비율이 3.5% / 결측치일 때 사기거래 비율이 2.5%로 큰 비율 차이가 없다고 판단함\n- 따라서 결측치를 최빈값으로 대체하기로 결정함","metadata":{}},{"cell_type":"code","source":"#value_counts에 대한 barplot 생성\ntrain_transaction.card6.value_counts(normalize = True).plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:25.823478Z","iopub.execute_input":"2021-10-05T14:12:25.823761Z","iopub.status.idle":"2021-10-05T14:12:26.161729Z","shell.execute_reply.started":"2021-10-05T14:12:25.823727Z","shell.execute_reply":"2021-10-05T14:12:26.161063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- debit와 credit이 대다수를 차지함\n- debit or credit, charge card는 그래프에서 눈으로 확인이 불가능한 수준임\n- 따라서 실제 수치값(비율)을 출력해봤음","metadata":{}},{"cell_type":"code","source":"print(train_transaction.card6.value_counts(normalize = True))\nprint('\\n')\nprint(train_transaction.card6.value_counts(normalize = False))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:14:40.106924Z","iopub.execute_input":"2021-10-05T14:14:40.107194Z","iopub.status.idle":"2021-10-05T14:14:40.363746Z","shell.execute_reply.started":"2021-10-05T14:14:40.107166Z","shell.execute_reply":"2021-10-05T14:14:40.362586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 실제로 수치적으로 debit or credit, charge card는 각각 샘플의 수가 30개, 15개로 빈도가 매우 적고 전체 비율도 0%에 가까움","metadata":{}},{"cell_type":"code","source":"#각 항목별 사기거래의 비율을 계산\ntrain_transaction.groupby('card6')['isFraud'].mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:12:26.43173Z","iopub.execute_input":"2021-10-05T14:12:26.432037Z","iopub.status.idle":"2021-10-05T14:12:26.523632Z","shell.execute_reply.started":"2021-10-05T14:12:26.431999Z","shell.execute_reply":"2021-10-05T14:12:26.522691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- credit과 debit 사이에 차이가 존재함\n- debit or credit과 charge card는 사기거래일 확률이 0%임\n    - 하지만 전체 거래 빈도 자체가 너무 적어서 없는지, 실제로 없는 것인지 알 수가 없음(빈도가 적어서일 확률이 높음)\n    - 따라서 0%라고 하여도 큰 의미가 없음\n- card6 feature는 두 범주가 사기 거래인 데이터가 없으므로 사기거래 데이터가 있는 credit인지 아닌지(debit인지)여부를 나타내는 binary 변수로 변환","metadata":{}},{"cell_type":"markdown","source":"### P_emaildomain과 R_emaildomain feature\n- 이전 탐색에서 두 feature 각각의 Unique값의 개수가 59, 60임을 확인함\n- 또한, 결측치가 많았는데 email이 결측치라는 것은 이용자가 메일츨 기입하지 않았다는 의미로 해셕할 수 있음\n- 메일을 적지 않았다는 의미에서 결측치와 사기거래여부와의 관계성을 살펴볼 필요가 있음\n- feature의 이름에서 두 feature간의 관계가 있을 것이라고 추축이 가능함","metadata":{}},{"cell_type":"code","source":"#결측치 개수 확인\nprint('P_emaildomain missing values')\nP_missing_count = train_transaction.P_emaildomain.isnull().sum()\nprint(P_missing_count) # 결측치 94456개 \nprint(P_missing_count / train_transaction.shape[0]) #결측치 비율 약 16%\nprint('\\n')\nprint('R_emaildomain missing values')\nR_missing_count = train_transaction.R_emaildomain.isnull().sum()\nprint(R_missing_count) # 결측치 453249개 \nprint(R_missing_count / train_transaction.shape[0]) #결측치 비율 무려 약 77%\n\ndel P_missing_count, R_missing_count\nx = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:33:17.6807Z","iopub.execute_input":"2021-10-05T14:33:17.682877Z","iopub.status.idle":"2021-10-05T14:33:17.972633Z","shell.execute_reply.started":"2021-10-05T14:33:17.682831Z","shell.execute_reply":"2021-10-05T14:33:17.971986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 두 feature 모두 결측치의 비율이 상당히 높은데 특히 R_emaildomain의 결측치 비율이 77%나 되어 최빈값으로 채우는 것은 해당 feature의 분포에 영향을 줄 수 있을 것이라고 판단됨\n- 결측치데이터가 사기거래 여부에 대해 어떤 유의미한 점이 있는지 판단해야함","metadata":{}},{"cell_type":"code","source":"emaildomain_df = train_transaction[['isFraud','P_emaildomain','R_emaildomain']]\n\n#결측치를 나타내는 feature 생성\nemaildomain_df['NA_P_emaildomain'] = emaildomain_df.P_emaildomain.isnull().astype(int)\nemaildomain_df['NA_R_emaildomain'] = emaildomain_df.R_emaildomain.isnull().astype(int)\n\n#결측치 여부에 따른 사기거래 비율\nprint(emaildomain_df.groupby('NA_P_emaildomain')['isFraud'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:22:37.122486Z","iopub.execute_input":"2021-10-05T15:22:37.124688Z","iopub.status.idle":"2021-10-05T15:22:37.232691Z","shell.execute_reply.started":"2021-10-05T15:22:37.124638Z","shell.execute_reply":"2021-10-05T15:22:37.231682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- P_emaildomain는 결측치가 아닌 경우, 사기거래의 비율이 약 3.6%이고 결측치인 경우, 사기거래의 비율이 약 3%정도이기 때문에 크게 문제 없어 보임","metadata":{}},{"cell_type":"code","source":"print(emaildomain_df.groupby('NA_R_emaildomain')['isFraud'].mean())\n\ndel emaildomain_df\nx= gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:22:40.430445Z","iopub.execute_input":"2021-10-05T15:22:40.430995Z","iopub.status.idle":"2021-10-05T15:22:40.577719Z","shell.execute_reply.started":"2021-10-05T15:22:40.430962Z","shell.execute_reply":"2021-10-05T15:22:40.576941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- R_emaildomain은 오히려 결측치가 아닌 경우에 사기거래의 비율이 약 8.2%이고, 결측치의 경우, 사기거래의 비율이 약 2.1%로 나타남\n- **결측치인 경우보다 결측치가 아닌 경우의 사기거래가 4배 이상 많음**\n- 따라서, 해당 정보를 변수로 활용할 예정임","metadata":{}},{"cell_type":"code","source":"# train과 test 변수에 R_emaildomain의 결측치 여부 binary 정보를 변수로 추가함\ntrain_transaction['NA_R_emaildomain'] = train_transaction.P_emaildomain.isnull().astype(int)\ntest_transaction['NA_R_emaildomain'] = test_transaction.P_emaildomain.isnull().astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:40:21.10193Z","iopub.execute_input":"2021-10-05T15:40:21.10223Z","iopub.status.idle":"2021-10-05T15:40:21.203487Z","shell.execute_reply.started":"2021-10-05T15:40:21.102199Z","shell.execute_reply":"2021-10-05T15:40:21.202544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#각 Unique값(email domain)별로 데이터 수가 몇개인지 확인\ntrain_transaction.P_emaildomain.value_counts(normalize = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:08:06.727087Z","iopub.execute_input":"2021-10-05T15:08:06.727789Z","iopub.status.idle":"2021-10-05T15:08:06.85122Z","shell.execute_reply.started":"2021-10-05T15:08:06.727753Z","shell.execute_reply":"2021-10-05T15:08:06.85038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- domain 값이 제대로 정리되지 않고 'gmail.com' / 'gmail'과 같은 형태로 '.com'이 붙지 않은 형태도 존재함\n- 그리고 domain은 같은데 '.com, .co.uk, .co.jp와 같이 서로 다르게 표현된 email도 존재함\n    - 따라서, '.'을 기준으로 domain 주소값과 com, net과 같은 domain들을 분리하여 domain 주소값만 가져와서 봐야할 필요가 있음 ","metadata":{}},{"cell_type":"code","source":"#domain 주소값만 가져와서 추가적인 탐색 수행\ntrain_transaction['P_emaildomain'] = train_transaction['P_emaildomain'].str.split('.').str[0]\ntrain_transaction['R_emaildomain'] = train_transaction['R_emaildomain'].str.split('.').str[0]\n\ntest_transaction['P_emaildomain'] = train_transaction['P_emaildomain'].str.split('.').str[0]\ntest_transaction['R_emaildomain'] = train_transaction['R_emaildomain'].str.split('.').str[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:48:28.843791Z","iopub.execute_input":"2021-10-05T15:48:28.844386Z","iopub.status.idle":"2021-10-05T15:48:30.439402Z","shell.execute_reply.started":"2021-10-05T15:48:28.844351Z","shell.execute_reply":"2021-10-05T15:48:30.43867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transaction.P_emaildomain.value_counts(normalize = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:49:51.943047Z","iopub.execute_input":"2021-10-05T15:49:51.943305Z","iopub.status.idle":"2021-10-05T15:49:52.087267Z","shell.execute_reply.started":"2021-10-05T15:49:51.943278Z","shell.execute_reply":"2021-10-05T15:49:52.086631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#각 domain 주소별 사기거래 비율 확인\ntrain_transaction.groupby('P_emaildomain')['isFraud'].mean().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:54:43.141604Z","iopub.execute_input":"2021-10-05T15:54:43.142363Z","iopub.status.idle":"2021-10-05T15:54:43.240733Z","shell.execute_reply.started":"2021-10-05T15:54:43.142325Z","shell.execute_reply":"2021-10-05T15:54:43.23992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- P_emaildomain에 따른 사기거래 비율의 차이가 존재함\n- 다만, 사기거래 비율이 약 40%로 가장 높은 protonmail의 경우 샘플 수가 76개이고, 약 19%인 mail은 559개, aim은 315개임\n- 전체 데이터 수가 54만개 정도인 것을 생각하며 그 수가 매우 적어서 유의한 것인지 판단하기 애매함\n- 만약 변수로 사용한다면 사기거래 비율이 반올림하여 약 10%이상 되는 protonmail, mail, aim, outlook을 그룹으로 묶어 해당 그룹인지 아닌지 여부로 사용할 것임","metadata":{}},{"cell_type":"code","source":"train_transaction.R_emaildomain.value_counts(normalize = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:04:30.672794Z","iopub.execute_input":"2021-10-05T16:04:30.673642Z","iopub.status.idle":"2021-10-05T16:04:30.748361Z","shell.execute_reply.started":"2021-10-05T16:04:30.673595Z","shell.execute_reply":"2021-10-05T16:04:30.747713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transaction.groupby('R_emaildomain')['isFraud'].mean().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:03:00.714066Z","iopub.execute_input":"2021-10-05T16:03:00.714321Z","iopub.status.idle":"2021-10-05T16:03:00.799132Z","shell.execute_reply.started":"2021-10-05T16:03:00.714295Z","shell.execute_reply":"2021-10-05T16:03:00.798309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- P_emaildomain과 마찬가지로, R_emaildomain에 따른 사기거래 비율의 차이가 존재함\n- 다만, P_emaildomain과 같이 사기거래 비율이 약 95%로 가장 높은 protonmail의 경우 샘플 수가 41개이고, 약 38%인 mail은 122개임\n- 전체 데이터 수가 54만개 정도인 것을 생각하며 그 수가 매우 적어서 유의한 것인지 판단하기 애매함\n- 만약 변수로 사용한다면 사기거래 비율이 반올림하여 약 10%이상 되는 protonmail, mail, outlook, icloud, gmail을 그룹으로 묶어 해당 그룹인지 아닌지 여부로 사용할 것임\n- P_emaildomain의 경우와 R_emaildomain의 경우를 비교해보면, 사기거래의 비율이 높은 도메인 주소가 몇개 겹침(protonmail, mail, outlook)\n- 따라서, P_emaildomain와 R_emaildomain가 같은 거래인지 여부를 확인함","metadata":{}},{"cell_type":"code","source":"# 각 거래에 대해(같은 거래에 대해) P_emaildomain와 R_emaildomain의 값이 서로 같은지 여부를 확인함\nprint((train_transaction.P_emaildomain == train_transaction.R_emaildomain).astype(int).value_counts(False))\nprint('\\n')\nprint((train_transaction.P_emaildomain == train_transaction.R_emaildomain).astype(int).value_counts(True))\nprint('\\n')\n\n# P_emaildomain와 R_emaildomain의 값이 서로 같은지 여부에 따른 사기거래의 비율 확인\nemaildomain_df = train_transaction[['P_emaildomain','R_emaildomain','isFraud']]\nemaildomain_df['same_emaildomain'] = (emaildomain_df.P_emaildomain == emaildomain_df.R_emaildomain).astype(int)\nprint(emaildomain_df.groupby('same_emaildomain')['isFraud'].mean())\n\ndel emaildomain_df\nx = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:47:54.79837Z","iopub.execute_input":"2021-10-05T16:47:54.799091Z","iopub.status.idle":"2021-10-05T16:47:55.276825Z","shell.execute_reply.started":"2021-10-05T16:47:54.799052Z","shell.execute_reply":"2021-10-05T16:47:55.27598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 같은 doamin 주소인 거래의 데이터 샘플 수는 총 102523개이며 전체 대비 약 17%에 해당함 -> 데이터 샘플 수도 굉장히 많은 편임\n- domain의 주소가 같은 거래의 경우 사기인 비율이 약 9.6%로 거의 10%에 가까우며, 주소가 다른 경우에는 사기 비율이 약 2.2%로 매우 낮음\n- 실제 사기 거래의 비율이 3.5%인데 같은 domain의 거래의 약 10%가 사기임\n- domain 주소가 같은 거래의 수가 전체의 17%로 굉장히 많은데 이에 따른 사기 비율이 약 4배이상 차이가 나기 때문에 이는 매우 유의미하다고 판단할 수 있음\n- 따라서, 해당 정보를 변수로 활용할 예정임","metadata":{}},{"cell_type":"code","source":"#train과 test 데이터에 same_emaildomain이라는 두 feature가 서로 같은지 여부에 대한 binary 값을 설명변수로 추가함\ntrain_transaction['same_emaildomain'] = (train_transaction.P_emaildomain == train_transaction.R_emaildomain).astype(int)\ntest_transaction['same_emaildomain'] = (test_transaction.P_emaildomain == test_transaction.R_emaildomain).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:47:14.844324Z","iopub.execute_input":"2021-10-05T16:47:14.845188Z","iopub.status.idle":"2021-10-05T16:47:14.984513Z","shell.execute_reply.started":"2021-10-05T16:47:14.845149Z","shell.execute_reply":"2021-10-05T16:47:14.983761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### C3 feature\n- 결측치가 없다는 것을 이전에 확인하였음\n- 데이터 type은 float이지만, Unique값의 개수가 총 27개로 많지 않음 -> 일단은 범주형으로 판단함","metadata":{}},{"cell_type":"code","source":"train_transaction.C3.value_counts(normalize=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:52:52.559491Z","iopub.execute_input":"2021-10-05T16:52:52.559763Z","iopub.status.idle":"2021-10-05T16:52:52.576418Z","shell.execute_reply.started":"2021-10-05T16:52:52.559734Z","shell.execute_reply":"2021-10-05T16:52:52.575561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transaction.C3.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:52:50.731731Z","iopub.execute_input":"2021-10-05T16:52:50.732021Z","iopub.status.idle":"2021-10-05T16:52:50.752312Z","shell.execute_reply.started":"2021-10-05T16:52:50.731969Z","shell.execute_reply":"2021-10-05T16:52:50.751283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 거의 모든(약 99.6%) 데이터가 0의 값임을 알 수 있음","metadata":{}},{"cell_type":"code","source":"train_transaction.groupby('C3')['isFraud'].mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T16:54:57.310693Z","iopub.execute_input":"2021-10-05T16:54:57.311244Z","iopub.status.idle":"2021-10-05T16:54:57.33536Z","shell.execute_reply.started":"2021-10-05T16:54:57.311207Z","shell.execute_reply":"2021-10-05T16:54:57.334616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 2 이상의 값은 전체 대비 샘플 수가 너무 적기 때문에 사기비율이 0으로 나왔을 것으로 추측함\n- 0(약3.5%)은 전체의 99.6%이기 때문에 전체 데이터의 사기거래비율(약 3.5%)과 유사함\n- 1은 샘플 수가 2137로 어느정도 있음에도 사기거래 비율이 약 0.2%로 전체 사기비율과 크게 차이남\n- C3값이 0인지 0이 아닌지에 따른 차이가 존재할 것이라는 추측이 가능함","metadata":{}},{"cell_type":"markdown","source":"### M 관련 변수(features)\n- 모두 범주형 변수이며, 이전에 확인한 것처럼 값이 대부분 T/F의 값을 가지고 있기 때문에 같이 탐색함","metadata":{}},{"cell_type":"code","source":"#M column 이름 모음\nM_cols = ['M'+str(i) for i in range(1,10)]\nfor M_col in M_cols:\n    print(f'{M_col} missing values')\n    #결측치 개수 확인\n    count = train_transaction[M_col].isnull().sum()\n    print('count:', count)\n    #결측치 비율 확인\n    print('ratio: %.2f'%(count / train_transaction.shape[0]))\n    print('======================')\n    print(f'{M_col} values')\n    #변수 분포 확인\n    print( train_transaction[M_col].value_counts())\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:52:16.279709Z","iopub.execute_input":"2021-10-05T17:52:16.280257Z","iopub.status.idle":"2021-10-05T17:52:17.369245Z","shell.execute_reply.started":"2021-10-05T17:52:16.280219Z","shell.execute_reply":"2021-10-05T17:52:17.368585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 모든 feature들에 대한 결측치의 비율이 약 50% 가까이 또는 그 이상으로 매우 많으므로 단순히 다른 값으로 대체하거나 제거하지 못함\n- M4 feature를 제외하고 나머지 모든 feature들은 T/F의 값을 가짐","metadata":{}},{"cell_type":"code","source":"#탐색을 위해, 모든 결측값을 잠시 대체함\nM_df = train_transaction[M_cols+['isFraud']]\nM_df[M_cols] = M_df[M_cols].fillna('MV') #missing vlaue\n\nfor col in M_cols:\n    print(M_df.groupby(col)['isFraud'].mean())\n    print('\\n')\n    \ndel M_cols, count, M_df\nx = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T17:53:17.655391Z","iopub.execute_input":"2021-10-05T17:53:17.655647Z","iopub.status.idle":"2021-10-05T17:53:18.953806Z","shell.execute_reply.started":"2021-10-05T17:53:17.65562Z","shell.execute_reply":"2021-10-05T17:53:18.952963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- M4,M5를 제외한 모든 feature들에서 결측치를 의미하는 'MV'일 경우 사기거래 비율이 다른 T/F보다 높음\n- M4의 경우 결측치일 때 오히려 사기비율이 약 2%로 다른 결측치가 아닐 때 다른 class보다 낮음\n- 하지만 확실히 대부분의 feature들에서 결측치를 의미할 경우와 결측치가 아닌 경우의 사기거래 비율에서 확실한 차이를 보이고 있으므로 결측치에 대해서 하나의 범주로 판단하기로 결정함","metadata":{}},{"cell_type":"markdown","source":"### DeviceType feature","metadata":{}},{"cell_type":"code","source":"#결측치 개수 확인\nprint(train_identity.DeviceType.isnull().sum()) # 결측치 3423개 \nprint(train_identity.DeviceType.isnull().sum() / train_identity.shape[0]) #결측치 비율 약 2.4%임\n","metadata":{"execution":{"iopub.status.busy":"2021-10-05T18:08:36.540282Z","iopub.execute_input":"2021-10-05T18:08:36.540579Z","iopub.status.idle":"2021-10-05T18:08:36.572788Z","shell.execute_reply.started":"2021-10-05T18:08:36.540533Z","shell.execute_reply":"2021-10-05T18:08:36.572066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DeviceType_df = train_identity[['TransactionID','DeviceType']].merge(train_transaction[['TransactionID','isFraud']], how = 'right', on='TransactionID')\n#train_transaction 데이터와 합친 데이테에 대한 결측치 개수 확인\nprint(DeviceType_df.DeviceType.isnull().sum()) # 결측치 449730개 \nprint(DeviceType_df.DeviceType.isnull().sum() / DeviceType_df.shape[0]) #결측치 비율 약 76%임\nprint('\\n')\n#결측치를 나타내는 feature 생성\nDeviceType_df['NA_DeviceType'] = DeviceType_df.DeviceType.isnull().astype(int)\nprint(DeviceType_df.groupby('NA_DeviceType')['isFraud'].mean())\n\ndel DeviceType_df\nx= gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T18:31:24.012255Z","iopub.execute_input":"2021-10-05T18:31:24.012898Z","iopub.status.idle":"2021-10-05T18:31:24.448785Z","shell.execute_reply.started":"2021-10-05T18:31:24.012856Z","shell.execute_reply":"2021-10-05T18:31:24.447915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- identity에서는 결측치가 3423개, 전체 약 2.4%였지만, transaction 데이터를 합치니까 결측치가 449730개에 76%로 증가함\n    - 결측치에 해당되는 전체의 2.4%해당 되는 소수의 ID들의 거래 횟수가 전체 거래횟수의 약 76%를 차지한다는 의미임\n- 앞서 살펴본 R_emaildomain와 유사하게 오히려 결측치가 아닌 경우에 사기거래의 비율이 약 8%이고, 결측치의 경우, 사기거래의 비율이 약 2.1%로 나타남\n- **결측치가 아닌 경우의 사기거래가 결측치인 경우보다 약 4배 가까이 많음**\n- 따라서, 해당 정보를 변수로 활용할 예정임","metadata":{}},{"cell_type":"markdown","source":"## 2.5 연속형 변수(Numerical feature) 탐색\n- 변수별 분포 확인(histogram)\n- 변수와 Target간 관계 파악 (boxplot)","metadata":{}},{"cell_type":"markdown","source":"# 3. Data Preprocessing\n- Categorical Features Preprocessing (Encoding)\n- Feature Selection\n- Feature Engineering\n- PDA ","metadata":{}},{"cell_type":"markdown","source":"## Merge Transaction data and Identity data\n- train, test에 대해 transaction과 identitiy 데이터를 합쳐서 사용함","metadata":{}},{"cell_type":"code","source":"# 처음에 미리 데이터의 index를 TransactionID로 설정한 경우\nif is_index_TransactionID:\n    X_train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n    X_test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\nelse:\n# 처음에 미리 데이터의 index를 TransactionID로 설정하지 않은 경우\n    # 'TransactionID' feature를 기준으로 transaction, identity 데이터 합치기\n    X_train = pd.merge(train_transaction, train_identity, how = 'left', on = 'TransactionID')\n    X_test = pd.merge(test_transaction, test_identity, how = 'left', on = 'TransactionID')\n    # 'TransactionID' feature를 index로 설정함\n    X_train = X_train.set_index('TransactionID')\n    X_test = X_test.set_index('TransactionID')\n\ndel train_identity, test_identity, train_transaction, test_transaction\ntmp = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 설명변수(feature)와 반응변수(target)를 분리","metadata":{}},{"cell_type":"code","source":"# target_col = 'isFraud'\n# feature_col = X_train.columns.difference([target_col])\n# y_train = X_train[target_col].copy()\n# X_train = X_train[feature_col]\n\ny_train = X_train.pop['isFraud']\n#X_train.drop(['isFraud'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalize D Columns (D feature 정규화)","metadata":{}},{"cell_type":"markdown","source":"- D feature는 과거의 어떤 순간부터의 거래 시점까지의 \"Time delta\"값임\n- D feature를 델타값이 아닌 그 과거의 시점의 값으로 변환하여 해당 feature가 시간에 따라 증가하는 특성을 없애\n  시계열의 특성을 제거한 모델에 조금 더 의미있는 feature로 사용함\n- 단, D1의 카드만든 이후 지금까지의 기간과 같이 델타값이 의미가 있는 feature는 제외함","metadata":{}},{"cell_type":"code","source":"# Normalize D features\nfor idx in range(1,16):\n    # 일부 feature는 제외함\n    if idx in [1,2,3,5,9]: \n        continue\n    # 델타값(일단위값) - (거래시점(초단위)/24*60*60 -> 초단위값을 일단위로 변환)\n    X_train['D'+str(idx)] =  X_train['D'+str(idx)] - X_train.TransactionDT/np.float32(24*60*60)\n    X_test['D'+str(idx)] = X_test['D'+str(idx)] - X_test.TransactionDT/np.float32(24*60*60) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- test의 id feature를 train의 id feature와 이름을 통일시킴","metadata":{}},{"cell_type":"code","source":"for column in X_test.columns:\n    if column.startswith('id'):\n            X_test.rename(columns={column:column.replace('-','_')},inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"markdown","source":"- 결측치가 N개 이상인 feature들을 모두 제거함으로써 feature를 골라냄","metadata":{}},{"cell_type":"code","source":"def drop_N_missing_values_columns(df_train, df_test,N=100000):\n    \n    def getNulls(data):\n        #결측치 개수 및 비율 계산\n        total = data.isnull().sum()\n        percent = data.isnull().sum() / data.isnull().count()\n        missing_data = pd.concat([total, percent], axis = 1, keys = ['total', 'precent'])\n\n        return missing_data\n\n    # Train 데이터의 결측치를 파악함\n    missing_data_train = getNulls(df_train)\n\n    # 결측치가 N개 이상있는 경우, 해당 feature 버림\n    sel_cols = missing_data_train[missing_data_train['total'] > N].index\n    del missing_data_train\n\n    # Drop the columns\n    df_train.drop(sel_cols, axis = 1, inplace = True)\n    df_test.drop(sel_cols, axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#N = 100000\n#N defalt 값으로 100000으로 설정 \ndrop_N_missing_values_columns(X_train, X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handle Missing Values","metadata":{}},{"cell_type":"markdown","source":"- 결측치를 최빈값이나 평균값으로 채우는지, -1로 채우는지에 따라 방법이 다름","metadata":{}},{"cell_type":"code","source":"def handle_missing_values_mean_mode(df_train, df_test):\n    ntrain = df_train.shape[0]\n    ntest = df_test.shape[0]\n    #train , test데이터를 합침\n    df_all = pd.concat([df_train, df_test], axis = 0, sort = False)\n    #모든 데이터에 대한 column명을 가져옴\n    all_data_cols = df_all.columns\n\n    # 최빈값으로 결측치 채움\n    for i in all_data_cols:\n        # str값의 경우 최빈값으로 결측치를 채움\n        if df_all[i].dtype == 'object':\n            df_all[i] = df_all[i].fillna(df_all[i].mode()[0])\n        # C 또는 V feature의 경우에 최빈값으로 결측치를 채움\n        elif (i.startswith(\"C\") or (i.startswith(\"V\"))) and df_all[i].isnull().sum() > 0:\n            df_all[i] = df_all[i].fillna(df_all[i].mode()[0])\n\n    # 평균값으로 결측치 채움\n    df_all['card2'] = df_all['card2'].fillna(df_all['card2'].mean())\n    df_all['card3'] = df_all['card3'].fillna(df_all['card3'].mean())\n    df_all['card5'] = df_all['card5'].fillna(df_all['card5'].mean())\n    df_all['D1'] = df_all['D1'].fillna(df_all['D1'].mode()[0])\n    df_all['D10'] = df_all['D10'].fillna(df_all['D10'].mode()[0])\n    df_all['D15'] = df_all['D15'].fillna(df_all['D15'].mode()[0])\n    df_all['addr1'] = df_all['addr1'].fillna(df_all['addr1'].mean())\n    df_all['addr2'] = df_all['addr2'].fillna(df_all['addr2'].mean())\n\n    # 다시 train과 test 데이터로 나눔\n    df_train = df_all[:ntrain]\n    df_test = df_all[ntrain:]\n    \n    del df_all \n    gc.collect()\n\ndef handle_missing_values_negative_one(df_train, df_test):\n    for col in df_train.columns:\n        #숫자값 데이터를 가지는 feature에 대해\n        if not df_train[col].dtype=='object':\n            #'TransactionAmt','TransactionDT' feature를 제외한 feature들에 대해\n            if col not in ['TransactionAmt','TransactionDT']:\n                #각 feature의 최소값을 구해 \n                mn = np.min((df_train[col].min(),df_test[col].min()))\n                #각 feature의 모든 값들에 대해 최소값을 빼주어 양수로 만듦\n                df_train[col] -= np.float32(mn)\n                df_test[col] -= np.float32(mn)\n                #결측치를 모두 -1로 설정함\n                df_train[col].fillna(-1,inplace=True)\n                df_test[col].fillna(-1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" handle_missing_values_negative_one(X_train, X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode the categorical features (Label Encode)","metadata":{}},{"cell_type":"code","source":"#1) 원핫인코딩(one-hot-encoding)\ndef encode_one_hot (df_train, df_test):\n    df_train = pd.get_dummies(df_train)\n    df_test = pd.get_dummies(df_test)\n\n#2) factorize함수로 직접 Label encode 하기\ndef encode_label (df_train, df_test):\n    # 데이터를 라벨숫자로 변환함\n    for col in df_train.columns:\n        if df_train[col].dtype=='object': \n            df_comb = pd.concat([df_train[col],df_test[col]],axis=0)\n            df_comb,_ = df_comb.factorize(sort=True)\n            X_train[col] = df_comb[:len(df_train)].astype('int16')\n            X_test[col] = df_comb[len(df_train):].astype('int16')\n            \n#3) Label Encoder() 사용하기\nfrom sklearn.preprocessing import LabelEncoder\ndef label_encoder (df_train, df_test):\n    for col in df_train.columns:\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one-hot-encoding/ labelencoderlibrary/ label-encoding\nencode_label(X_train, X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# 4. Machine Learning Modeling ","metadata":{}},{"cell_type":"markdown","source":"## Validation for Machine Learning Model\n- 시계열 데이터는 Random Sampling을 하면 안됨\n- Train엔 과거 데이터, Test엔 (과거 대비) 미래 데이터가 있어야 함\n- 해당 데이터가 시계열 데이터이긴 하지만 예측하고자 하는 Target이 시간에 영향을 받을 수 있는 수요값같은 게 아니라 사기거래 여부임\n- 각각의 거래에 대한 정보들을 통해 사기거래 여부를 판별하는 binary classification 문제이므로 데이터를 섞어도 상관없음\n\n### 1) Split of Train dataset and Validation dataset by using Stratified Random Sampling\n- Train data만으로 성능을 평가해보고 데이터에 대한 모델의 성능을 개선하는 데에 있어서 하이퍼 파라미터를 조절하거나 타겟 데이터에 대한 Oversampling을 적용하거나 Bagging을 적용한 결과에 대한 성능평가를 해보기 위해 Train dataset을 Train data(훈련 데이터)와 Validation data(검증 데이터)로 나눔\n- 해당 문제의 타겟 데이터의 class 비율이 imbalance하므로 Scikit-learn에 있는 model_selection의 train_test_split()에서 stratify파라미터와 StratifiedShuffleSplit()을 사용하여 y_train의 class비율에 따라 데이터를 나누는 층화추출(Stratified Sampling)기법을 사용함\n- train_test_split()함수의 stratify파라미터를 y_train으로 설정하여 y_train의 class비율에 따라 데이터를 나눔\n- StratifiedShuffleSplit()함수에 X_train, y_train을 파라미터로 넣어 X_train에 대해서 y_train의 class 비율에 따라 층화추출함","metadata":{}},{"cell_type":"code","source":"#방법(1) sklearn.model_selection.train_test_split 함수를 이용한 Train, Test set 분할 \n#(층을 고려한 X_train, X_test, y_train, y_test 반환)\ndef split_validation_dataset(X_train=X_train, y_train=y_train, val_size=0.2, shuffle=True, stratify=y_train):\n    from sklearn.model_selection import train_test_split\n    \n    return train_test_split(X_train, y_train, stratify=stratify, test_size=val_size, shuffle=shuffle)\n\n#방법(2) sklearn.model_selection.StratifiedShuffleSplit 함수를 이용한 Train, Test set 분할\n#(층을 고려한 train/test index 반환 --> Train, Test set indexing)\ndef split_validation_index(X_train=X_train, y_train=y_train, val_size=0.2):\n    from sklearn.model_selection import StratifiedShuffleSplit\n    #1개의 train/ test set 만을 분할하므로 n_splits=1 로 지정해주며, test_size에 test set의 비율을 지정해주고, \n    #random_state에는 재현가능성을 위해 난수 초기값으로 아무값이 지정해줍니다.\n    split_object = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n    return split_object.split(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN 80% Validation 20%\n\n#CASE1: Split DataFrame of Train data\nX_train, X_val, y_train, y_val = split_validation_dataset()\n\n#CASE2: Split Index of Train data\n# idxT, idxV = split_validation_index()\n# X_train = X_train[idxT]\n# X_val = X_train[idxV]\n# y_train = y_train[idxT]\n# y_test = y_train[idxV]\n\n# TRAIN 75% Validation 25%\n# idxT = X_train.index[:3*len(X_train)//4]\n# idxV = X_train.index[3*len(X_train)//4:]\n\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 나누어진 Dataset의 Target 데이터의 class비율대로 나누어졌는지 데이터 분포 확인","metadata":{}},{"cell_type":"code","source":"# 나뉘어진 반응 변수의 분포 확인(Class imbalance 확인)\nprint('Number of y_train data is', len(y_train))\nprint('Number of y_val data is', len(y_val))\nprint('\\n')\nfrom collections import Counter\ntarget_train_dist = Counter(y_train)\ntarget_val_dist = Counter(y_val)\nprint(target_train_dist)\nprint(target_val_dist)\nprint('\\n')\nprint('Ratio of fraud transaction data by train data is %.1f%%'%(target_train_dist[0] / len(y_train)*100))\nprint('Ratio of non-fraud transaction data by train data is %.1f%%'%(target_train_dist[1]/ len(y_train)*100))\nprint('\\n')\nprint('Ratio of fraud transaction data by validation data is %.1f%%'%(target_val_dist[0] / len(y_val)*100))\nprint('Ratio of non-fraud transaction data by validation data is %.1f%%'%(target_val_dist[1]/ len(y_val)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Cross Validation(CV)\n- 교차검증을 수행함\n- class(Label)가 imbalance하므로 Stratified K-Fold CV을 적용함\n- 따라서 Scikit-learn의 model_selection에 있는 StratifiedKFlod()함수 사용함","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Oversampling of Target data","metadata":{}},{"cell_type":"code","source":"def oversampling_target_data(X_train=X_train, y_train=y_train, ratio=0.3, method='SMOTE'):\n    if method == 'SMOTE':\n        from imblearn.over_sampling import SMOTE\n\n        smote = SMOTE(ratio = 0.3) # SMOTE 알고리즘, 비율 증가\n        X_train_res, y_train_res = smote.fit_sample(X_train, y_train.ravel()) # Over Sampling 진행\n        \n    elif method =='BorderlineSMOTE':\n        from imblearn.over_sampling import BorderlineSMOTE\n    \n    elif method =='ADASYN':\n        from imblearn.over_sampling import ADASYN\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling Method","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nxgmodel = xgb.XGBClassifier( \n        n_estimators=2000,\n        max_depth=12, \n        learning_rate=0.02, \n        subsample=0.8,\n        colsample_bytree=0.4, \n        missing=-1, \n        eval_metric='auc',\n        # USE CPU\n        #nthread=4,\n        #tree_method='hist' \n        # USE GPU\n        tree_method='gpu_hist' \n    )\n# xgmodel = xgb.XGBClassifier(n_estimators = 5000,\n#                             #max_depth = 12,\n#                             #learning_rate = 0.02,\n#                             #subsample = 0.8,\n#                             #colsample_bytree = 0.4,\n#                             #missing = -1,\n#                             #random_state = 42,\n#                             #tree_method = 'gpu_hist')\nxgmodel.fit(X_train.loc[idxT,:], y_train[idxT],eval_set=[(X_train.loc[idxV,:],y_train[idxV])],\n        verbose=50, early_stopping_rounds=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBM","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble of Ensemble Method","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}