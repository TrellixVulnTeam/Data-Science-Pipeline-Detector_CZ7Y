{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Merge identity and transaction for both training and test dataset\ntrain_identity = pd.read_csv('../input/train_identity.csv')\ntrain_transaction = pd.read_csv('../input/train_transaction.csv')\ntest_identity = pd.read_csv('../input/test_identity.csv')\ntest_transaction = pd.read_csv('../input/test_transaction.csv')\n\ntrain = pd.merge( train_transaction,train_identity, on = 'TransactionID', how = 'left')\ntest = pd.merge(  test_transaction,test_identity, on = 'TransactionID', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#delete unused datasets\ndel train_identity, train_transaction, test_identity, test_transaction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training data's shape: \", train.shape)\nprint(\"Test data's shape: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Take a look at Missing data: number, percentage for each column\ndef info_missing( df ):\n    missing_num = df.isna().sum()\n    missing_perc = missing_num/df.shape[0]*100\n    col_dtype = pd.Series([df[col].dtype for col in df.columns], index = df.columns)\n    res = pd.concat( [missing_num, missing_perc, col_dtype], axis = 1, keys = ['Missing#', 'Missing%', 'dtype'])\n    return res.T\n\npd.set_option('max_columns', 500)\ninfo_missing(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Take a look at number of unique value for each categorical column: \ndef info_unique( df ):\n    cols_cat = [c for c in df.columns if df[c].dtype == 'object']\n    n_unique = [ df[c].nunique() for c in cols_cat]\n    res = pd.Series(n_unique, index = cols_cat).sort_values(ascending = True).transpose()\n    return res\ninfo_unique(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Unbalanced data: need to deal with later\nprint( \"Fraud % is  {:1f} % in training set\".format(train.isFraud.sum()/train.shape[0]*100)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Divide and conqur \n#id_01 - id_38: id's data\ncols = train.columns.tolist()\nid_01_index = cols.index('id_01')\nid_38_index = cols.index('id_38')\ntrain_id = train.iloc[:,id_01_index: id_38_index+1]\n\n#id's numerical data\ntrain_id_num = train_id.select_dtypes( exclude = ['object'])\ntrain_id_num.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_id_num.hist(bins = 20, figsize = (20, 15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation of id's numerical data\nimport seaborn as sns\ntrain_id_num_corr = train_id_num.corr()\nsns.heatmap( train_id_num_corr, cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#id's categorical data\ntrain_id_cat = train_id.select_dtypes( include = ['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_id_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_id_cat.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef bar_plot( feature, n, norm = True):\n    train_fraud = train[train.isFraud ==1][feature].value_counts(dropna = False, normalize= norm)\n    train_notfraud = train[train.isFraud ==0][feature].value_counts(dropna = False, normalize= norm)\n    f, ax = plt.subplots(1,2, figsize = (18,4))\n    sns.barplot( y = train_fraud.index[:n], x = train_fraud[:n], ax = ax[0]).set_title( feature + ' - Fraud')\n    sns.barplot( y = train_notfraud.index[:n], x = train_notfraud[:n], ax = ax[1]).set_title(feature +' - Not Fraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#id_30 seems to be system, with Windows 10 being most common, 75 unique values\nbar_plot('id_30',10) #Fraud seems to have more systems other than windows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#id_31 seems to be explorer, with chrome being most common, 130 unique values\nbar_plot('id_31',10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#id_33? 260 unique values\nbar_plot('id_33',10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Device type\nbar_plot('DeviceType', 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Device info, somehow overlaps with id_30\nbar_plot('DeviceInfo', 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TransactionDT\nprint( len(train.TransactionDT.unique()))\ntrain.TransactionDT.describe() #TransactionDT seems different for every record","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.TransactionDT.plot( kind = 'hist', figsize = (15, 5), label = 'train', bins = 50, title = 'TransactionDT')\ntest.TransactionDT.plot( kind = 'hist', label = 'test', bins = 50)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TransactionAmt: \ntrain.TransactionAmt.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TransactionAmt: some outliers\n#train.TransactionAmt[train.TransactionAmt<3000].hist(bins = 50, figsize = (8,6))\nax = train.plot( x = 'TransactionDT', y = 'TransactionAmt', kind = 'scatter', alpha = 0.01, label = 'Train', \n           title = 'Transaction Amount', figsize = (15,5), ylim = (0,5000))\ntest.plot( x = 'TransactionDT', y = 'TransactionAmt', kind = 'scatter', alpha = 0.01, label = 'Test', ax = ax)\n#fraud\ntrain.loc[ train.isFraud ==1].plot( x = 'TransactionDT', y = 'TransactionAmt', kind = 'scatter', alpha = 0.01,color = 'yellow', ax = ax)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ProductCD: 5 unique values, not sure what this is\nbar_plot( 'ProductCD',5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#card1 - card6: categorical data\nindex_card1 = cols.index('card1')\ntrain_card = train.iloc[:, index_card1:index_card1+6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_card_num = train_card.select_dtypes( exclude = ['object'])\ntrain_card_num.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_card_num.hist(bins = 50, figsize = (15,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#card4\nbar_plot('card4',5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#card6: fraud has higher share from credit card \nbar_plot('card6',5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dist1, dist2\ntrain.loc[:,['dist1','dist2']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[:,['dist1','dist2']].hist(bins = 20, figsize= (10,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#P_emaildomain and R_emaildomain\ntrain.loc[:,['P_emaildomain', 'R_emaildomain']].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#P_domain\nbar_plot('P_emaildomain', 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R_domain\nbar_plot('R_emaildomain', 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#C1-C14: all numerical data - float64\nindex_C1 = cols.index('C1')\ntrain_C = train.iloc[:,index_C1:index_C1+14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_C.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_C.hist(bins=50, figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#D1 - D15\nindex_D1 = cols.index('D1')\ntrain_D = train.iloc[:, index_D1:index_D1+15]\ntrain_D.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_D.hist(bins = 50, figsize = (15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#M1 - M9: objects; boolean except for M4\nindex_M1 = cols.index('M1')\ntrain_M = train.iloc[:,index_M1: index_M1+9]\ntrain_M.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#V1-V339: all float values\nindex_V1 = cols.index('V1')\ntrain_V = pd.DataFrame(train.iloc[:, index_V1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_V.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_V.info()\ntrain_V.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare data for machine learning algorithms\n#1. delete columns with 1) unique value 2) 90% are different value and 3) more than 90% is missing value\nunique_col_train = [col for col in train.columns if train[col].nunique() <= 1]\nunique_col_test = [col for col in test.columns if test[col].nunique()<= 1]\nvarious_col_train = [col for col in train.columns if train[col].value_counts(dropna = False, normalize = True).values[0] > 0.9]\nvarious_col_test = [col for col in test.columns if test[col].value_counts(dropna = False, normalize = True).values[0] > 0.9]\nmissing_col_train = [col for col in train.columns if train[col].isnull().sum()/train.shape[0] > 0.9]\nmissing_col_test =  [col for col in test.columns if test[col].isnull().sum()/test.shape[0] >0.9 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [unique_col_train, unique_col_test, various_col_train, various_col_test, missing_col_train, missing_col_test]:\n    print( i, len(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_to_drop = list(set(unique_col_test +unique_col_train + various_col_test +various_col_train + missing_col_test +missing_col_train))\ncol_to_drop.remove('isFraud')\nlen(col_to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop( col_to_drop, axis = 1, inplace = True)\ntest.drop(col_to_drop, axis = 1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2. deal with email domain\n#https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499#latest-579654\nemails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    train[c + '_bin'] = train[c].map(emails)\n    test[c + '_bin'] = test[c].map(emails)\n    \n    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n    test[c + '_suffix'] = test[c].map(lambda x: str(x).split('.')[-1])\n    \n    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    test[c + '_suffix'] = test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3. deal with categorical data\nfrom sklearn.preprocessing import LabelEncoder\ncat_cols = [col for col in train.columns if train[col].dtype is ['object']]\nfor col in cat_cols:\n    le = LabelEncoder()\n    le.fit( list(train[col].astype(str).values) + list( test[col].astype(str).values))\n    train[col] = le.transform( list(train[col].astype(str).values))\n    test[col] = le.transform( list(test[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop transaction ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}