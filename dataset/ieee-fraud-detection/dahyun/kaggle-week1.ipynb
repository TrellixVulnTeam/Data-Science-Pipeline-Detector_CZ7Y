{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 고객 거래 이상징후 탐지\n\n#### 두번째 노트북 필사 : https://www.kaggle.com/shahules/tackling-class-imbalance\n\n* 목표 : 고객별로 거래가 발생했을 때 그에 대한 Fraud의 정도를 예측한다. \n* binary target : isFraud","metadata":{}},{"cell_type":"markdown","source":"## Data description\nThe data is broken into two files **identity** and **transaction**, which are joined by TransactionID.\n\n### transaction table  \nIt contains money transfer and also other gifting goods and service, like you booked a ticket for others, etc. \n\n**Features - Transaction**\n* TransactionDT: 지정된 거래 참조 날짜의 델타 시간(실제 타임스탬프가 아님)\n-> ex) “TransactionDT first value is 86400, which corresponds to the number of seconds in a day (60 * 60 * 24 = 86400). So we know the data spans 6 months, as the maximum value is 15811131, which would correspond to day 183.\"\n\n* TransactionAMT: 거래 결제 금액(USD : 미국달러 단위) \n* dist: 거리 (청구주소, 우편주소, 우편번호, IP주소, 전화 지역간의 거리...) \n* C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked. 결제 카드와 연결된 주소의 수 등의 counting으로 실제 의미는 숨겨져 있음 \n* D1-D15: 이전(previous) 거래 일수와 같은 델타시간\n* Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations. \n\n**Categorical Features - Transaction**\n* ProductCD: 거래별 상품 코드 (여기서 상품은 제품과 더불어 서비스도 포함됨) \n* emaildomain: 구매자 및 수신자 이메일 주소\n* card1 - card6:  카드종류(type), 카드분류(category), 발행 은행, 국가 등 결제 지불 카드에 대한 정보 \n* addr1, addr2 : 주소(카드 결제한 주소). addr1,2 모두 구매자에 대한 정보로 addr1은 billing region(거래 청구서를 발행한 지역), addr2는 billing country(거래 청구서를 발행한 나라)를 의미한다. \n* P_emaildomain \n* R_emaildomain\n* M1-M9: match, such as names on card and address, etc. 카드 이름, 주소 등의 일치(match)\n\n### identity table\n이 표의 변수는 identity (ID)에 대한 정보로,(IP, ISP, 프록시 등)와같은 네트워크 연결 정보와 거래와 관련된 전자서명(UA/브라우저/os/버전 등)에 대한 정보를 담고 있습니다. Vesta의 부정 행위 방지 시스템과 디지털 보안 파트너가 이러한 정보를 수집합니다. \n(field명은 maksed 되어 있으며 개인 정보 보호 및 계약 합의를 위해 쌍별 사전이 제공되지 않습니다.)\n\n**Categorical Features - Identity**\n* DeviceType : 거래 기기의 유형\n* DeviceInfo : 거래 기기에 대한 정보 (연결 네트워크, 전자서명) \n* id_12 - id_38 \n\n\n### labeling logic\n* 부정거래 : Fraud=1\n* 합법적 거래 : isFraud = 0  ","metadata":{}},{"cell_type":"markdown","source":"## Questions\n* 1) 어떤 유형의 데이터가 존재하는가\n* 2) missing value(누락된 값)은 몇개인가\n* 3) target (isFraud) 값의 분포는 어떻게 되는가\n* 4) 이상거래와 정상거래의 transactions values의 분포는 어떻게 되는가\n* 5) 이상거래가 두드러진 상품이 있는가\n* 6) feature나 target이 흥미로운 특징을 보이는가\n","metadata":{}},{"cell_type":"markdown","source":"### 클래스 불균형 해결방안 관련 참고 사이트\nhttps://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html","metadata":{}},{"cell_type":"markdown","source":"#### 1. import library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score,precision_recall_curve,roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport time\nimport matplotlib.patches as mpatches\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:13:52.623693Z","iopub.execute_input":"2021-06-25T13:13:52.62416Z","iopub.status.idle":"2021-06-25T13:13:53.904424Z","shell.execute_reply.started":"2021-06-25T13:13:52.624068Z","shell.execute_reply":"2021-06-25T13:13:53.903567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. loading train datasets & basic info","metadata":{}},{"cell_type":"code","source":"train_identity= pd.read_csv(\"../input/ieee-fraud-detection/train_identity.csv\")\ntrain_transactions = pd.read_csv(\"../input/ieee-fraud-detection/train_transaction.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:13:53.905991Z","iopub.execute_input":"2021-06-25T13:13:53.906313Z","iopub.status.idle":"2021-06-25T13:14:22.686068Z","shell.execute_reply.started":"2021-06-25T13:13:53.906275Z","shell.execute_reply":"2021-06-25T13:14:22.68514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transactions.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:22.688027Z","iopub.execute_input":"2021-06-25T13:14:22.688641Z","iopub.status.idle":"2021-06-25T13:14:22.730295Z","shell.execute_reply.started":"2021-06-25T13:14:22.688594Z","shell.execute_reply":"2021-06-25T13:14:22.729491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transactions.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:22.731959Z","iopub.execute_input":"2021-06-25T13:14:22.73233Z","iopub.status.idle":"2021-06-25T13:14:22.758617Z","shell.execute_reply.started":"2021-06-25T13:14:22.732291Z","shell.execute_reply":"2021-06-25T13:14:22.757275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_identity.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:22.759996Z","iopub.execute_input":"2021-06-25T13:14:22.760377Z","iopub.status.idle":"2021-06-25T13:14:22.961729Z","shell.execute_reply.started":"2021-06-25T13:14:22.760336Z","shell.execute_reply":"2021-06-25T13:14:22.960879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. 클래스 불균형 확인하기","metadata":{}},{"cell_type":"code","source":"# target variable\n# train_transactions['isFraud'].value_counts() # 0:569877개, 1:20663개\nx=train_transactions['isFraud'].value_counts().values\nsns.barplot([0,1],x)\nplt.title('Target variable count')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:22.963073Z","iopub.execute_input":"2021-06-25T13:14:22.96343Z","iopub.status.idle":"2021-06-25T13:14:23.099376Z","shell.execute_reply.started":"2021-06-25T13:14:22.963393Z","shell.execute_reply":"2021-06-25T13:14:23.098314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":": **클래스 불균형(class imbalance)**가 존재한다. \n\n* 클래스 불균형 : 머신러닝 알고리즘은 각 클래스들의 개수가 거의 비슷한 경우에 가장 좋은 결과를 보여준다. 클래스의 개수가 한쪽으로 치우처진 클래스 불균형이 발생한 상황이라면, **'소수의 클래스에 특별히 더 큰 관심이 필요하여'** 클래스 균형을 맞춰야 하는 목적이 있을 때만 그에 맞는 테크닉을 적용하면 된다. 현재 다루고 있는 부정거래를 탐지하는 경우엔 isFraud인 경우(1)가 정상거래(0)보다 훨씬 적다. 그러나 **우리의 관심은 부정거래(1)이기 때문에 정상거래라고 예측하는 정확도에 비해 훨씬 더 큰 정확도를 가져야** 한다. 따라서 클래스 균형을 맞춰주기 위해 'isFraud'인 경우에 더 많은 가중치를 두어야 한다. \n\n* 참고사이트\n\nhttps://techblog-history-younghunjo1.tistory.com/74\n\nhttps://3months.tistory.com/414\n\nhttps://rosypark.tistory.com/354\n\n* the metric trap (클래스 불균형에서 발생 가능한 모델 평가의 함정)\n\n클래스가 불균형한 경우, accuracy와 같은 평가지표를 사용하면 결과해석에 문제가 발생할 수 있다 (가령 비대칭 데이터셋에서는 정확도가 높아도 재현율[부정거래를 부정거래라고 예측할 확률] 이 급격히 작아지는 현상이 발생한다). 만약 분류기가 피쳐에 대한 분석을 거치지 않고, 단순히 많은 수의 클래스로 예측하게 되면 항상 높은 정확율을 보일 것이다. \n\n- false positive : 실제로는 부정거래가 아닌데 부정거래라고 판정한 경우\n- false negative : 실제로 부정거래인데 정상거래라고 판정한 경우 \n\n* Change the performance metric (클래스 불균형에 적합한 지표)\n1. Confusion Matrix\n2. precision\n3. recall\n4. F1 scores\n\ncf) roc 곡선은 각 클래스의 관측수가 거의 동일해야 의미있는 측정지표가 된다. PR(precision-recall) 곡선은 클래스 불균형이 어느정도 많이 두드러질 때 사용한다. ","metadata":{}},{"cell_type":"markdown","source":"#### 4. transaction 와 identity dataset 병합하기","metadata":{}},{"cell_type":"code","source":"train=train_transactions.merge(train_identity,how='left',left_index=True,right_index=True)\ny_train=train['isFraud'].astype('uint8') #목표변수셋\nprint('Train shape',train.shape)\n\ndel train_transactions, train_identity\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:23.10093Z","iopub.execute_input":"2021-06-25T13:14:23.101284Z","iopub.status.idle":"2021-06-25T13:14:24.52129Z","shell.execute_reply.started":"2021-06-25T13:14:23.101243Z","shell.execute_reply":"2021-06-25T13:14:24.520106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:24.5239Z","iopub.execute_input":"2021-06-25T13:14:24.524269Z","iopub.status.idle":"2021-06-25T13:14:24.555231Z","shell.execute_reply.started":"2021-06-25T13:14:24.524228Z","shell.execute_reply":"2021-06-25T13:14:24.554286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"+) Reducing memory usage (메모리 사용 줄이기) [이해x]","metadata":{}},{"cell_type":"code","source":"%%time\n# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n# WARNING! THIS CAN DAMAGE THE DATA \ndef reduce_mem_usage2(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:24.556818Z","iopub.execute_input":"2021-06-25T13:14:24.557172Z","iopub.status.idle":"2021-06-25T13:14:24.569875Z","shell.execute_reply.started":"2021-06-25T13:14:24.557136Z","shell.execute_reply":"2021-06-25T13:14:24.569049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = reduce_mem_usage2(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:14:24.571036Z","iopub.execute_input":"2021-06-25T13:14:24.571748Z","iopub.status.idle":"2021-06-25T13:15:50.039906Z","shell.execute_reply.started":"2021-06-25T13:14:24.571708Z","shell.execute_reply":"2021-06-25T13:15:50.0389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. splitting to train and validation 훈련 데이터셋,검증 데이터셋으로 나누기 ","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(train.drop('isFraud',axis=1),y_train,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:15:50.041353Z","iopub.execute_input":"2021-06-25T13:15:50.041882Z","iopub.status.idle":"2021-06-25T13:15:53.170338Z","shell.execute_reply.started":"2021-06-25T13:15:50.041842Z","shell.execute_reply":"2021-06-25T13:15:53.169444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6. resampling\n\n* resampling : 클래스 불균형을 처리하기 위한 기술로, undersampling(다수집단에서 샘플을 제거) 방법과 oversampling(소수 집단에서 더 많은 예를 추가) 방법이 있다. \n\n* undersampling을 할 때, 줄어든 다수집단의 데이터는 원본 데이터의 대표성을 잘 지니고 있어야 하는 것이 중요하다. oversampling의 경우엔 원본 데이터를 복사하는 개념이기 때문에 양이 늘어난 데이터는 양이 적었던 원본 데이터의 성질과 동일하다. ","metadata":{}},{"cell_type":"markdown","source":"##### 6-1. oversmapling \n* 작업할 데이터가 많지 않은 경우 좋은 선택지가 될 수 있다. ","metadata":{}},{"cell_type":"code","source":"X=pd.concat([X_train,y_train],axis=1)\n\nnot_fraud = X[X.isFraud==0]\nfraud = X[X.isFraud==1]\n\n# upsample minority\nfraud_upsampled = resample(fraud,replace=True,n_samples=len(not_fraud),random_state=27)\n\n# combine majority and upsampled minority\nupsampled = pd.concat([not_fraud, fraud_upsampled])\n\n# check new class counts\nupsampled.isFraud.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:15:53.171649Z","iopub.execute_input":"2021-06-25T13:15:53.172035Z","iopub.status.idle":"2021-06-25T13:15:57.905826Z","shell.execute_reply.started":"2021-06-25T13:15:53.171983Z","shell.execute_reply":"2021-06-25T13:15:57.904823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=upsampled.isFraud.value_counts()\nsns.barplot(y=y,x=[0,1])\nplt.title('upsampled data class count')\nplt.ylabel('count')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:15:57.907311Z","iopub.execute_input":"2021-06-25T13:15:57.907692Z","iopub.status.idle":"2021-06-25T13:15:58.011764Z","shell.execute_reply.started":"2021-06-25T13:15:57.90765Z","shell.execute_reply":"2021-06-25T13:15:58.010805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 6-2. undersample majority class\n* 데이터가 엄청 많은 경우엔 수백만개의 행을 고려해 언더샘플링을 선택하는 것이 좋다. 그러나 데이터를 제거하는 것이기 때문에 정보의 손실이 발생하여 테스트 세트에 대한 일반화가 제대로 이루어지지 않을 수 있다. ","metadata":{}},{"cell_type":"code","source":"not_fraud_downsampled=resample(not_fraud,replace=False,n_samples=len(fraud),random_state=27)\n\n# combine minority and downsampled majority\ndownsampled = pd.concat([not_fraud_downsampled,fraud])\n\n# checking counts\ndownsampled.isFraud.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:15:58.013116Z","iopub.execute_input":"2021-06-25T13:15:58.013477Z","iopub.status.idle":"2021-06-25T13:15:58.2685Z","shell.execute_reply.started":"2021-06-25T13:15:58.013439Z","shell.execute_reply":"2021-06-25T13:15:58.267477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=downsampled.isFraud.value_counts()\nsns.barplot(y=y,x=[0,1])\nplt.title('downsampled data class count')\nplt.ylabel('count')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:15:58.269974Z","iopub.execute_input":"2021-06-25T13:15:58.270325Z","iopub.status.idle":"2021-06-25T13:15:58.39807Z","shell.execute_reply.started":"2021-06-25T13:15:58.270285Z","shell.execute_reply":"2021-06-25T13:15:58.397112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7. make_classification 데이터 만들기 \n* 사이킷런 패키지는 분류 모형의 테스트를 위해make_classification 와 make_blob 라는 가상 데이터 생성 함수를 제공한다.\n* 쉽게 시각화할 수 있도록 make_classification 방법을 사용하여 작은 불균형 샘플 데이터 세트를 생성한다. \n\nhttps://taeguu.tistory.com/15","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_classification\n\n\nX,y=make_classification(\n    n_classes=2, class_sep=1.5, weights=[0.9,0.1],\n    n_informative=3, n_redundant=1, flip_y=0,\n    n_features=20, n_clusters_per_class=1,\n    n_samples=1000, random_state=10\n\n)\n\ndf=pd.DataFrame(X)\ndf['target']=y\ndf.target.value_counts().plot(kind=\"bar\",title='Count(target)')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:20:53.095897Z","iopub.execute_input":"2021-06-25T13:20:53.096259Z","iopub.status.idle":"2021-06-25T13:20:53.224784Z","shell.execute_reply.started":"2021-06-25T13:20:53.096224Z","shell.execute_reply":"2021-06-25T13:20:53.223976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:23:31.101971Z","iopub.execute_input":"2021-06-25T13:23:31.102333Z","iopub.status.idle":"2021-06-25T13:23:31.128422Z","shell.execute_reply.started":"2021-06-25T13:23:31.102299Z","shell.execute_reply":"2021-06-25T13:23:31.127163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"resampling 없이 make_classification으로 생성한 데이터로 로지스틱 회귀분석 모형의 데이터를 적합 및 예측하고 출력 점수를 관찰해보기","metadata":{}},{"cell_type":"code","source":"def logistic(X,y):\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n    lr=LogisticRegression()\n    lr.fit(X_train,y_train)\n    prob=lr.predict_proba(X_test)\n    return (prob[:,1],y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:25:35.663641Z","iopub.execute_input":"2021-06-25T13:25:35.664044Z","iopub.status.idle":"2021-06-25T13:25:35.66978Z","shell.execute_reply.started":"2021-06-25T13:25:35.664011Z","shell.execute_reply":"2021-06-25T13:25:35.668655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs,y_test=logistic(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:25:51.173987Z","iopub.execute_input":"2021-06-25T13:25:51.174359Z","iopub.status.idle":"2021-06-25T13:25:51.207259Z","shell.execute_reply.started":"2021-06-25T13:25:51.174325Z","shell.execute_reply":"2021-06-25T13:25:51.206276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PR curve와 roc curve를 그리기 위한 함수 정의하기","metadata":{}},{"cell_type":"code","source":"def plot_pre_curve(y_test,probs):\n    precision, recall, thresholds = precision_recall_curve(y_test,probs)\n    plt.plot([0,1],[0.5,0.5],linestyle='--')\n    plt.plot(recall,precision,marker='.')\n    plt.title(\"precision recall curve\")\n    plt.xlabel('Recall')\n    plt.ylabel('precision')\n    plt.show()\n\ndef plot_roc(y_test,prob):\n    fpr,tpr,thresholds = roc_curve(y_test,probs)\n    plt.plot([0,1],[0,1],linestyle='--')\n    plt.plot(fpr,tpr,marker='.')\n    plt.title('ROC curve')\n    plt.xlabel('false positive rate')\n    plt.ylabel('true positive rage')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:30:24.735195Z","iopub.execute_input":"2021-06-25T13:30:24.735603Z","iopub.status.idle":"2021-06-25T13:30:24.743274Z","shell.execute_reply.started":"2021-06-25T13:30:24.735566Z","shell.execute_reply":"2021-06-25T13:30:24.742048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pre_curve(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:30:40.750146Z","iopub.execute_input":"2021-06-25T13:30:40.750497Z","iopub.status.idle":"2021-06-25T13:30:40.886599Z","shell.execute_reply.started":"2021-06-25T13:30:40.750463Z","shell.execute_reply":"2021-06-25T13:30:40.885494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:30:55.604998Z","iopub.execute_input":"2021-06-25T13:30:55.605354Z","iopub.status.idle":"2021-06-25T13:30:55.730134Z","shell.execute_reply.started":"2021-06-25T13:30:55.605321Z","shell.execute_reply":"2021-06-25T13:30:55.729088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" 데이터 분포를 확인하기 위해 2차원 플롯함수 plot_2d_space 만들기 ","metadata":{}},{"cell_type":"code","source":"def plot_2d_space(X_train, y_train,X=X,y=y ,label='Classes'):   \n    colors = ['#1F77B4', '#FF7F0E']\n    markers = ['o', 's']\n    \n    fig,(ax1,ax2)=plt.subplots(1,2, figsize=(8,4))\n   \n    for l, c, m in zip(np.unique(y), colors, markers):\n        ax1.scatter(\n            X_train[y_train==l, 0],\n            X_train[y_train==l, 1],\n            c=c, label=l, marker=m\n        )\n    for l, c, m in zip(np.unique(y), colors, markers):\n        ax2.scatter(\n            X[y==l, 0],\n            X[y==l, 1],\n            c=c, label=l, marker=m\n        )\n   \n    ax1.set_title(label)\n    ax2.set_title('original data')\n    plt.legend(loc='upper right')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:07:23.934008Z","iopub.execute_input":"2021-06-25T14:07:23.93438Z","iopub.status.idle":"2021-06-25T14:07:23.942629Z","shell.execute_reply.started":"2021-06-25T14:07:23.934345Z","shell.execute_reply":"2021-06-25T14:07:23.941477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8. 차원축소, 군집화(clustering)\n\n* t-SNE 알고리즘(차원축소 알고리즘)을 이해하기 위해 알아야할 개념 \n - Euclidean Distance\n - Conditional Probability\n - Normal and T-Distribution Plots\n \n\n* 차원축소 알고리즘\n - T-sne\n - PCA\n - Truncated SVD\n \n\n* t-sne 알고리즘\n: sne 학습과정에서 가우시안 분포대신 t분포를 사용한다. \nhttps://m.blog.naver.com/xorrms78/222112752837\n\n* Truncated SVD\n: https://ariz1623.tistory.com/219","metadata":{}},{"cell_type":"code","source":"#  t-sne implementation \nt0 = time.time()\nX_reduced_tsne = TSNE(n_components=2,random_state=42).fit_transform(X)\nt1=time.time()\nprint(\"t-sne took {:.2} s\".format(t1-t0))\n\n# PCA Implementation\nt0 = time.time()\nX_reduced_pca = PCA(n_components=2,random_state=42).fit_transform(X)\nt1=time.time()\nprint(\"PCA took {:.2} s\".format(t1-t0))\n\n# TruncatedSVD\nt0 = time.time()\nX_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(X)\nt1 = time.time()\nprint(\"Truncated SVD took {:.2} s\".format(t1 - t0))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:48:58.263885Z","iopub.execute_input":"2021-06-25T13:48:58.264293Z","iopub.status.idle":"2021-06-25T13:49:05.525723Z","shell.execute_reply.started":"2021-06-25T13:48:58.264255Z","shell.execute_reply":"2021-06-25T13:49:05.524621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"위의 세가지 알고리즘 적용한 결과를 2차원 평면에 시각화한다.","metadata":{}},{"cell_type":"code","source":"f, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(24,6))\n# labels=['No Fraud','Fraud']\nf.suptitle('Clusters using Dimensionality Reduction',fontsize=14)\n\nblue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\nred_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n\n\n# t-sne scatter plot\nax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y==0),cmap='coolwarm',label='No Fraud',linewidths=2)\nax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y==1), cmap='coolwarm', label='Fraud', linewidths=2)\nax1.set_title('t-SNE', fontsize=14)\nax1.grid(True)\nax1.legend(handles=[blue_patch, red_patch])\n\n# PCA scatter plot\nax2.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y==0), cmap='coolwarm', label='No Fraud', linewidths=2)\nax2.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y==1), cmap='coolwarm', label='Fraud', linewidths=2)\nax2.set_title('PCA', fontsize=14)\nax2.grid(True)\nax2.legend(handles=[blue_patch, red_patch])\n\n# TruncatedSVD scatter plot\nax3.scatter(X_reduced_svd[:,0], X_reduced_svd[:,1], c=(y==0), cmap='coolwarm', label='No Fraud', linewidths=2)\nax3.scatter(X_reduced_svd[:,0], X_reduced_svd[:,1], c=(y==1), cmap='coolwarm', label='Fraud', linewidths=2)\nax3.set_title('X_reduced_svd', fontsize=14)\nax3.grid(True)\nax3.legend(handles=[blue_patch, red_patch])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T13:56:41.616274Z","iopub.execute_input":"2021-06-25T13:56:41.616723Z","iopub.status.idle":"2021-06-25T13:56:42.32877Z","shell.execute_reply.started":"2021-06-25T13:56:41.616683Z","shell.execute_reply":"2021-06-25T13:56:42.327936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9. 파이썬 imbalanced-learn module \n보다 정교한 resampling 기술이 제안되었다. 예를들어 수가 많은 클래스의 레코드를 클러스터링하고, 각 클러스터에 대해 레코드를 제거하여 undersampling을 수행하여 정보를 보존할 수 있다. oversampling의 경우엔 수가 적은 클래스의 레코드의 정확히 똑같은 복사본을 만드는 대신, 복사본에 작은 변형을 도입하여 다양한 합성 샘플을 만들 수 있다. 파이썬의 imbalanced learn 라이브러리를 통해 구현할 수 있다. ","metadata":{}},{"cell_type":"code","source":"import imblearn","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:02:39.295246Z","iopub.execute_input":"2021-06-25T14:02:39.295644Z","iopub.status.idle":"2021-06-25T14:02:39.451633Z","shell.execute_reply.started":"2021-06-25T14:02:39.295609Z","shell.execute_reply":"2021-06-25T14:02:39.450796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 9-1. random undersampling with imbalanced-learn","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\nran = RandomUnderSampler() #intialize to return indices of dropped rows\nX_rs, y_rs = ran.fit_resample(X,y)\n\n## indices : index의 복수\nplot_2d_space(X_rs,y_rs,X,y,'Random under sampling')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:08:27.854275Z","iopub.execute_input":"2021-06-25T14:08:27.854633Z","iopub.status.idle":"2021-06-25T14:08:28.118609Z","shell.execute_reply.started":"2021-06-25T14:08:27.854597Z","shell.execute_reply":"2021-06-25T14:08:28.117639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"fit and predict on this data and observe the outcome","metadata":{}},{"cell_type":"code","source":"probs, y_test = logistic(X_rs,y_rs)\nplot_pre_curve(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:09:42.534593Z","iopub.execute_input":"2021-06-25T14:09:42.535051Z","iopub.status.idle":"2021-06-25T14:09:42.735694Z","shell.execute_reply.started":"2021-06-25T14:09:42.535013Z","shell.execute_reply":"2021-06-25T14:09:42.73484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:09:51.133623Z","iopub.execute_input":"2021-06-25T14:09:51.133975Z","iopub.status.idle":"2021-06-25T14:09:51.26137Z","shell.execute_reply.started":"2021-06-25T14:09:51.133944Z","shell.execute_reply":"2021-06-25T14:09:51.260322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 9-2. random oversampling with imbalanced-learn","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nran=RandomOverSampler()\nX_ran, y_ran = ran.fit_resample(X,y)\n\nprint('the new data contains {} rows'.format(X_ran.shape[0]))\n\nplot_2d_space(X_ran,y_ran,X,y,'over-sampled')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:11:38.182102Z","iopub.execute_input":"2021-06-25T14:11:38.182477Z","iopub.status.idle":"2021-06-25T14:11:38.433558Z","shell.execute_reply.started":"2021-06-25T14:11:38.182443Z","shell.execute_reply":"2021-06-25T14:11:38.43254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"fit and predict on this data and observe the outcome","metadata":{}},{"cell_type":"code","source":"probs,y_test=logistic(X_ran,y_ran)\nplot_pre_curve(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:12:11.645363Z","iopub.execute_input":"2021-06-25T14:12:11.64578Z","iopub.status.idle":"2021-06-25T14:12:11.838102Z","shell.execute_reply.started":"2021-06-25T14:12:11.645741Z","shell.execute_reply":"2021-06-25T14:12:11.837303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:12:19.173675Z","iopub.execute_input":"2021-06-25T14:12:19.174035Z","iopub.status.idle":"2021-06-25T14:12:19.298508Z","shell.execute_reply.started":"2021-06-25T14:12:19.174002Z","shell.execute_reply":"2021-06-25T14:12:19.297551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 10. under-sampling : Tomek links\n토멕링크(Tomek’s link)란 서로 다른 클래스에 속하는 한 쌍의 데이터를 뜻한다.이러한 가까운 한 쌍의 데이터를 찾은 다음 그 중에서 다수 클래스(majority class)에 속하는 데이터를 제거하는 방법이다. 이렇게 다수 클래스를 제거함으로써 데이터 불균형 문제도 어느정도 해결이되면서 동시에 두 클래스간의 거리가 멀어지기 때문에 분류 문제를 조금 더 수월하게 만들어 준다. 하지만 여전히 데이터 손실에 대한 문제를 가지고 있기 때문에 유의해야 한다.\n\nhttps://seing.tistory.com/53","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import TomekLinks\n\ntl = TomekLinks()\n\nX_tl, y_tl = tl.fit_resample(X,y)\n\nplot_2d_space(X_tl, y_tl,X,y, 'Tomek links under-sampling')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:20:36.50274Z","iopub.execute_input":"2021-06-25T14:20:36.503124Z","iopub.status.idle":"2021-06-25T14:20:36.95026Z","shell.execute_reply.started":"2021-06-25T14:20:36.503088Z","shell.execute_reply":"2021-06-25T14:20:36.949445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs,y_test=logistic(X_tl,y_tl)\nplot_pre_curve(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:20:46.663202Z","iopub.execute_input":"2021-06-25T14:20:46.663582Z","iopub.status.idle":"2021-06-25T14:20:46.863346Z","shell.execute_reply.started":"2021-06-25T14:20:46.663545Z","shell.execute_reply":"2021-06-25T14:20:46.862554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:20:53.454805Z","iopub.execute_input":"2021-06-25T14:20:53.455373Z","iopub.status.idle":"2021-06-25T14:20:53.677883Z","shell.execute_reply.started":"2021-06-25T14:20:53.455315Z","shell.execute_reply":"2021-06-25T14:20:53.675907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 11. over-sampling : SMOTE\n\n쉽게 설명하면, SMOTE는 k-nearest neighbour를 활용하여 소수 클래스(minority class)의 임의의 knn 데이터들을 추가하는 방법이다. 기존의 minority class 데이터들 사이를 보간하여 새로운 데이터를 추가하는 것이기 때문에 완전히 새로운 사례의 데이터의 예측에서는 취약할 수 있다.","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nX_sm, y_sm = smote.fit_resample(X, y)\n\nplot_2d_space(X_sm, y_sm,X,y, 'SMOTE over-sampling')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:25:03.622699Z","iopub.execute_input":"2021-06-25T14:25:03.623091Z","iopub.status.idle":"2021-06-25T14:25:03.91925Z","shell.execute_reply.started":"2021-06-25T14:25:03.623057Z","shell.execute_reply":"2021-06-25T14:25:03.918434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" fit and predict on this data and observe the outcome.","metadata":{}},{"cell_type":"code","source":"probs,y_test=logistic(X_sm,y_sm)\nplot_pre_curve(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:25:42.822287Z","iopub.execute_input":"2021-06-25T14:25:42.822671Z","iopub.status.idle":"2021-06-25T14:25:43.012453Z","shell.execute_reply.started":"2021-06-25T14:25:42.822635Z","shell.execute_reply":"2021-06-25T14:25:43.011671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc(y_test,probs)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:25:46.294958Z","iopub.execute_input":"2021-06-25T14:25:46.295296Z","iopub.status.idle":"2021-06-25T14:25:46.422804Z","shell.execute_reply.started":"2021-06-25T14:25:46.295264Z","shell.execute_reply":"2021-06-25T14:25:46.421722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### PR plot\nPrecision Recall Plot (이하 PR 그래프)의 경우도 ROC 와 유사한데, 주로 데이타 라벨의 분포가 심하게 불균등 할때 사용한데, 예를 들어 이상 거래 검출 시나리오의 경우 정상 거래의 비율이 비정상 거래에 비해서 압도적으로 많기 때문에 (98%, 2%) 이런 경우에는 ROC 그래프보다 PR 그래프가 분석에 더 유리하다. 그래프가 위쪽으로 갈수록 정확도가 높은 모델이고, ROC와 마찬가지로 PR 그래프의 AUC (면적)값을 이용하여 모델의 정확도를 평가할 수 있다. 그러면 모델이 쓸만한 모델인지 아닌지는 어떤 기준을 사용할까? ROC 그래프의 경우에는 Y=X 그래프를 기준으로 그래프 윗쪽에 있는 경우 쓸만한 모델로 판단을 했는데, PR 그래프의 경우 Base line이라는 것을 사용한다.\n\n\nhttps://bcho.tistory.com/1206 ","metadata":{}},{"cell_type":"markdown","source":"#### 12. ensemble algorithm techniques\nThe above section, deals with handling imbalanced data by resampling original data to provide balanced classes. In this section, we are going to look at an alternate approach i.e. Modifying existing classification algorithms to make them appropriate for imbalanced data sets. 즉 샘플링을 다시하는게 아니라, 분류 알고리즘 자체를 불균형 데이터셋에 맞게 변형해 본다는 것!\n\nThe main objective of ensemble methodology is to improve the performance of single classifiers. The approach involves constructing several two stage classifiers from the original data and then aggregate their prediction. 앙상블 방법론의 주요 목표는 단일 분류기의 성능을 개선하는 것이다. 여러 단일 분류기의 결과를 합쳐서 강한 분류기를 만든다. \n\n* XGBoost (Extreme Gradient Boosting) \n: 일반 Gradient boosting보다 10배 빠른 알고리즘이다. ","metadata":{}}]}