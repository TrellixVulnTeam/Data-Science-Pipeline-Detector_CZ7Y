{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">Introduction</div>\n\n## <b><span style='color:#5364B4'>1.1 | </span>Objective</b>\n\nIn this month's [TPS Competiton](https://www.kaggle.com/c/tabular-playground-series-mar-2022/overview), my goal is forecast 12 hours of traffic flow in a major US metropolis. The time series in this dataset are labelled with both location coordinates and a direction of travel â€“ a combination of spatio-temporal features within a highly dynamic traffic network. \n\n## <b><span style='color:#5364B4'>1.2 | </span>Data Overview</b>\nThe training data consists of six month's of traffic congestion levels in 20-minute intervals across a network of 65 roadways from April through September of 1991. The variables in the dataset include:\n- `time`: The 20-minute period in which each measurement was taken.\n- `x`: The East-West midpoint coordinate of the roadway.\n- `y`: The North-South midpoint coordinate of the roadway.\n- `direction`: The direction of travel of the roadway. EB indicates Eastbound travel, for example, while SW indicates a Southwest direction of travel.\n- `congestion`: Congestion levels for the roadway during each hour; the target. The congestion measurements have been normalized to the range 0 to 100.\n\nThe test set contains the roadway's coordinate location and direction of travel on the day of 1991-09-30.\n\n## <b><span style='color:#5364B4'>1.3 | </span>Descriptive Statistics</b>","metadata":{}},{"cell_type":"code","source":"import os, warnings\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode\nfrom datetime import datetime, timedelta\nfrom itertools import chain\nfrom scipy.stats import gaussian_kde\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom statsmodels.tsa.stattools import pacf, acf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.api import ExponentialSmoothing\nfrom lightgbm import LGBMRegressor\nwarnings.filterwarnings(\"ignore\")\ninit_notebook_mode(connected=True)\ntemp=dict(layout=go.Layout(font=dict(family=\"Franklin Gothic\", size=12), \n                           height=500, width=700))\n\ntrain=pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', \n                  parse_dates=['time'], index_col='row_id')\ntest=pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv', \n                 parse_dates=['time'], index_col='row_id')\nsub=pd.read_csv('../input/tabular-playground-series-mar-2022/sample_submission.csv')\n\nprint(\"There are {:,} rows and {} columns in the training set.\".format(train.shape[0], train.shape[1]))\nprint(\"The time series starts on {} and ends on {}.\\n\".format(train.time.min(), train.time.max()))\nprint(\"There are {:,} rows and {} columns in the test set.\".format(test.shape[0], test.shape[1]))\nprint(\"The time series starts on {} and ends on {}.\\n\".format(test.time.min(), test.time.max()))\n\n# Create time & direction variables\nfor df in [train, test]:\n    df['month'] = df['time'].dt.month\n    df['week'] = df['time'].dt.isocalendar().week\n    df['day_of_week'] = df['time'].dt.dayofweek+1\n    df['day'] = df['time'].dt.day\n    df['hour'] = df['time'].dt.hour\n    df['minute'] = df['time'].dt.minute\n    df['weekend'] = (df['day_of_week']>5).astype(int)\n    df['xydir'] = df.x.astype(str)+df.y.astype(str)+df.direction.astype(str)\n\ndisplay(train.describe().T.round(3).style.format('{:,.2f}')\n        .text_gradient(cmap='Greys_r')\n        .bar(color='#7784CB', axis=0, vmin=0)\n        .set_caption(\"Summary statistics of numeric columns\"))\nprint()\ncat=train.select_dtypes(include=['object']).columns.tolist()\nfor i in cat[:1]:\n    obs=train[i].value_counts()\n    avg_congest=train.groupby(i)['congestion'].mean()\n    df=pd.DataFrame({\"Number of Observations\":obs, \n                     \"Average Congestion\":avg_congest})\n    df.index.rename('Direction', inplace=True)\n    display(df.sort_values(by=\"Average Congestion\", ascending=False)\n            .style.background_gradient(cmap='cividis',subset=['Average Congestion'], vmin=20, vmax=54)\n            .format({\"Number of Observations\": \"{:,.0f}\", \"Average Congestion\": \"{:.1f}\"})\n            .set_caption(\"Summary statistics of categorical columns\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T00:48:16.605098Z","iopub.execute_input":"2022-03-30T00:48:16.605534Z","iopub.status.idle":"2022-03-30T00:48:25.718851Z","shell.execute_reply.started":"2022-03-30T00:48:16.605425Z","shell.execute_reply":"2022-03-30T00:48:25.71775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">Exploratory Data Analysis</div>","metadata":{}},{"cell_type":"code","source":"hist_data=train['congestion']\ndensity=gaussian_kde(dataset=hist_data, bw_method='silverman')\nx=np.arange(0,100) \ndensity.covariance_factor = lambda: .14  \ndensity._compute_covariance()\nkde_curve=density(x)\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=hist_data, histnorm='probability density', marker_color='#F4F4F4'))\nfig.add_trace(go.Scatter(x=x, y=kde_curve, marker_color='#6168CE', fill='tozeroy'))\nfig.update_traces(marker=dict(line=dict(width=1, color='#BDC3C7')), \n                  hovertemplate='%{y}<extra></extra>')\nfig.update_layout(template=temp, title=\"Distribution of Congestion\", \n                  xaxis_title=\"Congestion\", yaxis_title=\"Probability Densities\", showlegend=False)\nfig.show()\n\ncolors = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, 9)]\ndirection=train.groupby('direction')['congestion'].median().sort_values(ascending=False)\nname=['South Bound', 'North Bound', 'East Bound', 'West Bound', \n      'Southwest', 'Northeast', 'Southeast', 'Northwest']\nfig = go.Figure()\nfor i, name, col in zip(direction.index, name, colors):\n    plot_df=train[train.direction==i]\n    fig.add_trace(go.Box(y=plot_df['congestion'], name=name, boxmean=True, whiskerwidth=0.2, \n                         marker_size=2, line_width=1, marker_color=col, showlegend=False))\nfig.update_layout(template=temp, title=\"Distribution of Traffic Congestion<br>by Direction\",\n                  yaxis_title='Congestion', xaxis_tickangle=30)\nfig.show()\n\navg=train.groupby('time').congestion.mean()\nfig = px.line(avg, x=avg.index, y=avg.values)\nfig.update_traces(line=dict(width=1))\nfig.update_layout(template=temp, title=\"Average Congestion Levels from April - Sept 1991\", \n                  xaxis_title='', yaxis_title='Congestion', \n                  hovermode=\"x unified\")\nfig.show()\n\nweek=train.groupby('week').congestion.mean()\nweek_day=train.groupby('day_of_week').congestion.mean()\nday=train.groupby('day').congestion.mean()\nhr=train.groupby('hour').congestion.mean()\n\nfig = make_subplots(rows=2, cols=2, \n                    subplot_titles=(\"Average Congestion by Week\",\"Average Congestion by Week Day\", \n                                    \"Average Congestion by Day\",\"Average Congestion by Hour\"))\nfig.append_trace(go.Scatter(x=week.index, y=week, mode='lines', name='Congestion'), row=1,col=1)\nfig.append_trace(go.Scatter(x=week_day.index, y=week_day, mode='lines',name='Congestion'), row=1,col=2)\nfig.append_trace(go.Scatter(x=day.index, y=day, mode='lines',name='Congestion'), row=2,col=1)\nfig.append_trace(go.Scatter(x=hr.index, y=hr, mode='lines',name='Congestion'), row=2,col=2)\nfig.update_xaxes(showline=True, zeroline=False)\nfig.update_yaxes(showline=True, zeroline=False)\nfig.update_layout(template=temp, hovermode=\"x unified\", xaxis2_tickmode='linear', \n                  xaxis3=dict(tickmode='array', tickvals=[i for i in range(0,31,5)]),\n                  showlegend=False, height=800)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T00:48:25.720711Z","iopub.execute_input":"2022-03-30T00:48:25.720948Z","iopub.status.idle":"2022-03-30T00:48:30.794496Z","shell.execute_reply.started":"2022-03-30T00:48:25.72092Z","shell.execute_reply":"2022-03-30T00:48:30.79347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#5364B4'>2.1 | </span>EDA Summary</b>\n- The distribution of our target variable, `Congestion` is fairly normally distributed.\n- The four roadways, Southbound through Westbound, have the highest congestion levels overall with a median between 47 and 55, while the Southeast and Northwest regions have the lowest congestion levels, although there are more outliers in these regions.\n- The average values of the time series from April - Sept 1991 fluctuate widely but have remained at about the same level over time.\n- The weekly and daily congestion levels hover between 46-48, while there is a little more variation in the hourly and weekday congestion levels. On weekdays, the average congestion is around 49 and drops to about 44.7 on weekends. In addition, roadways are the least congested between the hours of 11pm and 6am and peak to an average of about 54 at 5pm.\n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">Time Series Components</div>\n\nTo help identify the seasonality and stationarity in the data, the graphs below show the weekly decomposition of each time series along with their Autocorrelation and Partial Autocorrelation Plots. ","metadata":{}},{"cell_type":"code","source":"direction=train.xydir.unique()[::3]\nfor i in direction: \n    \n    t=train[train.xydir==i].set_index('time')\n    a=pd.Series(acf(t.congestion, nlags=251)[1:])\n    p=pd.Series(pacf(t.congestion, nlags=251)[1:])\n    up_ci, low_ci = 2.58/np.sqrt(len(t)), -2.58/np.sqrt(len(t)) # 99% confidence \n    decomp = seasonal_decompose(t.congestion, model=\"additive\", period=504) # weekly decomp\n    \n    fig = make_subplots(rows=4, cols=2,\n                        specs=[[{}, {'rowspan': 2}], [{}, None],\n                               [{}, {'rowspan': 2}], [{}, None]],\n                        horizontal_spacing=0.07,\n                        subplot_titles=('', 'Autocorrelation Plot', '','',\n                                        'Partial Autocorrelation Plot',''))\n    \n    # ACF plot\n    for j in range(len(a)):\n        fig.add_shape(dict(type=\"line\", x0=j+1, x1=j+1, y0=0, y1=a[j], \n                           line_color=\"#555555\",opacity=0.45,line_width=1), \n                      row=1, col=2)\n    fig.append_trace(go.Scatter(x=a.index+1, y=a, mode='markers', \n                                marker_color='#3F51B5', marker_size=5,\n                                hovertemplate='Autocorrelation of Lag %{x} = %{y:.2f}<extra></extra>'), \n                     row=1,col=2)\n    \n    # PACF plot\n    for k in range(len(p)):\n        fig.add_shape(dict(type=\"line\", x0=k+1, x1=k+1, y0=0, y1=p[k], \n                           line_color=\"#555555\",opacity=0.45,line_width=1), \n                      row=3, col=2)\n    fig.append_trace(go.Scatter(x=p.index+1, y=p, mode='markers', \n                                marker_color='#3F51B5', marker_size=5,\n                                hovertemplate='Partial Autocorrelation of Lag %{x} = %{y:.2f}<extra></extra>'), \n                     row=3,col=2)\n    fig.add_hrect(y0=low_ci, y1=up_ci, fillcolor=\"#8A9DC5\", opacity=0.5, line_width=0) \n    \n    # Decomposition plots\n    fig.append_trace(go.Scatter(x=t.index, y=decomp.observed, line=dict(color='#4858BA',width=1),\n                                hovertemplate='%{x}<br>Observed: %{y}<extra></extra>'), row=1, col=1) \n    fig.append_trace(go.Scatter(x=t.index, y=decomp.trend, line=dict(color='#5AA68E'),\n                                hovertemplate='%{x}<br>Trend: %{y:.2f}<extra></extra>'), row=2, col=1)\n    fig.append_trace(go.Scatter(x=t.index, y=decomp.seasonal, line=dict(color='#3180BD',width=1),\n                                hovertemplate='%{x}<br>Seasonality = %{y:.2f}<extra></extra>'), row=3, col=1)\n    fig.append_trace(go.Scatter(x=t.index, y=decomp.resid, line=dict(color='#C86F7D',width=1),\n                                hovertemplate='%{x}<br>Residual = %{y:.2f}<extra></extra>'), row=4, col=1)\n    fig.update_xaxes(showline=True)\n    fig.update_layout(title=\"Time Series Decomposition of<br>Direction {}, Coordinates ({}, {})\".format(i[2:],i[0],i[1]),\n                      yaxis1=dict(title='Observed', showline=True), xaxis1_showline=False,\n                      xaxis2=dict(range=(-2,251.5), showline=False, zeroline=False, showgrid=False), \n                      yaxis3=dict(title='Trend',showline=True),\n                      yaxis4=dict(title='Seasonal',showline=True),\n                      xaxis5=dict(title='Lag', range=(-2,251.5), showline=False, zeroline=False, showgrid=False),\n                      yaxis6=dict(title='Residuals',showline=True),\n                      template=temp, showlegend=False, height=600)\n    fig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T00:48:30.795913Z","iopub.execute_input":"2022-03-30T00:48:30.79615Z","iopub.status.idle":"2022-03-30T01:15:38.340498Z","shell.execute_reply.started":"2022-03-30T00:48:30.796123Z","shell.execute_reply":"2022-03-30T01:15:38.339731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graphs above show the trend, seasonal, and residual components of each time series as well as their Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) Plots, which can be used to identify the seasonality and stationarity in the data. In the Seasonal graphs, we see a clear pattern with regularly spaced peaks and troughs occurring each week, indicating there is a weekly seasonality in the time series. The graphs of the trend, on the other hand, display irregular patterns that vary over time. We also see evidence of non-stationarity in the ACF and PACF plots. The lags in the Autocorrelation plots display sinusoidal patterns that are above the 99% confidence intervals shown in the blue bands along the $x$-axis, while the Partial Autocorrelation plots go to zero relatively quickly and then peak again at about every 72 lags. To reduce the trend and seasonality from the time series, I will take both the first weekly seasonal difference and the first non-seasonal difference of the congestion levels. This will create a new series where for every time interval, $t$, our congestion levels, $y$, become $y = (y_t-y_{t-504})-(y_{t-1}-y_{t-504-1})$, in which 504 represents the number of time periods in one week of our data in 20-minute intervals. Below are the graphs of the Autocorrelation and Partial Autocorrelation Functions of the differenced time series.\n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;letter-spacing:0.01px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Seasonal ACF &#38; PACF Plots</p></div>","metadata":{}},{"cell_type":"code","source":"for i in direction: \n    \n    t=train[train.xydir==i].set_index('time')\n    t['seasonal_diff']=t['congestion']-t['congestion'].shift(504)\n    t.dropna(inplace=True)\n    t['second_diff']=t['seasonal_diff']-t['seasonal_diff'].shift()\n    t.dropna(inplace=True)\n\n    a=pd.Series(acf(t.second_diff, nlags=75)[1:])\n    p=pd.Series(pacf(t.second_diff, nlags=75)[1:])\n    decomp = seasonal_decompose(t.second_diff, model=\"additive\", period=504)\n    up_ci, low_ci = 2.58/np.sqrt(len(t)), -2.58/np.sqrt(len(t))\n    \n    fig = make_subplots(rows=4, cols=2,\n                        specs=[[{}, {'rowspan': 2}], [{}, None],\n                               [{}, {'rowspan': 2}], [{}, None]],\n                        horizontal_spacing=0.07,\n                        subplot_titles=('', 'Autocorrelation Plot', '','',\n                                        'Partial Autocorrelation Plot',''))\n    \n    # ACF plot\n    for j in range(len(a)):\n        fig.add_shape(dict(type=\"line\", x0=j+1, x1=j+1, y0=0, y1=a[j], \n                           line_color=\"#555555\",opacity=0.5,line_width=1), \n                      row=1, col=2)\n    fig.append_trace(go.Scatter(x=a.index+1, y=a, mode='markers', \n                                marker_color='#3F51B5', marker_size=5,\n                                hovertemplate='Autocorrelation of Lag %{x} = %{y:.2f}<extra></extra>'), \n                     row=1,col=2)\n    \n    # PACF plot\n    for k in range(len(p)):\n        fig.add_shape(dict(type=\"line\", x0=k+1, x1=k+1, y0=0, y1=p[k], \n                           line_color=\"#555555\",opacity=0.5,line_width=1), \n                      row=3, col=2)\n    fig.append_trace(go.Scatter(x=p.index+1, y=p, mode='markers', \n                                marker_color='#3F51B5', marker_size=5,\n                                hovertemplate='Partial Autocorrelation of Lag %{x} = %{y:.2f}<extra></extra>'), \n                     row=3,col=2)\n    fig.add_hrect(y0=low_ci, y1=up_ci, fillcolor=\"#8A9DC5\", opacity=0.5, line_width=0) \n    \n    # Decomposition plots\n    fig.append_trace(go.Scatter(x=t.index, y=decomp.observed, line=dict(color='#4858BA',width=1),\n                                hovertemplate='%{x}<br>Observed: %{y}<extra></extra>'), row=1, col=1) \n    fig.append_trace(go.Scatter(x=t.index, y=decomp.trend, line=dict(color='#5AA68E'),\n                                hovertemplate='%{x}<br>Trend: %{y:.2f}<extra></extra>'), row=2, col=1)\n    fig.append_trace(go.Scatter(x=t.index, y=decomp.seasonal, line=dict(color='#3180BD',width=1),\n                                hovertemplate='%{x}<br>Seasonality = %{y:.2f}<extra></extra>'), row=3, col=1)\n    fig.append_trace(go.Scatter(x=t.index, y=decomp.resid, line=dict(color='#C86F7D',width=1),\n                                hovertemplate='%{x}<br>Residual = %{y:.2f}<extra></extra>'), row=4, col=1)\n    fig.update_xaxes(showline=True)\n    fig.update_layout(title=\"Weekly Seasonal Differenced Time Series of<br>Direction {}, Coordinates ({}, {})\".format(i[2:],i[0],i[1]),\n                      yaxis1=dict(title='Observed', showline=True), xaxis1_showline=False,\n                      xaxis2=dict(range=(0,75.5), showline=False, zeroline=False, showgrid=False), \n                      yaxis3=dict(title='Trend',showline=True),\n                      yaxis4=dict(title='Seasonal',showline=True),\n                      xaxis5=dict(title='Lag', range=(0,75.5), showline=False, zeroline=False, showgrid=False),\n                      yaxis6=dict(title='Residuals',showline=True),\n                      template=temp, showlegend=False, height=600)\n    fig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:15:38.343382Z","iopub.execute_input":"2022-03-30T01:15:38.34403Z","iopub.status.idle":"2022-03-30T01:18:48.98316Z","shell.execute_reply.started":"2022-03-30T01:15:38.343961Z","shell.execute_reply":"2022-03-30T01:18:48.981108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the decomposition plots of the seasonally differenced congestion levels, we see that most of the trend has been removed from the time series with a stabilized mean and data points that lie very close to the $x$-axis. The range of variance in the graphs of the seasonality has also notably decreased. Additionally, in the ACF and PACF plots of the differenced congestion levels, we see the lags in the Autocorrelation plots quickly go below the significance levels after about Lag 2, while the PACF tapers off more slowly. This pattern suggests a Moving Average process of order 2. To forecast the next 12 hours of traffic flow, I will try both a Moving Average model and experiment with adding an Autoregressive term to the model and compare the performance of each on the test set. \n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;letter-spacing:0.01px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Moving Average Forecast</p></div>\n\nBased on the ACF and PACF plots above, the first forecasting method I will try is a second-order Moving Average model using the first difference of the seasonally differenced congestion levels. Below is the 12-hour forecast of the predicted traffic levels on the test set. ","metadata":{}},{"cell_type":"code","source":"date=train.time.max()-timedelta(days=7)\nprev_week_df=train[train.time>date][['time','congestion']].set_index('time')\nprev_week_df=pd.DataFrame({'congestion':prev_week_df.groupby(prev_week_df.index)['congestion'].mean(), 'value':'Actual Values'})\n\ndef plot_forecast_dist(preds, test_df, title=\"\"): \n    \n    len_dir=len(preds)\n    len_pred=len(preds[0])\n    pred_list=list(chain(*zip(preds[i][j] for j in range(len_pred) for i in range(len_dir))))\n    pred_df=pd.DataFrame({'preds':pred_list}, index=test_df.time)\n    plot_df=pd.DataFrame({'forecast':pred_df.groupby(pred_df.index)['preds'].mean(), 'value':'Forecast'})\n    \n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=prev_week_df.index, y=prev_week_df.congestion, \n                             name='Actual Values', marker_color='#636EFA'))\n    fig.add_trace(go.Scatter(x=plot_df.index, y=plot_df.forecast, \n                             name='Forecast', marker_color='#EF553B'))\n    fig.update_layout(template=temp, title=title, \n                      xaxis_title='', yaxis_title='Congestion', \n                      hovermode=\"x unified\",\n                      legend=dict(orientation=\"v\", yanchor=\"bottom\", \n                                  y=1.09, xanchor=\"right\", x=.99, title=\"\"))\n    fig.show()\n    \n    # Histogram\n    hist_data=pred_df['preds']\n    density=gaussian_kde(dataset=hist_data, bw_method='silverman')\n    x=np.arange(0,100) \n    density.covariance_factor = lambda: .25 \n    density._compute_covariance()\n    kde_curve=density(x)\n\n    fig = go.Figure()\n    fig.add_trace(go.Histogram(x=hist_data, histnorm='probability density', marker_color='#F4F4F4'))\n    fig.add_trace(go.Scatter(x=x, y=kde_curve, marker_color='#6168CE', fill='tozeroy'))\n    fig.update_traces(marker=dict(line=dict(width=1, color='#BDC3C7')), \n                      hovertemplate='%{y}<extra></extra>')\n    fig.update_layout(template=temp, title=\"Distribution of Predictions\", \n                      xaxis_title=\"Congestion\", yaxis_title=\"Probability Densities\", showlegend=False)\n    fig.show()\n    \n    return pred_df\n\ndef plot_forecast(direction, train, preds): \n    \n    plot_df=train_df[train_df.index>='1991-09-12 00:00:00']\n    fig=go.Figure()\n    fig.add_trace(go.Scatter(x=plot_df.index, y=plot_df.congestion, name='Actual Values', marker_color='#636EFA'))\n    fig.add_trace(go.Scatter(x=inverse_df.index, y=inverse_df.diff_inv, name='Forecast', marker_color='#EF553B'))\n    fig.update_layout(template=temp, title=\"12-Hour Traffic Forecast of<br>Direction {}, Coordinates ({}, {})\"\\\n                      .format(direction[2:], direction[0], direction[1]), \n                      xaxis_title='', yaxis_title='Congestion', hovermode=\"x unified\",\n                      legend=dict(orientation=\"v\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=.99, title=\"\"))\n    fig.show()\n    \n\n# Moving Average model\nma_preds=[]\nfor i in train.xydir.unique():\n    \n    # Split the data\n    train_df=train[train.xydir==i].set_index('time')\n    test_df=test[test.xydir==i].set_index('time')\n    \n    # Create weekly seasonal differenced target\n    train_df['seasonal_diff']=train_df['congestion']-train_df['congestion'].shift(504)\n    train_df.dropna(inplace=True)\n    y_train=train_df[['seasonal_diff']]\n    inverse_df=train_df.copy()\n    \n    ma2=ARIMA(y_train, order=(0,1,2)).fit()\n    forecast=ma2.predict(start=len(y_train)+1,\n                         end=len(y_train)+len(test_df),\n                         dynamic=True)    \n    \n    # Inverse differenced predictions\n    forecast=pd.Series(forecast.values, name='congestion', index=test_df.index)\n    inverse_df=pd.concat([inverse_df['congestion'], forecast], axis=0).to_frame()\n    inverse_df['diff_inv']=inverse_df['congestion']+inverse_df['congestion'].shift(504)\n    inverse_df=inverse_df[inverse_df.index>='1991-09-30 12:00:00']\n    ma_preds.append(inverse_df.diff_inv.tolist()) \n    \n    # Forecasts for each direction\n    # plot_forecast(direction=i, train=train_df, preds=inverse_df)\n    \nres=plot_forecast_dist(preds=ma_preds, test_df=test, title='12-Hour Moving Average Forecast')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:18:48.984774Z","iopub.execute_input":"2022-03-30T01:18:48.985003Z","iopub.status.idle":"2022-03-30T01:21:14.014789Z","shell.execute_reply.started":"2022-03-30T01:18:48.984976Z","shell.execute_reply":"2022-03-30T01:21:14.013742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Predictions</span>","metadata":{}},{"cell_type":"code","source":"sub_ma2=sub.copy()\nsub_ma2['congestion']=np.array(res['preds']).round(0).astype(int)\nsub_ma2.to_csv('submission_ma2.csv', index=False)\nsub_ma2","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:21:14.016162Z","iopub.execute_input":"2022-03-30T01:21:14.016376Z","iopub.status.idle":"2022-03-30T01:21:14.042626Z","shell.execute_reply.started":"2022-03-30T01:21:14.016351Z","shell.execute_reply":"2022-03-30T01:21:14.041701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Test set MAE: 7.22</span>\n\n<br>\n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;letter-spacing:0.01px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">ARIMA</p></div>\n\nThe Moving Average model had a mean absolute error (MAE) of 7.22 on the test set. To try to improve the Moving Average forecast, I will add a second-order Autoregressive term, creating a seasonal Autoregressive Integrated Moving Average model in the order of ARIMA $(2,1,2)$ $(0,1,0)$ $_{504}$.","metadata":{}},{"cell_type":"code","source":"arima_preds=[]\nfor i in train.xydir.unique():\n    \n    # Split the data\n    train_df=train[train.xydir==i].set_index('time')\n    test_df=test[test.xydir==i].set_index('time')\n    \n    # Create weekly seasonal differenced target\n    train_df['seasonal_diff']=train_df['congestion']-train_df['congestion'].shift(504)\n    train_df.dropna(inplace=True)\n    y_train=train_df[['seasonal_diff']]\n    inverse_df=train_df.copy()\n    \n    # ARIMA ar(2) ma(2) \n    sarima=ARIMA(y_train, order=(2,1,2)).fit()\n    forecast=sarima.predict(start=len(y_train)+1,\n                            end=len(y_train)+len(test_df),\n                            dynamic=True)    \n    \n    # Inverse differenced predictions\n    forecast=pd.Series(forecast.values, name='congestion', index=test_df.index)\n    inverse_df=pd.concat([inverse_df['congestion'], forecast], axis=0).to_frame()\n    inverse_df['diff_inv']=inverse_df['congestion']+inverse_df['congestion'].shift(504)\n    inverse_df=inverse_df[inverse_df.index>='1991-09-30 12:00:00']\n    arima_preds.append(inverse_df.diff_inv.tolist()) \n    \n    # Forecasts for each direction\n    # plot_forecast(direction=i, train=train_df, preds=inverse_df)\n    \nres=plot_forecast_dist(preds=arima_preds, test_df=test, title='Seasonal ARIMA<br>12-Hour Traffic Forecast')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:21:14.044113Z","iopub.execute_input":"2022-03-30T01:21:14.044434Z","iopub.status.idle":"2022-03-30T01:30:41.540877Z","shell.execute_reply.started":"2022-03-30T01:21:14.044394Z","shell.execute_reply":"2022-03-30T01:30:41.540119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Predictions</span>","metadata":{}},{"cell_type":"code","source":"sub_arima=sub.copy()\nsub_arima['congestion']=np.array(res['preds']).round(0).astype(int)\nsub_arima.to_csv('submission_arima.csv', index=False)\nsub_arima","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:30:41.54232Z","iopub.execute_input":"2022-03-30T01:30:41.543424Z","iopub.status.idle":"2022-03-30T01:30:41.56583Z","shell.execute_reply.started":"2022-03-30T01:30:41.543358Z","shell.execute_reply":"2022-03-30T01:30:41.564975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Test set MAE: 6.95</span>\n<br>\n\nThe addition of a second-order Autoregressive term to the model was able to improve the forecast with a lower MAE of 6.95 on the test set.\n\n<br>\n\n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;letter-spacing:0.01px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Exponential Smoothing</p></div>\n\nThe next forecasting model I will try is Exponential Smoothing. Exponential Smoothing uses a weighted moving average method in which the weights decrease exponentially with time, giving a higher weight to more recent observations. Based on the time series decomposition plots of the trend and seasonality of the congestion levels, I will apply the Holt-Winter's additive method for the trend and seasonal components in the model. ","metadata":{}},{"cell_type":"code","source":"periods=[495,502,505,502,495,502,502,\n         501,1009,507,505,504,500,1005,\n         1009,505,500,500,501,500,505,\n         500,503,500,1005,500,504,499,497,\n         503,505,504,1003,505,505,504,\n         505,502,500,502,505,503,505,\n         1009,1009,1009,500,501,506,65,\n         499,496,498,504,502,505,506,505,\n         498,1009,502,501,502,1009,494]\n\nets_preds=[]\nfor direction, period in zip(train.xydir.unique(), periods):\n\n    X_train=train[train.xydir==direction].set_index('time')\n    X_test=test[test.xydir==direction].set_index('time')\n    y_train=X_train[X_train.index>='1991-09-01 00:00:00']['congestion']   \n    \n    ets = ExponentialSmoothing(y_train,\n                               trend='add', seasonal='add',\n                               seasonal_periods=period).fit()\n    forecast = ets.forecast(steps=len(X_test))\n    ets_preds.append(forecast.tolist())\n    \n    # Forecasts for each direction\n    # plot_forecast(direction=i, train=train_df, preds=inverse_df)\n    \nres=plot_forecast_dist(preds=ets_preds, test_df=test, title=\"12-Hour Traffic Forecast<br>with Exponential Smoothing\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:30:41.567034Z","iopub.execute_input":"2022-03-30T01:30:41.567269Z","iopub.status.idle":"2022-03-30T01:37:00.312267Z","shell.execute_reply.started":"2022-03-30T01:30:41.567243Z","shell.execute_reply":"2022-03-30T01:37:00.311137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Predictions</span>","metadata":{}},{"cell_type":"code","source":"sub_esm=sub.copy()\nsub_esm['congestion']=np.array(res['preds']).round(0).astype(int)\nsub_esm.to_csv(\"submission_esm.csv\", index=False)\nsub_esm","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:37:00.315029Z","iopub.execute_input":"2022-03-30T01:37:00.315277Z","iopub.status.idle":"2022-03-30T01:37:00.33572Z","shell.execute_reply.started":"2022-03-30T01:37:00.315247Z","shell.execute_reply":"2022-03-30T01:37:00.335089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Test set MAE: 7.401</span>\n<br>\n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;letter-spacing:0.01px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Gradient Boosting</p></div>\n\nTo see if I can improve the performance of the Time Series models, the last forecasting method I will try is Gradient Boosting.","metadata":{}},{"cell_type":"code","source":"scaler=MinMaxScaler(feature_range=(0,1))\ngbm_preds=[]\nfor i in train.xydir.unique():\n    \n    # Split the data\n    train_df=train[train.xydir==i].set_index('time')\n    test_df=test[test.xydir==i].set_index('time')\n    y_train=train_df.congestion\n\n    # Scale features\n    X_train=train_df.drop(['x','y','direction','congestion','xydir'], axis=1)\n    X_test=test_df.drop(['x','y','direction','xydir'], axis=1)\n    X_train=pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n    X_test=pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n\n    gbm=LGBMRegressor(boosting_type='gbdt', \n                      num_leaves=31, \n                      max_depth=-1, \n                      learning_rate=0.1, \n                      n_estimators=500,\n                      objective='mae',\n                      random_state=21)\n    gbm.fit(X_train, y_train)\n    gbm_pred=gbm.predict(X_test)\n    gbm_preds.append(gbm_pred.tolist())\n    \n    # Forecasts for each direction\n    # plot_forecast(direction=i, train=train_df, preds=inverse_df)\n    \nres=plot_forecast_dist(preds=gbm_preds, test_df=test, title=\"12-Hour Traffic Forecast<br>with Gradient Boosting\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:37:00.336666Z","iopub.execute_input":"2022-03-30T01:37:00.336909Z","iopub.status.idle":"2022-03-30T01:38:05.244094Z","shell.execute_reply.started":"2022-03-30T01:37:00.336883Z","shell.execute_reply":"2022-03-30T01:38:05.243104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Predictions</span>","metadata":{}},{"cell_type":"code","source":"sub_gbm=sub.copy()\nsub_gbm['congestion']=np.array(res['preds']).round(0).astype(int)\nsub_gbm.to_csv(\"submission_gbm.csv\", index=False)\nsub_gbm","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T01:38:05.245616Z","iopub.execute_input":"2022-03-30T01:38:05.246331Z","iopub.status.idle":"2022-03-30T01:38:05.268923Z","shell.execute_reply.started":"2022-03-30T01:38:05.246282Z","shell.execute_reply":"2022-03-30T01:38:05.267804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#4B5EB5'>Test set MAE: 5.20</span>\n<br>\n\n# <div style=\"color:white;display:fill;border-radius:5px;background-color:#6777C7;letter-spacing:0.01px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Conclusion</p></div>\n\nTo forecast traffic levels across 65 different roadways, three time series models were developed: a Moving Average, ARIMA, and Exponential Smoothing model. In the Moving Average and ARIMA models, the first difference of the weekly seasonally differenced congestion levels was taken to reduce the trend and seasonality in the data, and in the Exponential Smoothing model, Holt-Winter's additive method was used to account for the trend and seasonal components. Out of these three methods, the ARIMA model provided a more accurate forecast on the test set with a Mean Absolute Error of 6.95. The Gradient Boosting model was able to further improve on the traffic forecasts with the lowest test error overall of 5.2.\n\n## <p style='color:#4B5EB5;text-align:center'>Thank you for reading!<br>Please let me know if you have any questions and I look forward to any suggestions ðŸ™‚</p>\n\n### <b><span style='color:#4B5EB5'>References</span></b>\nHyndman, R.J., & Athanasopoulos, G. (2021) *Forecasting: principles and practice*, 3rd edition, OTexts: Melbourne, Australia. [OTexts.com/fpp3](https://otexts.com/fpp3/). ","metadata":{}}]}