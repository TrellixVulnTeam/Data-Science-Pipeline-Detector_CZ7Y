{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data and basic pre-processing","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv')\ndf_test  = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_date_features(df):\n    df['time']  = pd.to_datetime(df['time'])\n    df['day']   = df['time'].dt.dayofweek\n    df['month'] = df['time'].dt.month\n    df['hour']  = df['time'].dt.hour\n    df['week']  = df['time'].dt.isocalendar().week\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = add_date_features(df_train)\ndf_test  = add_date_features(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How does total congestion evolve on a weekly basis?","metadata":{}},{"cell_type":"code","source":"# Average congestion in a monthly basis\nweekly_grouped = df_train.groupby('week')['congestion'].mean().reset_index()\nfig, ax = plt.subplots(figsize=(15, 5))\nax.plot(weekly_grouped['week'], weekly_grouped['congestion'])\n\nax.set_ylabel('Average weekly total congestion')\nax.set_xlabel('Ordinal week')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weekly congestion average per road","metadata":{}},{"cell_type":"code","source":"# Average congestion in a monthly basis\ngrouped = df_train.groupby(['week', 'x', 'y'])['congestion'].mean().reset_index()\nfig, ax = plt.subplots(len(df_train['y'].unique()), len(df_train['x'].unique()), figsize=(30, 20))\n\nfor i, _y in enumerate(df_train['y'].unique()):\n    for j, _x in enumerate(df_train['x'].unique()):\n        \n        view = grouped[ (grouped['x'] == _x) & (grouped['y'] == _y) ]\n        \n        ax[i, j].plot(view['week'], view['congestion'])\n        ax[i, j].set_ylabel('Average weekly total congestion')\n        ax[i, j].set_xlabel('Ordinal week')\n        ax[i, j].set_title(f'Road (x, y): ({_x}, {_y})')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Seems like there is an unusual drop in the average for week 40\n* Particularly noticeable for road (1, 1), (1, 2),  (2, 1)","metadata":{}},{"cell_type":"markdown","source":"# Create week lag congestion features","metadata":{}},{"cell_type":"code","source":"print(df_train['x'].unique())\nprint(df_train['y'].unique())\nprint(df_train['direction'].unique())\n\n# create lagged congestion feature, probably a better way to do this....\n# unique x, y, direction pairings\nx_unique         = df_train['x'].unique()\ny_unique         = df_train['y'].unique()\ndirection_unique = df_train['direction'].unique()\n\nprint(f'Number of pairings: {len(x_unique) * len(y_unique) * len(direction_unique)}')\n\nnlags = 20\n\nlagged_dfs = []\n\n# this assigns a variable congestion_week_lag_n for the congestion value on the n-1th week\nfor _x in x_unique:\n    for _y in y_unique:\n        for _direction in direction_unique:\n            view = df_train[ (df_train['x'] == _x) & (df_train['y'] == _y) & (df_train['direction'] == _direction) ].copy(deep=True)\n            for i in range(nlags):\n                view[f'congestion_week_lag_{i+1}'] = view['congestion'].shift(i + 1)\n                lagged_dfs.append(view)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine lagged DFs together\n# concat them all together\ndf_train = pd.concat(lagged_dfs)\n\n# drop nans\ndf_train.dropna(inplace=True)\n#print(df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lag correlations","metadata":{}},{"cell_type":"code","source":"lags = ['congestion']\nlags.extend( ['congestion_week_lag_' + str(v+1) for v in range(nlags)] )\nlag_view = df_train[lags]\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\nsns.heatmap(lag_view.corr(), cmap=sns.color_palette(\"vlag\", as_cmap=True), square=True, ax=ax, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple BRT model","metadata":{}},{"cell_type":"code","source":"# map direction with cyclical representations\n# REF: https://www.kaggle.com/inversion/tps-mar-22-cyclical-features\nfrom math import sin, cos, pi\n\nsin_vals = {\n    'NB': 0.0,\n    'NE': sin(1 * pi/4),\n    'EB': 1.0,\n    'SE': sin(3 * pi/4),\n    'SB': 0.0,\n    'SW': sin(5 * pi/4),    \n    'WB': -1.0,    \n    'NW': sin(7 * pi/4),  \n}\n\ndf_train['sin'] = df_train['direction'].map(sin_vals)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(df_train.columns)\ntraining = df_train[\n    [\n        'x',\n        'y',\n        'day',\n        'hour',\n        'congestion_week_lag_1',\n        'sin'\n    ]\n]\nprint(training)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train/test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(training, df_train['congestion'], test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# hyperparameter tuning","metadata":{}},{"cell_type":"markdown","source":"## Search space","metadata":{}},{"cell_type":"code","source":"# defining search space\nfrom hyperopt import hp\n#mln = [v + 1 for v in range(1, 20)]\n#mln.append(None)\n#print(mln)\n\nparams = {\n    'n_estimators'   : hp.quniform('n_estimators', 25, 50, 5),\n    'max_depth'      : hp.quniform('max_depth', 1, 20, 2),\n    #'max_leaf_nodes' : hp.choice('max_leaf_nodes', mln),\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Objective function","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom hyperopt import STATUS_OK\n\ndef objective(params):\n    global X_train, y_train, X_test, y_test\n    \n    print(f'Running with {params}')\n    \n    params['n_estimators']   = int(params['n_estimators'])\n    params['max_depth']      = int(params['max_depth'])\n    \n    \"\"\"if params['max_leaf_nodes'] is not None:\n        params['max_leaf_nodes'] = int(params['max_leaf_nodes'])\n\"\"\"    \n    # fit model\n    model = XGBRegressor(**params, random_state=42, verbosity=2, tree_method='hist')\n    #model = GradientBoostingRegressor(**params, random_state=42)\n    #model = RandomForestRegressor(**params, random_state=42)\n    model.fit(X_train, y_train)\n    \n    # make predictions with fitted model\n    y_pred = model.predict(X_test)\n    \n    print(f'Loss: {mean_absolute_error(y_pred, y_test)}')\n    \n    # return metrics\n    return {\n        'loss'     : mean_absolute_error(y_pred, y_test),\n        'status'   : STATUS_OK,\n        'RMSE'     : mean_squared_error(y_pred, y_test, squared=False)\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run trials","metadata":{}},{"cell_type":"code","source":"\"\"\"from hyperopt import fmin, tpe, Trials\n\ntrials = Trials()\nbest = fmin(objective,\n            space = params,\n            algo = tpe.suggest,\n            max_evals = 50,\n            trials = trials)\nprint(best)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking with cross validation","metadata":{}},{"cell_type":"code","source":"\"\"\"from sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor(max_depth=18, n_estimators=45, tree_method='hist')\n\nscores = cross_val_score(model,\n                         X_train,\n                         y_train,\n                         cv = 5,\n                         scoring = 'neg_mean_absolute_error',\n                         verbose = 1)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"print(np.mean(scores))\nprint(np.std(scores))\"\"\"\n#-4.737009782253329\n#0.005871818057510222","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting model on all training data","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\n#model = XGBRegressor(max_depth=16, n_estimators=25, tree_method='hist', verbosity=2)\nmodel = XGBRegressor(max_depth=18, n_estimators=45, tree_method='hist', verbosity=2)\nmodel.fit(training, df_train['congestion'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing test data","metadata":{}},{"cell_type":"code","source":"# prepare testing data\ndf_test['congestion_week_lag_1'] = np.nan\ndf_test['sin'] = df_test['direction'].map(sin_vals)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating 1 week lags\n#print(df_train.head())\ndf_lagged = df_train.copy(deep=True)\ndf_lagged['time'] = df_lagged['time'] + dt.timedelta(days=7)\ndf_lagged = df_lagged[['x', 'y', 'direction', 'time', 'congestion']]\n#print(df_lagged.head())\ndf_lagged = df_lagged[ ['time', 'x', 'y', 'congestion', 'direction'] ]\ndf_lagged = df_lagged.rename(columns={'congestion' : 'congestion_week_lag_1'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# really hacky way to set the lag values, this REALLY needs fixing\ntesting = df_test.merge(df_lagged, on=['time', 'x', 'y', 'direction'], how='inner')\ntesting = testing[ testing['row_id'].isin(df_test['row_id']) ]\ntesting = testing.drop_duplicates()\nprint(testing)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping columns not needed\ntesting.drop(['time', 'month', 'week', 'direction', 'congestion_week_lag_1_x'], axis=1, inplace=True)\ntesting = testing.rename(columns={'congestion_week_lag_1_y' : 'congestion_week_lag_1'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rearrange columns for model evaluation\ntesting = testing.reindex(columns=training.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testing.head())\nprint(len(testing))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate test data","metadata":{}},{"cell_type":"code","source":"pred = model.predict(testing)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-mar-2022/sample_submission.csv')\nsubmission['congestion'] = pred\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}