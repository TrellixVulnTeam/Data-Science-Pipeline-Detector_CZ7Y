{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Simple solution with any machine learning\n\nInspired by some discussions in the forum this notebook tries to solve the competition using a simple solution: Calculate the mean congestion value for each time stamp and use this value for the prediction. I will create the mean congestion values in the training data set, group the data by the columns 'x','y','direction', 'day_of_week','hour', 'minute'. Afterthat this mean congestion value wil be added to the test data set. As the mean value i use the arithmetic, the geometric mean and the median value. \n\nI also add the idea from huseyincotel and his notebook https://www.kaggle.com/huseyincot/without-machine-learning-pick-the-means to get the best congestion value for each row: calculate the absolute difference between the real congestion value and the different mean values. The mean value with the lowest difference is used for the submission then.\n\nThanks https://www.kaggle.com/wti200 for the idea of Geometric and Harmonic means.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport holidays\n\nimport seaborn as sns\n\nfrom fastai.imports import *\nfrom fastai.tabular.core import *\nfrom scipy.stats.mstats import gmean\nfrom sklearn.metrics import mean_absolute_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-17T10:37:04.059286Z","iopub.execute_input":"2022-03-17T10:37:04.059946Z","iopub.status.idle":"2022-03-17T10:37:04.065611Z","shell.execute_reply.started":"2022-03-17T10:37:04.059912Z","shell.execute_reply":"2022-03-17T10:37:04.064818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('../input/tabular-playground-series-mar-2022')\nPath.BASE_PATH = path\npath.ls()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:04.067258Z","iopub.execute_input":"2022-03-17T10:37:04.067456Z","iopub.status.idle":"2022-03-17T10:37:04.080031Z","shell.execute_reply.started":"2022-03-17T10:37:04.067432Z","shell.execute_reply":"2022-03-17T10:37:04.078924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(path, 'train.csv')).set_index(\"row_id\")\ntest_df = pd.read_csv(os.path.join(path, 'test.csv')).set_index(\"row_id\")\nsample_submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n\ndep_var = 'congestion'\ndate_var = 'time'","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:04.082357Z","iopub.execute_input":"2022-03-17T10:37:04.083161Z","iopub.status.idle":"2022-03-17T10:37:04.51066Z","shell.execute_reply.started":"2022-03-17T10:37:04.083119Z","shell.execute_reply":"2022-03-17T10:37:04.509796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:04.512068Z","iopub.execute_input":"2022-03-17T10:37:04.512373Z","iopub.status.idle":"2022-03-17T10:37:04.52278Z","shell.execute_reply.started":"2022-03-17T10:37:04.512344Z","shell.execute_reply":"2022-03-17T10:37:04.521978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following function are used to add extendeded feature like the minute,hour, day of week,etc to the data sets. I use this feature later to group the data or to select a subset of the provided training data.","metadata":{}},{"cell_type":"code","source":"def add_holiday_info(df):\n    \n    make_date(df, date_var)\n     \n    us_holidays = []\n    for x in holidays.UnitedStates(years=1991).items():\n        us_holidays.append(str(x[0]))\n    \n    df['is_holiday'] = [1 if str(val).split()[0] in us_holidays else 0 for  val in df[date_var].dt.date]\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:04.523911Z","iopub.execute_input":"2022-03-17T10:37:04.524143Z","iopub.status.idle":"2022-03-17T10:37:04.532957Z","shell.execute_reply.started":"2022-03-17T10:37:04.524089Z","shell.execute_reply":"2022-03-17T10:37:04.532181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = add_holiday_info(train_df)\ntest_df = add_holiday_info(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:04.535245Z","iopub.execute_input":"2022-03-17T10:37:04.535724Z","iopub.status.idle":"2022-03-17T10:37:06.146062Z","shell.execute_reply.started":"2022-03-17T10:37:04.535694Z","shell.execute_reply":"2022-03-17T10:37:06.14527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_time_features(df):\n    \n    make_date(df, date_var)\n    \n    date_field = df[date_var] \n    \n    df['day_of_week'] = date_field.dt.dayofweek\n    df['day_of_year'] = date_field.dt.dayofyear - 1\n    \n    df['month'] = date_field.dt.month \n    df['hour'] = date_field.dt.hour \n    df['minute'] = date_field.dt.minute \n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.14715Z","iopub.execute_input":"2022-03-17T10:37:06.147496Z","iopub.status.idle":"2022-03-17T10:37:06.152697Z","shell.execute_reply.started":"2022-03-17T10:37:06.147465Z","shell.execute_reply":"2022-03-17T10:37:06.151828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = add_time_features(train_df)\ntest_df = add_time_features(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.154041Z","iopub.execute_input":"2022-03-17T10:37:06.154432Z","iopub.status.idle":"2022-03-17T10:37:06.571483Z","shell.execute_reply.started":"2022-03-17T10:37:06.154391Z","shell.execute_reply":"2022-03-17T10:37:06.570774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function calculates the different congestion mean values and the absolut differences of the traing data and add these new features to the trainging and test data set.","metadata":{}},{"cell_type":"code","source":"def add_congestion_stats(df1, df2):\n\n    tmp_df = df1.reset_index()\n    keys = ['x','y','direction', 'day_of_week','hour', 'minute']\n\n    df = tmp_df.groupby(by=keys)[dep_var].mean().reset_index().set_index(keys)\n    df['congestion_mean'] = df['congestion']\n    df1 = df1.merge(df['congestion_mean'], how='left', left_on=keys, right_on=keys)\n    df2 = df2.merge(df['congestion_mean'], how='left', left_on=keys, right_on=keys)\n\n    df = tmp_df.groupby(by=keys)[dep_var].median().reset_index().set_index(keys)\n    df['congestion_median'] = df['congestion']\n    df1 = df1.merge(df['congestion_median'], how='left', left_on=keys, right_on=keys)\n    df2 = df2.merge(df['congestion_median'], how='left', left_on=keys, right_on=keys)\n    \n    df = tmp_df.groupby(by=keys)[dep_var].apply(gmean).reset_index().set_index(keys)\n    df['congestion_geo_mean'] = df['congestion']\n    df1 = df1.merge(df['congestion_geo_mean'], how='left', left_on=keys, right_on=keys)\n    df2 = df2.merge(df['congestion_geo_mean'], how='left', left_on=keys, right_on=keys)\n    \n    df1[\"mae_mean\"] = np.abs(df1[dep_var] - df1[\"congestion_mean\"])\n    df2[\"mae_mean\"] = np.abs(df1[dep_var] - df2[\"congestion_mean\"])\n    \n    df1[\"mae_median\"] = np.abs(df1[dep_var] - df1[\"congestion_median\"])\n    df2[\"mae_median\"] = np.abs(df1[dep_var] - df2[\"congestion_median\"])\n    \n    df1[\"mae_geo_mean\"] = np.abs(df1[dep_var] - df1[\"congestion_geo_mean\"])\n    df2[\"mae_geo_mean\"] = np.abs(df1[dep_var] - df2[\"congestion_geo_mean\"])\n    \n    return df1, df2\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.572668Z","iopub.execute_input":"2022-03-17T10:37:06.573365Z","iopub.status.idle":"2022-03-17T10:37:06.585499Z","shell.execute_reply.started":"2022-03-17T10:37:06.573327Z","shell.execute_reply":"2022-03-17T10:37:06.584507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select only Monday data from the passed dataframe. I can limit the selection to p.m. values and/or holidays","metadata":{}},{"cell_type":"code","source":"def get_all_mondays(df, is_holiday=0, only_pm_values = False):\n    \n    mask = (df['day_of_week'] == 0) &  (df['is_holiday'] == is_holiday)\n    if only_pm_values:\n        mask = mask & (df['hour'] >11)\n\n    return df[mask]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.586884Z","iopub.execute_input":"2022-03-17T10:37:06.587329Z","iopub.status.idle":"2022-03-17T10:37:06.600212Z","shell.execute_reply.started":"2022-03-17T10:37:06.587286Z","shell.execute_reply":"2022-03-17T10:37:06.599471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select only Mondays in September 1991","metadata":{}},{"cell_type":"code","source":"def get_september_mondays(df, only_pm_values = False):\n    \n    mask = (df['day_of_week'] == 0) &  (df['month'] == 9)\n    if only_pm_values:\n        mask = mask & (df['hour'] >11)\n    \n    return df[mask]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.601219Z","iopub.execute_input":"2022-03-17T10:37:06.601569Z","iopub.status.idle":"2022-03-17T10:37:06.610706Z","shell.execute_reply.started":"2022-03-17T10:37:06.601525Z","shell.execute_reply":"2022-03-17T10:37:06.609934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select the proper training data set","metadata":{}},{"cell_type":"code","source":"training_df = get_all_mondays(train_df, only_pm_values=False)\n# training_df = get_september_mondays(train_df, only_pm_values=False)\n\ntraining_df['day_of_year'].min(), training_df['day_of_year'].max()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.612807Z","iopub.execute_input":"2022-03-17T10:37:06.613048Z","iopub.status.idle":"2022-03-17T10:37:06.681452Z","shell.execute_reply.started":"2022-03-17T10:37:06.613021Z","shell.execute_reply":"2022-03-17T10:37:06.680907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_df, test_df = add_congestion_stats(training_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:06.682579Z","iopub.execute_input":"2022-03-17T10:37:06.682808Z","iopub.status.idle":"2022-03-17T10:37:07.112288Z","shell.execute_reply.started":"2022-03-17T10:37:06.682781Z","shell.execute_reply":"2022-03-17T10:37:07.111602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function returns the lowest mean congstion value","metadata":{}},{"cell_type":"code","source":"def get_best_congestion(row):\n\n    ret_val = row['congestion_mean']\n    \n    if row['mae_median'] < row['mae_geo_mean'] and row['mae_median'] < row['mae_mean']:\n        ret_val= row['congestion_median']\n    elif row['mae_geo_mean'] < row['mae_mean']:\n        ret_val= row['congestion_geo_mean'] \n    \n    if ret_val == 0:\n        ret_val = row['congestion_mean']\n    return ret_val","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.113445Z","iopub.execute_input":"2022-03-17T10:37:07.114001Z","iopub.status.idle":"2022-03-17T10:37:07.118605Z","shell.execute_reply.started":"2022-03-17T10:37:07.113969Z","shell.execute_reply":"2022-03-17T10:37:07.118038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.119533Z","iopub.execute_input":"2022-03-17T10:37:07.119968Z","iopub.status.idle":"2022-03-17T10:37:07.142236Z","shell.execute_reply.started":"2022-03-17T10:37:07.119937Z","shell.execute_reply":"2022-03-17T10:37:07.141232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[dep_var] = test_df.apply(lambda row: get_best_congestion(row), axis=1)\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.143336Z","iopub.execute_input":"2022-03-17T10:37:07.144086Z","iopub.status.idle":"2022-03-17T10:37:07.397853Z","shell.execute_reply.started":"2022-03-17T10:37:07.144049Z","shell.execute_reply":"2022-03-17T10:37:07.397115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,6))\nsns.lineplot(data = test_df , x =\"time\",  y = sample_submission[dep_var], label = dep_var, ci=None)\nplt.title(\"The predictions\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.39893Z","iopub.execute_input":"2022-03-17T10:37:07.399126Z","iopub.status.idle":"2022-03-17T10:37:07.638723Z","shell.execute_reply.started":"2022-03-17T10:37:07.399102Z","shell.execute_reply":"2022-03-17T10:37:07.637887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's do the 'special value' handling","metadata":{}},{"cell_type":"code","source":"sample_submission = sample_submission.set_index('row_id', drop=False)\nsample_submission.loc[[848891,848956,848956,849021,849151,849216,849281,849346,849411]]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.639766Z","iopub.execute_input":"2022-03-17T10:37:07.639985Z","iopub.status.idle":"2022-03-17T10:37:07.650814Z","shell.execute_reply.started":"2022-03-17T10:37:07.63996Z","shell.execute_reply":"2022-03-17T10:37:07.649461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.loc[[848891,848956,848956,849021,849151,849216,849281,849346,849411],dep_var] = 20\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.653138Z","iopub.execute_input":"2022-03-17T10:37:07.653667Z","iopub.status.idle":"2022-03-17T10:37:07.666017Z","shell.execute_reply.started":"2022-03-17T10:37:07.653624Z","shell.execute_reply":"2022-03-17T10:37:07.665133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.loc[[848891,848956,848956,849021,849151,849216,849281,849346,849411]]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.667034Z","iopub.execute_input":"2022-03-17T10:37:07.667237Z","iopub.status.idle":"2022-03-17T10:37:07.678999Z","shell.execute_reply.started":"2022-03-17T10:37:07.667214Z","shell.execute_reply":"2022-03-17T10:37:07.677966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -la","metadata":{"execution":{"iopub.status.busy":"2022-03-17T10:37:07.68067Z","iopub.execute_input":"2022-03-17T10:37:07.680973Z","iopub.status.idle":"2022-03-17T10:37:08.474076Z","shell.execute_reply.started":"2022-03-17T10:37:07.680943Z","shell.execute_reply":"2022-03-17T10:37:08.473178Z"},"trusted":true},"execution_count":null,"outputs":[]}]}