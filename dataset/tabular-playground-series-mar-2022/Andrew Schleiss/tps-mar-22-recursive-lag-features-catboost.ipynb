{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## To do \n* Optimize LightGBM \n* Feature engineering \n* different shift and rolling timeframe\n* different shift and rolling measures (mean, median, std)  --remove rolling/shift\n* Resample! \n\n### Done \n\n1. recursive CSV","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\nfrom optuna.samplers import TPESampler\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, TimeSeriesSplit, KFold, train_test_split\nfrom sklearn.metrics import mean_absolute_error, r2_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SCALER_NAME = \"None\" \n# SCALER = MinMaxScaler() \n\nEPOCHS = 10000     \nEARLY_STOPPING = 30\n\nFOLDS = 5\n\n#predict only monday data\nPRED_MONDAY = False\n\nLAG_FEATURES = True\n\nsns.set(font_scale = 1)\n\nOPTUNA = True\nTASK = \"GPU\"  #GPU","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_original = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\", index_col = 0)\ntest_original = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\", index_col = 0)\nsubmission = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\", index_col = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def basic_feats(df):\n    df= df.copy(deep = True)\n    \n    df[\"time\"] = pd.to_datetime(df[\"time\"])\n    df[\"dir_x_y\"] = df['x'].astype('str') + df['y'].astype('str')+ df['direction']\n    #df.drop([\"x\",\"y\",\"direction\"],axis =1 , inplace = True)\n    \n    df[\"minute\"] = df[\"time\"].dt.minute\n    df[\"hour\"] = df[\"time\"].dt.hour    \n    df[\"day\"] = df[\"time\"].dt.day\n    df[\"month\"] = df[\"time\"].dt.month\n    df[\"dayofweek\"]= df[\"time\"].dt.weekday\n    \n    #New features\n    df[\"x+y\"] = df[\"x\"]+df[\"y\"]\n    df['x_y'] = df['x'].astype('str') + df['y'].astype('str')\n    df['hour_direction'] = df['hour'].astype('str') + df['direction'].astype('str')\n    \n    #df['afternoon'] = (df['time'].dt.hour > 12).astype('int')\n    #df['dayofyear'] = df['time'].dt.dayofyear\n    #df['inverse_dayofyear'] = 365 - df['time'].dt.dayofyear\n    \n    return df \n\ntrain = basic_feats(train_original)\ntest = basic_feats(test_original)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PRED_MONDAY:\n    #only predict monday\n    print(\"Predicting Monday only\")\n    train[train[\"dayofweek\"]==0].reset_index(drop= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scaling ","metadata":{}},{"cell_type":"code","source":"num_col = []\nfor col in train.columns:\n    if train[col].dtypes != \"object\" and col != \"congestion\" and col !=\"time\":\n        num_col.append(col)\n        \nscaler = StandardScaler()\ntrain[num_col] = scaler.fit_transform(train[num_col])\ntest[num_col] = scaler.transform(test[num_col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rolling & Lag Features ","metadata":{}},{"cell_type":"code","source":"shift_list = [1 \n              ,2,3,4, 8\n             ]\nroll_window = [4,8, 12]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shift_vals(df, shift_list, groupby):\n    df = df.copy(deep = True)\n    \n    for i in shift_list:\n        #df[f\"shift_{i}\"]  = df.groupby(groupby)['congestion'].shift(1, fill_value=0)\n        df[f\"shift_{i}\"] = df.groupby(groupby)['congestion'].transform(lambda s: s.shift(i, fill_value=0))\n    return df\n\ntrain = shift_vals(train,shift_list,groupby= 'dir_x_y')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rolling(df, roll_window, groupby):\n    df = df.copy(deep = True)\n    \n    for i in roll_window:\n        df[f\"rolling_mean_{i}\"] = df.groupby(groupby)['shift_1'].transform(lambda s: s.rolling(i, min_periods=1).mean())\n        df[f\"rolling_median_{i}\"] = df.groupby(groupby)['shift_1'].transform(lambda s: s.rolling(i, min_periods=1).median())\n        df[f\"rolling_std_{i}\"] = df.groupby(groupby)['shift_1'].transform(lambda s: s.rolling(i, min_periods=1).std())\n    return df.fillna(0)\n\ntrain = rolling(train,roll_window, groupby= 'dir_x_y')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check \ntrain[train[\"dir_x_y\"]==\"00EB\"].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding \n### Assumption \nThere is a relationship in the direction of the highways \\\ni.e. EB highway becomes NB at some point therefore NB is affected by EB's congestion \n\nI cant seem to find a way to identify this relationship at this time, I therefore will apply **2 types of encodings** on the data: \n* LabelEncoder - to identify any sort of relationship (albet a poor one) \n* Onehotencoder - categorical engineering ","metadata":{}},{"cell_type":"code","source":"# label encoder\n# encoder = LabelEncoder()\n# train[\"dir_x_y_LE\"] = encoder.fit_transform(train[\"dir_x_y\"])\n# test [\"dir_x_y_LE\"] = encoder.transform(test[\"dir_x_y\"])\n\n# #Onehot\n# # have to concatenate as test does not include all the feats as train \n# all_df = pd.concat([train.assign(ds=1),test.assign(ds=0)],axis =0)\n# all_df = pd.get_dummies(all_df)\n# test = all_df[all_df[\"ds\"]==0].drop([\"congestion\",\"ds\"],axis =1)\n# train = all_df[all_df[\"ds\"]==1].drop([\"ds\"],axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \nfor col in str_list:\n    encoder = LabelEncoder()\n    encoder.fit(train[col])\n    train[col] = encoder.transform(train[col])\n\n    for label in np.unique(test[col]):\n        if label not in encoder.classes_: \n            encoder.classes_ = np.append(encoder.classes_, label) \n    test[col] = encoder.transform(test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split ","metadata":{}},{"cell_type":"code","source":"X = train.drop([\"congestion\",\"time\"],axis =1 )\ny = train[\"congestion\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nfeatures = train.drop([\"time\",\"congestion\"],axis=1).columns \nprint(len(features))\nprint([col for col in features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnumeric_cols = train.columns[(train.dtypes != 'object') & (train.columns != 'congestion') & (train.columns != 'time')]\nX_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\nX_test[numeric_cols] = scaler.transform(X_test[numeric_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna ","metadata":{}},{"cell_type":"code","source":"import optuna \ndef objective(trial):\n    params = {\n        \"random_state\":trial.suggest_categorical(\"random_state\", [2022]),\n        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.0001, 0.3),\n        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n        \"n_estimators\": 1000,\n        \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n        'random_strength' :trial.suggest_int('random_strength', 0, 100),\n        \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n        'task_type': trial.suggest_categorical('task_type', [TASK]),\n        'loss_function': trial.suggest_categorical('loss_function', ['MAE']),\n        'eval_metric': trial.suggest_categorical('eval_metric', ['MAE'])\n    }\n\n    model = CatBoostRegressor(**params)\n    X_train_tmp, X_valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n    model.fit(\n        X_train_tmp, y_train_tmp,\n        eval_set=[(X_valid_tmp, y_valid_tmp)],\n        early_stopping_rounds=35, verbose=0\n    )\n        \n    y_train_pred = model.predict(X_train_tmp)\n    y_valid_pred = model.predict(X_valid_tmp)\n    train_mae = mae(y_train_tmp, y_train_pred)\n    valid_mae = mae(y_valid_tmp, y_valid_pred)\n    \n    print(f'MAE of Train: {train_mae}')\n    print(f'MAE of Validation: {valid_mae}')\n    \n    return valid_mae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRIALS = 100\nTIMEOUT = 3600\n\n\nif OPTUNA:\n    sampler = TPESampler(seed=42)\n\n    study = optuna.create_study(\n        study_name = 'cat_parameter_opt',\n        direction = 'minimize',\n        sampler = sampler,\n    )\n    study.optimize(objective, n_trials=TRIALS)\n    print(\"Best Score:\",study.best_value)\n    print(\"Best trial\",study.best_trial.params)\n    \n    best_params = study.best_params\n    \n    X_train_tmp, X_valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n    model_tmp = CatBoostRegressor(**best_params, n_estimators=30000, verbose=1000).fit(X_train_tmp, y_train_tmp, eval_set=[(X_valid_tmp, y_valid_tmp)], early_stopping_rounds=35)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"  \ndef fit_model(X_train,y_train,X_test,y_test,test_df=None):\n    \n    if OPTUNA:\n        model = CatBoostRegressor(**best_params, n_estimators=model_tmp.get_best_iteration(), verbose=1000).fit(X_train, y_train)\n    else:\n        model = CatBoostRegressor(\n            verbose=1000,\n            early_stopping_rounds=10,\n            random_seed=2022,\n            max_depth=12,\n            task_type='GPU',\n            learning_rate=0.035,\n            iterations=30000,\n            loss_function='MAE',\n            eval_metric= 'MAE'\n        ).fit(X_train, y_train)\n    \n    train_preds =model.predict(X_test) \n    \n    #predict test data\n    if test_df is None:\n        test_preds = []\n    else:\n        test_preds = model.predict(test_df)\n    \n    mae = mean_absolute_error(y_test, train_preds)\n    print(\"\\nMAE:\", mae)\n    print(\"r2: \",r2_score(y_test, train_preds)) \n    \n    return train_preds, test_preds, mae, model\n\ntrain_preds, test_preds, mae ,model= fit_model(X_train, y_train, X_test, y_test, None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV ","metadata":{}},{"cell_type":"code","source":"kfold = KFold(n_splits= FOLDS,shuffle = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_val(X,y, test):\n    \n    test_predictions = []\n    lgb_scores = []\n\n    for idx, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n\n        print(\"\\n\",10*\"=\", f\"Fold={idx+1}\", 10*\"=\")\n\n        X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx,]\n        X_valid, y_val = X.iloc[val_idx,:], y.iloc[val_idx,]\n        \n        train_preds, test_preds, mae ,model= fit_model(X_train[features], y_train, X_valid[features], y_val, test)                          \n                                                       \n        lgb_scores.append(mae)\n        test_predictions.append(test_preds)\n        \n        del X_valid\n        del y_val\n\n    print(\"Mean Validation MAE :\", np.mean(lgb_scores))\n    return test_predictions\n\n#test_predictions = cross_val(X,y, test= None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission[\"congestion\"] = np.round(np.mean(test_predictions, axis =0))\n# submission.to_csv(\"submission_ml.csv\")\n\n# plt.figure(figsize = (20,8))\n# sns.lineplot(data = train.iloc[-8000:], x = train.iloc[-8000:].index.date,  y = \"congestion\", label = \"actual\")\n# sns.lineplot(x = test.index.date,  y = submission[\"congestion\"], label = \"predicted\")\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recursive ","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\",index_col=0)\n\nFREQUENCY = 20 #prediction interval in minutes\n\nstart_date = min(test[\"time\"]) \nend_date = max(test[\"time\"])\nprint(start_date)\nprint(end_date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multi_step_recursive(start_date, end_date, freq, sub, train_i, test_i):\n    delta = pd.DateOffset(minutes = freq)\n\n    all_df = pd.concat([train_i.assign(ds=\"a\"),test_i.assign(ds=\"b\")],axis =0)\n    \n    #Shift and rolling features\n    if LAG_FEATURES:\n        all_df = shift_vals(all_df,shift_list, groupby= \"dir_x_y_LE\")\n        all_df = rolling(all_df,roll_window, groupby= \"dir_x_y_LE\")\n        \n    while start_date <= end_date:\n        \n        print(\"\\n############ Start date\" , start_date, \" ############\")\n        #Select slice to predict\n        test_split = all_df [  (all_df[\"time\"]>= start_date ) & (all_df[\"time\"]< start_date+delta) ][features]\n\n        X = all_df[ all_df[\"time\"]< start_date][features]\n        y = all_df[ all_df[\"time\"]< start_date][\"congestion\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n        #predict 1 timeframe - full data\n        #one_period_preds, model = fit_model_full(X, y, test_df =test_split)\n        one_period_preds = cross_val(X,y,test_split)\n        \n        #Add predicted test data back to all_df\n        test_split[\"congestion\"] = np.mean(one_period_preds, axis =0)\n        all_df.loc[test_split.index, \"congestion\"]  = test_split[\"congestion\"]\n        print(np.mean(one_period_preds, axis =0))\n        \n        #update submission \n        sub.loc[test_split.index , \"congestion\"] =  np.mean(one_period_preds, axis =0)\n        \n        if LAG_FEATURES:\n            all_df = shift_vals(all_df,shift_list, groupby= \"dir_x_y_LE\")\n            all_df = rolling(all_df,roll_window, groupby= \"dir_x_y_LE\")\n        \n        #update start date\n        start_date += delta\n    \n    return sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub_recursive  = multi_step_recursive(start_date, end_date, FREQUENCY, sub.copy(deep=True), train, test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_recursive[\"congestion\"] = np.round(sub_recursive[\"congestion\"] )\n# sub_recursive.to_csv(\"sub_recursive.csv\")\n# sub_recursive","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize = (20,8))\n# sns.lineplot(data = train.iloc[-8000:], x = train.iloc[-8000:][\"time\"],  y = \"congestion\", label = \"actual\")\n# sns.lineplot(x = test[\"time\"],  y = sub_recursive[\"congestion\"], label = \"predicted\")\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}