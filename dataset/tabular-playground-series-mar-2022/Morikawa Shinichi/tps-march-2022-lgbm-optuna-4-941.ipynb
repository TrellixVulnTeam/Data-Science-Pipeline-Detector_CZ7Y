{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# introduction\n\nI would like to share my code to achive Score 4.941.  \nThe congestion is predicted with 3 features of date&time and road names.  \nI use LightGBM and Optuna to search hyper parameters.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\nimport lightgbm as lgb\nfrom lightgbm import early_stopping\nfrom lightgbm import log_evaluation\n\nimport optuna.integration.lightgbm as lgb_o\nimport optuna\n\nimport warnings\nwarnings.simplefilter('ignore', UserWarning)\noptuna.logging.set_verbosity(optuna.logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T14:06:36.863135Z","iopub.execute_input":"2022-03-29T14:06:36.864216Z","iopub.status.idle":"2022-03-29T14:06:36.87079Z","shell.execute_reply.started":"2022-03-29T14:06:36.864174Z","shell.execute_reply":"2022-03-29T14:06:36.870058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# import data","metadata":{}},{"cell_type":"code","source":"#import data\ntrain_o = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv')\ntest_o = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv')\n#add a column to identify train data & test data\ntrain_o['train'] = 1\ntest_o['train'] = 0\n#connect train & test data\nalldata = pd.concat([train_o,test_o])\nalldata.reset_index(inplace=True,drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:49:49.714801Z","iopub.execute_input":"2022-03-29T13:49:49.715122Z","iopub.status.idle":"2022-03-29T13:49:50.660681Z","shell.execute_reply.started":"2022-03-29T13:49:49.715091Z","shell.execute_reply":"2022-03-29T13:49:50.659656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create features","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:09:48.208367Z","iopub.execute_input":"2022-03-29T13:09:48.209188Z","iopub.status.idle":"2022-03-29T13:09:48.212369Z","shell.execute_reply.started":"2022-03-29T13:09:48.209152Z","shell.execute_reply":"2022-03-29T13:09:48.211482Z"}}},{"cell_type":"code","source":"#features relating date & time\nalldata['time'] = pd.to_datetime(alldata['time'])\nalldata['dow'] = alldata['time'].apply(lambda x:x.dayofweek) # dow: day of week\nalldata['doy'] = alldata['time'].apply(lambda x:x.dayofyear) # doy: day of year\nalldata['hm'] = alldata['time'].apply(lambda x:x.hour*60+x.minute) # hm: hour and minute\nalldata['date'] = alldata['time'].apply(lambda x:x.date())\nalldata['date'] = pd.to_datetime(alldata['date'])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:49:52.861373Z","iopub.execute_input":"2022-03-29T13:49:52.861655Z","iopub.status.idle":"2022-03-29T13:50:16.072864Z","shell.execute_reply.started":"2022-03-29T13:49:52.861626Z","shell.execute_reply":"2022-03-29T13:50:16.071845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#road: direction + x + y\nalldata['road'] = alldata['direction'].str.cat(alldata['x'].astype(str).str.cat(alldata['y'].astype(str),sep=''),sep='')\nalldata.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:40:10.987797Z","iopub.execute_input":"2022-03-29T13:40:10.988301Z","iopub.status.idle":"2022-03-29T13:40:13.335375Z","shell.execute_reply.started":"2022-03-29T13:40:10.988264Z","shell.execute_reply":"2022-03-29T13:40:13.3346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# define category features","metadata":{}},{"cell_type":"code","source":"rd_dummy = pd.get_dummies(alldata['road'],prefix='rd')\ndummies = rd_dummy\ncategorical_features = dummies.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:40:16.644351Z","iopub.execute_input":"2022-03-29T13:40:16.644904Z","iopub.status.idle":"2022-03-29T13:40:16.985547Z","shell.execute_reply.started":"2022-03-29T13:40:16.644859Z","shell.execute_reply":"2022-03-29T13:40:16.984583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepara data for training/validation/test","metadata":{}},{"cell_type":"code","source":"#correct data\ndata_cong = alldata.loc[:,['congestion','doy','dow','hm']]\ndata_cong = pd.concat([data_cong,dummies],axis=1)\n\n#data period of validation data\nvalid_s = pd.to_datetime('1991-09-23 12:00')\nvalid_f = pd.to_datetime('1991-09-23 23:40')\n\n#index: train / valid / test\ntrain_index = alldata.query('train==1 & time<@valid_s').index\nvalid_index = alldata.query('train==1 & @valid_s<=time<=@valid_f').index\ntest_index = alldata.query('train==0').index\n\n#create data of train/valid/test\nX_train = data_cong.loc[train_index,'doy':].values\ny_train = data_cong.loc[train_index,'congestion'].astype(int).values\nX_valid = data_cong.loc[valid_index,'doy':].values\ny_valid = data_cong.loc[valid_index,'congestion'].astype(int).values\nX_test = data_cong.loc[test_index,'doy':].values\n\n#feature names\nfeature_names = data_cong.loc[train_index, 'doy':].columns.to_list()\n\nprint('categorical features')\nprint(categorical_features)\nprint('-'*30)\nprint('feature names')\nprint(feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:40:18.461058Z","iopub.execute_input":"2022-03-29T13:40:18.461517Z","iopub.status.idle":"2022-03-29T13:40:19.724989Z","shell.execute_reply.started":"2022-03-29T13:40:18.461478Z","shell.execute_reply":"2022-03-29T13:40:19.723495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# search best hyper parameters","metadata":{}},{"cell_type":"code","source":"#data for hyper parameter tuning & validation\ndtrain = lgb_o.Dataset(X_train, label=y_train)\ndvalid = lgb_o.Dataset(X_valid, label=y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:40:22.291405Z","iopub.execute_input":"2022-03-29T13:40:22.291996Z","iopub.status.idle":"2022-03-29T13:40:22.295834Z","shell.execute_reply.started":"2022-03-29T13:40:22.291948Z","shell.execute_reply":"2022-03-29T13:40:22.295141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nstudy = optuna.create_study(direction='minimize')\nkf = KFold(n_splits=3)\n\nparams = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',                \n        'random_seed': 0,\n        'learning_rate': 0.1\n        }\n\ntuner = lgb_o.LightGBMTunerCV(\n    params,\n    dtrain, \n    study=study,\n    folds=kf,#rkf,\n    num_boost_round=1000,\n    verbose_eval=False,\n    early_stopping_rounds=250,\n    optuna_seed = 0,\n    show_progress_bar=True,\n    time_budget=19800, # Time budget of 5 hours, we will not really need it\n    return_cvbooster=True\n)\n\ntuner.run()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_tuning_results(model):\n    print('best parameters')\n    print(model.best_params)\n    print('-'*30)\n    print(f'best score: {model.best_score}')\n\ndisplay_tuning_results(tuner)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training with the searched hyper parameters","metadata":{}},{"cell_type":"code","source":"#define model\ntunedmodel = lgb.train(tuner.best_params,dtrain)\n#predict congestion with train/validation data\npred_train = np.round(tunedmodel.predict(X_train))\npred_valid = np.round(tunedmodel.predict(X_valid))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#score calculation\nr2_train = r2_score(y_train,pred_train)\nr2_valid = r2_score(y_valid,pred_valid)\nrmse_train = np.sqrt(mean_squared_error(y_train,pred_train))\nrmse_valid = np.sqrt(mean_squared_error(y_valid,pred_valid))\nmae_train = np.sqrt(mean_absolute_error(y_train,pred_train))\nmae_valid = np.sqrt(mean_absolute_error(y_valid,pred_valid))\nrmse_mae_train = rmse_train / mae_train\nrmse_mae_valid = rmse_valid / mae_valid\n\nprint('R2')\nprint(f'train: {r2_train}')\nprint(f'valid: {r2_valid}')\nprint('-'*30)\nprint('RMSE - Root Mean Squared Error')\nprint(f'train: {rmse_train}')\nprint(f'valid: {rmse_valid}')\nprint('-'*30)\nprint('MAE - Mean Absolute Error')\nprint(f'train: {mae_train}')\nprint(f'valid: {mae_valid}')\nprint('-'*30)\nprint('RMSE/MAE')\nprint(f'train: {rmse_mae_train}')\nprint(f'valid: {rmse_mae_valid}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prediction of test data","metadata":{}},{"cell_type":"code","source":"pred_test = tunedmodel.predict(X_test)\npred_test = np.round(pred_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create submitting file","metadata":{}},{"cell_type":"code","source":"#train data in September 1991\nsep = alldata.copy().query('train==1 & date>\"1991-09-01\"')\nsep['hour'] = sep['time'].apply(lambda x:x.hour)\nsep['minute'] = sep['time'].apply(lambda x:x.minute)\n\n#choose data of weekday afternoon in September excepting LaborDay (2 September 1991)\nsep = sep.query('hour>=12 & dow<5 & date!=\"1991-09-02\"')\nlower = sep.groupby(['hour', 'minute', 'x', 'y', 'direction']).congestion.quantile(0.15).values\nupper = sep.groupby(['hour', 'minute', 'x', 'y', 'direction']).congestion.quantile(0.7).values\n\n#input predicted values\nalldata.loc[alldata.query('train==0').index,'congestion'] = pred_test\n\n#clipping special values\nsub_data = alldata.loc[alldata.query('train==0').index,['row_id','congestion']]\nsub_data.rename(columns={'row_id':'row_Id','congestion':'congestion_before_clipping'},inplace=True)\nsub_data['congestion'] = submitted_file['congestion_before_clipping'].clip(lower,upper)\nsub_data\n\n#create file to submit\nsubmitted_file = sub_data.loc[:,['row_Id','congestion']].astype(int)\nsubmitted_file.to_csv('submition.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}