{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA - Visualization Tutorial\n\nHello Kaggler. This time, I prepared EDA Tutorial\n\nSome people has fear when see the Big Data or never seen dataset before.\n\nSo, I want to introduce my EDA Way include Simple Visualization","metadata":{}},{"cell_type":"markdown","source":"## 1. Load Datasets\n\nIt's simple of simple.\n\nPython has Powerful libraries.\n\nOne of that is Pandas. \n\nIf you, Using Pandas, You can load datasets, handling the data ...","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\nsubmission = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-13T15:37:16.164646Z","iopub.execute_input":"2022-03-13T15:37:16.165578Z","iopub.status.idle":"2022-03-13T15:37:16.664784Z","shell.execute_reply.started":"2022-03-13T15:37:16.165531Z","shell.execute_reply":"2022-03-13T15:37:16.66379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's easy. Using `pd.read_csv(\"file path\")` \n","metadata":{}},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:37:16.666795Z","iopub.execute_input":"2022-03-13T15:37:16.66714Z","iopub.status.idle":"2022-03-13T15:37:16.687831Z","shell.execute_reply.started":"2022-03-13T15:37:16.667085Z","shell.execute_reply":"2022-03-13T15:37:16.686817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And, Just examine data. Slowly\n\nDon't be afraid.","metadata":{}},{"cell_type":"markdown","source":"## 2. Drop Not using data\n\nIf you see the data, you can feel `row_id` is not need. \n\nIt's just a index ! Drop!","metadata":{}},{"cell_type":"code","source":"train = train.drop('row_id',axis=1)\ntest = test.drop('row_id',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:37:16.689377Z","iopub.execute_input":"2022-03-13T15:37:16.689693Z","iopub.status.idle":"2022-03-13T15:37:16.717716Z","shell.execute_reply.started":"2022-03-13T15:37:16.689652Z","shell.execute_reply":"2022-03-13T15:37:16.716824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To drop columns, Using `DataFrame.drop('column_name', axis=1)` \n\nYou should `axis=1` If you not set axis, It take default value `axis=0`. So you will meet error.\n\n-> `axis=1` mean column, `axis=0` mean row","metadata":{}},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:37:16.720016Z","iopub.execute_input":"2022-03-13T15:37:16.720355Z","iopub.status.idle":"2022-03-13T15:37:16.736549Z","shell.execute_reply.started":"2022-03-13T15:37:16.720312Z","shell.execute_reply":"2022-03-13T15:37:16.735722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great. It's dropped successfully\n\nNow I will check datatype totally.","metadata":{}},{"cell_type":"markdown","source":"## 3. Check DataType","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:37:16.737981Z","iopub.execute_input":"2022-03-13T15:37:16.738345Z","iopub.status.idle":"2022-03-13T15:37:16.940766Z","shell.execute_reply.started":"2022-03-13T15:37:16.738311Z","shell.execute_reply":"2022-03-13T15:37:16.939496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can check datatype easily. Using `DataFrame.info()`\n\nIt show that's Not-Null Count, Dtype, memory usage\n\nIt's very useful.","metadata":{}},{"cell_type":"code","source":"train['time'] = pd.to_datetime(train['time'])\ntest['time'] = pd.to_datetime(test['time'])","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:37:16.942364Z","iopub.execute_input":"2022-03-13T15:37:16.94267Z","iopub.status.idle":"2022-03-13T15:37:17.108487Z","shell.execute_reply.started":"2022-03-13T15:37:16.942625Z","shell.execute_reply":"2022-03-13T15:37:17.107514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I want to change time's datatype.\n\nI will change it object -> datatime\n\nUsing `pd.to_datetime(data)`. Then you can change it","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:37:17.109914Z","iopub.execute_input":"2022-03-13T15:37:17.110504Z","iopub.status.idle":"2022-03-13T15:37:17.218107Z","shell.execute_reply.started":"2022-03-13T15:37:17.110467Z","shell.execute_reply":"2022-03-13T15:37:17.217243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's changed successfully.","metadata":{}},{"cell_type":"markdown","source":"## 4. Count values.","metadata":{}},{"cell_type":"code","source":"for column_name in ['x', 'y', 'direction']:\n    print(\"-------\", column_name, \"--------\")\n    print(train[column_name].value_counts(), '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:39:38.715705Z","iopub.execute_input":"2022-03-13T15:39:38.716013Z","iopub.status.idle":"2022-03-13T15:39:38.8638Z","shell.execute_reply.started":"2022-03-13T15:39:38.715982Z","shell.execute_reply":"2022-03-13T15:39:38.862913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you want to check how many columns take values. Using `data.value_counts()`\n\nThen you can check how many columns take values.","metadata":{}},{"cell_type":"markdown","source":"## 5. Just Look using visualization\n\nI like this methods. \n\nJust visualization. Then you can see the data.\n\nI don't know statistics more detaily. So I just visualization them.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nh1 = train.groupby(pd.Grouper(key='time',freq='1H')).mean().reset_index()\nh3 = train.groupby(pd.Grouper(key='time',freq='1D')).mean().reset_index()\nh6 = train.groupby(pd.Grouper(key='time',freq='5D')).mean().reset_index()\n\nfig, ax = plt.subplots(figsize=(25,6),facecolor=\"white\")\nspec = gridspec.GridSpec(ncols=9, nrows=1, figure=fig)\n\nax1 = fig.add_subplot(spec[0, :3])\nax2 = fig.add_subplot(spec[0, 3:6])\nax3 = fig.add_subplot(spec[0, 6:])\n\nax1.plot(h1['time'],h1['congestion'])\nax1.set_title(\"Group by 1Hour\")\nax2.plot(h3['time'],h3['congestion'])\nax2.set_title(\"Group by 1Day\")\nax3.plot(h6['time'],h6['congestion'])\nax3.set_title(\"Group by 5Days\")\n\nax.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:46:13.199598Z","iopub.execute_input":"2022-03-13T15:46:13.200227Z","iopub.status.idle":"2022-03-13T15:46:13.864705Z","shell.execute_reply.started":"2022-03-13T15:46:13.200177Z","shell.execute_reply":"2022-03-13T15:46:13.863726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, I made time - congestion relationship.\n\nIt repeats vibrate. So I compared it using another time group.\n\nFirst is 1Hour. It can't see deatily. \n\nThen Using 1Day and 5Days.\n\nJust try many. Then you can check it's characteristic.","metadata":{}},{"cell_type":"code","source":"tmp = pd.DataFrame(train.groupby(['x','y'])['congestion'].mean()).reset_index()\nfig, ax = plt.subplots(figsize=(20,13),facecolor=\"white\")\nplt.scatter(x=tmp['x'], y=tmp['y'], s=tmp['congestion']**2.3)\nplt.xlim(-0.5, 2.5)\nplt.ylim(-0.5, 3.5)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\nfor index, row in tmp.iterrows():\n    plt.text(s=f\"{round(row.congestion,2)}\", x=row.x, y=row.y, va='center', ha='center', fontsize=25, color='white')\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:50:05.387099Z","iopub.execute_input":"2022-03-13T15:50:05.387415Z","iopub.status.idle":"2022-03-13T15:50:05.756074Z","shell.execute_reply.started":"2022-03-13T15:50:05.387383Z","shell.execute_reply":"2022-03-13T15:50:05.755322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then I want to check x, y - congestion relationship\n\nI don't have any domain about that, So, I don't know what it mean.\n\nI just feeling, It meaningful data to predict congestion.","metadata":{}},{"cell_type":"code","source":"tmp = pd.DataFrame(train.groupby('direction')['congestion'].mean()).reset_index()\ntmp = tmp.sort_values(by='congestion',ascending=False)\ntmp = tmp.reset_index(drop=True)\n\nfig, ax = plt.subplots(figsize=(20,8),facecolor=\"white\")\nplt.bar(x=tmp['direction'], height=tmp['congestion'])\n\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\nfor index, row in tmp.iterrows():\n    plt.text(s=f\"{round(row.congestion,2)}\", x=index, y=row['congestion']+1, ha='center', fontsize=25)\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:00:24.714016Z","iopub.execute_input":"2022-03-13T16:00:24.714308Z","iopub.status.idle":"2022-03-13T16:00:25.034295Z","shell.execute_reply.started":"2022-03-13T16:00:24.714278Z","shell.execute_reply":"2022-03-13T16:00:25.033622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, Check direction - congestion relationship.\n\nSB and NW 's difference is more than 26. That mean, It's useful data too.","metadata":{}},{"cell_type":"markdown","source":"## 6. Make Model.\n\nIf you checked Data. Make Model using proper ML/DL Algorithms.\n\nI don't progress this. I hope this work help you.","metadata":{}}]}