{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-01T09:34:11.907622Z","iopub.execute_input":"2022-03-01T09:34:11.907938Z","iopub.status.idle":"2022-03-01T09:34:11.923218Z","shell.execute_reply.started":"2022-03-01T09:34:11.907904Z","shell.execute_reply":"2022-03-01T09:34:11.922208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"table-of-contents\"></a>\n# Table of Contents\n\n- [1 Introduction](#1)\n    - [1.1 Problem Statement](#1.1)\n    - [1.2 Data Dictionary](#1.2)\n- [2 Preparations](#2)\n    - [2.1 Importing Packages](#2.1)\n    - [2.2 Loading The Dataset](#2.2)\n- [3 Getting Basic Understanding of The Data](#3)\n    - [3.1 Seeing the data and shape](#3.1)\n    - [3.2 Statistics](#3.2)\n    - [3.3 Number of Unique Values in Each Column](#3.3)\n    - [3.4 Distribution of target Variable](#3.4)\n- [4 Changing The Data Type Of Variables for Analysis and Space Saving](#4)\n    - [4.1 Dropping The `id` Columns](#4.1)\n    - [4.2 Changing The Data Type Of variables](#4.2)\n- [5 Univariate Analysis](#5)\n    - [5.1 Distribution of Categorical Variables](#5.1)\n- [6 Bivariate Analysis](#6)\n    - [6.1 Distribution of Target w.r.t. Categorical Variables](#6.1)\n- [7 Model Building](#7)\n    - [7.1 Data Preprocessing](#7.1)\n    - [7.2 Predicting with Baseline Model](#7.2)\n    - [7.3 Feature Engineering](#7.3)\n    - [7.4 Setting Up a Cross-Validation Strategy](#7.4)\n    - [7.5 Final Predictions](#7.5)","metadata":{}},{"cell_type":"markdown","source":"\n<a id=\"1\"></a>\n# 1. Introduction\n\nIn this competition, you'll forecast twelve-hours of traffic flow in a major U.S. metropolitan area. Time, space, and directional features give you the chance to model interactions across a network of roadways.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n### 1. 1 Problem Statement\n\nFor the March edition of the 2022 Tabular Playground Series you're challenged to forecast twelve-hours of traffic flow in a U.S. metropolis. The time series in this dataset are labelled with both location coordinates and a direction of travel -- a combination of features that will test your skill at spatio-temporal forecasting within a highly dynamic traffic network.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"1.2\"></a>\n### 1.2 Data Dictionary\n\n**row_id**     - a unique identifier for this instance\n\n**time**       - the 20-minute period in which each measurement was taken\n\n**x**          - the east-west midpoint coordinate of the roadway\n\n**y**          - the north-south midpoint coordinate of the roadway\n\n**direction**  - the direction of travel of the roadway. EB indicates \"eastbound\" travel, for example, while SW indicates a \"southwest\" direction of travel.\n\n**congestion** `target variable` - congestion levels for the roadway during each hour; the target. The congestion measurements have been normalized to the range 0 to 100.","metadata":{}},{"cell_type":"markdown","source":"---\n\n<a id=\"2\"></a>\n# 2. Preparations\n\nImporting packages and loading the data that will be used in the analysis and modelling process. \n\n[back to top](#table-of-contents)\n<a id=\"table-of-contents\"></a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2.1\"></a>\n\n\n### 2.1 Importing Packages","metadata":{}},{"cell_type":"code","source":"#### Data Manipulation\nimport pandas as pd\nimport numpy as np\nimport warnings\n\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', None)\nwarnings.filterwarnings('ignore')\n\n#### Data Visulization \nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nfrom matplotlib import ticker\nimport seaborn as sns\nsns.set(style = 'white')\n\n############## Libraries for Machine Learning Modeling ###############\n\n# Data Preprocessing\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nle = LabelEncoder()\nscaler = MinMaxScaler()\n\n# Model Building\nfrom sklearn.model_selection import train_test_split, KFold\n\n# Machine Learning Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\n# Evaluation\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:15.406568Z","iopub.execute_input":"2022-03-01T09:34:15.406879Z","iopub.status.idle":"2022-03-01T09:34:15.417346Z","shell.execute_reply.started":"2022-03-01T09:34:15.406846Z","shell.execute_reply":"2022-03-01T09:34:15.415915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"2.2\"></a>\n\n### 2.2 Loading The Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\nss = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:15.994591Z","iopub.execute_input":"2022-03-01T09:34:15.99487Z","iopub.status.idle":"2022-03-01T09:34:16.513285Z","shell.execute_reply.started":"2022-03-01T09:34:15.994843Z","shell.execute_reply":"2022-03-01T09:34:16.512262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<a id = '3'></a>\n# 3. Getting Basic Understanding of The Dataset\n\n[back to top](#table-of-contents)\n<a id=\"table-of-contents\"></a>\n\n\n<a id = \"3.1\"></a>\n### 3.1 Seeing the data and shape","metadata":{}},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:16.520665Z","iopub.execute_input":"2022-03-01T09:34:16.520951Z","iopub.status.idle":"2022-03-01T09:34:16.532459Z","shell.execute_reply.started":"2022-03-01T09:34:16.520923Z","shell.execute_reply":"2022-03-01T09:34:16.531593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:16.764616Z","iopub.execute_input":"2022-03-01T09:34:16.765609Z","iopub.status.idle":"2022-03-01T09:34:16.777426Z","shell.execute_reply.started":"2022-03-01T09:34:16.765563Z","shell.execute_reply":"2022-03-01T09:34:16.776709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Shape of the train set is: {train.shape}\")\nprint(f\"The train set has {len(train.columns) - 1} features and 1 target variable: {train.columns[-1]}\")\nprint()\nprint()\nprint(f\"Shape of the test set is: {test.shape}\")\nprint(f\"The test set has {len(test.columns)} features\")\n\n\ntarget = 'congestion'","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:17.036411Z","iopub.execute_input":"2022-03-01T09:34:17.036916Z","iopub.status.idle":"2022-03-01T09:34:17.045162Z","shell.execute_reply.started":"2022-03-01T09:34:17.036871Z","shell.execute_reply":"2022-03-01T09:34:17.043886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"3.2\"></a>\n\n### 3.2 Statistics","metadata":{}},{"cell_type":"code","source":"train.describe().T.style.bar(color = '#eeb977').background_gradient(subset = ['std', '50%'], cmap='Reds', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:17.576434Z","iopub.execute_input":"2022-03-01T09:34:17.577474Z","iopub.status.idle":"2022-03-01T09:34:17.716681Z","shell.execute_reply.started":"2022-03-01T09:34:17.577406Z","shell.execute_reply":"2022-03-01T09:34:17.71571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe().T.style.bar(color = '#eeb977').background_gradient(subset = ['std', '50%'], cmap='Reds', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:17.837387Z","iopub.execute_input":"2022-03-01T09:34:17.838457Z","iopub.status.idle":"2022-03-01T09:34:17.873565Z","shell.execute_reply.started":"2022-03-01T09:34:17.838415Z","shell.execute_reply":"2022-03-01T09:34:17.872933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"3.3\"></a>\n### 3.3 Number of Unique Values in Each Columns","metadata":{}},{"cell_type":"code","source":"pd.concat([train.nunique(), test.nunique()], axis = 1, keys = ['train', 'test']).sort_values(by = 'train').style.bar(color = '#eeb977').background_gradient(cmap = 'Reds', axis =1)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:18.374675Z","iopub.execute_input":"2022-03-01T09:34:18.375774Z","iopub.status.idle":"2022-03-01T09:34:18.556035Z","shell.execute_reply.started":"2022-03-01T09:34:18.375707Z","shell.execute_reply":"2022-03-01T09:34:18.554997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"3.4\"></a>\n\n### 3.4 Distribution of Target variable","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(22, 12))\ngs = fig.add_gridspec(3, 1)\n\nbackground_color = \"#faf9f4\"\ncolor_palette = [\"#8d9e8c\", \"#eeb977\"]\n\n# Fig 1\nax0 = fig.add_subplot(gs[0, 0])\n\nfig.patch.set_facecolor(background_color)\nax0.set_facecolor(background_color)\n\n\nax0.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.kdeplot(train[\"congestion\"], color=\"#eeb977\", shade=True, ax=ax0, zorder=3)\nplt.ticklabel_format(style='plain')\nax0.set_xlabel(\"\")\nax0.set_ylabel(\"\")\n\n# Fig 2\nax1 = fig.add_subplot(gs[1, 0])\n\nfig.patch.set_facecolor(background_color)\nax1.set_facecolor(background_color)\n\nax1.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.boxplot(train[\"congestion\"], color=\"#77acee\", ax=ax1, zorder=3)\nax1.set_xlabel(\"\")\nax1.set_ylabel(\"\")\n\n_ = plt.title('Congestion Distribution',fontsize=30, y = 2.29, x = 0.5, fontweight='bold', fontfamily='serif', color=\"#323232\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T09:34:18.89928Z","iopub.execute_input":"2022-03-01T09:34:18.89961Z","iopub.status.idle":"2022-03-01T09:34:22.572431Z","shell.execute_reply.started":"2022-03-01T09:34:18.89958Z","shell.execute_reply":"2022-03-01T09:34:22.571622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<a id=\"1\"></a>\n# 4. Pre-Analysis Data Processing\n\n[back to top](#table-of-contents)\n<a id=\"table-of-contents\"></a>\n\n<a id = \"4.1\"></a>\n### 4.1 Dropping The `id` Columns","metadata":{}},{"cell_type":"code","source":"train.drop('row_id', axis = 1, inplace = True)\ntest.drop('row_id', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:22.574531Z","iopub.execute_input":"2022-03-01T09:34:22.575142Z","iopub.status.idle":"2022-03-01T09:34:22.598276Z","shell.execute_reply.started":"2022-03-01T09:34:22.575095Z","shell.execute_reply":"2022-03-01T09:34:22.597461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"4.2\"></a>\n### 4.2 Changing The Data Type","metadata":{"execution":{"iopub.status.busy":"2022-03-01T07:58:27.283347Z","iopub.execute_input":"2022-03-01T07:58:27.284365Z","iopub.status.idle":"2022-03-01T07:58:27.3031Z","shell.execute_reply.started":"2022-03-01T07:58:27.28432Z","shell.execute_reply":"2022-03-01T07:58:27.30185Z"}}},{"cell_type":"code","source":"train['time'] = pd.to_datetime(train['time'])\ntest['time'] = pd.to_datetime(test['time'])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:22.599361Z","iopub.execute_input":"2022-03-01T09:34:22.599582Z","iopub.status.idle":"2022-03-01T09:34:22.716397Z","shell.execute_reply.started":"2022-03-01T09:34:22.599557Z","shell.execute_reply":"2022-03-01T09:34:22.715791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['x', 'y']\n\ntrain[cols] = train[cols].astype('uint8')\ntest[cols] = test[cols].astype('uint8')\n\ntrain[target] = train[target].astype('int8')\n\n# This way we have reduced the memory usage by more than 50%.","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:22.717984Z","iopub.execute_input":"2022-03-01T09:34:22.718371Z","iopub.status.idle":"2022-03-01T09:34:22.737361Z","shell.execute_reply.started":"2022-03-01T09:34:22.718328Z","shell.execute_reply":"2022-03-01T09:34:22.736492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<a id = '5'></a>\n# 5. Univariate Analysis\n\n[back to top](#table-of-contents)\n<a id=\"table-of-contents\"></a>","metadata":{"execution":{"iopub.status.busy":"2022-03-01T08:05:24.299835Z","iopub.execute_input":"2022-03-01T08:05:24.300198Z","iopub.status.idle":"2022-03-01T08:05:24.307917Z","shell.execute_reply.started":"2022-03-01T08:05:24.300162Z","shell.execute_reply":"2022-03-01T08:05:24.306406Z"}}},{"cell_type":"code","source":"cat_cols = ['x', 'y', 'direction']","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:22.738529Z","iopub.execute_input":"2022-03-01T09:34:22.739228Z","iopub.status.idle":"2022-03-01T09:34:22.743152Z","shell.execute_reply.started":"2022-03-01T09:34:22.739192Z","shell.execute_reply":"2022-03-01T09:34:22.742325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '5.1'></a>\n### 5.1 Distribution of Categorical Variables","metadata":{"execution":{"iopub.status.busy":"2022-03-01T08:05:37.576951Z","iopub.execute_input":"2022-03-01T08:05:37.578281Z","iopub.status.idle":"2022-03-01T08:05:37.596857Z","shell.execute_reply.started":"2022-03-01T08:05:37.578219Z","shell.execute_reply":"2022-03-01T08:05:37.595795Z"}}},{"cell_type":"code","source":"color_palette = [\"#eeb977\",\"#8d9e8c\"]\n\nfig = plt.figure(figsize = (25, 35))\ngs = fig.add_gridspec(3, 2)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[1, 0])\nax3 = fig.add_subplot(gs[1, 1])\nax4 = fig.add_subplot(gs[2, 0])\nax5 = fig.add_subplot(gs[2, 1])\n\nbackground_color = \"#faf9f4\"\nfig.patch.set_facecolor(background_color) # figure background color\n\nax0.set_facecolor(background_color) # axes background color\nax1.set_facecolor(background_color) # axes background color\nax2.set_facecolor(background_color) # axes background color\nax3.set_facecolor(background_color) # axes background color\nax4.set_facecolor(background_color) # axes background color\nax5.set_facecolor(background_color) # axes background color\n\nfor s in ['right', 'top']:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax3.spines[s].set_visible(False)\n    ax4.spines[s].set_visible(False)\n    ax5.spines[s].set_visible(False)\n\naxis = { 'x' : [ax0, ax1],\n         'y' : [ax2, ax3],\n         'direction' : [ax4, ax5],\n}\n\nfor col in axis.keys():\n    temp = pd.DataFrame(train[col].value_counts())\n    temp = temp.reset_index(drop=False)\n    temp.columns = ['Number', 'Count']\n    \n    if col == 'direction':\n        sns.countplot(ax = axis[col][0], data = train, x = col, zorder=2, linewidth=0, alpha=1, saturation=1, palette=[\"#eeb977\",\"#8ebaf1\", \"#77eeb9\", \"#e8ee77\", \"#b977ee\", \"#ee77ac\"])\n    else:\n        sns.countplot(ax = axis[col][0], data = train, x = col, zorder=2, linewidth=0, alpha=1, saturation=1, palette=[\"#eeb977\",\"#8ebaf1\", \"#77eeb9\", \"#e8ee77\", \"#b977ee\", \"#ee77ac\"])\n    axis[col][0].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\n    axis[col][0].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\n    axis[col][0].set_ylabel('')\n    axis[col][0].set_xlabel('')\n    axis[col][0].tick_params(labelsize=10, width=0.5, length=1.5)\n    #axis[col][0].yaxis.set_major_formatter(ticker.PercentFormatter())\n    \n    \n    for p in axis[col][0].patches:\n        percentage = f'{p.get_height()}\\n'\n        x = p.get_x() + p.get_width()/2\n        y = p.get_height()\n        axis[col][0].text(x, y, percentage, ha='center', va='center', fontsize = 10)\n    \n    # Pie Plot\n    if col == 'direction':\n        train[col].value_counts().plot.pie(autopct='%1.1f%%', colors = [\"#eeb977\",\"#8ebaf1\", \"#77eeb9\", \"#e8ee77\", \"#b977ee\", \"#ee77ac\"], ax = axis[col][1])\n    else:\n        train[col].value_counts().plot.pie(autopct='%1.1f%%', colors = [\"#eeb977\",\"#8ebaf1\", \"#77eeb9\", \"#e8ee77\", \"#b977ee\", \"#ee77ac\"], ax = axis[col][1])\n    axis[col][1].set_ylabel('')\n    axis[col][1].set_xlabel('')\n    \n_ = ax0.text(2.5, -25000, 'x', fontsize = 30, fontweight='bold', fontfamily='serif', color='#323232')\n_ = ax2.text(3.5, -23000, 'y', fontsize = 30, fontweight='bold', fontfamily='serif', color='#323232')\n_ = ax4.text(6.5, -15000, 'Direction', fontsize = 30, fontweight='bold', fontfamily='serif', color='#323232')\n\n_ = plt.title('Distribution of Categorical Variables',fontsize=40, y = 3.5, x = -0.15, fontweight='bold', fontfamily='serif', color=\"#323232\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T09:34:23.732105Z","iopub.execute_input":"2022-03-01T09:34:23.732419Z","iopub.status.idle":"2022-03-01T09:34:25.600895Z","shell.execute_reply.started":"2022-03-01T09:34:23.732378Z","shell.execute_reply":"2022-03-01T09:34:25.600214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<a id = '6'></a>\n# 6. Bivariate Analysis\n\n[back to top](#table-of-contents)\n<a id=\"table-of-contents\"></a>\n\n<a id = 6.1></a>\n### 6.1 Distribution of Target w.r.t. Categorical Variables","metadata":{}},{"cell_type":"code","source":"color_palette = [\"#eeb977\",\"#8d9e8c\"]\n\nfig = plt.figure(figsize = (20, 10))\ngs = fig.add_gridspec(1, 3)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[0, 2])\n\nbackground_color = \"#faf9f4\"\nfig.patch.set_facecolor(background_color) # figure background color\nax0.set_facecolor(background_color) # axes background color\nax1.set_facecolor(background_color) # axes background color\nax2.set_facecolor(background_color) # axes background color\n\n\naxis = { 'x' : [ax0],\n         'y' : [ax1],\n         'direction' : [ax2]\n       }\n\nfor col in axis.keys():\n    if col == 'direction':\n        sns.boxplot(data = train, x = col, y = target, ax = axis[col][0], palette=[\"#eeb977\",\"#8ebaf1\", \"#77eeb9\", \"#e8ee77\", \"#b977ee\", \"#ee77ac\"])\n    else:\n        sns.boxplot(data = train, x = col, y = target, ax = axis[col][0], palette= [\"#eeb977\",\"#8ebaf1\", \"#77eeb9\", \"#e8ee77\", \"#b977ee\", \"#ee77ac\"])\n    axis[col][0].set_ylabel('')\n    axis[col][0].set_xlabel('')\n    \n_ = ax0.text(1, -15, 'X', fontsize = 20, fontweight='bold', fontfamily='serif', color='#323232')\n_ = ax1.text(1.5, -15, 'Y', fontsize = 20, fontweight='bold', fontfamily='serif', color='#323232')\n_ = ax2.text(2, -15, 'Direction', fontsize = 20, fontweight='bold', fontfamily='serif', color='#323232')\n\n_ = plt.title('Distribution of Categorical Variables',fontsize=30, y = 1.03, x = -0.7, fontweight='bold', fontfamily='serif', color=\"#323232\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T09:34:25.602286Z","iopub.execute_input":"2022-03-01T09:34:25.602801Z","iopub.status.idle":"2022-03-01T09:34:26.704464Z","shell.execute_reply.started":"2022-03-01T09:34:25.602769Z","shell.execute_reply":"2022-03-01T09:34:26.703629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<a id = '7'></a>\n# 7. Machine Learning\n\n[back to top](#table-of-contents)\n<a id=\"table-of-contents\"></a>\n\nHere, we will try to describe the relationship between Independent(Features) and Dependent(Target) Variable using Machine Learning Modeling.","metadata":{}},{"cell_type":"markdown","source":"<a id = 7.1></a>\n## 7.1 Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df = pd.concat([train, test], axis = 0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:26.705884Z","iopub.execute_input":"2022-03-01T09:34:26.706114Z","iopub.status.idle":"2022-03-01T09:34:26.729239Z","shell.execute_reply.started":"2022-03-01T09:34:26.706086Z","shell.execute_reply":"2022-03-01T09:34:26.728626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic Datetime Feature Retrival\ndf['Year'] = df['time'].dt.year\ndf['Month'] = df['time'].dt.month\ndf['Day'] = df['time'].dt.day\ndf['Hour'] = df['time'].dt.hour\ndf['Minute'] = df['time'].dt.minute\ndf['dayofweek'] = df['time'].dt.hour","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:27.65346Z","iopub.execute_input":"2022-03-01T09:34:27.654276Z","iopub.status.idle":"2022-03-01T09:34:28.134579Z","shell.execute_reply.started":"2022-03-01T09:34:27.654239Z","shell.execute_reply":"2022-03-01T09:34:28.133839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label Encoding\ndf['direction'] = df[['direction']].apply(le.fit_transform)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:28.179011Z","iopub.execute_input":"2022-03-01T09:34:28.179416Z","iopub.status.idle":"2022-03-01T09:34:28.353801Z","shell.execute_reply.started":"2022-03-01T09:34:28.179386Z","shell.execute_reply":"2022-03-01T09:34:28.352676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separating Train - Test and Creating Training and Validation Sets\n\ntrain_proc, test_proc = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop = True)\n\ntarget = 'congestion'\ndate = 'time'\n\nfeatures = [col for col in df.columns if col not in ([target, date])]","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:28.616234Z","iopub.execute_input":"2022-03-01T09:34:28.616488Z","iopub.status.idle":"2022-03-01T09:34:28.623303Z","shell.execute_reply.started":"2022-03-01T09:34:28.616461Z","shell.execute_reply":"2022-03-01T09:34:28.622459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '7.2'></a>\n## 7.2 Predicting With Baseline Model Building\n","metadata":{}},{"cell_type":"code","source":"trn, val = train_test_split(train_proc, test_size = 0.2, random_state = 1999)\n\n##### Input for model\nX_trn, X_val = trn[features], val[features]\n\n##### Target column\ny_trn, y_val = trn[target], val[target]\n\n##### Features for test data that we will be predicting\nX_test = test_proc[features]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:29.585247Z","iopub.execute_input":"2022-03-01T09:34:29.585756Z","iopub.status.idle":"2022-03-01T09:34:29.860666Z","shell.execute_reply.started":"2022-03-01T09:34:29.585701Z","shell.execute_reply":"2022-03-01T09:34:29.859523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dict = {}\n\nseed = 1999\n\nmodel_dict['Linear Regression'] = LinearRegression()\nmodel_dict['DecisionTree Regressor'] = DecisionTreeRegressor(random_state = seed)\nmodel_dict['Random Forest Regressor'] = RandomForestRegressor(random_state = seed)\nmodel_dict['LGBM Regressor'] = LGBMRegressor(random_state = seed)\nmodel_dict['XGB Regressor'] = XGBRegressor(random_state = seed)\nmodel_dict['Catboost Regressor'] = CatBoostRegressor(random_state = seed, verbose=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:52.35469Z","iopub.execute_input":"2022-03-01T09:34:52.35501Z","iopub.status.idle":"2022-03-01T09:34:52.361271Z","shell.execute_reply.started":"2022-03-01T09:34:52.354976Z","shell.execute_reply":"2022-03-01T09:34:52.360513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_evaluation(X_train, X_test, y_train, y_test, model, model_name):\n    \"\"\"\n    Dockstring:\n            Shows the score of ML Model by training and evaluating it.\n            \n    Parameters:\n    -----------\n            X_train: Training Data for ML Model\n            \n            X_test: Validation Data for ML Model\n            \n            y_train: Target values of training data\n            \n            y_test:  Target values of validation data\n            \n            model: Machine Learning Model\n            \n            model_name: Name of Machine Learning Model\n    \"\"\"\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    MAE = mean_absolute_error(y_test, y_pred)\n    print('======================================{}======================================='.format(model_name))\n    print()\n    print('Mean Absolute Error is : {}'.format(MAE))\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:34:55.235911Z","iopub.execute_input":"2022-03-01T09:34:55.236457Z","iopub.status.idle":"2022-03-01T09:34:55.241932Z","shell.execute_reply.started":"2022-03-01T09:34:55.23642Z","shell.execute_reply":"2022-03-01T09:34:55.241132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor model_name,model in model_dict.items():\n    model_evaluation(X_trn, X_val, y_trn, y_val, model, model_name)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:35:08.950306Z","iopub.execute_input":"2022-03-01T09:35:08.950856Z","iopub.status.idle":"2022-03-01T09:40:30.470255Z","shell.execute_reply.started":"2022-03-01T09:35:08.950813Z","shell.execute_reply":"2022-03-01T09:40:30.468423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using Complete Dataset For Predictions**","metadata":{}},{"cell_type":"code","source":"%%time\nmodel = XGBRegressor(objective='reg:linear', random_state = 1999)\n\n_ = model.fit(train_proc[features], train_proc[target])\n\npreds = model.predict(test_proc[features])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:40:30.472349Z","iopub.execute_input":"2022-03-01T09:40:30.472662Z","iopub.status.idle":"2022-03-01T09:40:59.317483Z","shell.execute_reply.started":"2022-03-01T09:40:30.472623Z","shell.execute_reply":"2022-03-01T09:40:59.316618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss[target] = preds\nss.to_csv('Baselin_XGB.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T09:40:59.318859Z","iopub.execute_input":"2022-03-01T09:40:59.319193Z","iopub.status.idle":"2022-03-01T09:40:59.331247Z","shell.execute_reply.started":"2022-03-01T09:40:59.319141Z","shell.execute_reply":"2022-03-01T09:40:59.330198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Stay Tuned For Next Steps:\n        - Advance Feature Engineering\n        - Building Cross validation Strategy\n        - Hyperparameter Tuning\n        - Ensembling, Stacking, Blending.","metadata":{}},{"cell_type":"markdown","source":"# ** Upvote The Notebook If You Like The Content **","metadata":{}}]}