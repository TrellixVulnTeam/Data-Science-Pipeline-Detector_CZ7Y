{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:28.83205Z","iopub.execute_input":"2022-03-31T13:22:28.832334Z","iopub.status.idle":"2022-03-31T13:22:28.837248Z","shell.execute_reply.started":"2022-03-31T13:22:28.832304Z","shell.execute_reply":"2022-03-31T13:22:28.836282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Function","metadata":{}},{"cell_type":"code","source":"def datetime_break(df):\n    df['time'] = pd.to_datetime(df['time'])\n    df['date'] = df['time'].dt.date\n    df['quarter'] = df['time'].dt.quarter\n    df['month'] = df['time'].dt.month\n    df['week_number'] = df['time'].dt.isocalendar().week\n    df['day'] = df['time'].dt.isocalendar().week\n    df['time_of_day'] = df['time'].dt.time\n    df['hour'] = df['time'].dt.hour\n    df['minute'] = df['time'].dt.minute\n    df.drop('time', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:30.477704Z","iopub.execute_input":"2022-03-31T13:22:30.477953Z","iopub.status.idle":"2022-03-31T13:22:30.484098Z","shell.execute_reply.started":"2022-03-31T13:22:30.477926Z","shell.execute_reply":"2022-03-31T13:22:30.48342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data loading & treatment","metadata":{}},{"cell_type":"code","source":"# path way for the data set\ntrain_path = '../input/tabular-playground-series-mar-2022/train.csv'\ntest_path = '../input/tabular-playground-series-mar-2022/test.csv'\n\n# load the data and seperate for train & test set\nx_train = pd.read_csv(train_path, index_col = 0).drop_duplicates()\nx_test = pd.read_csv(test_path,index_col = 0).drop_duplicates()\ny_train = x_train.pop('congestion').to_frame()\n\n# break the time column and drop it\ndatetime_break(x_train)\ndatetime_break(x_test)\n\n# ordianl labeling for direction column\nx_train_ohe = pd.get_dummies(x_train['direction'])\nx_toname = {x:y for x,y in enumerate(x_train_ohe.columns)}\nx_toint = {y:x for x,y in enumerate(x_train_ohe.columns)}\nx_train['direction_num'] = x_train['direction'].map(x_toint)\nx_test['direction_num'] = x_test['direction'].map(x_toint)\nx_train.drop(['direction','date','time_of_day'], axis = 1, inplace = True)\nx_test.drop(['direction','date','time_of_day'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:33.103829Z","iopub.execute_input":"2022-03-31T13:22:33.104081Z","iopub.status.idle":"2022-03-31T13:22:36.138264Z","shell.execute_reply.started":"2022-03-31T13:22:33.104053Z","shell.execute_reply":"2022-03-31T13:22:36.137507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check with the missing value\nprint(f'Missing value in training set: \\n{x_train.isna().sum()}')\nprint(f'Missing value in testing set: \\n{x_test.isna().sum()}')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:36.139958Z","iopub.execute_input":"2022-03-31T13:22:36.140291Z","iopub.status.idle":"2022-03-31T13:22:36.160707Z","shell.execute_reply.started":"2022-03-31T13:22:36.140255Z","shell.execute_reply":"2022-03-31T13:22:36.16Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preview for the testing set\nx_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:36.162033Z","iopub.execute_input":"2022-03-31T13:22:36.162356Z","iopub.status.idle":"2022-03-31T13:22:36.17555Z","shell.execute_reply.started":"2022-03-31T13:22:36.162318Z","shell.execute_reply":"2022-03-31T13:22:36.174592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preview for the testing set\nx_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:36.452658Z","iopub.execute_input":"2022-03-31T13:22:36.452914Z","iopub.status.idle":"2022-03-31T13:22:36.464008Z","shell.execute_reply.started":"2022-03-31T13:22:36.452886Z","shell.execute_reply":"2022-03-31T13:22:36.463237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Balanced label check for the x & y coordinate","metadata":{}},{"cell_type":"code","source":"# scatter plot of column 'x' & 'y' in train set\nx = 'x'\ny = 'y'\ndf_counts_train = x_train.groupby([x, y]).size().reset_index()\ndf_counts_train.columns.values[df_counts_train.columns == 0] = 'count'\n\nn_sc = 500 # scale constant\nscale = n_sc * df_counts_train['count'].size\nsize = df_counts_train['count'] / df_counts_train['count'].sum() * scale\n\nfig,ax = plt.subplots(figsize=(8,6))\nax.scatter(x, y, size, data = df_counts_train, zorder = 2)\nax.set_title(\"Scatter plot of 'x' & 'y' (train)\")\nax.set_xlabel(x)\nax.set_ylabel(y)\nax = plt.xticks([0,1,2])\nax = plt.yticks([0,1,2,3])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:41.597039Z","iopub.execute_input":"2022-03-31T13:22:41.597721Z","iopub.status.idle":"2022-03-31T13:22:41.781776Z","shell.execute_reply.started":"2022-03-31T13:22:41.597685Z","shell.execute_reply":"2022-03-31T13:22:41.780968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot of column 'x' & 'y' in test set\nx = 'x'\ny = 'y'\ndf_counts_test = x_test.groupby([x, y]).size().reset_index()\ndf_counts_test.columns.values[df_counts_test.columns == 0] = 'count'\n\nn_sc = 500 # scale constant\nscale = n_sc * df_counts_test['count'].size\nsize = df_counts_test['count'] / df_counts_test['count'].sum() * scale\n\nfig,ax = plt.subplots(figsize=(8,6))\nax.scatter(x, y, size, data = df_counts_test, zorder = 2)\nax.set_title(\"Scatter plot of 'x' & 'y' (test)\")\nax.set_xlabel(x)\nax.set_ylabel(y)\nax = plt.xticks([0,1,2])\nax = plt.yticks([0,1,2,3])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:43.971929Z","iopub.execute_input":"2022-03-31T13:22:43.972221Z","iopub.status.idle":"2022-03-31T13:22:44.104097Z","shell.execute_reply.started":"2022-03-31T13:22:43.972189Z","shell.execute_reply":"2022-03-31T13:22:44.103177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compare the sample distribution for both train & test set\ndf_counts_train['count'] = df_counts_train['count'] / df_counts_train['count'].sum()\ndf_counts_test['count'] = df_counts_test['count'] / df_counts_test['count'].sum()\n\ndf_diff = pd.DataFrame()\ndf_diff['diff'] = df_counts_train['count']/ df_counts_test['count']\ndf_diff['diff'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:45.699221Z","iopub.execute_input":"2022-03-31T13:22:45.699632Z","iopub.status.idle":"2022-03-31T13:22:45.717367Z","shell.execute_reply.started":"2022-03-31T13:22:45.69959Z","shell.execute_reply":"2022-03-31T13:22:45.715993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the calculation & plot, the count of x & y coordinate in both train set & test set is the same.","metadata":{}},{"cell_type":"markdown","source":"#### KNN with optimal K value","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\ntest_size = 0.25\nX_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size = test_size)\n\nmean_abs_error = []\nmean_squ_error = []\nr2 = []\n\nfor i in range(1,20):\n    knn = KNeighborsRegressor(n_neighbors = i)\n    knn.fit(X_train, Y_train)\n    pred_i = knn.predict(X_test)\n    mean_abs_error.append(mean_absolute_error(Y_test, pred_i))\n    mean_squ_error.append(mean_squared_error(Y_test, pred_i))\n    r2.append(r2_score(Y_test, pred_i))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T17:40:17.015015Z","iopub.execute_input":"2022-03-24T17:40:17.015266Z","iopub.status.idle":"2022-03-24T17:40:17.437973Z","shell.execute_reply.started":"2022-03-24T17:40:17.01524Z","shell.execute_reply":"2022-03-24T17:40:17.437231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,20), mean_abs_error, color = 'blue', linestyle= 'dashed', marker='o',\n        markerfacecolor='red', markersize= 10)\nplt.title('Mean absolute error vs K value')\nplt.xlabel('K')\nplt.ylabel('Mean absolute error')\nax = plt.xticks(range(1,20))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T19:00:03.533832Z","iopub.execute_input":"2022-03-21T19:00:03.534364Z","iopub.status.idle":"2022-03-21T19:00:03.817805Z","shell.execute_reply.started":"2022-03-21T19:00:03.534326Z","shell.execute_reply":"2022-03-21T19:00:03.816762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,20), mean_squ_error, color = 'green', linestyle = 'dashed', marker = '*', \n         markerfacecolor = 'red', markersize= 10)\nplt.title('Mean square error vs K value')\nplt.xlabel('K')\nplt.ylabel('Mean square error')\nax = plt.xticks(range(1,20))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T16:32:31.169195Z","iopub.status.idle":"2022-03-20T16:32:31.170186Z","shell.execute_reply.started":"2022-03-20T16:32:31.169907Z","shell.execute_reply":"2022-03-20T16:32:31.169937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,20), r2, color = 'green', linestyle = 'dashed', marker = '+', markerfacecolor = 'red', markersize= 10)\nplt.title('R2_score vs K value')\nplt.xlabel('K')\nplt.ylabel('R2_score')\nax = plt.xticks(range(1,20))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T16:32:31.171688Z","iopub.status.idle":"2022-03-20T16:32:31.172833Z","shell.execute_reply.started":"2022-03-20T16:32:31.172477Z","shell.execute_reply":"2022-03-20T16:32:31.172567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best k-value for KNN: 4 or 5","metadata":{}},{"cell_type":"markdown","source":"#### PCA part","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# standardize the data before PCA\nscaler = StandardScaler()\nx_scaled = scaler.fit_transform(x_train)\n\n# build PCA model with None n_components (return same amount PC as features)\npca = PCA(n_components = None)\nL = pca.fit_transform(x_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:54.989854Z","iopub.execute_input":"2022-03-31T13:22:54.990467Z","iopub.status.idle":"2022-03-31T13:22:55.747553Z","shell.execute_reply.started":"2022-03-31T13:22:54.990426Z","shell.execute_reply":"2022-03-31T13:22:55.74663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# round up the target with 10 to prevent chaos in visualization\ny_rounded = y_train.copy()\ny_rounded['congestion'] = np.round(y_rounded['congestion'], -1)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:56.428688Z","iopub.execute_input":"2022-03-31T13:22:56.429384Z","iopub.status.idle":"2022-03-31T13:22:56.455398Z","shell.execute_reply.started":"2022-03-31T13:22:56.429333Z","shell.execute_reply":"2022-03-31T13:22:56.453962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the explanied variance ratio\nprint(pca.explained_variance_ratio_ * 100);","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:58.189014Z","iopub.execute_input":"2022-03-31T13:22:58.189741Z","iopub.status.idle":"2022-03-31T13:22:58.194964Z","shell.execute_reply.started":"2022-03-31T13:22:58.189703Z","shell.execute_reply":"2022-03-31T13:22:58.19424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First two components captured around 64% of variability. Let's plot out and check is there any cluster can be found.","metadata":{}},{"cell_type":"code","source":"# plot out the PCA graph\ndef pca_scatter(pca, standardised_value, classifs):\n    foo = pca.transform(standardised_value)\n    bar = pd.DataFrame(zip(foo[:,0], foo[:,1], classifs), columns = ['PC1', 'PC2','Class'])\n    sns.lmplot(data = bar, x = 'PC1', y = 'PC2', hue = 'Class', fit_reg = False)\n    \npca_scatter(pca, x_scaled, y_rounded['congestion'])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:22:59.674836Z","iopub.execute_input":"2022-03-31T13:22:59.675366Z","iopub.status.idle":"2022-03-31T13:23:07.232001Z","shell.execute_reply.started":"2022-03-31T13:22:59.675328Z","shell.execute_reply":"2022-03-31T13:23:07.231303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no obvious cluster but there is a pattern. Let's check the feature with high co-efficient.","metadata":{}},{"cell_type":"code","source":"# absolute all the feature coefficient\npca_components = abs(pca.components_)\nprint('Top 3 most import features in each component:')\n# get the most highest absolute coefficient in all PC\nfor row in range(pca_components.shape[0]):\n    temp = np.argpartition(-(pca_components[row]),3)\n    \n    indices = temp[np.argsort((-pca_components[row])[temp])][:3]\n    \n    print(f'Component {row}: {x_train.columns[indices].to_list()}')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:10.695588Z","iopub.execute_input":"2022-03-31T13:23:10.695842Z","iopub.status.idle":"2022-03-31T13:23:10.704891Z","shell.execute_reply.started":"2022-03-31T13:23:10.695813Z","shell.execute_reply":"2022-03-31T13:23:10.704104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try using the reduced Data to train and predict the result","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\ntest_size = 0.25\nX_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size = test_size)\n\n# build up the pipeline for data input & prediction\n_sc = StandardScaler()\n_pca = PCA(n_components = None)\n_model = KNeighborsRegressor(n_neighbors = 5)\n\npipe = Pipeline([\n    ('std_scaler', _sc),\n    ('pca', _pca),\n    ('knn_5n', _model)\n])\n\n# fit split data and check with the metrics\npipe.fit(X_train.values, Y_train.values)\npred_i = pipe.predict(X_test.values)\nprint(f'MAE : {mean_absolute_error(Y_test, pred_i)}')\nprint(f'MSE : {mean_squared_error(Y_test, pred_i)}')\nprint(f'R2  : {r2_score(Y_test, pred_i)}')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:25:29.186829Z","iopub.execute_input":"2022-03-31T13:25:29.187097Z","iopub.status.idle":"2022-03-31T13:25:34.842865Z","shell.execute_reply.started":"2022-03-31T13:25:29.18706Z","shell.execute_reply":"2022-03-31T13:25:34.842101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the weight graph of k-Neighbors for points in 'x' 0 / 1 to check with any pattern\nA = _model.kneighbors_graph(X_test[X_test['x'] == 0].values, n_neighbors = 5)\nB = _model.kneighbors_graph(X_test[X_test['x'] == 1].values, n_neighbors = 5)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:24.921038Z","iopub.execute_input":"2022-03-31T13:23:24.921688Z","iopub.status.idle":"2022-03-31T13:23:35.886526Z","shell.execute_reply.started":"2022-03-31T13:23:24.921649Z","shell.execute_reply":"2022-03-31T13:23:35.88576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize the pattern and check any findings\nplt.figure(figsize= (20,16))\nplt.spy(A, c = 'red', markersize = 1)\nplt.spy(B, c = 'blue', markersize = 1, alpha = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:35.888164Z","iopub.execute_input":"2022-03-31T13:23:35.888457Z","iopub.status.idle":"2022-03-31T13:23:36.803597Z","shell.execute_reply.started":"2022-03-31T13:23:35.888421Z","shell.execute_reply":"2022-03-31T13:23:36.802962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance is not bad and try to predict with the test set and submit the result","metadata":{}},{"cell_type":"code","source":"# predict the result with the pipe built\npred_final3 = pipe.predict(x_test)\n# output the result as the submission template\nknn_result = pd.DataFrame()\nknn_result['row_id'] = x_test.index\nknn_result['congestion'] = pred_final3\nknn_result.to_csv('knn_submission3.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T18:21:39.978283Z","iopub.execute_input":"2022-03-20T18:21:39.978987Z","iopub.status.idle":"2022-03-20T18:21:40.035248Z","shell.execute_reply.started":"2022-03-20T18:21:39.978947Z","shell.execute_reply":"2022-03-20T18:21:40.034466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the submission, the score was decreased from 6.029 to 5.503. \n\nDimension reduction is worked in the performance improvement.\n\nTrain_test_split also provided better MAE instead of using the whole training set.","metadata":{}},{"cell_type":"markdown","source":"#### UMAP","metadata":{}},{"cell_type":"markdown","source":"Let's using UMAP and plot it out for visualization.","metadata":{}},{"cell_type":"code","source":"import umap\n# build the UMAP reducer\nreducer = umap.UMAP()\n# fit the data\nembedding = reducer.fit_transform(x_train,y_rounded['congestion'])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T18:28:10.801137Z","iopub.execute_input":"2022-03-20T18:28:10.801613Z","iopub.status.idle":"2022-03-20T18:38:52.66904Z","shell.execute_reply.started":"2022-03-20T18:28:10.801561Z","shell.execute_reply":"2022-03-20T18:38:52.667907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot it with the rounded group data again.","metadata":{}},{"cell_type":"code","source":"plt.scatter(reducer.embedding_[:,0], reducer.embedding_[:,1], s = 5, c = y_rounded['congestion'], cmap = 'Spectral')\nplt.gca().set_aspect('equal', 'datalim')\nplt.title(\"Visualizating the training data with UMAP\", fontsize = 24)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T18:42:00.646005Z","iopub.execute_input":"2022-03-20T18:42:00.646601Z","iopub.status.idle":"2022-03-20T18:42:21.483571Z","shell.execute_reply.started":"2022-03-20T18:42:00.646564Z","shell.execute_reply":"2022-03-20T18:42:21.482881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems it is not useful to use UMAP and we will work on PCA as previous findings.","metadata":{}},{"cell_type":"markdown","source":"#### Cut off date with PCA","metadata":{}},{"cell_type":"markdown","source":"As timeseries data, the training set should be started from June instead of the start from April since the closest data may have similar information due to the weather/ travel peak season. The information for June and April may be different. It's aimed to reduce the bias and make sure the training set and testing set got similar data distribution. Let's check the MAE was improved or not.","metadata":{}},{"cell_type":"code","source":"# cutoff the month from August for getting related information\nx_smaller_train = x_train[x_train['month'] >= 6]\ny_smaller_train = y_train.iloc[x_smaller_train.index]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:26:15.314591Z","iopub.execute_input":"2022-03-31T13:26:15.31485Z","iopub.status.idle":"2022-03-31T13:26:15.350897Z","shell.execute_reply.started":"2022-03-31T13:26:15.314821Z","shell.execute_reply":"2022-03-31T13:26:15.350167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# build up the pipeline for data input & prediction\n\ntest_size = 0.25\nX_train, X_test, Y_train, Y_test = train_test_split(x_smaller_train, y_smaller_train, test_size = test_size)\n\n_sc = StandardScaler()\n_pca = PCA(n_components = None)\n_model = KNeighborsRegressor(n_neighbors = 5)\n\npipe = Pipeline([\n    ('std_scaler', _sc),\n    ('pca', _pca),\n    ('knn_5n', _model)\n])\n\n# fit split data and check with the metrics\npipe.fit(X_train.values, Y_train.values)\npred_i = pipe.predict(X_test.values)\nprint(f'MAE : {mean_absolute_error(Y_test, pred_i)}')\nprint(f'MSE : {mean_squared_error(Y_test, pred_i)}')\nprint(f'R2  : {r2_score(Y_test, pred_i)}')\npred_distribution = pipe.predict(x_test.values)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:30:57.156735Z","iopub.execute_input":"2022-03-31T13:30:57.157549Z","iopub.status.idle":"2022-03-31T13:31:01.0129Z","shell.execute_reply.started":"2022-03-31T13:30:57.1575Z","shell.execute_reply":"2022-03-31T13:31:01.011192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the distribution for both training set & predicted result\nax = sns.distplot(y_train, hist = False, label = 'Train set')\nax = sns.distplot(pred_distribution, hist = False, label = 'Result')\nplt.title('Distribution of Train set and result')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:31:03.03882Z","iopub.execute_input":"2022-03-31T13:31:03.039373Z","iopub.status.idle":"2022-03-31T13:31:06.193629Z","shell.execute_reply.started":"2022-03-31T13:31:03.03933Z","shell.execute_reply":"2022-03-31T13:31:06.192948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a different for 60 - 80 congestion and the time cutoff didn't improve the performance much.","metadata":{}},{"cell_type":"markdown","source":"#### KNN hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import GridSearchCV\n\n# List the hyperparameters want to tune\nleaf_size = list(range(1,50))\nn_neighbors = [4, 5]\np = [1,2]\n\nhyperparameters = dict(leaf_size = leaf_size, n_neighbors = n_neighbors, p = p)\n\n# Split the training set into train & test set for training\ntest_size = 0.25\nX_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size = test_size)\n# build up the pipeline for data input & prediction\n_sc = StandardScaler()\n_pca = PCA(n_components = None)\n_model = KNeighborsRegressor()\n_clf = GridSearchCV(_model, hyperparameters, cv = 10)\n\npipe = Pipeline([\n    ('std_scaler', _sc),\n    ('pca', _pca),\n    ('clf', _clf)\n])\n\nbest_model = pipe.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T17:40:54.672952Z","iopub.execute_input":"2022-03-24T17:40:54.673612Z","iopub.status.idle":"2022-03-24T17:42:41.96643Z","shell.execute_reply.started":"2022-03-24T17:40:54.673576Z","shell.execute_reply":"2022-03-24T17:42:41.965644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Best leaf size: {_clf.best_estimator_.get_params()[\"leaf_size\"]}')\nprint(f'Best p: {_clf.best_estimator_.get_params()[\"p\"]}')\nprint(f'Best n_neighbors: {_clf.best_estimator_.get_params()[\"n_neighbors\"]}')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T17:43:53.961315Z","iopub.execute_input":"2022-03-24T17:43:53.961597Z","iopub.status.idle":"2022-03-24T17:43:53.967784Z","shell.execute_reply.started":"2022-03-24T17:43:53.961566Z","shell.execute_reply":"2022-03-24T17:43:53.966805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We finally using these best hyperparameter & PCA to predict our final submission.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# build up the pipeline for data input & prediction\n\ntest_size = 0.25\nX_train, X_test, Y_train, Y_test = train_test_split(x_smaller_train, y_smaller_train, test_size = test_size)\n\n_sc = StandardScaler()\n_pca = PCA(n_components = None)\n_model = KNeighborsRegressor(n_neighbors = 5, leaf_size = 35, p = 2)\n\npipe = Pipeline([\n    ('std_scaler', _sc),\n    ('pca', _pca),\n    ('knn', _model)\n])\n\n# fit split data and check with the metrics\npipe.fit(X_train.values, Y_train.values)\npred_i = pipe.predict(X_test.values)\nprint(f'MAE : {mean_absolute_error(Y_test, pred_i)}')\nprint(f'MSE : {mean_squared_error(Y_test, pred_i)}')\nprint(f'R2  : {r2_score(Y_test, pred_i)}')\npred_final = pipe.predict(x_test.values)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:36:14.100581Z","iopub.execute_input":"2022-03-31T13:36:14.10084Z","iopub.status.idle":"2022-03-31T13:36:17.557802Z","shell.execute_reply.started":"2022-03-31T13:36:14.100812Z","shell.execute_reply":"2022-03-31T13:36:17.557073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output the result as the submission template\nknn_result = pd.DataFrame()\nknn_result['row_id'] = x_test.index\nknn_result['congestion'] = pred_final\nknn_result.to_csv('knn_submission.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]}]}