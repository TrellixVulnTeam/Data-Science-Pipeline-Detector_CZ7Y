{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ExtraTrees Regression for the March TPS\n\nThis model is based on my [EDA notebook](https://www.kaggle.com/ambrosm/tpsmar22-eda-which-makes-sense).\n\nIt uses an `ExtraTreesRegressor`. According to the documentation, `ExtraTreesRegressor(criterion=“absolute_error”)` optimizes for MAE, but with this criterion it is unacceptably slow. It is better to optimize the forest for MSE.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator, PercentFormatter\nfrom cycler import cycler\nfrom IPython import display\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\noldcycler = plt.rcParams['axes.prop_cycle']\nplt.rcParams['axes.facecolor'] = '#0057b8' # blue\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n                                         oldcycler.by_key()['color'][1:])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T15:32:37.820234Z","iopub.execute_input":"2022-03-01T15:32:37.820672Z","iopub.status.idle":"2022-03-01T15:32:39.310067Z","shell.execute_reply.started":"2022-03-01T15:32:37.820563Z","shell.execute_reply":"2022-03-01T15:32:39.308893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_orig = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', index_col='row_id', parse_dates=['time'])\ntest_orig = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv', index_col='row_id', parse_dates=['time'])\ntrain_orig.shape, test_orig.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:32:39.312769Z","iopub.execute_input":"2022-03-01T15:32:39.31313Z","iopub.status.idle":"2022-03-01T15:32:40.552534Z","shell.execute_reply.started":"2022-03-01T15:32:39.313084Z","shell.execute_reply":"2022-03-01T15:32:40.551537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop outliers","metadata":{}},{"cell_type":"code","source":"# Memorial Day\ntrain_orig = train_orig[(train_orig.time.dt.month != 5) | (train_orig.time.dt.day != 27)]\n\n# July 4\ntrain_orig = train_orig[(train_orig.time.dt.month != 7) | (train_orig.time.dt.day != 4)]\n\n# Labor Day\ntrain_orig = train_orig[(train_orig.time.dt.month != 9) | (train_orig.time.dt.day != 2)]\n\n# Maybe drop some more ...","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:32:40.55394Z","iopub.execute_input":"2022-03-01T15:32:40.554203Z","iopub.status.idle":"2022-03-01T15:32:41.21246Z","shell.execute_reply.started":"2022-03-01T15:32:40.55417Z","shell.execute_reply":"2022-03-01T15:32:41.210799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"code","source":"# Feature engineering\n# Combine x, y and direction into a single categorical feature with 65 unique values\n# which can be one-hot encoded\ndef place_dir(df):\n    return df.apply(lambda row: f\"{row.x}-{row.y}-{row.direction}\", axis=1).values.reshape([-1, 1])\n\nfor df in [train_orig, test_orig]:\n    df['place_dir'] = place_dir(df)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:32:41.215159Z","iopub.execute_input":"2022-03-01T15:32:41.21611Z","iopub.status.idle":"2022-03-01T15:33:18.388179Z","shell.execute_reply.started":"2022-03-01T15:32:41.216052Z","shell.execute_reply":"2022-03-01T15:33:18.387045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ohe = OneHotEncoder(drop='first', sparse=False)\nohe.fit(train_orig[['place_dir']])\n\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    new_df = pd.DataFrame(ohe.transform(df[['place_dir']]),\n                          columns=ohe.categories_[0][1:],\n                          index=df.index)\n    new_df['saturday'] = df.time.dt.weekday == 5\n    new_df['sunday'] = df.time.dt.weekday == 6\n    new_df['daytime'] = df.time.dt.hour * 60 + df.time.dt.minute\n    new_df['dayofyear'] = df.time.dt.dayofyear # to model the trend\n    return new_df\n\n\ntrain = engineer(train_orig)\ntest = engineer(test_orig)\n\ntrain['congestion'] = train_orig.congestion\n\nfeatures = list(test.columns)\nprint(list(features))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:57:59.363062Z","iopub.execute_input":"2022-03-01T16:57:59.363474Z","iopub.status.idle":"2022-03-01T16:58:00.915745Z","shell.execute_reply.started":"2022-03-01T16:57:59.363432Z","shell.execute_reply":"2022-03-01T16:58:00.914829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation\n\nCurrently I use a set of afternoons in August and September for validation (i.e. a single train-test split rather than cross-validation). This may change in the future.\n\nI tried HuberRegressor with a low epsilon because this is one of the few linear models which can optimize mean absolute error, but RandomForestRegressor is better. As I said in the introduction, `RandomForestRegressor(criterion=“absolute_error”)` would optimize for MAE, but with this criterion it is unacceptably slow. It is better to optimize the random forest for MSE.\n\nAnd `ExtraTreesRegressor` is even better than `RandomForestRegressor`! \n\nThe bar chart shows that we shouldn't expect much improvement by increasing n_estimators above 1000.","metadata":{}},{"cell_type":"code","source":"%%time\n# Split into train and test\n# Use all Monday-Wednesday afternoons in August and September for validation\nval_idx = ((train_orig.time.dt.month >= 8) & \n           (train_orig.time.dt.weekday <= 3) &\n           (train_orig.time.dt.hour >= 12)).values\ntrain_idx = ~val_idx\n\nX_tr, X_va = train.loc[train_idx, features], train.loc[val_idx, features]\ny_tr, y_va = train.loc[train_idx, 'congestion'], train.loc[val_idx, 'congestion']\n\n# Train and validate the regressor\n#pipe = make_pipeline(StandardScaler(), HuberRegressor(epsilon=1.001, alpha=100))\n# pipe = RandomForestRegressor(n_estimators=0, max_samples=0.03,\n#                             n_jobs=-1, random_state=1)\npipe = ExtraTreesRegressor(n_estimators=0,\n                           #bootstrap=True, max_samples=0.20,\n                           min_samples_split=101,\n                           n_jobs=-1, random_state=1)\nestimators_list, mae_list = [], []\nn_estimators = 4\ninitialized = False\nwhile n_estimators < 256:\n    n_estimators *= 4\n    pipe.set_params(n_estimators=n_estimators,\n                    warm_start=initialized)\n    pipe.fit(X_tr, y_tr)\n    initialized = True\n\n    # Compute the (intermediate) validation score\n    y_va_pred = pipe.predict(X_va)\n    \n    estimators_list.append(pipe.get_params()['n_estimators'])\n    mae_list.append(mean_absolute_error(y_va, y_va_pred))\n    print(f\"{estimators_list[-1]:4} estimators:   \"\n          f\"Validation MAE = {mae_list[-1]:.5f}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:59:58.611936Z","iopub.execute_input":"2022-03-01T16:59:58.612217Z","iopub.status.idle":"2022-03-01T17:10:40.343175Z","shell.execute_reply.started":"2022-03-01T16:59:58.612182Z","shell.execute_reply":"2022-03-01T17:10:40.342512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.bar(range(len(estimators_list)), mae_list)\nplt.xticks(range(len(estimators_list)), estimators_list)\nplt.ylim(6.10, 6.40)\nplt.ylabel('Validation MAE')\nplt.xlabel('n_estimators')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T15:55:45.124996Z","iopub.execute_input":"2022-03-01T15:55:45.125289Z","iopub.status.idle":"2022-03-01T15:55:45.335494Z","shell.execute_reply.started":"2022-03-01T15:55:45.125255Z","shell.execute_reply":"2022-03-01T15:55:45.334665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Re-training and submission\n\nWe retrain the classifier on the complete training data, compute the test predictions and then postprocess two special cases (see the [EDA](https://www.kaggle.com/ambrosm/tpsmar22-eda-which-makes-sense) for the special congestion values).","metadata":{}},{"cell_type":"code","source":"%%time\n# Retrain the classifier on the complete training data (except outliers)\npipe.set_params(warm_start=False)\npipe.fit(train[features], train.congestion)\ntest['congestion'] = pipe.predict(test[features]).round(0).astype(int)\nassert test.congestion.min() >= 0\nassert test.congestion.max() <= 100\nsub = test.reset_index()[['row_id', 'congestion']]\n\nsub.to_csv('submission_extratrees.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:35:36.624827Z","iopub.status.idle":"2022-03-01T15:35:36.625697Z","shell.execute_reply.started":"2022-03-01T15:35:36.625426Z","shell.execute_reply":"2022-03-01T15:35:36.625458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of the test predictions\n# compared to the Monday afternoons in August and September\nplt.figure(figsize=(16,3))\nplt.hist(train.congestion[((train_orig.time.dt.month >= 8) & \n                           (train_orig.time.dt.weekday == 0) &\n                           (train_orig.time.dt.hour >= 12)).values],\n         bins=np.linspace(-0.5, 100.5, 102),\n         density=True, label='Validation',\n         color='#ffd700')\nplt.hist(sub['congestion'], np.linspace(-0.5, 100.5, 102),\n         density=True, rwidth=0.5, label='Test predictions',\n         color='r')\nplt.xlabel('Congestion')\nplt.ylabel('Frequency')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1, decimals=1))\nplt.legend()\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T15:35:36.627467Z","iopub.status.idle":"2022-03-01T15:35:36.628329Z","shell.execute_reply.started":"2022-03-01T15:35:36.62802Z","shell.execute_reply":"2022-03-01T15:35:36.628076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}