{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA which makes sense\n\nThis notebook analyzes the competition data and gives insight on how to proceed with modeling.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom cycler import cycler\nfrom IPython import display\nimport datetime\n\nplt.rcParams['axes.facecolor'] = '#0057b8' # blue\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-26T18:14:16.464911Z","iopub.execute_input":"2022-03-26T18:14:16.465755Z","iopub.status.idle":"2022-03-26T18:14:16.493705Z","shell.execute_reply.started":"2022-03-26T18:14:16.465647Z","shell.execute_reply":"2022-03-26T18:14:16.492941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', index_col='row_id', parse_dates=['time'])\ntest = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv', index_col='row_id', parse_dates=['time'])\n\nprint(train.shape, test.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:16.494942Z","iopub.execute_input":"2022-03-26T18:14:16.495754Z","iopub.status.idle":"2022-03-26T18:14:17.483777Z","shell.execute_reply.started":"2022-03-26T18:14:16.495711Z","shell.execute_reply":"2022-03-26T18:14:17.482963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Geography\n\nThere are 12 roadways, 8 directions and 65 combinations of roadway with direction. This means that on average, a roadway has between 5 and 6 directions. The code below shows this for the training data; the test data has the same geography. There are no missing values here.","metadata":{}},{"cell_type":"code","source":"# Unique roadways\nroadways = train[['x', 'y']].drop_duplicates()\ndisplay.display(roadways)\n\n# Unique directions\nprint('Unique directions:', train.direction.unique())\n\n# Unique roadways with direction\nroad_dir = train[['x', 'y', 'direction']].drop_duplicates()\ndisplay.display(road_dir)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:17.484905Z","iopub.execute_input":"2022-03-26T18:14:17.485123Z","iopub.status.idle":"2022-03-26T18:14:17.706274Z","shell.execute_reply.started":"2022-03-26T18:14:17.485096Z","shell.execute_reply":"2022-03-26T18:14:17.705456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can plot a geographical map of the 12 places with the directions:","metadata":{}},{"cell_type":"code","source":"dir_dict = {'EB': (1, 0), 'NB': (0, 1), 'SB': (0, -1), 'WB': (-1, 0), 'NE': (1, 1), 'SE': (1, -1), 'NW': (-1, 1), 'SW': (-1, -1)}\n\nplt.figure(figsize=(8, 8))\nplt.scatter(roadways.x, roadways.y)\nplt.gca().set_aspect('equal')\nfor _, x, y, d in road_dir.itertuples():\n    dx, dy = dir_dict[d]\n    dx, dy = dx/4, dy/4\n    plt.plot([x, x+dx], [y, y+dy], color='#ffd700')\nplt.gca().xaxis.set_major_locator(MaxNLocator(integer=True)) # only integer labels\nplt.gca().yaxis.set_major_locator(MaxNLocator(integer=True)) # only integer labels\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:17.707934Z","iopub.execute_input":"2022-03-26T18:14:17.708147Z","iopub.status.idle":"2022-03-26T18:14:17.942079Z","shell.execute_reply.started":"2022-03-26T18:14:17.70812Z","shell.execute_reply":"2022-03-26T18:14:17.941455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight:**\n- As congestion is measured for certain points and directions in space, we can expect that these congestions predict future congestion at the nearest point in the given direction. For instance, congestion at (0, 1, eastbound) should be correlated with future congestion at (1, 1, ...).\n- The correlation goes both ways so that we can try to predict backwards: congestion at (1, 1, eastbound) should be correlated with past congestion at (0, 1, ...).\n- At first sight, it is unclear whether we need the geography at all: A simple approach for the competition would be ignoring the geography and creating 65 independent time series.\n- Another simple approach is one-hot encoding the 65 position/direction combinations and using them as features.\n- Although the y coordinate in the diagram grows from bottom to top (south to north), we can't take this for granted. Maybe it should grow from top to bottom.","metadata":{}},{"cell_type":"markdown","source":"# Time\n\nThere are 13059 time values in the training data. As 13059 * 65 = 848835, i.e. the length of the `train` dataframe, we know that at every point in time, the congestion is known for all 65 roadways.","metadata":{}},{"cell_type":"code","source":"unique_times = train.time.unique()\nprint(unique_times.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:17.943557Z","iopub.execute_input":"2022-03-26T18:14:17.944048Z","iopub.status.idle":"2022-03-26T18:14:17.958805Z","shell.execute_reply.started":"2022-03-26T18:14:17.944002Z","shell.execute_reply":"2022-03-26T18:14:17.957207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All training timestamps are between 1991-04-01 00:00 and 1991-09-30 11:40. The test timestamps cover the half day from 1991-09-30 12:00 through 1991-09-30 23:40, which is a Monday.\n\nThe difference between successive training timestamps is almost always 20 minutes, except for the 28 timestamps in the following list:","metadata":{}},{"cell_type":"code","source":"print(unique_times.min(), unique_times.max())\nprint(test.time.min(), test.time.max())\nprint(np.diff(unique_times)[0])\nunique_times[1:][np.diff(unique_times) != np.diff(unique_times)[0]]","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:17.960107Z","iopub.execute_input":"2022-03-26T18:14:17.960466Z","iopub.status.idle":"2022-03-26T18:14:17.974099Z","shell.execute_reply.started":"2022-03-26T18:14:17.960418Z","shell.execute_reply":"2022-03-26T18:14:17.973133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight:**\n- There are missing values, and our training algorithm will have to deal with a noncontiguous time series.\n- As the test set is restricted to one Monday afternoon, perhaps we don't need to model the other days of the week. Maybe we can create a model which takes 6Â½ days from Tuesday morning until Monday noon as input and predicts Monday afternoon.","metadata":{}},{"cell_type":"markdown","source":"# Congestion and its special values\n\nThe congestion values are integers between 0 and 100 (inclusive). \n\n**Insight:** As most regression algorithms output float values, we will have to clip and round the regression output (see discussion post [Why rounding improves the score](https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/301249)).","metadata":{}},{"cell_type":"code","source":"np.unique(train.congestion)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:17.976141Z","iopub.execute_input":"2022-03-26T18:14:17.976722Z","iopub.status.idle":"2022-03-26T18:14:18.022187Z","shell.execute_reply.started":"2022-03-26T18:14:17.976678Z","shell.execute_reply":"2022-03-26T18:14:18.021569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histogram shows a Gaussian distribution with an overlay of certain values which occur much more often than their neighbors. The most prominent values are 15, 20, 21, 29, 34. \n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n#plt.hist(train.congestion, bins=np.linspace(-0.5, 100.5, 102))\nplt.bar(range(101), train.congestion.value_counts().sort_index(), width=1,\n        color=['r' if con in [15, 20, 21, 29, 34] else '#ffd700' for con in range(101)])\nplt.ylabel('Count')\nplt.xlabel('Congestion')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:18.023551Z","iopub.execute_input":"2022-03-26T18:14:18.024688Z","iopub.status.idle":"2022-03-26T18:14:18.408431Z","shell.execute_reply.started":"2022-03-26T18:14:18.024645Z","shell.execute_reply":"2022-03-26T18:14:18.40751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight:**\n- We need a deeper analysis in what contexts the values 15, 20, 21, 29, 34 are overrepresented.\n- It will be difficult to model this overrepresentation with a regression model. Maybe we need to invent special tricks to predict these values (if it is possible at all).\n\nLet's drill down into some roadways to see whether the same values are overrepresented everywhere.","metadata":{}},{"cell_type":"code","source":"plt.subplots(2, 2, sharex=True, sharey=True, figsize=(16, 12))\nfor y in range(4):\n    plt.subplot(2, 2, y+1)\n    vc = train[(train.x == 2) & (train.y == y)].congestion.value_counts().sort_index()\n    plt.bar(vc.index, vc, width=1,\n            color=['r' if con in [15, 20, 21, 29, 34] else '#ffd700' for con in vc.index])\n    plt.ylabel('Count')\n    plt.xlabel('Congestion')\n    plt.title(f\"(x = {2}) & (y = {y})\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:18.411209Z","iopub.execute_input":"2022-03-26T18:14:18.411448Z","iopub.status.idle":"2022-03-26T18:14:19.508514Z","shell.execute_reply.started":"2022-03-26T18:14:18.411421Z","shell.execute_reply":"2022-03-26T18:14:19.507509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obviously, congestions 15, 29 and 34 are a particularity of the roadway with x = 2 and y = 1. We'll drill down further, into the eight directions of this roadway, plotting all congestion values on a time axis, just to see that some of the directions have these special congestion values on every day of the six months of training data. ","metadata":{}},{"cell_type":"code","source":"for direction in train.direction.unique():\n    temp = train[(train.x == 2) & (train.y == 1) & (train.direction == direction)]\n    plt.subplots(1, 2, figsize=(18, 4))\n    plt.subplot(1, 2, 1)\n    vc = temp.congestion.value_counts().sort_index()\n    plt.bar(vc.index, vc, width=1,\n            color=['r' if con in [15, 20, 21, 29, 34] else '#ffd700' for con in vc.index])\n    plt.ylabel('Count')\n    plt.xlabel('Congestion')\n    plt.title(f\"(x = {2}) & (y = {1}) & (direction = {direction})\")\n    plt.subplot(1, 2, 2)\n    plt.scatter(temp.time, temp.congestion, s=1, color=['r' if con in [15, 20, 21, 29, 34] else '#ffd700' for con in temp.congestion])\n    plt.title(f\"(x = {2}) & (y = {1}) & (direction = {direction})\")\n    plt.ylabel('Congestion')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:19.510332Z","iopub.execute_input":"2022-03-26T18:14:19.510667Z","iopub.status.idle":"2022-03-26T18:14:25.886269Z","shell.execute_reply.started":"2022-03-26T18:14:19.510624Z","shell.execute_reply":"2022-03-26T18:14:25.885262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight:** At this level of detail, the dataset no longer looks like something which a linear regression can fit. Decision trees may be the better choice for these data.","metadata":{}},{"cell_type":"markdown","source":"# Dependence on time and date\n\nWe start by looking for a weekly pattern. As was to be expected, there is less traffic on weekends.","metadata":{}},{"cell_type":"code","source":"temp = train.groupby(train.time.dt.dayofweek).congestion.mean()\nplt.figure(figsize=(18, 6))\nplt.title('Days of the week')\nplt.bar(temp.index, temp, color='#ffd700')\nplt.xticks(ticks=temp.index, labels='MTWTFSS')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:25.887982Z","iopub.execute_input":"2022-03-26T18:14:25.888301Z","iopub.status.idle":"2022-03-26T18:14:26.190518Z","shell.execute_reply.started":"2022-03-26T18:14:25.888259Z","shell.execute_reply":"2022-03-26T18:14:26.189736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What about a daily pattern? There is a daily pattern with a morning peak and a higher peak in the late afternoon.","metadata":{}},{"cell_type":"code","source":"temp = train.groupby(train.time.dt.hour + train.time.dt.minute/60).congestion.mean()\nplt.figure(figsize=(18, 6))\nplt.title('Time of the day')\nplt.bar(temp.index, temp, color='#ffd700', width=0.34)\nplt.xticks(range(24))\nplt.xlabel('Time of day')\nplt.ylabel('Congestion')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:26.192047Z","iopub.execute_input":"2022-03-26T18:14:26.19323Z","iopub.status.idle":"2022-03-26T18:14:26.738888Z","shell.execute_reply.started":"2022-03-26T18:14:26.193169Z","shell.execute_reply":"2022-03-26T18:14:26.738198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drilling down we see that every road has its own daily pattern:","metadata":{}},{"cell_type":"code","source":"plt.subplots(2, 2, sharex=True, sharey=True, figsize=(16, 12))\nfor y in range(4):\n    plt.subplot(2, 2, y+1)\n    vc = train[(train.x == 2) & (train.y == y)]\n    temp = vc.groupby(vc.time.dt.hour + vc.time.dt.minute/60).congestion.mean()\n    plt.bar(temp.index, temp, color='#ffd700', width=0.34)\n    plt.xticks(range(24))\n    plt.xlabel('Time of day')\n    plt.ylabel('Congestion')\n    plt.title(f\"(x = {2}) & (y = {y})\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:26.739973Z","iopub.execute_input":"2022-03-26T18:14:26.740309Z","iopub.status.idle":"2022-03-26T18:14:28.032859Z","shell.execute_reply.started":"2022-03-26T18:14:26.740278Z","shell.execute_reply":"2022-03-26T18:14:28.032193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we plot the daily values for all days of the summer of 1991, we see more fluctuations:\n- The last week of April (the fifth week of the diagram) has exceptionally high traffic.\n- May 27 (Memorial Day) is a long weekend with little traffic on Monday.\n- The fourth of July (which was a Thursday) has exceptionally low traffic.\n- Labor day (September 2, the first Monday of September) has exceptionally low traffic.\n- The last two weekends in September look strange. Friday September 27 has very high traffic.\n- The rightmost bar of the diagram (Monday September 30) is quite low. This can probably be explained because the training data contains only the morning of this day (the afternoon is the test data).\n- Overall, there seem to be weeks with high traffic and weeks with low traffic.\n\n(I used [this calendar](https://www.timeanddate.com/calendar/?year=1991&country=1) for looking up the holidays.)\n\n**Insight:**\n- We will have to deal with outliers. A simple approach is dropping all the holidays before training.\n- If morning and afternoon of the same day are correlated, the morning of September 30 will play a special role in predicting the test afternoon.\n- We may need to find suitable external data to explain the high and low traffic weeks.\n- The worst case for our predictions will be if September 30 is a holiday or there is a big event which changes the traffic patterns.\n- A good validation strategy will be important. Perhaps we can use a few Monday afternoons as validation set.","metadata":{}},{"cell_type":"code","source":"temp = train.groupby(train.time.dt.date).congestion.mean()\nplt.figure(figsize=(18, 6))\nplt.title('Daily congestion')\nplt.bar(temp.index, temp, color='#ffd700')\nplt.ylim(40, 52)\nfor holiday_name, month, day in [('Memorial Day', 5, 27), ('Fourth of July', 7, 4), ('Labor Day', 9, 2)]:\n    date = datetime.date(1991, month, day)\n    plt.annotate(holiday_name,\n                 (np.datetime64(date), temp.loc[date]),\n                 xytext=(np.datetime64(date), temp.loc[date]-2),\n                 arrowprops={'arrowstyle': '->'},\n                 weight='bold',\n                 color='k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:28.033872Z","iopub.execute_input":"2022-03-26T18:14:28.034171Z","iopub.status.idle":"2022-03-26T18:14:28.91938Z","shell.execute_reply.started":"2022-03-26T18:14:28.034144Z","shell.execute_reply":"2022-03-26T18:14:28.918635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trend","metadata":{}},{"cell_type":"markdown","source":"We ca fit a linear regression to the daily averages to see if there is any significant growth during the six months. The diagram shows that the congestion grows by less than 0.2 over the whole period. I cannot yet tell whether this growth is significant.\n\n**Insight:** \n- Considering that the total growth amounts to 0.2 and we are predicting integers, we may neglect growth for the beginning.\n- Before we include the trend as a feature in a model, we should test its significance. ","metadata":{}},{"cell_type":"code","source":"temp = train.groupby(train.time.dt.date).congestion.mean()\nplt.figure(figsize=(18, 6))\nplt.title('Trend')\npoly = np.polynomial.polynomial.Polynomial.fit(range(len(temp.index)), temp, deg=1)\nplt.plot(temp.index, poly(range(len(temp.index))))\nplt.ylim(47, 48)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:28.920805Z","iopub.execute_input":"2022-03-26T18:14:28.921262Z","iopub.status.idle":"2022-03-26T18:14:29.461649Z","shell.execute_reply.started":"2022-03-26T18:14:28.921218Z","shell.execute_reply":"2022-03-26T18:14:29.460766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Alternative representations\n\nThe original dataframe has 848835 rows Ã 5 columns. The last column, `congestion` is the target, and every timestamp occurs 65 times. We can pivot the dataframe to get alternative representations, which may be helpful to create models:\n\n1. We can pivot the dataframe so that all 13059 timestamps occur only once. The new dataframe has 65 target columns. We can interpret the 65 target columns as 65 independent univariate time series, or we can look at them as a single multivariate time series.\n\n2. We can pivot the dataframe even more to get one row per day (i.e. 183 rows for the 183 days). This gives 4680  columns or 4680 independent time series.","metadata":{}},{"cell_type":"code","source":"# Original dataframe with a single target column\npd.set_option(\"display.max_rows\", 5, \"display.max_columns\", 15, \"display.width\", 120)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:29.46283Z","iopub.execute_input":"2022-03-26T18:14:29.463064Z","iopub.status.idle":"2022-03-26T18:14:29.479077Z","shell.execute_reply.started":"2022-03-26T18:14:29.463036Z","shell.execute_reply":"2022-03-26T18:14:29.478318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pivoted dataframe with every timestamp occurring only once and 65 target columns\ntrain.pivot(index=['time'], columns=['x', 'y', 'direction'])","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:29.480478Z","iopub.execute_input":"2022-03-26T18:14:29.480904Z","iopub.status.idle":"2022-03-26T18:14:29.932353Z","shell.execute_reply.started":"2022-03-26T18:14:29.480866Z","shell.execute_reply":"2022-03-26T18:14:29.931456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pivoted dataframe with one row per day and 4630 target columns\n# Note that the afternoon of the last day has been filled with NaN\ntrain2 = train.copy()\ntrain2['date'] = train2.time.dt.date\ntrain2['hour'] = train2.time.dt.hour\ntrain2['minute'] = train2.time.dt.minute\ntrain2.drop(columns=['time'], inplace=True)\ntrain2.pivot(index=['date'], columns=['x', 'y', 'direction', 'hour', 'minute'])","metadata":{"execution":{"iopub.status.busy":"2022-03-26T18:14:29.933806Z","iopub.execute_input":"2022-03-26T18:14:29.934029Z","iopub.status.idle":"2022-03-26T18:14:30.972757Z","shell.execute_reply.started":"2022-03-26T18:14:29.934Z","shell.execute_reply":"2022-03-26T18:14:30.971824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nThis will be an interesting competition!","metadata":{}}]}