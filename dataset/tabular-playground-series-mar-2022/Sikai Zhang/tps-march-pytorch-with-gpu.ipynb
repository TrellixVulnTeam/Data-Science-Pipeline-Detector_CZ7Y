{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-17T07:19:46.692666Z","iopub.execute_input":"2022-03-17T07:19:46.692937Z","iopub.status.idle":"2022-03-17T07:19:46.72484Z","shell.execute_reply.started":"2022-03-17T07:19:46.692863Z","shell.execute_reply":"2022-03-17T07:19:46.724037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', index_col=0, parse_dates=['time'])\ntest = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv', index_col=0, parse_dates=['time'])","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:46.726348Z","iopub.execute_input":"2022-03-17T07:19:46.72665Z","iopub.status.idle":"2022-03-17T07:19:47.657239Z","shell.execute_reply.started":"2022-03-17T07:19:46.726617Z","shell.execute_reply":"2022-03-17T07:19:47.656505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)  \n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:47.660424Z","iopub.execute_input":"2022-03-17T07:19:47.660624Z","iopub.status.idle":"2022-03-17T07:19:47.673324Z","shell.execute_reply.started":"2022-03-17T07:19:47.660598Z","shell.execute_reply":"2022-03-17T07:19:47.672472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:47.67517Z","iopub.execute_input":"2022-03-17T07:19:47.675792Z","iopub.status.idle":"2022-03-17T07:19:47.80297Z","shell.execute_reply.started":"2022-03-17T07:19:47.675757Z","shell.execute_reply":"2022-03-17T07:19:47.801188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nfrom math import sin, cos, pi\n\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:47.804168Z","iopub.execute_input":"2022-03-17T07:19:47.804421Z","iopub.status.idle":"2022-03-17T07:19:49.955524Z","shell.execute_reply.started":"2022-03-17T07:19:47.804388Z","shell.execute_reply":"2022-03-17T07:19:49.954779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledgement\n* AMBROSM--[TPSMAR22 Random Forest](https://www.kaggle.com/ambrosm/tpsmar22-random-forest)\n* CHECHE--[TPS_2022_03_pytorch_score(4.923)](https://www.kaggle.com/zhangcheche/tps-2022-03-pytorch-score-4-923)\n* AMBROSM--[TPSMAR22 EDA which makes sense ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/ambrosm/tpsmar22-eda-which-makes-sense)\n* MARTYNOV ANDREY--[TPS Mar 22, Step 0.1, Special values](https://www.kaggle.com/martynovandrey/tps-mar-22-step-0-1-special-values/notebook)\n* AMBROSM--[TPSMAR22 Generalizing the Special Values](https://www.kaggle.com/ambrosm/tpsmar22-generalizing-the-special-values?scriptVersionId=90141945)","metadata":{}},{"cell_type":"markdown","source":"# Drop Holidays","metadata":{}},{"cell_type":"code","source":"# Memorial Day\ntrain = train[(train.time.dt.month != 5) | (train.time.dt.day != 27)]\n\n# July 4\ntrain = train[(train.time.dt.month != 7) | (train.time.dt.day != 4)]\n\n# Labor Day\ntrain = train[(train.time.dt.month != 9) | (train.time.dt.day != 2)]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:49.95677Z","iopub.execute_input":"2022-03-17T07:19:49.95701Z","iopub.status.idle":"2022-03-17T07:19:50.486777Z","shell.execute_reply.started":"2022-03-17T07:19:49.956977Z","shell.execute_reply":"2022-03-17T07:19:50.486028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n## 1. Convert raw data to location, direction, data, and time","metadata":{}},{"cell_type":"code","source":"def fe0(data):\n    data['weekday'] = data.time.dt.weekday\n    data['hour'] = data.time.dt.hour\n    data['timeofday'] = data.time.dt.time\n\n    data['saturday'] = data['weekday'] == 5\n    data['sunday'] = data['weekday'] == 6\n    data['minute'] = data.time.dt.minute\n    data = data.drop(columns='time')\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:50.488169Z","iopub.execute_input":"2022-03-17T07:19:50.48869Z","iopub.status.idle":"2022-03-17T07:19:50.495272Z","shell.execute_reply.started":"2022-03-17T07:19:50.488654Z","shell.execute_reply":"2022-03-17T07:19:50.494649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = fe0(train)\ntest = fe0(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:50.49618Z","iopub.execute_input":"2022-03-17T07:19:50.496397Z","iopub.status.idle":"2022-03-17T07:19:51.23275Z","shell.execute_reply.started":"2022-03-17T07:19:50.496372Z","shell.execute_reply":"2022-03-17T07:19:51.23202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Histogram for Training Data","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(20,8))\nbin_weekday = list(range(8))\naxs[0].hist(train.weekday, bin_weekday, rwidth=0.5)\naxs[0].set_title('weekday')\naxs[0].set_xticks(bin_weekday)\naxs[0].set_ylabel('count')\n\nbin_hour = list(range(25))\naxs[1].hist(train.hour, bin_hour, rwidth=0.7)\naxs[1].set_title('hour')\naxs[1].set_xticks(bin_hour)\naxs[1].set_ylabel('count')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:51.234112Z","iopub.execute_input":"2022-03-17T07:19:51.234524Z","iopub.status.idle":"2022-03-17T07:19:51.838898Z","shell.execute_reply.started":"2022-03-17T07:19:51.234487Z","shell.execute_reply":"2022-03-17T07:19:51.837911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = train.groupby(train.weekday).congestion.mean()\nplt.figure(figsize=(18, 6))\nplt.bar(temp.index, temp)\nplt.xticks(ticks=temp.index, labels='MTWTFSS')\nplt.xlabel('Days of the week')\nplt.ylabel('Mean of Congestion')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:51.84387Z","iopub.execute_input":"2022-03-17T07:19:51.844156Z","iopub.status.idle":"2022-03-17T07:19:52.130982Z","shell.execute_reply.started":"2022-03-17T07:19:51.84412Z","shell.execute_reply":"2022-03-17T07:19:52.1302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Test Data","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(20,8))\nbin_weekday = list(range(8))\naxs[0].hist(test.weekday, bin_weekday, rwidth=0.5)\naxs[0].set_title('weekday')\naxs[0].set_xticks(bin_weekday)\naxs[0].set_ylabel('count')\n\nbin_hour = list(range(25))\naxs[1].hist(test.hour, bin_hour, rwidth=0.7)\naxs[1].set_title('hour')\naxs[1].set_xticks(bin_hour)\naxs[1].set_ylabel('count')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.134542Z","iopub.execute_input":"2022-03-17T07:19:52.134811Z","iopub.status.idle":"2022-03-17T07:19:52.58254Z","shell.execute_reply.started":"2022-03-17T07:19:52.134776Z","shell.execute_reply":"2022-03-17T07:19:52.581841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use the training data after 12:00 only.","metadata":{}},{"cell_type":"code","source":"train = train[train.hour >= 12]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.584069Z","iopub.execute_input":"2022-03-17T07:19:52.584579Z","iopub.status.idle":"2022-03-17T07:19:52.616619Z","shell.execute_reply.started":"2022-03-17T07:19:52.584541Z","shell.execute_reply":"2022-03-17T07:19:52.615995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train.congestion\ntrain = train.drop(columns='congestion')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.624206Z","iopub.execute_input":"2022-03-17T07:19:52.624548Z","iopub.status.idle":"2022-03-17T07:19:52.642871Z","shell.execute_reply.started":"2022-03-17T07:19:52.62445Z","shell.execute_reply":"2022-03-17T07:19:52.642231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.64418Z","iopub.execute_input":"2022-03-17T07:19:52.644451Z","iopub.status.idle":"2022-03-17T07:19:52.662008Z","shell.execute_reply.started":"2022-03-17T07:19:52.644417Z","shell.execute_reply":"2022-03-17T07:19:52.661378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. One-hot encode","metadata":{}},{"cell_type":"code","source":"ohe = OneHotEncoder(drop='first', sparse=False)\nohe.fit(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.664102Z","iopub.execute_input":"2022-03-17T07:19:52.664532Z","iopub.status.idle":"2022-03-17T07:19:52.768974Z","shell.execute_reply.started":"2022-03-17T07:19:52.664498Z","shell.execute_reply":"2022-03-17T07:19:52.768351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fe1(data):\n    data_ohe = ohe.transform(data)\n    df = pd.DataFrame(data_ohe, index=data.index)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.771209Z","iopub.execute_input":"2022-03-17T07:19:52.771458Z","iopub.status.idle":"2022-03-17T07:19:52.776072Z","shell.execute_reply.started":"2022-03-17T07:19:52.771433Z","shell.execute_reply":"2022-03-17T07:19:52.775402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = fe1(train)\nx_test = fe1(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:52.777386Z","iopub.execute_input":"2022-03-17T07:19:52.777835Z","iopub.status.idle":"2022-03-17T07:19:53.771637Z","shell.execute_reply.started":"2022-03-17T07:19:52.777802Z","shell.execute_reply":"2022-03-17T07:19:53.770873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_feature = x_data.shape[1]\nnum_feature","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:53.772749Z","iopub.execute_input":"2022-03-17T07:19:53.773Z","iopub.status.idle":"2022-03-17T07:19:53.778917Z","shell.execute_reply.started":"2022-03-17T07:19:53.772967Z","shell.execute_reply":"2022-03-17T07:19:53.77827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch\n## Send data to CUDA","metadata":{}},{"cell_type":"code","source":"x_data = x_data.values\nx_test = x_test.values\ntarget = target.values.reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:53.779906Z","iopub.execute_input":"2022-03-17T07:19:53.780472Z","iopub.status.idle":"2022-03-17T07:19:53.790009Z","shell.execute_reply.started":"2022-03-17T07:19:53.780435Z","shell.execute_reply":"2022-03-17T07:19:53.789316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = torch.tensor(x_data)\nx_test = torch.tensor(x_test)\ntarget = torch.tensor(target)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:53.790988Z","iopub.execute_input":"2022-03-17T07:19:53.791248Z","iopub.status.idle":"2022-03-17T07:19:53.947035Z","shell.execute_reply.started":"2022-03-17T07:19:53.791214Z","shell.execute_reply":"2022-03-17T07:19:53.946244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Using {device} device')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:53.948195Z","iopub.execute_input":"2022-03-17T07:19:53.948459Z","iopub.status.idle":"2022-03-17T07:19:53.993332Z","shell.execute_reply.started":"2022-03-17T07:19:53.948426Z","shell.execute_reply":"2022-03-17T07:19:53.992393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = x_data.double().to(device)\nx_test = x_test.double().to(device)\ntarget = target.double().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:53.996112Z","iopub.execute_input":"2022-03-17T07:19:53.996405Z","iopub.status.idle":"2022-03-17T07:19:56.709449Z","shell.execute_reply.started":"2022-03-17T07:19:53.996367Z","shell.execute_reply":"2022-03-17T07:19:56.708704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Model","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_data, target)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:56.71086Z","iopub.execute_input":"2022-03-17T07:19:56.71111Z","iopub.status.idle":"2022-03-17T07:19:56.740065Z","shell.execute_reply.started":"2022-03-17T07:19:56.711076Z","shell.execute_reply":"2022-03-17T07:19:56.739434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(num_feature, 300), \n            nn.ReLU(), \n            nn.Linear(300, 100), \n            nn.ReLU(),\n            nn.Linear(100, 50), \n            nn.ReLU(), \n            nn.Linear(50, 1)\n        )\n        \n    def forward(self, x):\n        logits = self.linear_relu_stack(x)\n        return logits\n    \nmodel = Net().double().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:56.741496Z","iopub.execute_input":"2022-03-17T07:19:56.741739Z","iopub.status.idle":"2022-03-17T07:19:56.762502Z","shell.execute_reply.started":"2022-03-17T07:19:56.741707Z","shell.execute_reply":"2022-03-17T07:19:56.761894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weight(layer):\n    if type(layer) == nn.Linear:\n        nn.init.xavier_normal_(layer.weight.data)\nmodel.apply(init_weight)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:56.763945Z","iopub.execute_input":"2022-03-17T07:19:56.764194Z","iopub.status.idle":"2022-03-17T07:19:56.774831Z","shell.execute_reply.started":"2022-03-17T07:19:56.764163Z","shell.execute_reply":"2022-03-17T07:19:56.77404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for X, y in dataloader:\n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    return loss.data\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    test_loss = 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n\n    test_loss /= num_batches\n    return test_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:56.777152Z","iopub.execute_input":"2022-03-17T07:19:56.777398Z","iopub.status.idle":"2022-03-17T07:19:56.783613Z","shell.execute_reply.started":"2022-03-17T07:19:56.777369Z","shell.execute_reply":"2022-03-17T07:19:56.782767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-3\nbatch_size = 128\nepochs = 1000\n\nloss_fn = nn.L1Loss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\ntrain_dataset = TensorDataset(x_train, y_train)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataset = TensorDataset(x_val, y_val)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n\nloss_list_train = []\nloss_list_test = []\nfor t in range(epochs):\n    loss_train = train_loop(train_dataloader, model, loss_fn, optimizer)\n    test_loss = test_loop(val_dataloader, model, loss_fn)\n    loss_list_train.append(loss_train)\n    loss_list_test.append(test_loss)\n    if t % 50 == 0:\n        print(f'epoch {t} loss {test_loss}')\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:19:56.78891Z","iopub.execute_input":"2022-03-17T07:19:56.789118Z","iopub.status.idle":"2022-03-17T07:21:56.107822Z","shell.execute_reply.started":"2022-03-17T07:19:56.789091Z","shell.execute_reply":"2022-03-17T07:21:56.107015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Test Loss","metadata":{}},{"cell_type":"code","source":"plt.plot(range(epochs),loss_list_test)\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:21:56.108975Z","iopub.execute_input":"2022-03-17T07:21:56.10921Z","iopub.status.idle":"2022-03-17T07:21:56.289168Z","shell.execute_reply.started":"2022-03-17T07:21:56.109176Z","shell.execute_reply":"2022-03-17T07:21:56.288506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    y_test = model(x_test)\n    y_test = torch.round(y_test)\ny_test","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:22:22.444854Z","iopub.execute_input":"2022-03-17T07:22:22.445114Z","iopub.status.idle":"2022-03-17T07:22:22.455135Z","shell.execute_reply.started":"2022-03-17T07:22:22.445083Z","shell.execute_reply":"2022-03-17T07:22:22.454377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-mar-2022/sample_submission.csv')\nsub.congestion = y_test.cpu()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:22:24.918647Z","iopub.execute_input":"2022-03-17T07:22:24.919178Z","iopub.status.idle":"2022-03-17T07:22:24.928302Z","shell.execute_reply.started":"2022-03-17T07:22:24.919142Z","shell.execute_reply":"2022-03-17T07:22:24.927539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Special Values","metadata":{}},{"cell_type":"code","source":"special = pd.read_csv('../input/tps-mar-22-special-values/special v2.csv', index_col=\"row_id\")\nspecial = special[['congestion']].rename(columns={'congestion':'special'})\nsub = sub.merge(special, left_index=True, right_index=True, how='left')\nsub['special'] = sub['special'].fillna(sub['congestion']).round().astype(int)\nsubmission_in = sub.drop(['congestion'], axis=1).rename(columns={'special':'congestion'})","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:21:56.348232Z","iopub.execute_input":"2022-03-17T07:21:56.348594Z","iopub.status.idle":"2022-03-17T07:21:56.368032Z","shell.execute_reply.started":"2022-03-17T07:21:56.348554Z","shell.execute_reply":"2022-03-17T07:21:56.36736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generalizing the Special Values","metadata":{}},{"cell_type":"code","source":"# Read and prepare the training data\ntrain = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', parse_dates=['time'])\ntrain['hour'] = train['time'].dt.hour\ntrain['minute'] = train['time'].dt.minute\n\n# Compute the quantiles of workday afternoons in September except Labor Day\nsep = train[(train.time.dt.hour >= 12) & (train.time.dt.weekday < 5) &\n            (train.time.dt.dayofyear >= 246)]\nlower = sep.groupby(['hour', 'minute', 'x', 'y', 'direction']).congestion.quantile(0.15).values\nupper = sep.groupby(['hour', 'minute', 'x', 'y', 'direction']).congestion.quantile(0.7).values\n\n# Clip the submission data to the quantiles\nsubmission_out = submission_in.copy()\nsubmission_out['congestion'] = submission_in.congestion.clip(lower, upper)\nsubmission_out['congestion'] = submission_out.congestion.round().astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_out.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:21:56.36907Z","iopub.execute_input":"2022-03-17T07:21:56.369349Z","iopub.status.idle":"2022-03-17T07:21:56.381495Z","shell.execute_reply.started":"2022-03-17T07:21:56.369298Z","shell.execute_reply":"2022-03-17T07:21:56.38079Z"},"trusted":true},"execution_count":null,"outputs":[]}]}