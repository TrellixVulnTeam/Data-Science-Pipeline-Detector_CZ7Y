{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground Series - Mar 2022 with ETNA ðŸŒ‹","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Notebook uses some unrelesed features, to install the latest release just write \"pip install -U etna\"\n!pip install git+https://github.com/tinkoff-ai/etna.git@3e432df98e1a8ec6d5e0a79e8d26d4220f82042a --ignore-installed -q 2> /dev/null\n!pip install -I jinja2==3.0.3 -q 2> /dev/null   ","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:17:44.173253Z","iopub.execute_input":"2022-03-29T17:17:44.174131Z","iopub.status.idle":"2022-03-29T17:20:05.137828Z","shell.execute_reply.started":"2022-03-29T17:17:44.173956Z","shell.execute_reply":"2022-03-29T17:20:05.136622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"https://github.com/tinkoff-ai/etna\">\n    <img src=\"https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white\"  align='left'>\n</a>","metadata":{}},{"cell_type":"markdown","source":"In this notebook we will make predictions for [Tabular Playground Series - Mar 2022](https://www.kaggle.com/competitions/tabular-playground-series-mar-2022/overview) with [etna time series library](https://github.com/tinkoff-ai/etna/).","metadata":{"execution":{"iopub.status.busy":"2022-03-26T16:10:21.32758Z","iopub.execute_input":"2022-03-26T16:10:21.328461Z","iopub.status.idle":"2022-03-26T16:10:21.342706Z","shell.execute_reply.started":"2022-03-26T16:10:21.328405Z","shell.execute_reply":"2022-03-26T16:10:21.340723Z"}}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:33.645465Z","iopub.execute_input":"2022-03-29T17:22:33.64607Z","iopub.status.idle":"2022-03-29T17:22:33.650598Z","shell.execute_reply.started":"2022-03-29T17:22:33.645995Z","shell.execute_reply":"2022-03-29T17:22:33.649738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"../input/tabular-playground-series-mar-2022/train.csv\"\nTEST_PATH = \"../input/tabular-playground-series-mar-2022/test.csv\"\nHORIZON = 36","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:34.031084Z","iopub.execute_input":"2022-03-29T17:22:34.031412Z","iopub.status.idle":"2022-03-29T17:22:34.03523Z","shell.execute_reply.started":"2022-03-29T17:22:34.031378Z","shell.execute_reply":"2022-03-29T17:22:34.034616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\n\nIn the previous notebook for [TPS Jan 2022](https://www.kaggle.com/code/chikovalexander/tps-jan-2022-etna/edit/run/86568046) we showed how to work with timeseries data using TSDataset. Here, the process of creating the dataset is literally the same, except the new parameter `known_future` in TSDataset constructor. It should contain the columns from `df_exog` which are \"regressors\" - exogenous data known in the future(i.e. \"direction\" of the road).","metadata":{}},{"cell_type":"code","source":"from etna.datasets import TSDataset","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:36.70474Z","iopub.execute_input":"2022-03-29T17:22:36.705087Z","iopub.status.idle":"2022-03-29T17:22:36.708974Z","shell.execute_reply.started":"2022-03-29T17:22:36.70505Z","shell.execute_reply":"2022-03-29T17:22:36.708353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(segments=None):\n    train = pd.read_csv(TRAIN_PATH, parse_dates=[\"time\"])\n    test = pd.read_csv(TEST_PATH, parse_dates=[\"time\"])\n    data = pd.concat([train, test])\n    \n    # Rename columns to fit the ETNA format\n    data = data.drop(columns=[\"row_id\"]).rename(columns={\"time\": \"timestamp\", \"congestion\": \"target\"})\n    data[\"segment\"] = data[\"x\"].astype(str) + \"_\" + data[\"y\"].astype(str) + \"_\" + data[\"direction\"]\n    data = TSDataset.to_flatten(TSDataset(df=TSDataset.to_dataset(data), freq=\"20T\").df)\n    if segments is not None:\n        data = data[data[\"segment\"].isin(segments)]\n\n    # Some FE + mark the categorical columns to be automatically handled with catboost\n    data['moment'] = (data['timestamp'].dt.hour * 3 + data['timestamp'].dt.minute // 20).astype(\"category\") \n    data = data.drop(columns=[\"x\", \"y\", \"direction\"])\n    \n    # Dataframe with targets\n    df = TSDataset.to_dataset(data[[\"timestamp\", \"segment\", \"target\"]]).iloc[:-HORIZON]\n    #Dataframe with exogenous data\n    df_exog = TSDataset.to_dataset(data.drop(columns=[\"target\"]))\n    ts = TSDataset(df=df, freq=\"20T\", df_exog=df_exog, known_future=[\"moment\"])\n    return ts","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:37.759736Z","iopub.execute_input":"2022-03-29T17:22:37.760529Z","iopub.status.idle":"2022-03-29T17:22:37.772544Z","shell.execute_reply.started":"2022-03-29T17:22:37.760483Z","shell.execute_reply":"2022-03-29T17:22:37.771548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we don't need to add prefix \"regressor_\" to all the features we suggest being regressors, dataset will **automatically update the regressors** list after each transformation.Now we do't need to add prefix \"regressor_\" to all the features we sugest to be regressors, dataset will automaticaly updete the regressors list after each transformation.","metadata":{}},{"cell_type":"code","source":"ts = load_dataset()\nts.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:40.590788Z","iopub.execute_input":"2022-03-29T17:22:40.591684Z","iopub.status.idle":"2022-03-29T17:22:46.727025Z","shell.execute_reply.started":"2022-03-29T17:22:40.591642Z","shell.execute_reply":"2022-03-29T17:22:46.726017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\n","metadata":{}},{"cell_type":"markdown","source":"## Special Values\n\nThere are some \"special values\" in the dataset, which were possibly used to fill the missing values in some segments.(see more in [TPSMAR22 EDA which makes sense](https://www.kaggle.com/code/ambrosm/tpsmar22-eda-which-makes-sense/notebook))","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.bar(range(101), TSDataset.to_flatten(ts[:,:,\"target\"]).target.value_counts().sort_index(), width=1,\n        color=['r' if con in [15, 20, 21, 29, 34] else '#ffd700' for con in range(101)])\nplt.ylabel('Count')\nplt.xlabel('Congestion');","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:49.857459Z","iopub.execute_input":"2022-03-29T17:22:49.857723Z","iopub.status.idle":"2022-03-29T17:22:50.4029Z","shell.execute_reply.started":"2022-03-29T17:22:49.857695Z","shell.execute_reply":"2022-03-29T17:22:50.401996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing values","metadata":{}},{"cell_type":"markdown","source":"First of all, some basic information about the series in the dataset. As we can see, there are 81 missing values in each segment, we should definitely look at them.","metadata":{}},{"cell_type":"code","source":"ts.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:51.753136Z","iopub.execute_input":"2022-03-29T17:22:51.753404Z","iopub.status.idle":"2022-03-29T17:22:51.853841Z","shell.execute_reply.started":"2022-03-29T17:22:51.753376Z","shell.execute_reply":"2022-03-29T17:22:51.852831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can select the imputation strategy by visualizing the imputed values. As we can see, the missing point are mostly not consequent, so we can use the last known value to impute them as the dataset frequency is high.","metadata":{}},{"cell_type":"code","source":"from etna.analysis import plot_imputation\nfrom etna.transforms import TimeSeriesImputerTransform","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:22:53.471134Z","iopub.execute_input":"2022-03-29T17:22:53.471431Z","iopub.status.idle":"2022-03-29T17:22:53.476212Z","shell.execute_reply.started":"2022-03-29T17:22:53.471399Z","shell.execute_reply":"2022-03-29T17:22:53.475254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = TimeSeriesImputerTransform(in_column=\"target\", strategy=\"forward_fill\")\nplot_imputation(ts=ts, imputer=imputer, segments=ts.segments[:4])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:12.97111Z","iopub.execute_input":"2022-03-29T09:20:12.971506Z","iopub.status.idle":"2022-03-29T09:20:14.946917Z","shell.execute_reply.started":"2022-03-29T09:20:12.971457Z","shell.execute_reply":"2022-03-29T09:20:14.945863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts.fit_transform([imputer])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:14.949098Z","iopub.execute_input":"2022-03-29T09:20:14.949463Z","iopub.status.idle":"2022-03-29T09:20:15.39214Z","shell.execute_reply.started":"2022-03-29T09:20:14.949418Z","shell.execute_reply":"2022-03-29T09:20:15.390964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Seasonality","metadata":{}},{"cell_type":"markdown","source":"Now, let's take a look at the time series in the dataset. ","metadata":{}},{"cell_type":"code","source":"ts.plot(segments=ts.segments[:10])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:15.39365Z","iopub.execute_input":"2022-03-29T09:20:15.39388Z","iopub.status.idle":"2022-03-29T09:20:17.265Z","shell.execute_reply.started":"2022-03-29T09:20:15.393853Z","shell.execute_reply":"2022-03-29T09:20:17.264053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see the **daily** seasonality.","metadata":{}},{"cell_type":"code","source":"ts.plot(segments=ts.segments[:10], start=\"1991-08-01\", end=\"1991-08-07\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:17.266484Z","iopub.execute_input":"2022-03-29T09:20:17.26675Z","iopub.status.idle":"2022-03-29T09:20:19.024144Z","shell.execute_reply.started":"2022-03-29T09:20:17.266718Z","shell.execute_reply":"2022-03-29T09:20:19.023468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also look at autocorrelation plot. In fact, there is also **weekly** seasonality, **12-hours** seasonality(i.e 2_2_NB), **2-days** seasonality(i.e. 2_2_NE). The absolute values of autocorrelation vary significantly from segment to segment. This might be hard for the model to catch all types of the seasonality as it varies from segment to segment.","metadata":{"execution":{"iopub.status.busy":"2022-03-26T16:55:05.753289Z","iopub.execute_input":"2022-03-26T16:55:05.753591Z","iopub.status.idle":"2022-03-26T16:55:05.759595Z","shell.execute_reply.started":"2022-03-26T16:55:05.753557Z","shell.execute_reply":"2022-03-26T16:55:05.758392Z"}}},{"cell_type":"code","source":"from etna.analysis import sample_acf_plot, sample_pacf_plot","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:19.025325Z","iopub.execute_input":"2022-03-29T09:20:19.026119Z","iopub.status.idle":"2022-03-29T09:20:19.029694Z","shell.execute_reply.started":"2022-03-29T09:20:19.026067Z","shell.execute_reply":"2022-03-29T09:20:19.029098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_acf_plot(ts, segments=[\"0_2_EB\", \"2_2_NE\", \"0_0_SB\", \"2_2_NB\"], lags=3*14*24)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:19.032554Z","iopub.execute_input":"2022-03-29T09:20:19.033269Z","iopub.status.idle":"2022-03-29T09:20:20.478715Z","shell.execute_reply.started":"2022-03-29T09:20:19.033227Z","shell.execute_reply":"2022-03-29T09:20:20.477987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlations","metadata":{}},{"cell_type":"markdown","source":"There might be correlations between the directions inside one road. To spot them, we can plot the correlation matrix. As we can see, there is correlation between SB and NB directions inside the road.\n\n**Note**: I tried to use the lags and the mark of the most correlated segment as features in the model, however it didn't help. May be, someone will find out how to use it smartly.","metadata":{}},{"cell_type":"code","source":"from etna.analysis import plot_correlation_matrix","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:20.479912Z","iopub.execute_input":"2022-03-29T09:20:20.480261Z","iopub.status.idle":"2022-03-29T09:20:20.48408Z","shell.execute_reply.started":"2022-03-29T09:20:20.480231Z","shell.execute_reply":"2022-03-29T09:20:20.483455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"road = \"0_1\"\nroad_segments= [segment for segment in ts.segments if segment.startswith(road)]\nplot_correlation_matrix(\n    TSDataset(ts.df.loc[:, pd.IndexSlice[:, \"target\"]], \"20T\"), # Bag, normaly you can just write \"ts\" here\n    segments=road_segments,\n    method=\"pearson\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:20.485317Z","iopub.execute_input":"2022-03-29T09:20:20.485661Z","iopub.status.idle":"2022-03-29T09:20:20.910421Z","shell.execute_reply.started":"2022-03-29T09:20:20.485632Z","shell.execute_reply":"2022-03-29T09:20:20.909123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, there is strong correlation between the neighbor roads in one direction(i.e. 1_2_NB and 1_3_NB). It might be helpful to show the model somehow the neighborhood of the segments.","metadata":{}},{"cell_type":"code","source":"direction = \"NB\"\ndirection_segments= [segment for segment in ts.segments if segment.endswith(direction)]\nplot_correlation_matrix(\n    TSDataset(ts.df.loc[:, pd.IndexSlice[:, \"target\"]], \"20T\"),\n    segments=direction_segments,\n    method=\"pearson\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:20.912005Z","iopub.execute_input":"2022-03-29T09:20:20.912402Z","iopub.status.idle":"2022-03-29T09:20:22.038935Z","shell.execute_reply.started":"2022-03-29T09:20:20.912364Z","shell.execute_reply":"2022-03-29T09:20:22.037997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clustering\n\nThere might be the roads with the same patterns, let's check it out.","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:28:32.957388Z","iopub.execute_input":"2022-03-26T17:28:32.957816Z","iopub.status.idle":"2022-03-26T17:28:32.963993Z","shell.execute_reply.started":"2022-03-26T17:28:32.957775Z","shell.execute_reply":"2022-03-26T17:28:32.963148Z"}}},{"cell_type":"code","source":"from etna.analysis import plot_clusters\nfrom etna.clustering import EuclideanClustering","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:22.040479Z","iopub.execute_input":"2022-03-29T09:20:22.041511Z","iopub.status.idle":"2022-03-29T09:20:23.115647Z","shell.execute_reply.started":"2022-03-29T09:20:22.041458Z","shell.execute_reply":"2022-03-29T09:20:23.11462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = EuclideanClustering()\nmodel.build_distance_matrix(ts=ts)\nmodel.build_clustering_algo(n_clusters=8, linkage=\"average\") # number of clusters = number of directions\nsegment2cluster = model.fit_predict()\ncentroids = model.get_centroids()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:23.117181Z","iopub.execute_input":"2022-03-29T09:20:23.117435Z","iopub.status.idle":"2022-03-29T09:20:41.74855Z","shell.execute_reply.started":"2022-03-29T09:20:23.1174Z","shell.execute_reply":"2022-03-29T09:20:41.747385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_clusters(ts=ts, segment2cluster=segment2cluster, centroids_df=centroids)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:41.750191Z","iopub.execute_input":"2022-03-29T09:20:41.750506Z","iopub.status.idle":"2022-03-29T09:20:55.34948Z","shell.execute_reply.started":"2022-03-29T09:20:41.750469Z","shell.execute_reply":"2022-03-29T09:20:55.348483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see here two big clusters and several smaller ones.\n\n**Note**: I tried to use the cluster marks as feature in the model, however it also did't help.","metadata":{}},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"code","source":"from etna.transforms import TimeSeriesImputerTransform \nfrom etna.transforms import StandardScalerTransform, YeoJohnsonTransform \nfrom etna.transforms import LagTransform, FourierTransform \nfrom etna.transforms import (MeanTransform, StdTransform, MinTransform,\n                             MaxTransform, MedianTransform, MADTransform)\nfrom etna.transforms import SegmentEncoderTransform","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:04.834203Z","iopub.execute_input":"2022-03-29T17:23:04.834882Z","iopub.status.idle":"2022-03-29T17:23:04.84133Z","shell.execute_reply.started":"2022-03-29T17:23:04.834833Z","shell.execute_reply":"2022-03-29T17:23:04.840311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputation\nimputer = TimeSeriesImputerTransform(in_column=\"target\", strategy=\"forward_fill\")\n\n# Preprocessing\npower = YeoJohnsonTransform(in_column=\"target\")\nscaler = StandardScalerTransform(in_column=\"target\")\n\n# Lags and seasonalities\nseasonlal_lags = [3 * 7 * 24 * i for i in range(1, 9)] + [3 * 24 * i for i in range(1, 9)] + [3 * 12 * i for i in range(1, 9)]\nlags = LagTransform(in_column=\"target\", lags=seasonlal_lags, out_column=\"lag\")\n\n# Rolling statistics\nstatistics_transforms = [MeanTransform, StdTransform, MinTransform,\n                         MaxTransform, MedianTransform, MADTransform]\nnames = [\"mean\", \"std\", \"min\", \"max\", \"median\", \"mad\"]\nseasonal_statistics = [\n    transform(in_column=\"lag_504\", window=-1, seasonality=3 * 7 * 24, out_column=name+\"_w\")\n    for transform, name in zip(statistics_transforms, names)\n]\nseasonal_statistics += [\n    transform(in_column=\"lag_72\", window=-1, seasonality=3 * 7 * 24, out_column=name+\"_d\")\n    for transform, name in zip(statistics_transforms, names)\n]\nseasonal_statistics += [\n    transform(in_column=\"lag_504\", window=4, seasonality=3 * 7 * 24, out_column=name+\"_short_w\")\n    for transform, name in zip(statistics_transforms, names)\n]\nseasonal_statistics += [\n    transform(in_column=\"lag_72\", window=7, seasonality=3 * 7 * 24, out_column=name+\"_short_d\")\n    for transform, name in zip(statistics_transforms, names)\n]\n\n\n# Segment mark\nsegment_encoder = SegmentEncoderTransform()\n\ntransforms = [imputer, power, scaler, lags, *seasonal_statistics, segment_encoder]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:06.414771Z","iopub.execute_input":"2022-03-29T17:23:06.415091Z","iopub.status.idle":"2022-03-29T17:23:06.428445Z","shell.execute_reply.started":"2022-03-29T17:23:06.415044Z","shell.execute_reply":"2022-03-29T17:23:06.427483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts = load_dataset()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:20:55.372927Z","iopub.execute_input":"2022-03-29T09:20:55.373823Z","iopub.status.idle":"2022-03-29T09:21:00.562278Z","shell.execute_reply.started":"2022-03-29T09:20:55.373787Z","shell.execute_reply":"2022-03-29T09:21:00.561161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts.fit_transform(deepcopy(transforms))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:21:00.563757Z","iopub.execute_input":"2022-03-29T09:21:00.56405Z","iopub.status.idle":"2022-03-29T09:21:24.755338Z","shell.execute_reply.started":"2022-03-29T09:21:00.564001Z","shell.execute_reply":"2022-03-29T09:21:24.754091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance\n\nRoads in the dataset have different behavior, this implies that the feature importance might vary between the road. Let's generate the set of feature, which will be used later in the model, and look at the top-20 important ones for each segment.","metadata":{}},{"cell_type":"code","source":"from etna.analysis import StatisticsRelevanceTable, ModelRelevanceTable, plot_feature_relevance\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:21:24.75672Z","iopub.execute_input":"2022-03-29T09:21:24.756978Z","iopub.status.idle":"2022-03-29T09:21:24.762185Z","shell.execute_reply.started":"2022-03-29T09:21:24.75695Z","shell.execute_reply":"2022-03-29T09:21:24.761095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bag, we will fix it later)\nts.df = ts.df.astype(float)\nts.df = ts.df.dropna() \nts = TSDataset(df=ts[:,[\"0_2_EB\", \"2_2_NE\", \"0_0_SB\", \"2_2_NB\"],:], freq=\"20T\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:21:24.763448Z","iopub.execute_input":"2022-03-29T09:21:24.763652Z","iopub.status.idle":"2022-03-29T09:21:25.658507Z","shell.execute_reply.started":"2022-03-29T09:21:24.763627Z","shell.execute_reply":"2022-03-29T09:21:25.657456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In our library, we use 2 approaches to evaluate feature relevance.\n\nThe first one is the feature relevance from the tree-base models:","metadata":{}},{"cell_type":"code","source":"plot_feature_relevance(\n    ts=ts,\n    relevance_table=ModelRelevanceTable(),\n    normalized=True,\n    relevance_aggregation_mode=\"per-segment\",\n    top_k=20,\n    segments=[\"0_2_EB\", \"2_2_NE\", \"0_0_SB\", \"2_2_NB\"],\n    relevance_params=dict(model=RandomForestRegressor(n_estimators=10))\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:21:25.660325Z","iopub.execute_input":"2022-03-29T09:21:25.660676Z","iopub.status.idle":"2022-03-29T09:21:38.918551Z","shell.execute_reply.started":"2022-03-29T09:21:25.660631Z","shell.execute_reply":"2022-03-29T09:21:38.917426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And the second one is based on statistical tests(feature relevance here is q-value => the less, the better):","metadata":{}},{"cell_type":"code","source":"plot_feature_relevance(\n    ts=ts,\n    normalized=True,\n    relevance_table=StatisticsRelevanceTable(),\n    relevance_aggregation_mode=\"per-segment\",\n    top_k=20,\n    segments=[\"0_2_EB\", \"2_2_NE\", \"0_0_SB\", \"2_2_NB\"],\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:21:38.919979Z","iopub.execute_input":"2022-03-29T09:21:38.920336Z","iopub.status.idle":"2022-03-29T09:21:52.572987Z","shell.execute_reply.started":"2022-03-29T09:21:38.920291Z","shell.execute_reply":"2022-03-29T09:21:52.572076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the order of the features for each segment is different, so the best way might be to use theÂ separate model for each segment. However, it works significantly slow, so we won't do it in this notebook, but you might try it yourself.","metadata":{}},{"cell_type":"markdown","source":"As we are going to use multi-segment model, we actually need aggregated feature relevance!","metadata":{}},{"cell_type":"code","source":"plot_feature_relevance(\n    ts=ts,\n    relevance_table=ModelRelevanceTable(),\n    normalized=True,\n    relevance_aggregation_mode=\"mean\",\n    top_k=20,\n    segments=[\"0_2_EB\", \"2_2_NE\", \"0_0_SB\", \"2_2_NB\"],\n    relevance_params=dict(model=RandomForestRegressor(n_estimators=10))\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:21:52.5746Z","iopub.execute_input":"2022-03-29T09:21:52.574858Z","iopub.status.idle":"2022-03-29T09:22:04.593093Z","shell.execute_reply.started":"2022-03-29T09:21:52.574823Z","shell.execute_reply":"2022-03-29T09:22:04.59183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_relevance(\n    ts=ts,\n    normalized=True,\n    relevance_table=StatisticsRelevanceTable(),\n    relevance_aggregation_mode=\"mean\",\n    top_k=20,\n    segments=[\"0_2_EB\", \"2_2_NE\", \"0_0_SB\", \"2_2_NB\"],\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:22:04.594969Z","iopub.execute_input":"2022-03-29T09:22:04.598315Z","iopub.status.idle":"2022-03-29T09:22:20.337714Z","shell.execute_reply.started":"2022-03-29T09:22:04.598242Z","shell.execute_reply":"2022-03-29T09:22:20.336407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note**: Both methods suggest **rolling statistics** the most important features","metadata":{}},{"cell_type":"markdown","source":"# Model\n\nNow, let's create a baseline","metadata":{}},{"cell_type":"code","source":"from etna.pipeline import Pipeline\nfrom etna.models import CatBoostModelMultiSegment","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:19.833547Z","iopub.execute_input":"2022-03-29T17:23:19.834098Z","iopub.status.idle":"2022-03-29T17:23:19.837524Z","shell.execute_reply.started":"2022-03-29T17:23:19.834044Z","shell.execute_reply":"2022-03-29T17:23:19.836871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Backtest\n\nThe important part in any project is correct validation. ","metadata":{}},{"cell_type":"code","source":"pipeline = Pipeline(model=CatBoostModelMultiSegment(), \n                   transforms=transforms, \n                   horizon=HORIZON)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:22:20.351684Z","iopub.execute_input":"2022-03-29T09:22:20.35211Z","iopub.status.idle":"2022-03-29T09:22:20.3617Z","shell.execute_reply.started":"2022-03-29T09:22:20.352061Z","shell.execute_reply":"2022-03-29T09:22:20.360528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from etna.metrics import MAE","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:22:20.363059Z","iopub.execute_input":"2022-03-29T09:22:20.363496Z","iopub.status.idle":"2022-03-29T09:22:20.375861Z","shell.execute_reply.started":"2022-03-29T09:22:20.363463Z","shell.execute_reply":"2022-03-29T09:22:20.374933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts = load_dataset(segments=sorted(ts.segments)[:10])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:22:20.377205Z","iopub.execute_input":"2022-03-29T09:22:20.377595Z","iopub.status.idle":"2022-03-29T09:22:25.095582Z","shell.execute_reply.started":"2022-03-29T09:22:20.377565Z","shell.execute_reply":"2022-03-29T09:22:25.094524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Firstly, let's try to use three last folds in classical time series cross validation strategy","metadata":{}},{"cell_type":"code","source":"metrics, forecast, _ = pipeline.backtest(ts=ts, metrics=[MAE()], n_folds=3, n_jobs=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:22:25.0971Z","iopub.execute_input":"2022-03-29T09:22:25.097367Z","iopub.status.idle":"2022-03-29T09:23:45.206419Z","shell.execute_reply.started":"2022-03-29T09:22:25.097334Z","shell.execute_reply":"2022-03-29T09:23:45.205083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.mean()[\"MAE\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:23:45.208125Z","iopub.execute_input":"2022-03-29T09:23:45.208373Z","iopub.status.idle":"2022-03-29T09:23:45.218059Z","shell.execute_reply.started":"2022-03-29T09:23:45.208343Z","shell.execute_reply":"2022-03-29T09:23:45.217104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Don't be upset. In fact, we need to forecast the afternoon of the Monday, so why we are validating on the last 36 hours? We need to validate on last tree Monday afternoons!","metadata":{}},{"cell_type":"code","source":"from etna.pipeline import FoldMask","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:23:45.219563Z","iopub.execute_input":"2022-03-29T09:23:45.219805Z","iopub.status.idle":"2022-03-29T09:23:45.230391Z","shell.execute_reply.started":"2022-03-29T09:23:45.219774Z","shell.execute_reply":"2022-03-29T09:23:45.229348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_mask_1 = FoldMask(first_train_timestamp=None, \n                       last_train_timestamp=\"1991-09-23 11:40:00\", \n                      target_timestamps=pd.date_range(start=\"1991-09-23 12:00:00\", end=\"1991-09-23 23:40:00\", freq=\"20T\"))\nfold_mask_2 = FoldMask(first_train_timestamp=None, \n                       last_train_timestamp=\"1991-09-16 11:40:00\", \n                      target_timestamps=pd.date_range(start=\"1991-09-16 12:00:00\", end=\"1991-09-16 23:40:00\", freq=\"20T\"))\nfold_mask_3 = FoldMask(first_train_timestamp=None, \n                       last_train_timestamp=\"1991-09-09 11:40:00\", \n                      target_timestamps=pd.date_range(start=\"1991-09-09 12:00:00\", end=\"1991-09-09 23:40:00\", freq=\"20T\"))\nfolds = [fold_mask_3, fold_mask_2, fold_mask_1]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:23:45.232558Z","iopub.execute_input":"2022-03-29T09:23:45.232911Z","iopub.status.idle":"2022-03-29T09:23:45.247351Z","shell.execute_reply.started":"2022-03-29T09:23:45.232862Z","shell.execute_reply":"2022-03-29T09:23:45.24649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_mondays, _, _ = pipeline.backtest(ts=ts, metrics=[MAE()], n_folds=folds, n_jobs=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:23:45.249025Z","iopub.execute_input":"2022-03-29T09:23:45.250278Z","iopub.status.idle":"2022-03-29T09:25:00.129181Z","shell.execute_reply.started":"2022-03-29T09:23:45.250207Z","shell.execute_reply":"2022-03-29T09:25:00.127709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_mondays.mean()[\"MAE\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:25:00.131237Z","iopub.execute_input":"2022-03-29T09:25:00.131518Z","iopub.status.idle":"2022-03-29T09:25:00.144161Z","shell.execute_reply.started":"2022-03-29T09:25:00.131484Z","shell.execute_reply":"2022-03-29T09:25:00.143084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks much more correlated with the LB!","metadata":{}},{"cell_type":"markdown","source":"# Ensemble\n\nNow, let's build the final solution. We will use the ensemble of Catboost models with different random seeds, to make the forecast more robust.","metadata":{}},{"cell_type":"code","source":"from etna.ensembles import VotingEnsemble","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:31.573231Z","iopub.execute_input":"2022-03-29T17:23:31.57371Z","iopub.status.idle":"2022-03-29T17:23:31.578184Z","shell.execute_reply.started":"2022-03-29T17:23:31.573651Z","shell.execute_reply":"2022-03-29T17:23:31.577368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seeds = [None, 13, 121, 11041999, 3141, 235813, 1501]\npipelines = [Pipeline(model=CatBoostModelMultiSegment(random_seed=seeds[i]),\n                      transforms=transforms,\n                      horizon=HORIZON) \n             for i in range(len(seeds))]\nensemble = VotingEnsemble(pipelines=pipelines, n_jobs=5)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:33.359882Z","iopub.execute_input":"2022-03-29T17:23:33.360685Z","iopub.status.idle":"2022-03-29T17:23:33.366996Z","shell.execute_reply.started":"2022-03-29T17:23:33.36064Z","shell.execute_reply":"2022-03-29T17:23:33.366067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forecast","metadata":{}},{"cell_type":"code","source":"from etna.analysis import plot_forecast","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:39.433396Z","iopub.execute_input":"2022-03-29T17:23:39.4337Z","iopub.status.idle":"2022-03-29T17:23:39.437912Z","shell.execute_reply.started":"2022-03-29T17:23:39.43366Z","shell.execute_reply":"2022-03-29T17:23:39.43706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts = load_dataset()\nensemble.fit(ts)\nforecast = ensemble.forecast()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:23:53.343546Z","iopub.execute_input":"2022-03-29T17:23:53.3439Z","iopub.status.idle":"2022-03-29T17:53:02.24493Z","shell.execute_reply.started":"2022-03-29T17:23:53.343862Z","shell.execute_reply":"2022-03-29T17:53:02.243961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_forecast(forecast_ts=forecast, train_ts=ts, n_train_samples=3*7*24, segments=sorted(ts.segments)[:10])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:53:02.2469Z","iopub.execute_input":"2022-03-29T17:53:02.247186Z","iopub.status.idle":"2022-03-29T17:53:05.079445Z","shell.execute_reply.started":"2022-03-29T17:53:02.247152Z","shell.execute_reply":"2022-03-29T17:53:05.078066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:53:05.080559Z","iopub.execute_input":"2022-03-29T17:53:05.080821Z","iopub.status.idle":"2022-03-29T17:53:05.085502Z","shell.execute_reply.started":"2022-03-29T17:53:05.080789Z","shell.execute_reply":"2022-03-29T17:53:05.08455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_submission(forecast):\n    forecast = TSDataset.to_flatten(forecast[:,:,\"target\"])\n    \n    test = pd.read_csv(TEST_PATH, parse_dates=[\"time\"])\n    test = test.rename(columns={\"time\": \"timestamp\"})\n    test[\"segment\"] = test[\"x\"].apply(str) + \"_\" + test[\"y\"].apply(str) + \"_\" + test[\"direction\"]\n    test = pd.merge(test, forecast, on=[\"timestamp\", \"segment\"])\n    test = test.rename(columns={\"target\": \"congestion\"})\n    submission = test[[\"row_id\", \"congestion\"]]\n    \n    # Postprocessing (see https://www.kaggle.com/code/ambrosm/tpsmar22-generalizing-the-special-values for an explanation)\n    \n    # Read and prepare the training data\n    train = pd.read_csv(TRAIN_PATH, parse_dates=['time'])\n    train['hour'] = train['time'].dt.hour\n    train['minute'] = train['time'].dt.minute\n    \n    # Compute the quantiles of workday afternoons in September except Labor Day\n    sep = train[(train.time.dt.hour >= 12) & (train.time.dt.weekday < 5) &\n                (train.time.dt.dayofyear >= 246)]\n    lower = sep.groupby(['hour', 'minute', 'x', 'y', 'direction']).congestion.quantile(0.2).values\n    upper = sep.groupby(['hour', 'minute', 'x', 'y', 'direction']).congestion.quantile(0.8).values\n\n    # Clip the submission data to the quantiles\n    submission_out = submission.copy()\n    submission_out['congestion'] = submission.congestion.clip(lower, upper)\n\n    # Display some statistics\n    mae = mean_absolute_error(submission.congestion, submission_out.congestion)\n    print(f'Mean absolute modification: {mae:.4f}')\n    print(f\"Submission was below lower bound: {(submission.congestion <= lower - 0.5).sum()}\")\n    print(f\"Submission was above upper bound: {(submission.congestion > upper + 0.5).sum()}\")\n\n    #Round targets\n    submission_out['congestion'] = submission_out[\"congestion\"].round().astype(int)\n    submission_out.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:53:05.088457Z","iopub.execute_input":"2022-03-29T17:53:05.088909Z","iopub.status.idle":"2022-03-29T17:53:05.107083Z","shell.execute_reply.started":"2022-03-29T17:53:05.088871Z","shell.execute_reply":"2022-03-29T17:53:05.106321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_submission(forecast)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T17:53:05.108394Z","iopub.execute_input":"2022-03-29T17:53:05.109104Z","iopub.status.idle":"2022-03-29T17:53:06.388916Z","shell.execute_reply.started":"2022-03-29T17:53:05.109069Z","shell.execute_reply":"2022-03-29T17:53:06.387858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Phew, baseline is ready. But work is still in progress, wait for updates soon!","metadata":{}}]}