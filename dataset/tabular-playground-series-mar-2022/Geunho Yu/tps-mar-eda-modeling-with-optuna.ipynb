{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style='text-align:center;font-family: sans-serif;font-weight:bold;color:#616161;font-size:25px;margin: 30px;'>TPS MAR</p>\n<p style='text-align:center;font-family: sans-serif ;font-weight:bold;color:black;font-size:30px;margin: 10px;'>EDA + Modeling with Optuna for <font color='#08B4E4'>Beginners</font></p>\n<p style=\"text-align:center;font-family: sans-serif ;font-weight:bold;color:#616161;font-size:20px;margin: 30px;\">Catboost for regression</p>","metadata":{}},{"cell_type":"markdown","source":"Hello, this is my first time using Catboost in TPS. It's an interesting model, and I tried tuning with Optuna. Hyperparameter tuning libraries such as Optuna are easy to use and improve performance, but do not always think that the results are the best.","metadata":{}},{"cell_type":"markdown","source":"## Import Modules","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom math import sin, cos, pi\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.ensemble import RandomForestRegressor\nfrom catboost import CatBoostRegressor\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom functools import partial\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nBACKCOLOR = '#f6f5f5'\nsns.set_palette(\"Paired\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-05T08:07:20.193444Z","iopub.execute_input":"2022-03-05T08:07:20.193874Z","iopub.status.idle":"2022-03-05T08:07:22.053222Z","shell.execute_reply.started":"2022-03-05T08:07:20.19374Z","shell.execute_reply":"2022-03-05T08:07:22.052474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', index_col='row_id', parse_dates=['time'])\ntest = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv', index_col='row_id', parse_dates=['time'])\nsubmission = pd.read_csv('../input/tabular-playground-series-mar-2022/sample_submission.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:22.056124Z","iopub.execute_input":"2022-03-05T08:07:22.056722Z","iopub.status.idle":"2022-03-05T08:07:23.012129Z","shell.execute_reply.started":"2022-03-05T08:07:22.056691Z","shell.execute_reply":"2022-03-05T08:07:23.011472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)  \n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\nreduce_mem_usage(train)\nreduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.013411Z","iopub.execute_input":"2022-03-05T08:07:23.013645Z","iopub.status.idle":"2022-03-05T08:07:23.154118Z","shell.execute_reply.started":"2022-03-05T08:07:23.013612Z","shell.execute_reply":"2022-03-05T08:07:23.153284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"### Step1: Understand each features  \nThe beginning of EDA is understanding variables.  \n- row_id - a unique identifier for this instance  \n- time - the 20-minute period in which each measurement was taken  \n- x - the east-west midpoint coordinate of the roadway  \n- y - the north-south midpoint coordinate of the roadway  \n- direction - the direction of travel of the roadway. EB indicates \"eastbound\" travel, for example, while SW indicates a \"southwest\" direction of travel.  \n- congestion - congestion levels for the roadway during each hour; the target. The congestion measurements have been normalized to the range 0 to 100.  ","metadata":{}},{"cell_type":"code","source":"# Check the type and missing value of each variable.\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.155406Z","iopub.execute_input":"2022-03-05T08:07:23.155715Z","iopub.status.idle":"2022-03-05T08:07:23.178593Z","shell.execute_reply.started":"2022-03-05T08:07:23.155678Z","shell.execute_reply":"2022-03-05T08:07:23.177799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.core.display import HTML\ndef multi_table(table_list):\n    return HTML(\n        f\"<table><tr> {''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list])} </tr></table>\")","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.180978Z","iopub.execute_input":"2022-03-05T08:07:23.181236Z","iopub.status.idle":"2022-03-05T08:07:23.185942Z","shell.execute_reply.started":"2022-03-05T08:07:23.181201Z","shell.execute_reply":"2022-03-05T08:07:23.184765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the actual value and count\nmulti_table([pd.DataFrame(train[i].value_counts()) for i in train.columns])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.187407Z","iopub.execute_input":"2022-03-05T08:07:23.187766Z","iopub.status.idle":"2022-03-05T08:07:23.303877Z","shell.execute_reply.started":"2022-03-05T08:07:23.187727Z","shell.execute_reply":"2022-03-05T08:07:23.30306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you look at the table above, you can see that there are 65 objects in each time. This means that there are 65 combinations of position values (x,y) and directions for each time.\n\nThe x coordinates are 0, 1, 2 / y coordinates are 0, 1, 2, 3, and there are 12 combinations.\nThe direction consists of eight directions: EB to SE.\n\nWhat we can see from this is that all combinations of positions and directions were not recorded at each point in time.","metadata":{}},{"cell_type":"markdown","source":"### Step2-1 - Time  \nRecords are recorded at intervals of 20 minutes from the initial start time, so a total of 13140 times must be recorded.  \nHowever, the actual time recorded is 13059, so 81 missing values exist.  \nThese missing values must be handled when using time series analysis. There are no applicable items in this analysis.","metadata":{}},{"cell_type":"code","source":"import datetime\nlast_datetime = datetime.datetime.strptime('1991-09-30 11:40:00', '%Y-%m-%d %H:%M:%S')\nfirst_datetime = datetime.datetime.strptime('1991-04-01 00:00:00', '%Y-%m-%d %H:%M:%S')\ninterval = datetime.timedelta(minutes=20)\n\nexp_count = int((last_datetime - first_datetime) / interval + 1)\ncur_count = train.time.nunique()\n\ntime_info = pd.DataFrame({'first datetime': [first_datetime], 'last datetime': [last_datetime], 'time interval': [interval]}, index=['value']).T\nmiss_table = pd.DataFrame({'expected count': [exp_count], 'actual row count': [cur_count], 'missing count': [exp_count - cur_count]}, index=['value']).T\nmulti_table([time_info, miss_table])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.305352Z","iopub.execute_input":"2022-03-05T08:07:23.305726Z","iopub.status.idle":"2022-03-05T08:07:23.328646Z","shell.execute_reply.started":"2022-03-05T08:07:23.305587Z","shell.execute_reply":"2022-03-05T08:07:23.32786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step2-2 - X and Y  \nThese values are numeric data, but they are nominal variables.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(15, 5))\nfor i, p in enumerate(['x', 'y']):\n    sns.countplot(train[p], ax=ax[i], edgecolor='black', linewidth=4)\n    ax[i].spines[['top', 'right']].set_visible(False)\n    ax[i].set_facecolor(BACKCOLOR)\n    for patch in ax[i].patches:\n        x, height, width = patch.get_x(), patch.get_height(), patch.get_width()\n        total_cnt = train[p].count()\n        ax[i].set_xlabel(p, size=15)\n        ax[i].set_ylabel('count', size=15)\n        ax[i].text(x + width / 2, height + 5, f'{height} / {height / total_cnt * 100:2.2f}%', va='center', ha='center', size=8, bbox={'facecolor': 'white', 'boxstyle': 'round'})\nf.suptitle('Count by X / Y', size=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.329951Z","iopub.execute_input":"2022-03-05T08:07:23.330297Z","iopub.status.idle":"2022-03-05T08:07:23.774575Z","shell.execute_reply.started":"2022-03-05T08:07:23.330259Z","shell.execute_reply":"2022-03-05T08:07:23.773946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step2-3 - Direction  ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, figsize=(15, 5))\nsns.countplot(train['direction'], edgecolor='black', linewidth=4)\nax.spines[['top', 'right']].set_visible(False)\nax.set_facecolor(BACKCOLOR)\nfor patch in ax.patches:\n    x, height, width = patch.get_x(), patch.get_height(), patch.get_width()\n    total_cnt = train[p].count()\n    ax.set_xlabel('direction', size=15)\n    ax.set_ylabel('count', size=15)\n    ax.text(x + width / 2, height + 5, f'{height} / {height / total_cnt * 100:2.2f}%', va='center', ha='center', size=10, bbox={'facecolor': 'white', 'boxstyle': 'round'})\n    \nf.suptitle('Distribution of direction', size=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:23.775636Z","iopub.execute_input":"2022-03-05T08:07:23.776023Z","iopub.status.idle":"2022-03-05T08:07:24.033717Z","shell.execute_reply.started":"2022-03-05T08:07:23.775981Z","shell.execute_reply":"2022-03-05T08:07:24.033041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 7))\ndir_dict = {'EB': (1, 0), 'NB': (0, 1), 'SB': (0, -1), 'WB': (-1, 0), 'NE': (1, 1), 'SE': (-1, 1), 'NW': (1, -1), 'SW': (-1, -1)}\nfor _, x, y, d in train[['x', 'y', 'direction']].drop_duplicates().itertuples():\n    dx, dy = dir_dict[d]\n    dx, dy = dx/4, dy/4\n    plt.plot([x, x+dx], [y, y+dy])\nax.spines[['top', 'right']].set_visible(False)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('directions', size=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:24.035114Z","iopub.execute_input":"2022-03-05T08:07:24.035559Z","iopub.status.idle":"2022-03-05T08:07:24.336177Z","shell.execute_reply.started":"2022-03-05T08:07:24.035519Z","shell.execute_reply":"2022-03-05T08:07:24.33553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step2-4 - Congestion  ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 4, figsize=(35, 10))\nsns.histplot(data=train, x='congestion', element='step', ax=ax[0])\nsns.violinplot(train.congestion, edgecolor='black', linewidth=5, ax=ax[1])\nsns.boxplot(train.congestion, ax=ax[2])\nsns.stripplot(train.congestion, ax=ax[3])\nfor i in range(4):\n    ax[i].spines[['top','right']].set_visible(False)\n    ax[i].set_facecolor(BACKCOLOR)\nf.suptitle(\"congestion's distribution\", weight='bold', size=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:24.337239Z","iopub.execute_input":"2022-03-05T08:07:24.338065Z","iopub.status.idle":"2022-03-05T08:07:30.377167Z","shell.execute_reply.started":"2022-03-05T08:07:24.338026Z","shell.execute_reply":"2022-03-05T08:07:30.376459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering  \nI conducted Feature Engineering by referring to INVERSION's notebook.  \nhttps://www.kaggle.com/inversion/tps-mar-22-cyclical-features","metadata":{}},{"cell_type":"code","source":"# train['year'] = train['time'].dt.year\n# train['month'] = train['time'].dt.month\n# train['day'] = train['time'].dt.day\ntrain['hour'] = train['time'].dt.hour\ntrain['minute'] = train['time'].dt.minute\ntrain['weekday'] = train['time'].dt.weekday\n\n# test['year'] = test['time'].dt.year\n# test['month'] = test['time'].dt.month\n# test['day'] = test['time'].dt.day\ntest['hour'] = test['time'].dt.hour\ntest['minute'] = test['time'].dt.minute\ntest['weekday'] = test['time'].dt.weekday\n\ntrain = train.drop('time', axis='columns')\ntest = test.drop('time', axis='columns')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:30.378307Z","iopub.execute_input":"2022-03-05T08:07:30.378909Z","iopub.status.idle":"2022-03-05T08:07:30.627782Z","shell.execute_reply.started":"2022-03-05T08:07:30.378869Z","shell.execute_reply":"2022-03-05T08:07:30.627063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:30.629133Z","iopub.execute_input":"2022-03-05T08:07:30.629393Z","iopub.status.idle":"2022-03-05T08:07:30.638114Z","shell.execute_reply.started":"2022-03-05T08:07:30.629358Z","shell.execute_reply":"2022-03-05T08:07:30.636539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns[(train.dtypes == 'object') | (train.dtypes == 'category')]:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col])\n    test[col] = le.transform(test[col])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:30.642423Z","iopub.execute_input":"2022-03-05T08:07:30.642613Z","iopub.status.idle":"2022-03-05T08:07:30.862846Z","shell.execute_reply.started":"2022-03-05T08:07:30.642589Z","shell.execute_reply":"2022-03-05T08:07:30.862135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnumeric_cols = train.columns[(train.dtypes != 'object') & (train.columns != 'congestion') & (train.columns != 'direction')]\ntrain[numeric_cols] = scaler.fit_transform(train[numeric_cols])\ntest[numeric_cols] = scaler.transform(test[numeric_cols])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:30.864124Z","iopub.execute_input":"2022-03-05T08:07:30.864369Z","iopub.status.idle":"2022-03-05T08:07:30.990399Z","shell.execute_reply.started":"2022-03-05T08:07:30.864337Z","shell.execute_reply":"2022-03-05T08:07:30.989714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = train.drop(['congestion'], axis=1), train['congestion']","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:30.992441Z","iopub.execute_input":"2022-03-05T08:07:30.992957Z","iopub.status.idle":"2022-03-05T08:07:31.035314Z","shell.execute_reply.started":"2022-03-05T08:07:30.992919Z","shell.execute_reply":"2022-03-05T08:07:31.034537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Option: Model Selection  \nWhy did I use Catboost?  \nUsing AutoML libraries, we can quickly and easily discover high-performance machine  learning algorithms for the currently prepared datasets.  \n  \nBy executing the following code, you can easily compare the performance of the model.","metadata":{}},{"cell_type":"code","source":"allow_pycaret = 0\n\nif allow_pycaret:\n    %%capture\n    !pip install pycaret[full]\n    \n    from pycaret.regression import *\n    \n    model = setup(data = train, \n              target = 'congestion', \n              use_gpu = True,\n              n_jobs = -1,\n              silent = True,\n              fold_shuffle = True,\n              fold = 5\n             )\n    \n    # The following code takes a lot of time.\n    best_model = compare_models(exclude=['et'])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:31.036671Z","iopub.execute_input":"2022-03-05T08:07:31.037178Z","iopub.status.idle":"2022-03-05T08:07:31.046639Z","shell.execute_reply.started":"2022-03-05T08:07:31.037139Z","shell.execute_reply":"2022-03-05T08:07:31.045963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used pycaret to get the next table. This table shows that Random Forest has the best performance. I decided to use CatBoost because Random Forest takes a long time.","metadata":{}},{"cell_type":"markdown","source":"|Model|MAE|MSE|RMSE|R2|RMSLE|MAPE|TT(Sec)|\n|------|---|---|---|---|---|---|---|\n|Random Forest Regressor|6.2035|77.1851|8.7855|0.7266|0.2455|0.1676|22.0880|\n|CatBoost Regressor|6.4813|83.3279|9.1284|0.7048|0.2570|0.1780|7.3560|\n|Extreme Gradient Boosting|6.5138|83.6836|9.1479|0.7036|0.2572|0.1787|1.5180|\n|Light Gradient Boosting Machine|7.0354|93.8601|9.6881|0.6675|0.2694|0.1947|3.7400|\n|Decision Tree Regressor|8.0557|140.3261|11.8459|0.5029|0.3304|0.2067|3.9780|\n|K Neighbors Regressor|9.2048|141.1331|11.8799|0.5001|0.3112|0.2520|1.7700|\n|Gradient Boosting Regressor|9.5307|150.3428|12.2612|0.4674|0.3204|0.2623|61.6240|\n|Bayesian Ridge|11.7967|214.2355|14.6368|0.2411|0.3666|0.3248|1.5120|\n|Least Angle Regression|11.7968|214.2355|14.6368|0.2411|0.3666|0.3248|0.3480|\n|Ridge Regression|11.7968|214.2355|14.6368|0.2411|0.3666|0.3248|0.1180|\n|Linear Regression|11.7962|214.2554|14.6375|0.2411|0.3666|0.3248|0.1120|\n|Huber Regressor|11.7607|214.8679|14.6584|0.2389|0.3659|0.3218|38.9500|\n|AdaBoost Regressor|12.6995|238.2440|15.4349|0.1561|0.3998|0.3761|29.6600|\n|Orthogonal Matching Pursuit|12.9429|253.2295|15.9132|0.1030|0.3956|0.3635|0.2920|\n|Elastic Net|13.4782|268.1863|16.3764|0.0500|0.4112|0.3831|0.1180|\n|Lasso Regression|13.6573|274.6520|16.5726|0.0271|0.4153|0.3887|0.1160|\n|Lasso Least Angle Regression|13.8705|282.3189|16.8023|-0.0000|0.4207|0.3965|0.2920|\n|Dummy Regressor|13.8705|282.3189|16.8023|-0.0000|0.4207|0.3965|0.0960|\n|Passive Aggressive Regressor|15.8143|391.0209|19.4711|-0.3857|0.4649|0.4301|1.5940|","metadata":{}},{"cell_type":"markdown","source":"## Optimize model  \nI tried to optimize easily using Optuna.","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        \"random_state\":trial.suggest_categorical(\"random_state\", [2022]),\n        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.0001, 0.3),\n        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n        \"n_estimators\": 1000,\n        \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n        'random_strength' :trial.suggest_int('random_strength', 0, 100),\n        \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n        'task_type': trial.suggest_categorical('task_type', ['GPU']),\n        'loss_function': trial.suggest_categorical('loss_function', ['MAE']),\n        'eval_metric': trial.suggest_categorical('eval_metric', ['MAE'])\n    }\n\n    model = CatBoostRegressor(**params)\n    X_train_tmp, X_valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n    model.fit(\n        X_train_tmp, y_train_tmp,\n        eval_set=[(X_valid_tmp, y_valid_tmp)],\n        early_stopping_rounds=35, verbose=0\n    )\n        \n    y_train_pred = model.predict(X_train_tmp)\n    y_valid_pred = model.predict(X_valid_tmp)\n    train_mae = mae(y_train_tmp, y_train_pred)\n    valid_mae = mae(y_valid_tmp, y_valid_pred)\n    \n    print(f'MAE of Train: {train_mae}')\n    print(f'MAE of Validation: {valid_mae}')\n    \n    return valid_mae","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:31.04802Z","iopub.execute_input":"2022-03-05T08:07:31.048479Z","iopub.status.idle":"2022-03-05T08:07:31.059971Z","shell.execute_reply.started":"2022-03-05T08:07:31.048441Z","shell.execute_reply":"2022-03-05T08:07:31.059111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allow_optimize = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-05T08:07:31.062874Z","iopub.execute_input":"2022-03-05T08:07:31.063104Z","iopub.status.idle":"2022-03-05T08:07:31.070877Z","shell.execute_reply.started":"2022-03-05T08:07:31.063079Z","shell.execute_reply":"2022-03-05T08:07:31.070024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRIALS = 100\nTIMEOUT = 3600\n\n\nif allow_optimize:\n    sampler = TPESampler(seed=42)\n\n    study = optuna.create_study(\n        study_name = 'cat_parameter_opt',\n        direction = 'minimize',\n        sampler = sampler,\n    )\n    study.optimize(objective, n_trials=TRIALS)\n    print(\"Best Score:\",study.best_value)\n    print(\"Best trial\",study.best_trial.params)\n    \n    best_params = study.best_params\n    \n    X_train_tmp, X_valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n    model_tmp = CatBoostRegressor(**best_params, n_estimators=30000, verbose=1000).fit(X_train_tmp, y_train_tmp, eval_set=[(X_valid_tmp, y_valid_tmp)], early_stopping_rounds=35)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T08:07:31.07246Z","iopub.execute_input":"2022-03-05T08:07:31.072966Z","iopub.status.idle":"2022-03-05T09:04:34.058946Z","shell.execute_reply.started":"2022-03-05T08:07:31.072927Z","shell.execute_reply":"2022-03-05T09:04:34.058239Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"code","source":"if allow_optimize:\n    model = CatBoostRegressor(**best_params, n_estimators=model_tmp.get_best_iteration(), verbose=1000).fit(X_train, y_train)\nelse:\n    model = CatBoostRegressor(\n        verbose=1000,\n        early_stopping_rounds=10,\n        random_seed=2022,\n        max_depth=12,\n        task_type='GPU',\n        learning_rate=0.035,\n        iterations=30000,\n        loss_function='MAE',\n        eval_metric= 'MAE'\n    ).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:04:34.068371Z","iopub.execute_input":"2022-03-05T09:04:34.076995Z","iopub.status.idle":"2022-03-05T09:05:07.688751Z","shell.execute_reply.started":"2022-03-05T09:04:34.076941Z","shell.execute_reply":"2022-03-05T09:05:07.6881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Interpretation  ","metadata":{}},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:05:07.692872Z","iopub.execute_input":"2022-03-05T09:05:07.694693Z","iopub.status.idle":"2022-03-05T09:05:07.857099Z","shell.execute_reply.started":"2022-03-05T09:05:07.694654Z","shell.execute_reply":"2022-03-05T09:05:07.856379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:05:07.858299Z","iopub.execute_input":"2022-03-05T09:05:07.858576Z","iopub.status.idle":"2022-03-05T09:05:08.267061Z","shell.execute_reply.started":"2022-03-05T09:05:07.858526Z","shell.execute_reply":"2022-03-05T09:05:08.266395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(test)\nsubmission['congestion'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:05:08.269478Z","iopub.execute_input":"2022-03-05T09:05:08.269739Z","iopub.status.idle":"2022-03-05T09:05:08.291856Z","shell.execute_reply.started":"2022-03-05T09:05:08.269702Z","shell.execute_reply":"2022-03-05T09:05:08.291132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:05:08.293141Z","iopub.execute_input":"2022-03-05T09:05:08.293379Z","iopub.status.idle":"2022-03-05T09:05:08.317215Z","shell.execute_reply.started":"2022-03-05T09:05:08.293345Z","shell.execute_reply":"2022-03-05T09:05:08.316425Z"},"trusted":true},"execution_count":null,"outputs":[]}]}