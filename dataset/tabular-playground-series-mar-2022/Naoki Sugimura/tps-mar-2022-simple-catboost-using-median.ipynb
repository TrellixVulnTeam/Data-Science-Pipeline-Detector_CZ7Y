{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T04:21:46.284921Z","iopub.execute_input":"2022-04-04T04:21:46.285649Z","iopub.status.idle":"2022-04-04T04:21:46.29006Z","shell.execute_reply.started":"2022-04-04T04:21:46.28561Z","shell.execute_reply":"2022-04-04T04:21:46.289198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load csv","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:21:46.294233Z","iopub.execute_input":"2022-04-04T04:21:46.294984Z","iopub.status.idle":"2022-04-04T04:21:47.177595Z","shell.execute_reply.started":"2022-04-04T04:21:46.294944Z","shell.execute_reply":"2022-04-04T04:21:47.176849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:21:47.179181Z","iopub.execute_input":"2022-04-04T04:21:47.179441Z","iopub.status.idle":"2022-04-04T04:21:47.362342Z","shell.execute_reply.started":"2022-04-04T04:21:47.179405Z","shell.execute_reply":"2022-04-04T04:21:47.361611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"markdown","source":"You can start feature engineering quickly by The function 'feat_eng()'","metadata":{}},{"cell_type":"markdown","source":"I'm inspired by the notebook [(Very Simple Using the Median)](https://www.kaggle.com/code/robertturro/very-simple-using-the-median)","metadata":{}},{"cell_type":"markdown","source":"inputs\n* time\n* month\n* weekday\n* hour\n* minute\n* month_start\n* month_end\n* weekend\n* afternoon\n* daytime_id\n* road\n* median\n\n-----------\noutput\n* congestion","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \nle = LabelEncoder()\n\n\ndef med():\n    df = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv')\n    df['time'] = pd.to_datetime(df['time'])\n    df['hour'] = df['time'].dt.hour\n    df['minute'] = df['time'].dt.minute\n    df['daytime_id'] = ( ( df.time.dt.hour*60 + df.time.dt.minute ) /20 ).astype(int)\n    df['road'] = df['x'].astype(str) + df['y'].astype(str) + df['direction']\n    df['road'] = le.fit_transform(df['road'])\n    # add median\n    med = df.groupby(['road', 'daytime_id']).congestion.median().astype(int)\n    return med\n    \n    \ndef feat_eng(train = True):\n    median = med()\n    if train:\n        # data processing about time\n        df = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv')\n        df['time'] = pd.to_datetime(df['time'])\n        df['month'] = df['time'].dt.month\n        df['weekday'] = df['time'].dt.weekday\n        df['hour'] = df['time'].dt.hour\n        #df['minute'] = df['time'].dt.minute\n        #df['month_start'] = df['time'].dt.is_month_start.astype('int')\n        #df['month_end'] = df['time'].dt.is_month_end.astype('int')\n        df['weekend'] = (df['time'].dt.dayofweek > 5).astype('int')\n        df['afternoon'] = (df['time'].dt.hour > 12).astype('int')\n        df['daytime_id'] = ( ( df.time.dt.hour*60 + df.time.dt.minute ) /20 ).astype(int)\n        \n        # labeling road\n        df['road'] = df['x'].astype(str) + df['y'].astype(str) + df['direction']\n        df['road'] = le.fit_transform(df['road'])\n        \n        # add median\n        df = df.merge(median,left_on=['road', 'daytime_id'], right_index=True,  suffixes=['', '_median'])\n        df = df.rename(columns={'congestion_median': 'median'})\n\n        # drop unnecessary columns \n        df = df.drop(['x','y','row_id', 'direction'], axis=1)\n        \n        x = df.drop(['congestion'], axis=1)\n        y = df['congestion']\n        \n        # return input(other), output(congestion)\n        return  x, y \n    \n    else:\n        # data processing about time\n        df = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv')\n        df['time'] = pd.to_datetime(df['time'])\n        df['month'] = df['time'].dt.month\n        df['weekday'] = df['time'].dt.weekday\n        df['hour'] = df['time'].dt.hour\n        #df['minute'] = df['time'].dt.minute\n        # df['month_start'] = df['time'].dt.is_month_start.astype('int')\n        # df['month_end'] = df['time'].dt.is_month_end.astype('int')\n        df['weekend'] = (df['time'].dt.dayofweek > 5).astype('int')\n        df['afternoon'] = (df['time'].dt.hour > 12).astype('int')\n        df['daytime_id'] = ( ( df.time.dt.hour*60 + df.time.dt.minute ) /20 ).astype(int)\n        \n        # labeling road\n        df['road'] = df['x'].astype(str) + df['y'].astype(str) + df['direction']\n        df['road'] = le.fit_transform(df['road'])\n        \n        # add median\n        df = df.merge(median,left_on=['road', 'daytime_id'], right_index=True)\n        df = df.rename(columns={'congestion': 'median'})\n        \n        # drop unnecessary columns \n        df = df.drop(['x','y','row_id', 'direction'], axis=1)\n        \n        # return input\n        return df","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:21:47.363467Z","iopub.execute_input":"2022-04-04T04:21:47.363711Z","iopub.status.idle":"2022-04-04T04:21:47.384152Z","shell.execute_reply.started":"2022-04-04T04:21:47.363667Z","shell.execute_reply":"2022-04-04T04:21:47.383206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datasets","metadata":{}},{"cell_type":"code","source":"train_x, train_y = feat_eng(train = True)\nval_x = feat_eng(train = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:21:47.38609Z","iopub.execute_input":"2022-04-04T04:21:47.386888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold,TimeSeriesSplit\nfrom catboost import CatBoostRegressor\n\n\nmodel_list = []\nmae_list = []\n\n# fold5\nkf = KFold(n_splits = 5, shuffle = True, random_state = 70)\n\n# modeling and training\nfor fold, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n    print(f'--------fold:{fold+1}--------')\n    fold+=1\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    \n    params = {'logging_level': 'Silent',\n              'depth': 12,\n              'eval_metric': 'MAE',\n              'loss_function': 'MAE',\n              'n_estimators': 800,\n              'task_type': 'GPU'\n        \n     }\n                  \n    model = CatBoostRegressor(**params)\n    # Training the model\n    \n    model.fit(tr_x,\n              tr_y,\n              eval_set=[(va_x, va_y)])\n    \n    val_pred = model.predict(va_x)\n    \n    print(f' MAE: {mean_absolute_error(va_y, val_pred)}')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna","metadata":{}},{"cell_type":"code","source":"# from sklearn.metrics import mean_absolute_error\n# from sklearn.model_selection import KFold,TimeSeriesSplit\n# from sklearn.linear_model import LinearRegression\n# import xgboost as xgb\n# from xgboost import XGBRegressor\n# from lightgbm import LGBMRegressor\n# from catboost import CatBoostRegressor\n\n# from sklearn.model_selection import train_test_split\n# from catboost import Pool\n# import sklearn.metrics\n\n# model_list = []\n# mae_list = []\n\n# # fold5\n# kf = KFold(n_splits = 5, shuffle = True, random_state = 70)\n\n# # modeling and training\n# def objective(trial):\n#     for fold, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n#         if fold ==1:\n#             print(f'--------fold:{fold+1}--------')\n#             fold+=1\n#             tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n#             tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n#             params = {\n#                 'logging_level': 'Silent',\n#                 'depth': trial.suggest_int('depth', 5, 15),\n#                 'eval_metric': 'MAE', \n#                 'loss_function': 'MAE', \n#                 'n_estimators': 800, \n#                 'task_type': 'GPU'\n#              }\n\n#             model = CatBoostRegressor()\n#             # Training the model\n\n#             model.fit(tr_x,\n#                       tr_y,\n#                       eval_set=[(va_x, va_y)])\n\n#             val_pred = model.predict(va_x)\n\n#             print(f' MAE: {mean_absolute_error(va_y, val_pred)}')\n#             return mean_absolute_error(va_y, val_pred)\n#         else:\n#             pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n# study = optuna.create_study()\n# study.optimize(objective, n_trials=1)\n# print(study.best_trial)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-mar-2022/sample_submission.csv')\nans = model.predict(val_x)\nsubmission['congestion'] = ans\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}