{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello! I fit a random forest regressor as a baseline model for the March 2022 TPS (Traffic congestion prediction).","metadata":{}},{"cell_type":"code","source":"N_ESTIMATORS = 400 # Number of estimators of RandomForestRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"e70d82cf-1141-453e-852c-5ef6ea13c3c9","_cell_guid":"8e0a9f90-bcff-4727-813a-b736f75f7f50","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-01T22:26:52.272656Z","iopub.execute_input":"2022-03-01T22:26:52.273266Z","iopub.status.idle":"2022-03-01T22:26:52.288701Z","shell.execute_reply.started":"2022-03-01T22:26:52.27318Z","shell.execute_reply":"2022-03-01T22:26:52.286767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2022/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2022/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2022/test.csv')\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:26:52.294967Z","iopub.execute_input":"2022-03-01T22:26:52.295461Z","iopub.status.idle":"2022-03-01T22:26:52.863877Z","shell.execute_reply.started":"2022-03-01T22:26:52.295417Z","shell.execute_reply":"2022-03-01T22:26:52.862896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check for duplicates and missing values (there are none):","metadata":{}},{"cell_type":"code","source":"print(sum(train.duplicated()))\nprint(sum(test.duplicated()))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:26:52.865578Z","iopub.execute_input":"2022-03-01T22:26:52.865901Z","iopub.status.idle":"2022-03-01T22:26:53.333518Z","shell.execute_reply.started":"2022-03-01T22:26:52.865858Z","shell.execute_reply":"2022-03-01T22:26:53.332123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.sum(train.isnull(),0))\nprint(np.sum(test.isnull(),0))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:26:53.336489Z","iopub.execute_input":"2022-03-01T22:26:53.337067Z","iopub.status.idle":"2022-03-01T22:26:53.539346Z","shell.execute_reply.started":"2022-03-01T22:26:53.337015Z","shell.execute_reply":"2022-03-01T22:26:53.538355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Process datetime column for training and test set (I should clean this up and not repeat code!):","metadata":{}},{"cell_type":"code","source":"train['year'] = train['time'].map(lambda x: int(x[:4]))\ntrain['month'] = train['time'].map(lambda x: int(x[5:7]))\ntrain['day'] = train['time'].map(lambda x: int(x[9:11]))\ntrain['hour'] = train['time'].map(lambda x: int(x[11:13]))\ntrain['minute'] = train['time'].map(lambda x: int(x[14:16]))\ntrain['second'] = train['time'].map(lambda x: int(x[17:19]))\ntrain.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:26:56.823043Z","iopub.execute_input":"2022-03-01T22:26:56.823324Z","iopub.status.idle":"2022-03-01T22:27:02.581403Z","shell.execute_reply.started":"2022-03-01T22:26:56.823272Z","shell.execute_reply":"2022-03-01T22:27:02.580332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['year'] = test['time'].map(lambda x: int(x[:4]))\ntest['month'] = test['time'].map(lambda x: int(x[5:7]))\ntest['day'] = test['time'].map(lambda x: int(x[9:11]))\ntest['hour'] = test['time'].map(lambda x: int(x[11:13]))\ntest['minute'] = test['time'].map(lambda x: int(x[14:16]))\ntest['second'] = test['time'].map(lambda x: int(x[17:19]))\ntest.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:27:02.583045Z","iopub.execute_input":"2022-03-01T22:27:02.586201Z","iopub.status.idle":"2022-03-01T22:27:02.650121Z","shell.execute_reply.started":"2022-03-01T22:27:02.586158Z","shell.execute_reply":"2022-03-01T22:27:02.649292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encode direction variable and drop rows to get X, y as training set, and Xtest","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\none_dir = OneHotEncoder()\ndirection_encoded = one_dir.fit_transform(np.array(train['direction']).reshape(-1,1)).todense()\nX = pd.concat((train, pd.DataFrame(direction_encoded)), axis=1)\nprint(X.describe().T)\nX = X.drop(['row_id','congestion','time','direction'],axis=1)\ny = train['congestion']\n\ntest_direction_encoded = one_dir.transform(np.array(test['direction']).reshape(-1,1)).todense()\nXtest = pd.concat((test, pd.DataFrame(test_direction_encoded)), axis=1)\nprint(Xtest.describe().T)\nXtest = Xtest.drop(['row_id','time','direction'],axis=1)\nprint(Xtest.describe().T)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:28:40.393264Z","iopub.execute_input":"2022-03-01T22:28:40.393865Z","iopub.status.idle":"2022-03-01T22:29:16.196722Z","shell.execute_reply.started":"2022-03-01T22:28:40.393827Z","shell.execute_reply":"2022-03-01T22:29:16.195739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Simple 85%/15% training/test split. Fit a Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nXtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size=0.15, random_state=1)\nimport time\nrfr = RandomForestRegressor(n_estimators = N_ESTIMATORS)\nprint(Xtrain.shape)\nprint(ytrain.shape)\nprint('Fitting Random Forest Regressor...')\ntt = time.time()\nrfr.fit(Xtrain, ytrain)\nprint('Done in %.1fs' % (time.time() - tt))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:28:40.393264Z","iopub.execute_input":"2022-03-01T22:28:40.393865Z","iopub.status.idle":"2022-03-01T22:29:16.196722Z","shell.execute_reply.started":"2022-03-01T22:28:40.393827Z","shell.execute_reply":"2022-03-01T22:29:16.195739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yvalid_pred = rfr.predict(Xvalid)\nfrom sklearn.metrics import mean_absolute_error as MAE\nprint('Mean absolute error on validation data: %.2f'%MAE(yvalid, yvalid_pred))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:29:22.368252Z","iopub.execute_input":"2022-03-01T22:29:22.368596Z","iopub.status.idle":"2022-03-01T22:29:23.689239Z","shell.execute_reply.started":"2022-03-01T22:29:22.36856Z","shell.execute_reply":"2022-03-01T22:29:23.688619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict using test data and submit!","metadata":{}},{"cell_type":"code","source":"predictions = rfr.predict(Xtest)\nprint(predictions)\n\noutput = pd.DataFrame({'row_id': test.row_id, 'congestion': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T22:30:12.086368Z","iopub.execute_input":"2022-03-01T22:30:12.086715Z","iopub.status.idle":"2022-03-01T22:30:12.130456Z","shell.execute_reply.started":"2022-03-01T22:30:12.086675Z","shell.execute_reply":"2022-03-01T22:30:12.129491Z"},"trusted":true},"execution_count":null,"outputs":[]}]}