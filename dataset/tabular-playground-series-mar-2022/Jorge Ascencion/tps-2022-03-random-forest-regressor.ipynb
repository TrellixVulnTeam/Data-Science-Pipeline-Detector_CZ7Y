{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T01:44:45.654963Z","iopub.execute_input":"2022-03-16T01:44:45.655545Z","iopub.status.idle":"2022-03-16T01:44:45.684495Z","shell.execute_reply.started":"2022-03-16T01:44:45.655428Z","shell.execute_reply":"2022-03-16T01:44:45.683656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport gc\nimport holidays\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nwarnings.filterwarnings(\"ignore\")\nseed = 256","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:44:45.686705Z","iopub.execute_input":"2022-03-16T01:44:45.687078Z","iopub.status.idle":"2022-03-16T01:44:47.145539Z","shell.execute_reply.started":"2022-03-16T01:44:45.687037Z","shell.execute_reply":"2022-03-16T01:44:47.144705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv')\nreal_test_df = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:44:47.146679Z","iopub.execute_input":"2022-03-16T01:44:47.14695Z","iopub.status.idle":"2022-03-16T01:44:47.875428Z","shell.execute_reply.started":"2022-03-16T01:44:47.14692Z","shell.execute_reply":"2022-03-16T01:44:47.874645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:44:47.876945Z","iopub.execute_input":"2022-03-16T01:44:47.877167Z","iopub.status.idle":"2022-03-16T01:44:47.883636Z","shell.execute_reply.started":"2022-03-16T01:44:47.87714Z","shell.execute_reply":"2022-03-16T01:44:47.883036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Model Evaluation functions\ndef evaluate_model(model, x, y):\n    y_pred = model.predict(x)\n    result = mean_absolute_error(y, y_pred)\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:44:47.88564Z","iopub.execute_input":"2022-03-16T01:44:47.886001Z","iopub.status.idle":"2022-03-16T01:44:47.897108Z","shell.execute_reply.started":"2022-03-16T01:44:47.88597Z","shell.execute_reply":"2022-03-16T01:44:47.896402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define data pre-processing functions\ndef label_encoder(df):\n    # Create coodinate codes\n    dir_mapper = {'EB': [1,0], 'NB': [0,1], 'SB': [0,-1], 'WB': [-1,0], \n                  'NE': [1,1], 'SW': [-1,-1], 'NW': [-1,1], 'SE': [1,-1]}\n    # Encode lables\n    direction = {d : i for i, d in enumerate(df['direction'].unique())}\n    df = df.copy()\n    df['direction_coord_0'] = df['direction'].map(lambda x: dir_mapper[x][0])\n    df['direction_coord_1'] = df['direction'].map(lambda x: dir_mapper[x][1])\n    df['direction'] = df['direction'].replace(direction)\n    return df\n\ndef preprocess_dates(df):\n    df = df.copy()\n    df['time'] = pd.to_datetime(df['time'])\n    df['minute'] = df['time'].dt.minute\n    df['hour'] = df['time'].dt.hour\n    df['weekday'] = df['time'].dt.weekday\n    df['day_of_month']=df['time'].dt.day\n    #df['week']=df['time'].dt.isocalendar().week     \n    #df['week'][df['week']>52]=52                    \n    #df['week']=df['week'].astype('int')\n    df['month']=df['time'].dt.month\n    #df['quarter'] = df['time'].dt.quarter\n    #df['year']=df['time'].dt.year\n    #df['day_of_year'] = df['time'].dt.day_of_year\n    df['is_month_start'] = df['time'].dt.is_month_start.astype('int')\n    df['is_month_end'] = df['time'].dt.is_month_end.astype('int')\n    df['is_weekend']=(df['weekday']//5 == 1).astype('int') \n    df['hour+minute'] = df['time'].dt.hour * 60 + df['time'].dt.minute\n    df['is_afternoon'] = (df['time'].dt.hour > 12).astype('int')\n    df['x+y'] = df['x'].astype('str') + df['y'].astype('str')\n    df['x+y+direction'] = df['x'].astype('str') + df['y'].astype('str') + df['direction'].astype('str')\n    #df['x+y+direction0'] = df['x'].astype('str') + df['y'].astype('str') + df['direction_coord_0'].astype('str')\n    #df['x+y+direction1'] = df['x'].astype('str') + df['y'].astype('str') + df['direction_coord_1'].astype('str')\n    df['hour+direction'] = df['hour'].astype('str') + df['direction'].astype('str')\n    df['hour+x+y'] = df['hour'].astype('str') + df['x'].astype('str') + df['y'].astype('str')\n    df['hour+direction+x'] = df['hour'].astype('str') + df['direction'].astype('str') + df['x'].astype('str')\n    df['hour+direction+y'] = df['hour'].astype('str') + df['direction'].astype('str') + df['y'].astype('str')\n    df['hour+direction+x+y'] = df['hour'].astype('str') + df['direction'].astype('str') + df['x'].astype('str') + df['y'].astype('str')\n    df['hour+x'] = df['hour'].astype('str') + df['x'].astype('str')\n    df['hour+y'] = df['hour'].astype('str') + df['y'].astype('str')\n    return df\n\ndef preprocess_holidays(df):\n    holidays_usa = holidays.CountryHoliday(country='US', years=[1991])\n    dates = list(holidays_usa.keys())\n    dates = sorted(pd.to_datetime(dates))\n    df = df.copy()\n    df['is_holiday'] = df['time'].apply(lambda x : 1 if x in dates else 0)\n    return df\n\ndef preprocess_timeseries(df):\n    df = df.copy()\n    # Sin of date values\n    df['sin_minute'] = np.sin(df['minute'])\n    df['sin_hour'] = np.sin(df['hour'])\n    df['sin_weekday'] = np.sin(df['weekday'])\n    df['sin_day_of_month'] = np.sin(df['day_of_month'])\n    # Cos of date values\n    df['cos_minute'] = np.cos(df['minute'])\n    df['cos_hour'] = np.cos(df['hour'])\n    df['cos_weekday'] = np.cos(df['weekday'])\n    df['cos_day_of_month'] = np.cos(df['day_of_month'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:44:47.898672Z","iopub.execute_input":"2022-03-16T01:44:47.899284Z","iopub.status.idle":"2022-03-16T01:44:47.919616Z","shell.execute_reply.started":"2022-03-16T01:44:47.89916Z","shell.execute_reply":"2022-03-16T01:44:47.918871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = label_encoder(train_df)\ntrain_df = preprocess_dates(train_df)\ntrain_df = preprocess_holidays(train_df)\ntrain_df = preprocess_timeseries(train_df)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:44:47.920654Z","iopub.execute_input":"2022-03-16T01:44:47.921284Z","iopub.status.idle":"2022-03-16T01:45:08.190315Z","shell.execute_reply.started":"2022-03-16T01:44:47.921252Z","shell.execute_reply":"2022-03-16T01:45:08.189526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train data split\ntarget_name = 'congestion'\n\nX_train = train_df.drop(['row_id', 'time', target_name], axis=1)\ny_train = train_df[target_name]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:45:08.191521Z","iopub.execute_input":"2022-03-16T01:45:08.191747Z","iopub.status.idle":"2022-03-16T01:45:08.647952Z","shell.execute_reply.started":"2022-03-16T01:45:08.191718Z","shell.execute_reply":"2022-03-16T01:45:08.647194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model: Random Forest Regressor\nhttps://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html","metadata":{}},{"cell_type":"code","source":"params = {#'n_estimators': 100, \n          #'criterion': 'squared_error',  # “squared_error”, “absolute_error”, “poisson”\n          #'max_depth': None,             # None\n          #'max_features': 'auto',         # “auto”, “sqrt”, “log2”\n          #'min_impurity_decrease': 0.0\n          #'min_samples_split': 2,\n          #'min_samples_leaf': 1, \n         }\n\nmodel =  RandomForestRegressor(**params,\n                               random_state=seed,\n                               n_jobs = -1,\n                               verbose=0)\n\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:45:08.649348Z","iopub.execute_input":"2022-03-16T01:45:08.649813Z","iopub.status.idle":"2022-03-16T01:49:29.87054Z","shell.execute_reply.started":"2022-03-16T01:45:08.649771Z","shell.execute_reply":"2022-03-16T01:49:29.869659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate model\nscore = evaluate_model(model, X_test, y_test)\nprint(score)\n#7.183546920190614","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:49:29.871632Z","iopub.execute_input":"2022-03-16T01:49:29.871864Z","iopub.status.idle":"2022-03-16T01:49:33.1884Z","shell.execute_reply.started":"2022-03-16T01:49:29.871836Z","shell.execute_reply":"2022-03-16T01:49:33.187555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features Importance","metadata":{}},{"cell_type":"code","source":"# Get features names\nfeature_names = X_train.columns.values.tolist()\n# Get features importances\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nmodel_importances = pd.Series(importances, index=feature_names).sort_values(ascending=True)[-20:]\n# Plot features importances\nfig, ax = plt.subplots(figsize=(9,9))\nmodel_importances.plot.barh()   #(yerr=std, ax=ax)\nax.set_title(\"Feature importance based on mean decrease in impurity\")\nax.set_ylabel(\"Mean decrease in impurity\")\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:49:33.189588Z","iopub.execute_input":"2022-03-16T01:49:33.189806Z","iopub.status.idle":"2022-03-16T01:49:34.862519Z","shell.execute_reply.started":"2022-03-16T01:49:33.18978Z","shell.execute_reply":"2022-03-16T01:49:34.861638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optuna Optimization","metadata":{}},{"cell_type":"code","source":"import optuna","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:49:34.863572Z","iopub.execute_input":"2022-03-16T01:49:34.86405Z","iopub.status.idle":"2022-03-16T01:49:35.392542Z","shell.execute_reply.started":"2022-03-16T01:49:34.864018Z","shell.execute_reply":"2022-03-16T01:49:35.391489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n   \n    n_estim = trial.suggest_int('n_estimators', 100, 300)\n    max_d = trial.suggest_int('max_depth', 18, 26)\n    #crit = trial.suggest_categorical('criterion', ['squared_error', 'poisson', 'absolute_error'])    \n    max_f = trial.suggest_categorical('max_features', ['sqrt', 'log2']) \n    #min_imp_d = trial.suggest_float('min_impurity_decrease', 0.0, 0.5, step = 0.01)\n    min_leaf = trial.suggest_int('min_samples_leaf', 5, 50)\n    min_split = trial.suggest_int('min_samples_split', min_leaf+1, min_leaf*2)\n    \n    \n    params = {'n_estimators': n_estim, \n              'max_depth': max_d, \n              #'criterion': crit,\n              'max_features': max_f,\n              #'min_impurity_decrease': min_imp_d,\n              'min_samples_split': min_split,\n              'min_samples_leaf': min_leaf,               \n             }\n    \n    model =  RandomForestRegressor(**params,\n                                   random_state=seed,\n                                   n_jobs = -1,\n                                   verbose=0)\n    \n    model.fit(X_train, y_train)\n    score = evaluate_model(model, X_test, y_test)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:49:35.393607Z","iopub.execute_input":"2022-03-16T01:49:35.393821Z","iopub.status.idle":"2022-03-16T01:49:35.401867Z","shell.execute_reply.started":"2022-03-16T01:49:35.393796Z","shell.execute_reply":"2022-03-16T01:49:35.400619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# treat all python warnings as lower-level \"ignore\" events\nwarnings.filterwarnings(\"ignore\")\n\n# Create Optuna Trial\nstudy = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.RandomSampler(seed=seed))\n\n# Run trials\n#study.optimize(objective , n_trials = 10)\nstudy.optimize(objective, timeout = int(3600*9))    # an hour * X","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-16T01:49:35.404683Z","iopub.execute_input":"2022-03-16T01:49:35.404971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See optimization history\nfig = optuna.visualization.plot_optimization_history(study)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See hyper-parameters importances\nfig = optuna.visualization.plot_param_importances(study)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See slice\nfig = optuna.visualization.plot_slice(study)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best trial\nprint('Best trial score:', study.best_trial.value)\nstudy.best_trial.params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create model with best trial parameters\nparams = {'n_estimators': study.best_trial.params['n_estimators'], \n          'max_depth': study.best_trial.params['max_depth'], \n          #'criterion': 'squared_error',\n          'max_features': study.best_trial.params['max_features'],\n          #'min_impurity_decrease': study.best_trial.params['min_impurity_decrease'],\n          'min_samples_split': study.best_trial.params['min_samples_split'],\n          'min_samples_leaf': study.best_trial.params['min_samples_leaf'],     \n         }\n\nbest_model =  RandomForestRegressor(**params,\n                                    random_state=seed,\n                                    n_jobs = -1,\n                                    verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"# Train best model with all train data\nX_train = train_df.drop(['row_id', 'time', target_name], axis=1)\ny_train = train_df[target_name]\n\nbest_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_test_df = label_encoder(real_test_df)\nreal_test_df = preprocess_dates(real_test_df)\nreal_test_df = preprocess_holidays(real_test_df)\nreal_test_df = preprocess_timeseries(real_test_df)\nX_real_test = real_test_df.drop(['row_id', 'time'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = best_model.predict(X_real_test).squeeze()\nrow_id =  real_test_df['row_id'].values\nsubmission = pd.DataFrame({'row_id' : row_id, target_name : prediction})\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since target values are integer, and model output is float, let's round the predicted values\nsubmission[target_name] = submission[target_name].round().astype(int)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]}]}