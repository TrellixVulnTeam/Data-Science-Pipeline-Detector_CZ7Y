{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThis is my first attempt at this competition. I always try to approach these things completely naive the first time, so that I look at the problem with fresh ideas and the fun of the puzzle is maintained. ","metadata":{}},{"cell_type":"code","source":"!pip install Pycaret\n\nfrom pycaret.regression import *","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:07.38374Z","iopub.execute_input":"2022-03-11T07:06:07.384162Z","iopub.status.idle":"2022-03-11T07:06:21.153509Z","shell.execute_reply.started":"2022-03-11T07:06:07.384062Z","shell.execute_reply":"2022-03-11T07:06:21.152375Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:21.155439Z","iopub.execute_input":"2022-03-11T07:06:21.155704Z","iopub.status.idle":"2022-03-11T07:06:21.221613Z","shell.execute_reply.started":"2022-03-11T07:06:21.155672Z","shell.execute_reply":"2022-03-11T07:06:21.220543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\", infer_datetime_format=True)\ntest_df = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:21.222743Z","iopub.execute_input":"2022-03-11T07:06:21.22301Z","iopub.status.idle":"2022-03-11T07:06:22.006666Z","shell.execute_reply.started":"2022-03-11T07:06:21.222979Z","shell.execute_reply":"2022-03-11T07:06:22.005593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:22.007986Z","iopub.execute_input":"2022-03-11T07:06:22.008224Z","iopub.status.idle":"2022-03-11T07:06:22.017295Z","shell.execute_reply.started":"2022-03-11T07:06:22.008197Z","shell.execute_reply":"2022-03-11T07:06:22.016252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Look for NaNs","metadata":{}},{"cell_type":"code","source":"def detect_NaNs(df_temp, verbose=0): \n    print('NaNs in data: ', df_temp.isnull().sum().sum())\n    count_nulls = df_temp.isnull().sum().sum()\n    columns_with_NaNs = []\n    if count_nulls > 0:\n        print('******')\n        for col in df_temp.columns:\n            if df_temp[col].isnull().sum().sum() > 0:\n                columns_with_NaNs.append(col)\n                print('NaNs in', col + \": \", df_temp[col].isnull().sum().sum())\n        print('******')\n    print('')\n    return columns_with_NaNs\n\ndetect_NaNs(df)\ndetect_NaNs(test_df)\ndisplay()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:22.019555Z","iopub.execute_input":"2022-03-11T07:06:22.019818Z","iopub.status.idle":"2022-03-11T07:06:22.191139Z","shell.execute_reply.started":"2022-03-11T07:06:22.019788Z","shell.execute_reply":"2022-03-11T07:06:22.190141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Balance","metadata":{}},{"cell_type":"code","source":"sns.displot(x=df[\"congestion\"], bins=20)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:22.192618Z","iopub.execute_input":"2022-03-11T07:06:22.193182Z","iopub.status.idle":"2022-03-11T07:06:22.686915Z","shell.execute_reply.started":"2022-03-11T07:06:22.193138Z","shell.execute_reply":"2022-03-11T07:06:22.685923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks at least somewhat Gaussian. Worth testing for normality.\n\n# Normality Test\n\nLet's test the class for normality.","metadata":{}},{"cell_type":"code","source":"from statsmodels.api import qqplot\nfrom scipy.stats import shapiro\n\ndef test_normality(series, column_name, plot = 0, silent = False):\n    # create right number of samples\n    if len(series) > 5000:\n        if type(series) is pd.Series:\n            series = series.sample(frac=1)[:5000]\n        else:\n            series = series[:5000]\n    # normality test\n    stat, p = shapiro(series)\n    if not silent:\n        print('Statistics=%.3f, p=%.3f' % (stat, p))\n    # interpret\n    alpha = 0.05\n    normal = False\n    if p > alpha:\n        normal = True\n        if not silent:\n            print(column_name ,'looks Gaussian (fail to reject H0)')\n    else:\n        if not silent:\n            print(column_name ,'does not look Gaussian (reject H0)')\n    # q-q plot\n    if plot > 0:\n        qqplot(series, line='s')\n        plt.show()\n    return(normal)\n\ntest_normality(df[\"congestion\"], \"congestion\", 1)\ndisplay()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:22.688093Z","iopub.execute_input":"2022-03-11T07:06:22.688634Z","iopub.status.idle":"2022-03-11T07:06:23.537634Z","shell.execute_reply.started":"2022-03-11T07:06:22.688588Z","shell.execute_reply":"2022-03-11T07:06:23.536508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not quite Gaussian but you can see from the way it follows the red line it is pretty close.","metadata":{}},{"cell_type":"markdown","source":"# Parse Dates","metadata":{}},{"cell_type":"code","source":"from dateutil.parser import parse\n\ndf['time'] = pd.to_datetime(df['time'])\ntest_df['time'] = pd.to_datetime(test_df['time'])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:23.539103Z","iopub.execute_input":"2022-03-11T07:06:23.53936Z","iopub.status.idle":"2022-03-11T07:06:23.695452Z","shell.execute_reply.started":"2022-03-11T07:06:23.539326Z","shell.execute_reply":"2022-03-11T07:06:23.694348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show Directions\n\nI just want to check to make sure there is nothing weird or incorrect in this","metadata":{}},{"cell_type":"code","source":"df.direction.unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:23.696623Z","iopub.execute_input":"2022-03-11T07:06:23.696869Z","iopub.status.idle":"2022-03-11T07:06:23.751762Z","shell.execute_reply.started":"2022-03-11T07:06:23.696814Z","shell.execute_reply":"2022-03-11T07:06:23.750686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=df[\"direction\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:23.753538Z","iopub.execute_input":"2022-03-11T07:06:23.753889Z","iopub.status.idle":"2022-03-11T07:06:24.520706Z","shell.execute_reply.started":"2022-03-11T07:06:23.753825Z","shell.execute_reply":"2022-03-11T07:06:24.519634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Location Ids\n\nI want to encode the location ids so I can use them later","metadata":{}},{"cell_type":"code","source":"df[\"location\"] = df[\"x\"].astype(str) + df[\"y\"].astype(str) + df[\"direction\"]\ntest_df[\"location\"] = df[\"x\"].astype(str) + df[\"y\"].astype(str) + df[\"direction\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:24.522406Z","iopub.execute_input":"2022-03-11T07:06:24.522671Z","iopub.status.idle":"2022-03-11T07:06:27.173665Z","shell.execute_reply.started":"2022-03-11T07:06:24.522642Z","shell.execute_reply":"2022-03-11T07:06:27.172742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now to encode them. ","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\ndef encode_column(df, column, test_df = None):\n    le = preprocessing.LabelEncoder()\n    classes_to_encode = df[column].astype(str).unique().tolist()\n    le.fit(classes_to_encode)\n    df[column] = le.transform(df[column].astype(str))\n    test_df[column] = le.transform(test_df[column].astype(str))\n    return df, test_df\n\ndf, test_df = encode_column(df, \"location\", test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:27.174816Z","iopub.execute_input":"2022-03-11T07:06:27.175162Z","iopub.status.idle":"2022-03-11T07:06:27.461232Z","shell.execute_reply.started":"2022-03-11T07:06:27.175129Z","shell.execute_reply":"2022-03-11T07:06:27.460214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode Direction and Engineer It\n\nIt might be nice to take the first and second letter of direction.","metadata":{}},{"cell_type":"code","source":"df[\"first_letter\"] = df[\"direction\"].str[0]\ntest_df[\"first_letter\"] = test_df[\"direction\"].str[0]\ndf, test_df = encode_column(df, \"first_letter\", test_df)\ndf[\"second_letter\"] = df[\"direction\"].str[1]\ntest_df[\"second_letter\"] = test_df[\"direction\"].str[1]\ndf, test_df = encode_column(df, \"second_letter\", test_df)\ndf, test_df = encode_column(df, \"direction\", test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:27.462451Z","iopub.execute_input":"2022-03-11T07:06:27.462674Z","iopub.status.idle":"2022-03-11T07:06:28.95255Z","shell.execute_reply.started":"2022-03-11T07:06:27.462646Z","shell.execute_reply":"2022-03-11T07:06:28.951492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check out the balance of location.","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=df[\"location\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:28.955369Z","iopub.execute_input":"2022-03-11T07:06:28.955637Z","iopub.status.idle":"2022-03-11T07:06:30.162159Z","shell.execute_reply.started":"2022-03-11T07:06:28.955605Z","shell.execute_reply":"2022-03-11T07:06:30.161197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice to see it's uniform.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Create Date Information","metadata":{}},{"cell_type":"code","source":"df['day_of_year'] = df['time'].dt.dayofyear\ndf['week_of_year'] = df['time'].dt.isocalendar().week\ndf['month_of_year'] = df['time'].dt.month\ndf['hour_of_day'] = df['time'].dt.hour\ndf['minute_of_day'] = df['time'].dt.minute\ndf['rectified_hour'] = df['hour_of_day'] + (df['time'].dt.minute / 60)\ntest_df['day_of_year'] = test_df['time'].dt.dayofyear\ntest_df['week_of_year'] = test_df['time'].dt.isocalendar().week\ntest_df['month_of_year'] = test_df['time'].dt.month\ntest_df['hour_of_day'] = test_df['time'].dt.hour\ntest_df['minute_of_day'] = test_df['time'].dt.minute\ntest_df['rectified_hour'] = test_df['hour_of_day'] + (test_df['time'].dt.minute / 60)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:30.163442Z","iopub.execute_input":"2022-03-11T07:06:30.163685Z","iopub.status.idle":"2022-03-11T07:06:30.862192Z","shell.execute_reply.started":"2022-03-11T07:06:30.163653Z","shell.execute_reply":"2022-03-11T07:06:30.861348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\ndf[\"sine\"] = np.sin((df[\"hour_of_day\"])/24 * 2 * math.pi)\ndf[\"cos\"] = np.cos((df[\"hour_of_day\"])/24 * 2 * math.pi)\ntest_df[\"sine\"] = np.sin((test_df[\"hour_of_day\"])/24 * 2 * math.pi)\ntest_df[\"cos\"] = np.cos((test_df[\"hour_of_day\"])/24 * 2 * math.pi)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:30.863932Z","iopub.execute_input":"2022-03-11T07:06:30.864247Z","iopub.status.idle":"2022-03-11T07:06:30.937645Z","shell.execute_reply.started":"2022-03-11T07:06:30.864204Z","shell.execute_reply":"2022-03-11T07:06:30.936613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add location and rectified hour\n\ndf[\"location_hour\"] = df['rectified_hour'].astype(str) + \"_\" + df['location'].astype(str)\ntest_df[\"location_hour\"] = test_df['rectified_hour'].astype(str) + \"_\" + test_df['location'].astype(str)\ndf, test_df = encode_column(df, \"location_hour\", test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:30.939272Z","iopub.execute_input":"2022-03-11T07:06:30.939941Z","iopub.status.idle":"2022-03-11T07:06:32.781713Z","shell.execute_reply.started":"2022-03-11T07:06:30.93989Z","shell.execute_reply":"2022-03-11T07:06:32.780778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot what we have so far","metadata":{}},{"cell_type":"code","source":"pltdf = df.copy()\npltdf.iloc[:500, :30].plot(subplots=True, layout=(5,6), figsize=(15,10))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:32.783008Z","iopub.execute_input":"2022-03-11T07:06:32.783477Z","iopub.status.idle":"2022-03-11T07:06:36.017635Z","shell.execute_reply.started":"2022-03-11T07:06:32.78344Z","shell.execute_reply":"2022-03-11T07:06:36.016905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Average by Time and Location\n\nThis could help us work on the test set. We will record the average for each time and location.","metadata":{}},{"cell_type":"code","source":"location_hour_df = df[['location_hour','congestion']].groupby(['location_hour']).mean()\nlocation_hour_dict = {}\nfor idx, row in location_hour_df.iterrows():\n    location_hour_dict[idx] = row[0]\ndf[\"location_hour_mean\"] = df[\"location_hour\"].map(location_hour_dict)\ntest_df[\"location_hour_mean\"] = test_df[\"location_hour\"].map(location_hour_dict)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:36.018769Z","iopub.execute_input":"2022-03-11T07:06:36.019522Z","iopub.status.idle":"2022-03-11T07:06:36.31392Z","shell.execute_reply.started":"2022-03-11T07:06:36.019481Z","shell.execute_reply":"2022-03-11T07:06:36.312911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LineRegression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import TimeSeriesSplit\n\ny = df.congestion.values\nX = df.drop(columns=[\"congestion\",\"time\",\"row_id\"]).values\n\ntscv = TimeSeriesSplit()\n\nfor i, indexes in enumerate(tscv.split(X)):\n    train_index = indexes[0]\n    test_index = indexes[1]\n    reg = LinearRegression().fit(X[train_index], y[train_index])\n    print(\"split: \" + str(i + 1))\n    print(reg.score(X[test_index], y[test_index]))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:36.31527Z","iopub.execute_input":"2022-03-11T07:06:36.315601Z","iopub.status.idle":"2022-03-11T07:06:40.505604Z","shell.execute_reply.started":"2022-03-11T07:06:36.315558Z","shell.execute_reply":"2022-03-11T07:06:40.504582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lasso Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nclf = Lasso()\n\ntscv = TimeSeriesSplit()\n\nfor i, indexes in enumerate(tscv.split(X)):\n    train_index = indexes[0]\n    test_index = indexes[1]\n    clf = Lasso().fit(X[train_index], y[train_index])\n    print(\"split: \" + str(i + 1))\n    print(clf.score(X[test_index], y[test_index]))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:40.50706Z","iopub.execute_input":"2022-03-11T07:06:40.507723Z","iopub.status.idle":"2022-03-11T07:06:43.84256Z","shell.execute_reply.started":"2022-03-11T07:06:40.50767Z","shell.execute_reply":"2022-03-11T07:06:43.841467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n\nfor i, indexes in enumerate(tscv.split(X)):\n    train_index = indexes[0]\n    test_index = indexes[1]\n    tree = DecisionTreeRegressor(random_state=0).fit(X[train_index], y[train_index])\n    print(\"split: \" + str(i + 1))\n    print(tree.score(X[test_index], y[test_index]))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:06:43.844116Z","iopub.execute_input":"2022-03-11T07:06:43.844548Z","iopub.status.idle":"2022-03-11T07:07:09.33443Z","shell.execute_reply.started":"2022-03-11T07:06:43.844501Z","shell.execute_reply":"2022-03-11T07:07:09.333348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pycaret","metadata":{}},{"cell_type":"code","source":"setup(data = df.copy().drop(columns=[\"time\",\"row_id\"]), \n             target = \"congestion\",\n             silent = True, session_id=1, normalize=False, remove_perfect_collinearity=False)\ndisplay()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:07:09.335655Z","iopub.execute_input":"2022-03-11T07:07:09.335998Z","iopub.status.idle":"2022-03-11T07:07:36.830777Z","shell.execute_reply.started":"2022-03-11T07:07:09.335966Z","shell.execute_reply":"2022-03-11T07:07:36.82968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = create_model(\"lr\")","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:13:45.673244Z","iopub.execute_input":"2022-03-11T07:13:45.673818Z","iopub.status.idle":"2022-03-11T07:13:58.867974Z","shell.execute_reply.started":"2022-03-11T07:13:45.673781Z","shell.execute_reply":"2022-03-11T07:13:58.866801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission","metadata":{}},{"cell_type":"code","source":"test_X = test_df.drop(columns=[\"time\",\"row_id\"]).values\npredictions = reg.predict(test_X)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:13:37.835817Z","iopub.status.idle":"2022-03-11T07:13:37.836743Z","shell.execute_reply.started":"2022-03-11T07:13:37.836407Z","shell.execute_reply":"2022-03-11T07:13:37.836443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")\nsample_sub[\"congestion\"] = np.round(test_df[\"location_hour_mean\"],0)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:13:37.841048Z","iopub.status.idle":"2022-03-11T07:13:37.841523Z","shell.execute_reply.started":"2022-03-11T07:13:37.841315Z","shell.execute_reply":"2022-03-11T07:13:37.841344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:13:37.843419Z","iopub.status.idle":"2022-03-11T07:13:37.84449Z","shell.execute_reply.started":"2022-03-11T07:13:37.844179Z","shell.execute_reply":"2022-03-11T07:13:37.844212Z"},"trusted":true},"execution_count":null,"outputs":[]}]}