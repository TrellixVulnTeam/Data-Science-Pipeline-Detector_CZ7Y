{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TTPS-22-03 with LSTM including Moving Average","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nimport math\nfrom tensorflow import keras\nimport time","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-03T13:24:25.596866Z","iopub.execute_input":"2022-03-03T13:24:25.597443Z","iopub.status.idle":"2022-03-03T13:24:29.917813Z","shell.execute_reply.started":"2022-03-03T13:24:25.597363Z","shell.execute_reply":"2022-03-03T13:24:29.916998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Common Parameters","metadata":{}},{"cell_type":"code","source":"sequence_length = 32\nbatch_size = 1024\ncategorical_columns = [\"x\", \"y\", \"direction\", \"hour\", \"month\", \"dayofweek\", \"key_index\"]\nsequence_numeric_columns = [\"ma5\", \"ma10\", \"ma30\", \"target\"]\nnumeric_values = [\"ma5\", \"ma10\", \"ma30\"]\nkeys = ['0_0_EB', '0_0_NB', '0_0_SB', '0_1_EB', '0_1_NB', '0_1_SB', '0_1_WB', '0_2_EB', '0_2_NB', '0_2_SB', '0_2_WB', '0_3_EB', '0_3_NB', '0_3_NE', '0_3_SB', '0_3_SW', '0_3_WB', '1_0_EB', '1_0_NB', '1_0_NE', '1_0_SB', '1_0_SW', '1_0_WB', '1_1_EB', '1_1_NB', '1_1_SB', '1_1_WB', '1_2_EB', '1_2_NB', '1_2_NE', '1_2_SB', '1_2_SW', '1_2_WB', '1_3_EB', '1_3_NB', '1_3_NE', '1_3_SB', '1_3_SW', '1_3_WB', '2_0_EB', '2_0_NB', '2_0_SB', '2_0_WB', '2_1_EB', '2_1_NB', '2_1_NE', '2_1_NW', '2_1_SB', '2_1_SE', '2_1_SW', '2_1_WB', '2_2_EB', '2_2_NB', '2_2_NE', '2_2_NW', '2_2_SB', '2_2_SE', '2_2_SW', '2_2_WB', '2_3_EB', '2_3_NB', '2_3_NE', '2_3_SB', '2_3_SW', '2_3_WB']\nis_training = False","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:24:29.919303Z","iopub.execute_input":"2022-03-03T13:24:29.919554Z","iopub.status.idle":"2022-03-03T13:24:29.928519Z","shell.execute_reply.started":"2022-03-03T13:24:29.919518Z","shell.execute_reply":"2022-03-03T13:24:29.927843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\")\ndirection_map = dict()\nfor i, direction in enumerate(train.direction.unique()):\n    direction_map[direction] = i\nkey_map = dict()\nfor i, key in enumerate(keys):\n    key_map[key] = i","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:24:33.041292Z","iopub.execute_input":"2022-03-03T13:24:33.041545Z","iopub.status.idle":"2022-03-03T13:24:33.954916Z","shell.execute_reply.started":"2022-03-03T13:24:33.041516Z","shell.execute_reply":"2022-03-03T13:24:33.954182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":" def feature_engineering(data):\n    data[\"key\"] = data[\"x\"].map(lambda item: str(item)) + \"_\" + data[\"y\"].map(lambda item: str(item)) + \"_\" + data[\"direction\"]\n    data[\"key_index\"] = data[\"key\"].map(lambda item: key_map[item])\n    data[\"direction\"] = data[\"direction\"].map(lambda item: direction_map[item])\n    data['time'] = pd.to_datetime(data['time'])\n    data['month'] = data['time'].dt.month\n    data['dayofweek'] = data['time'].dt.dayofweek\n    data['hour'] = data['time'].dt.hour\n    data = data.drop(['time'], axis=1)\n    return data\n\ndef calculate_moving_average(data):\n    for gap in [5, 10, 30]:\n        moving_average = data.rolling(gap).congestion.mean()\n        data[f\"ma{gap}\"] = list(moving_average)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:24:52.352503Z","iopub.execute_input":"2022-03-03T13:24:52.352763Z","iopub.status.idle":"2022-03-03T13:24:52.361411Z","shell.execute_reply.started":"2022-03-03T13:24:52.352735Z","shell.execute_reply":"2022-03-03T13:24:52.360746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = feature_engineering(train)\ntrain.head(30)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:24:56.003588Z","iopub.execute_input":"2022-03-03T13:24:56.004365Z","iopub.status.idle":"2022-03-03T13:24:58.249173Z","shell.execute_reply.started":"2022-03-03T13:24:56.004322Z","shell.execute_reply":"2022-03-03T13:24:58.248466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"When groupping the dataset by x, y and direction, each dataset contains 13059 records.","metadata":{}},{"cell_type":"code","source":"set(train[\"key\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:25:02.385612Z","iopub.execute_input":"2022-03-03T13:25:02.386076Z","iopub.status.idle":"2022-03-03T13:25:02.507971Z","shell.execute_reply.started":"2022-03-03T13:25:02.386041Z","shell.execute_reply":"2022-03-03T13:25:02.507244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target value is very volatile even for latest data.","metadata":{}},{"cell_type":"code","source":"gap = 30\nkey = f\"ma{gap}\"\n_0_0_EB = train[train.key==\"0_0_EB\"]\nmoving_average = _0_0_EB.rolling(gap).congestion.mean()\n_0_0_EB[key] = list(moving_average)\nlen(_0_0_EB)\n_0_0_EB[gap:][[\"congestion\", key]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:25:05.466359Z","iopub.execute_input":"2022-03-03T13:25:05.467011Z","iopub.status.idle":"2022-03-03T13:25:05.969429Z","shell.execute_reply.started":"2022-03-03T13:25:05.466973Z","shell.execute_reply":"2022-03-03T13:25:05.968651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Tensorflow Time Series Dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(window):\n    return (\n        window[:-1, 0], \n        window[:-1, 1], \n        window[:-1, 2],  \n        window[:-1, 3], \n        window[-1, 0], \n        window[-1, 1], \n        window[-1, 2],\n        window[-1, 3],\n        window[-1, 4],\n        window[-1, 5],\n        window[-1, 6],\n        window[-1, 7],\n        window[-1, 8],\n        window[-1, 9],\n    ), window[-1, -1]\ndef make_dataset(df, sequence_length=32):\n    dataset = tf.data.Dataset.from_tensor_slices((df[categorical_columns + numeric_values + [\"congestion\"]]))\n    dataset = dataset.window(sequence_length + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(sequence_length + 1))\n    dataset = dataset.map(preprocess)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:25:29.624016Z","iopub.execute_input":"2022-03-03T13:25:29.624576Z","iopub.status.idle":"2022-03-03T13:25:29.634708Z","shell.execute_reply.started":"2022-03-03T13:25:29.624534Z","shell.execute_reply":"2022-03-03T13:25:29.633893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsplit_fraction = 0.9\ntrain_datasets = []\nvalid_datasets = []\nvalidation_datas = []\nfor key in keys:\n    data = train[train.key==key].copy()\n    split_index = int(len(data) * split_fraction)\n    train_data = data[0:split_index]\n    train_data = calculate_moving_average(train_data)\n    val_data = data[split_index:]\n    val_data = calculate_moving_average(val_data)\n    train_data.shape, val_data.shape\n    train_ds = make_dataset(train_data[30:])\n    train_datasets.append(train_ds)\n    valid_ds = make_dataset(val_data[30:])\n    valid_datasets.append(valid_ds)\n    validation_datas.append(val_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:25:33.430756Z","iopub.execute_input":"2022-03-03T13:25:33.431316Z","iopub.status.idle":"2022-03-03T13:25:51.889392Z","shell.execute_reply.started":"2022-03-03T13:25:33.431277Z","shell.execute_reply":"2022-03-03T13:25:51.88874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = None\nvalid_dataset = None\nfor dataset in train_datasets:\n    if train_dataset == None:\n        train_dataset = dataset\n    else:\n        train_dataset = train_dataset.concatenate(dataset)\n\nfor dataset in valid_datasets:\n    if valid_dataset == None:\n        valid_dataset = dataset\n    else:\n        valid_dataset = valid_dataset.concatenate(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:25:59.512762Z","iopub.execute_input":"2022-03-03T13:25:59.513382Z","iopub.status.idle":"2022-03-03T13:25:59.679059Z","shell.execute_reply.started":"2022-03-03T13:25:59.513332Z","shell.execute_reply":"2022-03-03T13:25:59.678178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process_dataset(dataset, batch_size=1024, mode=\"train\"):\n    if mode == \"train\":\n        dataset = dataset.shuffle(buffer_size=batch_size)\n    dataset = dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:02.265712Z","iopub.execute_input":"2022-03-03T13:26:02.266449Z","iopub.status.idle":"2022-03-03T13:26:02.271233Z","shell.execute_reply.started":"2022-03-03T13:26:02.26641Z","shell.execute_reply":"2022-03-03T13:26:02.270373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = post_process_dataset(train_dataset)\nvalid_dataset = post_process_dataset(valid_dataset, mode=\"valid\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:07.461315Z","iopub.execute_input":"2022-03-03T13:26:07.46206Z","iopub.status.idle":"2022-03-03T13:26:07.471432Z","shell.execute_reply.started":"2022-03-03T13:26:07.462025Z","shell.execute_reply":"2022-03-03T13:26:07.470676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"markdown","source":"### Create Lookup layers","metadata":{}},{"cell_type":"code","source":"%%time\nlookupLayersMap = dict()\nfor column in categorical_columns:\n    unique_values = list(train[column].unique())\n    lookupLayersMap[column] = tf.keras.layers.IntegerLookup(vocabulary=unique_values)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:17.476464Z","iopub.execute_input":"2022-03-03T13:26:17.476722Z","iopub.status.idle":"2022-03-03T13:26:18.420008Z","shell.execute_reply.started":"2022-03-03T13:26:17.476693Z","shell.execute_reply":"2022-03-03T13:26:18.419267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    sequence_inputs = []\n    sequence_vectors = []\n    dense_inputs = []\n    dense_vectors = []\n    for column in sequence_numeric_columns:\n        sequence_input = keras.Input(shape=(sequence_length, 1), name=f\"{column}_sequnce_input\")\n        sequence_inputs.append(sequence_input)\n        sequence_vectors.append(sequence_input)\n    sequence_vector = keras.layers.Concatenate(axis=-1)(sequence_vectors)\n    sequence_vector = keras.layers.LSTM(128, return_sequences=True)(sequence_vector)\n    sequence_vector = keras.layers.LSTM(64, return_sequences=False)(sequence_vector)\n    sequence_vector = keras.layers.Dense(32, activation=\"relu\")(sequence_vector)\n\n    for column in categorical_columns:\n        dense_input = keras.Input(shape=(1, ), name=f\"{column}_dense_input\")\n        lookup = lookupLayersMap[column]\n        vocab_size = len(lookup.get_vocabulary())\n        embed_dimension = math.ceil(np.sqrt(vocab_size))\n        dense_vector = lookup(dense_input)\n        dense_vector = keras.layers.Embedding(vocab_size, embed_dimension, input_length=1)(dense_vector)\n        dense_vector = keras.layers.Reshape((-1,))(dense_vector)\n        dense_vectors.append(dense_vector)\n        dense_inputs.append(dense_input)\n        \n    for column in numeric_values:\n        dense_input = keras.Input(shape=(1, ), name=f\"{column}_dense_input\")\n        dense_vectors.append(dense_input)\n        dense_inputs.append(dense_input)\n        \n    dense_vector = keras.layers.Concatenate(axis=-1)(dense_vectors)\n    dense_vector = keras.layers.Dense(32, activation=\"relu\")(dense_vector)\n\n    vector = keras.layers.Concatenate(axis=-1)([sequence_vector, dense_vector])\n    vector = keras.layers.Dense(32, activation=\"relu\")(vector)\n    output = keras.layers.Dense(1)(vector)\n    model = keras.Model(inputs=sequence_inputs + dense_inputs, outputs=output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", \"mape\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:19.884695Z","iopub.execute_input":"2022-03-03T13:26:19.885248Z","iopub.status.idle":"2022-03-03T13:26:19.89869Z","shell.execute_reply.started":"2022-03-03T13:26:19.885209Z","shell.execute_reply":"2022-03-03T13:26:19.897943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"model = get_model()\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:22.808286Z","iopub.execute_input":"2022-03-03T13:26:22.80856Z","iopub.status.idle":"2022-03-03T13:26:25.263572Z","shell.execute_reply.started":"2022-03-03T13:26:22.808527Z","shell.execute_reply":"2022-03-03T13:26:25.262799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"cp = keras.callbacks.ModelCheckpoint(\"model.tf\", monitor=\"val_mae\", save_best_only=True, save_weights_only=True)\nes = keras.callbacks.EarlyStopping(patience=10)\nif is_training:\n    model.fit(train_dataset, epochs=50, validation_data=valid_dataset, callbacks=[es, cp])\n    model.load_weights(\"model.tf\")\nelse:\n    model.load_weights(f\"../input/tps2203-lstm-output-v2/model.tf\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:29.967169Z","iopub.execute_input":"2022-03-03T13:26:29.967463Z","iopub.status.idle":"2022-03-03T13:26:30.192296Z","shell.execute_reply.started":"2022-03-03T13:26:29.967431Z","shell.execute_reply":"2022-03-03T13:26:30.19156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"#print(model.evaluate(valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:26:32.725736Z","iopub.execute_input":"2022-03-03T13:26:32.726185Z","iopub.status.idle":"2022-03-03T13:26:52.872874Z","shell.execute_reply.started":"2022-03-03T13:26:32.726141Z","shell.execute_reply":"2022-03-03T13:26:52.871644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def make_test_dataset(df, congestions, ma5s, ma10s, ma30s, sequence_length=32):\n    data = df.copy()\n    data[\"congestion\"] = congestions[-sequence_length:len(congestions)] + [0]\n    data[\"ma5\"] = ma5s[-sequence_length-1:]\n    data[\"ma10\"] = ma10s[-sequence_length-1:]\n    data[\"ma30\"] = ma30s[-sequence_length-1:]\n    dataset = tf.data.Dataset.from_tensor_slices((data[categorical_columns + numeric_values + [\"congestion\"]]))\n    dataset = dataset.window(sequence_length + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(sequence_length + 1))\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(1)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:00:21.495241Z","iopub.execute_input":"2022-03-03T13:00:21.495926Z","iopub.status.idle":"2022-03-03T13:00:21.505144Z","shell.execute_reply.started":"2022-03-03T13:00:21.495882Z","shell.execute_reply":"2022-03-03T13:00:21.503156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_map = dict()\ncongestions_map = dict()\nma5_map = dict()\nma10_map = dict()\nma30_map = dict()\nfor key, validation_data in zip(keys, validation_datas):\n    df = validation_data.iloc[-sequence_length-1:]\n    df_map[key] = df\n    ma5_map[key] = list(df[\"ma5\"])\n    ma10_map[key] = list(df[\"ma10\"])\n    ma30_map[key] = list(df[\"ma30\"])\n    congestions_map[key] = list(df[\"congestion\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:05:51.125962Z","iopub.execute_input":"2022-03-03T13:05:51.126369Z","iopub.status.idle":"2022-03-03T13:05:51.187002Z","shell.execute_reply.started":"2022-03-03T13:05:51.126325Z","shell.execute_reply":"2022-03-03T13:05:51.185916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nbegin = time.time()\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\ntest = feature_engineering(test)\nsubmission = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")\npreditions = []\nfor i in range(len(test)):\n    item = test.iloc[i]\n    key = item[\"key\"]\n    df = df_map[key]\n    df = df.append(item)\n    congestions = congestions_map[key]\n    ma5s = ma5_map[key]\n    ma10s = ma10_map[key]\n    ma30s = ma30_map[key]\n    ds = make_test_dataset(\n        df.iloc[-sequence_length-1:len(df)], \n        congestions, \n        ma5s,\n        ma10s,\n        ma30s,\n        sequence_length=sequence_length)\n    congestion = model.predict(ds)[0][0]\n    preditions.append(congestion)\n    congestions.append(congestion)\n    ma5s.append(ma5s[-1] + (congestion - ma5s[-1]) / 5.0)\n    ma10s.append(ma10s[-1] + (congestion - ma10s[-1]) / 10.0)\n    ma30s.append(ma30s[-1] + (congestion - ma30s[-1]) / 30.0)\n    df_map[key] = df\n    congestions_map[key] = congestions\n    ma5_map[key] = ma5s\n    ma10_map[key] = ma10s\n    ma30_map[key] = ma30s\n    if (i + 1) % 100 == 0:\n        elaspsed_time = time.time() - begin\n        estimated_time = elaspsed_time / (i + 1) * len(test)\n        eta = estimated_time - elaspsed_time\n        print(f\"ETA: %.2fs\"%(eta))\nsubmission[\"congestion\"] = np.round(preditions)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T13:06:30.434157Z","iopub.execute_input":"2022-03-03T13:06:30.434428Z","iopub.status.idle":"2022-03-03T13:11:57.498885Z","shell.execute_reply.started":"2022-03-03T13:06:30.434395Z","shell.execute_reply":"2022-03-03T13:11:57.498128Z"},"trusted":true},"execution_count":null,"outputs":[]}]}