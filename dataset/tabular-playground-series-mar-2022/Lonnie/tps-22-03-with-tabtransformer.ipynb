{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS-22-03 with TabTransformer","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nimport math\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T14:15:14.123446Z","iopub.execute_input":"2022-03-05T14:15:14.124126Z","iopub.status.idle":"2022-03-05T14:15:14.128992Z","shell.execute_reply.started":"2022-03-05T14:15:14.124092Z","shell.execute_reply":"2022-03-05T14:15:14.128345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Common Parameters","metadata":{}},{"cell_type":"code","source":"batch_size = 1024\nembedding_dims = 16\nroadways = ['0_0_EB', '0_0_NB', '0_0_SB', '0_1_EB', '0_1_NB', '0_1_SB', '0_1_WB', '0_2_EB', '0_2_NB', '0_2_SB', '0_2_WB', '0_3_EB', '0_3_NB', '0_3_NE', '0_3_SB', '0_3_SW', '0_3_WB', '1_0_EB', '1_0_NB', '1_0_NE', '1_0_SB', '1_0_SW', '1_0_WB', '1_1_EB', '1_1_NB', '1_1_SB', '1_1_WB', '1_2_EB', '1_2_NB', '1_2_NE', '1_2_SB', '1_2_SW', '1_2_WB', '1_3_EB', '1_3_NB', '1_3_NE', '1_3_SB', '1_3_SW', '1_3_WB', '2_0_EB', '2_0_NB', '2_0_SB', '2_0_WB', '2_1_EB', '2_1_NB', '2_1_NE', '2_1_NW', '2_1_SB', '2_1_SE', '2_1_SW', '2_1_WB', '2_2_EB', '2_2_NB', '2_2_NE', '2_2_NW', '2_2_SB', '2_2_SE', '2_2_SW', '2_2_WB', '2_3_EB', '2_3_NB', '2_3_NE', '2_3_SB', '2_3_SW', '2_3_WB']\nroadways_map = dict()\nfor i, roadway in enumerate(roadways):\n    roadways_map[roadway] = i\ncategorical_columns = [\"x\", \"y\", \"direction\", \"roadway_index\", \"hour\", \"month\", \"dayofweek\"]\nis_training = True\nmlp_hidden_units_factors = [2, 1]","metadata":{"execution":{"iopub.status.busy":"2022-03-05T01:37:22.468846Z","iopub.execute_input":"2022-03-05T01:37:22.46972Z","iopub.status.idle":"2022-03-05T01:37:22.480095Z","shell.execute_reply.started":"2022-03-05T01:37:22.469674Z","shell.execute_reply":"2022-03-05T01:37:22.479154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\")\ndirection_map = dict()\nfor i, direction in enumerate(train.direction.unique()):\n    direction_map[direction] = i","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:50:25.424136Z","iopub.execute_input":"2022-03-05T00:50:25.425207Z","iopub.status.idle":"2022-03-05T00:50:26.28268Z","shell.execute_reply.started":"2022-03-05T00:50:25.425145Z","shell.execute_reply":"2022-03-05T00:50:26.281641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":" def feature_engineering(data):\n    data[\"roadway\"] = data[\"x\"].map(lambda item: str(item)) + \"_\" + data[\"y\"].map(lambda item: str(item)) + \"_\" + data[\"direction\"]\n    data[\"roadway_index\"] = data[\"roadway\"].map(lambda item: roadways_map[item])\n    data[\"direction\"] = data[\"direction\"].map(lambda item: direction_map[item])\n    data['time'] = pd.to_datetime(data['time'])\n    data['month'] = data['time'].dt.month\n    data['dayofweek'] = data['time'].dt.dayofweek\n    data['hour'] = data['time'].dt.hour\n    data = data.drop(['time'], axis=1)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:50:30.218232Z","iopub.execute_input":"2022-03-05T00:50:30.218553Z","iopub.status.idle":"2022-03-05T00:50:30.228095Z","shell.execute_reply.started":"2022-03-05T00:50:30.218523Z","shell.execute_reply":"2022-03-05T00:50:30.226738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = feature_engineering(train)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:50:33.28289Z","iopub.execute_input":"2022-03-05T00:50:33.283165Z","iopub.status.idle":"2022-03-05T00:50:35.916546Z","shell.execute_reply.started":"2022-03-05T00:50:33.283136Z","shell.execute_reply":"2022-03-05T00:50:35.915599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Tensorflow Dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(x, y):\n    return (x[0], x[1], x[2], x[3], x[4], x[5], x[6]), y\ndef make_dataset(df, sequence_length=32, mode=\"train\"):\n    dataset = tf.data.Dataset.from_tensor_slices((df[categorical_columns], df[\"congestion\"]))\n    dataset = dataset.map(preprocess)\n    if mode == \"train\":\n        dataset = dataset.shuffle(buffer_size=batch_size)\n    dataset = dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:50:38.049584Z","iopub.execute_input":"2022-03-05T00:50:38.050354Z","iopub.status.idle":"2022-03-05T00:50:38.05782Z","shell.execute_reply.started":"2022-03-05T00:50:38.050298Z","shell.execute_reply":"2022-03-05T00:50:38.056902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_fraction = 0.9\nsplit_index = int(len(train) * split_fraction)\ntrain_data = train[0:split_index]\nval_data = train[split_index:]\ntrain_data.shape, val_data.shape\ntrain_ds = make_dataset(train_data)\nvalid_ds = make_dataset(val_data, mode=\"valid\")","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:50:39.958651Z","iopub.execute_input":"2022-03-05T00:50:39.959086Z","iopub.status.idle":"2022-03-05T00:50:40.388337Z","shell.execute_reply.started":"2022-03-05T00:50:39.959054Z","shell.execute_reply":"2022-03-05T00:50:40.387651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"markdown","source":"### Create Lookup layers","metadata":{}},{"cell_type":"code","source":"%%time\nlookupLayersMap = dict()\nfor column in categorical_columns:\n    unique_values = list(train[column].unique())\n    lookupLayersMap[column] = tf.keras.layers.IntegerLookup(vocabulary=unique_values)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:50:46.910022Z","iopub.execute_input":"2022-03-05T00:50:46.910349Z","iopub.status.idle":"2022-03-05T00:50:48.19552Z","shell.execute_reply.started":"2022-03-05T00:50:46.910305Z","shell.execute_reply":"2022-03-05T00:50:48.194521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n    mlp_layers = []\n    for units in hidden_units:\n        mlp_layers.append(normalization_layer),\n        mlp_layers.append(layers.Dense(units, activation=activation))\n        mlp_layers.append(layers.Dropout(dropout_rate))\n\n    return keras.Sequential(mlp_layers, name=name)\ndef get_model():\n    categorical_inputs = []\n    categorical_vectors = []\n    for column in categorical_columns:\n        categorical_input = keras.Input(shape=(1, ), name=f\"{column}_dense_input\")\n        lookup = lookupLayersMap[column]\n        categorical_vector = lookup(categorical_input)\n        categorical_vector = keras.layers.Embedding(len(lookup.get_vocabulary()), embedding_dims, input_length=1)(categorical_vector)\n        categorical_vector = keras.layers.Reshape((-1, ))(categorical_vector)\n        categorical_vectors.append(categorical_vector)\n        categorical_inputs.append(categorical_input)\n    encoded_categorical_features = tf.stack(categorical_vectors, axis=1)\n    \n    num_columns = encoded_categorical_features.shape[1]\n    column_embedding = layers.Embedding(\n        input_dim=num_columns, output_dim=embedding_dims\n    )\n    column_indices = tf.range(start=0, limit=num_columns, delta=1)\n\n    encoded_categorical_features = encoded_categorical_features + column_embedding(\n        column_indices\n    )\n    for block_idx in range(3):\n        # Create a multi-head attention layer.\n        attention_output = layers.MultiHeadAttention(\n            num_heads=8,\n            key_dim=embedding_dims,\n            dropout=0.2,\n            name=f\"multihead_attention_{block_idx}\",\n        )(encoded_categorical_features, encoded_categorical_features)\n        # Skip connection 1.\n        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n            [attention_output, encoded_categorical_features]\n        )\n        # Layer normalization 1.\n        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n        # Feedforward.\n        feedforward_output = create_mlp(\n            hidden_units=[embedding_dims],\n            dropout_rate=0.2,\n            activation=keras.activations.gelu,\n            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n            name=f\"feedforward_{block_idx}\",\n        )(x)\n        # Skip connection 2.\n        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n        # Layer normalization 2.\n        encoded_categorical_features = layers.LayerNormalization(\n            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n        )(x)\n        \n    # Flatten the \"contextualized\" embeddings of the categorical features.\n    features = layers.Flatten()(encoded_categorical_features)\n    # Compute MLP hidden_units.\n    mlp_hidden_units = [\n        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n    ]\n    \n    # Create final MLP.\n    features = create_mlp(\n        hidden_units=mlp_hidden_units,\n        dropout_rate=0.2,\n        activation=keras.activations.selu,\n        normalization_layer=layers.BatchNormalization(),\n        name=\"MLP\",\n    )(features)\n\n    output = keras.layers.Dense(1)(features)\n    model = keras.Model(inputs=categorical_inputs, outputs=output)\n    adam = tfa.optimizers.AdamW(\n        learning_rate=1e-3, weight_decay=0.0001\n    )\n    model.compile(loss=\"mse\", optimizer=adam, metrics=[\"mae\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-05T01:43:52.404967Z","iopub.execute_input":"2022-03-05T01:43:52.405293Z","iopub.status.idle":"2022-03-05T01:43:52.424996Z","shell.execute_reply.started":"2022-03-05T01:43:52.405261Z","shell.execute_reply":"2022-03-05T01:43:52.42393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"model = get_model()\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T01:43:56.388334Z","iopub.execute_input":"2022-03-05T01:43:56.389266Z","iopub.status.idle":"2022-03-05T01:43:58.003732Z","shell.execute_reply.started":"2022-03-05T01:43:56.3892Z","shell.execute_reply":"2022-03-05T01:43:58.002753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"cp = keras.callbacks.ModelCheckpoint(\"model.tf\", monitor=\"val_mae\", save_best_only=True, save_weights_only=True)\nes = keras.callbacks.EarlyStopping(patience=10)\nif is_training:\n    history = model.fit(train_ds, epochs=50, validation_data=valid_ds, callbacks=[es, cp])\n    model.load_weights(\"model.tf\")\n    pd.DataFrame(history.history).plot()\n    plt.show()\nelse:\n    model.load_weights(f\"../input/tps2203-dnn-output/model.tf\")","metadata":{"execution":{"iopub.status.busy":"2022-03-05T01:44:08.357706Z","iopub.execute_input":"2022-03-05T01:44:08.358024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def preprocess_test(x):\n    return (x[0], x[1], x[2], x[3], x[4], x[5], x[6]), 0\ndef make_test_dataset(data):\n    dataset = tf.data.Dataset.from_tensor_slices((data))\n    dataset = dataset.map(preprocess_test)\n    dataset = dataset.batch(batch_size).cache().prefetch(1)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:26:32.205647Z","iopub.execute_input":"2022-03-02T15:26:32.205897Z","iopub.status.idle":"2022-03-02T15:26:32.211481Z","shell.execute_reply.started":"2022-03-02T15:26:32.205868Z","shell.execute_reply":"2022-03-02T15:26:32.210528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport time\nbegin = time.time()\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\ntest = feature_engineering(test)\ntest_ds = make_test_dataset(test[categorical_columns])\ny_pred = model.predict(test_ds)\nsubmission = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")\nsubmission[\"congestion\"] = np.round(y_pred)\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:27:46.228495Z","iopub.execute_input":"2022-03-02T15:27:46.229132Z","iopub.status.idle":"2022-03-02T15:27:51.070697Z","shell.execute_reply.started":"2022-03-02T15:27:46.229094Z","shell.execute_reply":"2022-03-02T15:27:51.07003Z"},"trusted":true},"execution_count":null,"outputs":[]}]}