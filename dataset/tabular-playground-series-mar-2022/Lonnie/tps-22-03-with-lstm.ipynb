{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS-22-03 with LSTM","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nimport math\nfrom tensorflow import keras","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-03T05:13:59.639694Z","iopub.execute_input":"2022-03-03T05:13:59.640411Z","iopub.status.idle":"2022-03-03T05:14:05.461143Z","shell.execute_reply.started":"2022-03-03T05:13:59.640309Z","shell.execute_reply":"2022-03-03T05:14:05.460103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Common Parameters","metadata":{}},{"cell_type":"code","source":"sequence_length = 32\nbatch_size = 1024\ncategorical_columns = [\"x\", \"y\", \"direction\", \"hour\", \"month\", \"dayofweek\"]\nsequence_categorical_columns = [\"x\", \"y\", \"direction\"]\nis_training = False","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:27:53.215289Z","iopub.execute_input":"2022-03-03T05:27:53.216166Z","iopub.status.idle":"2022-03-03T05:27:53.221666Z","shell.execute_reply.started":"2022-03-03T05:27:53.216119Z","shell.execute_reply":"2022-03-03T05:27:53.220772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\")\ndirection_map = dict()\nfor i, direction in enumerate(train.direction.unique()):\n    direction_map[direction] = i","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:19:26.783879Z","iopub.execute_input":"2022-03-03T05:19:26.784183Z","iopub.status.idle":"2022-03-03T05:19:27.335736Z","shell.execute_reply.started":"2022-03-03T05:19:26.784152Z","shell.execute_reply":"2022-03-03T05:19:27.334546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":" def feature_engineering(data):\n    data[\"key\"] = data[\"x\"].map(lambda item: str(item)) + \"_\" + data[\"y\"].map(lambda item: str(item)) + \"_\" + data[\"direction\"]\n    data[\"direction\"] = data[\"direction\"].map(lambda item: direction_map[item])\n    data['time'] = pd.to_datetime(data['time'])\n    data['month'] = data['time'].dt.month\n    data['dayofweek'] = data['time'].dt.dayofweek\n    data['hour'] = data['time'].dt.hour\n    data = data.drop(['time'], axis=1)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:19:41.768198Z","iopub.execute_input":"2022-03-03T05:19:41.768512Z","iopub.status.idle":"2022-03-03T05:19:41.776803Z","shell.execute_reply.started":"2022-03-03T05:19:41.768478Z","shell.execute_reply":"2022-03-03T05:19:41.775791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = feature_engineering(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:19:44.819929Z","iopub.execute_input":"2022-03-03T05:19:44.820275Z","iopub.status.idle":"2022-03-03T05:19:46.898947Z","shell.execute_reply.started":"2022-03-03T05:19:44.820237Z","shell.execute_reply":"2022-03-03T05:19:46.898018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(30)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:19:50.104816Z","iopub.execute_input":"2022-03-03T05:19:50.105097Z","iopub.status.idle":"2022-03-03T05:19:50.122581Z","shell.execute_reply.started":"2022-03-03T05:19:50.105068Z","shell.execute_reply":"2022-03-03T05:19:50.121807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"When groupping the dataset by x, y and direction, each dataset contains 13059 records.","metadata":{}},{"cell_type":"code","source":"set(train[\"key\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:20:59.423073Z","iopub.execute_input":"2022-03-03T05:20:59.423369Z","iopub.status.idle":"2022-03-03T05:20:59.564561Z","shell.execute_reply.started":"2022-03-03T05:20:59.423329Z","shell.execute_reply":"2022-03-03T05:20:59.56366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target value is very volatile even for latest data.","metadata":{}},{"cell_type":"code","source":"train[train.key==\"0_0_EB\"].congestion.plot()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:26:14.216217Z","iopub.execute_input":"2022-03-03T05:26:14.216598Z","iopub.status.idle":"2022-03-03T05:26:14.613556Z","shell.execute_reply.started":"2022-03-03T05:26:14.216563Z","shell.execute_reply":"2022-03-03T05:26:14.61269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.key==\"0_0_EB\"].congestion[-100:-1].plot()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:26:28.207943Z","iopub.execute_input":"2022-03-03T05:26:28.208862Z","iopub.status.idle":"2022-03-03T05:26:28.555516Z","shell.execute_reply.started":"2022-03-03T05:26:28.208804Z","shell.execute_reply":"2022-03-03T05:26:28.554654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Tensorflow Time Series Dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(window):\n    return (\n        window[:-1, 0], \n        window[:-1, 1], \n        window[:-1, 2],  \n        window[:-1, 3], \n        window[-1, 0], \n        window[-1, 1], \n        window[-1, 2],\n        window[-1, 3],\n        window[-1, 4],\n        window[-1, 5],\n    ), window[-1:, -1]\ndef make_dataset(df, sequence_length=32, mode=\"train\"):\n    dataset = tf.data.Dataset.from_tensor_slices((df[categorical_columns + [\"congestion\"]]))\n    dataset = dataset.window(sequence_length + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(sequence_length + 1))\n    dataset = dataset.map(preprocess)\n    if mode == \"train\":\n        dataset = dataset.shuffle(buffer_size=batch_size)\n    dataset = dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:27:42.42417Z","iopub.execute_input":"2022-03-03T05:27:42.424495Z","iopub.status.idle":"2022-03-03T05:27:42.435439Z","shell.execute_reply.started":"2022-03-03T05:27:42.424466Z","shell.execute_reply":"2022-03-03T05:27:42.434298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_fraction = 0.9\nsplit_index = int(len(train) * split_fraction)\ntrain_data = train[0:split_index]\nval_data = train[split_index:]\ntrain_data.shape, val_data.shape\ntrain_ds = make_dataset(train_data)\nvalid_ds = make_dataset(val_data, mode=\"valid\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T08:47:35.782126Z","iopub.execute_input":"2022-03-02T08:47:35.782661Z","iopub.status.idle":"2022-03-02T08:47:38.335217Z","shell.execute_reply.started":"2022-03-02T08:47:35.782624Z","shell.execute_reply":"2022-03-02T08:47:38.334492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"markdown","source":"### Create Lookup layers","metadata":{}},{"cell_type":"code","source":"%%time\nlookupLayersMap = dict()\nfor column in categorical_columns:\n    unique_values = list(train[column].unique())\n    lookupLayersMap[column] = tf.keras.layers.IntegerLookup(vocabulary=unique_values)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:27:57.24123Z","iopub.execute_input":"2022-03-03T05:27:57.241524Z","iopub.status.idle":"2022-03-03T05:27:58.63865Z","shell.execute_reply.started":"2022-03-03T05:27:57.241494Z","shell.execute_reply":"2022-03-03T05:27:58.637826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    sequence_inputs = []\n    sequence_vectors = []\n    dense_inputs = []\n    dense_vectors = []\n    for column in sequence_categorical_columns:\n        sequence_input = keras.Input(shape=(sequence_length, 1), name=f\"{column}_sequnce_input\")\n        lookup = lookupLayersMap[column]\n        vocab_size = len(lookup.get_vocabulary())\n        embed_dimension = max(math.ceil(np.sqrt(vocab_size)), 2)\n        sequence_vector = lookup(sequence_input)\n        sequence_vector = keras.layers.Embedding(vocab_size, embed_dimension, input_length=sequence_length)(sequence_vector)\n        sequence_vector = keras.layers.Reshape((-1, embed_dimension))(sequence_vector)\n        sequence_vectors.append(sequence_vector)\n        sequence_inputs.append(sequence_input)\n    target_sequence_input = keras.Input(shape=(sequence_length, 1))\n    sequence_inputs.append(target_sequence_input)\n    sequence_vectors.append(target_sequence_input)\n    sequence_vector = keras.layers.Concatenate(axis=-1)(sequence_vectors)\n    sequence_vector = keras.layers.LSTM(128, return_sequences=True)(sequence_vector)\n    sequence_vector = keras.layers.LSTM(64, return_sequences=False)(sequence_vector)\n    sequence_vector = keras.layers.Dense(128, activation=\"relu\")(sequence_vector)\n    sequence_vector = keras.layers.Dense(128, activation=\"relu\")(sequence_vector)\n    sequence_vector = keras.layers.Dense(128, activation=\"relu\")(sequence_vector)\n    sequence_vector = keras.layers.Dense(128, activation=\"relu\")(sequence_vector)\n\n    for column in categorical_columns:\n        dense_input = keras.Input(shape=(1, ), name=f\"{column}_dense_input\")\n        lookup = lookupLayersMap[column]\n        vocab_size = len(lookup.get_vocabulary())\n        embed_dimension = max(math.ceil(np.sqrt(vocab_size)), 2)\n        dense_vector = lookup(dense_input)\n        dense_vector = keras.layers.Embedding(vocab_size, embed_dimension, input_length=1)(dense_vector)\n        dense_vector = keras.layers.Reshape((-1,))(dense_vector)\n        dense_vectors.append(dense_vector)\n        dense_inputs.append(dense_input)\n        \n    dense_vector = keras.layers.Concatenate(axis=-1)(dense_vectors)\n    dense_vector = keras.layers.Dense(128, activation=\"relu\")(dense_vector)\n    dense_vector = keras.layers.Dense(128, activation=\"relu\")(dense_vector)\n    dense_vector = keras.layers.Dense(128, activation=\"relu\")(dense_vector)\n    dense_vector = keras.layers.Dense(128, activation=\"relu\")(dense_vector)\n\n    vector = keras.layers.Concatenate(axis=-1)([sequence_vector, dense_vector])\n    vector = keras.layers.Dense(32, activation=\"relu\")(vector)\n    output = keras.layers.Dense(1)(vector)\n    model = keras.Model(inputs=sequence_inputs + dense_inputs, outputs=output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:28:00.690281Z","iopub.execute_input":"2022-03-03T05:28:00.690594Z","iopub.status.idle":"2022-03-03T05:28:00.711459Z","shell.execute_reply.started":"2022-03-03T05:28:00.690553Z","shell.execute_reply":"2022-03-03T05:28:00.710724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"model = get_model()\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:28:04.489539Z","iopub.execute_input":"2022-03-03T05:28:04.489885Z","iopub.status.idle":"2022-03-03T05:28:06.880652Z","shell.execute_reply.started":"2022-03-03T05:28:04.489848Z","shell.execute_reply":"2022-03-03T05:28:06.879796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"cp = keras.callbacks.ModelCheckpoint(\"model.tf\", monitor=\"val_mae\", save_best_only=True, save_weights_only=True)\nes = keras.callbacks.EarlyStopping(patience=10)\nif is_training:\n    model.fit(train_ds, epochs=50, validation_data=valid_ds, callbacks=[es, cp])\n    model.load_weights(\"model.tf\")\nelse:\n    model.load_weights(f\"../input/tps2203-lstm-output/model.tf\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:28:12.32511Z","iopub.execute_input":"2022-03-03T05:28:12.325869Z","iopub.status.idle":"2022-03-03T05:28:12.707639Z","shell.execute_reply.started":"2022-03-03T05:28:12.325829Z","shell.execute_reply":"2022-03-03T05:28:12.706459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def make_test_dataset(df, congestions, sequence_length=32):\n    data = df.copy()\n    items = congestions[-sequence_length:len(congestions)] + [0]\n    data[\"congestion\"] = items\n    dataset = tf.data.Dataset.from_tensor_slices((data))\n    dataset = dataset.window(sequence_length + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(sequence_length + 1))\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(1)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:28:51.920732Z","iopub.execute_input":"2022-03-03T05:28:51.921127Z","iopub.status.idle":"2022-03-03T05:28:51.929784Z","shell.execute_reply.started":"2022-03-03T05:28:51.921094Z","shell.execute_reply":"2022-03-03T05:28:51.928636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport time\nbegin = time.time()\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\ntest = feature_engineering(test)\nsubmission = pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")\nfirst_batch = train.iloc[-sequence_length-1:-1]\ndf = pd.concat([first_batch[categorical_columns], test[categorical_columns]])\ncongestions = list(first_batch[\"congestion\"])\nfor i in range(len(test)):\n    ds = make_test_dataset(df.iloc[i: i+sequence_length+1], congestions, sequence_length=sequence_length)\n    congestion = model.predict(ds)[0][0]\n    congestions.append(congestion)\n    if (i + 1) % 100 == 0:\n        elaspsed_time = time.time() - begin\n        estimated_time = elaspsed_time / (i + 1) * len(test)\n        eta = estimated_time - elaspsed_time\n        print(f\"ETA: %.2f\"%(eta))\nsubmission[\"congestion\"] = np.round(congestions[sequence_length:])\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T08:47:39.48407Z","iopub.status.idle":"2022-03-02T08:47:39.484453Z","shell.execute_reply.started":"2022-03-02T08:47:39.484239Z","shell.execute_reply":"2022-03-02T08:47:39.484262Z"},"trusted":true},"execution_count":null,"outputs":[]}]}