{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **If you liked it, please upvote. It helps me a lot!!**","metadata":{}},{"cell_type":"markdown","source":"## XBoost for timeseries as simple as possible\n\nAfter a simple Exploratory Data Analysis [EDA](https://www.kaggle.com/thalesgaluchi/march-2022-playground-start-exploring), the XGBoost cames to get a good result.\n\nIn this notebook, I am going to setup and run a XGBoost. It is as simple as possible. Withoun any further feature Enginieering.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport datetime\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-04T18:22:25.863705Z","iopub.execute_input":"2022-03-04T18:22:25.86462Z","iopub.status.idle":"2022-03-04T18:22:25.870025Z","shell.execute_reply.started":"2022-03-04T18:22:25.864531Z","shell.execute_reply":"2022-03-04T18:22:25.869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH ='../input/tabular-playground-series-mar-2022/'\n\ntrain = pd.read_csv(PATH + 'train.csv', index_col = 'row_id', parse_dates=['time'])\ntest = pd.read_csv(PATH + 'test.csv', index_col = 'row_id', parse_dates=['time'])\n\n# Let's keep those line below. Just in case we need split day and time in the future.\ntrain['day'] = train.time.dt.date\ntrain['time_day'] = train.time.dt.time\n\ntest['day'] = test.time.dt.date\ntest['time_day'] = test.time.dt.time\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T18:22:25.871616Z","iopub.execute_input":"2022-03-04T18:22:25.871969Z","iopub.status.idle":"2022-03-04T18:22:27.568948Z","shell.execute_reply.started":"2022-03-04T18:22:25.871928Z","shell.execute_reply":"2022-03-04T18:22:27.568073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare train dataset\n\nLoad the train dataset, convert time to day, month, hour, minutes. I removed the year because it is the same and a number too big in relation to the others.\n\nThe train was splited in 10% for validation. As it is a time series, I took the last 10% for validation (more recent data).\n\nThe previous model used all the available data. (0.528 in public leaderboard).\n* **What if we use only Mondays for predictions?**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(PATH + 'train.csv', index_col = 'row_id', parse_dates=['time'])\n\ndata['day'] = data['time'].dt.day\ndata['month'] = data['time'].dt.month\n# data['year'] = data['time'].dt.year\ndata['hour'] = data['time'].dt.hour\ndata['min'] = data['time'].dt.minute\ndata['dayofweek'] = data['time'].dt.dayofweek\n\ndirections = pd.get_dummies(data.direction)\ndata = data.join(directions)\n \n# get number of rows for train and validation\nrows = len(data)\ntrain_rows = int(0.9*rows)\nvalid_rows = rows-train_rows\n\n# Select just Mondays for the model. \n# This is the only difference from the previous model.\ndata = data[data.dayofweek == 0]\n\nX_train, X_valid = data.iloc[:train_rows],  data.iloc[-valid_rows:] \n\n# X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n# X_valid, y_valid = valid.iloc[:,:-1], valid.iloc[:,-1]\n\ny_train = X_train.loc[:,'congestion']\ny_valid = X_valid.loc[:,'congestion']\n\ncols_drop = ['time','direction', 'congestion']\n# X_train = train.copy()\n# X_valid = valid.copy()\n\nX_train.drop(cols_drop, 1, inplace=True);\nX_valid.drop(cols_drop, 1, inplace=True);\n\n# display.display(X_train)\n# display.display(X_valid)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T18:22:27.570454Z","iopub.execute_input":"2022-03-04T18:22:27.571171Z","iopub.status.idle":"2022-03-04T18:22:28.907467Z","shell.execute_reply.started":"2022-03-04T18:22:27.57113Z","shell.execute_reply":"2022-03-04T18:22:28.906479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare test dataset","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(PATH + 'test.csv', index_col = 'row_id', parse_dates=['time'])\n\ntest['day'] = test['time'].dt.day\ntest['month'] = test['time'].dt.month\n# data['year'] = data['time'].dt.year\ntest['hour'] = test['time'].dt.hour\ntest['min'] = test['time'].dt.minute\ntest['dayofweek'] = test['time'].dt.dayofweek\n\ndirections = pd.get_dummies(test.direction)\ntest = test.join(directions)\n    \ncols_drop = ['time','direction']\ntest.drop(cols_drop, 1, inplace=True);\n\ntest.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T18:22:28.90924Z","iopub.execute_input":"2022-03-04T18:22:28.909502Z","iopub.status.idle":"2022-03-04T18:22:28.944099Z","shell.execute_reply.started":"2022-03-04T18:22:28.90947Z","shell.execute_reply":"2022-03-04T18:22:28.943374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model\n\nSimple XGBOOST setup. It can be improved using the parameters. ","metadata":{}},{"cell_type":"code","source":"# This model gives me 5.829.\nmodel = XGBRegressor(objective='reg:squarederror')\n\nmodel.fit(X_train, y_train,\n           eval_set = [(X_train, y_train), (X_valid, y_valid)],\n           early_stopping_rounds=50,\n           verbose=False)\n\nyhat = model.predict(test)\nyhat","metadata":{"execution":{"iopub.status.busy":"2022-03-04T18:22:28.945126Z","iopub.execute_input":"2022-03-04T18:22:28.9455Z","iopub.status.idle":"2022-03-04T18:22:34.942117Z","shell.execute_reply.started":"2022-03-04T18:22:28.945466Z","shell.execute_reply":"2022-03-04T18:22:34.941181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission file\n\nThe preparation os a submission file requires attention to be accepted. Then, I usually make a simple predicition to check if the file is correctly prepared.\n","metadata":{}},{"cell_type":"code","source":"# 3rd submission using XGBoost.\nsubm = pd.read_csv(PATH + 'test.csv' )\npreds = pd.DataFrame(yhat) #, columns=['congestion'] )\nsubm['congestion'] = preds\n\nfinal = subm[['row_id', 'congestion']]\nfinal.set_index('row_id', inplace = True)\n\nfinal.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T18:22:34.943642Z","iopub.execute_input":"2022-03-04T18:22:34.943996Z","iopub.status.idle":"2022-03-04T18:22:34.965006Z","shell.execute_reply.started":"2022-03-04T18:22:34.94395Z","shell.execute_reply":"2022-03-04T18:22:34.964279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Please, leave a comment o improve this notebook.\n\n### **If you liked, give a UPVOTE**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}