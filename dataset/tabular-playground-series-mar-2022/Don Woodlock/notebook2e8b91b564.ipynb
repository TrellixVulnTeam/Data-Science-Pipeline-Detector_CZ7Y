{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"nrows = None\niterations = None\n\nrun = 21","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:24.029535Z","iopub.execute_input":"2022-03-09T12:28:24.030324Z","iopub.status.idle":"2022-03-09T12:28:24.051278Z","shell.execute_reply.started":"2022-03-09T12:28:24.030208Z","shell.execute_reply":"2022-03-09T12:28:24.050481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-03-09T12:28:24.052708Z","iopub.execute_input":"2022-03-09T12:28:24.053106Z","iopub.status.idle":"2022-03-09T12:28:24.060073Z","shell.execute_reply.started":"2022-03-09T12:28:24.053063Z","shell.execute_reply":"2022-03-09T12:28:24.059146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split as train_eval_split\nfrom lightgbm import LGBMClassifier\nimport pdb\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom math import factorial\nimport re\nfrom catboost import CatBoostRegressor\nfrom collections import defaultdict\nfrom lightgbm import LGBMRegressor\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline, make_pipeline","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:24.06154Z","iopub.execute_input":"2022-03-09T12:28:24.061984Z","iopub.status.idle":"2022-03-09T12:28:26.495678Z","shell.execute_reply.started":"2022-03-09T12:28:24.061904Z","shell.execute_reply":"2022-03-09T12:28:26.494754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_eval_kfolds(X, y, n_splits=5, random_state=None):\n    assert hasattr(X, 'iloc') # needs to be pandas data\n    assert hasattr(y, 'iloc')\n    skf = TimeSeriesSplit(n_splits=n_splits) #, shuffle=True, random_state=random_state)\n    for train_index, eval_index in skf.split(X, y):\n        X_train, X_eval = X.iloc[train_index], X.iloc[eval_index]\n        y_train, y_eval = y.iloc[train_index], y.iloc[eval_index]\n        yield X_train, X_eval, y_train, y_eval","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:26.497454Z","iopub.execute_input":"2022-03-09T12:28:26.497692Z","iopub.status.idle":"2022-03-09T12:28:26.503768Z","shell.execute_reply.started":"2022-03-09T12:28:26.497662Z","shell.execute_reply":"2022-03-09T12:28:26.50288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def isnotebook():\n    try:\n        shell = get_ipython().__class__.__name__\n        if shell == 'ZMQInteractiveShell':\n            return True   # Jupyter notebook or qtconsole\n        elif shell == 'TerminalInteractiveShell':\n            return False  # Terminal running IPython\n        else:\n            return False  # Other type (?)\n    except NameError:\n        return False      # Probably standard Python interpreter","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:26.505274Z","iopub.execute_input":"2022-03-09T12:28:26.505753Z","iopub.status.idle":"2022-03-09T12:28:26.522087Z","shell.execute_reply.started":"2022-03-09T12:28:26.505704Z","shell.execute_reply":"2022-03-09T12:28:26.521348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\n    '../input/tabular-playground-series-mar-2022/train.csv', index_col='row_id', nrows=nrows)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:26.523486Z","iopub.execute_input":"2022-03-09T12:28:26.524259Z","iopub.status.idle":"2022-03-09T12:28:26.577038Z","shell.execute_reply.started":"2022-03-09T12:28:26.524217Z","shell.execute_reply":"2022-03-09T12:28:26.576181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.to_datetime(train_df['time'])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:26.578225Z","iopub.execute_input":"2022-03-09T12:28:26.578755Z","iopub.status.idle":"2022-03-09T12:28:26.594084Z","shell.execute_reply.started":"2022-03-09T12:28:26.57872Z","shell.execute_reply":"2022-03-09T12:28:26.592952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['congestion']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:26.595239Z","iopub.execute_input":"2022-03-09T12:28:26.595907Z","iopub.status.idle":"2022-03-09T12:28:26.60388Z","shell.execute_reply.started":"2022-03-09T12:28:26.59586Z","shell.execute_reply":"2022-03-09T12:28:26.603079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isnotebook():\n    train_df['congestion'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:26.605161Z","iopub.execute_input":"2022-03-09T12:28:26.605816Z","iopub.status.idle":"2022-03-09T12:28:27.060194Z","shell.execute_reply.started":"2022-03-09T12:28:26.605775Z","shell.execute_reply":"2022-03-09T12:28:27.058992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_mean = train_df['congestion'].mean()\ntarget_mean","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.063418Z","iopub.execute_input":"2022-03-09T12:28:27.063711Z","iopub.status.idle":"2022-03-09T12:28:27.074412Z","shell.execute_reply.started":"2022-03-09T12:28:27.063674Z","shell.execute_reply":"2022-03-09T12:28:27.07215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_df['congestion'] - target_mean).abs().mean() # s/b 13.87 for starters.","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.076214Z","iopub.execute_input":"2022-03-09T12:28:27.077119Z","iopub.status.idle":"2022-03-09T12:28:27.090177Z","shell.execute_reply.started":"2022-03-09T12:28:27.077043Z","shell.execute_reply":"2022-03-09T12:28:27.088535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['x'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.092341Z","iopub.execute_input":"2022-03-09T12:28:27.093322Z","iopub.status.idle":"2022-03-09T12:28:27.101776Z","shell.execute_reply.started":"2022-03-09T12:28:27.093269Z","shell.execute_reply":"2022-03-09T12:28:27.100821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['y'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.103938Z","iopub.execute_input":"2022-03-09T12:28:27.104683Z","iopub.status.idle":"2022-03-09T12:28:27.113911Z","shell.execute_reply.started":"2022-03-09T12:28:27.104633Z","shell.execute_reply":"2022-03-09T12:28:27.112507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['x', 'y']].drop_duplicates().shape # only 12 locations.  Maybe do 12 models","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.115745Z","iopub.execute_input":"2022-03-09T12:28:27.117305Z","iopub.status.idle":"2022-03-09T12:28:27.33561Z","shell.execute_reply.started":"2022-03-09T12:28:27.117251Z","shell.execute_reply":"2022-03-09T12:28:27.334275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations = []\nfor x_loc in train_df['x'].unique():\n    for y_loc in train_df['y'].unique():\n        locations.append((x_loc, y_loc))\nlocations","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.337256Z","iopub.execute_input":"2022-03-09T12:28:27.337556Z","iopub.status.idle":"2022-03-09T12:28:27.350331Z","shell.execute_reply.started":"2022-03-09T12:28:27.337518Z","shell.execute_reply":"2022-03-09T12:28:27.348918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [c for c in train_df.columns if c not in ['congestion']]\n\nX = train_df[features]\ny = train_df['congestion']\nfeatures","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.351998Z","iopub.execute_input":"2022-03-09T12:28:27.352787Z","iopub.status.idle":"2022-03-09T12:28:27.36617Z","shell.execute_reply.started":"2022-03-09T12:28:27.352738Z","shell.execute_reply":"2022-03-09T12:28:27.364383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HandleDates(BaseEstimator, TransformerMixin):\n    \n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X, y = None):\n        X2 = X.copy()\n        date_series = pd.to_datetime(X['time'])\n\n        date_accessor = date_series.dt\n        for attr in ['date', \n                     'day', 'day_of_week', 'day_of_year', \n                     'days_in_month', 'freq', 'hour', \n                     'is_leap_year', 'is_month_end', 'is_month_start', 'is_quarter_end', \n                     'is_quarter_start', 'is_year_end', 'is_year_start', \n                     'microsecond', 'minute', 'month', 'nanosecond', \n                      'quarter', 'second', 'time', \n                     'weekday', 'year'\n                    ]:\n            X2[attr] = getattr(date_accessor, attr)\n        X2['week'] = date_accessor.isocalendar().week.astype(int)\n        X2['original_time'] = X['time']\n        X2['time'] = X2['time'].astype(str)\n        \n        # add location as one column\n        # this makes the eval better and kaggle worse. Commenting out for now.\n#         X2['location'] = X2[[\"x\",\"y\"]].apply(tuple, axis=1)\n        return X2","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.367896Z","iopub.execute_input":"2022-03-09T12:28:27.368691Z","iopub.status.idle":"2022-03-09T12:28:27.384459Z","shell.execute_reply.started":"2022-03-09T12:28:27.36864Z","shell.execute_reply":"2022-03-09T12:28:27.383477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HandleCategoricals(BaseEstimator, TransformerMixin):\n    def fit(self, X, y = None):     \n        self.object_cols = list(X.dtypes[X.dtypes == object].index)\n        print(\"found these categoricals\", self.object_cols)\n        self.encoders = {}\n        for col in self.object_cols:\n            self.encoders[col] = {c: i for i, c in enumerate(X[col].unique())}\n\n        return self\n\n    def transform(self, X, y = None):\n        X2 = X.copy()\n        for col in self.object_cols:\n            X2[col] = X2[col].map(self.encoders[col]).fillna(-1).astype(int)\n        return X2    ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.386162Z","iopub.execute_input":"2022-03-09T12:28:27.386769Z","iopub.status.idle":"2022-03-09T12:28:27.401656Z","shell.execute_reply.started":"2022-03-09T12:28:27.386722Z","shell.execute_reply":"2022-03-09T12:28:27.400248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myHandleCategoricals = HandleCategoricals()\nmyPipeline = Pipeline(steps=[\n    ('HandleDates', HandleDates()),\n    ('HandleCategoricals', myHandleCategoricals)\n])\nmyPipeline.fit(X)\nX_transformed = myPipeline.transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.403597Z","iopub.execute_input":"2022-03-09T12:28:27.404249Z","iopub.status.idle":"2022-03-09T12:28:27.475358Z","shell.execute_reply.started":"2022-03-09T12:28:27.404126Z","shell.execute_reply":"2022-03-09T12:28:27.473776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Pipeline:\n#     object_cols = None\n    \n#     def transform(self, X):\n\n#         X2 = X.copy()\n#         date_series = pd.to_datetime(X['time'])\n\n#         date_accessor = date_series.dt\n#         for attr in ['date', \n#                      'day', 'day_of_week', 'day_of_year', \n#                      'days_in_month', 'freq', 'hour', \n#                      'is_leap_year', 'is_month_end', 'is_month_start', 'is_quarter_end', \n#                      'is_quarter_start', 'is_year_end', 'is_year_start', \n#                      'microsecond', 'minute', 'month', 'nanosecond', \n#                       'quarter', 'second', 'time', \n#                      'weekday', 'year'\n#                     ]:\n#             X2[attr] = getattr(date_accessor, attr)\n#         X2['week'] = date_accessor.isocalendar().week.astype(int)\n#         X2['original_time'] = X['time']\n#         X2['time'] = X2['time'].astype(str)\n        \n#         # add location as one column\n#         # this makes the eval better and kaggle worse. Commenting out for now.\n# #         X2['location'] = X2[[\"x\",\"y\"]].apply(tuple, axis=1)\n        \n#         # turn other objects into strings.\n#         self.object_cols = list(X2.dtypes[X2.dtypes == object].index)\n#         X2[self.object_cols] = X2[self.object_cols].astype(str)\n        \n        \n#         return X2","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.47677Z","iopub.execute_input":"2022-03-09T12:28:27.477047Z","iopub.status.idle":"2022-03-09T12:28:27.482646Z","shell.execute_reply.started":"2022-03-09T12:28:27.476992Z","shell.execute_reply":"2022-03-09T12:28:27.481682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# myPipeline = Pipeline()\n# X_transformed = myPipeline.transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.484104Z","iopub.execute_input":"2022-03-09T12:28:27.485124Z","iopub.status.idle":"2022-03-09T12:28:27.497309Z","shell.execute_reply.started":"2022-03-09T12:28:27.485067Z","shell.execute_reply":"2022-03-09T12:28:27.49618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# models by location\nmodels_by_location = {}\nscores = []; weights = []\nfor (x_loc, y_loc) in locations:\n    print(\"location\", x_loc, y_loc)\n    subset_index = X_transformed.query(f\"x == {x_loc} and y == {y_loc}\").index\n    models = []\n    for i, (X_train, X_eval, y_train, y_eval) in enumerate(\n        train_eval_kfolds(X_transformed.loc[subset_index], y.loc[subset_index], random_state=20220301)):\n\n        print(\"split\", i)\n        model = CatBoostRegressor(verbose=0, cat_features=myHandleCategoricals.object_cols, \n                              random_state=20220301, iterations=iterations) \n#         model = LGBMRegressor(random_state=20220305)\n        model.fit(X_train, y_train, eval_set=(X_eval, y_eval))\n        score = mean_absolute_error(model.predict(X_eval), y_eval)\n        print('\\tmae', score)\n        scores.append(score)\n        weights.append(len(y_eval)) # to compute weighted average\n        models.append(model)\n    models_by_location[(x_loc, y_loc)] = models","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:28:27.49881Z","iopub.execute_input":"2022-03-09T12:28:27.499258Z","iopub.status.idle":"2022-03-09T12:29:02.013851Z","shell.execute_reply.started":"2022-03-09T12:28:27.499214Z","shell.execute_reply":"2022-03-09T12:29:02.013055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_models_by_location = np.average(scores, weights=weights)\nprint(\"average mean of models by location\", score_models_by_location)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:02.014895Z","iopub.execute_input":"2022-03-09T12:29:02.015627Z","iopub.status.idle":"2022-03-09T12:29:02.0217Z","shell.execute_reply.started":"2022-03-09T12:29:02.015592Z","shell.execute_reply":"2022-03-09T12:29:02.020755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nscores = []\noverall_models = []\nfor i, (X_train, X_eval, y_train, y_eval) in enumerate(\n    train_eval_kfolds(X_transformed, y, random_state=20220301)):\n    \n    print(\"split\", i)\n    model = CatBoostRegressor(verbose=100, cat_features=myHandleCategoricals.object_cols, \n                          random_state=20220301, iterations=iterations)   \n#     model = LGBMRegressor(random_state=20220305)\n    model.fit(X_train, y_train, eval_set=(X_eval, y_eval))\n    score = mean_absolute_error(model.predict(X_eval), y_eval)\n    print('\\tmae', score)\n    scores.append(score)\n    overall_models.append(model)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:02.023508Z","iopub.execute_input":"2022-03-09T12:29:02.023846Z","iopub.status.idle":"2022-03-09T12:29:08.57199Z","shell.execute_reply.started":"2022-03-09T12:29:02.02377Z","shell.execute_reply":"2022-03-09T12:29:08.570901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_overall_model = np.mean(scores)\nprint(\"mae for overall model\", score_overall_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.573775Z","iopub.execute_input":"2022-03-09T12:29:08.574099Z","iopub.status.idle":"2022-03-09T12:29:08.578971Z","shell.execute_reply.started":"2022-03-09T12:29:08.574055Z","shell.execute_reply":"2022-03-09T12:29:08.578079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"overall eval score\", np.mean([score_overall_model, score_models_by_location]))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.580549Z","iopub.execute_input":"2022-03-09T12:29:08.581089Z","iopub.status.idle":"2022-03-09T12:29:08.591031Z","shell.execute_reply.started":"2022-03-09T12:29:08.581043Z","shell.execute_reply":"2022-03-09T12:29:08.590071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\n    '../input/tabular-playground-series-mar-2022/test.csv', index_col='row_id')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.592711Z","iopub.execute_input":"2022-03-09T12:29:08.593309Z","iopub.status.idle":"2022-03-09T12:29:08.618058Z","shell.execute_reply.started":"2022-03-09T12:29:08.593265Z","shell.execute_reply":"2022-03-09T12:29:08.617446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_transformed = myPipeline.transform(test_df)\ntest_df_transformed","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.621113Z","iopub.execute_input":"2022-03-09T12:29:08.621516Z","iopub.status.idle":"2022-03-09T12:29:08.67667Z","shell.execute_reply.started":"2022-03-09T12:29:08.621484Z","shell.execute_reply":"2022-03-09T12:29:08.675712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test_df[[]].copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.677848Z","iopub.execute_input":"2022-03-09T12:29:08.678099Z","iopub.status.idle":"2022-03-09T12:29:08.682609Z","shell.execute_reply.started":"2022-03-09T12:29:08.678071Z","shell.execute_reply":"2022-03-09T12:29:08.682051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (x_loc, y_loc) in locations:\n    subset_index = test_df_transformed.query(f\"x == {x_loc} and y == {y_loc}\").index\n    models = models_by_location[(x_loc, y_loc)]\n    all_test_preds = []\n    for model in models:\n        test_preds = model.predict(test_df_transformed.loc[subset_index])\n        all_test_preds.append(test_preds)\n    submission_df.loc[subset_index, \"by_location_pred\"] = sum(all_test_preds) / len(all_test_preds)  ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.683615Z","iopub.execute_input":"2022-03-09T12:29:08.683796Z","iopub.status.idle":"2022-03-09T12:29:08.826595Z","shell.execute_reply.started":"2022-03-09T12:29:08.683773Z","shell.execute_reply":"2022-03-09T12:29:08.825371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.827995Z","iopub.status.idle":"2022-03-09T12:29:08.828765Z","shell.execute_reply.started":"2022-03-09T12:29:08.82848Z","shell.execute_reply":"2022-03-09T12:29:08.828509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_test_preds = []\nfor model in overall_models:\n    test_preds = model.predict(test_df_transformed)\n    all_test_preds.append(test_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.830247Z","iopub.status.idle":"2022-03-09T12:29:08.83097Z","shell.execute_reply.started":"2022-03-09T12:29:08.83071Z","shell.execute_reply":"2022-03-09T12:29:08.830741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensembled_test_preds = sum(all_test_preds) / len(all_test_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.832382Z","iopub.status.idle":"2022-03-09T12:29:08.833112Z","shell.execute_reply.started":"2022-03-09T12:29:08.832826Z","shell.execute_reply":"2022-03-09T12:29:08.832855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['overall_model'] = ensembled_test_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.834739Z","iopub.status.idle":"2022-03-09T12:29:08.835219Z","shell.execute_reply.started":"2022-03-09T12:29:08.834955Z","shell.execute_reply":"2022-03-09T12:29:08.834981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.836829Z","iopub.status.idle":"2022-03-09T12:29:08.837311Z","shell.execute_reply.started":"2022-03-09T12:29:08.837061Z","shell.execute_reply":"2022-03-09T12:29:08.837089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['congestion'] = submission_df[['overall_model', 'by_location_pred']].mean(\n    axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.838684Z","iopub.status.idle":"2022-03-09T12:29:08.839147Z","shell.execute_reply.started":"2022-03-09T12:29:08.838897Z","shell.execute_reply":"2022-03-09T12:29:08.838923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# round - see if that helps\nsubmission_df['congestion'] = submission_df['congestion'].round().astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.840421Z","iopub.status.idle":"2022-03-09T12:29:08.840723Z","shell.execute_reply.started":"2022-03-09T12:29:08.840565Z","shell.execute_reply":"2022-03-09T12:29:08.840588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df[['congestion']].to_csv(f'submission_run{run}.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.841805Z","iopub.status.idle":"2022-03-09T12:29:08.842203Z","shell.execute_reply.started":"2022-03-09T12:29:08.841975Z","shell.execute_reply":"2022-03-09T12:29:08.842029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:29:08.843129Z","iopub.status.idle":"2022-03-09T12:29:08.843434Z","shell.execute_reply.started":"2022-03-09T12:29:08.843269Z","shell.execute_reply":"2022-03-09T12:29:08.843291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}