{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS March 2022 - Traffic Congestion Forecasting\n\nIn Kaggle's TPS March 2022 competition, we are challenged to forecast traffic congestion in U.S. metropolis. The dataset contains congestion across 65 roadways from April to September in 1991. We will be forecasting the afternoon of 30 September 1991.\n\nSince I have no experience with Time Series, i will follow [Kaggle's Time Series Course](https://www.kaggle.com/learn/time-series) by [Ryan Holbrook](https://www.kaggle.com/ryanholbrook) to gain some experience in Time Series.\n\nIf you are here to see the model I used, you can jump directly to the section [Boosted Hybrid Model](#Boosted-Hybrid-Model).\n\nLet's start with importing necessary packages and datasets.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport holidays\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\ndf_train = pd.read_csv(\"/kaggle/input/tabular-playground-series-mar-2022/train.csv\",\n                      parse_dates=[\"time\"], index_col=\"row_id\")\ndf_test = pd.read_csv(\"/kaggle/input/tabular-playground-series-mar-2022/test.csv\",\n                      parse_dates=[\"time\"], index_col=\"row_id\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:15:52.290918Z","iopub.execute_input":"2022-03-26T17:15:52.291723Z","iopub.status.idle":"2022-03-26T17:15:55.462181Z","shell.execute_reply.started":"2022-03-26T17:15:52.291614Z","shell.execute_reply":"2022-03-26T17:15:55.461277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unique Directions\n\nDirection can be one of 8 values: \n* NB ↑\n* NE ↗\n* EB →\n* SE ↘\n* SB ↓\n* SW ↙\n* WB ←\n* NW ↖\n\nSince the dataset contains 65 direction, a (x,y) coordinate can not have all these 8 directions. Lets find out unique directions.","metadata":{}},{"cell_type":"code","source":"uniq_dirs = (df_train.x.astype(str) +\" \"+ df_train.y.astype(str) +\" \"+ df_train.direction).unique()\nprint(\"There are {} unique directions as:\".format(len(uniq_dirs)))\nprint(uniq_dirs)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:15:55.463702Z","iopub.execute_input":"2022-03-26T17:15:55.463957Z","iopub.status.idle":"2022-03-26T17:15:57.877864Z","shell.execute_reply.started":"2022-03-26T17:15:55.463923Z","shell.execute_reply":"2022-03-26T17:15:57.876986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imputing Missing Time Stamps\n\nThe dataset does not have a missing value in any row or column. Still, there are missing time stamps. In this section i will create these time stamps. To impute congestion values, i will calculate mean value for the same time on the same week day in a road.","metadata":{}},{"cell_type":"code","source":"# finding difference between all possible times and out times \nall_times = pd.DataFrame(pd.date_range(\"1991-04-01 00:00:00\",\"1991-09-30 11:40:00\",freq=\"20Min\"), columns=[\"time\"])\nmissing_times = list(set(all_times.time.values)-set(df_train.time.unique()))\nprint(\"There are {} missing time stamps.\".format(len(missing_times)))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:15:57.879147Z","iopub.execute_input":"2022-03-26T17:15:57.879435Z","iopub.status.idle":"2022-03-26T17:15:57.944717Z","shell.execute_reply.started":"2022-03-26T17:15:57.879395Z","shell.execute_reply":"2022-03-26T17:15:57.943992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating average congestion for each road_weekday_hour_minute\ndf = df_train.copy()\ndf[\"day_of_week\"] = df.time.dt.day_name()\ndf[\"hour\"] = df[\"time\"].dt.hour.astype('Int64')\ndf[\"minute\"] = df[\"time\"].dt.minute.astype('Int64')\ndf[\"road_and_time\"] = df.x.astype(str)+df.y.astype(str)+df.direction+\"_\"+df.day_of_week+\"_\"+df.hour.astype(str)+\"_\"+df.minute.astype(str)\ndf = df.groupby(\"road_and_time\")[\"congestion\"].mean().round(0).astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:15:57.946396Z","iopub.execute_input":"2022-03-26T17:15:57.946656Z","iopub.status.idle":"2022-03-26T17:16:03.010498Z","shell.execute_reply.started":"2022-03-26T17:15:57.946625Z","shell.execute_reply":"2022-03-26T17:16:03.0095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looping through missing times for all roads\nmiss_cong = []\nfor t in missing_times:\n    for uniq_dir in uniq_dirs:\n        # road:\n        uniq_dir = uniq_dir.split()\n        x = uniq_dir[0]\n        y = uniq_dir[1]\n        direc = uniq_dir[2]\n        \n        # time:\n        t = pd.to_datetime(t)\n        dayofweek = t.day_name()\n        hour = t.hour\n        minute = t.minute\n        \n        # creating string to search\n        search = x+y+direc+\"_\"+dayofweek+\"_\"+str(hour)+\"_\"+str(minute)\n        cong = df[search] # avg congestion\n        miss_cong.append([t, int(x), int(y), direc, cong]) # saving in a list\n\n# into DataFrame\nmiss_cong = pd.DataFrame(miss_cong, columns=df_train.columns)\nmiss_cong.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:03.012082Z","iopub.execute_input":"2022-03-26T17:16:03.01297Z","iopub.status.idle":"2022-03-26T17:16:03.16309Z","shell.execute_reply.started":"2022-03-26T17:16:03.012921Z","shell.execute_reply":"2022-03-26T17:16:03.162226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concat with original dataframe\ndf_train = pd.concat([df_train, miss_cong])\n# sorting and resetting index\ndf_train = df_train.set_index([\"time\", \"x\", \"y\", \"direction\"]).sort_index().reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:03.164389Z","iopub.execute_input":"2022-03-26T17:16:03.164677Z","iopub.status.idle":"2022-03-26T17:16:03.641359Z","shell.execute_reply.started":"2022-03-26T17:16:03.164637Z","shell.execute_reply":"2022-03-26T17:16:03.640522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_times = pd.DataFrame(pd.date_range(\"1991-04-01 00:00:00\",\"1991-09-30 11:40:00\",freq=\"20Min\"), columns=[\"time\"])\nmissing_times = list(set(all_times.time.values)-set(df_train.time.unique()))\nprint(\"After imputation, remaining missing time stamps: {}\".format(len(missing_times)))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:03.642736Z","iopub.execute_input":"2022-03-26T17:16:03.643052Z","iopub.status.idle":"2022-03-26T17:16:03.697037Z","shell.execute_reply.started":"2022-03-26T17:16:03.643013Z","shell.execute_reply":"2022-03-26T17:16:03.696263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Congestion per Day\n\nI would like to see the mean congestion of each day between April and September. I will group the dataset by day, take mean and plot. Also, i will include moving average in the plot to see the trend.","metadata":{}},{"cell_type":"code","source":"# creating column for date\ndf = df_train.copy()\ndf[\"date\"] = pd.to_datetime(df.time.dt.date)\n\n# grouping by date\ndf = df.groupby(\"date\").mean()[\"congestion\"]\ndf = pd.DataFrame(df).reset_index()\n\n# Calculating moving average\ndf[\"congestion_ma\"] = df.congestion.rolling(window=45,  # 45-day window\n                            center=True, min_periods=15).mean()\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(\"date\", \"congestion\", data=df, color='0.5', ls='--', marker='o')\nax.plot(\"date\", \"congestion_ma\", data=df, lw=3)\nax.set_title('Average Traffic Congestion per Day');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:03.698048Z","iopub.execute_input":"2022-03-26T17:16:03.698265Z","iopub.status.idle":"2022-03-26T17:16:04.91807Z","shell.execute_reply.started":"2022-03-26T17:16:03.698238Z","shell.execute_reply":"2022-03-26T17:16:04.917223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## -- Fitting a Linear Regression Line with Weekly Dummies\n\nIn the previous plot, the first thing that caught my attention is weekly seasonality. Most probably, there are less traffic at the weekends comparing to weekdays. I will use a dummy variable for weekday and apply one hot encoding. For trend, i will use first order time step feature. Also, I will include 15 days forecasting in the plot.","metadata":{}},{"cell_type":"code","source":"# defining 1st order DeterministicProcess to fit linear regression line\ndp = DeterministicProcess(index=df.date.dt.to_period(), order=1, drop=True)\nX = dp.in_sample()\nX_fore = dp.out_of_sample(steps=15) # forecasting next 15 days\n\n# Weekly Dummies\nX[\"day_of_week\"] = X.index.dayofweek.astype(str)\nX = pd.get_dummies(X, drop_first=True)\nX_fore[\"day_of_week\"] = X_fore.index.dayofweek.astype(str)\nX_fore = pd.get_dummies(X_fore, drop_first=True)\n\n# linear regression\nmodel = LinearRegression()\nmodel.fit(X, df.loc[:,\"congestion\"])\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(\"date\", \"congestion\", data=df, color='0.5', ls='--', marker='o')\nax.plot(y_pred.index, y_pred.values, lw=2, color=\"C0\")\nax.plot(y_fore.index, y_fore.values, lw=2, color=\"C3\")\nax.set_title('Average Traffic Congestion per Day');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:04.919419Z","iopub.execute_input":"2022-03-26T17:16:04.920138Z","iopub.status.idle":"2022-03-26T17:16:05.314035Z","shell.execute_reply.started":"2022-03-26T17:16:04.9201Z","shell.execute_reply":"2022-03-26T17:16:05.313166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the folling code cell, I also included Annual seasonality. But for now, I am not sure to use it in model since we don't have the data of complete year.","metadata":{}},{"cell_type":"code","source":"# defining 1st order DeterministicProcess to fit linear regression line\nfourier_Q = CalendarFourier(freq=\"A\", order=3)\n\ndp = DeterministicProcess(index=df.date.dt.to_period(),\n                          additional_terms=[fourier_Q],\n                          order=1, drop=True)\nX = dp.in_sample()\nX_fore = dp.out_of_sample(steps=15) # forecasting next 15 days\n\n# Weekly Dummies \nX[\"day_of_week\"] = X.index.dayofweek.astype(str)\nX = pd.get_dummies(X, drop_first=True)\nX_fore[\"day_of_week\"] = X_fore.index.dayofweek.astype(str)\nX_fore = pd.get_dummies(X_fore, drop_first=True)\n\n# linear regression\nmodel = LinearRegression()\nmodel.fit(X, df.loc[:,\"congestion\"])\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(\"date\", \"congestion\", data=df, color='0.5', ls='--', marker='o')\nax.plot(y_pred.index, y_pred.values, lw=2, color=\"C0\")\nax.plot(y_fore.index, y_fore.values, lw=2, color=\"C3\")\nax.set_title('Average Traffic Congestion per Day');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:05.316666Z","iopub.execute_input":"2022-03-26T17:16:05.316912Z","iopub.status.idle":"2022-03-26T17:16:05.728756Z","shell.execute_reply.started":"2022-03-26T17:16:05.316882Z","shell.execute_reply":"2022-03-26T17:16:05.72812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Holidays\n\nUsing Python's holidays module, we can import holiday dates for different countries. I imported the holidays in 1991 in US and used as a feature with only a first order trend to see if it affect the traffic congestion. Looking at the plot, being a holiday that day pulls the linear regression line down. As a conclusion, there are less traffic in holiday days.","metadata":{}},{"cell_type":"code","source":"all_holidays = holidays.US(years=1991)\nall_holidays_list = list(all_holidays.keys()) # taking days into list\nprint(\"All holidays in 1991 in US:\")\npd.DataFrame.from_dict(all_holidays, orient=\"index\", columns=[\"Holiday\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:05.729922Z","iopub.execute_input":"2022-03-26T17:16:05.730304Z","iopub.status.idle":"2022-03-26T17:16:05.742872Z","shell.execute_reply.started":"2022-03-26T17:16:05.73026Z","shell.execute_reply":"2022-03-26T17:16:05.741993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp = DeterministicProcess(index=df.date.dt.to_period(), order=1, drop=True)\nX = dp.in_sample()\n\n# CREATING HOLIDAY FEATURE\nX[\"holiday\"] = 0\nX.loc[X.index.to_timestamp().isin(all_holidays_list),\"holiday\"] = 1\n\nmodel = LinearRegression() # linear regression\nmodel.fit(X, df.loc[:,\"congestion\"])\ny_pred = pd.Series(model.predict(X), index=X.index)\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(\"date\", \"congestion\", data=df, color='0.5', ls='--', marker='o')\nax.plot(y_pred.index, y_pred.values, lw=2, color=\"C0\")\nax.plot_date(X.loc[X.holiday==1].index, y_pred[X.loc[X.holiday==1].index], color=\"C3\", ms=8)\nax.set_title('Average Traffic Congestion per Day');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:05.744365Z","iopub.execute_input":"2022-03-26T17:16:05.744862Z","iopub.status.idle":"2022-03-26T17:16:06.110718Z","shell.execute_reply.started":"2022-03-26T17:16:05.744831Z","shell.execute_reply":"2022-03-26T17:16:06.110106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hourly Congestion\n\nIn this section, I will investigate the effect of time on traffic congestion.","metadata":{}},{"cell_type":"code","source":"# creating column for hour:minute\ndf = df_train.copy()\ndf[\"hr_mn\"] = df[\"time\"].dt.time\n\n# grouping by hour:minute\ndf = df.groupby(\"hr_mn\").mean()[\"congestion\"]\ndf = pd.DataFrame(df).reset_index()\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 4))\nax.plot(df[\"hr_mn\"].astype(str), df[\"congestion\"], color='0.5', ls='--', marker='o')\nax.tick_params(axis=\"x\", labelrotation=90)\nax.set_title('Average Traffic Congestion');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:06.111773Z","iopub.execute_input":"2022-03-26T17:16:06.112292Z","iopub.status.idle":"2022-03-26T17:16:08.958037Z","shell.execute_reply.started":"2022-03-26T17:16:06.112241Z","shell.execute_reply":"2022-03-26T17:16:08.957254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the previous graph, it is seen that there are more traffic in the afternoon comparing to morning. I will try to fit a regression line using a daily fourier components with high order.","metadata":{}},{"cell_type":"code","source":"# creating column for hour:minute\ndf = df_train.copy()\ndf[\"hr_mn\"] = df[\"time\"].dt.time\ndf[\"week\"] = df[\"time\"].dt.isocalendar().week #week number\n\n# grouping by hour:minute\ndf = df.groupby([\"week\",\"time\"]).mean()[\"congestion\"]\ndf = pd.DataFrame(df).reset_index()\nprint(\"Dataset contains information for weeks: {}\".format(df.week.unique()))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:08.959413Z","iopub.execute_input":"2022-03-26T17:16:08.959655Z","iopub.status.idle":"2022-03-26T17:16:10.02909Z","shell.execute_reply.started":"2022-03-26T17:16:08.959625Z","shell.execute_reply":"2022-03-26T17:16:10.028256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at week 14\nweek_no = 14\ndf2 = df[df.week == week_no]\n\n# daily fourier components\nfourier = CalendarFourier(freq=\"D\", order=24)\ndp = DeterministicProcess(index=df2.time.dt.to_period(\"20min\"),\n                          additional_terms=[fourier],\n                          order=1, drop=True)\nX = dp.in_sample()\nX_fore = dp.out_of_sample(steps=24*3) # forecasting for 1 day\n\n# linear regression\nmodel = LinearRegression()\nmodel.fit(X, df2.loc[:,\"congestion\"])\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 4))\nax.plot(df2[\"time\"], df2[\"congestion\"], color='0.5', ls='--', marker='o')\nax.plot(y_pred.index.to_timestamp(), y_pred.values, lw=3, color=\"C0\")\nax.plot(y_fore.index.to_timestamp(), y_fore.values, lw=3, color=\"C3\")\nax.set_title('Average Traffic Congestion per Day (Week {})'.format(week_no));\nax.tick_params(axis=\"x\", labelrotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:10.030537Z","iopub.execute_input":"2022-03-26T17:16:10.031067Z","iopub.status.idle":"2022-03-26T17:16:10.507449Z","shell.execute_reply.started":"2022-03-26T17:16:10.031018Z","shell.execute_reply":"2022-03-26T17:16:10.506494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at week 30\nweek_no = 30\ndf2 = df[df.week == week_no]\n\n# daily fourier components\nfourier = CalendarFourier(freq=\"D\", order=24)\ndp = DeterministicProcess(index=df2.time.dt.to_period(\"20min\"),\n                          additional_terms=[fourier],\n                          order=1, drop=True)\nX = dp.in_sample()\nX_fore = dp.out_of_sample(steps=24*3) # forecasting for 1 day\n\n# linear regression\nmodel = LinearRegression()\nmodel.fit(X, df2.loc[:,\"congestion\"])\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 4))\nax.plot(df2[\"time\"], df2[\"congestion\"], color='0.5', ls='--', marker='o')\nax.plot(y_pred.index.to_timestamp(), y_pred.values, lw=3, color=\"C0\")\nax.plot(y_fore.index.to_timestamp(), y_fore.values, lw=3, color=\"C3\")\nax.set_title('Average Traffic Congestion per Day (Week {})'.format(week_no));\nax.tick_params(axis=\"x\", labelrotation=90)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-26T17:16:11.031109Z","iopub.execute_input":"2022-03-26T17:16:11.031463Z","iopub.status.idle":"2022-03-26T17:16:11.592625Z","shell.execute_reply.started":"2022-03-26T17:16:11.03142Z","shell.execute_reply":"2022-03-26T17:16:11.591804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at week 38\nweek_no = 38\ndf2 = df[df.week == week_no]\n\n# daily fourier components\nfourier = CalendarFourier(freq=\"D\", order=24)\ndp = DeterministicProcess(index=df2.time.dt.to_period(\"20min\"),\n                          additional_terms=[fourier],\n                          order=1, drop=True)\nX = dp.in_sample()\nX_fore = dp.out_of_sample(steps=24*3) # forecasting for 1 day\n\n# linear regression\nmodel = LinearRegression()\nmodel.fit(X, df2.loc[:,\"congestion\"])\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\n# Plot\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(12, 4))\nax.plot(df2[\"time\"], df2[\"congestion\"], color='0.5', ls='--', marker='o')\nax.plot(y_pred.index.to_timestamp(), y_pred.values, lw=3, color=\"C0\")\nax.plot(y_fore.index.to_timestamp(), y_fore.values, lw=3, color=\"C3\")\nax.set_title('Average Traffic Congestion per Day (Week {})'.format(week_no));\nax.tick_params(axis=\"x\", labelrotation=90)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-26T17:16:11.593956Z","iopub.execute_input":"2022-03-26T17:16:11.594667Z","iopub.status.idle":"2022-03-26T17:16:12.138323Z","shell.execute_reply.started":"2022-03-26T17:16:11.594623Z","shell.execute_reply":"2022-03-26T17:16:12.137285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Regression Model\n\nIn this section, I will build a linear regression model to train traffic congestion. Using knowledge from the previous sections, there will be following features:\n* Dummy variable for week day\n* Holiday Feature\n* Daily fourier components","metadata":{}},{"cell_type":"code","source":"# Preparing DataFrame for training\ndf = df_train.copy()\ndf[\"time\"] = df.time.dt.to_period(\"20min\")\ndf = df.set_index([\"time\", \"x\", \"y\", \"direction\"]).sort_index()\n\ny = df.unstack([\"x\", \"y\", \"direction\"])\ny.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:12.139709Z","iopub.execute_input":"2022-03-26T17:16:12.140029Z","iopub.status.idle":"2022-03-26T17:16:12.854288Z","shell.execute_reply.started":"2022-03-26T17:16:12.139987Z","shell.execute_reply":"2022-03-26T17:16:12.853633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# daily fourier components\nfourier = CalendarFourier(freq=\"D\", order=24)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    additional_terms=[fourier],\n    drop=True)\n\nX = dp.in_sample()\nX_test = dp.out_of_sample(steps=12*3) #forecasting next 12 hours for every 20 minutes\n\n# Weekly Dummies\nX[\"day_of_week\"] = X.index.dayofweek.astype(str)\nX = pd.get_dummies(X, drop_first=True)\nX_test[\"day_of_week\"] = X_test.index.dayofweek.astype(str)\nX_test = pd.get_dummies(X_test, drop_first=True)\n\n# Since test set is only on Monday, there will be missing columns for other days\n# Creating these missing column in the test set\nmiss_dummies = list(set(X.columns) - set(X_test.columns))\nX_test[miss_dummies] = 0\nX_test = X_test[X.columns] #reordering columns\n\n# Holiday Feature\nX[\"holiday\"] = 0\nX.loc[X.index.to_timestamp().isin(all_holidays_list),\"holiday\"] = 1\nX_test[\"holiday\"] = 0\nX_test.loc[X_test.index.to_timestamp().isin(all_holidays_list),\"holiday\"] = 1\n\nX.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:12.855356Z","iopub.execute_input":"2022-03-26T17:16:12.855906Z","iopub.status.idle":"2022-03-26T17:16:13.099148Z","shell.execute_reply.started":"2022-03-26T17:16:12.85587Z","shell.execute_reply":"2022-03-26T17:16:13.098264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression Model\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X, y)\n\n# Predicting Test set\ny_submit = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)\ny_submit = y_submit.stack([\"x\", \"y\", \"direction\"])\n\n# Preparing df_test to the same format as y_submit\n# so that i can concat row_id and congestion\ndf_tst = df_test.copy()\ndf_tst = df_tst.reset_index()\n\ndf_tst[\"time\"] = df_tst.time.dt.to_period(\"20min\")\ndf_tst = df_tst.set_index([\"time\", \"x\", \"y\", \"direction\"]).sort_index()\n\n# concating y_submit and df_tst\ny_submit = pd.concat([df_tst, y_submit], axis=1)\ny_submit.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:13.100603Z","iopub.execute_input":"2022-03-26T17:16:13.101381Z","iopub.status.idle":"2022-03-26T17:16:13.29264Z","shell.execute_reply.started":"2022-03-26T17:16:13.101347Z","shell.execute_reply":"2022-03-26T17:16:13.291787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Boosted Hybrid Model\n\nIn this section, I will build a Boosted Hybrid model by stacking Linear Regression and XGBoost. I will first train the linear regression model and calculate residuals. Then use XGBoost to fit these residuals. I also used the predictions of the first layer as a lag feature for second layer. My features are:\n\nLinear Regression:\n* Daily fourier components (high order)\n* Dummy variable for week day\n* Holiday (boolean)\n\nXGBoost:\n* Lag feature\n* Dummy variable for week day\n* Hour\n* Month\n* Afternoon (boolean)","metadata":{}},{"cell_type":"code","source":"# definition of boosted hybrid model\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # to store column names\n        \n    def fit(self, X_1, X_2, y):\n        #training first model and calculation residuals\n        self.model_1.fit(X_1, y)\n        y_fit = pd.DataFrame(self.model_1.predict(X_1),\n                             index=X_1.index, columns=y.columns)\n        y_resid = y - y_fit\n        y_resid = y_resid.stack([\"x\", \"y\", \"direction\"]).squeeze() # wide to long\n        \n        # training second model on residuals\n        self.model_2.fit(X_2, y_resid)\n        self.y_columns = y.columns # saving for predict method\n        \n    def predict(self, X_1, X_2):\n        # predicting with first model\n        y_pred = pd.DataFrame(self.model_1.predict(X_1),\n                              index=X_1.index, columns=self.y_columns)\n        y_pred = y_pred.stack([\"x\", \"y\", \"direction\"]).squeeze()  # wide to long\n        \n        # predicting with second model and taking sum\n        y_pred += self.model_2.predict(X_2)\n        return y_pred\n    \n    def model1_fit_predict(self, X_1, X_1_test, y):\n        self.model_1.fit(X_1, y)\n        y_pred = pd.DataFrame(self.model_1.predict(X_1_test),\n                              index=X_1_test.index, columns=y.columns)\n        return y_pred.stack([\"x\", \"y\", \"direction\"])\n\n# BoostedHybrid instance\nmodel = BoostedHybrid(model_1 = LinearRegression(),\n                      model_2 = XGBRegressor(random_state=0))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:13.293849Z","iopub.execute_input":"2022-03-26T17:16:13.294088Z","iopub.status.idle":"2022-03-26T17:16:13.305772Z","shell.execute_reply.started":"2022-03-26T17:16:13.294059Z","shell.execute_reply":"2022-03-26T17:16:13.304871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing data for the first model\ndf = df_train.copy()\ndf[\"time\"] = df.time.dt.to_period(\"20min\")\ndf = df.set_index([\"time\", \"x\", \"y\", \"direction\"]).sort_index()\n\ny = df.unstack([\"x\", \"y\", \"direction\"])\n\n# Same X for linear regression as the previous section:\nfourier = CalendarFourier(freq=\"D\", order=24)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    additional_terms=[fourier],\n    drop=True)\nX_1 = dp.in_sample()\nX_test_1 = dp.out_of_sample(steps=12*3) #forecasting next 12 hours for every 20 minutes\n\n# Weekly Dummies\nX_1[\"day_of_week\"] = X_1.index.dayofweek.astype(str)\nX_1 = pd.get_dummies(X_1, drop_first=True)\nX_test_1[\"day_of_week\"] = X_test_1.index.dayofweek.astype(str)\nX_test_1 = pd.get_dummies(X_test_1, drop_first=True)\n\n# Since test set is only on Monday, there will be missing columns for other days\n# Creating these missing column in the test set\nmiss_dummies = list(set(X_1.columns) - set(X_test_1.columns))\nX_test_1[miss_dummies] = 0\nX_test_1 = X_test_1[X_1.columns] #reordering columns\n\n# Holiday Feature\nX_1[\"holiday\"] = 0\nX_1.loc[X_1.index.to_timestamp().isin(all_holidays_list),\"holiday\"] = 1\nX_test_1[\"holiday\"] = 0\nX_test_1.loc[X_test_1.index.to_timestamp().isin(all_holidays_list),\"holiday\"] = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:13.307418Z","iopub.execute_input":"2022-03-26T17:16:13.307665Z","iopub.status.idle":"2022-03-26T17:16:14.238552Z","shell.execute_reply.started":"2022-03-26T17:16:13.307634Z","shell.execute_reply":"2022-03-26T17:16:14.237729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing data for the second model\ntest_len = len(df_test) # length of test set\n\n# using predictions from first layer as lag feature for second layer\ny_pred_1 = model.model1_fit_predict(X_1, X_test_1, y) # prediction with linear regression\ndf_test_copy = df_test.copy()\ndf_test_copy[\"congestion\"] = y_pred_1.values \n\n# concat train and test set (to prepare lag features)\ndf_all = pd.concat([df_train, df_test_copy], axis=0)\ndf_all[\"time\"] = df_all.time.dt.to_period(\"20min\")\ndf_all = df_all.set_index([\"time\", \"x\", \"y\", \"direction\"]).sort_index()\ndf_all = df_all.unstack([\"x\", \"y\", \"direction\"])\n\n##### LAG FEATURES:\nlag_1 = df_all.shift(1) # 1 step lag (20 min)\nlag_1_roll = lag_1.rolling(6).mean() # rolling mean of 1 step lag\n#lag_1week = df_all.shift(7*24*3) # 1 week lag\n# renaming columns\nlag_1.columns = lag_1.columns.set_levels([\"lag_1\"],level=0)\nlag_1_roll.columns = lag_1_roll.columns.set_levels([\"lag_1_roll\"],level=0)\n#lag_1week.columns = lag_1week.columns.set_levels([\"lag_1week\"],level=0)\n\n# concat all lags\ndf_all = pd.concat([df_all, lag_1, lag_1_roll], axis=1)\ndf_all = df_all.stack([\"x\", \"y\", \"direction\"]).reset_index([\"x\", \"y\", \"direction\"])\n\n# dropping congestion, day of week & hour feature, get dummies:\ndf_all = df_all.drop([\"congestion\"], axis=1)\ndf_all = df_all.dropna()\ndf_all[\"day_of_week\"] = df_all.index.dayofweek.astype(str)\ndf_all[\"hour\"] = df_all.index.hour.astype('int64')\ndf_all[\"month\"] = df_all.index.month.astype('int64')\ndf_all.loc[df_all.index.minute == 20, \"hour\"] += 0.33 # encoding minute in hour\ndf_all.loc[df_all.index.minute == 40, \"hour\"] += 0.67\ndf_all[\"is_afternoon\"] = 0\ndf_all.loc[df_all.hour>11, \"is_afternoon\"] = 1\ndf_all = pd.get_dummies(df_all)\n\n# split train and test set\nX_2 = df_all.head(len(df_all) - test_len)\nX_test_2 = df_all.tail(test_len)\n\n# since I dropped missing lag rows in X_2, i have to drop same days in X_1 and y:\nX_2_wide_len = int(len(X_2)/65)\nX_1 = X_1.tail(X_2_wide_len)\ny = y.tail(X_2_wide_len)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:14.239809Z","iopub.execute_input":"2022-03-26T17:16:14.240352Z","iopub.status.idle":"2022-03-26T17:16:17.873565Z","shell.execute_reply.started":"2022-03-26T17:16:14.240304Z","shell.execute_reply":"2022-03-26T17:16:17.8729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_1, X_2, y)\ny_submit = model.predict(X_test_1, X_test_2)\n\n# Preparing df_test to the same format as y_submit\n# so that i can concat row_id and congestion\ndf_tst = df_test.copy()\ndf_tst = df_tst.reset_index()\n\ndf_tst[\"time\"] = df_tst.time.dt.to_period(\"20min\")\ndf_tst = df_tst.set_index([\"time\", \"x\", \"y\", \"direction\"]).sort_index()\n\n# concating y_submit and df_tst\ny_submit = pd.concat([df_tst, y_submit], axis=1)\ny_submit.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:16:17.87467Z","iopub.execute_input":"2022-03-26T17:16:17.875382Z","iopub.status.idle":"2022-03-26T17:17:12.88111Z","shell.execute_reply.started":"2022-03-26T17:16:17.875328Z","shell.execute_reply":"2022-03-26T17:17:12.880143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T17:17:12.882466Z","iopub.execute_input":"2022-03-26T17:17:12.882944Z","iopub.status.idle":"2022-03-26T17:17:12.900149Z","shell.execute_reply.started":"2022-03-26T17:17:12.882899Z","shell.execute_reply":"2022-03-26T17:17:12.89946Z"},"trusted":true},"execution_count":null,"outputs":[]}]}