{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#!pip install keras-self-attention\n#!pip install attention\n#!pip install keras-multi-head\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-27T13:07:45.505784Z","iopub.execute_input":"2022-03-27T13:07:45.506295Z","iopub.status.idle":"2022-03-27T13:07:45.540243Z","shell.execute_reply.started":"2022-03-27T13:07:45.506201Z","shell.execute_reply":"2022-03-27T13:07:45.53944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df  = pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:07:45.59878Z","iopub.execute_input":"2022-03-27T13:07:45.599008Z","iopub.status.idle":"2022-03-27T13:07:46.277769Z","shell.execute_reply.started":"2022-03-27T13:07:45.598983Z","shell.execute_reply":"2022-03-27T13:07:46.277026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df.time.unique()))\nprint(df.x.unique())\nprint(df.y.unique())\nprint(df.direction.unique())","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:07:46.279213Z","iopub.execute_input":"2022-03-27T13:07:46.279463Z","iopub.status.idle":"2022-03-27T13:07:46.425408Z","shell.execute_reply.started":"2022-03-27T13:07:46.27943Z","shell.execute_reply":"2022-03-27T13:07:46.42472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n#scaling data and formating them such as we only keep position (x,y), direction, hour and day of the week as features for congestion \ndata = df.pivot_table(index = 'time', columns = ['direction','x','y'], fill_value = 0, values = 'congestion')\n\nprint(data)\n\n\ndatatime = pd.to_datetime(data.index)\n\nsc = MinMaxScaler()\ndatanorm = sc.fit_transform(data)\n\nTime = (datatime.hour.to_numpy()*3 + datatime.minute.to_numpy()/20)\n\ndatanorm= np.append(datanorm,datatime.weekday.to_numpy()[:,np.newaxis]/6, axis = 1) \ndatanorm= np.append(datanorm, Time[:,np.newaxis]/71, axis = 1) \n\nprint(datanorm)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:07:46.426683Z","iopub.execute_input":"2022-03-27T13:07:46.427094Z","iopub.status.idle":"2022-03-27T13:07:48.141223Z","shell.execute_reply.started":"2022-03-27T13:07:46.427058Z","shell.execute_reply":"2022-03-27T13:07:48.139748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n#computing mean congestion per day of week and standard deviation associated\n\ndatatarget = datanorm[(datanorm[:,-2] == 0) & (datanorm[:,-1] <= 1) & (0.5 < datanorm[:,-1]) ] \n\ndatatarget = np.reshape(datatarget[:,:-2], (26,36,65))*100\ndatamean = np.mean(datatarget, axis = 0)\ndatadev = np.empty((36,65))\nfor i in range(65):\n    \n    for j in range(36):\n        A = (np.sum((datatarget[:,j,i] - datamean[j,i]), axis = 0)/26)\n        datadev[j,i] = A*10**15\nprint(datadev)\nprint(np.mean(datadev, axis = 1))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:07:48.14343Z","iopub.execute_input":"2022-03-27T13:07:48.143681Z","iopub.status.idle":"2022-03-27T13:07:48.17769Z","shell.execute_reply.started":"2022-03-27T13:07:48.143647Z","shell.execute_reply":"2022-03-27T13:07:48.177022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#formating datas as time-serie: 2 days of history for 12 hours of prediction\n\nNdays = 2\nlenseq = int(3*24*Ndays-36)\nXtrain = np.empty((1,lenseq, datanorm.shape[1]))\nYtrain = np.empty((1,3*12, datanorm.shape[1]-2))\n\nT = 0\nfor t in range(0, datanorm.shape[0]-(lenseq + 12*12), 6) :\n    if t//1000 > T:\n        T = t//1000\n        print(T)\n    Xtemp = np.reshape(datanorm[t:t+lenseq,:],(1,lenseq, datanorm.shape[1]))\n    Ytemp = np.reshape(datanorm[t+lenseq:t+lenseq+3*12,:datanorm.shape[1]-2],(1,3*12, datanorm.shape[1]-2))\n        \n    Xtrain = np.append(Xtrain,Xtemp, axis = 0)\n    Ytrain = np.append(Ytrain,Ytemp, axis = 0)\n    #Ytrain.append(Ytemp)\n\nXtrain = Xtrain[1:,:,:]   \nYtrain = Ytrain[1:,:,:]  \n\nXtest = np.reshape(datanorm[-lenseq:,:],(1,lenseq, datanorm.shape[1]))\n\nXval = np.reshape(datanorm[-lenseq-6*12:-6*12,:],(1,lenseq, datanorm.shape[1]))\n\nYval = np.reshape(datanorm[-12*6:-12*3,:datanorm.shape[1]-2],(1,3*12, datanorm.shape[1]-2))\nprint(Xval.shape)\nprint(Yval.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:07:48.179035Z","iopub.execute_input":"2022-03-27T13:07:48.179459Z","iopub.status.idle":"2022-03-27T13:08:45.086698Z","shell.execute_reply.started":"2022-03-27T13:07:48.179423Z","shell.execute_reply":"2022-03-27T13:08:45.085984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Xtrain.shape)\nprint(Ytrain.shape)\nprint(np.isnan(Xtrain).sum())\nXtrain[np.isnan(Xtrain)] = 0\nprint(np.isnan(Xtrain).sum())\n","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:08:45.087879Z","iopub.execute_input":"2022-03-27T13:08:45.088127Z","iopub.status.idle":"2022-03-27T13:08:45.170897Z","shell.execute_reply.started":"2022-03-27T13:08:45.088092Z","shell.execute_reply":"2022-03-27T13:08:45.170216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.keras.backend.clear_session()\nfilt = 32\nunits = 128\n#building and training model (bi-lstm + MultiHead Self Attention cells x 3 )\n\nInputs = tf.keras.Input(shape=(lenseq, datanorm.shape[1]))\nx = tf.keras.layers.Reshape((lenseq,datanorm.shape[1]),  input_shape=(lenseq, datanorm.shape[1]))(Inputs)\ny = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(units*2, return_sequences = True))(x)\ny = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(units, return_sequences = True))(y)\n\nz = tf.keras.layers.MultiHeadAttention(num_heads=9, key_dim=12, attention_axes=(1,2))(y, y, return_attention_scores=False)\nz = tf.keras.layers.LayerNormalization()(z)\nz2 = tf.keras.layers.Add()([y, z])\nz3= tf.keras.layers.TimeDistributed(\n        tf.keras.layers.Dense(units*2, activation = 'relu'))(z2)\na = tf.keras.layers.MultiHeadAttention(num_heads=9, key_dim=12, attention_axes=(1,2))(z3, z3, return_attention_scores=False)\na = tf.keras.layers.LayerNormalization()(a)\na2 = tf.keras.layers.Add()([a, z2])\na3= tf.keras.layers.TimeDistributed(\n        tf.keras.layers.Dense(units*2, activation = 'relu'))(a2)\nb = tf.keras.layers.MultiHeadAttention(num_heads=9, key_dim=12, attention_axes=(1))(a3, a3, return_attention_scores=False)\nb = tf.keras.layers.LayerNormalization()(b)\nb2 = tf.keras.layers.Add()([a2, b])\nb3= tf.keras.layers.TimeDistributed(\n        tf.keras.layers.Dense(units*2, activation = 'relu'))(b2)\nc2= tf.compat.v1.keras.layers.CuDNNLSTM(65,return_sequences = True )(b3)\nout = tf.keras.layers.Lambda(lambda x: x[:, -3*12:, :])(c2)\n\nmodel = tf.keras.Model(inputs=Inputs, outputs=out)\n\noptimizer = tf.keras.optimizers.Adam()\nloss = tf.keras.losses.MeanAbsoluteError()\nmodel.compile(optimizer = optimizer, loss = loss, metrics = ['mae'])\nmodel.summary()\nmodel.fit(Xtrain, Ytrain, shuffle = 'True', validation_data = (Xval,Yval),epochs =130, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T14:47:38.640481Z","iopub.execute_input":"2022-03-27T14:47:38.640726Z","iopub.status.idle":"2022-03-27T14:57:47.614385Z","shell.execute_reply.started":"2022-03-27T14:47:38.640698Z","shell.execute_reply":"2022-03-27T14:57:47.613675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots( layout='constrained')\nplt.ylim([0, 0.16])\nax.plot((model.history.history['loss']), label='train')\n\nax.plot((model.history.history['val_loss']), label='val')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:24:09.724687Z","iopub.execute_input":"2022-03-27T13:24:09.725028Z","iopub.status.idle":"2022-03-27T13:24:10.022985Z","shell.execute_reply.started":"2022-03-27T13:24:09.724989Z","shell.execute_reply":"2022-03-27T13:24:10.022331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import matplotlib as mpl\nimport matplotlib.pyplot as plt\n#making predictions on validation set and comparing them too real values\n\n\nYpredval = model.predict(Xval)\nYpredval = sc.inverse_transform(Ypredval[0,:,:])\nYval2 = sc.inverse_transform(Yval[0,:,:])\nTOT = 0\nfor i in range(0,65):\n    tot = abs(Ypredval[:,i] - Yval2[:,i]).sum()/Yval2.shape[0]\n    TOT += tot\n    fig, ax = plt.subplots( layout='constrained')\n    plt.ylim([0, 100])\n    ax.plot((Ypredval[:,i]), label='pred')\n    ax.plot(Yval2[:,i], label='real') \n    print(tot)\nprint(\"total =\" + str(TOT/65))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T14:05:43.484733Z","iopub.execute_input":"2022-03-27T14:05:43.485295Z","iopub.status.idle":"2022-03-27T14:05:58.303821Z","shell.execute_reply.started":"2022-03-27T14:05:43.485256Z","shell.execute_reply":"2022-03-27T14:05:58.303031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import matplotlib as mpl\n#ploting predictions for test\nimport matplotlib.pyplot as plt\n\nXtest = np.reshape(datanorm[-lenseq:,:],(1,lenseq, datanorm.shape[1]))\nYpred = model.predict(Xtest)\nprint(Ypred.shape)\nYpred = sc.inverse_transform(Ypred[0,:,:])\nfor i in range(0,65):\n    fig, ax = plt.subplots( layout='constrained')\n    plt.ylim([0, 100])\n    ax.plot((Ypred[:,i]), label='pred')\n    ax.plot(datamean[:,i], label='mean')  ","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:24:25.226294Z","iopub.execute_input":"2022-03-27T13:24:25.226612Z","iopub.status.idle":"2022-03-27T13:24:38.875909Z","shell.execute_reply.started":"2022-03-27T13:24:25.226574Z","shell.execute_reply":"2022-03-27T13:24:38.875224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Writing predictions in final pandas dataframe\n\n\nimport pandas as pd\nimport numpy as np\ndftest  = pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\n\ndftest2 = dftest.sort_values(['time','direction','x','y'])\nprint(dftest2)\nprint(dftest2.shape)\nYpred2 = np.ravel(Ypred[:36,:])\nprint(Ypred2)\nprint(len(Ypred2))\ndftest2.insert(1, 'congestion', Ypred2)\ndftest2 = dftest2.drop(columns = ['direction','x','y','time'])\nprint(dftest2)\nsubmission = dftest2.sort_values(['row_id'])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:24:38.882837Z","iopub.execute_input":"2022-03-27T13:24:38.883293Z","iopub.status.idle":"2022-03-27T13:24:38.919182Z","shell.execute_reply.started":"2022-03-27T13:24:38.883255Z","shell.execute_reply":"2022-03-27T13:24:38.918434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(submission)\nsubmission['congestion'] = round(submission['congestion'] )\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:24:38.920294Z","iopub.execute_input":"2022-03-27T13:24:38.920524Z","iopub.status.idle":"2022-03-27T13:24:38.928189Z","shell.execute_reply.started":"2022-03-27T13:24:38.920489Z","shell.execute_reply":"2022-03-27T13:24:38.927253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# = pd.DataFrame(Ypred)\nsubmission.to_csv(\"./submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:24:38.929607Z","iopub.execute_input":"2022-03-27T13:24:38.930164Z","iopub.status.idle":"2022-03-27T13:24:38.944978Z","shell.execute_reply.started":"2022-03-27T13:24:38.930127Z","shell.execute_reply":"2022-03-27T13:24:38.944346Z"},"trusted":true},"execution_count":null,"outputs":[]}]}