{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\nIn this notebook I have performed a short analysis of the traffic volumes. I will keep adding content; its work in progress.\n\n   <a id=\"toc\"></a>\n   \n   - [1. EDA - Short Insights](#1)\n   - [2. Local Cross Validation Strategy](#2)\n   - [3. Advanced Central Tendency Approach](#3)\n\n---\n\n<a id=\"1\"></a>\n### **EDA - short insights**","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport pandas as pd\nimport numpy as np\n\nfrom datetime import datetime, time\nimport matplotlib.pyplot as plt\nimport matplotlib \nfrom matplotlib import gridspec\nimport seaborn as sns\nfrom scipy.stats.mstats import gmean, hmean\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# runtime configuration of matplotlib\nplt.style.use(\"Solarize_Light2\")\nplt.rc(\"figure\", \n    autolayout=True, \n    figsize=(20, 10)\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=20,\n    titlepad=10,\n)\n\n# load data\ntrain_raw = pd.read_csv('../input/tabular-playground-series-mar-2022/train.csv', index_col='row_id', parse_dates=['time'])\ntest_raw = pd.read_csv('../input/tabular-playground-series-mar-2022/test.csv', index_col='row_id', parse_dates=['time'])\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T12:43:53.09412Z","iopub.execute_input":"2022-03-10T12:43:53.094441Z","iopub.status.idle":"2022-03-10T12:43:53.880208Z","shell.execute_reply.started":"2022-03-10T12:43:53.09441Z","shell.execute_reply":"2022-03-10T12:43:53.879358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates = [datetime(1991,9,30,0,0,0),train_raw['time'].max(), test_raw['time'].min(), test_raw['time'].max()]\n\nmin_date = datetime(1991,9,29,23,0,0)\nmax_date = datetime(1991,9,30,23,59,0)\n\nlabels = [\"\", 'End train period', 'Start test period', 'End test period']\n# labels with associated dates\nlabels = ['{0:%H:%M}\\n{1}'.format(d, l) for l, d in zip(labels, dates)]\n\nfig, ax = plt.subplots(figsize=(15, 2), constrained_layout=False)\n_ = ax.set_ylim(-2, 1.75)\n_ = ax.set_xlim(min_date, max_date)\n_ = ax.axhline(0, xmin=0.05, xmax=0.95, c='deeppink', zorder=1)\n \n_ = ax.scatter(dates, np.zeros(len(dates)), s=120, c='palevioletred', zorder=2)\n_ = ax.scatter(dates, np.zeros(len(dates)), s=30, c='darkmagenta', zorder=3)\n\nlabel_offsets = np.zeros(len(dates))\nlabel_offsets[::2] = 1\nlabel_offsets[1::2] = -1.5\nfor i, (l, d) in enumerate(zip(labels, dates)):\n    _ = ax.text(d, label_offsets[i], l, ha='center', fontfamily='serif', fontweight='bold', color='black',fontsize=10)\n\nstems = np.zeros(len(dates))\nstems[::2] = 0.9\nstems[1::2] =-0.9  \nmarkerline, stemline, baseline = ax.stem(dates, stems, use_line_collection=True)\n_ = plt.setp(markerline, marker=',', color='darkmagenta')\n_ = plt.setp(stemline, color='darkmagenta')\n\n# hide lines around chart\nfor spine in [\"left\", \"top\", \"right\", \"bottom\"]:\n    _ = ax.spines[spine].set_visible(False)\n \n# hide tick labels\n_ = ax.set_xticks([])\n_ = ax.set_yticks([])\n \n_ = ax.set_title('30 September 1991', fontweight=\"normal\", fontfamily='serif', fontsize=12, color='black');\n","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-10T12:43:17.184648Z","iopub.execute_input":"2022-03-10T12:43:17.184986Z","iopub.status.idle":"2022-03-10T12:43:17.434736Z","shell.execute_reply.started":"2022-03-10T12:43:17.184942Z","shell.execute_reply":"2022-03-10T12:43:17.433903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to extract time components\ndef time_components(df):\n    \n    df_copy = df.copy()\n    \n    df_copy['year'] = df_copy['time'].dt.year\n    df_copy['month'] = df_copy['time'].dt.month\n    df_copy['day'] = df_copy['time'].dt.day\n    df_copy['hour'] = df_copy['time'].dt.hour\n    df_copy['minute'] = df_copy['time'].dt.minute\n    df_copy['weekday'] = df_copy['time'].dt.weekday\n    \n    return df_copy\n\n# Add time components\ntrain = time_components(train_raw)\ntest = time_components(test_raw)\n\n# Prepare data for plot\nweekday = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thur\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\ntrain[\"day_week\"] = train[\"weekday\"].map(weekday)\n\ndf_plot = train.loc[:,[\"day_week\", \"weekday\", \"hour\",\"congestion\"]].groupby([\"day_week\", \"weekday\",\"hour\"]).mean(\"congestion\")\ndf_plot.reset_index([\"day_week\", \"weekday\",\"hour\"], inplace=True)\n\ndf_plot[\"weekday-hour\"] = df_plot[\"day_week\"] + \"-\" + df_plot[\"hour\"].astype(str)\ndf_plot[\"hour\"] = df_plot[\"hour\"].astype(int)\ndf_plot.sort_values(by=[\"weekday\", \"hour\"], inplace=True)\n\n# plot\nfig = plt.figure(constrained_layout=False)\nspec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n\nax1 = fig.add_subplot(spec[0, 0])\nsns.countplot(y=\"direction\", ax=ax1, data=train);\nax1.set(xlabel=\"Number of rides\", ylabel = \"\")\nax1.set_title('Destinations');\n\nax2 = fig.add_subplot(spec[0, 1])\nsns.histplot(x=\"congestion\", ax=ax2, data=train, palette=['r' if con in [15, 20, 21, 29, 34] else '#ffd700' for con in range(101)]);\nax2.set(xlabel=\"Congestion values\", ylabel = \"\")\nax2.set_title('Congestion Histogram');\n\nax3 = fig.add_subplot(spec[1,:])\nsns.lineplot(x=\"weekday-hour\", y=\"congestion\", data=df_plot, color=\"g\")\n\ndays = [\"Mon-0\", \"Tue-0\", \"Wed-0\", \"Thur-0\", \"Fri-0\", \"Sat-0\", \"Sun-0\"]\nweekdays = [\"Monday\", \"Tuesday\", \"Wendsday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n\nfor day, weekday in zip(days, weekdays):\n    plt.axvline(x = day, color = 'k', alpha=0.3)\n    ax3.text(day, 56, weekday, fontsize=12, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\n\nax3.set_xlim(-1, \"Sun-23\");\nax3.xaxis.set_ticks([\"Mon-8\",\"Mon-16\", \"Tue-8\",\"Tue-17\", \"Wed-8\",\"Wed-17\", \"Thur-8\", \"Thur-17\", \"Fri-8\",\"Fri-17\", \"Sat-15\", \"Sun-14\"])\nax3.set_xticklabels([\"8.00 AM\", \"16.00 PM\", \"8.00 AM\",\"17.00 PM\", \"8.00 AM\",\"17.00 PM\", \"8.00 AM\",\"17.00 PM\",\"8.00 AM\", \"17.00 PM\",\"15.00 PM\", \"14.00 PM\"])\nax3.set_title('Hourly Congestion Level')\nax3.set(ylabel=\"Average congestion\", xlabel=None)\n\nplt.setp(ax3.get_xticklabels(), rotation=0, weight='bold');","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-10T12:43:17.436329Z","iopub.execute_input":"2022-03-10T12:43:17.436842Z","iopub.status.idle":"2022-03-10T12:43:20.913213Z","shell.execute_reply.started":"2022-03-10T12:43:17.436793Z","shell.execute_reply":"2022-03-10T12:43:20.912285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Takeaways**\n    - The second plot has some interessting observations at `[15, 20, 21, 29, 34]`. We have to dig deeper here to understand why these congestion levels are overrepresented. When useing Random Forest one must adjust for this with `sample_weight` parameter while fitting. I will get back to this at a later moment.\n    - The third plotgrab details normal traffic congestion pattern on a daily basis, for each hour of the day. Travel times are seen to peak around 8.00 AM and 17.00 PM.\n    - In the second plot we can see that there are `0` congestion observations which is overrepresented compared to `1, 2, 3,...` congestion levels. Could this be road closures for example? We have to dig in to the data and see what is happening. \n\n---","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n\n### **Local Cross Validation Strategy**\n\nThe second step after EDA in every Kaggle competition is to build a reliable local validation strategy. With reliable I mean a `local CV` score that correlates with `LB` score. Because then we can use our local CV score to evaluate experiments or to tune (hyper)parameters. There are two question that I usually try to answer. \n\n1. How to split the data in `train` and `validation` (there are a lot of different strategies) and \n2. Once a strategy is chosen does `LB` score moves in the direction of `local CV` score? If the answer is yes then probably the relationship between your local folds is the same relationship between Kaggle's train and test. If not, try other CV strategy and if you cannot find a reliable `local CV` then is it probably time to stop taking part in the competition because at the end you might be highly disappointed after the final shake-up. \n    \n\nFor this competition I have the following CV strategy:\n    \n - *Train/Validation split* : All `Mondays` from`12 noon` until `12 midnight` are selected as training data. September 2 which is Labour Day is excluded from analysis because it had a negative impact on the performance. Mondays for the month of September are used as `3 validation` folds and the rest of the mondays are used as training data.\n - *Local CV and LB agreement*: See next section where **Advanced Central Tendency Approach** is applied to predict congestion.","metadata":{}},{"cell_type":"code","source":"#\ntrain_monday = train.loc[(train[\"weekday\"]==0) & (train[\"hour\"]>=12),:]\ntrain_monday[\"date\"] = train_monday[\"time\"].dt.date\n\nmean_train_monday = train_monday[[\"time\", \"congestion\"]].groupby([\"time\"]).mean(\"congestion\")\nmean_train_monday.reset_index(inplace=True)\nmean_train_monday = time_components(mean_train_monday)\n\nmean_train_monday[\"weekday_hour\"] = mean_train_monday[\"month\"].astype(str) + \"-\" + mean_train_monday[\"day\"].astype(str) + \" \" \\\n    + mean_train_monday[\"hour\"].astype(str)+ \":\" + mean_train_monday[\"minute\"].astype(str)\nmean_train_monday.sort_values(by=[\"time\"], inplace=True)\n\nfrom matplotlib.ticker import (MultipleLocator, FormatStrFormatter,AutoMinorLocator)\nfig = plt.figure(constrained_layout=False)\nspec = gridspec.GridSpec(ncols=1, nrows=2, figure=fig)\n\n\nax1 = fig.add_subplot(spec[0,0])\nsns.scatterplot(x=\"weekday_hour\", y=\"congestion\", data=mean_train_monday, color=\"g\")\n\nmondays = [\"4-1 12:0\",\"5-6 12:0\",\"6-3 12:0\",\"7-1 12:0\",\"8-5 12:0\",\"9-2 12:0\"]\nmonths = [\"April\", \"May\", \"June\", \"July\", \"August\", \"September\"]\nxticklabels = [\"April-1\", \"May-6\", \"June-3\", \"July-1\", \"August-5\", \"September-2\"]\n\nax1.xaxis.set_ticks(mondays)\nax1.set_xticklabels(xticklabels)\n\nax1.set_xlim(\"4-1 12:0\", \"9-30 12:0\")\n\n\nfor monday, month in zip(mondays, months):\n    plt.axvline(x = monday, color = 'k', alpha=0.3)\n    ax1.text(monday, 61, month, fontsize=12, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\n    \nplt.setp(ax1.get_xticklabels(), rotation=45, weight='bold');\n\nfig.patches.extend([plt.Rectangle((0.845,0.545),0.04,0.15,\n                                  fill=True, color='r', alpha=0.2, zorder=1000,\n                                  transform=fig.transFigure, figure=fig)])\nax1.annotate(\"Labour Day\", (\"9-2 12:0\", 43), (\"8-19 12:0\", 40) , arrowprops={\"arrowstyle\": \"simple\"},\\\n    fontproperties=\"cursive\", fontsize=15)\n\nfig.patches.extend([plt.Rectangle((0.3259,0.545),0.04,0.265,\n                                  fill=True, color='r', alpha=0.2, zorder=1000,\n                                  transform=fig.transFigure, figure=fig)])\nax1.annotate(\"Memorial Day\", (\"6-3 12:0\", 43), (\"6-10 12:0\", 40) , arrowprops={\"arrowstyle\": \"simple\"},\\\n     fontproperties=\"cursive\", fontsize=15)\n\nax1.set_title('Monday Congestion (Hourly-Minute)')\nax1.set(ylabel=\"Mean congestion\", xlabel=None);","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-10T12:43:20.916248Z","iopub.execute_input":"2022-03-10T12:43:20.91658Z","iopub.status.idle":"2022-03-10T12:43:22.755043Z","shell.execute_reply.started":"2022-03-10T12:43:20.916541Z","shell.execute_reply":"2022-03-10T12:43:22.753919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Takeaways\n    - Month of `August` has the highst congestion level and it looks pretty consistent for all of the mondays of this month.\n    - First monday of `September` is `Labour Day` that is why congestion level is significantly low.\n    - For the month of `May` the last monday is `Memorial Day` that is why congestion levels are relatively low.\n    - My general observation is that congestion level are more or less the same for the mondays within the same month, excluding holidays of course.","metadata":{}},{"cell_type":"markdown","source":"---\n<a id=\"3\"></a>\n\n### **Advanced Central Tendency Approach**\n\nIn this section I would like to see how the central tendency approaches like `geometric mean`,,`harmonic mean`, `arithmetic mean`, `median` and `mode` performs. I validate my results with the afternoon `congestion` level for `9, 16` and `23 September`.  `Labour Day` is removed and the performance increased. I also removed `Memorial Day` but that did not improve the performance. So, after calculating the above mentioned approaches I also took the linear ensemble of some of the approaches. The coefficients were calculated with the help of linear regression.","metadata":{}},{"cell_type":"code","source":"train = time_components(train_raw)\ntest = time_components(test_raw)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:43:22.756604Z","iopub.execute_input":"2022-03-10T12:43:22.756828Z","iopub.status.idle":"2022-03-10T12:43:23.284627Z","shell.execute_reply.started":"2022-03-10T12:43:22.756801Z","shell.execute_reply":"2022-03-10T12:43:23.283559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\nfrom scipy.stats.mstats import gmean\n\ntrain_monday = train.loc[(train[\"weekday\"]==0) & (train[\"hour\"]>=12),:]\ntrain_monday[\"date\"] = train_monday[\"time\"].dt.date\n\ntrain_period = [day for day in list(train_monday['date'].unique()) if (day.month!=9)]\nval_period = [day for day in list(train_monday['date'].unique()) if (day.month==9 and day.day!=2)]\n\ntrain_X = train_monday.loc[train_monday['date'].isin(train_period),:]\ntrain_X = train_X.loc[(train_X[\"congestion\"]>=0) & (train_X[\"congestion\"]<=100),:]\n\ntrain_val = train_monday.loc[train_monday['date'].isin(val_period),:]\n\n# Compute the median congestion for every place and time of week    \nmedian = pd.DataFrame(train_X.groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.median())\nmean = pd.DataFrame(train_X.loc[train_X[\"congestion\"]>0,:].groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.mean())\nh_mean = pd.DataFrame(train_X.loc[train_X[\"congestion\"]>0,:].groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.apply(hmean))\ng_mean = pd.DataFrame(train_X.loc[train_X[\"congestion\"]>0,:].groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.apply(gmean))\nmode = train_X.groupby(['x', 'y', 'direction', 'hour', 'minute'])['congestion'].agg(lambda x:x.value_counts().index[0])\n\ncentral_measures = median.merge(h_mean, how=\"left\", left_index=True, right_index=True)\ncentral_measures = central_measures.merge(g_mean, how=\"left\", left_index=True, right_index=True)\ncentral_measures = central_measures.merge(mean, how=\"left\", left_index=True, right_index=True)\ncentral_measures = central_measures.merge(mode, how=\"left\", left_index=True, right_index=True)\n\ncentral_measures.columns = [\"median\", \"h_mean\",\"g_mean\", \"mean\", \"mode\"]\n\n# train set error performance\ntrain_score = train_X.merge(central_measures, how=\"left\", \\\nleft_on=['x', 'y', 'direction', 'hour', 'minute'], right_on=['x', 'y', 'direction', 'hour', 'minute'])\ntrain_score[\"median_mae\"] = np.abs(train_score[\"congestion\"] - train_score[\"median\"])\ntrain_score[\"g_mean_mae\"] = np.abs(train_score[\"congestion\"] - train_score[\"g_mean\"])\ntrain_score[\"h_mean_mae\"] = np.abs(train_score[\"congestion\"] - train_score[\"h_mean\"])\ntrain_score[\"mean_mae\"] = np.abs(train_score[\"congestion\"] - train_score[\"mean\"])\ntrain_score[\"mode_mae\"] = np.abs(train_score[\"congestion\"] - train_score[\"mode\"])\n\nfrom sklearn import linear_model\n\nX = train_score[[\"median\", \"g_mean\"]]\ny = train_score[\"congestion\"]\n\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X,y)\npredictions = lm.predict(X)\nprint(f'Median linear weight:{np.round(lm.coef_[0],4)}\\n')\nprint(f'Geometric Mean linear weight:{np.round(lm.coef_[1],4)}\\n')\n\ntrain_score[\"ensemble\"] =lm.coef_[0]*train_score[\"median\"] + lm.coef_[1]*train_score[\"g_mean\"]\ntrain_score[\"ensemble_mae\"] = np.abs(train_score[\"congestion\"] - train_score[\"ensemble\"])\n\n# validation performance\nval_score = train_val.merge(central_measures, how=\"left\", \\\nleft_on=['x', 'y', 'direction', 'hour', 'minute'], right_on=['x', 'y', 'direction', 'hour', 'minute'])\nval_score[\"median_mae\"] = np.abs(val_score[\"congestion\"] - val_score[\"median\"])\nval_score[\"g_mean_mae\"] = np.abs(val_score[\"congestion\"] - val_score[\"g_mean\"])\nval_score[\"h_mean_mae\"] = np.abs(val_score[\"congestion\"] - val_score[\"h_mean\"])\nval_score[\"mean_mae\"] = np.abs(val_score[\"congestion\"] - val_score[\"mean\"])\nval_score[\"mode_mae\"] = np.abs(val_score[\"congestion\"] - val_score[\"mode\"])\n\nval_score[\"ensemble\"] =lm.coef_[0]*val_score[\"median\"] + lm.coef_[1]*val_score[\"g_mean\"]\nval_score[\"ensemble_mae\"] = np.abs(val_score[\"congestion\"] - val_score[\"ensemble\"])\nval_score[[\"date\", \"median_mae\", \"g_mean_mae\", \"h_mean_mae\", \"mean_mae\", \"mode_mae\", \"ensemble_mae\"]].groupby([\"date\"]).mean()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T13:01:16.244069Z","iopub.execute_input":"2022-03-10T13:01:16.244395Z","iopub.status.idle":"2022-03-10T13:01:17.455981Z","shell.execute_reply.started":"2022-03-10T13:01:16.244361Z","shell.execute_reply":"2022-03-10T13:01:17.453386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n* **Takeaways**\n    - `Geometric` and `harmonic` means outperforms other approaches.\n    - The ensemble of the `median` and `geometric mean` gives the best `local CV` and `LB` performance.\n    - The `geometric mean` approach scored `4.967` on the public LB and `ensemble` scored `4.940` which is inline with the local CV. \n---\n\n*Stay tuned for:*\n\n- Error Analysis of Central Tendency Approach\n- Tree Based application\n- Analysis of `0` congestion\n- ...","metadata":{}},{"cell_type":"markdown","source":"---\n### Submission","metadata":{}},{"cell_type":"code","source":"train_monday = train.loc[(train[\"weekday\"]==0) & (train[\"hour\"]>=12),:]\ntrain_monday[\"date\"] = train_monday[\"time\"].dt.date\n\ntrain_period = [day for day in list(train_monday['date'].unique()) if (day.month!=2)]\n\ntrain_X = train_monday.loc[train_monday['date'].isin(train_period),:]\ntrain_X = train_X.loc[(train_X[\"congestion\"]>=0) & (train_X[\"congestion\"]<=100),:]\n\n# Compute the median congestion for every place and time of week    \nmedian = pd.DataFrame(train_X.groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.median())\nmean = pd.DataFrame(train_X.loc[train_X[\"congestion\"]>0,:].groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.mean())\nh_mean = pd.DataFrame(train_X.loc[train_X[\"congestion\"]>0,:].groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.apply(hmean))\ng_mean = pd.DataFrame(train_X.loc[train_X[\"congestion\"]>0,:].groupby(['x', 'y', 'direction', 'hour', 'minute']).congestion.apply(gmean))\nmode = train_X.groupby(['x', 'y', 'direction', 'hour', 'minute'])['congestion'].agg(lambda x:x.value_counts().index[0])\n\ncentral_measures = median.merge(h_mean, how=\"left\", left_index=True, right_index=True)\ncentral_measures = central_measures.merge(g_mean, how=\"left\", left_index=True, right_index=True)\ncentral_measures = central_measures.merge(mean, how=\"left\", left_index=True, right_index=True)\ncentral_measures = central_measures.merge(mode, how=\"left\", left_index=True, right_index=True)\n\ncentral_measures.columns = [\"median\", \"h_mean\",\"g_mean\", \"mean\", \"mode\"]\n\ndf_score = train_X.merge(central_measures, how=\"left\", \\\nleft_on=['x', 'y', 'direction', 'hour', 'minute'], right_on=['x', 'y', 'direction', 'hour', 'minute'])\ndf_score[\"median_mae\"] = np.abs(df_score[\"congestion\"] - df_score[\"median\"])\ndf_score[\"g_mean_mae\"] = np.abs(df_score[\"congestion\"] - df_score[\"g_mean\"])\ndf_score[\"h_mean_mae\"] = np.abs(df_score[\"congestion\"] - df_score[\"h_mean\"])\ndf_score[\"mean_mae\"] = np.abs(df_score[\"congestion\"] - df_score[\"mean\"])\ndf_score[\"mean_mode\"] = np.abs(df_score[\"congestion\"] - df_score[\"mode\"])\n\n\n## Without a constant\nfrom sklearn import linear_model\n\nX = df_score[[\"median\", \"g_mean\"]]\ny = df_score[\"congestion\"]\n\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X,y)\npredictions = lm.predict(X)\n\ndf_score[\"ensemble\"] =lm.coef_[0]*df_score[\"median\"] + lm.coef_[1]*df_score[\"g_mean\"]\ndf_score[\"ensemble_mae\"] = np.abs(df_score[\"congestion\"] - df_score[\"ensemble\"])\n\ntest = time_components(test_raw)\ntest.reset_index(\"row_id\", inplace=True)\n\nsubmission = df_score[['x', 'y', 'direction' ,'hour','minute','g_mean', 'h_mean',\"median\",\"mean\", \"ensemble\"]].groupby(['x', 'y', 'direction' ,'hour', 'minute']).mean([\"g_mean\",\"h_mean\",\"median\",\"mean\", \"ensemble\"])\nsubmission.reset_index(inplace=True)\n\nsubmission = test.merge(submission, how=\"left\", \\\nleft_on=['x', 'y', 'direction', 'hour', 'minute'], right_on=['x', 'y', 'direction', 'hour', 'minute'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T13:08:41.567028Z","iopub.execute_input":"2022-03-10T13:08:41.567581Z","iopub.status.idle":"2022-03-10T13:08:42.752444Z","shell.execute_reply.started":"2022-03-10T13:08:41.567543Z","shell.execute_reply":"2022-03-10T13:08:42.750917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,1, figsize=(16,5))\n\naxes.hist(train.congestion[((train.time.dt.weekday == 0) & (train.time.dt.hour >= 12)).values],\n         bins=np.linspace(-0.5, 100.5, 102), density=True, label='Train', color='b')\n\naxes.hist(submission['ensemble'], np.linspace(-0.5, 100.5, 102),\n         density=True, rwidth=0.5, label='Test predictions', color='r')\naxes.legend()\naxes.set_title(\"Ensemble (Geometric Mean & Median)\", fontsize=12, fontproperties=\"italic\")\naxes.set_ylabel('Density', fontproperties=\"italic\")\naxes.set_xlabel('Congestion', fontproperties=\"italic\")\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T13:15:47.459441Z","iopub.execute_input":"2022-03-10T13:15:47.460274Z","iopub.status.idle":"2022-03-10T13:15:48.686446Z","shell.execute_reply.started":"2022-03-10T13:15:47.460232Z","shell.execute_reply":"2022-03-10T13:15:48.685416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = submission[['row_id','ensemble']]\nsubmission.columns = [\"row_id\", \"congestion\"]\nsubmission.set_index(\"row_id\", inplace=True)\nsubmission['congestion'] = submission['congestion'].round().astype(int)\nsubmission.to_csv(\"submission.csv\", index=True)\n\nsubmission.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T13:07:54.900099Z","iopub.execute_input":"2022-03-10T13:07:54.900395Z","iopub.status.idle":"2022-03-10T13:07:54.926135Z","shell.execute_reply.started":"2022-03-10T13:07:54.900367Z","shell.execute_reply":"2022-03-10T13:07:54.925466Z"},"trusted":true},"execution_count":null,"outputs":[]}]}