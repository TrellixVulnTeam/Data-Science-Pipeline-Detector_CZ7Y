{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task\nfrom lightautoml.report.report_deco import ReportDeco\nimport seaborn as sns\nimport lightgbm as ltb\nfrom xgboost import XGBRegressor\n!pip install -U lightautoml","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/tabular-playground-series-mar-2022/train.csv\",parse_dates=True)\ntest=pd.read_csv(\"../input/tabular-playground-series-mar-2022/test.csv\")\nsub=pd.read_csv(\"../input/tabular-playground-series-mar-2022/sample_submission.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.time=df.time.astype('str')\ntest.time=df.time.astype('str')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce Memory usage","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)  \n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\nreduce_mem_usage(df)\nreduce_mem_usage(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting time column to Date_time","metadata":{}},{"cell_type":"code","source":"df['time'] = pd.to_datetime(df['time'])\ntest['time'] = pd.to_datetime(test['time'])\npt_df=df.copy()\npt_test=test.copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def features_new(data):\n    data['month'] = data['time'].dt.month\n    data['weekday'] = data['time'].dt.weekday\n    data['hour'] = data['time'].dt.hour\n    data['minute'] = data['time'].dt.minute\n    data['is_month_start'] = data['time'].dt.is_month_start.astype('int')\n    data['is_month_end'] = data['time'].dt.is_month_end.astype('int')\n    data['hour+minute'] = data['time'].dt.hour * 60 + data['time'].dt.minute\n    data['is_weekend'] = (data['time'].dt.dayofweek > 4).astype('int')\n    data['is_afternoon'] = (data['time'].dt.hour > 12).astype('int')\n    data['x+y'] = data['x'].astype('str') + data['y'].astype('str')\n    data['x+y+direction'] = data['x'].astype('str') + data['y'].astype('str') + data['direction'].astype('str')\n    data['hour+direction'] = data['hour'].astype('str') + data['direction'].astype('str')\n    data['hour+x+y'] = data['hour'].astype('str') + data['x'].astype('str') + data['y'].astype('str')\n    data['hour+direction+x'] = data['hour'].astype('str') + data['direction'].astype('str') + data['x'].astype('str')\n    data['hour+direction+y'] = data['hour'].astype('str') + data['direction'].astype('str') + data['y'].astype('str')\n    data['hour+direction+x+y'] = data['hour'].astype('str') + data['direction'].astype('str') + data['x'].astype('str') + data['y'].astype('str')\n    data['hour+x'] = data['hour'].astype('str') + data['x'].astype('str')\n    data['hour+y'] = data['hour'].astype('str') + data['y'].astype('str')\n    data.direction=data.direction.astype(str)\nfeatures_new(df)\nfeatures_new(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding weekend ⛪🏡 *Saturday* and *Sunday* as features","metadata":{}},{"cell_type":"code","source":"\ndf['sunday'] = np.where(df['weekday']==6,1, 0)\ndf['saturday'] = np.where(df['weekday']==5,1, 0)\n\ntest['sunday'] = np.where(test['weekday']==6,1, 0)\ntest['saturday'] = np.where(test['weekday']==5,1, 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Bar chart for congestion🚗🚙🚔\n* It can be observed from plot that some values have higher congestion than their neighbouring values.\n    * Values with traffic **🚗🚗🚙** **congestion=15,20,21,29,34** has much higher count than its neighbours.    ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 6))\nplt.bar(range(101), pt_df.congestion.value_counts().sort_index(), width=1,\n        color=['gold' if con in [15, 20, 21, 29, 34] else 'coral' for con in range(101)])\nplt.title(\"Congestion count plot\")\nplt.xlabel(\"Congestion\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dependence of congestion 🚗🚙 on time of day\n* Maximum traffic congestion is at 5:00 P.M\n* Minimum traffic congestion is at 4:00 A.M","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(18, 6))\nplt.bar(pt_df.groupby(pt_df.time.dt.hour).congestion.mean().index,pt_df.groupby(df.time.dt.hour).congestion.mean(),color=\"coral\")\nplt.xticks(range(24))\nplt.ylabel(\"congestion\")\nplt.title(\"Congestion on time\")\nplt.show()","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traffic 🚗🚙 Congestion on Date","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18, 6))\nplt.bar(df.groupby(pt_df.time.dt.date).congestion.mean().index,pt_df.groupby(pt_df.time.dt.date).congestion.mean(),color=\"coral\")\nplt.ylabel(\"congestion\")\nplt.title(\"Congestion on date\")\nplt.ylim(40, 52)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traffic 🚗🚙 Congestion on day of week\n* It is observed that congestion is less on weekend.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18, 6))\nplt.bar(pt_df.groupby(pt_df.time.dt.dayofweek).congestion.mean().index,pt_df.groupby(pt_df.time.dt.dayofweek).congestion.mean(),color=\"coral\")\nplt.xticks(range(7))\nplt.ylabel(\"congestion\")\nplt.title(\"Congestion on day of week\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn import preprocessing\n# cat=[col for col in df.columns if df[col].dtype==\"object\"]\n# encoder = preprocessing.LabelEncoder()\n# for i in cat:\n#     encoder = preprocessing.LabelEncoder()\n#     df[i] = encoder.fit_transform(df[i])\n#     test[i] = encoder.transform(test[i])\n#     print(i,\"==> unique\",df[i].nunique())","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import OneHotEncoder\n# cat=[col for col in df.columns if df[col].dtype==\"object\"]\n# OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n# train = pd.DataFrame(OH_encoder.fit_transform(df[cat]),columns=list(OH_encoder.get_feature_names()))\n# en_test = pd.DataFrame(OH_encoder.transform(test[cat]),columns=list(OH_encoder.get_feature_names()))\n# # One-hot encoding removed index; put it back\n# train.index = df.index\n# en_test.index = test.index\n# df=df.drop(cat,axis=1)\n# test=test.drop(cat,axis=1)\n# df=pd.concat([df,train],axis=1)\n# test=pd.concat([test,en_test],axis=1)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Useful Feats","metadata":{}},{"cell_type":"code","source":"feats=[col for col in df.columns if col not in [\"row_id\",\"congestion\",\"time\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Light-AUTO ML","metadata":{}},{"cell_type":"code","source":"import time\nnp.random.seed(2022)\ntorch.set_num_threads(4)\nTARGET_NAME = 'congestion'\ntask = Task('reg', metric='mae', loss='mae')\nroles = {'target': TARGET_NAME,\n         'drop': ['row_id']\n         }\n%time \nautoml = TabularAutoML(task = task,\n                       timeout = 8*3600,\n                       cpu_limit = 4,\n                       reader_params = {'n_jobs': 4, 'random_state': 2022},\n                       general_params = {'use_algos': [['lgb']]}\n                      )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_pred = automl.fit_predict(df, roles = roles, verbose=1)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"%%time\n\nfast_fi = automl.get_feature_scores('fast')\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize=(20, 10), grid=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"%%time\ntest_pred = automl.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub[TARGET_NAME] = test_pred.data[:, 0].round()\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}