{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Before","metadata":{}},{"cell_type":"code","source":"# imports \nimport numpy as np\nimport pandas as pd \nimport random,os\n\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom catboost import CatBoostRegressor\n\nTRAIN_PATH = \"../input/tabular-playground-series-mar-2022/train.csv\"\nTEST_PATH = \"../input/tabular-playground-series-mar-2022/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"../input/tabular-playground-series-mar-2022/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"row_id\"\nTARGET = \"congestion\"\nTIME = \"time\"\n\nSEED = 2022\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything()\n\nMODEL_MAX_DEPTH = 12\nMODEL_TASK_TYPE = 'GPU'\nMODEL_RL = 0.035\nMODEL_EVAL_METRIC ='MAE'\nMODEL_LOSS_FUNCTION = 'MAE'\nMODEL_ESR = 10\nMODEL_VERBOSE = 100\nMODEL_ITERATIONS = 30000","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-04T02:09:06.977407Z","iopub.execute_input":"2022-03-04T02:09:06.977937Z","iopub.status.idle":"2022-03-04T02:09:06.986616Z","shell.execute_reply.started":"2022-03-04T02:09:06.977899Z","shell.execute_reply":"2022-03-04T02:09:06.985726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(TRAIN_PATH,parse_dates=[TIME])\ntest = pd.read_csv(TEST_PATH,parse_dates=[TIME])\n\ndef addTimeFeature(df,time_col):\n    df['weekday'] = df[time_col].dt.weekday\n    df['hour'] = df[time_col].dt.hour\n    df['minute'] = df[time_col].dt.minute \n    \n    df = df.drop([time_col],axis=1)\n    \n    return df\n\ntrain = addTimeFeature(train,TIME)\ntest = addTimeFeature(test,TIME)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:09:06.988826Z","iopub.execute_input":"2022-03-04T02:09:06.989606Z","iopub.status.idle":"2022-03-04T02:09:07.856296Z","shell.execute_reply.started":"2022-03-04T02:09:06.989569Z","shell.execute_reply":"2022-03-04T02:09:07.855588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].median()\n            else:\n                df.loc[df[col].isnull() == True,col] = \"Missing\"\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_col = []\nfor col in train.columns:\n    if train[col].dtypes != \"object\" and col != TARGET and col != ID:\n        num_col.append(col)\n        \nscaler = StandardScaler()\ntrain[num_col] = scaler.fit_transform(train[num_col])\ntest[num_col] = scaler.transform(test[num_col])","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:09:07.952569Z","iopub.execute_input":"2022-03-04T02:09:07.953241Z","iopub.status.idle":"2022-03-04T02:09:08.064735Z","shell.execute_reply.started":"2022-03-04T02:09:07.953205Z","shell.execute_reply":"2022-03-04T02:09:08.063609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \nfor col in str_list:\n    encoder = LabelEncoder()\n    encoder.fit(train[col])\n    train[col] = encoder.transform(train[col])\n\n    for label in np.unique(test[col]):\n        if label not in encoder.classes_: \n            encoder.classes_ = np.append(encoder.classes_, label) \n    test[col] = encoder.transform(test[col])","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:09:08.066341Z","iopub.execute_input":"2022-03-04T02:09:08.066752Z","iopub.status.idle":"2022-03-04T02:09:08.300104Z","shell.execute_reply.started":"2022-03-04T02:09:08.066715Z","shell.execute_reply":"2022-03-04T02:09:08.299421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build","metadata":{}},{"cell_type":"code","source":"X = train.drop([ID,TARGET],axis =1)\ny = train[TARGET]\n\nmodel = CatBoostRegressor(\n    verbose=MODEL_VERBOSE,\n    early_stopping_rounds=MODEL_ESR,\n    random_seed=SEED,\n    max_depth=MODEL_MAX_DEPTH,\n    task_type=MODEL_TASK_TYPE,\n    learning_rate=MODEL_RL,\n    iterations=MODEL_ITERATIONS,\n    loss_function=MODEL_LOSS_FUNCTION,\n    eval_metric= MODEL_EVAL_METRIC\n)\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:09:08.303027Z","iopub.execute_input":"2022-03-04T02:09:08.303229Z","iopub.status.idle":"2022-03-04T02:09:56.636132Z","shell.execute_reply.started":"2022-03-04T02:09:08.303204Z","shell.execute_reply":"2022-03-04T02:09:56.635552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After","metadata":{}},{"cell_type":"code","source":"X_test = test.drop([ID],axis=1)\npred_test = model.predict(X_test)\n\nsub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = pred_test\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:09:56.639629Z","iopub.execute_input":"2022-03-04T02:09:56.64133Z","iopub.status.idle":"2022-03-04T02:09:56.72774Z","shell.execute_reply.started":"2022-03-04T02:09:56.641295Z","shell.execute_reply":"2022-03-04T02:09:56.727189Z"},"trusted":true},"execution_count":null,"outputs":[]}]}