{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#xgboost code from here https://www.kaggle.com/misfyre/grupo-bimbo-inventory-demand/simple-xgboost/code\n#less memory code from here https://www.kaggle.com/ericcouto/grupo-bimbo-inventory-demand/using-82-less-memory\n\nimport numpy as np\nimport pandas as pd\nimport math\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\nfrom ml_metrics import rmsle\n\n# Full table:   6.1Gb\n# This version: 1.1Gb (-82%)\ntypes = {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,\n         'Ruta_SAK':np.uint16, 'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,\n         'Demanda_uni_equil':np.uint32}\n\ntrain = pd.read_csv('../input/train.csv', usecols=types.keys(), dtype=types,nrows = 7000000)\nprint(train.info(memory_usage=True))\n\n\nprint ('')\nprint ('Loading Data')\n\ndef evalerror(preds, dtrain):\n\n    labels = dtrain.get_label()\n    assert len(preds) == len(labels)\n    labels = labels.tolist()\n    preds = preds.tolist()\n    terms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0,preds[i]) + 1)) ** 2.0 for i,pred in enumerate(labels)]\n    return 'error', (sum(terms_to_sum) * (1.0/len(preds))) ** 0.5\n\ntesttypes = {'id':np.uint16, 'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,\n         'Ruta_SAK':np.uint16, 'Cliente_ID':np.uint32, 'Producto_ID':np.uint16}\n\ntest = pd.read_csv('../input/test.csv', usecols=testtypes.keys(), dtype=testtypes)\nprint(test.info(memory_usage=True))\n\nprint ('')\nprint ('Training_Shape:', train.shape)\n\nprint ('')\nprint ('Testing_Shape:', test.shape)\n\nids = test['id']\ntest = test.drop(['id'],axis = 1)\n\nprint(type(train))\nprint(type(test))\n\ny = train['Demanda_uni_equil']\nX = train[test.columns.values]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)\n\nprint ('Division_Set_Shapes:', X.shape, y.shape)\nprint ('Validation_Set_Shapes:', X_train.shape, X_test.shape)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"params = {}\nparams['objective'] = \"reg:linear\"\nparams['eta'] = 0.025\nparams['max_depth'] = 5\nparams['subsample'] = 0.8\nparams['colsample_bytree'] = 0.6\nparams['silent'] = True\n\nprint ('')\nprint ('Constructing matrix')\n\ntest_preds = np.zeros(test.shape[0])\nxg_train = xgb.DMatrix(X_train, label=y_train)\nxg_test = xgb.DMatrix(X_test)\n\nwatchlist = [(xg_train, 'train')]\nnum_rounds = 20\n\nprint ('')\nprint ('Training the classifier')\n\nxgclassifier = xgb.train(params, xg_train, num_rounds, watchlist, feval = evalerror, early_stopping_rounds= 20, verbose_eval = 1)\npreds = xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration)\n\nprint ('RMSLE Score:', rmsle(y_test, preds))\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print ('')\nprint ('Making predictions')\n\nfxg_test = xgb.DMatrix(test)\n#fxg_test = test.as_matrix()\nfold_preds = np.around(xgclassifier.predict(fxg_test, ntree_limit=xgclassifier.best_iteration), decimals = 1)\ntest_preds += fold_preds\n\nsubmission = pd.DataFrame({'id':ids, 'Demanda_uni_equil': test_preds})\nsubmission.to_csv('submission.csv', index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}