{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import random\n\ndef random_sampler(filename, k):\n    sample = []\n    with open(filename, 'rb') as f:\n        f.seek(0, 2)\n        filesize = f.tell()\n        \n        random_set = sorted(random.sample(range(filesize), k))\n       \n        for i in range(k):\n            f.seek(random_set[i])\n            # Skip current line (because we might be in the middle of a line) \n            f.readline()\n            # Append the next line to the sample set \n            sample.append(f.readline().rstrip())\n\n    return sample"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"TRAIN_SAMPLES = 5*10**6\ntrain_sample = random_sampler('../input/train.csv', TRAIN_SAMPLES)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_sample[0].decode().split(',')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_sample_ = [row.decode().split(\",\") for row in train_sample]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.DataFrame(train_sample_)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"del train_sample\ndel train_sample_"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv', nrows=1)\ntrain.columns = train_df.columns"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = train.apply(pd.to_numeric)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.info()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train['Demanda_uni_equil'] = np.log1p(train['Demanda_uni_equil'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"x_cols = train.columns\nx_cols = x_cols.drop(['Venta_uni_hoy', 'Venta_hoy', 'Dev_uni_proxima', 'Dev_proxima', 'Demanda_uni_equil'])\nprint(x_cols)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"model.fit(train[x_cols], train['Demanda_uni_equil'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test = pd.read_csv('../input/test.csv')\ntest.info()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test['Demanda_uni_equil'] = np.expm1(model.predict(test[x_cols]))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test[['id', 'Demanda_uni_equil']].to_csv('predictions_rf_random_sampling.csv', index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}