{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom IPython.display import display_markdown as mkdown # as print\n\ndef nl():\n    print('\\n')\n\nfor f in os.listdir('../input'):\n    print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# copy from: https://www.kaggle.com/vykhand/grupo-bimbo-inventory-demand/exploring-products"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"products  =  pd.read_csv(\"../input/producto_tabla.csv\")\nproducts  =  pd.read_csv(\"../input/producto_tabla.csv\")\nproducts['short_name'] = products.NombreProducto.str.extract('^(\\D*)', expand=False)\nproducts['brand'] = products.NombreProducto.str.extract('^.+\\s(\\D+) \\d+$', expand=False)\nw = products.NombreProducto.str.extract('(\\d+)(Kg|g)', expand=True)\nproducts['weight'] = w[0].astype('float')*w[1].map({'Kg':1000, 'g':1})\nproducts['pieces'] =  products.NombreProducto.str.extract('(\\d+)p ', expand=False).astype('float')\nproducts.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def lstm_model(time_steps, rnn_layers, dense_layers=None):\n  \"\"\"\n  Creates a deep model based on:\n      * stacked lstm cells\n      * an optional dense layers\n  :param time_steps: the number of time steps the model will be looking at.\n  :param rnn_layers: list of int or dict\n                       * list of int: the steps used to instantiate the `BasicLSTMCell` cell\n                       * list of dict: [{steps: int, keep_prob: int}, ...]\n  :param dense_layers: list of nodes for each layer\n  :return: the model definition\n  \"\"\"\n\n  def lstm_cells(layers):\n    if isinstance(layers[0], dict):\n      return [tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(layer['steps'],\n                                                                        state_is_tuple=True),\n                                                                        layer['keep_prob'])\n      if layer.get('keep_prob') else tf.nn.rnn_cell.BasicLSTMCell(layer['steps'],\n                                                                  state_is_tuple=True)\n      for layer in layers]\n    return [tf.nn.rnn_cell.BasicLSTMCell(steps, state_is_tuple=True) for steps in layers]\n\n  def dnn_layers(input_layers, layers):\n    if layers and isinstance(layers, dict):\n      return learn.ops.dnn(input_layers,\n                                layers['layers'],\n                                activation=layers.get('activation'),\n                                dropout=layers.get('dropout'))\n    elif layers:\n      return learn.ops.dnn(input_layers, layers)\n    else:\n      return input_layers\n\n  def _lstm_model(X, y):\n    stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(lstm_cells(rnn_layers), state_is_tuple=True)\n    x_ = learn.ops.split_squeeze(1, time_steps, X)\n    output, layers = tf.nn.rnn(stacked_lstm, x_, dtype=dtypes.float32)\n    output = dnn_layers(output[-1], dense_layers)\n    return learn.models.linear_regression(output, y)\n\n  return _lstm_model"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def rnn_data(data, time_steps, labels=False):\n  \"\"\"\n  creates new data frame based on previous observation\n    * example:\n      l = [1, 2, 3, 4, 5]\n      time_steps = 2\n      -> labels == False [[1, 2], [2, 3], [3, 4]]\n      -> labels == True [2, 3, 4, 5]\n  \"\"\"\n  rnn_df = []\n  for i in range(len(data) - time_steps):\n    if labels:\n      try:\n        rnn_df.append(data.iloc[i + time_steps].as_matrix())\n      except AttributeError:\n        rnn_df.append(data.iloc[i + time_steps])\n    else:\n      data_ = data.iloc[i: i + time_steps].as_matrix()\n      rnn_df.append(data_ if len(data_.shape) > 1 else [[i] for i in data_])\n  return np.array(rnn_df)\n\n\ndef split_data(data, val_size=0.1, test_size=0.1):\n  \"\"\"\n  splits data to training, validation and testing parts\n  \"\"\"\n  ntest = int(round(len(data) * (1 - test_size)))\n  nval = int(round(len(data.iloc[:ntest]) * (1 - val_size)))\n\n  df_train, df_val, df_test = data.iloc[:nval], data.iloc[nval:ntest], data.iloc[ntest:]\n\n  return df_train, df_val, df_test\n\n\ndef prepare_data(data, time_steps, labels=False, val_size=0.1, test_size=0.1):\n  \"\"\"\n  Given the number of `time_steps` and some data,\n  prepares training, validation and test data for an lstm cell.\n  \"\"\"\n  df_train, df_val, df_test = split_data(data, val_size, test_size)\n  return (rnn_data(df_train, time_steps, labels=labels),\n           rnn_data(df_val, time_steps, labels=labels),\n           rnn_data(df_test, time_steps, labels=labels))\n\n\ndef generate_data(fct, x, time_steps, seperate=False):\n  \"\"\"generates data with based on a function fct\"\"\"\n  data = fct(x)\n  if not isinstance(data, pd.DataFrame):\n    data = pd.DataFrame(data)\n    train_x, val_x, test_x = prepare_data(data['a'] if seperate else data, time_steps)\n    train_y, val_y, test_y = prepare_data(data['b'] if seperate else data, time_steps, labels=True)\n    return dict(train=train_x, val=val_x, test=test_x), dict(train=train_y, val=val_y, test=test_y)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}