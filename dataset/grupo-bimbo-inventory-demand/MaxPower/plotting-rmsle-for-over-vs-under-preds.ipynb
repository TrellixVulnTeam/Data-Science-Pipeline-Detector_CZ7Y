{"cells":[{"cell_type":"markdown","metadata":{},"source":"The Kaggle wiki page on RMSLE states that \"RMSLE penalizes an under-predicted estimate greater than an over-predicted estimate.\" This notebook plots RMSLE for over- vs under-predictions to visualize this relationship. "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#rmsle calc from https://www.kaggle.com/jpopham91/caterpillar-tube-pricing/rmlse-vectorized/code\ndef rmsle(pred, act):\n    return np.sqrt(np.mean(np.power(np.log1p(pred)-np.log1p(act), 2)))\n\n\n#Get Curves For RMSLE as a Function of Over- and Under-Predicted Amounts\ndef calcOverPredUnderPredCurves(errorRange):   \n\n    #Initialize Lists to hold Results\n    overPredCurve = []\n    underPredCurve= []\n    \n    #Set 'Actual' Data as 100 so [e] of e.g. 5 is 5% error\n    actual = 100\n    \n    for e in range(errorRange):\n        \n        #Calculate rmsle for overprediction underprediction by [e]\n        overPrediction = actual + e\n        underPrediction = actual - e\n        \n        overPredRMSLE = rmsle(overPrediction, actual)\n        underPredRMSLE= rmsle(underPrediction, actual)\n\n        #Append to running list of results\n        overPredCurve.append(overPredRMSLE)\n        underPredCurve.append(underPredRMSLE)\n        \n    return overPredCurve, underPredCurve\n   \nover, under = calcOverPredUnderPredCurves(100) \n\n\n#Plot Curves\nsns.set_style(\"darkgrid\")\nplt.plot(under, color=\"darkblue\", label=\"under-prediction RMSLE\")\nplt.plot(over, color=\"green\", label=\"over-prediction RMSLE\")\nplt.ylabel(\"RMSLE\")\nplt.xlabel(\"% error in Prediction\")\nplt.legend(loc=\"best\")\nplt.show()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}