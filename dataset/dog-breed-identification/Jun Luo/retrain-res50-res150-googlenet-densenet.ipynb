{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%cd ../input/dog-breed-identification/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport time\nimport copy\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nimport torchvision\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torchvision.transforms as transforms\nimport albumentations as albu\nimport matplotlib.image as mpi\n\nfrom albumentations import (HorizontalFlip,VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise,RandomRotate90,Transpose,RandomBrightnessContrast,RandomCrop)\nfrom albumentations.pytorch import ToTensor\nfrom PIL import Image\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import models\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim import lr_scheduler\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import f1_score\n\nwarnings.filterwarnings(\"ignore\")\nseed = 69\nrandom.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nnp.random.seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CLASSES = 120\nlabels = pd.read_csv(\"labels.csv\")\nselected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\nlabels = labels[labels['breed'].isin(selected_breed_list)].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = labels['breed']\ndf2 = labels[\"id\"]\ndf1 = pd.get_dummies(df1)\ndf = pd.concat([df2,df1], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train,df_val = train_test_split(df,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DogDataset(Dataset):\n\n  def __init__(self,df,root,phase):\n    self.df = df\n    self.length = df.shape[0]\n    self.root = root\n    if phase==\"train\":\n        self.transforms = albu.Compose([\n            albu.SmallestMaxSize(256),\n            albu.RandomCrop(256,256),\n            albu.HorizontalFlip(p=0.5),\n            albu.Cutout(),\n            albu.RGBShift(),\n            albu.Rotate(limit=(-90,90)),\n            # albu.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n        ])\n    elif phase==\"val\":\n        self.transforms = albu.Compose([\n            albu.Resize(256,256),\n            # albu.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n        ])\n\n  def __getitem__(self,index):\n    label = self.df.iloc[index,1:]\n    label = label.to_numpy()\n    image_id = self.df.iloc[index,0]\n    path = os.path.join(self.root,str(image_id) + \".jpg\")\n    img = plt.imread(path)\n    img = self.transforms(image=np.array(img))\n    img = img['image']\n    img = np.transpose(img,(2,0,1)).astype(np.float32)\n    img = torch.tensor(img, dtype = torch.float)\n    label = np.argmax(label)\n    return img,label\n  \n  def __len__(self):\n    return self.length \n  \n  def label_name(self,label):\n    breeds = self.df.columns.values\n    breeds = breeds[1:]\n    idx = np.argmax(label)\n    return breeds[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs):\n    since = time.time()\n    dataset_sizes = {'train': len(dataloaders['train'].dataset), \n                     'val': len(dataloaders['val'].dataset)}\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    number_of_iter = 0\n    acc_train = []\n    acc_val = []\n    loss_train = []\n    loss_val = []\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            current_loss = 0.0\n            current_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                current_loss += loss.item() * inputs.size(0)\n                current_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = current_loss / dataset_sizes[phase]\n            epoch_acc = current_corrects.double() / dataset_sizes[phase]\n            if phase==\"train\":\n                acc_train.append(epoch_acc)\n                loss_train.append(epoch_loss)\n            else:\n                acc_val.append(epoch_acc)\n                loss_val.append(epoch_loss)\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_since = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_since // 60, time_since % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    model.load_state_dict(best_model_wts)\n    \n    \n    return model,acc_val,acc_train,loss_train,loss_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = DogDataset(df_train,root = \"train\", phase=\"train\")\nvaldata = DogDataset(df_val,root = \"train\", phase=\"val\")\ntrainloader = DataLoader(traindata,batch_size = 24,num_workers=0)\nvalloader = DataLoader(valdata,batch_size = 24,num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(trainloader)\nimage,label = dataiter.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_img(img):\n    plt.figure(figsize=(18,15))\n    img = img / 2 + 0.5  \n    npimg = img.numpy()\n    npimg = np.clip(npimg, 0., 1.)\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\nshow_img(torchvision.utils.make_grid(image))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resnet152"},{"metadata":{"trusted":true},"cell_type":"code","source":"__all__ = ['ResNet50', 'ResNet101','ResNet152']\n\ndef Conv1(in_planes, places, stride=2):\n    return nn.Sequential(\n        nn.Conv2d(in_channels=in_planes,out_channels=places,kernel_size=7,stride=stride,padding=3, bias=False),\n        nn.BatchNorm2d(places),\n        nn.ReLU(inplace=True),\n        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n    )\n\nclass Bottleneck(nn.Module):\n    def __init__(self,in_places,places, stride=1,downsampling=False, expansion = 4):\n        super(Bottleneck,self).__init__()\n        self.expansion = expansion\n        self.downsampling = downsampling\n\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(in_channels=in_places,out_channels=places,kernel_size=1,stride=1, bias=False),\n            nn.BatchNorm2d(places),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(places),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=places, out_channels=places*self.expansion, kernel_size=1, stride=1, bias=False),\n            nn.BatchNorm2d(places*self.expansion),\n        )\n\n        if self.downsampling:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels=in_places, out_channels=places*self.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(places*self.expansion)\n            )\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        residual = x\n        out = self.bottleneck(x)\n\n        if self.downsampling:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self,blocks, num_classes=120, expansion = 4):\n        super(ResNet,self).__init__()\n        self.expansion = expansion\n\n        self.conv1 = Conv1(in_planes = 3, places= 64)\n\n        self.layer1 = self.make_layer(in_places = 64, places= 64, block=blocks[0], stride=1)\n        self.layer2 = self.make_layer(in_places = 256,places=128, block=blocks[1], stride=2)\n        self.layer3 = self.make_layer(in_places=512,places=256, block=blocks[2], stride=2)\n        self.layer4 = self.make_layer(in_places=1024,places=512, block=blocks[3], stride=2)\n\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(2048,num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def make_layer(self, in_places, places, block, stride):\n        layers = []\n        layers.append(Bottleneck(in_places, places,stride, downsampling =True))\n        for i in range(1, block):\n            layers.append(Bottleneck(places*self.expansion, places))\n\n        return nn.Sequential(*layers)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\ndef ResNet50():\n    return ResNet([3, 4, 6, 3])\n\ndef ResNet101():\n    return ResNet([3, 4, 23, 3])\n\ndef ResNet152():\n    return ResNet([3, 8, 36, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet152 = ResNet152()\nfc_inputs = resnet152.fc.in_features\ncs_net = nn.Sequential(\n            nn.Linear(fc_inputs, NUM_CLASSES*12),\n            nn.ReLU(inplace=True),\n            nn.Linear(NUM_CLASSES*12, NUM_CLASSES*6),\n            nn.ReLU(inplace=True),\n            nn.Linear(NUM_CLASSES*6, NUM_CLASSES),\n)\nresnet152.fc = cs_net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model = resnet152\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=0.001)\nscheduler = ReduceLROnPlateau(optimizer,factor=0.33, mode=\"min\", patience=2)\ndataloaders = {\"train\":trainloader,\"val\":valloader}\nstart_time = time.time()\nmodel_resnet, acc_val_resnet, acc_train_resnet, loss_train_resnet, loss_val_resnet = \\\n        train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resnet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50 = ResNet50()\nfc_inputs = resnet50.fc.in_features\ncs_net = nn.Sequential(\n            nn.Linear(fc_inputs, NUM_CLASSES*12),\n            nn.ReLU(inplace=True),\n            nn.Linear(NUM_CLASSES*12, NUM_CLASSES*6),\n            nn.ReLU(inplace=True),\n            nn.Linear(NUM_CLASSES*6, NUM_CLASSES),\n)\nresnet50.fc = cs_net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = resnet50\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.001)\nscheduler = ReduceLROnPlateau(optimizer, factor=0.33, mode=\"min\", patience=2)\ndataloaders = {\"train\":trainloader,\"val\":valloader}\nmodel_resnet50, acc_val_resnet50, acc_train_resnet50, loss_train_resnet50, loss_val_resnet50 = \\\n        train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GoogleNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"googlenet = models.googlenet(pretrained=True).to(device)\nfor param in googlenet.parameters():\n    param.requires_grad=False\nfc_inputs = googlenet.fc.in_features\ngooglenet.fc = nn.Linear(fc_inputs,NUM_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = googlenet\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=0.001)\nscheduler = ReduceLROnPlateau(optimizer,factor=0.33, mode=\"min\", patience=2)\nmodel = model.to(device)\ndataloaders = {\"train\":trainloader,\"val\":valloader}\nnum_epochs = 15\nstart_time = time.time()\nmodel_googlenet, acc_val_googlenet, acc_train_googlenet, loss_train_googlenet, loss_val_googlenet = \\\n        train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DenseNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"class _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super(_DenseLayer, self).__init__()\n        self.add_module(\"norm1\", nn.BatchNorm2d(num_input_features))\n        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n        self.add_module(\"conv1\", nn.Conv2d(num_input_features, bn_size*growth_rate,\n                                           kernel_size=1, stride=1, bias=False))\n        self.add_module(\"norm2\", nn.BatchNorm2d(bn_size*growth_rate))\n        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n        self.add_module(\"conv2\", nn.Conv2d(bn_size*growth_rate, growth_rate,\n                                           kernel_size=3, stride=1, padding=1, bias=False))\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super(_DenseLayer, self).forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n        return torch.cat([x, new_features], 1)\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features+i*growth_rate, growth_rate, bn_size,\n                                drop_rate)\n            self.add_module(\"denselayer%d\" % (i+1,), layer)\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_feature, num_output_features):\n        super(_Transition, self).__init__()\n        self.add_module(\"norm\", nn.BatchNorm2d(num_input_feature))\n        self.add_module(\"relu\", nn.ReLU(inplace=True))\n        self.add_module(\"conv\", nn.Conv2d(num_input_feature, num_output_features,\n                                          kernel_size=1, stride=1, bias=False))\n        self.add_module(\"pool\", nn.AvgPool2d(2, stride=2))\n        \nclass DenseNet(nn.Module):\n    \"DenseNet-BC model\"\n    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64,\n                 bn_size=4, compression_rate=0.5, drop_rate=0, num_classes=1000):\n        super(DenseNet, self).__init__()\n        # first Conv2d\n        self.features = nn.Sequential(OrderedDict([\n            (\"conv0\", nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n            (\"norm0\", nn.BatchNorm2d(num_init_features)),\n            (\"relu0\", nn.ReLU(inplace=True)),\n            (\"pool0\", nn.MaxPool2d(3, stride=2, padding=1))\n        ]))\n\n        # DenseBlock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers, num_features, bn_size, growth_rate, drop_rate)\n            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n            num_features += num_layers*growth_rate\n            if i != len(block_config) - 1:\n                transition = _Transition(num_features, int(num_features*compression_rate))\n                self.features.add_module(\"transition%d\" % (i + 1), transition)\n                num_features = int(num_features * compression_rate)\n\n        # final bn+ReLU\n        self.features.add_module(\"norm5\", nn.BatchNorm2d(num_features))\n        self.features.add_module(\"relu5\", nn.ReLU(inplace=True))\n\n        # classification layer\n        self.classifier = nn.Linear(num_features, num_classes)\n\n        # params initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.bias, 0)\n                nn.init.constant_(m.weight, 1)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        features = self.features(x)\n        out = F.avg_pool2d(features, 7, stride=1).view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n    \ndef densenet121(pretrained=False, **kwargs):\n    \"\"\"DenseNet121\"\"\"\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n                     **kwargs)\n\n    if pretrained:\n        pattern = re.compile(\n            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n        state_dict = model_zoo.load_url(model_urls['densenet121'])\n        for key in list(state_dict.keys()):\n            res = pattern.match(key)\n            if res:\n                new_key = res.group(1) + res.group(2)\n                state_dict[new_key] = state_dict[key]\n                del state_dict[key]\n        model.load_state_dict(state_dict)\n    return model\n\ndensenet = densenet121(pretrained=True)\nclassifier_inputs = densenet.classifier.in_features\ncs_net = nn.Sequential(\n            nn.Linear(classifier_inputs, NUM_CLASSES*12),\n            nn.ReLU(inplace=True),\n            nn.Linear(NUM_CLASSES*12, NUM_CLASSES*6),\n            nn.ReLU(inplace=True),\n            nn.Linear(NUM_CLASSES*6, NUM_CLASSES),\n)\ndensenet.classifier = cs_net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = densenet\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=0.001)\nscheduler = ReduceLROnPlateau(optimizer,factor=0.33, mode=\"min\", patience=2)\ndataloaders = {\"train\":trainloader, \"val\":valloader}\nstart_time = time.time()\nmodel_densenet, acc_val_densenet, acc_train_densenet, loss_train_densenet, loss_val_densenet = \\\n        train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = []\nfor x in range(num_epochs):\n    epoch.append(x)\nplt.plot(epoch,loss_train,label = 'TrainLoss')\nplt.plot(epoch,loss_val,label = 'ValLoss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(plt.style.available)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = list(range(1, 26))\nplt.style.use('default')\nplt.plot(epoch, acc_train_densenet, label='DenseNet')\nplt.plot(epoch, acc_train_googlenet, label='GoogleNet')\nplt.plot(epoch, acc_train_resnet, label='ResNet152')\nplt.plot(epoch, acc_train_resnet50, label='ResNet50')\nplt.ylabel('Training Set Accuracy')\nplt.xlabel('Epoch')\nplt.grid(linestyle='-.')\nplt.legend(loc=(0.72, 0.1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = list(range(1, 26))\nplt.style.use('default')\nplt.plot(epoch, acc_val_densenet, label='DenseNet')\nplt.plot(epoch, acc_val_googlenet, label='GoogleNet')\nplt.plot(epoch, acc_val_resnet, label='ResNet152')\nplt.plot(epoch, acc_val_resnet50, label='ResNet50')\nplt.ylabel('Validation Set Accuracy')\nplt.xlabel('Epoch')\nplt.grid(linestyle='-.')\nplt.legend(loc=(0.72, 0.1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = list(range(1, 26))\nplt.plot(epoch, loss_train_densenet, label='DenseNet')\nplt.plot(epoch, loss_train_googlenet, label='GoogleNet')\nplt.plot(epoch, loss_train_resnet, label='ResNet152')\nplt.plot(epoch, loss_train_resnet50, label='ResNet50')\nplt.ylabel('Training Set Loss')\nplt.xlabel('Epoch')\nplt.grid(linestyle='-.')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = list(range(1, 26))\nplt.plot(epoch, loss_val_densenet, label='DenseNet')\nplt.plot(epoch, loss_val_googlenet, label='GoogleNet')\nplt.plot(epoch, loss_val_resnet, label='ResNet152')\nplt.plot(epoch, loss_val_resnet50, label='ResNet50')\nplt.ylabel('Validation Set Loss')\nplt.xlabel('Epoch')\nplt.grid(linestyle='-.')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(),'res152.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame(index=sub.index,columns = sub.keys())\noutput['id'] = sub['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata = DogDataset(sub,root=\"test\",phase='val')\ntestloader = DataLoader(testdata,batch_size=24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_submission(model):\n    since = time.time()\n    sub_output = []\n    model.train(False)\n    for data in testloader:\n        inputs,labels = data\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        sub_output.append(outputs.data.cpu().numpy())\n    sub_output = np.concatenate(sub_output)\n    for idx,row in enumerate(sub_output.astype('float')):\n        sub_output[idx] = np.exp(row)/np.sum(np.exp(row))\n    output.loc[:,1:] = sub_output\n    print()\n    time_elapsed = time.time() - since\n    print('Run complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd '/kaggle/input/dog-breed-identification'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)\ntest_submission(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd '/kaggle/working'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(\"dogs_idres152.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}