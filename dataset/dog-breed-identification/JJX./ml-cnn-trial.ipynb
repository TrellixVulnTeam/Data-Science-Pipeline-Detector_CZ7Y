{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Installation","metadata":{}},{"cell_type":"markdown","source":"## Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow import keras\ntfds.disable_progress_bar()\n\nfrom keras.preprocessing import image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\ntest_labels = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')\ntrain_labels.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = \"../input/dog-breed-identification/train\"\ntest_dir = \"../input/dog-breed-identification/test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def append_ext(fn):\n    return fn + '.jpg'\n\ntrain_labels['id'] = train_labels['id'].apply(append_ext)\ntest_labels['id'] = test_labels['id'].apply(append_ext)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Examples","metadata":{}},{"cell_type":"code","source":"import os\n\nsrc_path = \"../input/dog-breed-identification/train\"\nsub_class = os.listdir(src_path)\n\nfig = plt.figure(figsize = (10, 5))\nfor e in range(len(sub_class[:8])):\n    plt.subplot(2, 4, e+1)\n    img = plt.imread(os.path.join(src_path, sub_class[e]))\n    plt.imshow(img, cmap = plt.get_cmap('gray'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nimg_size = 224","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                  horizontal_flip = True,\n                                  validation_split = 0.1\n                                  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_labels,\n    directory = train_dir,\n    x_col = \"id\",\n    y_col = \"breed\",\n    subset = \"training\",\n    batch_size = batch_size,\n    seed = 42,\n    shuffle = True,\n    class_mode = \"categorical\",\n    target_size = (img_size, img_size),\n    color_mode = \"rgb\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot Augmented Images","metadata":{}},{"cell_type":"code","source":"x, y = next(train_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(x))\nprint(x.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid\n\ndef show_grid(image_list, nrows, ncols, figsize = (10,10), showaxis='off'):\n    if type(image_list) is not list:\n        if(image_list.shape[-1] == 1):\n            image_list = [image_list[i,:,:,0] for i in range(image_list.shape[0])]\n            \n        elif(image_list.shape[-1]==3):\n            image_list = [image_list[i,:,:,:] for i in range(image_list.shape[0])]\n            \n    fig = plt.figure(None, figsize,frameon=False)\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(nrows, ncols),  # creates 2x2 grid of axes\n                     axes_pad=0.3,  # pad between axes in inch.\n                     share_all=True,\n                     )\n    \n    for i in range(nrows*ncols):\n        ax = grid[i]\n        ax.imshow(image_list[i],cmap='Greys_r')  # The AxesGrid object work as a list of axes.\n        ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_grid(x, 4, 8, figsize=(25, 25))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation Data","metadata":{}},{"cell_type":"code","source":"val_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_labels,\n    directory = train_dir,\n    x_col = \"id\",\n    y_col = \"breed\",\n    subset = \"validation\",\n    batch_size = batch_size,\n    seed = 42,\n    shuffle = True,\n    class_mode = \"categorical\",\n    target_size = (img_size, img_size),\n    color_mode = \"rgb\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Data","metadata":{}},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = test_labels,\n    directory = test_dir,\n    x_col = \"id\",\n    y_col = None,\n    batch_size = batch_size,\n    seed = 42,\n    shuffle = False,\n    class_mode = None,\n    target_size = (img_size, img_size),\n    color_mode = \"rgb\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the CNN","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.AveragePooling2D(6, 3, input_shape=(224, 224, 3)),\n#     keras.layers.Conv2D(64, 3, activation='relu'),\n#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'),\n#     keras.layers.MaxPool2D(2, 2),\n#     keras.layers.Dropout(0.5),\n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation='relu'),\n    keras.layers.Dropout(0.4),\n    keras.layers.Dense(120, activation='softmax')\n])\n\nmodel.compile(optimizer=keras.optimizers.SGD(learning_rate = 0.01),\n              loss=keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VAL = val_generator.n//val_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n\nmodel.fit(train_generator,\n          steps_per_epoch=STEP_SIZE_TRAIN,\n          validation_data=val_generator,\n          validation_steps=STEP_SIZE_VAL,\n          epochs=20,\n          callbacks = [early])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nstart = time.time()\nscore = model.evaluate(val_generator, batch_size = 32)\nend = time.time()\n\nprint(\"Accuracy: {:.2f}%\".format(score[1] * 100)) \nprint(\"Loss: \",score[0])\nprint(\"Time per test instance: \", (end-start)/1022)      #no. of val images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = model.predict(val_generator)\ny_pred = np.argmax(Y_pred, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nprint(\"Micro F1: \", f1_score(val_generator.classes,y_pred,average='micro'))\nprint(\"Macro F1: \", f1_score(val_generator.classes,y_pred,average='macro'))\nprint(\"Weighted F1: \", f1_score(val_generator.classes,y_pred,average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For Submission","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv')\ndf_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\nfile_list = test_generator.filenames\nid_list = []\nfor name in file_list:\n    m = re.sub('test/', '', name)\n    m = re.sub('.jpg', '', m)\n    id_list.append(m)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission['id'] = id_list\ndf_submission.iloc[:,1:] = pred\ndf_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_sub = df_submission.set_index('id')\nfinal_sub.to_csv('Submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"pip install -U keras-tuner","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kerastuner.tuners import RandomSearch\n\ndef build_model(hp):\n    model = keras.Sequential()\n\n    model.add(keras.layers.AveragePooling2D(6, 3, input_shape=(224, 224, 3)))\n\n#     model.add(keras.layers.MaxPool2D(2, 2))\n   \n    model.add(keras.layers.Flatten())\n\n    #hp.Choice allows the model to try out the different hyperparams to pick out the best performing one\n    model.add(keras.layers.Dense(hp.Choice(\"Dense layer\", [64, 128, 256, 512, 1024]), activation='relu'))\n    model.add(keras.layers.Dropout(hp.Choice(\"Dropout\", [0.1, 0.2, 0.3, 0.4, 0.5, 0.6])))\n    model.add(keras.layers.Dense(120, activation='softmax'))\n\n    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    \n    model.compile(optimizer=keras.optimizers.SGD(learning_rate = hp_lr),\n              loss = keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner = RandomSearch(\n    build_model,\n    objective = 'val_accuracy',\n    max_trials = 32,\n    directory = './multi_conv'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VAL = val_generator.n//val_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n\ntuner.search(train_generator,\n            steps_per_epoch=STEP_SIZE_TRAIN,\n            validation_data=val_generator,\n            validation_steps=STEP_SIZE_VAL,\n            epochs=20,\n            callbacks=[early])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = tuner.get_best_models()[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save & Load Models","metadata":{}},{"cell_type":"code","source":"best_model.save('./best_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = keras.models.load_model('./best_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Image from Numpy Array","metadata":{}},{"cell_type":"code","source":"#RGB image\nrgb_images = np.array([example['image'].numpy() for example in ds_train.take(1)])\nrgb_image = rgb_images[0]\n\nimage = train_images[0].reshape(300, 300)\n\nplt.imshow(rgb_image)\nrgb_image.shape\n\n#Greyscale image\n# image = train_images[0].reshape(300, 300)\n\n# plt.imshow(train_images[0], cmap='Greys_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert PNG/JPG Imgaes to Numpy Format","metadata":{}},{"cell_type":"code","source":"import imageio\n\nim = imageio.imread('')\n\nprint(type(im))\n\nim_np = np.asarray(im)\n\nprint(im_np.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import glob\n\n# # First of all we will extract the detail of all the data and save all of them in terms of dataframe with foldername, imagename, objectname and labels\n# detail = sorted(glob.glob(\"../input/dog-breed-identification/train/*\"))\n# Folder_Name = [str(i.split(\"in/\")[0]) + \"in\" for i in detail]\n# Image_Name = [str(i.split(\"/\")[4]) for i in detail]\n# Train_Labels = np.array((pd.read_csv('../input/dog-breed-identification/labels.csv'))[\"breed\"])\n\n# # Defining dataframe and saving all the extracted information in that dataframe\n# train_detail = pd.DataFrame() \n# train_detail[\"Folder Name\"] = Folder_Name\n# train_detail[\"Image Name\"] = Image_Name\n# train_detail[\"Train Labels\"] = Train_Labels\n\n\n# # Analying the train data detail\n# print(\"\\nNumber of images in training set = \"+str(len(detail)))\n# print(train_detail.columns)\n# train_detail.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}