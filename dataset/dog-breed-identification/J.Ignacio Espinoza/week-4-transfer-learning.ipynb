{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport gc\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tqdm.autonotebook import tqdm\nimport numpy as np\nimport pandas as pd \nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom keras.preprocessing.image import load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\ntf.config.list_physical_devices(\"GPU\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to show bar length\n#def barw(ax): \n    \n#    for p in ax.patches:\n#        val = p.get_width() #height of the bar\n#        x = p.get_x()+ p.get_width() # x- position \n#        y = p.get_y() + p.get_height()/2 #y-position\n#        ax.annotate(round(val,2),(x,y))\n        \n#finding top dog brands\n\n#plt.figure(figsize = (15,30))\n#ax0 =sns.countplot(y=labels['breed'],order=labels['breed'].value_counts().index)\n#barw(ax0)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display, Image\nImage(\"../input/dog-breed-identification/train/43572ba7edf772a95f539e57afd9eb43.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\nclass_to_num = dict(zip(classes, range(n_classes)))\nclass_to_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (331,331,3)\n\n\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8)\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix]=img\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time \nt = time.time()\n\nX,y = images_to_array('/kaggle/input/dog-breed-identification/train', labels[:])\n\nprint('runtime in seconds: {}'.format(time.time() - t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=20\n\nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n    ax = plt.subplot(5, 5, i+1)\n    plt.title(classes[np.where(y[i] ==1)[0][0]])\n    plt.imshow(X[i].astype('int32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Learning Rate Annealer\nlrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n#Prepare call backs\nEarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nbatch_size= 128\nepochs=50\nlearn_rate=.001\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to extract features from the dataset by a given pretrained model\nimg_size = (331,331,3)\n\ndef get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using InceptionV3 \nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using Xception \nfrom keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using InceptionResNetV2 \nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using NASNetLarge \nfrom keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_features(NASNetLarge,\n                               nasnet_preprocessor,\n                               img_size, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X #to free up some ram memory\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features,], axis=-1)\n\nprint('Final feature maps shape', final_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare Deep net\n\nmodel = Sequential()\nmodel.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\nmodel.add(Dense(n_classes,activation= 'softmax'))\n\nmodel.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Training the model. \nhistory = model.fit(final_features, y,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2,\n            callbacks=[lrr,EarlyStop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#deleting to free up ram memory\n\ndel inception_features\ndel xception_features\ndel nasnet_features\ndel inc_resnet_features\ndel final_features\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to read images from test directory\n\ndef images_to_array_test(test_path, img_size = (331,331,3)):\n    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\n    data_size = len(test_filenames)\n    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    \n    for ix,img_dir in enumerate(tqdm(test_filenames)):\n        img = load_img(img_dir, target_size = img_size)\n        images[ix]=img\n        del img\n    print('Ouptut Data Size: ', images.shape)\n    return images\n\ntest_data = images_to_array_test('/kaggle/input/dog-breed-identification/test/', img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract test data features.\ndef extact_features(data):\n    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n\n    final_features = np.concatenate([inception_features,\n                                     xception_features,\n                                     nasnet_features,\n                                     inc_resnet_features],axis=-1)\n    \n    print('Final feature maps shape', final_features.shape)\n    \n    #deleting to free up ram memory\n    del inception_features\n    del xception_features\n    del nasnet_features\n    del inc_resnet_features\n    gc.collect()\n    \n    \n    return final_features\n\ntest_features = extact_features(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Free up some space.\ndel test_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict test labels given test data features.\n\npred = model.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First prediction\nprint(pred[0])\nprint(f\"Max value (probability of prediction): {np.max(pred[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(pred[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(pred[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {classes[np.argmax(pred[0])]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create pandas DataFrame with empty columns\npreds_df = pd.DataFrame(columns=[\"id\"] + list(classes))\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Append test image ID's to predictions DataFrame\ntest_path = \"/kaggle/input/dog-breed-identification/test/\"\npreds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df.loc[:,list(classes)]= pred\n\npreds_df.to_csv('submission.csv',index=None)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Custom input\n\nImage('../input/dogtest/DBS_GoldRetriever_1280.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading the image and converting it into an np array\n\nimg_g = load_img('../input/dogtest/DBS_GoldRetriever_1280.jpg',target_size = img_size)\nimg_g = np.expand_dims(img_g, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_g.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Predict test labels given test data features.\ntest_features = extact_features(img_g)\npredg = model.predict(test_features)\nprint(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\nprint(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}