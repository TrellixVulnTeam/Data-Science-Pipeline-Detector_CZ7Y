{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dog Breed classification","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plte\n%matplotlib inline\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.594977Z","iopub.status.idle":"2021-06-08T08:43:33.595387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"#show labels\n\nlabels_df = pd.read_csv('../input/dog-breed-identification/labels.csv')\nlabels_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.596388Z","iopub.status.idle":"2021-06-08T08:43:33.596793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.597805Z","iopub.status.idle":"2021-06-08T08:43:33.598213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize data\n\nlabels_df['breed'].value_counts().plot.bar(figsize=(10,10))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.599079Z","iopub.status.idle":"2021-06-08T08:43:33.599497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df['breed'].value_counts().median()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.60049Z","iopub.status.idle":"2021-06-08T08:43:33.600942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show one image\nfrom IPython.display import Image\nImage('../input/dog-breed-identification/train/001cdf01b096e06d78e9e5112d419397.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.601725Z","iopub.status.idle":"2021-06-08T08:43:33.602113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Format data","metadata":{"execution":{"iopub.status.busy":"2021-06-08T07:26:33.659309Z","iopub.execute_input":"2021-06-08T07:26:33.660069Z","iopub.status.idle":"2021-06-08T07:26:33.664414Z","shell.execute_reply.started":"2021-06-08T07:26:33.66002Z","shell.execute_reply":"2021-06-08T07:26:33.663349Z"}}},{"cell_type":"code","source":"#create image path in data\n\nfilenames = [\"../input/dog-breed-identification/train/\" + fname + \".jpg\"for fname in labels_df['id']]\nfilenames[22]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.602907Z","iopub.status.idle":"2021-06-08T08:43:33.603298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# verify each image has is  path\n\nimport os\n\nif len(os.listdir(\"../input/dog-breed-identification/train/\")) == len (filenames):\n    print (\"ok\")\nelse:\n    print (\"not ok\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.604091Z","iopub.status.idle":"2021-06-08T08:43:33.604483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check one image and is label\n\nImage(filenames[25])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.819543Z","iopub.execute_input":"2021-06-08T08:43:33.819924Z","iopub.status.idle":"2021-06-08T08:43:33.82804Z","shell.execute_reply.started":"2021-06-08T08:43:33.819892Z","shell.execute_reply":"2021-06-08T08:43:33.826754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels_df['breed'][25])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.829823Z","iopub.execute_input":"2021-06-08T08:43:33.830415Z","iopub.status.idle":"2021-06-08T08:43:33.841019Z","shell.execute_reply.started":"2021-06-08T08:43:33.830367Z","shell.execute_reply":"2021-06-08T08:43:33.839641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## turning data into numbers","metadata":{}},{"cell_type":"code","source":"# tunr labels into numpy array\n\nlabels = labels_df['breed']\nlabels = np.array(labels)\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.843307Z","iopub.execute_input":"2021-06-08T08:43:33.843928Z","iopub.status.idle":"2021-06-08T08:43:33.856891Z","shell.execute_reply.started":"2021-06-08T08:43:33.843877Z","shell.execute_reply":"2021-06-08T08:43:33.855595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check everything is ok\n\nif len(labels) == len(filenames):\n    print('everything is ok')\nelse:\n    print ('ouch')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.858616Z","iopub.execute_input":"2021-06-08T08:43:33.859028Z","iopub.status.idle":"2021-06-08T08:43:33.874024Z","shell.execute_reply.started":"2021-06-08T08:43:33.858994Z","shell.execute_reply":"2021-06-08T08:43:33.872658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels encoding\n\nunique_breed = np.unique(labels)\nunique_breed","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.875605Z","iopub.execute_input":"2021-06-08T08:43:33.876393Z","iopub.status.idle":"2021-06-08T08:43:33.900234Z","shell.execute_reply.started":"2021-06-08T08:43:33.876345Z","shell.execute_reply":"2021-06-08T08:43:33.899076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Turn single label into an array of boolean.\nprint(labels[0])\nlabels[0] == unique_breed","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.901457Z","iopub.execute_input":"2021-06-08T08:43:33.901745Z","iopub.status.idle":"2021-06-08T08:43:33.917951Z","shell.execute_reply.started":"2021-06-08T08:43:33.901718Z","shell.execute_reply":"2021-06-08T08:43:33.916811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Turning every label into an array of boolean\nboolean_labels = [labels == unique_breed for labels in labels]\nboolean_labels[:2]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:33.919579Z","iopub.execute_input":"2021-06-08T08:43:33.919972Z","iopub.status.idle":"2021-06-08T08:43:34.027519Z","shell.execute_reply.started":"2021-06-08T08:43:33.919936Z","shell.execute_reply":"2021-06-08T08:43:34.026671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turining boolean arrays into integers.\nprint(labels[0])   #orginal index\nprint(np.where(unique_breed==labels[0]))    #index where labels occurs.\nprint(boolean_labels[0].argmax())     #index where label occurs in boolean array\nprint(boolean_labels[0].astype(int))   #there will be a 1 where sample label occurs","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.028536Z","iopub.execute_input":"2021-06-08T08:43:34.028936Z","iopub.status.idle":"2021-06-08T08:43:34.037859Z","shell.execute_reply.started":"2021-06-08T08:43:34.0289Z","shell.execute_reply":"2021-06-08T08:43:34.036109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## creating sets","metadata":{}},{"cell_type":"code","source":"# setup x and y variables.\nX = filenames\ny = boolean_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.04085Z","iopub.execute_input":"2021-06-08T08:43:34.04119Z","iopub.status.idle":"2021-06-08T08:43:34.057183Z","shell.execute_reply.started":"2021-06-08T08:43:34.04116Z","shell.execute_reply":"2021-06-08T08:43:34.056006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#just a sample\nNUM_IMAGES = 1000 ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.059994Z","iopub.execute_input":"2021-06-08T08:43:34.060502Z","iopub.status.idle":"2021-06-08T08:43:34.073151Z","shell.execute_reply.started":"2021-06-08T08:43:34.060451Z","shell.execute_reply":"2021-06-08T08:43:34.072086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's split our data into train and validation.\nfrom sklearn.model_selection import train_test_split\n\n#spliting into training and validation of total size NUM_IMAGES.\n\nX_train,X_val,y_train,y_val = train_test_split(X[:NUM_IMAGES],\n                                                y[:NUM_IMAGES],\n                                                test_size=0.2,\n                                                random_state=42)\nlen(X_train),len(X_val),len(y_train),len(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.074156Z","iopub.execute_input":"2021-06-08T08:43:34.07444Z","iopub.status.idle":"2021-06-08T08:43:34.091922Z","shell.execute_reply.started":"2021-06-08T08:43:34.074413Z","shell.execute_reply":"2021-06-08T08:43:34.090736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n\n\nPreprocessing Images\n\nTurning images into tensors\n\nLet's write a function to preprocess the image. The function will do the following tasks.\n\n    The function will take an image filepath as input.\n    Use the tensorflow to read the file and save it to the variable.\n    Turn our variable (.jpg) into tensors.\n    Normalize our image(convert color channel from 0-255 to 0-1).|\n    Resize the image.\n    Return the modified variable.\n\n","metadata":{}},{"cell_type":"code","source":"from matplotlib.pyplot import imread\nimage = imread(filenames[42])\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.095298Z","iopub.execute_input":"2021-06-08T08:43:34.095655Z","iopub.status.idle":"2021-06-08T08:43:34.108324Z","shell.execute_reply.started":"2021-06-08T08:43:34.095602Z","shell.execute_reply":"2021-06-08T08:43:34.107472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets conver them into tensor\ntf.constant(image)[:2]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.109828Z","iopub.execute_input":"2021-06-08T08:43:34.110119Z","iopub.status.idle":"2021-06-08T08:43:34.117985Z","shell.execute_reply.started":"2021-06-08T08:43:34.110092Z","shell.execute_reply":"2021-06-08T08:43:34.117215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fonction for preprocessing\n# Define image size\nIMG_SIZE = 224\n\ndef process_image(image_path):\n  \"\"\"\n  Takes an image file path and turns it into a Tensor.\n  \"\"\"\n  # Read in image file\n  image = tf.io.read_file(image_path)\n  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n  image = tf.image.decode_jpeg(image, channels=3)\n  # Convert the colour channel values from 0-225 values to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  # Resize the image to our desired size (224, 244)\n  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n  return image","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.119363Z","iopub.execute_input":"2021-06-08T08:43:34.119661Z","iopub.status.idle":"2021-06-08T08:43:34.132405Z","shell.execute_reply.started":"2021-06-08T08:43:34.119634Z","shell.execute_reply":"2021-06-08T08:43:34.131181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## creat batches","metadata":{}},{"cell_type":"code","source":"# Create a simple function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n  \"\"\"\n  Takes an image file path name and the associated label,\n  processes the image and returns a tuple of (image, label).\n  \"\"\"\n  image = process_image(image_path)\n  return image, label","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.133953Z","iopub.execute_input":"2021-06-08T08:43:34.134388Z","iopub.status.idle":"2021-06-08T08:43:34.1513Z","shell.execute_reply.started":"2021-06-08T08:43:34.134331Z","shell.execute_reply":"2021-06-08T08:43:34.150086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the batch size, 32 is a good default\nBATCH_SIZE = 32\n\n# Create a function to turn data into batches\ndef create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n  \"\"\"\n  Creates batches of data out of image (x) and label (y) pairs.\n  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n  Also accepts test data as input (no labels).\n  \"\"\"\n  # If the data is a test dataset, we probably don't have labels\n  if test_data:\n    print(\"Creating test data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n    data_batch = data.map(process_image).batch(BATCH_SIZE)\n    return data_batch\n  \n  # If the data if a valid dataset, we don't need to shuffle it\n  elif valid_data:\n    print(\"Creating validation data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n    return data_batch\n\n  else:\n    # If the data is a training dataset, we shuffle it\n    print(\"Creating training data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                              tf.constant(y))) # labels\n    \n    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n    data = data.shuffle(buffer_size=len(x))\n\n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n\n    # Turn the data into batches\n    data_batch = data.batch(BATCH_SIZE)\n  return data_batch","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.152557Z","iopub.execute_input":"2021-06-08T08:43:34.15302Z","iopub.status.idle":"2021-06-08T08:43:34.164421Z","shell.execute_reply.started":"2021-06-08T08:43:34.152975Z","shell.execute_reply":"2021-06-08T08:43:34.163517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.165689Z","iopub.execute_input":"2021-06-08T08:43:34.166159Z","iopub.status.idle":"2021-06-08T08:43:34.286298Z","shell.execute_reply.started":"2021-06-08T08:43:34.166122Z","shell.execute_reply":"2021-06-08T08:43:34.285467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out the different attributes of our data batches\ntrain_data.element_spec, val_data.element_spec","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.287469Z","iopub.execute_input":"2021-06-08T08:43:34.28789Z","iopub.status.idle":"2021-06-08T08:43:34.2942Z","shell.execute_reply.started":"2021-06-08T08:43:34.28786Z","shell.execute_reply":"2021-06-08T08:43:34.293266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## create model","metadata":{}},{"cell_type":"code","source":"# Setting up input shape to the model\nINPUT_SHAPE = [BATCH_SIZE, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n\n# Setting up output shape of the model\nOUTPUT_SHAPE = len(unique_breed) # number of unique labels\n\n# Setting up model URL from TensorFlow Hub\nMODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\"\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.295313Z","iopub.execute_input":"2021-06-08T08:43:34.295633Z","iopub.status.idle":"2021-06-08T08:43:34.308695Z","shell.execute_reply.started":"2021-06-08T08:43:34.295586Z","shell.execute_reply":"2021-06-08T08:43:34.307635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_SHAPE","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.310222Z","iopub.execute_input":"2021-06-08T08:43:34.310905Z","iopub.status.idle":"2021-06-08T08:43:34.328539Z","shell.execute_reply.started":"2021-06-08T08:43:34.310858Z","shell.execute_reply":"2021-06-08T08:43:34.327718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=INPUT_SHAPE[1:]))\n    model.add(MaxPool2D())\n\n    model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D())\n\n    model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D())\n    model.add(Dropout(0.4))\n\n    model.add(Flatten())\n    model.add(Dense(128,activation=\"relu\"))\n    model.add(Dense(units=OUTPUT_SHAPE, activation=\"softmax\"))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.329913Z","iopub.execute_input":"2021-06-08T08:43:34.330206Z","iopub.status.idle":"2021-06-08T08:43:34.34072Z","shell.execute_reply.started":"2021-06-08T08:43:34.330177Z","shell.execute_reply":"2021-06-08T08:43:34.339662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.342354Z","iopub.execute_input":"2021-06-08T08:43:34.343202Z","iopub.status.idle":"2021-06-08T08:43:34.360641Z","shell.execute_reply.started":"2021-06-08T08:43:34.343154Z","shell.execute_reply":"2021-06-08T08:43:34.359597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create early stopping (once our model stops improving, stop training)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=3) # stops after 3 rounds of no improvements","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.362228Z","iopub.execute_input":"2021-06-08T08:43:34.362555Z","iopub.status.idle":"2021-06-08T08:43:34.369751Z","shell.execute_reply.started":"2021-06-08T08:43:34.362526Z","shell.execute_reply":"2021-06-08T08:43:34.368844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 100\n# Build a function to train and return a trained model\ndef train_model():\n  \"\"\"\n  Trains a given model and returns the trained version.\n  \"\"\"\n  # Create a model\n  model = create_model()\n\n  # Compile the model\n  model.compile(\n      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n      metrics=[\"accuracy\"] # We'd like this to go up\n  )\n\n  # Fit the model to the data passing it the callbacks we created\n  model.fit(x=train_data,\n            epochs=NUM_EPOCHS,\n            validation_data=val_data,\n            validation_freq=1, # check validation metrics every epoch\n            callbacks=early_stopping)\n  \n  return model","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.371026Z","iopub.execute_input":"2021-06-08T08:43:34.371437Z","iopub.status.idle":"2021-06-08T08:43:34.384079Z","shell.execute_reply.started":"2021-06-08T08:43:34.371402Z","shell.execute_reply":"2021-06-08T08:43:34.382949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_model = train_model()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T08:43:34.385137Z","iopub.execute_input":"2021-06-08T08:43:34.38541Z","iopub.status.idle":"2021-06-08T08:46:23.990469Z","shell.execute_reply.started":"2021-06-08T08:43:34.385384Z","shell.execute_reply":"2021-06-08T08:46:23.989119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot();","metadata":{},"execution_count":null,"outputs":[]}]}