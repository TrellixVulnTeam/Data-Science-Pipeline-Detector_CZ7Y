{"nbformat_minor":1,"metadata":{"language_info":{"file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","mimetype":"text/x-python","version":"3.6.1","pygments_lexer":"ipython3","nbconvert_exporter":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_uuid":"1f853cb71a91a57c7a25415b9327a91a0ea22e94","_cell_guid":"0247294e-7b15-40ca-8a2d-50b2caae7e0e"},"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.applications.vgg19 import VGG19\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten\n\nimport os\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport cv2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"df_train = pd.read_csv('../input/labels.csv')\ndf_test = pd.read_csv('../input/sample_submission.csv')","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"df_train.head(10)","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"One Hot Encoding"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"targets_series = pd.Series(df_train['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"one_hot_labels = np.asarray(one_hot)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"im_size = 224","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"x_train = []\ny_train = []\nx_test = []","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"i = 0 \nfor f, breed in tqdm(df_train.values):\n    img = cv2.imread('../input/train/{}.jpg'.format(f))\n    label = one_hot_labels[i]\n    x_train.append(cv2.resize(img, (im_size, im_size)))\n    y_train.append(label)\n    i += 1","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"for f in tqdm(df_test['id'].values):\n    img = cv2.imread('../input/test/{}.jpg'.format(f))\n    x_test.append(cv2.resize(img, (im_size, im_size)))","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"y_train_raw = np.array(y_train, np.uint8)\nx_train_raw = np.array(x_train, np.float32) / 255.\nx_test  = np.array(x_test, np.float32) / 255.","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"print(x_train_raw.shape)\nprint(y_train_raw.shape)\nprint(x_test.shape)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"num_class = y_train_raw.shape[1]","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size = 0.3, random_state = 1)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"# Create the base pre-trained model\n# Can't download weights in the kernel\nbase_model = VGG19(#weights='imagenet',\n    weights = None, include_top=False, input_shape=(im_size, im_size, 3))\n\n# Add a new top layer\nx = base_model.output\nx = Flatten()(x)\npredictions = Dense(num_class, activation='softmax')(x)\n\n# This is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# First: train only the top layers (which were randomly initialized)\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer = 'adam', \n              metrics = ['accuracy'])\n\ncallbacks_list = [\n    keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 3, verbose = 1)\n                 ]\nmodel.summary()","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"model.fit(X_train, Y_train, epochs = 1, validation_data = (X_valid, Y_valid), verbose = 1)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"preds = model.predict(x_test)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"# Set the highest prediction to 1 and the rest to 0\npreds == preds.max(axis = 1, keepdims=True)\npreds = (preds == preds.max(axis = 1, keepdims = True)).astype(int)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"sub = pd.DataFrame(preds)\n# Set column names to those generated by the one-hot encoding earlier\ncol_names = one_hot.columns.values\nsub.columns = col_names\n# Insert the column id from the sample_submission at the start of the data frame\nsub.insert(0, 'id', df_test['id'])\nsub.head(5)","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"","outputs":[]}]}