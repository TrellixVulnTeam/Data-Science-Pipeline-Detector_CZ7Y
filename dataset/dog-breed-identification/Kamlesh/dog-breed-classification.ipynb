{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport time \n\nimport matplotlib.pyplot as plt\n\nfrom keras import Sequential\nfrom keras.layers import Dense, Dropout, InputLayer, Lambda, Input\nfrom keras.preprocessing.image import load_img, img_to_array\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_df = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\nsample = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print('no of images in train dataset: {}'.format(len(labels_df)))\nprint('no of images in test dataset: {}'.format(len(sample)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def images_to_array(directory, label_dataframe, target_size = (331, 331, 3)):\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]], dtype=np.uint8)\n    img = ''\n    for ix, image_name in enumerate(label_dataframe['id'].values):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img_to_array(img)\n    del img\n    label_dict = dict(enumerate(label_dataframe['breed'].unique()))\n    return images, label_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = time.time()\ntrain_images, labels = images_to_array('/kaggle/input/dog-breed-identification/train', labels_df[:])\nprint('runtime in seconds: {}'.format(time.time() - t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nfor ix, image in enumerate(train_images[:16]):\n    plt.subplot(4, 8, ix + 1)\n    plt.imshow(image / 255.0)\n    plt.xticks([])\n    plt.yticks([])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_feature(model_name, preprocess_input, images, target_size = (331,331,3)):\n    base_model = model_name(input_shape = target_size, include_top=False, pooling = 'avg')\n\n    model = Sequential()\n    model.add(InputLayer(input_shape = target_size))\n    model.add(Lambda(preprocess_input))\n    model.add(base_model)\n\n    feature = model.predict(images)\n    \n    print('feature-map shape: {}'.format(feature.shape))\n    return feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### inception model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\n\ninception_preprocess = preprocess_input\ninception_feature = get_feature(InceptionV3, preprocess_input, train_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### NASNetLarge model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_feature(NASNetLarge, nasnet_preprocessor, train_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xception model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.xception import Xception, preprocess_input\n\nxception_preprocess = preprocess_input\nxception_feature = get_feature(Xception, xception_preprocess, train_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ResNet50V2 model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n\nresnet_preprocess = preprocess_input\nresnet_feature = get_feature(InceptionResNetV2, resnet_preprocess, train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_features = np.concatenate([inception_feature, nasnet_features, xception_feature, resnet_feature], axis = 1)\nprint('final features shape: {}'.format(final_features.shape))\ndel train_images, inception_feature, nasnet_features, xception_feature, resnet_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_to_index = dict({labels[ix]:ix for ix in labels.keys()})\nindex_to_class = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = labels_df['breed'].map(class_to_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(features_shape = 1024):\n    model = Sequential()\n    model.add(InputLayer(input_shape = (features_shape, )))\n    #model.add(Dense(4096, activation = 'relu'))\n    model.add(Dropout(0.7))\n    model.add(Dense(len(class_to_index), activation = 'softmax'))\n    \n    model.compile(loss = 'sparse_categorical_crossentropy', optimizer ='Adam', metrics = ['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop_neuron = [0.1, 0.2, 0.3]\n\n#param_grid = dict(drop_neuron = drop_neuron)\n#model = KerasClassifier(build_fn=create_model, epochs = 10, batch_size = 32)\n#grid_search = GridSearchCV(estimator=model, param_grid=param_grid)\n#result = grid_search.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#means = result.cv_results_['mean_test_score']\n#stds = result.cv_results_['std_test_score']\n#params = result.cv_results_['params']\n#print('best param: {}'.format(result.best_params_))\n#for mean, stdev, param in zip(means, stds, params):\n#    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model(final_features.shape[1])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(final_features, labels, epochs = 6, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del final_features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def images_to_array(directory, label_dataframe, target_size = (331, 331,3)):\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]], dtype=np.uint8)\n    img = ''\n    for ix, image_name in enumerate(label_dataframe['id'].values):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img_to_array(img)\n    del img\n    return images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = time.time()\ntest_images = images_to_array('/kaggle/input/dog-breed-identification/test', sample)\nprint('runtime in seconds: {}'.format(time.time() - t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_feature = get_feature(InceptionResNetV2, resnet_preprocess, test_images)\nxception_feature = get_feature(Xception, xception_preprocess, test_images)\nnasnet_features = get_feature(NASNetLarge, nasnet_preprocessor, test_images)\ninception_feature = get_feature(InceptionV3, preprocess_input, test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_features = np.concatenate([inception_feature, nasnet_features, xception_feature, resnet_feature], axis = 1)\nprint('final features shape: {}'.format(final_features.shape))\ndel test_images, inception_feature, nasnet_features, xception_feature, resnet_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(final_features)\nsubmission = pd.DataFrame({'id':sample.id})\nprediction = pd.DataFrame(prediction)\nprediction.columns = class_to_index.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([submission, prediction], axis = 1)\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}