{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-08T11:53:25.524575Z","iopub.execute_input":"2021-06-08T11:53:25.52509Z","iopub.status.idle":"2021-06-08T11:53:53.142135Z","shell.execute_reply.started":"2021-06-08T11:53:25.52498Z","shell.execute_reply":"2021-06-08T11:53:53.140665Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standard imports\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plte\n%matplotlib inline\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:53:53.144442Z","iopub.execute_input":"2021-06-08T11:53:53.14495Z","iopub.status.idle":"2021-06-08T11:54:00.356012Z","shell.execute_reply.started":"2021-06-08T11:53:53.144902Z","shell.execute_reply":"2021-06-08T11:54:00.354856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get a look at labels","metadata":{}},{"cell_type":"code","source":"labels_csv = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\nlabels_csv.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:00.358204Z","iopub.execute_input":"2021-06-08T11:54:00.358593Z","iopub.status.idle":"2021-06-08T11:54:00.430722Z","shell.execute_reply.started":"2021-06-08T11:54:00.358557Z","shell.execute_reply":"2021-06-08T11:54:00.429435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_csv.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:00.432423Z","iopub.execute_input":"2021-06-08T11:54:00.432747Z","iopub.status.idle":"2021-06-08T11:54:00.491961Z","shell.execute_reply.started":"2021-06-08T11:54:00.432706Z","shell.execute_reply":"2021-06-08T11:54:00.490904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_csv['breed'].value_counts().plot.bar(figsize=(20,12));","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:00.493434Z","iopub.execute_input":"2021-06-08T11:54:00.493845Z","iopub.status.idle":"2021-06-08T11:54:02.874214Z","shell.execute_reply.started":"2021-06-08T11:54:00.493803Z","shell.execute_reply":"2021-06-08T11:54:02.873171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#median number of image in each class.\nlabels_csv['breed'].value_counts().median()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.875547Z","iopub.execute_input":"2021-06-08T11:54:02.875869Z","iopub.status.idle":"2021-06-08T11:54:02.889467Z","shell.execute_reply.started":"2021-06-08T11:54:02.875836Z","shell.execute_reply":"2021-06-08T11:54:02.888235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#viewing any image from the train data.\nfrom IPython.display import Image\nImage('/kaggle/input/dog-breed-identification/train/0a0c223352985ec154fd604d7ddceabd.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.890819Z","iopub.execute_input":"2021-06-08T11:54:02.891094Z","iopub.status.idle":"2021-06-08T11:54:02.910192Z","shell.execute_reply.started":"2021-06-08T11:54:02.891068Z","shell.execute_reply":"2021-06-08T11:54:02.908898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting images and their labels","metadata":{}},{"cell_type":"code","source":"filenames = ['/kaggle/input/dog-breed-identification/train/' + fname + '.jpg' for fname in labels_csv['id']]\nfilenames[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.913324Z","iopub.execute_input":"2021-06-08T11:54:02.913611Z","iopub.status.idle":"2021-06-08T11:54:02.92376Z","shell.execute_reply.started":"2021-06-08T11:54:02.913574Z","shell.execute_reply":"2021-06-08T11:54:02.923093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check wheather the the number of files matches number of actual images.\nif len(os.listdir('/kaggle/input/dog-breed-identification/train/')) == len(filenames):\n    print('Number of file matches number of actual images!')\nelse:\n    print('Number of file doesnot matches number of actual images!!')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.925142Z","iopub.execute_input":"2021-06-08T11:54:02.925413Z","iopub.status.idle":"2021-06-08T11:54:02.94368Z","shell.execute_reply.started":"2021-06-08T11:54:02.925388Z","shell.execute_reply":"2021-06-08T11:54:02.942102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing images according to their index.\nImage(filenames[900])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.945265Z","iopub.execute_input":"2021-06-08T11:54:02.945578Z","iopub.status.idle":"2021-06-08T11:54:02.965961Z","shell.execute_reply.started":"2021-06-08T11:54:02.945547Z","shell.execute_reply":"2021-06-08T11:54:02.964717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#finding the name of the above displayed dog.\nlabels_csv['breed'][900]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.967293Z","iopub.execute_input":"2021-06-08T11:54:02.96759Z","iopub.status.idle":"2021-06-08T11:54:02.974656Z","shell.execute_reply.started":"2021-06-08T11:54:02.967563Z","shell.execute_reply":"2021-06-08T11:54:02.973122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Turning our data into numbers","metadata":{}},{"cell_type":"code","source":"labels = labels_csv['breed']\nlabels = np.array(labels)\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.976546Z","iopub.execute_input":"2021-06-08T11:54:02.976989Z","iopub.status.idle":"2021-06-08T11:54:02.990009Z","shell.execute_reply.started":"2021-06-08T11:54:02.976957Z","shell.execute_reply":"2021-06-08T11:54:02.989218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check wheather the number of labels matches the number of filenames.\nif len(labels) == len(filenames):\n    print('Number of labels matches the number of filenames.')\nelse:\n    print('Number of labels doesnot matches the number of filenames')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:02.990922Z","iopub.execute_input":"2021-06-08T11:54:02.99122Z","iopub.status.idle":"2021-06-08T11:54:03.004276Z","shell.execute_reply.started":"2021-06-08T11:54:02.991193Z","shell.execute_reply":"2021-06-08T11:54:03.002997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finding the unique labels values\nunique_breed = np.unique(labels) \nunique_breed","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.005642Z","iopub.execute_input":"2021-06-08T11:54:03.005989Z","iopub.status.idle":"2021-06-08T11:54:03.031385Z","shell.execute_reply.started":"2021-06-08T11:54:03.005958Z","shell.execute_reply":"2021-06-08T11:54:03.03016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Turn single label into an array of boolean.\nprint(labels[0])\nlabels[0] == unique_breed","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.034991Z","iopub.execute_input":"2021-06-08T11:54:03.035296Z","iopub.status.idle":"2021-06-08T11:54:03.04861Z","shell.execute_reply.started":"2021-06-08T11:54:03.035266Z","shell.execute_reply":"2021-06-08T11:54:03.047094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Turning every label into an array of boolean\nboolean_labels = [labels == unique_breed for labels in labels]\nboolean_labels[:2]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.050138Z","iopub.execute_input":"2021-06-08T11:54:03.050641Z","iopub.status.idle":"2021-06-08T11:54:03.154343Z","shell.execute_reply.started":"2021-06-08T11:54:03.050609Z","shell.execute_reply":"2021-06-08T11:54:03.153198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turining boolean arrays into integers.\nprint(labels[0])   #orginal index\nprint(np.where(unique_breed==labels[0]))    #index where labels occurs.\nprint(boolean_labels[0].argmax())     #index where label occurs in boolean array\nprint(boolean_labels[0].astype(int))   #there will be a 1 where sample label occurs","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.156103Z","iopub.execute_input":"2021-06-08T11:54:03.156408Z","iopub.status.idle":"2021-06-08T11:54:03.164768Z","shell.execute_reply.started":"2021-06-08T11:54:03.156378Z","shell.execute_reply":"2021-06-08T11:54:03.163346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating our own validation set","metadata":{}},{"cell_type":"code","source":"# setup x and y variables.\nX = filenames\ny = boolean_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.166565Z","iopub.execute_input":"2021-06-08T11:54:03.167049Z","iopub.status.idle":"2021-06-08T11:54:03.179405Z","shell.execute_reply.started":"2021-06-08T11:54:03.16701Z","shell.execute_reply":"2021-06-08T11:54:03.177884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First starting with ~1000 images because we have lots of data to train for the very first attempt\n\n#set number of images to set for the experiment.\nNUM_IMAGES = 1000 #@param {type:\"slider\",min:1000,max:10000}","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.18073Z","iopub.execute_input":"2021-06-08T11:54:03.181226Z","iopub.status.idle":"2021-06-08T11:54:03.191586Z","shell.execute_reply.started":"2021-06-08T11:54:03.181183Z","shell.execute_reply":"2021-06-08T11:54:03.190858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's split our data into train and validation.\nfrom sklearn.model_selection import train_test_split\n\n#spliting into training and validation of total size NUM_IMAGES.\n\nX_train,X_val,y_train,y_val = train_test_split(X[:NUM_IMAGES],\n                                                y[:NUM_IMAGES],\n                                                test_size=0.2,\n                                                random_state=42)\nlen(X_train),len(X_val),len(y_train),len(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.192598Z","iopub.execute_input":"2021-06-08T11:54:03.193025Z","iopub.status.idle":"2021-06-08T11:54:03.94973Z","shell.execute_reply.started":"2021-06-08T11:54:03.192994Z","shell.execute_reply":"2021-06-08T11:54:03.948553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[:5],y_train[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.951127Z","iopub.execute_input":"2021-06-08T11:54:03.951406Z","iopub.status.idle":"2021-06-08T11:54:03.966027Z","shell.execute_reply.started":"2021-06-08T11:54:03.951379Z","shell.execute_reply":"2021-06-08T11:54:03.964758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Images\nTurning images into tensors\n\nLet's write a function to preprocess the image. The function will do the following tasks.\n\n    The function will take an image filepath as input.\n    Use the tensorflow to read the file and save it to the variable.\n    Turn our variable (.jpg) into tensors.\n    Normalize our image(convert color channel from 0-255 to 0-1).|\n    Resize the image.\n    Return the modified variable.\n","metadata":{}},{"cell_type":"code","source":"# converting images to numpy array\n\nfrom matplotlib.pyplot import imread\nimage = imread(filenames[42])\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.967751Z","iopub.execute_input":"2021-06-08T11:54:03.968081Z","iopub.status.idle":"2021-06-08T11:54:03.989286Z","shell.execute_reply.started":"2021-06-08T11:54:03.968053Z","shell.execute_reply":"2021-06-08T11:54:03.988209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:03.993822Z","iopub.execute_input":"2021-06-08T11:54:03.994132Z","iopub.status.idle":"2021-06-08T11:54:04.000693Z","shell.execute_reply.started":"2021-06-08T11:54:03.994103Z","shell.execute_reply":"2021-06-08T11:54:03.999903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets conver them into tensor\ntf.constant(image)[:2]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.002309Z","iopub.execute_input":"2021-06-08T11:54:04.002587Z","iopub.status.idle":"2021-06-08T11:54:04.048686Z","shell.execute_reply.started":"2021-06-08T11:54:04.00256Z","shell.execute_reply":"2021-06-08T11:54:04.04789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making a function to preprocess the data\n\n# Define image size\nIMG_SIZE = 224\n\ndef process_image(image_path):\n  \"\"\"\n  Takes an image file path and turns it into a Tensor.\n  \"\"\"\n  # Read in image file\n  image = tf.io.read_file(image_path)\n  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n  image = tf.image.decode_jpeg(image, channels=3)\n  # Convert the colour channel values from 0-225 values to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  # Resize the image to our desired size (224, 244)\n  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n  return image","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.050058Z","iopub.execute_input":"2021-06-08T11:54:04.050592Z","iopub.status.idle":"2021-06-08T11:54:04.056639Z","shell.execute_reply.started":"2021-06-08T11:54:04.050554Z","shell.execute_reply":"2021-06-08T11:54:04.05596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Turning our data into batches\n\nWhy turn our data into batches?\n\nWe are trying to fit the 10000+ data images. They all might not fit into memory.\n\nSo,that's why we use 32(this is batch size) images at a time. we can change the batch size whenever we need.\n\nIn order to use the tensorflow effective we need to convert the images into tuple tensor which looks like (image,labels)\n","metadata":{}},{"cell_type":"code","source":"# Create a simple function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n  \"\"\"\n  Takes an image file path name and the associated label,\n  processes the image and returns a tuple of (image, label).\n  \"\"\"\n  image = process_image(image_path)\n  return image, label","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.05819Z","iopub.execute_input":"2021-06-08T11:54:04.058927Z","iopub.status.idle":"2021-06-08T11:54:04.079091Z","shell.execute_reply.started":"2021-06-08T11:54:04.058882Z","shell.execute_reply":"2021-06-08T11:54:04.077851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the batch size, 32 is a good default\nBATCH_SIZE = 32\n\n# Create a function to turn data into batches\ndef create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n  \"\"\"\n  Creates batches of data out of image (x) and label (y) pairs.\n  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n  Also accepts test data as input (no labels).\n  \"\"\"\n  # If the data is a test dataset, we probably don't have labels\n  if test_data:\n    print(\"Creating test data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n    data_batch = data.map(process_image).batch(BATCH_SIZE)\n    return data_batch\n  \n  # If the data if a valid dataset, we don't need to shuffle it\n  elif valid_data:\n    print(\"Creating validation data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n    return data_batch\n\n  else:\n    # If the data is a training dataset, we shuffle it\n    print(\"Creating training data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                              tf.constant(y))) # labels\n    \n    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n    data = data.shuffle(buffer_size=len(x))\n\n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n\n    # Turn the data into batches\n    data_batch = data.batch(BATCH_SIZE)\n  return data_batch","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.081077Z","iopub.execute_input":"2021-06-08T11:54:04.081693Z","iopub.status.idle":"2021-06-08T11:54:04.094159Z","shell.execute_reply.started":"2021-06-08T11:54:04.081647Z","shell.execute_reply":"2021-06-08T11:54:04.093151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.095486Z","iopub.execute_input":"2021-06-08T11:54:04.095803Z","iopub.status.idle":"2021-06-08T11:54:04.32198Z","shell.execute_reply.started":"2021-06-08T11:54:04.095768Z","shell.execute_reply":"2021-06-08T11:54:04.320876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out the different attributes of our data batches\ntrain_data.element_spec, val_data.element_spec","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.323389Z","iopub.execute_input":"2021-06-08T11:54:04.323693Z","iopub.status.idle":"2021-06-08T11:54:04.330713Z","shell.execute_reply.started":"2021-06-08T11:54:04.323661Z","shell.execute_reply":"2021-06-08T11:54:04.329649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualisation pour comprendre les batches","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create a function for viewing images in a data batch\ndef show_25_images(images, labels):\n  \"\"\"\n  Displays 25 images from a data batch.\n  \"\"\"\n  # Setup the figure\n  plt.figure(figsize=(10, 10))\n  # Loop through 25 (for displaying 25 images)\n  for i in range(25):\n    # Create subplots (5 rows, 5 columns)\n    ax = plt.subplot(5, 5, i+1)\n    # Display an image\n    plt.imshow(images[i])\n    # Add the image label as the title\n    plt.title(unique_breed[labels[i].argmax()])\n    # Turn gird lines off\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.332208Z","iopub.execute_input":"2021-06-08T11:54:04.332515Z","iopub.status.idle":"2021-06-08T11:54:04.344108Z","shell.execute_reply.started":"2021-06-08T11:54:04.332484Z","shell.execute_reply":"2021-06-08T11:54:04.342977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize training images from the training data batch\ntrain_images, train_labels = next(train_data.as_numpy_iterator())\nshow_25_images(train_images, train_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:04.3458Z","iopub.execute_input":"2021-06-08T11:54:04.34612Z","iopub.status.idle":"2021-06-08T11:54:06.269229Z","shell.execute_reply.started":"2021-06-08T11:54:04.346091Z","shell.execute_reply":"2021-06-08T11:54:06.26836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize validation images from the validation data batch\nval_images, val_labels = next(val_data.as_numpy_iterator())\nshow_25_images(val_images, val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:06.270482Z","iopub.execute_input":"2021-06-08T11:54:06.270965Z","iopub.status.idle":"2021-06-08T11:54:08.363787Z","shell.execute_reply.started":"2021-06-08T11:54:06.270909Z","shell.execute_reply":"2021-06-08T11:54:08.362803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating and training a model.\n\nNow our data is ready now lets model our data.\n\nBefore we build a model, there are a few things we need to define:\n\n    The input shape (images, in the form of Tensors) to our model.\n    The output shape (image labels, in the form of Tensors) of our model.\n\n","metadata":{}},{"cell_type":"code","source":"# Setting up input shape to the model\nINPUT_SHAPE = [BATCH_SIZE, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n\n# Setting up output shape of the model\nOUTPUT_SHAPE = len(unique_breed) # number of unique labels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:08.365315Z","iopub.execute_input":"2021-06-08T11:54:08.3659Z","iopub.status.idle":"2021-06-08T11:54:08.37093Z","shell.execute_reply.started":"2021-06-08T11:54:08.365855Z","shell.execute_reply":"2021-06-08T11:54:08.369854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_SHAPE","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:08.372312Z","iopub.execute_input":"2021-06-08T11:54:08.372922Z","iopub.status.idle":"2021-06-08T11:54:08.38744Z","shell.execute_reply.started":"2021-06-08T11:54:08.372871Z","shell.execute_reply":"2021-06-08T11:54:08.385888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\npretrained_base = keras.applications.MobileNetV2(\n    input_shape = (224,224,3),\n    include_top=False, weights='imagenet'\n)\n\npretrained_base.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:08.389098Z","iopub.execute_input":"2021-06-08T11:54:08.389421Z","iopub.status.idle":"2021-06-08T11:54:09.810623Z","shell.execute_reply.started":"2021-06-08T11:54:08.389393Z","shell.execute_reply":"2021-06-08T11:54:09.809391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    pretrained_base,\n    layers.Flatten(),\n    #layers.Dense(6, activation='relu'),\n    layers.Dense(120, activation='softmax'),\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:09.812385Z","iopub.execute_input":"2021-06-08T11:54:09.812858Z","iopub.status.idle":"2021-06-08T11:54:10.309623Z","shell.execute_reply.started":"2021-06-08T11:54:09.812815Z","shell.execute_reply":"2021-06-08T11:54:10.30859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n      metrics=[\"accuracy\"] # We'd like this to go up\n  )","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:10.311178Z","iopub.execute_input":"2021-06-08T11:54:10.311613Z","iopub.status.idle":"2021-06-08T11:54:10.336459Z","shell.execute_reply.started":"2021-06-08T11:54:10.311567Z","shell.execute_reply":"2021-06-08T11:54:10.335037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check details of model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:10.338231Z","iopub.execute_input":"2021-06-08T11:54:10.338675Z","iopub.status.idle":"2021-06-08T11:54:10.357962Z","shell.execute_reply.started":"2021-06-08T11:54:10.338631Z","shell.execute_reply":"2021-06-08T11:54:10.357186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.01,\n    restore_best_weights=True,\n    )","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:10.358961Z","iopub.execute_input":"2021-06-08T11:54:10.359683Z","iopub.status.idle":"2021-06-08T11:54:10.363554Z","shell.execute_reply.started":"2021-06-08T11:54:10.35965Z","shell.execute_reply":"2021-06-08T11:54:10.362864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history =  model.fit(\n            x=train_data,\n            epochs=10,\n            validation_data=val_data,\n            validation_freq=1, # check validation metrics every epoch\n            verbose=1,\n            callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:54:10.364475Z","iopub.execute_input":"2021-06-08T11:54:10.364911Z","iopub.status.idle":"2021-06-08T11:58:08.263014Z","shell.execute_reply.started":"2021-06-08T11:54:10.36488Z","shell.execute_reply":"2021-06-08T11:58:08.261687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:08.264647Z","iopub.execute_input":"2021-06-08T11:58:08.264951Z","iopub.status.idle":"2021-06-08T11:58:08.453568Z","shell.execute_reply.started":"2021-06-08T11:58:08.264922Z","shell.execute_reply":"2021-06-08T11:58:08.452368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df.loc[:, ['accuracy', 'val_accuracy']].plot();","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:08.455497Z","iopub.execute_input":"2021-06-08T11:58:08.456084Z","iopub.status.idle":"2021-06-08T11:58:08.649608Z","shell.execute_reply.started":"2021-06-08T11:58:08.456024Z","shell.execute_reply":"2021-06-08T11:58:08.648571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\npredictions","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:08.651042Z","iopub.execute_input":"2021-06-08T11:58:08.65134Z","iopub.status.idle":"2021-06-08T11:58:15.282302Z","shell.execute_reply.started":"2021-06-08T11:58:08.651309Z","shell.execute_reply":"2021-06-08T11:58:15.28105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First prediction\nprint(predictions[0])\nprint(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {unique_breed[np.argmax(predictions[0])]}\") # the predicted label","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:15.283935Z","iopub.execute_input":"2021-06-08T11:58:15.284457Z","iopub.status.idle":"2021-06-08T11:58:15.292309Z","shell.execute_reply.started":"2021-06-08T11:58:15.284423Z","shell.execute_reply":"2021-06-08T11:58:15.291605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return unique_breed[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:15.293337Z","iopub.execute_input":"2021-06-08T11:58:15.293776Z","iopub.status.idle":"2021-06-08T11:58:15.304267Z","shell.execute_reply.started":"2021-06-08T11:58:15.293747Z","shell.execute_reply":"2021-06-08T11:58:15.303196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n  \"\"\"\n  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n  of images and labels.\n  \"\"\"\n  images = []\n  labels = []\n  # Loop through unbatched data\n  for image, label in data.unbatch().as_numpy_iterator():\n    images.append(image)\n    labels.append(unique_breed[np.argmax(label)])\n  return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:15.307801Z","iopub.execute_input":"2021-06-08T11:58:15.308961Z","iopub.status.idle":"2021-06-08T11:58:16.191929Z","shell.execute_reply.started":"2021-06-08T11:58:15.308917Z","shell.execute_reply":"2021-06-08T11:58:16.190715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_pred(prediction_probabilities, labels, images, n=1):\n  \"\"\"\n  View the prediction, ground truth label and image for sample n.\n  \"\"\"\n  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n  # Get the pred label\n  pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n  plt.imshow(image)\n  plt.xticks([])\n  plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\"\n\n  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:16.193383Z","iopub.execute_input":"2021-06-08T11:58:16.193721Z","iopub.status.idle":"2021-06-08T11:58:16.201279Z","shell.execute_reply.started":"2021-06-08T11:58:16.193689Z","shell.execute_reply":"2021-06-08T11:58:16.200258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View an example prediction, original image and truth label\nplot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:16.202493Z","iopub.execute_input":"2021-06-08T11:58:16.202954Z","iopub.status.idle":"2021-06-08T11:58:16.311581Z","shell.execute_reply.started":"2021-06-08T11:58:16.20291Z","shell.execute_reply":"2021-06-08T11:58:16.310836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images, n=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:16.312808Z","iopub.execute_input":"2021-06-08T11:58:16.313248Z","iopub.status.idle":"2021-06-08T11:58:16.39934Z","shell.execute_reply.started":"2021-06-08T11:58:16.313203Z","shell.execute_reply":"2021-06-08T11:58:16.398605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images, n=3)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:16.400455Z","iopub.execute_input":"2021-06-08T11:58:16.400898Z","iopub.status.idle":"2021-06-08T11:58:16.4975Z","shell.execute_reply.started":"2021-06-08T11:58:16.400854Z","shell.execute_reply":"2021-06-08T11:58:16.496816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images, n=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:58:16.498605Z","iopub.execute_input":"2021-06-08T11:58:16.499112Z","iopub.status.idle":"2021-06-08T11:58:16.595721Z","shell.execute_reply.started":"2021-06-08T11:58:16.499071Z","shell.execute_reply":"2021-06-08T11:58:16.59502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Predicted label: {unique_breed[np.argmax(predictions[0])]}\") # the predicted label","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:47:13.662207Z","iopub.execute_input":"2021-06-08T12:47:13.662674Z","iopub.status.idle":"2021-06-08T12:47:13.66867Z","shell.execute_reply.started":"2021-06-08T12:47:13.66264Z","shell.execute_reply":"2021-06-08T12:47:13.667542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:48:12.654145Z","iopub.execute_input":"2021-06-08T12:48:12.654591Z","iopub.status.idle":"2021-06-08T12:48:12.660081Z","shell.execute_reply.started":"2021-06-08T12:48:12.654553Z","shell.execute_reply":"2021-06-08T12:48:12.659364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_labels=[]\nfor i in range(200): \n    pred_labels.append(get_pred_label(predictions[i]))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:58:23.390564Z","iopub.execute_input":"2021-06-08T12:58:23.391054Z","iopub.status.idle":"2021-06-08T12:58:23.398471Z","shell.execute_reply.started":"2021-06-08T12:58:23.391018Z","shell.execute_reply":"2021-06-08T12:58:23.397224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:58:36.012076Z","iopub.execute_input":"2021-06-08T12:58:36.012578Z","iopub.status.idle":"2021-06-08T12:58:36.023242Z","shell.execute_reply.started":"2021-06-08T12:58:36.012528Z","shell.execute_reply":"2021-06-08T12:58:36.022123Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_labels=[]\nfor i in range(200): \n    true_labels.append(labels[i])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:00:17.97802Z","iopub.execute_input":"2021-06-08T13:00:17.978423Z","iopub.status.idle":"2021-06-08T13:00:17.984284Z","shell.execute_reply.started":"2021-06-08T13:00:17.978392Z","shell.execute_reply":"2021-06-08T13:00:17.983069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:00:27.090184Z","iopub.execute_input":"2021-06-08T13:00:27.090597Z","iopub.status.idle":"2021-06-08T13:00:27.104565Z","shell.execute_reply.started":"2021-06-08T13:00:27.090557Z","shell.execute_reply":"2021-06-08T13:00:27.103679Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(true_labels, pred_labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:01:04.129511Z","iopub.execute_input":"2021-06-08T13:01:04.13001Z","iopub.status.idle":"2021-06-08T13:01:04.156548Z","shell.execute_reply.started":"2021-06-08T13:01:04.129971Z","shell.execute_reply":"2021-06-08T13:01:04.155207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(true_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:04:49.372845Z","iopub.execute_input":"2021-06-08T13:04:49.37329Z","iopub.status.idle":"2021-06-08T13:04:49.38291Z","shell.execute_reply.started":"2021-06-08T13:04:49.373258Z","shell.execute_reply":"2021-06-08T13:04:49.381492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(true_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:16:47.873121Z","iopub.execute_input":"2021-06-08T13:16:47.873533Z","iopub.status.idle":"2021-06-08T13:16:47.883699Z","shell.execute_reply.started":"2021-06-08T13:16:47.873502Z","shell.execute_reply":"2021-06-08T13:16:47.882518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_labels=[]\nfor i in range(200): \n    pred_labels.append(get_pred_label(predictions[i]))\ny_test=val_labels\ny_pred=pred_labels\n#importing confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(val_labels, pred_labels)\nprint('Confusion Matrix\\n')\nprint(confusion)\n\n#importing accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T14:09:30.281298Z","iopub.execute_input":"2021-06-08T14:09:30.281638Z","iopub.status.idle":"2021-06-08T14:09:30.348359Z","shell.execute_reply.started":"2021-06-08T14:09:30.28161Z","shell.execute_reply":"2021-06-08T14:09:30.346879Z"},"trusted":true},"execution_count":null,"outputs":[]}]}