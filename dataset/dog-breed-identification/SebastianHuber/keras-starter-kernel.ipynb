{"nbformat":4,"cells":[{"execution_count":null,"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom IPython.core.debugger import set_trace\nimport cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras.layers import Dropout\nfrom keras.models import  Model\nfrom keras import optimizers\nfrom os import makedirs\nfrom os.path import join, exists, expanduser\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","metadata":{"_uuid":"29af90ddea6dc4135afd1e754684cefe2bca9abe","_cell_guid":"2539a002-800a-43d0-b96c-52af69d08a38"}},{"source":"***Show input files of dog-breed- identification***","cell_type":"markdown","metadata":{"_uuid":"e443153ba1a78e1351ad6740524c3d00d1c35549","_cell_guid":"a5d4d8e0-6461-4630-9dda-bf600e3ae430"}},{"execution_count":null,"outputs":[],"source":"!ls ../input/dog-breed-identification\n","cell_type":"code","metadata":{"_uuid":"cb79ec37199ff66574e6b4be03ce52a5967c781e","_cell_guid":"2be83c0d-0d0c-4cf0-9392-8acb5219fed9"}},{"source":"***Create dirs vor pretrained keras models***","cell_type":"markdown","metadata":{"_uuid":"fbdc8c6ca84ca8ecfb3ff2c5cf8ff1f6a97c8021","_cell_guid":"abc59e93-0c2a-4823-8649-7a6ed84d8635"}},{"execution_count":null,"outputs":[],"source":"cache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"790143b060fd8767c228ddfcc743d1d6f08c0692","_cell_guid":"f2131c68-d513-4e79-be40-2de2c665bf8e"}},{"execution_count":null,"outputs":[],"source":"!ls ../input/inceptionv3","cell_type":"code","metadata":{"_uuid":"f37bb0d824b79439f4c6e72b692c635d01ccf819","_cell_guid":"57473f9f-2b85-4328-9ab1-885fcbde467a"}},{"source":"***Copy pretrained keras model in the new dir***","cell_type":"markdown","metadata":{"_uuid":"2b995cb040c82b31c473a0e54f81fe541056f077","_cell_guid":"b4893ef5-87a0-4f4a-8a33-9082b79ca372"}},{"execution_count":null,"outputs":[],"source":"!cp  ../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 ~/.keras/models/\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"2c72f81720185606314b1cdd0646aca3a848c9f8","_cell_guid":"b59cdec4-1837-4a47-8e58-9cbc64a0e63c"}},{"execution_count":null,"outputs":[],"source":"!ls ~/.keras/models/","cell_type":"code","metadata":{"_uuid":"8bf13254c33b9bb03df8cc81a9cae195cfe0eb70","_cell_guid":"9e14a256-b04a-40c2-af53-4af2192d041c"}},{"source":"**Load CSV-File with pandas and print the first ten rows**","cell_type":"markdown","metadata":{"_uuid":"d8690d66c3d222c6ecde6221584b59cc89d916fd","_cell_guid":"153a0599-12a8-4e61-a646-cc5308f109fa"}},{"execution_count":null,"outputs":[],"source":"df_train = pd.read_csv(\"../input/dog-breed-identification/labels.csv\")\ndf_train.head(10)","cell_type":"code","metadata":{"_uuid":"97c54cb7d53e3e5bfe7b28513a3891c723d1b4ba","_cell_guid":"a9534a45-0687-4d90-a40a-4c4f2d4dec8d"}},{"source":"***Visualize trainingsdata distribution***\n","cell_type":"markdown","metadata":{"_uuid":"48ca27106d26898d7a70edb32d69b6fedcb04ba1","_cell_guid":"64b711f9-84d4-4290-89dd-f9f675343564"}},{"execution_count":null,"outputs":[],"source":"ax=pd.value_counts(df_train['breed'],ascending=True).plot(kind='barh',\n                                                       fontsize=\"40\",\n                                                       title=\"Class Distribution\",\n                                                       figsize=(50,100))\nax.set(xlabel=\"Images per class\", ylabel=\"Classes\")\nax.xaxis.label.set_size(40)\nax.yaxis.label.set_size(40)\nax.title.set_size(60)\n\n","cell_type":"code","metadata":{"_uuid":"511f4885630c4c48ae11512ebfa5029a4dd38177","_cell_guid":"3c866014-b3e8-412b-8e40-7baee04b2faf"}},{"source":"***For the sake of simplicity, we only take the 10 classes with the most images***","cell_type":"markdown","metadata":{"_uuid":"4a0ea278079886172a71f3895a09550931715c36","_cell_guid":"026d304f-9bd2-48c7-afff-9951ec416d67"}},{"execution_count":null,"outputs":[],"source":"# take a subset of the trainigsdata with die ten most frequently classes\nNUM_CLASSES=10\nprint(\"Dataset shape before: {0}\".format(df_train.shape))\nselected_breed_list = list(df_train.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\ndf_sub_train=df_train[df_train['breed'].isin(selected_breed_list)]\nprint(\"Dataset shape after: {0}\".format(df_sub_train.shape))\n\n# plot the distribution of this subset\nax=pd.value_counts(df_sub_train['breed'],ascending=True).plot(kind='barh',\n                                                       fontsize=\"40\",\n                                                       title=\"Class Distribution\",\n                                                       figsize=(50,20))\nax.set(xlabel=\"Images per class\", ylabel=\"Classes\")\nax.xaxis.label.set_size(40)\nax.yaxis.label.set_size(40)\nax.title.set_size(60)\n","cell_type":"code","metadata":{"_uuid":"fdfc4909a0d4e5c9a96a04997d5cd0aba1e3f17c","_cell_guid":"fb81ad48-8724-43cc-9201-87fedc357bd1"}},{"source":"***Load the traingingsdata***","cell_type":"markdown","metadata":{"_uuid":"de5ee485d0c52b2e772d21385ea47218066b6df3","_cell_guid":"cf4bc4b2-4272-4e5d-a84b-0ae8cea8850a"}},{"execution_count":null,"outputs":[],"source":"IMG_WIDTH=250\nIMG_Height=250\nimages=[]\nclasses=[]\ntargets_series = pd.Series(df_sub_train['breed'])\none_hot = pd.get_dummies(targets_series, sparse=True)\none_hot_labels = np.asarray(one_hot)\ni = 0\n#load training images\nfor f, breed in tqdm(df_sub_train.values):\n    img = cv2.imread('../input/dog-breed-identification/train/{}.jpg'.format(f))\n    images.append(cv2.resize(img, (IMG_WIDTH, IMG_Height)))   \n    label = one_hot_labels[i]\n    classes.append(label)\n    \n    ","cell_type":"code","metadata":{"_uuid":"865aea61e31b13309b783f5272e877c1e840cb38","_cell_guid":"ab672901-3d0e-4f69-aae9-635998eec073"}},{"source":"***Split trainigsdata in  a train and valid subset***","cell_type":"markdown","metadata":{"_uuid":"ebeb2286e5e7a9ba89c06edcb82fc4eb388835f0","_cell_guid":"adbd10ea-2437-4191-b6e3-647ffea265e7"}},{"execution_count":null,"outputs":[],"source":"classes_raw = np.array(classes, np.uint8)\nimages_raw = np.array(images, np.float32)\n\nx_train, x_valid, y_train, y_valid = train_test_split(images_raw, classes_raw, test_size=0.2, random_state=1)\n\nprint(\"Trainigsdata shape : {0}\".format(x_train.shape))\nprint(\"Trainingslabel shape : {0}\".format(y_train.shape))\nprint(\"Validdata shape : {0}\".format(x_valid.shape))\nprint(\"Validlabel shape : {0}\".format(y_valid.shape))\n","cell_type":"code","metadata":{"_uuid":"dc17854f091f7415e87dc3bd51c7e2e2fb283b49","_cell_guid":"f09aeb49-b2e5-4078-bcc5-c0cbd08b78b5"}},{"source":"*** Generate batches of images with data augmentation***","cell_type":"markdown","metadata":{"_uuid":"67132f8fc1a3fb4610af2c835ea38379e1a475db","_cell_guid":"9c44c3b7-72e0-4f1f-b977-6dbbeb884da6"}},{"execution_count":null,"outputs":[],"source":"train_datagen = ImageDataGenerator(\n        rescale=1. / 255,   \n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n       \n\nvalid_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=32)\nvalid_generator = valid_datagen.flow(x_valid, y_valid, batch_size=32)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"c8e0704894a5714450b896721801d2e8242b2461","_cell_guid":"a80da513-5816-4cac-83b3-ed5c53eccf06"}},{"source":"***Define the model***\n\n***In this case we use InceptionV3***","cell_type":"markdown","metadata":{"_uuid":"44fbd6a6b8ea6b6aa104100c02aa4ffd2522e462","_cell_guid":"d9b7ca25-5d66-4879-8685-125cf4d41380"}},{"execution_count":null,"outputs":[],"source":"base_model=InceptionV3(include_top=False, weights='imagenet', \n                        input_shape=(IMG_WIDTH, IMG_Height, 3),\n                        classes=NUM_CLASSES)\n# Adding custom Layers\nmodel = base_model.output\nmodel = Flatten()(model)\nmodel = Dense(1024, activation=\"relu\")(model)\nmodel = Dropout(0.5)(model)\nmodel = Dense(1024, activation=\"relu\")(model)\npredictions = Dense(NUM_CLASSES, activation=\"softmax\")(model)\n# creating the final model\nmodel_final = Model(input=base_model.input, output=predictions)\n# compile the model\nmodel_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),\n                           metrics=[\"accuracy\"])\n#print the model\nmodel_final.summary()","cell_type":"code","metadata":{"_uuid":"66087002484f75c17707ff67dff270fc2b8a82ce","_cell_guid":"4fcad287-66e7-499d-b244-db846c897b8e"}},{"source":"***Train the model***","cell_type":"markdown","metadata":{"_uuid":"b39c112ce0fb582a5deae861ca6f8cfd84bd0970","_cell_guid":"c1e80ff5-d3e7-47b5-8551-1228ab4d4e77"}},{"execution_count":null,"outputs":[],"source":"# Train the model\nhistory=model_final.fit_generator(\n        train_generator,\n        samples_per_epoch=912,\n        epochs=100,\n        validation_data=valid_generator,\n        nb_val_samples=229)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"11a389d8ef055077957f2ce1f02a3afbbb703ed8","_cell_guid":"c6b9c9e8-4a9e-47a3-a523-a3685ac27504"}},{"source":"Result after training: loss:  loss: 0.2278 - acc: 0.9297 - val_loss: 0.2109 - val_acc: 0.9212\n","cell_type":"markdown","metadata":{"_uuid":"6ed19ccb678055f536c1a92d2e471b9d61c67057","_cell_guid":"c0fe7180-5045-4394-aae6-4f53c7c0dd0c"}},{"source":"***Plot the acc and loss***","cell_type":"markdown","metadata":{"_uuid":"a9d82a60d6e9cd2b9e945753820e19562188053e","_cell_guid":"ac7a82bc-1b79-403b-a803-234b3e58160b"}},{"execution_count":null,"outputs":[],"source":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","cell_type":"code","metadata":{"collapsed":true,"_uuid":"5ecaf96009b44774d422701b25fab445e6b3da92","_cell_guid":"adc61cf1-3511-4989-ba75-0d5f2c4c57c0"}},{"source":"","cell_type":"markdown","metadata":{"_uuid":"13dba3fdfed7d7d7a57e51da3c2ebd157a7c91a1","_cell_guid":"3585626a-3646-4c84-8a99-6beceff8fa64"}},{"source":"To improve the accuracy increase the image size","cell_type":"markdown","metadata":{"_uuid":"813fabde67cc5e55ded4248d79029d1e07bf9862","_cell_guid":"6bed8d16-98ea-4d14-95cc-0c7538014fd1"}}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.6.3","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python","name":"python"}},"nbformat_minor":1}