{"cells":[{"metadata":{"_uuid":"567d822a77b80f27f2b43c314796b8da76a08bf8"},"cell_type":"markdown","source":"\n**Forked from** https://www.kaggle.com/orangutan/keras-vgg19-starter\n\n**For details**,.. https://www.kaggle.com/c/dog-breed-identification\n"},{"metadata":{"_cell_guid":"8a7bff8d-c95a-4cfb-8c38-14ab989f769b","_uuid":"4da5a3e7db32799ca0108576e469157094d23111","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten,  Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.preprocessing.image import img_to_array, load_img\n\n\nimport os\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport sys\nimport bcolz\nimport random\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b8fddbc-447f-4083-88c4-9bd5f811253d","_uuid":"7c64ad63b95b36df5a2223b4c499c1caad9c73ee"},"cell_type":"markdown","source":"First we will read in the csv's so we can see some more information on the filenames and breeds"},{"metadata":{"_cell_guid":"bcbeef91-f00e-4a68-b1b8-25e206027bb2","_uuid":"18e9091e9a3d851fb0ce796a3b537ffb7f47c874","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/dog-breed-identification/labels.csv')\ndf_test = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6abe20dc-a411-4334-ad66-2526d99c7f63","_uuid":"0ba75a32f91650bc75440443ab3d11c35e44e1c9","trusted":true},"cell_type":"code","source":"df_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20c0da740a007aa6df69ca63e1fa645d157929cf"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom mpl_toolkits.axes_grid1 import ImageGrid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92350610e9da8b22926d8b2f7985e7038d024b38"},"cell_type":"code","source":"train_files = glob('../input/dog-breed-identification/train/*.jpg')\ntest_files = glob('../input/dog-breed-identification/test/*.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b673e68df37d6cc3686f91f7adc3405391548035","scrolled":true},"cell_type":"code","source":"plt.imshow(plt.imread(train_files[100]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ba5da72-9d82-404d-aa25-ce9739a45775","_uuid":"7fbb53109a3d08bedb1abac074f8186bdea991ac","trusted":true},"cell_type":"code","source":"targets_series = pd.Series(df_train['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)\none_hot_labels = np.asarray(one_hot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b4b0a25f14f055e766b4596ea2fa05f96546962"},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"421885e6-97a5-4a43-bdf5-6b60cfc0b3d3","_uuid":"d59fb275c2e30a410c9c8af8489f38138b1513ac"},"cell_type":"markdown","source":"Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to,  90x90 px, you should play with this number to see how it affects accuracy."},{"metadata":{"_cell_guid":"0e89e3ca-7c9e-4f76-aaf8-8c5267e3a415","_uuid":"7b47e6524b0fcf5ccb9a237cbdc8d444ff215dfb","trusted":true},"cell_type":"code","source":"im_size = 400","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc632b19-d7c8-4c78-b5bf-4f0313603c11","_uuid":"e7f00cc68bbb5b9b15ee3373361bab01287476ce","trusted":true},"cell_type":"code","source":"y_train = []\ny_val = []\n\nx_train_raw = bcolz.zeros((0,im_size,im_size,3),np.float32)\nx_val_raw = bcolz.zeros((0,im_size,im_size,3),np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98aab483-199c-451b-80a9-a9c1cf3d02be","_uuid":"1f099a6a4d6b16ed3202a91d5376b77579664d04","trusted":true},"cell_type":"code","source":"i = 0 \nfor f, breed in tqdm(df_train.values):\n    # load an image from file\n    image = load_img('../input/dog-breed-identification/train/{}.jpg'.format(f), target_size=(im_size, im_size))\n    image = img_to_array(image)\n    # prepare the image for the VGG model\n    #image = preprocess_input(image)\n    label = one_hot_labels[i]\n    if random.randint(1,101) < 80: \n        x_train_raw.append(image)\n        y_train.append(label)\n    else:\n        x_val_raw.append(image)\n        y_val.append(label)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d7dccd3d-9369-4b7c-b589-97f4bd299cd2","_uuid":"29804cc313366d5ac155dead1c37fabbc036a4ad","trusted":true},"cell_type":"code","source":"y_train_raw = np.array(y_train, np.uint8)\ny_val_raw = np.array(y_val, np.uint8)\ndel(y_train,y_val)\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad4bb94f-2464-4685-9b44-32f5502e224a","_uuid":"0e64cd331abd85c517cf870d41b2440b200a54f1"},"cell_type":"markdown","source":"We check the shape of the outputs to make sure everyting went as expected."},{"metadata":{"_cell_guid":"b26f825e-8c02-43d9-9d1d-3e0092d69d26","_uuid":"a5dddeebe7556cecf31da047693710179ce29f98","trusted":true},"cell_type":"code","source":"print(x_train_raw.shape)\nprint(y_train_raw.shape)\nprint(x_val_raw.shape)\nprint(y_val_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8586a5da8a6028f8618bf16014c36f3cb52d7e6f"},"cell_type":"code","source":"def plotImages( images_arr, n_images=4):\n    fig, axes = plt.subplots(n_images, n_images, figsize=(12,12))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow( img)\n        ax.set_xticks(())\n        ax.set_yticks(())\n    plt.tight_layout()\nplotImages(x_train_raw[0:16,]/255.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"900eeb548709654f4530d0f29d06e5790d04c27a"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n#         width_shift_range=0.2,\n#         height_shift_range=0.2,\n#         shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3c6de3f8-d801-4cde-8877-db415b61da8e","_uuid":"70495031a1e6789f8784b4a0c1c2919df4896722"},"cell_type":"markdown","source":"\nWe can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."},{"metadata":{"_cell_guid":"60707a5f-0689-4ecf-a0df-3e3e9c76e076","_uuid":"00fdfb9bf52e9f7a8030d88dfab823262c0f1dc2","trusted":true},"cell_type":"code","source":"num_class = y_train_raw.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fd2dec22-e057-433b-81ba-f1d8a7580b8e","_uuid":"116f3d718f6bf256eb0a2992c344e5f52f9be181","trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfac5d44a9e41601954777a2c2292fe6f6b174fd"},"cell_type":"code","source":"del(x_train_raw)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8752f7abf35b6008e6de770f2afb22d839549228"},"cell_type":"code","source":"# Create the base pre-trained model\nbase_model = VGG19(weights = 'imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n#base_model = ResNet50(weights = 'imagenet', include_top=False, input_shape=(im_size, im_size, 3))\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75a4da8837aad5686bc11b73a8530131b2468f14"},"cell_type":"code","source":"len(base_model.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33175d738fabfe877440e0d2c1e5b394b5076b5f"},"cell_type":"code","source":"layers_to_remove = 2\nif layers_to_remove >0:\n    for i in range(0,layers_to_remove):\n        base_model.layers.pop()\n    base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b6e311de1f508c48d50e3f8dae9f4a3d316d449"},"cell_type":"code","source":"fine_tuning_layers = 0\nlayers_to_freeze = len(base_model.layers) - fine_tuning_layers\nprint(layers_to_freeze)\n\nfor layer in base_model.layers[0:layers_to_freeze]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"decf1fdf-5a24-41cd-b9b3-d49825efec82","_uuid":"0946091bb67a488a05f9e39e8dac432b485eb70a","trusted":true},"cell_type":"code","source":"# Add a new top layer\nx = base_model.layers[layers_to_freeze-1+fine_tuning_layers].output\nx = Dropout(0.4)(x)\nx = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(x)\nx = Conv2D(32, (5, 5), padding='same')(x)\nx = Dropout(0.4)(x)\nx = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(x)\nx = Dropout(0.4)(x)\nx = Conv2D(16, (2, 2), padding='same')(x)\n\nx = Flatten()(x)\n\n#x = Dense(64, activation='relu')(x)\nx = Dropout(0.4)(x)\npredictions = Dense(num_class, activation='softmax')(x)\n\n# This is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30980d88497bbc455f5398e91c05a85e8193f3a6"},"cell_type":"code","source":"batch_size = 16\nfilepath=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, verbose=1),checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4978ca0c4a8cece9a4d33795653e175599b9a25"},"cell_type":"code","source":"K.get_value(model.optimizer.lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d9f4bc9752de00a24c4de57fe32c55a995a808d"},"cell_type":"code","source":"model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n          steps_per_epoch=  X_train.shape[0]//batch_size,\n          epochs=2,\n          verbose=1,validation_data=(X_valid, Y_valid))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2580ad4a-8c2a-4b7c-bef1-e39293b0b02c","_uuid":"5183ff91d3f3179aeeff320d81299a3cf1f2a852","trusted":true},"cell_type":"code","source":"K.set_value(model.optimizer.lr, 0.001)\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n          steps_per_epoch=  X_train.shape[0]//batch_size,\n          epochs=3,\n          verbose=1,validation_data=(X_valid, Y_valid),callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2378a860757e5cd45f7f8358e053abb6e32014b"},"cell_type":"code","source":"for f in tqdm(df_test['id'].values):\n    img = cv2.imread('../input/dog-breed-identification/test/{}.jpg'.format(f))\n    x_test.append(cv2.resize(img, (im_size, im_size)))\nx_test  = np.array(x_test, np.float32) / 255.\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dd591de9eee0d58d7f8d29a9659fafc49ff850d"},"cell_type":"code","source":"model.load_weights(\"weights.best.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f72763e1-68b6-4e54-9b80-ff0f4f94aa28","_uuid":"e8a63ce4e324f3e011b3de7fc459301337d1b8d0","trusted":true},"cell_type":"code","source":"preds = model.predict(x_test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0457a19d-0e26-4619-a3c8-78c71e7d41e6","_uuid":"626b762d81d28ff77032658092d5bd9523b186b1","trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(preds)\n# Set column names to those generated by the one-hot encoding earlier\ncol_names = one_hot.columns.values\nsub.columns = col_names\n# Insert the column id from the sample_submission at the start of the data frame\nsub.insert(0, 'id', df_test['id'])\nsub.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68b399930152e3e44e4df41aebf60173acbcc8a4"},"cell_type":"code","source":"%pwd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a4ed0f81-8675-4a10-8b19-2d3ef191afe2","_uuid":"b72af806cbbdea33edd7f73d24dbe9b9cbaae805","trusted":true},"cell_type":"code","source":"sub.to_csv(\"My first submission.csv\",index =False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}