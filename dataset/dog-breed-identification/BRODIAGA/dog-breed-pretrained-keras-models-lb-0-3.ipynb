{"cells":[{"metadata":{"_uuid":"b30a120404b8e104774a292b45f0902e89acef68","_cell_guid":"657faca0-c88f-4138-8c62-cf9974e0c894"},"cell_type":"markdown","source":"# Transfer learning with pretrained Keras models\n\nAlthough Kernel resources were increased recently we still can not train useful CNNs without GPU. The original ImageNet set has quite a few different dog classes so we can reuse CNNs with pretrained ImageNet weights. Fortunately prediction is much faster (<1s/image) making it possible to run meaningful experiments with Kaggle Kernels."},{"metadata":{"_uuid":"151b0f031d10c081017bee0831d1e276148b413b","_cell_guid":"d4c4a3a8-93af-4cd2-a95b-32a2526ac3a2","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\nfrom tqdm import tqdm\nfrom sklearn.metrics import log_loss, accuracy_score, f1_score\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications import xception\nfrom keras.applications import inception_v3\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"928b27a4686daca6a69bcf74bb592c9e99393992","_cell_guid":"c60a6481-e35a-49fd-b1b3-4c74f4adc472","trusted":true},"cell_type":"code","source":"start = dt.datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21279ccec131b58e04cca5516041df6046693ec1","_cell_guid":"9ed0e437-74af-4568-8d15-342e9adcdb5d"},"cell_type":"markdown","source":"# Use Keras Pretrained Models dataset\n\nKernels can't use network connection to download pretrained keras model weights.\nThis dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \nYou can find more details [here](https://www.kaggle.com/gaborfodor/keras-pretrained-models).\n\nWe have to copy the pretrained models to the cache directory (~/.keras/models) where keras is looking for them.\n"},{"metadata":{"_uuid":"4838c6bd2565ff67ce2c47ba014035c7f70a9018","_cell_guid":"d2bdd2f5-2395-43ef-a971-5472066a0d36","trusted":true},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ac04695a27c65eccb786d1e48fe229a3c1e288a8","_cell_guid":"482686db-3424-4b64-86b9-119563d77940","trusted":true},"cell_type":"code","source":"cache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"463b5222d5affca14b75657257f0efeb40be4ea0","_cell_guid":"ed6bb30d-f37b-4662-a1c4-ed02974204aa","trusted":true},"cell_type":"code","source":"!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7506ec54c661024a9636fb247f4a05473aa9982d","_cell_guid":"c357ada4-644c-403a-ba61-0a84c9510a89","trusted":true},"cell_type":"code","source":"!ls ~/.keras/models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db9e42caac1312e22a6d4b0d3eec804c74e17e16","_cell_guid":"aa2e9829-2f0e-43ef-bc30-1023bca24579","trusted":true},"cell_type":"code","source":"!ls ../input/dog-breed-identification","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48c9f0e65f26fa26375dd32289f9c59bd1353d1a","_cell_guid":"7024f870-2c6f-4b86-a64e-adab46e34c1b"},"cell_type":"markdown","source":"# Use top 16 classes\nUsing all the images would take more than the 1 hour kernel limit. Let's focus on the most frequent 16 breeds."},{"metadata":{"_uuid":"3f62e82d998e8b2ba3999542492e632c5083a901","_cell_guid":"8bcb2bda-88dc-4ad8-9177-0c126401c3e1","trusted":true},"cell_type":"code","source":"INPUT_SIZE = 224\nNUM_CLASSES = 16\nSEED = 1987\ndata_dir = '../input/dog-breed-identification'\nlabels = pd.read_csv(join(data_dir, 'labels.csv'))\nsample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\nprint(len(listdir(join(data_dir, 'train'))), len(labels))\nprint(len(listdir(join(data_dir, 'test'))), len(sample_submission))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab322ce7a697d43a883b1725c7f71bf4486fd5ed","_cell_guid":"f55b18df-3698-4146-9157-913227416e21","trusted":true,"collapsed":true},"cell_type":"code","source":"selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\nlabels = labels[labels['breed'].isin(selected_breed_list)]\nlabels['target'] = 1\nlabels['rank'] = labels.groupby('breed').rank()['id']\nlabels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\nnp.random.seed(seed=SEED)\nrnd = np.random.random(len(labels))\ntrain_idx = rnd < 0.8\nvalid_idx = rnd >= 0.8\ny_train = labels_pivot[selected_breed_list].values\nytr = y_train[train_idx]\nyv = y_train[valid_idx]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7d26cc67909b5bd70173b5f2ed8352b210e06fb3","_cell_guid":"c48fc864-d70f-4045-96eb-12de12c0ad41","trusted":true},"cell_type":"code","source":"def read_img(img_id, train_or_test, size):\n    \"\"\"Read and resize image.\n    # Arguments\n        img_id: string\n        train_or_test: string 'train' or 'test'.\n        size: resize the original image.\n    # Returns\n        Image as numpy array.\n    \"\"\"\n    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n    img = image.img_to_array(img)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd270f61ff0278c9171592f4999513b460f8f262","_cell_guid":"5759352a-e324-468c-b0b9-b360962a823f"},"cell_type":"markdown","source":"# Extract VGG16 bottleneck features"},{"metadata":{"_uuid":"db4f7052673aa28ca7822b9030dba078a6afb878","_cell_guid":"62de53fc-18b6-45f4-8ec3-14a3287b2015","trusted":true},"cell_type":"code","source":"INPUT_SIZE = 224\nPOOLING = 'avg'\nx_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, img_id in tqdm(enumerate(labels['id'])):\n    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_train[i] = x\nprint('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11bfa7db44dc81846a939f2c5259b283bbb7f9e4","_cell_guid":"ff0176f1-60a6-4487-9df4-438f3604e4b8","trusted":true},"cell_type":"code","source":"Xtr = x_train[train_idx]\nXv = x_train[valid_idx]\nprint((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\nvgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\ntrain_vgg_bf = vgg_bottleneck.predict(Xtr, batch_size=32, verbose=1)\nvalid_vgg_bf = vgg_bottleneck.predict(Xv, batch_size=32, verbose=1)\nprint('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\nprint('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8adbc32293a65ff184b659282e3c9a4a5eba64af","_cell_guid":"68b9963a-e2cd-463c-8708-11d2685e0eb2"},"cell_type":"markdown","source":"# LogReg on VGG bottleneck features"},{"metadata":{"_uuid":"6af396744a3c6d41f8256f993e60389d67e2ab52","_cell_guid":"90569f5c-b196-4104-9089-43d8b8ddd12b","trusted":true,"collapsed":true},"cell_type":"code","source":"logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(train_vgg_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\nvalid_probs = logreg.predict_proba(valid_vgg_bf)\nvalid_preds = logreg.predict(valid_vgg_bf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_result = []\nfor i in range(len(yv)):\n    for j in range(len(yv[i])):\n        if yv[i][j] == 1:\n            test_result.append(j)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4213c70e4a252cfae11f792aad256664258bb6be","_cell_guid":"c92cf2e3-bd0f-44f4-932a-8fec12bf95ea","trusted":true},"cell_type":"code","source":"print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))\nprint('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f1_score(test_result,valid_preds , average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_breeds = (yv * range(NUM_CLASSES)).sum(axis=1)\nerror_idx = (valid_breeds == valid_preds)\nfor img_id, breed, pred in zip(labels.loc[valid_idx, 'id'].values,\n                                [selected_breed_list[int(b)] for b in valid_preds[valid_idx]],\n                                [selected_breed_list[int(b)] for b in valid_breeds[valid_idx]]):\n    fig, ax = plt.subplots(figsize=(5,5))\n    img = read_img(img_id, 'train', (299, 299))\n    ax.imshow(img / 255.)\n    ax.text(10, 250, 'Prediction: %s' % pred, color='w', backgroundcolor='k', alpha=0.8)\n    ax.text(10, 270, 'LABEL: %s' % breed, color='k', backgroundcolor='w', alpha=0.8)\n    ax.axis('off')\n    plt.show()  ","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","version":"3.6.3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}