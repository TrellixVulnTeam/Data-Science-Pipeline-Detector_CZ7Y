{"cells":[{"outputs":[],"metadata":{"_uuid":"203bcca41381459a1204a90977611ae3985a5c1a","_cell_guid":"e6a4439f-d488-4a7c-843c-bc321ae6d317"},"cell_type":"code","source":"import os \nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2\nimport pathlib\nimport shutil\nfrom keras.optimizers import Adam\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Activation,Dense,Flatten\nfrom keras.layers import Dropout\nfrom keras.models import Sequential,load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping","execution_count":1},{"outputs":[],"metadata":{"_uuid":"c3e8d663c45646828abc058375d95fb107584184","_cell_guid":"2fa8f466-dadf-49f7-b2a5-2512d915bbf7"},"cell_type":"code","source":"#Dividing photos according to breed in appropriate folders (total 120 breed so 120 folders)\ndf_train = pd.read_csv('../input/labels.csv')\ntargets_series = pd.Series(df_train['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)\none_hot_labels = np.asarray(one_hot)\ni = 0 \nfor f, breed in tqdm(df_train.values):\n    pathlib.Path('kaggle.com/syedfaizalex/Dog_Breed_data/{}'.format(breed)).mkdir(parents=True,\n                                                                                  exist_ok=True)\n    shutil.copy('../input/train/{}.jpg'.format(f),\n                'kaggle.com/syedfaizalex/Dog_Breed_data/{}/{}.jpg'.format(breed,f))\n    ","execution_count":2},{"outputs":[],"metadata":{"_uuid":"182193c063d813f277ebb500862e682c00b5a47f","_cell_guid":"35f4e064-98c1-4e80-982a-c00a5da63cf7"},"cell_type":"code","source":"#Moving 10% photos of each class for validation Dataset\n#taking folder names available in folder \"Dog_Breed_data\" in variable ls\nls = os.listdir('kaggle.com/syedfaizalex/Dog_Breed_data')\nfor i in tqdm(ls):        \n    count = 0\n    n =  len(os.listdir('kaggle.com/syedfaizalex/Dog_Breed_data/'+i))\n    #taking only 10% photos from each folder/breed for validation\n    n = int((n*10)/100)\n    for j in os.listdir('kaggle.com/syedfaizalex/Dog_Breed_data/'+i):\n        pathlib.Path('kaggle.com/syedfaizalex/Val-Dog-Breed/'+i).mkdir(parents=True, exist_ok=True)\n        count+=1 \n        if count < n:\n            shutil.move('kaggle.com/syedfaizalex/Dog_Breed_data/{}/{}'.format(i,j),\n                        'kaggle.com/syedfaizalex/Val-Dog-Breed/{}/{}'.format(i,j))\n        else:\n            break ","execution_count":3},{"outputs":[],"metadata":{"_uuid":"426cd8d23d310c86740347375acd9a44c56dc439","_cell_guid":"a02f9146-a7bd-4730-ba5d-a23afe0b8036"},"cell_type":"code","source":"#Using Keras ImageDataGenerator to apply Data augmentation technique in order to increase dataset\nprint(\"For Training\")\ntrain_x = ImageDataGenerator(rescale=1/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntrain = train_x.flow_from_directory(directory='kaggle.com/syedfaizalex/Dog_Breed_data/',\n                                    batch_size=32,target_size=(320,320)) \nprint(\"For Validation\")\nvalid = ImageDataGenerator(rescale=1/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nvalid = valid.flow_from_directory(directory='kaggle.com/syedfaizalex/Val-Dog-Breed',\n                                  batch_size=32,target_size=(320,320)) \n","execution_count":4},{"outputs":[],"metadata":{"_uuid":"cb64d9deb99dee42c4d347c20c6aa55de4f20f40","_cell_guid":"8d2372b8-db47-4112-9e96-52ec0d7d3f26"},"cell_type":"code","source":"#Lets check class indices\nprint(train.class_indices)","execution_count":5},{"outputs":[],"metadata":{"_uuid":"7c8e0449b75bea2c9a95c19f002ad69705634f89","scrolled":false,"_cell_guid":"12e77a70-9093-46f5-bfe9-01d546f847f4"},"cell_type":"code","source":"#Tranfer Learning With InceptionV3\nmodel_base = InceptionV3(weights='imagenet',include_top=False,input_shape=(320,320,3))\nfor i in model_base.layers:\n    i.trainable = False\nmodel = Sequential()\nmodel.add(model_base)\nmodel.add(Flatten())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(120))\nmodel.add(Activation('softmax'))\nadam=Adam(lr=0.0001)\nmodel.compile(optimizer=adam,loss=\"categorical_crossentropy\",metrics=['accuracy'])\ncb1 = ModelCheckpoint(filepath='kaggle.com/syedfaizalex/checkpoint_120_InceptionV3_12-29_3.h5',\n                      save_best_only=True)\n#Each epoch will take approx. 25Hours if used powerful machines\n#after 2-3 epoch you may achieve more than 85% val-acc and more than 95% train acc\nhistory = model.fit_generator(train,validation_data=valid,callbacks=[cb1],\n                              steps_per_epoch=9374,epochs=5,validation_steps=848,initial_epoch=0)\nhistory =  pd.DataFrame(history.history).to_csv('kaggle.com/syedfaizalex/trainHistoryDict.csv')\nmodel.save(filepath='kaggle.com/syedfaizalex/CNN_KaggleOnly_Inception_12-31_3.h5')","execution_count":6}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"nbconvert_exporter":"python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}