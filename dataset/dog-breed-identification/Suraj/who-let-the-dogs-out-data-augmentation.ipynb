{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten,  Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras import backend as K\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import load_img\n#from keras.applications.vgg16 import preprocess_input\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nimport os\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport sys\nimport bcolz\nimport random\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the train and test files which has the image file name and associated labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/labels.csv')\ndf_test = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the top 10 rows"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing necessary python packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom mpl_toolkits.axes_grid1 import ImageGrid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the all the images in input directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files = glob('../input/train/*.jpg')\ntest_files = glob('../input/test/*.jpg')\ntrain_files[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying one of the images"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(plt.imread(train_files[100]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot coding of target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_series = pd.Series(df_train['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)\none_hot_labels = np.asarray(one_hot)\none_hot_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_size = 300","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating array for train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = []\ny_val = []\nx_train_raw = bcolz.zeros((0,im_size,im_size,3),np.float32)\nx_val_raw = bcolz.zeros((0,im_size,im_size,3),np.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading all images into array for train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_label=[]\ni = 0 \nfor f, breed in tqdm(df_train.values):\n    # load an image from file\n    image = load_img('../input/train/{}.jpg'.format(f), target_size=(im_size, im_size))\n    image = img_to_array(image)\n    # prepare the image for the VGG model\n    #image = preprocess_input(image)\n    label = one_hot_labels[i]\n    if random.randint(1,101) < 80: \n        x_train_raw.append(image)\n        y_train.append(label)\n        y_train_label.append(breed)\n    else:\n        x_val_raw.append(image)\n        y_val.append(label)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_raw = np.array(y_train, np.uint8)\ny_val_raw = np.array(y_val, np.uint8)\n#del(y_train,y_val)\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checkng the shape of train and test arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train_raw.shape)\nprint(y_train_raw.shape)\nprint(x_val_raw.shape)\nprint(y_val_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying some of the images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotImages( images_arr, n_images=4):\n    fig, axes = plt.subplots(n_images, n_images, figsize=(12,12))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.set_xticks(())\n        ax.set_yticks(())\n    plt.tight_layout()\nplotImages(x_train_raw[0:16,]/255.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_class = y_train_raw.shape[1]\nnum_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=2\nresize_factor=0.8","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data augmentation by cropping and flipping of images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def augmentation(x_train_raw,y_train_raw,batch_size,resize_factor):\n    \n    datagen = ImageDataGenerator()\n    data_aug = np.zeros((batch_size,int(im_size*resize_factor),int(im_size*resize_factor),3),dtype=np.float32)\n\n    rand_samp=random.sample(list(np.arange(0,x_train_raw.shape[0])),batch_size)\n    print (rand_samp)\n\n#cropping\n    for i in range(0,len(rand_samp)):\n    #top_left\n        if random.randint(1,101) < 20:\n            data_aug[i]=x_train_raw[rand_samp[i],0:int(im_size*resize_factor),\n                                    0:int(im_size*resize_factor), : ]\n            print ('top_left')\n            \n    #top_right    \n        elif random.randint(1,101) < 20:\n            data_aug[i]=x_train_raw[rand_samp[i],0:int(im_size*resize_factor),\n                                im_size-int(im_size*resize_factor):im_size, : ]\n            print ('top_right')\n            \n    #bottom_left \n        elif random.randint(1,101) < 20:\n            data_aug[i]=x_train_raw[rand_samp[i],im_size-int(im_size*resize_factor):im_size,\n                                0:int(im_size*resize_factor), : ]\n            print ('bottom_left')\n            \n    #bottom_right\n        elif random.randint(1,101) < 20:\n            data_aug[i]=x_train_raw[rand_samp[i],im_size-int(im_size*resize_factor):im_size,\n                                im_size-int(im_size*resize_factor):im_size, : ]\n            print ('bottom_right')\n                \n    #center\n        else:\n            data_aug[i]=x_train_raw[rand_samp[i],30:im_size-30,30:im_size-30, : ]\n            print ('center')\n        \n#flipping\n        if random.randint(1,101) < 50: \n            flip_horizontal = True\n        else:\n            flip_horizontal = False\n        if random.randint(1,101) < 50: \n            flip_vertical = True\n        else:\n            flip_vertical = False\n  \n        data_aug[i] = datagen.apply_transform(data_aug[i],{\n            'flip_horizontal':flip_horizontal,\n            'flip_vertical':flip_vertical,\n            })\n\n#displaying the actual images\n#     plt.title(y_train_label[rand_samp[i]])\n#     plt.imshow(x_train_raw[rand_samp[i],]/255.0)\n\n#displaying the cropped and flipped images    \n    def plotImages(images_arr, n_images=2):\n        fig, axes = plt.subplots(n_images-1, n_images, figsize=(12,12))\n        axes = axes.flatten()\n        for img, ax in zip( images_arr, axes ):\n            ax.imshow(img)\n            ax.set_xticks(())\n            ax.set_yticks(())\n            plt.tight_layout()\n            \n    plotImages(x_train_raw[rand_samp,]/255.)    #actaul images\n    plotImages(data_aug[:,]/255.)               #cropped images\n        \naugmentation(x_train_raw, y_train_raw,batch_size,resize_factor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}