{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-23T09:01:42.287621Z","iopub.execute_input":"2022-06-23T09:01:42.28827Z","iopub.status.idle":"2022-06-23T09:02:02.407543Z","shell.execute_reply.started":"2022-06-23T09:01:42.288161Z","shell.execute_reply":"2022-06-23T09:02:02.406834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing required libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tqdm.autonotebook import tqdm\n\nimport numpy as np \nimport pandas as pd \n\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\n\nfrom tensorflow.keras.optimizers import Adam,SGD \nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\n# from keras import regularizers\nfrom tensorflow.keras.models import Model\n\nfrom keras.preprocessing.image import load_img\n# from keras.preprocessing.image import img_to_array\n# from keras.applications.imagenet_utils import decode_predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:02.409174Z","iopub.execute_input":"2022-06-23T09:02:02.409439Z","iopub.status.idle":"2022-06-23T09:02:08.541706Z","shell.execute_reply.started":"2022-06-23T09:02:02.409404Z","shell.execute_reply":"2022-06-23T09:02:08.540793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for GPU\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\ntf.config.list_physical_devices(\"GPU\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:08.546129Z","iopub.execute_input":"2022-06-23T09:02:08.548636Z","iopub.status.idle":"2022-06-23T09:02:08.861379Z","shell.execute_reply.started":"2022-06-23T09:02:08.548595Z","shell.execute_reply":"2022-06-23T09:02:08.858675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=pd.read_csv(\"../input/dog-breed-identification/labels.csv\")\nlabels.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:08.862781Z","iopub.execute_input":"2022-06-23T09:02:08.863376Z","iopub.status.idle":"2022-06-23T09:02:08.905032Z","shell.execute_reply.started":"2022-06-23T09:02:08.863332Z","shell.execute_reply":"2022-06-23T09:02:08.904218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#describe\nlabels.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:08.907438Z","iopub.execute_input":"2022-06-23T09:02:08.908185Z","iopub.status.idle":"2022-06-23T09:02:08.935158Z","shell.execute_reply.started":"2022-06-23T09:02:08.908138Z","shell.execute_reply":"2022-06-23T09:02:08.934484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show bar length\ndef barw(ax):\n    for p in ax.patches:\n        val=p.get_width()#height of the bar\n        x=p.get_x()+p.get_width()#x- position\n        y=p.get_y()+p.get_height()/2#y-position\n        ax.annotate(round(val,2),(x,y))\n        \n#finding top dog breed\nplt.figure(figsize=(15,30))\nax0 =sns.countplot(y=labels['breed'],order=labels['breed'].value_counts().index)\nbarw(ax0)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:08.936187Z","iopub.execute_input":"2022-06-23T09:02:08.93644Z","iopub.status.idle":"2022-06-23T09:02:11.714085Z","shell.execute_reply.started":"2022-06-23T09:02:08.936406Z","shell.execute_reply":"2022-06-23T09:02:11.713443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #total unique breeds\n\nlabels['breed'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:11.716868Z","iopub.execute_input":"2022-06-23T09:02:11.717655Z","iopub.status.idle":"2022-06-23T09:02:11.73007Z","shell.execute_reply.started":"2022-06-23T09:02:11.717615Z","shell.execute_reply":"2022-06-23T09:02:11.72935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display,Image\nImage(\"../input/dog-breed-identification/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:11.731933Z","iopub.execute_input":"2022-06-23T09:02:11.736018Z","iopub.status.idle":"2022-06-23T09:02:11.753243Z","shell.execute_reply.started":"2022-06-23T09:02:11.735981Z","shell.execute_reply":"2022-06-23T09:02:11.752613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nif len(os.listdir(\"../input/dog-breed-identification/train\"))==len(labels[\"id\"]):\n    print('Number of file matches number of actual images!')\nelse:\n    print('Number of file does not matches number of actual images!')","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:11.754506Z","iopub.execute_input":"2022-06-23T09:02:11.755132Z","iopub.status.idle":"2022-06-23T09:02:11.773309Z","shell.execute_reply.started":"2022-06-23T09:02:11.755097Z","shell.execute_reply":"2022-06-23T09:02:11.772538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create list of alphabetically sorted labels.\nclasses=sorted(list(set(labels[\"breed\"])))\nn_classes=len(classes)\nprint(\"Total unique breed{}\".format(n_classes))\n\n#map each label string to integer label.\nclass_to_num=dict(zip(classes,range(n_classes)))\nclass_to_num","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:11.774245Z","iopub.execute_input":"2022-06-23T09:02:11.774484Z","iopub.status.idle":"2022-06-23T09:02:11.795019Z","shell.execute_reply.started":"2022-06-23T09:02:11.774453Z","shell.execute_reply":"2022-06-23T09:02:11.79313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one hot encoding\ninput_shape = (331,331,3)\n\n\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n#         img = np.expand_dims(img, axis=0)\n#         img = processed_image_resnet(img)\n#         img = img/255\n        images[ix]=img\n#         images[ix] = img_to_array(img)\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images,y                ","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:11.796157Z","iopub.execute_input":"2022-06-23T09:02:11.796941Z","iopub.status.idle":"2022-06-23T09:02:11.813359Z","shell.execute_reply.started":"2022-06-23T09:02:11.796905Z","shell.execute_reply":"2022-06-23T09:02:11.81139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nt=time.time()\nX,y=images_to_array(\"../input/dog-breed-identification/train\",labels[:])\nprint(\"run time in seconds:{}\".format(time.time()-t))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:02:11.814763Z","iopub.execute_input":"2022-06-23T09:02:11.815001Z","iopub.status.idle":"2022-06-23T09:03:29.130829Z","shell.execute_reply.started":"2022-06-23T09:02:11.81497Z","shell.execute_reply":"2022-06-23T09:03:29.130058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=25\n\nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n\n    ax = plt.subplot(5, 5, i+1)\n    plt.title(classes[np.where(y[i] ==1)[0][0]])\n    plt.imshow(X[i].astype('int32'))    ","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:03:29.132073Z","iopub.execute_input":"2022-06-23T09:03:29.132832Z","iopub.status.idle":"2022-06-23T09:03:32.425479Z","shell.execute_reply.started":"2022-06-23T09:03:29.132791Z","shell.execute_reply":"2022-06-23T09:03:32.422361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating Call backs**","metadata":{}},{"cell_type":"code","source":"#learning rate annelar\nlrr=ReduceLROnPlateau(monitor=\"val_acc\",factor=0.01,patience=3,min_lr=1e-5,verbose=1)\n#prepare call backs\nEarlyStop=EarlyStopping(monitor=\"val_loss\",patience=10,restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:03:32.42876Z","iopub.execute_input":"2022-06-23T09:03:32.430449Z","iopub.status.idle":"2022-06-23T09:03:32.434894Z","shell.execute_reply.started":"2022-06-23T09:03:32.430406Z","shell.execute_reply":"2022-06-23T09:03:32.434306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyperparameters\nbatch_size=128\nepochs=50\nlearn_rate=.001\nsgd=SGD(learning_rate=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(learning_rate=learn_rate,beta_1=0.9,beta_2=0.999,epsilon=None,amsgrad=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:03:32.436699Z","iopub.execute_input":"2022-06-23T09:03:32.437171Z","iopub.status.idle":"2022-06-23T09:03:32.458371Z","shell.execute_reply.started":"2022-06-23T09:03:32.437124Z","shell.execute_reply":"2022-06-23T09:03:32.457701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#functions to extract features from the dataset by a given pretrained model\nimg_size = (331,331,3)\n\ndef get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:03:32.459248Z","iopub.execute_input":"2022-06-23T09:03:32.459526Z","iopub.status.idle":"2022-06-23T09:03:32.467019Z","shell.execute_reply.started":"2022-06-23T09:03:32.459494Z","shell.execute_reply":"2022-06-23T09:03:32.466262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract features using InceptionV3 \nfrom keras.applications.inception_v3 import InceptionV3,preprocess_input\ninception_preprocessor=preprocess_input\ninception_features=get_features(InceptionV3,inception_preprocessor,img_size,X)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:03:32.468339Z","iopub.execute_input":"2022-06-23T09:03:32.468843Z","iopub.status.idle":"2022-06-23T09:04:26.157687Z","shell.execute_reply.started":"2022-06-23T09:03:32.468808Z","shell.execute_reply":"2022-06-23T09:04:26.156146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.xception import Xception,preprocess_input\nxception_preprocessor=preprocess_input\nxception_features=get_features(Xception,xception_preprocessor,img_size,X)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:04:26.162734Z","iopub.execute_input":"2022-06-23T09:04:26.162933Z","iopub.status.idle":"2022-06-23T09:05:23.454383Z","shell.execute_reply.started":"2022-06-23T09:04:26.162906Z","shell.execute_reply":"2022-06-23T09:05:23.453617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input\ninc_resnet_preprocessor=preprocess_input\ninc_resnet_features=get_features(InceptionResNetV2,inc_resnet_preprocessor,img_size,X)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:05:23.459274Z","iopub.execute_input":"2022-06-23T09:05:23.45953Z","iopub.status.idle":"2022-06-23T09:06:44.230371Z","shell.execute_reply.started":"2022-06-23T09:05:23.459501Z","shell.execute_reply":"2022-06-23T09:06:44.22962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.nasnet import NASNetLarge,preprocess_input\nnasnet_preprocessor=preprocess_input\nnasnet_features=get_features(NASNetLarge,nasnet_preprocessor,img_size,X)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:06:44.231936Z","iopub.execute_input":"2022-06-23T09:06:44.232263Z","iopub.status.idle":"2022-06-23T09:09:56.789074Z","shell.execute_reply.started":"2022-06-23T09:06:44.232222Z","shell.execute_reply":"2022-06-23T09:09:56.78794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X #to free up some RAM\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:09:56.791222Z","iopub.execute_input":"2022-06-23T09:09:56.791641Z","iopub.status.idle":"2022-06-23T09:09:57.583258Z","shell.execute_reply.started":"2022-06-23T09:09:56.7916Z","shell.execute_reply":"2022-06-23T09:09:57.582538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating final featuremap by combining all extracted features\nfinal_features=np.concatenate([inception_features,xception_features,inc_resnet_features,nasnet_features],axis=-1)#axis -1 to concatenate horizontally\nprint(\"Final feature map shape:\",final_features.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:09:57.585686Z","iopub.execute_input":"2022-06-23T09:09:57.585961Z","iopub.status.idle":"2022-06-23T09:09:57.738862Z","shell.execute_reply.started":"2022-06-23T09:09:57.585921Z","shell.execute_reply":"2022-06-23T09:09:57.738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare Deep net\n\nmodel = Sequential()\n# model.add(Dense(1028,input_shape=(final_features.shape[1],)))\nmodel.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\nmodel.add(Dense(n_classes,activation= 'softmax'))\n\nmodel.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Training the model. \nhistory = model.fit(final_features, y,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2,\n            callbacks=[lrr,EarlyStop])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:09:57.740433Z","iopub.execute_input":"2022-06-23T09:09:57.740698Z","iopub.status.idle":"2022-06-23T09:10:03.497688Z","shell.execute_reply.started":"2022-06-23T09:09:57.740651Z","shell.execute_reply":"2022-06-23T09:10:03.496904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del inception_features\ndel xception_features\ndel nasnet_features\ndel inc_resnet_features\ndel final_features\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:10:03.498873Z","iopub.execute_input":"2022-06-23T09:10:03.499127Z","iopub.status.idle":"2022-06-23T09:10:03.780471Z","shell.execute_reply.started":"2022-06-23T09:10:03.499091Z","shell.execute_reply":"2022-06-23T09:10:03.779619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to read images from test directory\n\ndef images_to_array_test(test_path, img_size = (331,331,3)):\n    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\n    data_size = len(test_filenames)\n    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    \n    for ix,img_dir in enumerate(tqdm(test_filenames)):\n#         img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = img_size)\n#         img = np.expand_dims(img, axis=0)\n#         img = processed_image_resnet(img)\n#         img = img/255\n        images[ix]=img\n#         images[ix] = img_to_array(img)\n        del img\n    print('Ouptut Data Size: ', images.shape)\n    return images\n\ntest_data = images_to_array_test(\"/kaggle/input/dog-breed-identification/test/\", img_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:10:03.781843Z","iopub.execute_input":"2022-06-23T09:10:03.78218Z","iopub.status.idle":"2022-06-23T09:11:42.102019Z","shell.execute_reply.started":"2022-06-23T09:10:03.782132Z","shell.execute_reply":"2022-06-23T09:11:42.101227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extract test data features.\ndef extact_features(data):\n    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n\n    final_features = np.concatenate([inception_features,\n                                     xception_features,\n                                     nasnet_features,\n                                     inc_resnet_features],axis=-1)\n    \n    print('Final feature maps shape', final_features.shape)\n    \n    #deleting to free up ram memory\n    del inception_features\n    del xception_features\n    del nasnet_features\n    del inc_resnet_features\n    gc.collect()\n    \n    \n    return final_features\n\ntest_features = extact_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:11:42.103211Z","iopub.execute_input":"2022-06-23T09:11:42.103979Z","iopub.status.idle":"2022-06-23T09:18:51.320915Z","shell.execute_reply.started":"2022-06-23T09:11:42.10394Z","shell.execute_reply":"2022-06-23T09:18:51.320065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Free up some space.\ndel test_data\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:51.326284Z","iopub.execute_input":"2022-06-23T09:18:51.326501Z","iopub.status.idle":"2022-06-23T09:18:51.680856Z","shell.execute_reply.started":"2022-06-23T09:18:51.326476Z","shell.execute_reply":"2022-06-23T09:18:51.679771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict test labels given test data features.\n\npred = model.predict(test_features)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:51.682682Z","iopub.execute_input":"2022-06-23T09:18:51.683019Z","iopub.status.idle":"2022-06-23T09:18:53.108259Z","shell.execute_reply.started":"2022-06-23T09:18:51.682979Z","shell.execute_reply":"2022-06-23T09:18:53.107426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First Prediction\nprint(pred[0])\nprint(f\"Max Value(Probablity of prediction):{np.max(pred[0])}\") # max probability value predicted by the model\nprint(f\"Sum:{np.sum(pred[0])}\") # because we used softmax activation in our model which willl be close to 1\nprint(f\"Max index:{np.argmax(pred[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label:{classes[np.argmax(pred[0])]}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:53.110058Z","iopub.execute_input":"2022-06-23T09:18:53.110341Z","iopub.status.idle":"2022-06-23T09:18:53.12903Z","shell.execute_reply.started":"2022-06-23T09:18:53.110303Z","shell.execute_reply":"2022-06-23T09:18:53.128066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create pandas DataFrame with empty columns\npreds_df = pd.DataFrame(columns=[\"id\"] + list(classes))\npreds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:53.130996Z","iopub.execute_input":"2022-06-23T09:18:53.131636Z","iopub.status.idle":"2022-06-23T09:18:53.185968Z","shell.execute_reply.started":"2022-06-23T09:18:53.131593Z","shell.execute_reply":"2022-06-23T09:18:53.185176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Append test image ID's to predictions DataFrame\ntest_path = \"/kaggle/input/dog-breed-identification/test/\"\npreds_df[\"id\"]=[os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:53.186981Z","iopub.execute_input":"2022-06-23T09:18:53.187211Z","iopub.status.idle":"2022-06-23T09:18:53.365984Z","shell.execute_reply.started":"2022-06-23T09:18:53.187176Z","shell.execute_reply":"2022-06-23T09:18:53.365181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_df.loc[:,list(classes)]=pred\npreds_df.to_csv(\"submission.csv\",index=None)\npreds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:53.367081Z","iopub.execute_input":"2022-06-23T09:18:53.367337Z","iopub.status.idle":"2022-06-23T09:18:55.534881Z","shell.execute_reply.started":"2022-06-23T09:18:53.367302Z","shell.execute_reply":"2022-06-23T09:18:55.534148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Custom input\n\nImage(\"../input/testakash1/White-dog-1.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:55.536028Z","iopub.execute_input":"2022-06-23T09:18:55.536267Z","iopub.status.idle":"2022-06-23T09:18:55.589909Z","shell.execute_reply.started":"2022-06-23T09:18:55.536232Z","shell.execute_reply":"2022-06-23T09:18:55.589338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the image and converting it into an np array\n\nimg_g = load_img('../input/testakash1/White-dog-1.jpg',target_size = img_size)\nimg_g = np.expand_dims(img_g, axis=0) # as we trained our model in (row, img_height, img_width, img_rgb) format, np.expand_dims convert the image into this format\n# img_g","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:55.590939Z","iopub.execute_input":"2022-06-23T09:18:55.591375Z","iopub.status.idle":"2022-06-23T09:18:55.621683Z","shell.execute_reply.started":"2022-06-23T09:18:55.591339Z","shell.execute_reply":"2022-06-23T09:18:55.620915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Predict test labels given test data features.\ntest_features = extact_features(img_g)\npredg = model.predict(test_features)\nprint(f\"Dog Breed: {classes[np.argmax(predg[0])]}\")\nprint(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:18:55.622806Z","iopub.execute_input":"2022-06-23T09:18:55.623615Z","iopub.status.idle":"2022-06-23T09:19:27.066105Z","shell.execute_reply.started":"2022-06-23T09:18:55.623575Z","shell.execute_reply":"2022-06-23T09:19:27.065415Z"},"trusted":true},"execution_count":null,"outputs":[]}]}