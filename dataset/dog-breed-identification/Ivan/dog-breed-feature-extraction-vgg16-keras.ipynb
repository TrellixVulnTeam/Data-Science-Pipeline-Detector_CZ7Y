{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom IPython.display import display\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"labels = pd.read_csv('../input/labels.csv')\n# sample_submission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display image\nIMG = labels.iloc[8]\nimg_path = '../input/train/{}.jpg'.format(IMG[0])\ndisplay(load_img(img_path))\nprint(IMG[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create index for subset data\nnp.random.seed(123)\nindex = np.array(labels.index)\nnp.random.shuffle(index)\ntrain_index = index[:6400]\nval_index = index[6400:9600]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create lists with path to file and associated labels\ndef split_dataset(labels, index):\n    x = []\n    y = []\n    for i, breed in labels.iloc[index].values:\n        x.append('../input/train/{}.jpg'.format(i))\n        y.append(breed)\n    return x, y\n\nx_train, y_train = split_dataset(labels, train_index)\nx_val, y_val = split_dataset(labels, val_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generator\nfrom tensorflow.keras.utils import Sequence\n# Here, `x_set` is list of path to the images\n# and `y_set` are the associated classes.\n\nclass dog_sequence(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x = x_set\n        self.y = pd.get_dummies(y_set)\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.x) / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n        \n        x = np.empty(shape=(128, 224, 224, 3))\n        n = 0\n        for file_name in batch_x:\n            img = img_to_array(load_img(file_name, target_size=(224, 224)))\n            img = np.expand_dims(img, 0)\n            x[n,:,:,:] = img\n            n += 1\n        x = preprocess_input(x)\n               \n        return x, batch_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load VGG16 model\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n# base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(base_model)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(120, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0.0001),\n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint   \ncheckpointer = ModelCheckpoint(filepath='myModel.hdf5', verbose=1, save_best_only=True,\n                              save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit_generator(dog_sequence(x_train, y_train, batch_size=128),\n                           validation_data=dog_sequence(x_val, y_val, batch_size=128),\n                           epochs=10, verbose=1, callbacks=[checkpointer])\ntext = ' max acc: {:.3f}\\n max val_acc {:.3f}'.format(max(hist.history['acc']), max(hist.history['val_acc']))\nprint(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(hist.history['acc'], label='train');\nplt.plot(hist.history['val_acc'], label='val');\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine-tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in base_model.layers:\n    if layer.name.startswith('block5'):\n        layer.trainable = True\n    else:\n        layer.trainable = False\n    print(layer.name, layer.trainable)\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save_weights('myModel.hdf5')\n# model.load_weights('myModel.hdf5', by_name=True) # by_name=False","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}