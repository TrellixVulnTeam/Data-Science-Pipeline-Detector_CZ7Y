{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\n\nimport tensorflow as tf\nfrom tqdm.autonotebook import tqdm\n\n\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\n\n\nfrom keras.preprocessing.image import load_img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T08:13:54.663429Z","iopub.execute_input":"2021-06-06T08:13:54.663904Z","iopub.status.idle":"2021-06-06T08:14:01.233824Z","shell.execute_reply.started":"2021-06-06T08:13:54.663826Z","shell.execute_reply":"2021-06-06T08:14:01.231509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading labels csv file\nlabels = pd.read_csv('../input/dog-breed-identification/labels.csv')\nlabels.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:01.235858Z","iopub.execute_input":"2021-06-06T08:14:01.236491Z","iopub.status.idle":"2021-06-06T08:14:01.292733Z","shell.execute_reply.started":"2021-06-06T08:14:01.236448Z","shell.execute_reply":"2021-06-06T08:14:01.291368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:01.295462Z","iopub.execute_input":"2021-06-06T08:14:01.295942Z","iopub.status.idle":"2021-06-06T08:14:01.51453Z","shell.execute_reply.started":"2021-06-06T08:14:01.295894Z","shell.execute_reply":"2021-06-06T08:14:01.513598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check one image\nfrom IPython.display import display, Image\nImage(\"../input/dog-breed-identification/train/0a0c223352985ec154fd604d7ddceabd.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:01.516794Z","iopub.execute_input":"2021-06-06T08:14:01.5173Z","iopub.status.idle":"2021-06-06T08:14:01.536762Z","shell.execute_reply.started":"2021-06-06T08:14:01.517243Z","shell.execute_reply":"2021-06-06T08:14:01.535398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(os.listdir('../input/dog-breed-identification/train/')) == len(labels['id']):\n    print('Number of file matches number of actual images!')\nelse:\n    print('Number of file doesnot matches number of actual images!!')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:01.538572Z","iopub.execute_input":"2021-06-06T08:14:01.539033Z","iopub.status.idle":"2021-06-06T08:14:01.890842Z","shell.execute_reply.started":"2021-06-06T08:14:01.538978Z","shell.execute_reply":"2021-06-06T08:14:01.88959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create list of alphabetically sorted labels.\nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))\nclass_to_num","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:01.892698Z","iopub.execute_input":"2021-06-06T08:14:01.893191Z","iopub.status.idle":"2021-06-06T08:14:01.909578Z","shell.execute_reply.started":"2021-06-06T08:14:01.893147Z","shell.execute_reply":"2021-06-06T08:14:01.907866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels['breed'].value_counts().plot.bar(figsize=(20,12));","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:01.911685Z","iopub.execute_input":"2021-06-06T08:14:01.912233Z","iopub.status.idle":"2021-06-06T08:14:04.475487Z","shell.execute_reply.started":"2021-06-06T08:14:01.912189Z","shell.execute_reply":"2021-06-06T08:14:04.474391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (224,224,3)\n\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix]=img\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images,y","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:04.478391Z","iopub.execute_input":"2021-06-06T08:14:04.478781Z","iopub.status.idle":"2021-06-06T08:14:04.488733Z","shell.execute_reply.started":"2021-06-06T08:14:04.478737Z","shell.execute_reply":"2021-06-06T08:14:04.487207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time \nt = time.time()\n\nX,y = images_to_array('../input/dog-breed-identification/train', labels[:])\n\nprint('runtime in seconds: {}'.format(time.time() - t))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:14:04.4909Z","iopub.execute_input":"2021-06-06T08:14:04.491461Z","iopub.status.idle":"2021-06-06T08:15:46.985855Z","shell.execute_reply.started":"2021-06-06T08:14:04.491416Z","shell.execute_reply":"2021-06-06T08:15:46.984515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:15:46.987467Z","iopub.execute_input":"2021-06-06T08:15:46.987959Z","iopub.status.idle":"2021-06-06T08:15:46.996249Z","shell.execute_reply.started":"2021-06-06T08:15:46.987913Z","shell.execute_reply":"2021-06-06T08:15:46.994612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=25\n\nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n    ax = plt.subplot(5, 5, i+1)\n    plt.title(classes[np.where(y[i] ==1)[0][0]])\n    plt.imshow(X[i].astype('int32'))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:15:46.998393Z","iopub.execute_input":"2021-06-06T08:15:46.999038Z","iopub.status.idle":"2021-06-06T08:15:51.215971Z","shell.execute_reply.started":"2021-06-06T08:15:46.998992Z","shell.execute_reply":"2021-06-06T08:15:51.214841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nbatch_size= 128\nepochs=50\nlearn_rate=.001\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:15:51.217718Z","iopub.execute_input":"2021-06-06T08:15:51.218449Z","iopub.status.idle":"2021-06-06T08:15:51.232208Z","shell.execute_reply.started":"2021-06-06T08:15:51.218395Z","shell.execute_reply":"2021-06-06T08:15:51.230846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to extract features from the dataset by a given pretrained model\nimg_size = (224,224,3)\n\ndef get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:15:51.234127Z","iopub.execute_input":"2021-06-06T08:15:51.235268Z","iopub.status.idle":"2021-06-06T08:15:51.244718Z","shell.execute_reply.started":"2021-06-06T08:15:51.235215Z","shell.execute_reply":"2021-06-06T08:15:51.243486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model VGG16","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nvgg16_preprocessor = preprocess_input\nvgg_features = get_features(VGG16,\n                            vgg16_preprocessor,\n                            img_size  , X)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:15:51.248572Z","iopub.execute_input":"2021-06-06T08:15:51.249286Z","iopub.status.idle":"2021-06-06T08:34:41.861255Z","shell.execute_reply.started":"2021-06-06T08:15:51.249245Z","shell.execute_reply":"2021-06-06T08:34:41.859733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare Deep net\n\nmodel_vgg = Sequential()\nmodel_vgg.add(Dense(1028, input_shape=(vgg_features.shape[1], ),\n                       kernel_initializer = 'he_uniform', \n                       kernel_regularizer = None,\n                       kernel_constraint = 'MaxNorm',\n                       activation = 'relu')) \nmodel_vgg.add(Dropout(0.7,input_shape=(vgg_features.shape[1],)))\nmodel_vgg.add(Dense(n_classes,activation= 'softmax'))\n\nmodel_vgg.compile(optimizer=adam,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n#Training the model. \nhistory_VGG = model_vgg.fit(vgg_features, y,batch_size=batch_size, epochs=epochs, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:34:41.864514Z","iopub.execute_input":"2021-06-06T08:34:41.864968Z","iopub.status.idle":"2021-06-06T08:34:58.023489Z","shell.execute_reply.started":"2021-06-06T08:34:41.864921Z","shell.execute_reply":"2021-06-06T08:34:58.022376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history_VGG.history['accuracy'])\nplt.plot(history_VGG.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_VGG.history['loss'])\nplt.plot(history_VGG.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:34:58.025284Z","iopub.execute_input":"2021-06-06T08:34:58.025619Z","iopub.status.idle":"2021-06-06T08:34:58.392708Z","shell.execute_reply.started":"2021-06-06T08:34:58.025581Z","shell.execute_reply":"2021-06-06T08:34:58.391378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model ResNet50","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50,preprocess_input\nresnet50_preprocessor = preprocess_input\nresnet_features = get_features(ResNet50,\n                               resnet50_preprocessor,\n                               img_size, X)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:34:58.394764Z","iopub.execute_input":"2021-06-06T08:34:58.395299Z","iopub.status.idle":"2021-06-06T08:35:20.320257Z","shell.execute_reply.started":"2021-06-06T08:34:58.395254Z","shell.execute_reply":"2021-06-06T08:35:20.318803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare Deep net\n\nmodel_resnet = Sequential()\nmodel_resnet.add(Dense(1028, input_shape=(resnet_features.shape[1], ),\n                       kernel_initializer = 'he_uniform', \n                       kernel_regularizer = None,\n                       kernel_constraint = 'MaxNorm',\n                       activation = 'relu')) \nmodel_resnet.add(Dropout(0.7,input_shape=(resnet_features.shape[1],)))\nmodel_resnet.add(Dense(n_classes,activation= 'softmax'))\n\nmodel_resnet.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Training the model. \nhistory_resnet = model_resnet.fit(resnet_features, y,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:35:20.322373Z","iopub.execute_input":"2021-06-06T08:35:20.323069Z","iopub.status.idle":"2021-06-06T08:35:36.824106Z","shell.execute_reply.started":"2021-06-06T08:35:20.323017Z","shell.execute_reply":"2021-06-06T08:35:36.822923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history_resnet.history['accuracy'])\nplt.plot(history_resnet.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_resnet.history['loss'])\nplt.plot(history_resnet.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:35:36.828092Z","iopub.execute_input":"2021-06-06T08:35:36.828404Z","iopub.status.idle":"2021-06-06T08:35:37.196995Z","shell.execute_reply.started":"2021-06-06T08:35:36.828373Z","shell.execute_reply":"2021-06-06T08:35:37.195824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model DenseNet169","metadata":{}},{"cell_type":"code","source":"from keras.applications.densenet import DenseNet169,preprocess_input\ndensenet169_preprocessor = preprocess_input\ndensenet_features = get_features(DenseNet169,\n                                 densenet169_preprocessor,\n                                 img_size, X)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:35:37.198445Z","iopub.execute_input":"2021-06-06T08:35:37.199089Z","iopub.status.idle":"2021-06-06T08:36:10.558279Z","shell.execute_reply.started":"2021-06-06T08:35:37.199025Z","shell.execute_reply":"2021-06-06T08:36:10.557268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare Deep net\n\nmodel_densenet = Sequential()\nmodel_densenet.add(Dense(1028, input_shape=(densenet_features.shape[1],),\n                         kernel_initializer = 'he_uniform', \n                         kernel_regularizer = None,\n                         kernel_constraint = 'MaxNorm',\n                         activation = 'relu')) \nmodel_densenet.add(Dropout(0.7,input_shape=(densenet_features.shape[1],)))\nmodel_densenet.add(Dense(n_classes,activation= 'softmax'))\n\nmodel_densenet.compile(optimizer=adam,\n                       loss='categorical_crossentropy',\n                       metrics=['accuracy'])\n\n#Training the model. \nhistory_densenet = model_densenet.fit(densenet_features, y,\n                                      batch_size=batch_size,\n                                      epochs=epochs,\n                                      validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:10.56213Z","iopub.execute_input":"2021-06-06T08:36:10.562418Z","iopub.status.idle":"2021-06-06T08:36:27.669023Z","shell.execute_reply.started":"2021-06-06T08:36:10.562389Z","shell.execute_reply":"2021-06-06T08:36:27.66785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history_densenet.history['accuracy'])\nplt.plot(history_densenet.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_densenet.history['loss'])\nplt.plot(history_densenet.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:27.670905Z","iopub.execute_input":"2021-06-06T08:36:27.671235Z","iopub.status.idle":"2021-06-06T08:36:28.043403Z","shell.execute_reply.started":"2021-06-06T08:36:27.671191Z","shell.execute_reply":"2021-06-06T08:36:28.041905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model MobileNetV2","metadata":{}},{"cell_type":"code","source":"from keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\nmobilenetV2_preprocessor = preprocess_input\nmobilenetV2_features = get_features(MobileNetV2,\n                                    mobilenetV2_preprocessor,\n                                    img_size  , X)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:28.045349Z","iopub.execute_input":"2021-06-06T08:36:28.045957Z","iopub.status.idle":"2021-06-06T08:36:40.140326Z","shell.execute_reply.started":"2021-06-06T08:36:28.045903Z","shell.execute_reply":"2021-06-06T08:36:40.139292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_mobilenet = Sequential()\nmodel_mobilenet.add(Dense(1028, input_shape=(mobilenetV2_features.shape[1], ),\n                    kernel_initializer = 'he_uniform', \n                    kernel_regularizer = None,\n                    kernel_constraint = 'MaxNorm',\n                    activation = 'relu')) \nmodel_mobilenet.add(Dropout(0.7,input_shape=(mobilenetV2_features.shape[1],)))\nmodel_mobilenet.add(Dense(n_classes,activation= 'softmax'))\n\nmodel_mobilenet.compile(optimizer=adam,\n                        loss='categorical_crossentropy',\n                        metrics=['accuracy'])\n\nhistory_mobilenet = model_mobilenet.fit(mobilenetV2_features, y,\n                              batch_size=batch_size,\n                              epochs=epochs,\n                              validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:40.143008Z","iopub.execute_input":"2021-06-06T08:36:40.143429Z","iopub.status.idle":"2021-06-06T08:36:56.701515Z","shell.execute_reply.started":"2021-06-06T08:36:40.143378Z","shell.execute_reply":"2021-06-06T08:36:56.700449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history_mobilenet.history['accuracy'])\nplt.plot(history_mobilenet.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_mobilenet.history['loss'])\nplt.plot(history_mobilenet.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:56.7062Z","iopub.execute_input":"2021-06-06T08:36:56.706529Z","iopub.status.idle":"2021-06-06T08:36:57.074713Z","shell.execute_reply.started":"2021-06-06T08:36:56.706499Z","shell.execute_reply":"2021-06-06T08:36:57.073621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compare Models","metadata":{}},{"cell_type":"code","source":"# Train Loss for different models\nplt.plot(history_VGG.history['loss'])\nplt.plot(history_resnet.history['loss'])\nplt.plot(history_densenet.history['loss'])\nplt.plot(history_mobilenet.history['loss'])\nplt.title('Train Loss for different models')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['VGG16', 'ResNet50', 'DenseNet169', 'MobileNetV2'], loc='upper left')\nplt.savefig('./train_loss.png')\nplt.show()\n# Test Loss for different models\nplt.plot(history_VGG.history['val_loss'])\nplt.plot(history_resnet.history['val_loss'])\nplt.plot(history_densenet.history['val_loss'])\nplt.plot(history_mobilenet.history['val_loss'])\nplt.title('Test Loss for different models')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['VGG16', 'ResNet50', 'DenseNet169', 'MobileNetV2'], loc='upper left')\nplt.savefig('./test_loss.png')\nplt.show()\n\n# Train Accuracy for different models\nplt.plot(history_VGG.history['accuracy'])\nplt.plot(history_resnet.history['accuracy'])\nplt.plot(history_densenet.history['accuracy'])\nplt.plot(history_mobilenet.history['accuracy'])\nplt.title('Train Accuracy for different models')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['VGG16', 'ResNet50', 'DenseNet169', 'MobileNetV2'], loc='upper left')\nplt.savefig('./train_accuracy.png')\nplt.show()\n\n# Test Accuracy for different models\nplt.plot(history_VGG.history['val_accuracy'])\nplt.plot(history_resnet.history['val_accuracy'])\nplt.plot(history_densenet.history['val_accuracy'])\nplt.plot(history_mobilenet.history['val_accuracy'])\nplt.title('Test Accuracy for different models')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['VGG16', 'ResNet50', 'DenseNet169', 'MobileNetV2'], loc='upper left')\nplt.savefig('./test_accuracy.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:07:42.235283Z","iopub.execute_input":"2021-06-06T09:07:42.235729Z","iopub.status.idle":"2021-06-06T09:07:43.326324Z","shell.execute_reply.started":"2021-06-06T09:07:42.235698Z","shell.execute_reply":"2021-06-06T09:07:43.325319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_test = [np.array(history_VGG.history['val_accuracy']).mean(),\n                  np.array(history_resnet.history['val_accuracy']).mean(),\n                  np.array(history_densenet.history['val_accuracy']).mean(),\n                  np.array(history_mobilenet.history['val_accuracy']).mean()\n                 ]\naccuracy_train = [np.array(history_VGG.history['accuracy']).mean(),\n                  np.array(history_resnet.history['accuracy']).mean(),\n                  np.array(history_densenet.history['accuracy']).mean(),\n                  np.array(history_mobilenet.history['accuracy']).mean()\n                 ]\nloss_test = [np.array(history_VGG.history['val_loss']).mean(),\n             np.array(history_resnet.history['val_loss']).mean(),\n             np.array(history_densenet.history['val_loss']).mean(),\n             np.array(history_mobilenet.history['val_loss']).mean()\n            ]\nloss_train = [np.array(history_VGG.history['loss']).mean(),\n              np.array(history_resnet.history['loss']).mean(),\n              np.array(history_densenet.history['loss']).mean(),\n              np.array(history_mobilenet.history['loss']).mean()\n             ]\n\ndf = pd.DataFrame({\n    'Model':['VGG16','ResNet50','DenseNet169','MobileNetV2'],\n    'Loss (Train)':loss_train,\n    'Loss (Test)':loss_test,\n    'Accuracy (Train)':accuracy_train,\n    'Accuracy (Test)': accuracy_test,\n})\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:58.151438Z","iopub.execute_input":"2021-06-06T08:36:58.151982Z","iopub.status.idle":"2021-06-06T08:36:58.180819Z","shell.execute_reply.started":"2021-06-06T08:36:58.151917Z","shell.execute_reply":"2021-06-06T08:36:58.179291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to read images from test directory\n\ndef images_to_array_test(test_path, img_size = (224,224,3)):\n    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\n    data_size = len(test_filenames)\n    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    \n    for ix,img_dir in enumerate(tqdm(test_filenames)):\n        img = load_img(img_dir, target_size = img_size)\n        images[ix]=img\n        del img\n    print('Ouptut Data Size: ', images.shape)\n    return images\n\ntest_data = images_to_array_test('../input/dog-breed-identification/test/', img_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:36:58.183158Z","iopub.execute_input":"2021-06-06T08:36:58.183694Z","iopub.status.idle":"2021-06-06T08:38:55.748122Z","shell.execute_reply.started":"2021-06-06T08:36:58.183651Z","shell.execute_reply":"2021-06-06T08:38:55.746845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extract test data features.\ndef extact_features_vgg(data):\n    vgg_features = get_features(VGG16, vgg16_preprocessor, img_size, data)\n    return vgg_features\ndef extact_features_resnet(data):\n    resnet_features = get_features(ResNet50, resnet50_preprocessor, img_size, data)\n    return resnet_features\ndef extact_features_densenet(data):\n    densenet_features = get_features(DenseNet169, densenet169_preprocessor, img_size, data)\n    return densenet_features\ndef extact_features_mobilenet(data):\n    mobilenetV2_features = get_features(MobileNetV2, mobilenetV2_preprocessor, img_size, data)\n    return mobilenetV2_features\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:38:55.749883Z","iopub.execute_input":"2021-06-06T08:38:55.750579Z","iopub.status.idle":"2021-06-06T08:38:55.757953Z","shell.execute_reply.started":"2021-06-06T08:38:55.750505Z","shell.execute_reply":"2021-06-06T08:38:55.756552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame({\n    'Models': ['VGG16', 'ResNet50', 'DenseNet169', 'MobileNetV2']\n})\ntest_df = test_df.set_index('Models')\ndog_names = [\"Pomeranian\", \"Siberian Husky\", \"Irish Setter\", \"Danua\", \"Chihuahua\", \"Newfoundland\", \"Maltese \", \"Bullmastiff\", \"Cairn Terrier\", \"Norwich Terrier\"]\ntest_df = pd.concat([test_df,pd.DataFrame(columns = dog_names)])\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-06-06T08:38:55.759721Z","iopub.execute_input":"2021-06-06T08:38:55.760511Z","iopub.status.idle":"2021-06-06T08:38:55.798653Z","shell.execute_reply.started":"2021-06-06T08:38:55.760465Z","shell.execute_reply":"2021-06-06T08:38:55.79743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('-------------------------------Testing VGG16 Model-------------------------------')\nresult = []\nfor j in range(1,11):\n    img_g = load_img('../input/mydogsample/dog%s.jpg'%j,target_size = img_size)\n    img_g = np.expand_dims(img_g, axis=0) \n\n    test_features = extact_features_vgg(img_g)\n    pred = model_vgg.predict(test_features)\n    result.append(classes[np.argmax(pred[0])] + \" \" + str(round(np.max(pred[0]))* 100)  + \"%\")\ntest_df.loc['VGG16'] = result\n\nprint('-------------------------------Testing ResNet50 Model-------------------------------')\nresult = []\nfor j in range(1,11):\n    img_g = load_img('../input/mydogsample/dog%s.jpg'%j,target_size = img_size)\n    img_g = np.expand_dims(img_g, axis=0) \n\n    test_features = extact_features_resnet(img_g)\n    pred = model_resnet.predict(test_features)\n    result.append(classes[np.argmax(pred[0])] + \" \" + str(round(np.max(pred[0]))* 100)  + \"%\")\ntest_df.loc['ResNet50'] = result\n\nprint('-------------------------------Testing DenseNet169 Model-------------------------------')\nresult = []\nfor j in range(1,11):\n    img_g = load_img('../input/mydogsample/dog%s.jpg'%j,target_size = img_size)\n    img_g = np.expand_dims(img_g, axis=0) \n\n    test_features = extact_features_densenet(img_g)\n    pred = model_densenet.predict(test_features)\n    result.append(classes[np.argmax(pred[0])] + \" \" + str(round(np.max(pred[0]))* 100)  + \"%\")\ntest_df.loc['DenseNet169'] = result\n\nprint('-------------------------------Testing MobileNetV2 Model-------------------------------')\nresult = []\nfor j in range(1,11):\n    img_g = load_img('../input/mydogsample/dog%s.jpg'%j,target_size = img_size)\n    img_g = np.expand_dims(img_g, axis=0) \n\n    test_features = extact_features_mobilenet(img_g)\n    pred = model_mobilenet.predict(test_features)\n    result.append(classes[np.argmax(pred[0])] + \" \" + str(round(np.max(pred[0]))* 100)  + \"%\")\ntest_df.loc['MobileNetV2'] = result\nresult = []","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:25:55.247Z","iopub.execute_input":"2021-06-06T09:25:55.247339Z","iopub.status.idle":"2021-06-06T09:28:41.261491Z","shell.execute_reply.started":"2021-06-06T09:25:55.24731Z","shell.execute_reply":"2021-06-06T09:28:41.259853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:28:46.788871Z","iopub.execute_input":"2021-06-06T09:28:46.789342Z","iopub.status.idle":"2021-06-06T09:28:46.813586Z","shell.execute_reply.started":"2021-06-06T09:28:46.789312Z","shell.execute_reply":"2021-06-06T09:28:46.812052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}