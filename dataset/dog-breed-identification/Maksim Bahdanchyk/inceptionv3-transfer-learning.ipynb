{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"label = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/input/dog-breed-identification/train/'\ntest_dir  = '/kaggle/input/dog-breed-identification/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = os.listdir(train_dir)\ntest_img  = os.listdir(test_dir)\n\nprint('Number of train_img',len(train_img))\nprint('Number of test_img' ,len(test_img))\nprint(len(set(train_img)))\nprint(len(set(test_img)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"label['path'] = train_dir+label.id+'.jpg'\n\nfig,axes = plt.subplots(2,5,figsize = (30,10))\n\nfor ax in axes.reshape(-1,):\n    rnd_idx = np.random.randint(label.index[0],label.index[-1])\n    arr = plt.imread(label.loc[rnd_idx,'path'])\n    ax.imshow(arr)\n    ax.set_title(label.loc[rnd_idx,'breed']+'\\n'+str(arr.shape))\n    ax.axis('off')\n\n# as we can see pictures have different size.\n# lets extract this feature and write to label frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there should be more straitforward way\n\nsizes_info = label.path.apply(lambda x: plt.imread(x).shape).values.tolist()\nmeta_df    = pd.DataFrame(sizes_info,columns = ['height','width','channels'])\nlabel      = pd.merge(label,meta_df,how = 'left',left_index = True,right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nfig,axes = plt.subplots(1,3,figsize = (20,5))\n\nfor ax,col in zip(axes,['height','width','channels']):\n    label[[col]].hist(bins = 100,ax = ax)\n\n# most of the pictures have height = 300 and width 500\n# make sense to rescale pictures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label['id1'] = label.id+'.jpg'\nbreed = label.breed.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd_row = np.random.randint(label.index[0],label.index[-1],2000)\nshorter_df = label.loc[rnd_row,:].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale          =1./255,\n    #rotation_range   = 45,\n    #horizontal_flip  = True,\n    #shear_range      = 0.2,\n    validation_split = 0.25\n)\n\ntrain_generator=datagen.flow_from_dataframe(\n    dataframe = label,\n    directory=\"/kaggle/input/dog-breed-identification/train/\",\n    x_col=\"id1\",\n    y_col=\"breed\",\n    color_mode = 'rgb',\n    subset = 'training',\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    target_size=(300,300)\n)\n\nval_generator=datagen.flow_from_dataframe(\n    dataframe = label,\n    directory=\"/kaggle/input/dog-breed-identification/train/\",\n    x_col=\"id1\",\n    y_col=\"breed\",\n    color_mode = 'rgb',\n    subset = 'validation',\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    target_size=(300,300)\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = {x:y for x,y in classes.items()}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initiate transfer learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mnv = tf.keras.applications.inception_v3.InceptionV3(include_top = False,\n                                           weights      = 'imagenet',\n                                           input_shape = (300,300,3))\n\nmnv.trainbale = False\nfor layer in mnv.layers:\n    layer.trainable = False\n    \n\nmodel = tf.keras.Sequential([\n    mnv,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation ='relu'),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(256,activation ='relu'),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(120,activation = 'softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy',\n              optimizer = tf.keras.optimizers.Adam(),\n              metrics   = ['accuracy'])\n\nhist = model.fit_generator(generator = train_generator,\n                           epochs = 3,\n                           steps_per_epoch  = train_generator.n//train_generator.batch_size,\n                           validation_data  = val_generator,\n                           validation_steps = val_generator.n//val_generator.batch_size)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (5,5))\nax.plot(range(1,len(hist.history['accuracy'])+1),hist.history['accuracy'])\nax.plot(range(1,len(hist.history['val_accuracy'])+1),hist.history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check model performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pred = np.argmax(model.predict(val_generator),axis=-1)\nclasses = {x:y for y,x in classes.items()}\n\nfig,axes = plt.subplots(2,5,figsize = (30,10))\n\nfor ax in axes.reshape(-1,):\n    rnd_idx = np.random.randint(0,len(val_generator.filepaths))\n    arr = plt.imread(val_generator.filepaths[rnd_idx])\n    ax.imshow(arr)\n    breed_true = classes[val_generator.classes[rnd_idx]]\n    breed_pred = classes[val_pred[rnd_idx]]\n    \n    if breed_true != classes[val_pred[rnd_idx]]:\n        ax.set_title(breed_true+'\\n'+ breed_pred,color = 'red',fontsize = 15)\n    else:\n        ax.set_title(breed_true+'\\n'+ breed_pred,color = 'black',fontsize = 15)\n\n    ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(val_generator.classes,val_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}