{"cells":[{"metadata":{"_uuid":"567d822a77b80f27f2b43c314796b8da76a08bf8"},"cell_type":"markdown","source":"\n**Forked from** https://www.kaggle.com/orangutan/keras-vgg19-starter\n\n**For details**,.. https://www.kaggle.com/c/dog-breed-identification\n"},{"metadata":{"_cell_guid":"8a7bff8d-c95a-4cfb-8c38-14ab989f769b","_uuid":"4da5a3e7db32799ca0108576e469157094d23111","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten,  Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras import backend as K\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import load_img\n#from keras.applications.vgg16 import preprocess_input\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nimport os\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport sys\nimport bcolz\nimport random\nimport numpy as np\nfrom scipy import ndimage\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b8fddbc-447f-4083-88c4-9bd5f811253d","_uuid":"7c64ad63b95b36df5a2223b4c499c1caad9c73ee"},"cell_type":"markdown","source":"First we will read in the csv's so we can see some more information on the filenames and breeds"},{"metadata":{"_cell_guid":"bcbeef91-f00e-4a68-b1b8-25e206027bb2","_uuid":"18e9091e9a3d851fb0ce796a3b537ffb7f47c874","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/labels.csv')\ndf_test = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6abe20dc-a411-4334-ad66-2526d99c7f63","_uuid":"0ba75a32f91650bc75440443ab3d11c35e44e1c9","trusted":true},"cell_type":"code","source":"df_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92350610e9da8b22926d8b2f7985e7038d024b38","trusted":true},"cell_type":"code","source":"train_files = glob('../input/train/*.jpg')\ntest_files = glob('../input/test/*.jpg')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b673e68df37d6cc3686f91f7adc3405391548035","scrolled":true,"trusted":true},"cell_type":"code","source":"plt.imshow(plt.imread(train_files[100]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ba5da72-9d82-404d-aa25-ce9739a45775","_uuid":"7fbb53109a3d08bedb1abac074f8186bdea991ac","trusted":true},"cell_type":"code","source":"targets_series = pd.Series(df_train['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)\none_hot_labels = np.asarray(one_hot)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e89e3ca-7c9e-4f76-aaf8-8c5267e3a415","_uuid":"7b47e6524b0fcf5ccb9a237cbdc8d444ff215dfb","trusted":true},"cell_type":"code","source":"im_size = 300","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37551a8756b04008c6d71bd4f4b7d70214fb47e1","trusted":true},"cell_type":"code","source":"####  storing train data in a bcolz array with image size 300\ny_train = []\nx_train_raw = bcolz.zeros((0,im_size,im_size,3),np.float32)\nx_test_raw = bcolz.zeros((0,im_size,im_size,3),np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98aab483-199c-451b-80a9-a9c1cf3d02be","_uuid":"1f099a6a4d6b16ed3202a91d5376b77579664d04","trusted":true},"cell_type":"code","source":"####  storing train data in a bcolz array with image size 300\ni = 0 \nfor f, breed in tqdm(df_train.values):\n    # load an image from file\n    image = load_img('../input/train/{}.jpg'.format(f), target_size=(im_size, im_size))\n    image = img_to_array(image)\n    # prepare the image for the VGG model\n    #image = preprocess_input(image)\n    label = one_hot_labels[i]\n    x_train_raw.append(image)\n    y_train.append(label)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####  storing test data in a bcolz array with image size 300\n# for f in tqdm(df_test[\"id\"]):\n#     # load an image from file\n#     image = load_img('../input/test/{}.jpg'.format(f), target_size=(im_size, im_size))\n#     image = img_to_array(image)\n#     # prepare the image for the VGG model\n#     #image = preprocess_input(image)\n#     x_test_raw.append(image)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train_raw.shape)\n# print(x_test_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    ### commentinf since not supported in kernel\n# print(\"Enter batch size - how many images do you want to see \\n\")\n# batch_size=input()\n# batch_size=int(batch_size)\n# print(\"Enter the resize_factor between 0.0 and 1.0 \\n\")\n# resize_factor = input()\n# resize_factor = float(resize_factor)\n\nbatch_size=2\nresize_factor=0.8\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shuffle_dataset_select_indices(x_train_raw,batch_size,im_size):\n    print(\"Let's shuffle the dataset first \")\n    np.random.shuffle(x_train_raw)\n    print(x_train_raw.shape)\n    idx=np.random.choice(im_size, batch_size, replace=False)\n    res= x_train_raw[idx]\n    res=res/255.\n    print(\"selected indices - \", idx)\n    print(\"please note that the cropping and flipping are done with train images , later it can be extended to test easily\")\n    \n    fig, axes = plt.subplots(1,2, figsize=(12,12))\n    axes = axes.flatten()\n    i=0\n    for img, ax in zip( res, axes):\n        ax.imshow(img)\n        ax.set_xticks(())\n        ax.set_yticks(())\n        if i==0:\n            ax.set_title(\"Image 1\")\n        elif i==1:\n            ax.set_title(\"Image 2\")\n        i+=1\n    plt.tight_layout()\n    \n    return idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_flip_images(idx,x_train_raw,resize_factor,im_size):\n    \n    \n    temp=[]\n    cropping_direction=[]\n    flipping_direction=[]\n    \n    for i in (idx):\n        x_temp= x_train_raw[i]\n        print(\"actual image\")\n        plt.imshow(x_temp/255.)\n        temp.append(x_train_raw[i])\n        ##  After cropping , to return back the iamge to original size of IM_SIZE (300) , the original image is blurred \n        ## and kept in a IM_SIZE * IM_SIZE * 3 array. Parts of this array would be replaced by the cropped_iamge\n        \n        x1= np.zeros_like(x_train_raw[0])\n        x1 = ndimage.uniform_filter(x_temp, size=(147, 147, 1)) \n        print(\"Blurred image- helps in retaining the original IM_SIZE shape .\\\n              Blurring to a good extent would  in avoding detecting more objects in non-cropped parts \")\n#         plt.imshow(x1/255.)\n\n        \n        print(\"Lets crop first :\")\n              \n        \n        im_size_new = im_size * resize_factor\n        im_size_new= int(im_size_new)\n\n        x_starting_point = im_size-im_size_new\n        x_starting_point\n\n        i=0\n        randm_number = random.randint(1,101)\n        print(randm_number)\n        if randm_number <= 20: \n            i=0\n            print(\"Cropping from top left \\n\")\n            x1[:im_size_new,:im_size_new] = x_temp[:im_size_new,:im_size_new]\n\n        elif randm_number > 20 and randm_number <= 40:     ### cropping  bottom left\n            i=1\n            print(\"Cropping from bottom left \\n\")\n            x1[:im_size_new,:im_size_new] = x_temp[x_starting_point:,:im_size_new]\n\n        elif randm_number > 40 and randm_number <= 60:     ### cropping top right \n            i=2\n            print(\"Cropping from top right \\n\")\n            x1[:im_size_new,:im_size_new] = x_temp[:im_size_new,x_starting_point:]\n\n        elif randm_number > 60 and randm_number <= 80:     ###cropping bottom right \n            i=3\n            print(\"Cropping from bottom right \\n\")\n            x1[:im_size_new,:im_size_new] = x_temp[x_starting_point:,x_starting_point:]\n\n        elif randm_number > 80 and randm_number <= 100:        ## ccropping enter\n            i=4\n            print(\"Cropping from center \\n\")\n            x1[:im_size_new,:im_size_new] = x_temp[(im_size//2)-(im_size_new//2): (im_size//2)+(im_size_new//2),\n                                          (im_size//2)-(im_size_new//2): (im_size//2)+(im_size_new//2)]\n        temp.append(x1)\n        \n        \n        print(\"Now lets flip:\")\n        randm_number = random.randint(1,101)\n        print(randm_number)\n        if randm_number  <= 50:\n            j=0\n#             plt.imshow((x2[:,::-1]/255.)) \n            print(\"Flipping Horizontally\")\n            x1 = x1[:,::-1] ## horizontalflop\n        elif randm_number > 50: \n            j=1\n#             plt.imshow((x2[::-1,:]/255.))\n            print(\"Flipping vertically\")\n            x1 = x1[::-1,:] ## vertical flop\n\n        temp.append(x1)\n    return temp,i,j\n        \n#         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_images(temp,batch_size,i,j):\n    res = np.concatenate([arr[np.newaxis] for arr in temp])\n    res.shape\n    res=res/255.\n\n\n\n    print(\"Lets see the final images\")\n    fig, axes = plt.subplots(batch_size,3, figsize=(12,12))\n    axes = axes.flatten()\n    cntr=0\n    for img, ax in zip( res, axes):\n        ax.imshow(img)\n        ax.set_xticks(())\n        ax.set_yticks(())\n#         if cntr ==1 and i==0:\n#             ax.set_title(\"Cropped from top left\")\n#         elif cntr ==1 and i==1:\n#             ax.set_title(\"Cropped from Bottm left\")\n#         elif cntr ==1 and i==2:\n#             ax.set_title(\"Cropped from top right\")\n#         elif cntr ==1 and  i==3:\n#             ax.set_title(\"Cropped from bottom right\")\n#         elif cntr==1 and i==4:\n#             ax.set_title(\"Cropped from centre\")\n#         if cntr==2 and  j==0:\n#              ax.set_title(\"Flipped Horizontally\")\n#         if cntr==2 and  j==1:\n#              ax.set_title(\"Flipped Horizontally\")\n        cntr+=1\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flag=input(\"press 1 to start:\")\n# if flag==1:\nidx=shuffle_dataset_select_indices(x_train_raw,batch_size,im_size)\ntemp,i,j=crop_flip_images(idx,x_train_raw,resize_factor,im_size)\nview_images(temp,batch_size,i,j)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}