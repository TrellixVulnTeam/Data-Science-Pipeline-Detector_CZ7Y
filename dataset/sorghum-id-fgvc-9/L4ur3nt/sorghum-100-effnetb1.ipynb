{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# First step is to install the very good ImageDataAugmentor Library from mjkvaak under MIT licence.","metadata":{}},{"cell_type":"code","source":"pip install git+https://github.com/mjkvaak/ImageDataAugmentor","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:04:59.453962Z","iopub.execute_input":"2022-05-16T13:04:59.454563Z","iopub.status.idle":"2022-05-16T13:05:13.180198Z","shell.execute_reply.started":"2022-05-16T13:04:59.454466Z","shell.execute_reply":"2022-05-16T13:05:13.179288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attempting to predict Sorghum species with pretrained model :\n\n* We will use the given dataset of 22194 1024x1024 images\n\n* We will use data augmentation via Flow_from_dataframe resizing the image 260x260\n\n* We will try EfficientNet B1 in this notebook","metadata":{}},{"cell_type":"markdown","source":"# Importing my favorite libraries for Deep learning activities","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sys\nimport os\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nimport tensorflow as tf\nimport random\nfrom IPython.core.debugger import set_trace\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Sequential, layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.data import Dataset\nimport cv2\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport albumentations as A\nfrom albumentations.core.composition import Compose, OneOf\nimport datetime\nfrom ImageDataAugmentor.image_data_augmentor import *","metadata":{"papermill":{"duration":5.788397,"end_time":"2022-03-30T07:46:56.84275","exception":false,"start_time":"2022-03-30T07:46:51.054353","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:05:13.182033Z","iopub.execute_input":"2022-05-16T13:05:13.182617Z","iopub.status.idle":"2022-05-16T13:05:21.070539Z","shell.execute_reply.started":"2022-05-16T13:05:13.182577Z","shell.execute_reply":"2022-05-16T13:05:21.069791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We define the PATH and Batch_size :","metadata":{}},{"cell_type":"code","source":"# Load the TensorBoard notebook extension\n%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:21.071723Z","iopub.execute_input":"2022-05-16T13:05:21.073755Z","iopub.status.idle":"2022-05-16T13:05:21.093613Z","shell.execute_reply.started":"2022-05-16T13:05:21.07371Z","shell.execute_reply":"2022-05-16T13:05:21.092748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '/kaggle/input/sorghum-id-fgvc-9/'\ntrain_path = PATH+'train_images/'\ntest_path = PATH+'test/'\nbatch_size = 16\nepoch = 50\nWIDTH = 260\nHEIGHT = 260","metadata":{"papermill":{"duration":0.045996,"end_time":"2022-03-30T07:46:56.929131","exception":false,"start_time":"2022-03-30T07:46:56.883135","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:05:21.096934Z","iopub.execute_input":"2022-05-16T13:05:21.097581Z","iopub.status.idle":"2022-05-16T13:05:21.104535Z","shell.execute_reply.started":"2022-05-16T13:05:21.097523Z","shell.execute_reply":"2022-05-16T13:05:21.103749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create our Dataframe for training :","metadata":{}},{"cell_type":"code","source":"image_df = pd.read_csv(PATH+'train_cultivar_mapping.csv')","metadata":{"papermill":{"duration":0.075762,"end_time":"2022-03-30T07:46:57.305354","exception":false,"start_time":"2022-03-30T07:46:57.229592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:05:28.152037Z","iopub.execute_input":"2022-05-16T13:05:28.152871Z","iopub.status.idle":"2022-05-16T13:05:28.193932Z","shell.execute_reply.started":"2022-05-16T13:05:28.152823Z","shell.execute_reply":"2022-05-16T13:05:28.193022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df.dropna(inplace=True)","metadata":{"papermill":{"duration":0.086915,"end_time":"2022-03-30T07:46:57.620511","exception":false,"start_time":"2022-03-30T07:46:57.533596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:05:28.814987Z","iopub.execute_input":"2022-05-16T13:05:28.815703Z","iopub.status.idle":"2022-05-16T13:05:28.829571Z","shell.execute_reply.started":"2022-05-16T13:05:28.815664Z","shell.execute_reply":"2022-05-16T13:05:28.828671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df","metadata":{"papermill":{"duration":0.104566,"end_time":"2022-03-30T07:46:57.465979","exception":false,"start_time":"2022-03-30T07:46:57.361413","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:05:34.586593Z","iopub.execute_input":"2022-05-16T13:05:34.586868Z","iopub.status.idle":"2022-05-16T13:05:34.607606Z","shell.execute_reply.started":"2022-05-16T13:05:34.586836Z","shell.execute_reply":"2022-05-16T13:05:34.606889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Debugging the notebook with lower values \n\n# epoch = 20\n# image_df = image_df[:200]\n# image_df","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:35.904475Z","iopub.execute_input":"2022-05-16T13:05:35.90486Z","iopub.status.idle":"2022-05-16T13:05:35.908945Z","shell.execute_reply.started":"2022-05-16T13:05:35.904827Z","shell.execute_reply":"2022-05-16T13:05:35.908058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=4, shuffle=True)\n\nfor train_index, valid_index in kfold.split(image_df['image'],image_df['cultivar']):\n    train_images, valid_images = image_df['image'].iloc[train_index], image_df['image'].iloc[valid_index]\n    train_cultivar, valid_cultivar = image_df['cultivar'].iloc[train_index], image_df['cultivar'].iloc[valid_index]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:36.666959Z","iopub.execute_input":"2022-05-16T13:05:36.667649Z","iopub.status.idle":"2022-05-16T13:05:36.740054Z","shell.execute_reply.started":"2022-05-16T13:05:36.66761Z","shell.execute_reply":"2022-05-16T13:05:36.739264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df= pd.DataFrame({'image':train_images, 'cultivar':train_cultivar})\nval_df= pd.DataFrame({'image':valid_images, 'cultivar':valid_cultivar})","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:37.412151Z","iopub.execute_input":"2022-05-16T13:05:37.412414Z","iopub.status.idle":"2022-05-16T13:05:37.421438Z","shell.execute_reply.started":"2022-05-16T13:05:37.412385Z","shell.execute_reply":"2022-05-16T13:05:37.420394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_df), len(val_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:43.034224Z","iopub.execute_input":"2022-05-16T13:05:43.03453Z","iopub.status.idle":"2022-05-16T13:05:43.041756Z","shell.execute_reply.started":"2022-05-16T13:05:43.03449Z","shell.execute_reply":"2022-05-16T13:05:43.040864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df, val_df = train_test_split(image_df, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:49.991492Z","iopub.execute_input":"2022-05-16T13:05:49.991768Z","iopub.status.idle":"2022-05-16T13:05:49.996694Z","shell.execute_reply.started":"2022-05-16T13:05:49.991736Z","shell.execute_reply":"2022-05-16T13:05:49.995854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Images are 1024x1024 RGB in a .png format\n\n# Let's create our Train and Validation datasets (pair of tensors with images preprocessed and targets) :","metadata":{"papermill":{"duration":0.066834,"end_time":"2022-03-30T07:46:57.754387","exception":false,"start_time":"2022-03-30T07:46:57.687553","status":"completed"},"tags":[]}},{"cell_type":"code","source":"transform = Compose([\n            A.RandomResizedCrop(height=HEIGHT, width=WIDTH),\n            A.Flip(p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.5),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=0.5),\n                A.RandomGamma(p=0.5),\n            ], p=0.5),\n            A.OneOf([\n                A.Blur(p=0.1),\n                A.GaussianBlur(p=0.1),\n                A.MotionBlur(p=0.1),\n            ], p=0.1),\n            A.OneOf([\n                A.GaussNoise(p=0.1),\n                A.ISONoise(p=0.1),\n                A.GridDropout(ratio=0.5, p=0.2),\n                A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n            ], p=0.2)\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:51.393946Z","iopub.execute_input":"2022-05-16T13:05:51.394229Z","iopub.status.idle":"2022-05-16T13:05:51.402802Z","shell.execute_reply.started":"2022-05-16T13:05:51.394198Z","shell.execute_reply":"2022-05-16T13:05:51.401933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataAugmentor(augment=transform)\nval_datagen = ImageDataAugmentor()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:05:54.102489Z","iopub.execute_input":"2022-05-16T13:05:54.103026Z","iopub.status.idle":"2022-05-16T13:05:54.107726Z","shell.execute_reply.started":"2022-05-16T13:05:54.102988Z","shell.execute_reply":"2022-05-16T13:05:54.107068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_augmented = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    shuffle=True,\n    directory=train_path,\n    x_col='image',\n    y_col='cultivar',\n    class_mode='categorical',\n    target_size=(HEIGHT,WIDTH),\n    batch_size=batch_size)","metadata":{"papermill":{"duration":34.97662,"end_time":"2022-03-30T07:47:32.936606","exception":false,"start_time":"2022-03-30T07:46:57.959986","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:05:55.070997Z","iopub.execute_input":"2022-05-16T13:05:55.071738Z","iopub.status.idle":"2022-05-16T13:06:06.658293Z","shell.execute_reply.started":"2022-05-16T13:05:55.0717Z","shell.execute_reply":"2022-05-16T13:06:06.657526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_augmented = val_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    shuffle=True,\n    directory=train_path,\n    x_col='image',\n    y_col='cultivar',\n    class_mode='categorical',\n    target_size=(HEIGHT,WIDTH),\n    batch_size=batch_size)","metadata":{"papermill":{"duration":7.957408,"end_time":"2022-03-30T07:47:40.935384","exception":false,"start_time":"2022-03-30T07:47:32.977976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:06:06.65973Z","iopub.execute_input":"2022-05-16T13:06:06.661303Z","iopub.status.idle":"2022-05-16T13:06:10.509389Z","shell.execute_reply.started":"2022-05-16T13:06:06.661258Z","shell.execute_reply":"2022-05-16T13:06:10.508649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = len(train_augmented.class_indices)\nnum_classes","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:06:32.268412Z","iopub.execute_input":"2022-05-16T13:06:32.268689Z","iopub.status.idle":"2022-05-16T13:06:32.274189Z","shell.execute_reply.started":"2022-05-16T13:06:32.268658Z","shell.execute_reply":"2022-05-16T13:06:32.273391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_id, num_images = np.unique(train_augmented.classes,return_counts=True)\nmax_value = max(num_images)\nclass_weights = {c : max_value/n for c,n in zip(class_id, num_images)}","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:06:35.431216Z","iopub.execute_input":"2022-05-16T13:06:35.432032Z","iopub.status.idle":"2022-05-16T13:06:35.440988Z","shell.execute_reply.started":"2022-05-16T13:06:35.431985Z","shell.execute_reply":"2022-05-16T13:06:35.440095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's plot 9 images to see if is works :","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nbatch=train_augmented.next()\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(batch[0][i].astype(np.uint8))\n    plt.title(batch[0][i].shape)\n    plt.axis(\"off\")","metadata":{"papermill":{"duration":6.538954,"end_time":"2022-03-30T07:47:47.51561","exception":false,"start_time":"2022-03-30T07:47:40.976656","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:06:38.091586Z","iopub.execute_input":"2022-05-16T13:06:38.092101Z","iopub.status.idle":"2022-05-16T13:06:39.865569Z","shell.execute_reply.started":"2022-05-16T13:06:38.092066Z","shell.execute_reply":"2022-05-16T13:06:39.864114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nbatch=val_augmented.next()\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(batch[0][i].astype(np.uint8))\n    plt.title(batch[0][i].shape)\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:06:43.014893Z","iopub.execute_input":"2022-05-16T13:06:43.015209Z","iopub.status.idle":"2022-05-16T13:06:44.58611Z","shell.execute_reply.started":"2022-05-16T13:06:43.015173Z","shell.execute_reply":"2022-05-16T13:06:44.58505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# It's time to prepare our model and start the training :","metadata":{}},{"cell_type":"code","source":"def plot_history(history, title='', axs=None, exp_name=\"\"): # This is the simple function to plot our training and validation curves\n    if axs is not None:\n        ax1, ax2 = axs\n    else:\n        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    if len(exp_name) > 0 and exp_name[0] != '_':\n        exp_name = '_' + exp_name\n    ax1.plot(history.history['loss'], label='train' + exp_name)\n    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n    ax1.set_ylim(0., 4)\n    ax1.set_title('loss')\n    ax1.legend()\n\n    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n    ax2.plot(history.history['val_accuracy'], label='val_accuracy'  + exp_name)\n    ax2.set_ylim(0, 1)\n    ax2.set_title('Accuracy')\n    ax2.legend()\n    return (ax1, ax2)","metadata":{"papermill":{"duration":0.066367,"end_time":"2022-03-30T07:47:47.63634","exception":false,"start_time":"2022-03-30T07:47:47.569973","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:06:48.39075Z","iopub.execute_input":"2022-05-16T13:06:48.39118Z","iopub.status.idle":"2022-05-16T13:06:48.400935Z","shell.execute_reply.started":"2022-05-16T13:06:48.391137Z","shell.execute_reply":"2022-05-16T13:06:48.400069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(): # Here we choose our model : Efficientnet B1 pretrained with ImageNet dataset with an input shape of 260x260\n    model = tf.keras.applications.EfficientNetB1(include_top=False,weights='imagenet',input_shape=(HEIGHT,WIDTH,3))\n    return model","metadata":{"papermill":{"duration":6.117054,"end_time":"2022-03-30T07:47:53.807006","exception":false,"start_time":"2022-03-30T07:47:47.689952","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:06:55.55426Z","iopub.execute_input":"2022-05-16T13:06:55.554764Z","iopub.status.idle":"2022-05-16T13:06:55.560418Z","shell.execute_reply.started":"2022-05-16T13:06:55.554717Z","shell.execute_reply":"2022-05-16T13:06:55.559659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_nontrainable_layers(model): # We define trainability for the base model\n    model.trainable=False\n    return model\n\ndef set_trainable_layers(model): \n    model.trainable=True\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:07:13.760092Z","iopub.execute_input":"2022-05-16T13:07:13.760705Z","iopub.status.idle":"2022-05-16T13:07:13.766607Z","shell.execute_reply.started":"2022-05-16T13:07:13.760667Z","shell.execute_reply":"2022-05-16T13:07:13.764189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_last_layers(model): # Here we complete our model with last layers for our problem at hand\n#     base_model = set_nontrainable_layers(model)\n    input_layer = tf.keras.Input(shape=(HEIGHT,WIDTH,3))\n    base_model = set_trainable_layers(model)\n    flatten_layer = layers.Flatten()\n    global_layer = layers.GlobalAveragePooling2D()\n    dense_layer = layers.Dense(256, activation='relu', kernel_initializer='he_uniform')\n    dropout_layer = layers.Dropout(0.5)\n    prediction_layer = layers.Dense(num_classes, activation='softmax')\n    \n    model = Sequential([\n#         input_layer,\n        base_model,\n        global_layer,\n        dropout_layer,\n#         flatten_layer,\n#         dense_layer,\n        prediction_layer\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:07:46.637928Z","iopub.execute_input":"2022-05-16T13:07:46.638232Z","iopub.status.idle":"2022-05-16T13:07:46.644523Z","shell.execute_reply.started":"2022-05-16T13:07:46.638199Z","shell.execute_reply":"2022-05-16T13:07:46.643615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(): # We assemble our model and compile it with the proper loss function and metrics for image classification\n    model = load_model()\n    model = add_last_layers(model)\n    \n    opt = tf.keras.optimizers.Adam()\n    model.compile(loss='categorical_crossentropy',\n                 optimizer=opt,\n                 metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:07:58.072021Z","iopub.execute_input":"2022-05-16T13:07:58.072645Z","iopub.status.idle":"2022-05-16T13:07:58.078775Z","shell.execute_reply.started":"2022-05-16T13:07:58.07261Z","shell.execute_reply":"2022-05-16T13:07:58.078033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_effnet= build_model()\nmodel_effnet.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:08:02.362889Z","iopub.execute_input":"2022-05-16T13:08:02.363169Z","iopub.status.idle":"2022-05-16T13:08:08.384135Z","shell.execute_reply.started":"2022-05-16T13:08:02.363132Z","shell.execute_reply":"2022-05-16T13:08:08.383386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_accuracy',\n                   patience=7,\n                   verbose=1,\n                   restore_best_weights=True)\n\ncp = ModelCheckpoint('/kaggle/working/effnetB1.ckpt',\n                     monitor='val_accuracy',\n                     verbose=1,\n                     save_best_only=True,\n                     save_weights_only=False,\n                     mode='min' )\n\ncsv = tf.keras.callbacks.CSVLogger('history_effnetB1.csv')\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n                                                 factor=0.4,\n                                                 verbose=1,\n                                                 patience=2, \n                                                 min_lr=0.00001)","metadata":{"papermill":{"duration":0.066896,"end_time":"2022-03-30T07:47:55.200302","exception":false,"start_time":"2022-03-30T07:47:55.133406","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:09:29.681977Z","iopub.execute_input":"2022-05-16T13:09:29.682484Z","iopub.status.idle":"2022-05-16T13:09:29.688403Z","shell.execute_reply.started":"2022-05-16T13:09:29.68244Z","shell.execute_reply":"2022-05-16T13:09:29.687619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TRAIN = train_augmented.n//train_augmented.batch_size\nSTEP_SIZE_VALID = val_augmented.n//val_augmented.batch_size","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:09:31.952554Z","iopub.execute_input":"2022-05-16T13:09:31.953598Z","iopub.status.idle":"2022-05-16T13:09:31.95931Z","shell.execute_reply.started":"2022-05-16T13:09:31.953549Z","shell.execute_reply":"2022-05-16T13:09:31.958288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nhistory = model_effnet.fit(train_augmented,\n                    epochs=epoch,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    callbacks=[es,cp,reduce_lr,csv],\n                    verbose=1,\n                    class_weight=class_weights,\n                    validation_data=val_augmented,\n                    validation_steps=STEP_SIZE_VALID)","metadata":{"papermill":{"duration":9367.330539,"end_time":"2022-03-30T10:24:02.589412","exception":false,"start_time":"2022-03-30T07:47:55.258873","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-16T13:09:36.560468Z","iopub.execute_input":"2022-05-16T13:09:36.56105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"papermill":{"duration":11.347117,"end_time":"2022-03-30T10:24:17.179815","exception":false,"start_time":"2022-03-30T10:24:05.832698","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we can use our trained model to predict the labels for test images :","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(PATH+'sample_submission.csv')\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen= ImageDataAugmentor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n                                              directory=test_path,\n                                              x_col='filename',\n                                              y_col=None,\n                                              target_size=(WIDTH,HEIGHT),\n                                              color_mode='rgb',\n                                              class_mode=None,\n                                              batch_size=1,\n                                              shuffle=False,)","metadata":{"papermill":{"duration":0.760723,"end_time":"2022-03-30T10:24:18.696646","exception":false,"start_time":"2022-03-30T10:24:17.935923","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TEST=test_generator.n//test_generator.batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TEST,test_generator.n,test_generator.batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\ntest_generator.reset()\nresults = model_effnet.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_results = np.argmax(results,axis=1)\n# label_dict = pd.read_csv(PATH+'train_cultivar_mapping.csv').drop(columns=['image'])\n# best_cultivar = []\n# for result in best_results:\n#     best_cultivar.append(label_dict.iloc[result].values[0])\n# submission['cultivar']=best_cultivar\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_class_indices=np.argmax(results,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = (train_augmented.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames=test_generator.filenames\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n                      \"cultivar\":predictions})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# And finally we create our submission.csv in order to scor our prediction :","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission_effnet_dataaug.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For the moment, the test accuracy remains very low, I am grateful for any comment or suggestion on how to achieve better accuracy with my code.\n\n# Have a nice day","metadata":{}},{"cell_type":"code","source":"!kaggle competitions submit -c sorghum-id-fgvc-9 -f submission_effnet_dataaug.csv -m \"With flow from dataframe generator\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}