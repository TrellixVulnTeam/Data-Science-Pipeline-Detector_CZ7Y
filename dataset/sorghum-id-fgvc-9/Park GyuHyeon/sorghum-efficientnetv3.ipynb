{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ✔️ 필요한 모듈 Install","metadata":{}},{"cell_type":"code","source":"# !pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n!pip install timm # install pytorch image models\n!pip install torchmetrics","metadata":{"papermill":{"duration":20.299559,"end_time":"2022-05-15T02:42:06.284782","exception":false,"start_time":"2022-05-15T02:41:45.985223","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:17:37.743678Z","iopub.execute_input":"2022-06-07T03:17:37.744001Z","iopub.status.idle":"2022-06-07T03:17:56.904391Z","shell.execute_reply.started":"2022-06-07T03:17:37.743969Z","shell.execute_reply":"2022-06-07T03:17:56.903434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ 필요한 Libray Import","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nimport pandas as pd\nimport numpy as np\nimport random \n\nimport albumentations as A\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nimport timm\n\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torchvision.models as models\nimport torch.nn.functional as F\nfrom torch import nn\nimport torchmetrics \nfrom torch.nn.modules.loss import _Loss\nfrom  torch.cuda.amp import autocast, GradScaler","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":9.937056,"end_time":"2022-05-15T02:42:16.252097","exception":false,"start_time":"2022-05-15T02:42:06.315041","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T03:17:56.906325Z","iopub.execute_input":"2022-06-07T03:17:56.906586Z","iopub.status.idle":"2022-06-07T03:17:58.610519Z","shell.execute_reply.started":"2022-06-07T03:17:56.906557Z","shell.execute_reply":"2022-06-07T03:17:58.609655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Model Configure\n### ➿ 사용 모델 - efficientnet_b3\n-----\n* **Train batch 사이즈 - 8**\n* **validation batch 사이즈 - 32**\n* **사용 모델 - efficientnet_b3**\n* **Learning rate - 3e-5**\n* **Epoch - 20**","metadata":{}},{"cell_type":"code","source":"class GlobalConstantsConfigure():\n    def __init__(self):\n        self.continue_training = True\n        self.last_model = '../input/sorghum-100-cultivar-identification/resnext50d_32x4d_60_last.pt' \n        self.num_epochs_done = 40\n        self.seed = 127 # 107\n        self.fold = 1\n        self.num_folds = 4\n        self.num_classes = 100\n        self.biggest_loss = 999\n        self.training_size_rate = 0.8\n        self.training_dir = '../input/sorghum-id-fgvc-9/train_images'\n        self.model_name = 'efficientnet_b3'\n        self.model_path = './rexnet_150.pt'\n        self.image_size = 512\n        self.batch_size = 8\n        self.val_batch_size = 32\n        self.lr = 3e-5 # 3e-5\n        self.num_epochs = 1\n        self.steps_per_decay = 5\n        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n        self.num_workers = 1  # if torch.cuda.is_available() else 4\n        \ngcc = GlobalConstantsConfigure()","metadata":{"papermill":{"duration":0.098421,"end_time":"2022-05-15T02:42:17.15626","exception":false,"start_time":"2022-05-15T02:42:17.057839","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:15.026867Z","iopub.execute_input":"2022-06-07T04:17:15.027791Z","iopub.status.idle":"2022-06-07T04:17:15.036759Z","shell.execute_reply.started":"2022-06-07T04:17:15.027713Z","shell.execute_reply":"2022-06-07T04:17:15.03595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed) : \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nset_seed(gcc.seed)","metadata":{"papermill":{"duration":0.044999,"end_time":"2022-05-15T02:42:17.231345","exception":false,"start_time":"2022-05-15T02:42:17.186346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:16.985081Z","iopub.execute_input":"2022-06-07T04:17:16.985874Z","iopub.status.idle":"2022-06-07T04:17:16.997575Z","shell.execute_reply.started":"2022-06-07T04:17:16.985828Z","shell.execute_reply":"2022-06-07T04:17:16.996463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ✔️ Train DataSet 확인 & Nan 값 제거","metadata":{}},{"cell_type":"code","source":"df_all = pd.read_csv('../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv')\nprint(len(df_all))\n\ndf_all.dropna(inplace=True)\nprint(len(df_all))\n\ndf_all.head()","metadata":{"papermill":{"duration":0.097813,"end_time":"2022-05-15T02:42:17.359361","exception":false,"start_time":"2022-05-15T02:42:17.261548","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:20.074507Z","iopub.execute_input":"2022-06-07T04:17:20.074839Z","iopub.status.idle":"2022-06-07T04:17:20.127149Z","shell.execute_reply.started":"2022-06-07T04:17:20.074802Z","shell.execute_reply":"2022-06-07T04:17:20.126027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Train DataSet 전처리 & 모델 입력값 수정","metadata":{}},{"cell_type":"code","source":"### class 개수 확인 & 유일한 값 추출\nunique_cultivars = list(df_all[\"cultivar\"].unique())","metadata":{"papermill":{"duration":0.044312,"end_time":"2022-05-15T02:42:17.43483","exception":false,"start_time":"2022-05-15T02:42:17.390518","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:22.351626Z","iopub.execute_input":"2022-06-07T04:17:22.351971Z","iopub.status.idle":"2022-06-07T04:17:22.360138Z","shell.execute_reply.started":"2022-06-07T04:17:22.351933Z","shell.execute_reply":"2022-06-07T04:17:22.358819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train DataSet 파일 불러오기 & DataFrame에 저장\ndf_all[\"file_path\"] = df_all[\"image\"].apply(lambda image: '../input/sorghum-id-fgvc-9/train_images/' + image)\n\n# 본래 Train DataSet 파일 속 class 이름 속 인덱스 저장\n# 유일한 값에 해당 & 유일한 값의 인덱스 저장\ndf_all[\"cultivar_index\"] = df_all[\"cultivar\"].map(lambda item: unique_cultivars.index(item))\n\n# 파일 이름 중 존재 하는 경우 저장\ndf_all[\"is_exist\"] = df_all[\"file_path\"].apply(lambda file_path: os.path.exists(file_path))\n\n# 존재하는 파일만 저장하기 때문에 존재 여부 True\ndf_all = df_all[df_all.is_exist==True]\n\n# Train DataSet Head 추출\ndf_all.head()","metadata":{"papermill":{"duration":41.392566,"end_time":"2022-05-15T02:42:58.858163","exception":false,"start_time":"2022-05-15T02:42:17.465597","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:23.849917Z","iopub.execute_input":"2022-06-07T04:17:23.850209Z","iopub.status.idle":"2022-06-07T04:17:33.370613Z","shell.execute_reply.started":"2022-06-07T04:17:23.850179Z","shell.execute_reply":"2022-06-07T04:17:33.369577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Train DataSet & Validation DataSet 분리\n-----\n* **KFold 방법론 사용**\n* **KFold 횟수 - 4**","metadata":{}},{"cell_type":"code","source":"# 총 KFold 수 - 4번\nskf = StratifiedKFold(n_splits=gcc.num_folds, shuffle=True, random_state=gcc.seed)\n\n# DataSet 담을 List 선언\ntrain_folds = []\nval_folds = []\n\nfor train_idx, valid_idx in skf.split(df_all['image'], df_all[\"cultivar_index\"]):\n    train_folds.append(train_idx)\n    val_folds.append(valid_idx)\n\ndf_train = df_all.iloc[train_folds[gcc.fold]]\ndf_valid = df_all.iloc[val_folds[gcc.fold]]\n\nprint(f\"train size: {len(df_train)}\")\nprint(f\"valid size: {len(df_valid)}\")\n\nprint(df_train.cultivar.value_counts())\nprint(df_valid.cultivar.value_counts())","metadata":{"papermill":{"duration":0.068452,"end_time":"2022-05-15T02:42:58.958295","exception":false,"start_time":"2022-05-15T02:42:58.889843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.373184Z","iopub.execute_input":"2022-06-07T04:17:33.373877Z","iopub.status.idle":"2022-06-07T04:17:33.412545Z","shell.execute_reply.started":"2022-06-07T04:17:33.37382Z","shell.execute_reply":"2022-06-07T04:17:33.411574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Image 전처리\n-----\n* **Random Box를 이용하여 이미지를 자름**\n* **랜덤으로 추출한 Postion을 이용하여 해당 위치부터 Random 박스 이용하여 자름**\n* **본래 가지고 있던 Image 사이즈를 원하는 사이즈인 512로 바꾸기 위한 과정**","metadata":{}},{"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 20,40\n\n# Random 박스 생성 & 결국에는 새로운 Image 생성\n# 다른 전처리를 하지는 않고 자르기만 진행\ndef rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int64(W * cut_rat)\n    cut_h = np.int64(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\n\n# 자르기 위한 전처리 과정\ndef cutmix(data, target, alpha):\n    \n    # 정수로 구성된 난수를 생성 -> Data 사이즈 범위 내에서 생성\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_target = target[indices]\n\n    lam = np.clip(np.random.beta(alpha, alpha),0.3,0.4)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n    \n    # 이미지 요소를 그대로 복제\n    new_data = data.clone()\n    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n    \n    # rand_bbox에서 나온 결과값을 Data의 픽셀과 비율을 정확하게 매치 시키기 위한 과정 수행\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n    targets = (target, shuffled_target, lam)\n\n    return new_data, targets","metadata":{"papermill":{"duration":0.056354,"end_time":"2022-05-15T02:42:59.051932","exception":false,"start_time":"2022-05-15T02:42:58.995578","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.414204Z","iopub.execute_input":"2022-06-07T04:17:33.414618Z","iopub.status.idle":"2022-06-07T04:17:33.435081Z","shell.execute_reply.started":"2022-06-07T04:17:33.41456Z","shell.execute_reply":"2022-06-07T04:17:33.433557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ✔️ 불러온 DataSet을 전처리하기 전 사용하는 함수 & 클래스 정의","metadata":{}},{"cell_type":"code","source":"class SorghumDataset(Dataset):\n    def __init__(self, dirs, labels, transformation=None):\n        super(SorghumDataset,self).__init__()\n        self.dirs = dirs\n        self.labels = labels\n        self.transformation = transformation\n    def __len__(self):\n        return len(self.dirs)\n\n    def __getitem__(self, index):\n        image = cv2.imread(self.dirs[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.labels[index] # need to one hot encoding here\n        \n        image = np.array(image)\n\n        if self.transformation:\n            aug_image = self.transformation(image=image)\n            image = aug_image['image']\n        \n        # 픽셀 값을 255로 나누어 정규화 진행\n        image = image / 255.\n        image = image.transpose((2, 0, 1))\n        \n        image = torch.from_numpy(image).type(torch.float32)\n        image = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n        \n        labels = torch.from_numpy(np.array(self.labels[index])).type(torch.float32)\n\n        return image, labels","metadata":{"papermill":{"duration":0.043394,"end_time":"2022-05-15T02:42:59.129655","exception":false,"start_time":"2022-05-15T02:42:59.086261","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.438469Z","iopub.execute_input":"2022-06-07T04:17:33.439208Z","iopub.status.idle":"2022-06-07T04:17:33.453525Z","shell.execute_reply.started":"2022-06-07T04:17:33.439143Z","shell.execute_reply":"2022-06-07T04:17:33.452775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_transformation = A.Compose([\n    A.Resize(width=gcc.image_size, height=gcc.image_size, p=1.0),\n    A.Flip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(p=0.5),\n    A.HueSaturationValue(p=0.5),\n])\n\nvalidation_transformation = A.Compose([\n    A.Resize(width=gcc.image_size, height=gcc.image_size, p=1.0)\n])","metadata":{"papermill":{"duration":0.040413,"end_time":"2022-05-15T02:42:59.201618","exception":false,"start_time":"2022-05-15T02:42:59.161205","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.455162Z","iopub.execute_input":"2022-06-07T04:17:33.45576Z","iopub.status.idle":"2022-06-07T04:17:33.469351Z","shell.execute_reply.started":"2022-06-07T04:17:33.455691Z","shell.execute_reply":"2022-06-07T04:17:33.468619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Train & Validation DataSet 로드\n-----\n* **Train batch size : 8**\n* **Validation batch size : 32**\n* **Suffle : True**","metadata":{}},{"cell_type":"code","source":"training_set = SorghumDataset(df_train.file_path.values, df_train.cultivar_index.values, training_transformation)\nvalidation_set = SorghumDataset(df_valid.file_path.values, df_valid.cultivar_index.values, validation_transformation)\n\ntraining_dataloader = DataLoader(\n    training_set,\n    batch_size = gcc.batch_size,\n    shuffle = True,\n    num_workers = gcc.num_workers,\n    pin_memory = True, \n    drop_last = True\n)\n\nvalidation_dataloader = DataLoader(\n    validation_set,\n    batch_size = gcc.val_batch_size,\n    shuffle = True,\n    num_workers = gcc.num_workers,\n    pin_memory = True,\n    drop_last = True\n)","metadata":{"papermill":{"duration":0.040182,"end_time":"2022-05-15T02:42:59.27266","exception":false,"start_time":"2022-05-15T02:42:59.232478","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.471259Z","iopub.execute_input":"2022-06-07T04:17:33.471631Z","iopub.status.idle":"2022-06-07T04:17:33.482527Z","shell.execute_reply.started":"2022-06-07T04:17:33.47158Z","shell.execute_reply":"2022-06-07T04:17:33.48146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ 사용하고자 하는 모델을 원하는 모델로 재정의","metadata":{}},{"cell_type":"code","source":"class CustomModel(torch.nn.Module): \n    def __init__(self, model_backbone):\n        super(CustomModel,self).__init__()\n        self.model = model_backbone\n        self.num_in_features = self.model.get_classifier().in_features\n        print(self.num_in_features)\n        \n        # 여러 클래스를 구분하기 위해서 Sequential 사용\n        # 활성 함수 : ReLU\n        # 과적합 방지를 위한 Dropout : 0.5 설정\n        self.model.classifier = nn.Sequential(\n            nn.BatchNorm1d(self.num_in_features),\n            nn.Linear(self.num_in_features, 512),\n            nn.Dropout(0.5),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, gcc.num_classes),\n        )\n\n    def forward(self,x):\n        x = self.model(x)\n        return x","metadata":{"papermill":{"duration":0.039676,"end_time":"2022-05-15T02:42:59.343183","exception":false,"start_time":"2022-05-15T02:42:59.303507","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.484339Z","iopub.execute_input":"2022-06-07T04:17:33.484687Z","iopub.status.idle":"2022-06-07T04:17:33.497083Z","shell.execute_reply.started":"2022-06-07T04:17:33.48464Z","shell.execute_reply":"2022-06-07T04:17:33.496128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_one_hot(labels, num_classes, dtype=torch.float, dim=1):\n    if labels.ndim < dim + 1:\n        shape = list(labels.shape) + [1] * (dim + 1 - len(labels.shape))\n        labels = torch.reshape(labels, shape)\n    sh = list(labels.shape)\n    sh[dim] = num_classes\n    o = torch.zeros(size=sh, dtype=dtype, device=labels.device)\n    labels = o.scatter_(dim=dim, index=labels.long(), value=1)\n    return labels\n\nclass PolyLoss(_Loss):\n    def __init__(self, softmax, ce_weight=None, reduction='mean', epsilon=1.0):\n        super().__init__()\n        self.softmax = softmax\n        self.reduction = reduction\n        self.epsilon = epsilon\n        self.cross_entropy = nn.CrossEntropyLoss(weight=ce_weight, reduction='none')\n\n    def forward(self, input, target):\n\n        if len(input.shape) - len(target.shape) == 1:\n            target = target.unsqueeze(1).long()\n        n_pred_ch, n_target_ch = input.shape[1], target.shape[1]\n        if n_pred_ch != n_target_ch:\n            self.ce_loss = self.cross_entropy(input, torch.squeeze(target, dim=1).long())\n            target = to_one_hot(target, num_classes=n_pred_ch)\n        else:\n            self.ce_loss = self.cross_entropy(input, torch.argmax(target, dim=1))\n\n        if self.softmax:\n            input = torch.softmax(input, 1)\n\n        pt = (input * target).sum(dim=1) \n        \n        poly_loss = self.ce_loss + self.epsilon * (1 - pt)\n\n        polyl = torch.mean(poly_loss)  # the batch and channel average\n        # polyl = torch.sum(poly_loss)  # sum over the batch and channel dims\n        return (polyl)","metadata":{"papermill":{"duration":0.045133,"end_time":"2022-05-15T02:42:59.419914","exception":false,"start_time":"2022-05-15T02:42:59.374781","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:33.499131Z","iopub.execute_input":"2022-06-07T04:17:33.499594Z","iopub.status.idle":"2022-06-07T04:17:33.518335Z","shell.execute_reply.started":"2022-06-07T04:17:33.499553Z","shell.execute_reply":"2022-06-07T04:17:33.517333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ 학습에 필요한 함수들 선언\n-----\n* **Loss 함수 : CrossEntropyLoss**\n* **Optimizer 함수 : Adam**\n* **스케줄러 : CosineAnnealingWarmRestarts**","metadata":{}},{"cell_type":"code","source":"# 사용하고자 하는 모델 불러와서 새롭게 재정의\nbackbone = timm.create_model(gcc.model_name,pretrained=True)\n\nscaler = GradScaler()   \n# 재정의 할 클래스에 입력\nmodel = CustomModel(backbone)\n\nloss_func = torch.nn.CrossEntropyLoss().to(gcc.device)\nmetrics_acc = torchmetrics.Accuracy(threshold=0.0, num_classes = gcc.num_classes)\n\ntrainable_parameters = [param for param in model.parameters() if param.requires_grad == True]\noptimizer = torch.optim.Adam(trainable_parameters, lr = gcc.lr)\n\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n\nmodel.to(gcc.device)\n\nprint('load model done')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:17:33.520038Z","iopub.execute_input":"2022-06-07T04:17:33.520813Z","iopub.status.idle":"2022-06-07T04:17:37.213314Z","shell.execute_reply.started":"2022-06-07T04:17:33.520719Z","shell.execute_reply":"2022-06-07T04:17:37.212171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Image Data 분석\n------\n* **Color Image로 구성되어있어서 tensor[0]에 3가지(R,G,B)의 이미지 정보가 들어있음**\n* **tensor[1]에는 label이 함께 포함이 됨**","metadata":{}},{"cell_type":"code","source":"training_set[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:17:37.21596Z","iopub.execute_input":"2022-06-07T04:17:37.216238Z","iopub.status.idle":"2022-06-07T04:17:37.379702Z","shell.execute_reply.started":"2022-06-07T04:17:37.216208Z","shell.execute_reply":"2022-06-07T04:17:37.378997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Model 학습 진행\n------\n* **학습을 진행하면서 주석처리 부분을 이용하여 사용되는 Data 확인**","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as T\nfrom torchvision.transforms.functional import to_pil_image\n\ndef training_progress(training_dataloader, loss_func, scheduler):\n    model.train()\n    training_loss = 0\n    training_acc = 0\n    cnt = 0 \n    print('Learning rate: ',scheduler.get_last_lr())\n    print(scheduler.state_dict())\n    training_loader = tqdm(training_dataloader, desc='Iterating through the training set')\n    for image, label in training_loader:\n        image = image.to(gcc.device).float()\n        label = label.to(gcc.device).long()\n\n#         plt.figure()\n#         plt.subplot(1,2,1)\n#         plt.imshow(to_pil_image(image[0]), cmap='gray')\n#         plt.title('train')\n\n        mix_decision = np.random.rand()\n        if mix_decision < 0.25:\n            image, label = cutmix(image, label, 1.)\n\n        with autocast():\n            output = model(image.float())\n\n            if mix_decision < 0.25:\n\n                acc = metrics_acc(output, label[0].cpu().argmax(1)) * label[2].cpu().argmax(1) + metric_acc(output, label[1].cpu().argmax(1)) * (1. - label[2].cpu().argmax(1)) # metrics_acc(output.cpu().argmax(1), label.cpu().int())\n                loss = loss_func(output, label[0]) * label[2] + loss_func(output, label[1]) * (1. - label[2])\n                \n            else:\n                loss = loss_func(output, label)\n\n        # acc = 0\n        acc = metrics_acc(output.cpu().argmax(1), label.cpu().int())\n        # metrics_acc(output.cpu().argmax(1), label.cpu().int())\n        # loss = loss_func(output, label.long())\n\n        training_loss += loss.detach().item()\n        training_acc += acc\n        cnt +=1 \n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    \n    mean_training_loss = training_loss / cnt\n    mean_training_acc = training_acc / cnt\n    \n    return mean_training_loss, mean_training_acc","metadata":{"papermill":{"duration":0.04628,"end_time":"2022-05-15T02:43:29.169155","exception":false,"start_time":"2022-05-15T02:43:29.122875","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:37.380704Z","iopub.execute_input":"2022-06-07T04:17:37.381392Z","iopub.status.idle":"2022-06-07T04:17:37.396768Z","shell.execute_reply.started":"2022-06-07T04:17:37.381333Z","shell.execute_reply":"2022-06-07T04:17:37.395989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Model Validation 진행\n------\n* **정확도가 떨어지는 class를 확인하기 위해 데이터셋의 label과 모델 예측 label을 저장**\n* **batch size가 32로 설정이 되어있어, label_list에 32개씩 저장됨**\n* **예측값과 정답을 비교하여, 정확도가 떨어지는 class 찾기**","metadata":{}},{"cell_type":"code","source":"label_list = []\n\ndef validation_progress(validation_dataloader, loss_func):\n    model.eval()\n    validation_loss = 0\n    validation_acc = 0\n    cnt = 0 \n    global label_list\n    validation_loader = tqdm(validation_dataloader, desc='Iterating through the validation set')\n    with torch.no_grad():\n        for image, label in validation_loader:\n            image = image.to(gcc.device)\n            label = label.to(gcc.device)\n\n            output = model(image)\n            loss = loss_func(output, label.long())\n            # acc = calc_accuracy(output.cpu(), label.cpu())\n            # output.to(gcc.device)\n            acc = metrics_acc(output.cpu().argmax(1), label.cpu().int())\n            label_list.append(output.cpu().argmax(1))\n            label_list.append(label.cpu().int())\n            # calculate accuracy here\n            validation_loss += loss.detach().item()\n            validation_acc += acc\n            \n            cnt += 1\n\n    mean_validation_loss = validation_loss / cnt\n    mean_validation_acc = validation_acc / cnt\n    return mean_validation_loss, mean_validation_acc","metadata":{"papermill":{"duration":0.042979,"end_time":"2022-05-15T02:43:29.24513","exception":false,"start_time":"2022-05-15T02:43:29.202151","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:38.111007Z","iopub.execute_input":"2022-06-07T04:17:38.111504Z","iopub.status.idle":"2022-06-07T04:17:38.122921Z","shell.execute_reply.started":"2022-06-07T04:17:38.111468Z","shell.execute_reply":"2022-06-07T04:17:38.121842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_model(model, training_dataloader, validation_dataloader, loss_func, scheduler):\n    training_losses_history, validation_losses_history = [], []\n    training_acc_history, validation_acc_history = [], []\n    best_loss = gcc.biggest_loss\n    for epoch in range(gcc.num_epochs):\n        \n        training_loss, training_acc = training_progress(training_dataloader, loss_func, scheduler)\n        training_losses_history.append(training_loss)\n        training_acc_history.append(training_acc)\n        \n        validation_loss, validation_acc = validation_progress(validation_dataloader, loss_func)\n        validation_losses_history.append(validation_loss)\n        validation_acc_history.append(validation_acc)\n        \n        if validation_loss <= best_loss: # sussy baka\n            best_loss = validation_loss\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict()\n            }, gcc.model_name + '_best.pt')\n            # torch.save(model.state_dict(), gcc.model_name + '_best.pt')\n        \n        if epoch == gcc.num_epochs - 1: # i believe my timing capability\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict()\n            }, gcc.model_name + '_' + str(gcc.num_epochs_done + gcc.num_epochs) + '_last.pt')\n\n        print(f'Epoch {epoch + 1}/{gcc.num_epochs} | Training_loss : {training_loss:.3f} | Validation_loss : {validation_loss:.3f}' \n             + f' Training_acc : {training_acc:.3f} | Validation_acc : {validation_acc:.3f}'\n             )\n    return training_losses_history, validation_losses_history, training_acc_history, validation_acc_history\n","metadata":{"papermill":{"duration":0.045573,"end_time":"2022-05-15T02:43:29.324245","exception":false,"start_time":"2022-05-15T02:43:29.278672","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:40.213458Z","iopub.execute_input":"2022-06-07T04:17:40.21399Z","iopub.status.idle":"2022-06-07T04:17:40.226339Z","shell.execute_reply.started":"2022-06-07T04:17:40.213946Z","shell.execute_reply":"2022-06-07T04:17:40.225224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training_losses_history, validation_losses_history, training_acc_history, validation_acc_history = training_model(model, training_dataloader, validation_dataloader, loss_func, lr_scheduler)","metadata":{"papermill":{"duration":32460.236904,"end_time":"2022-05-15T11:44:29.594253","exception":false,"start_time":"2022-05-15T02:43:29.357349","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T04:17:41.481601Z","iopub.execute_input":"2022-06-07T04:17:41.482539Z","iopub.status.idle":"2022-06-07T04:17:53.32578Z","shell.execute_reply.started":"2022-06-07T04:17:41.482487Z","shell.execute_reply":"2022-06-07T04:17:53.322283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Model 학습 상황 (Loss, Accuracy)\n------\n* **Train, Validation Loss는 계속해서 떨어지고 있는 양상을 보임**\n* **Accuracy도 계속해서 오르는 추세를 보이지만, 20 epoch 가까이 가게 되면 일정 수준을 유지하거나 떨어지기 시작함**","metadata":{}},{"cell_type":"code","source":"def plot_loss_history(model_name, train_loss_history, val_loss_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_loss_history, label='Train Loss', lw=3)\n    plt.plot(x, val_loss_history, label='Validation Loss', lw=3)\n\n    plt.title(f\"{model_name}\", fontsize=20)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"Loss\", fontsize=15)\n\n    plt.show()\n    \nplot_loss_history(gcc.model_name, training_losses_history, validation_losses_history, gcc.num_epochs)","metadata":{"papermill":{"duration":15.355875,"end_time":"2022-05-15T11:45:29.737309","exception":false,"start_time":"2022-05-15T11:45:14.381434","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:23:18.728462Z","iopub.execute_input":"2022-06-06T13:23:18.728926Z","iopub.status.idle":"2022-06-06T13:23:19.009991Z","shell.execute_reply.started":"2022-06-06T13:23:18.72889Z","shell.execute_reply":"2022-06-06T13:23:19.009253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_acc_history(model_name, train_acc_history, val_acc_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_acc_history, label='Training Accuracy', lw=3)\n    plt.plot(x, val_acc_history, label='Validation Accuracy', lw=3)\n\n    plt.title(f\"{model_name}\", fontsize=20)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"Accuracy\", fontsize=15)\n\n    plt.show()\n    \nplot_acc_history(gcc.model_name, training_acc_history, validation_acc_history, gcc.num_epochs)","metadata":{"papermill":{"duration":15.266458,"end_time":"2022-05-15T11:45:59.867503","exception":false,"start_time":"2022-05-15T11:45:44.601045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:23:19.011602Z","iopub.execute_input":"2022-06-06T13:23:19.012093Z","iopub.status.idle":"2022-06-06T13:23:19.224901Z","shell.execute_reply.started":"2022-06-06T13:23:19.012053Z","shell.execute_reply":"2022-06-06T13:23:19.224256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load(gcc.model_name + '_best.pt')\nmodel.load_state_dict(checkpoint['model_state_dict'])","metadata":{"papermill":{"duration":16.577703,"end_time":"2022-05-15T11:46:30.941925","exception":false,"start_time":"2022-05-15T11:46:14.364222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:23:19.226118Z","iopub.execute_input":"2022-06-06T13:23:19.226373Z","iopub.status.idle":"2022-06-06T13:23:19.570119Z","shell.execute_reply.started":"2022-06-06T13:23:19.226341Z","shell.execute_reply":"2022-06-06T13:23:19.56943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Model Test\n------\n* **Test DataSet 개수 : 23639개**","metadata":{}},{"cell_type":"code","source":"sub[\"filename\"] = sub[\"filename\"].apply(lambda image: '../input/sorghum-id-fgvc-9/test/' + image)\nsub[\"cultivar\"] = 0\n\nsub.head()","metadata":{"papermill":{"duration":14.592959,"end_time":"2022-05-15T11:47:29.938039","exception":false,"start_time":"2022-05-15T11:47:15.34508","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T16:29:40.241518Z","iopub.execute_input":"2022-06-06T16:29:40.242287Z","iopub.status.idle":"2022-06-06T16:29:40.266986Z","shell.execute_reply.started":"2022-06-06T16:29:40.242248Z","shell.execute_reply":"2022-06-06T16:29:40.266262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_dataset = SorghumDataset(sub['filename'], sub['cultivar'], validation_transformation)\n\ntesting_dataloader = DataLoader(testing_dataset, \n                                batch_size=gcc.val_batch_size, \n                                shuffle=False, \n                                num_workers=gcc.num_workers)","metadata":{"papermill":{"duration":14.557059,"end_time":"2022-05-15T11:47:59.440386","exception":false,"start_time":"2022-05-15T11:47:44.883327","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:23:19.669227Z","iopub.execute_input":"2022-06-06T13:23:19.669476Z","iopub.status.idle":"2022-06-06T13:23:19.673866Z","shell.execute_reply.started":"2022-06-06T13:23:19.669447Z","shell.execute_reply":"2022-06-06T13:23:19.673189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions = np.zeros(len(testing_dataloader))\npredictions = []\ncnt = 0 \nwith torch.no_grad():\n    for image, label in tqdm(testing_dataloader):\n        image = image.to(gcc.device)\n        outputs = model(image)\n        # print(outputs)\n        preds = outputs.detach().cpu()\n        predictions.append(preds.argmax(1)) # need optimize here\n        # print(predictions)","metadata":{"papermill":{"duration":1234.674931,"end_time":"2022-05-15T12:08:49.430358","exception":false,"start_time":"2022-05-15T11:48:14.755427","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:23:19.675656Z","iopub.execute_input":"2022-06-06T13:23:19.676208Z","iopub.status.idle":"2022-06-06T13:53:08.268829Z","shell.execute_reply.started":"2022-06-06T13:23:19.676167Z","shell.execute_reply":"2022-06-06T13:53:08.267991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = predictions[0]\nfor i in range(len(predictions) - 1):\n    tmp = torch.cat((tmp, predictions[i+1]))","metadata":{"papermill":{"duration":14.585764,"end_time":"2022-05-15T12:09:19.303547","exception":false,"start_time":"2022-05-15T12:09:04.717783","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:53:08.271548Z","iopub.execute_input":"2022-06-06T13:53:08.272222Z","iopub.status.idle":"2022-06-06T13:53:08.28712Z","shell.execute_reply.started":"2022-06-06T13:53:08.27219Z","shell.execute_reply":"2022-06-06T13:53:08.286266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions = label_encoder.inverse_transform(tmp)\npredictions = [unique_cultivars[pred] for pred in tmp]","metadata":{"papermill":{"duration":15.264096,"end_time":"2022-05-15T12:09:49.13467","exception":false,"start_time":"2022-05-15T12:09:33.870574","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:53:08.291985Z","iopub.execute_input":"2022-06-06T13:53:08.292217Z","iopub.status.idle":"2022-06-06T13:53:08.339775Z","shell.execute_reply.started":"2022-06-06T13:53:08.292189Z","shell.execute_reply":"2022-06-06T13:53:08.338817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/sorghum-id-fgvc-9/sample_submission.csv')\nsub['cultivar'] = predictions\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"papermill":{"duration":15.270386,"end_time":"2022-05-15T12:10:18.808727","exception":false,"start_time":"2022-05-15T12:10:03.538341","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-06T13:53:08.341439Z","iopub.execute_input":"2022-06-06T13:53:08.341774Z","iopub.status.idle":"2022-06-06T13:53:08.432998Z","shell.execute_reply.started":"2022-06-06T13:53:08.341735Z","shell.execute_reply":"2022-06-06T13:53:08.432267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ✔️ Model 학습 결과, 정확도가 떨어지는 Class 찾기\n------\n* **정확도가 떨어지는 class를 찾기 위해 모델 예측값과 정답 비교**\n* **label_list = 모델 예측값, 정답**","metadata":{}},{"cell_type":"code","source":"label_list[:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-06T15:27:05.51097Z","iopub.execute_input":"2022-06-06T15:27:05.511263Z","iopub.status.idle":"2022-06-06T15:27:05.52049Z","shell.execute_reply.started":"2022-06-06T15:27:05.511233Z","shell.execute_reply":"2022-06-06T15:27:05.51953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ❤️ 저장된 값 타입 변경 : Tensor -> DataFrame\n------\n* **label_list 내부는 Tensor로 저장**","metadata":{}},{"cell_type":"code","source":"label_list_model = []\nlabel_list_answer = []\n\nfor i in range(len(label_list)):\n    if i % 2 == 0:\n        for j in range(32):\n            label_list_model.append((label_list[i].tolist()[j]))\n\n    else :\n        for j in range(32):\n            label_list_answer.append((label_list[i].tolist())[j])\n\nlabel_pre = pd.DataFrame({'model_pre':[], 'answer':[]})\n\nlabel_pre['model_pre'] = label_list_model\nlabel_pre['answer'] = label_list_answer\n\nlabel_pre","metadata":{"execution":{"iopub.status.busy":"2022-06-06T16:08:21.165126Z","iopub.execute_input":"2022-06-06T16:08:21.165491Z","iopub.status.idle":"2022-06-06T16:08:21.990519Z","shell.execute_reply.started":"2022-06-06T16:08:21.16545Z","shell.execute_reply":"2022-06-06T16:08:21.989685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_answer = []\n\nfor i in range(len(label_pre)):\n    if label_pre['model_pre'][i] == label_pre['answer'][i]:\n        is_answer.append(1)\n    else:\n        is_answer.append(0)\n        \nlabel_pre['is_answer'] = is_answer\n\nlabel_pre","metadata":{"execution":{"iopub.status.busy":"2022-06-06T16:21:20.064963Z","iopub.execute_input":"2022-06-06T16:21:20.065753Z","iopub.status.idle":"2022-06-06T16:21:21.682256Z","shell.execute_reply.started":"2022-06-06T16:21:20.065714Z","shell.execute_reply":"2022-06-06T16:21:21.681475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = {}\n\nfor i in range(100):\n    prediction[i] = 0\n\nfor i in range(1731,):\n    if label_pre['is_answer'][i] == 0:\n        prediction[label_pre['answer'][i]] = prediction[label_pre['answer'][i]] + 1\n\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T17:10:16.69419Z","iopub.execute_input":"2022-06-06T17:10:16.694497Z","iopub.status.idle":"2022-06-06T17:10:16.740041Z","shell.execute_reply.started":"2022-06-06T17:10:16.694462Z","shell.execute_reply":"2022-06-06T17:10:16.739113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pre = pd.read_csv('../input/is-false/label_list.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T03:30:40.819462Z","iopub.execute_input":"2022-06-07T03:30:40.819788Z","iopub.status.idle":"2022-06-07T03:30:40.848828Z","shell.execute_reply.started":"2022-06-07T03:30:40.819754Z","shell.execute_reply":"2022-06-07T03:30:40.847789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_false = pd.DataFrame({'model_pre':[], 'answer':[], 'is_answer' : []})\n\nmodel_pre = []\nanswer = []\nis_answer = []\n\nfor i in range(len(label_pre)):\n    if label_pre['is_answer'][i] == 0:\n        model_pre.append(label_pre['model_pre'][i])\n        answer.append(label_pre['answer'][i])\n        is_answer.append(label_pre['is_answer'][i])\n        \nis_false['model_pre'] = model_pre\nis_false['answer'] = answer\nis_false['is_answer'] = is_answer\n\nis_false","metadata":{"execution":{"iopub.status.busy":"2022-06-07T03:33:53.654328Z","iopub.execute_input":"2022-06-07T03:33:53.654637Z","iopub.status.idle":"2022-06-07T03:33:55.159313Z","shell.execute_reply.started":"2022-06-07T03:33:53.654603Z","shell.execute_reply":"2022-06-07T03:33:55.158334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=[24, 6], dpi=200)\nsns.countplot(x=is_false['answer'])\nplt.xticks(rotation=60)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:01:17.709439Z","iopub.execute_input":"2022-06-07T04:01:17.709709Z","iopub.status.idle":"2022-06-07T04:01:19.028322Z","shell.execute_reply.started":"2022-06-07T04:01:17.70968Z","shell.execute_reply":"2022-06-07T04:01:19.027383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_all[\"cultivar_index\"] = df_all[\"cultivar\"].map(lambda item: unique_cultivars.index(item))\nfor i in range(len(df_all)):\n    if df_all[\"cultivar_index\"][i] == 6:\n        print(df_all['image'][i], df_all[\"cultivar\"][i], i)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:26:57.498302Z","iopub.execute_input":"2022-06-07T04:26:57.498952Z","iopub.status.idle":"2022-06-07T04:26:57.661678Z","shell.execute_reply.started":"2022-06-07T04:26:57.498897Z","shell.execute_reply":"2022-06-07T04:26:57.65967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class31 = pd.DataFrame({'model_pre':[], 'answer':[], 'is_answer' : []})\n\nmodel_pre = []\nanswer = []\nis_answer = []\n\nfor i in range(len(is_false)):\n    if is_false['answer'][i] == 32:\n        model_pre.append(is_false['model_pre'][i])\n        answer.append(is_false['answer'][i])\n        is_answer.append(is_false['is_answer'][i])\n        \nclass31['model_pre'] = model_pre\nclass31['answer'] = answer\nclass31['is_answer'] = is_answer\n\nclass31","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:10:57.651352Z","iopub.execute_input":"2022-06-07T04:10:57.652327Z","iopub.status.idle":"2022-06-07T04:10:57.880781Z","shell.execute_reply.started":"2022-06-07T04:10:57.652286Z","shell.execute_reply":"2022-06-07T04:10:57.880097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class90 = pd.DataFrame({'model_pre':[], 'answer':[], 'is_answer' : []})\n\nmodel_pre = []\nanswer = []\nis_answer = []\n\nfor i in range(len(is_false)):\n    if is_false['answer'][i] == 90:\n        model_pre.append(is_false['model_pre'][i])\n        answer.append(is_false['answer'][i])\n        is_answer.append(is_false['is_answer'][i])\n        \nclass90['model_pre'] = model_pre\nclass90['answer'] = answer\nclass90['is_answer'] = is_answer\n\nclass90","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:12:21.66538Z","iopub.execute_input":"2022-06-07T04:12:21.666088Z","iopub.status.idle":"2022-06-07T04:12:21.917897Z","shell.execute_reply.started":"2022-06-07T04:12:21.666023Z","shell.execute_reply":"2022-06-07T04:12:21.916666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class72 = pd.DataFrame({'model_pre':[], 'answer':[], 'is_answer' : []})\n\nmodel_pre = []\nanswer = []\nis_answer = []\n\nfor i in range(len(is_false)):\n    if is_false['answer'][i] == 72:\n        model_pre.append(is_false['model_pre'][i])\n        answer.append(is_false['answer'][i])\n        is_answer.append(is_false['is_answer'][i])\n        \nclass72['model_pre'] = model_pre\nclass72['answer'] = answer\nclass72['is_answer'] = is_answer\n\nclass72","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:13:32.159917Z","iopub.execute_input":"2022-06-07T04:13:32.160235Z","iopub.status.idle":"2022-06-07T04:13:32.389654Z","shell.execute_reply.started":"2022-06-07T04:13:32.160204Z","shell.execute_reply":"2022-06-07T04:13:32.38878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=[24, 6], dpi=200)\nsns.countplot(x=class72['model_pre'])\nplt.xticks(rotation=60)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:13:32.391056Z","iopub.execute_input":"2022-06-07T04:13:32.391388Z","iopub.status.idle":"2022-06-07T04:13:33.095587Z","shell.execute_reply.started":"2022-06-07T04:13:32.391356Z","shell.execute_reply":"2022-06-07T04:13:33.094701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=[24, 6], dpi=200)\nsns.countplot(x=class90['model_pre'])\nplt.xticks(rotation=60)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:12:33.750831Z","iopub.execute_input":"2022-06-07T04:12:33.751177Z","iopub.status.idle":"2022-06-07T04:12:34.222625Z","shell.execute_reply.started":"2022-06-07T04:12:33.751141Z","shell.execute_reply":"2022-06-07T04:12:34.221273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndir = '../input/sorghum-id-fgvc-9/train_images'\nfilename1 = '2017-06-28__10-19-29-505.png'\nfilename2 = '2017-06-01__11-00-44-942.png'\nfilename3 = '2017-06-01__11-00-13-909.png'\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=[12, 6], dpi=300)\n\naxes[0].imshow(Image.open(os.path.join(dir, filename1)))\naxes[1].imshow(Image.open(os.path.join(dir, filename2)))\naxes[2].imshow(Image.open(os.path.join(dir, filename3)))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T03:55:37.767686Z","iopub.execute_input":"2022-06-07T03:55:37.768387Z","iopub.status.idle":"2022-06-07T03:55:41.204433Z","shell.execute_reply.started":"2022-06-07T03:55:37.768348Z","shell.execute_reply":"2022-06-07T03:55:41.202382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndir = '../input/sorghum-id-fgvc-9/train_images'\nfilename1 = '2017-06-02__18-04-25-964.png'\nfilename2 = '2017-06-09__11-56-23-546.png'\nfilename3 = '2017-06-26__11-57-27-185.png'\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=[12, 6], dpi=300)\n\naxes[0].imshow(Image.open(os.path.join(dir, filename1)))\naxes[1].imshow(Image.open(os.path.join(dir, filename2)))\naxes[2].imshow(Image.open(os.path.join(dir, filename3)))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T03:55:41.668942Z","iopub.execute_input":"2022-06-07T03:55:41.669245Z","iopub.status.idle":"2022-06-07T03:55:44.83735Z","shell.execute_reply.started":"2022-06-07T03:55:41.669213Z","shell.execute_reply":"2022-06-07T03:55:44.835506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndir = '../input/sorghum-id-fgvc-9/train_images'\nfilename1 = '2017-06-28__11-50-22-395.png'\nfilename2 = '2017-06-13__11-55-55-043.png'\nfilename3 = '2017-06-22__13-39-10-652.png'\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=[12, 6], dpi=300)\n\naxes[0].imshow(Image.open(os.path.join(dir, filename1)))\naxes[1].imshow(Image.open(os.path.join(dir, filename2)))\naxes[2].imshow(Image.open(os.path.join(dir, filename3)))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:01:59.019922Z","iopub.execute_input":"2022-06-07T04:01:59.020217Z","iopub.status.idle":"2022-06-07T04:02:02.418784Z","shell.execute_reply.started":"2022-06-07T04:01:59.020186Z","shell.execute_reply":"2022-06-07T04:02:02.417319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndir = '../input/sorghum-id-fgvc-9/train_images'\nfilename1 = '2017-06-18__13-23-50-617.png'\nfilename2 = '2017-06-21__12-09-32-052.png'\nfilename3 = '2017-06-14__13-11-56-857.png'\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=[12, 6], dpi=300)\n\naxes[0].imshow(Image.open(os.path.join(dir, filename1)))\naxes[1].imshow(Image.open(os.path.join(dir, filename2)))\naxes[2].imshow(Image.open(os.path.join(dir, filename3)))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:24:52.072548Z","iopub.execute_input":"2022-06-07T04:24:52.072934Z","iopub.status.idle":"2022-06-07T04:24:55.498852Z","shell.execute_reply.started":"2022-06-07T04:24:52.072898Z","shell.execute_reply":"2022-06-07T04:24:55.497818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img,img_to_array\n\nimage  = load_img(os.path.join(dir, filename1))\ngrayscale = load_img(os.path.join(dir, filename1),color_mode = \"grayscale\")\ngray_array=  img_to_array(grayscale)\nimage_array = img_to_array(image)\n\nplt.imshow(image)\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=1,ncols=4, sharey=True, figsize=(24,5))\n\nax1.hist(image_array[:,:,0].ravel(),256,[0,256],color='red')\nplt.ylim(0,20000)\nax2.hist(image_array[:,:,1].ravel(),256,[0,256], color='green')\nax3.hist(image_array[:,:,1].ravel(),256,[0,256], color='blue')\nax4.hist(gray_array.ravel(),256,[0,256])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:27:51.425419Z","iopub.execute_input":"2022-06-07T04:27:51.426144Z","iopub.status.idle":"2022-06-07T04:28:01.628511Z","shell.execute_reply.started":"2022-06-07T04:27:51.426104Z","shell.execute_reply":"2022-06-07T04:28:01.627591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename2 = '2017-06-28__10-19-29-505.png'\n\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\n\nimage  = load_img(os.path.join(dir, filename2))\ngrayscale = load_img(os.path.join(dir, filename2),color_mode = \"grayscale\")\ngray_array=  img_to_array(grayscale)\nimage_array = img_to_array(image)\n\nplt.imshow(image)\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=1,ncols=4, sharey=True, figsize=(24,5))\n\nax1.hist(image_array[:,:,0].ravel(),256,[0,256],color='red')\nplt.ylim(0,20000)\nax2.hist(image_array[:,:,1].ravel(),256,[0,256], color='green')\nax3.hist(image_array[:,:,1].ravel(),256,[0,256], color='blue')\nax4.hist(gray_array.ravel(),256,[0,256])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T04:28:25.904599Z","iopub.execute_input":"2022-06-07T04:28:25.904947Z","iopub.status.idle":"2022-06-07T04:28:30.408851Z","shell.execute_reply.started":"2022-06-07T04:28:25.904911Z","shell.execute_reply":"2022-06-07T04:28:30.407983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}