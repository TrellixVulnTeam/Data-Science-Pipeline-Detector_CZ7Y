{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip uninstall -y tensorflow_datasets\n! pip install tensorflow_datasets==4.4.0","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:03.406319Z","iopub.execute_input":"2022-04-09T10:45:03.406698Z","iopub.status.idle":"2022-04-09T10:45:15.534995Z","shell.execute_reply.started":"2022-04-09T10:45:03.406626Z","shell.execute_reply":"2022-04-09T10:45:15.534224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nimport dill\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras import backend as K \nimport seaborn as sns\nimport random\nimport gc\nfrom tqdm.notebook import tqdm\nimport tensorflow_addons as tfa\nimport sys\nsys.path.append(\"../input/sorghum100cultivarjpgimages512x512\") \n# from fgvc_dataset import FGVCDataset","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:15.540777Z","iopub.execute_input":"2022-04-09T10:45:15.540991Z","iopub.status.idle":"2022-04-09T10:45:20.366788Z","shell.execute_reply.started":"2022-04-09T10:45:15.540963Z","shell.execute_reply":"2022-04-09T10:45:20.365739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\ntpu = None\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\n    \n#strategy,tpu = tf.distribute.MirroredStrategy(devices=[\"TPU:0\", \"TPU:1\",\"TPU:2\"]),True\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:20.368189Z","iopub.execute_input":"2022-04-09T10:45:20.368456Z","iopub.status.idle":"2022-04-09T10:45:26.530978Z","shell.execute_reply.started":"2022-04-09T10:45:20.368418Z","shell.execute_reply":"2022-04-09T10:45:26.530117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import  LabelEncoder\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\nimport dill\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:26.533074Z","iopub.execute_input":"2022-04-09T10:45:26.533332Z","iopub.status.idle":"2022-04-09T10:45:27.063457Z","shell.execute_reply.started":"2022-04-09T10:45:26.533296Z","shell.execute_reply":"2022-04-09T10:45:27.062603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General Tools\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\n# SciKit Learn\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, make_scorer, precision_score, recall_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold, train_test_split\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize \nfrom sklearn.feature_selection import SelectKBest, f_classif\n\n# TensorFlow & Keras\nimport tensorflow as tf\n# from tensorflow import keras\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n# from keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\n\nfrom tensorflow.keras.applications import EfficientNetB0 , InceptionV3 ,NASNetLarge,NASNetMobile, ResNet50, ResNet50V2, Xception\n\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n\n\n# Misc\nimport random\nimport warnings\nfrom sys import modules\nfrom time import time\nimport os\nfrom platform import python_version\nimport urllib #<! Download internet files\nimport shutil #<! Handle zip files\n\n# Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# IPython\nfrom IPython.display import Image, display\nfrom IPython.core.display import HTML\nfrom IPython import get_ipython\n\n# Confuguration\n%matplotlib inline\nmpl.style.use('ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context = \"notebook\", palette = \"dark\", style = 'whitegrid', color_codes = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.064827Z","iopub.execute_input":"2022-04-09T10:45:27.065051Z","iopub.status.idle":"2022-04-09T10:45:27.226844Z","shell.execute_reply.started":"2022-04-09T10:45:27.065027Z","shell.execute_reply":"2022-04-09T10:45:27.225922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dir(tf.keras.applications))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.228492Z","iopub.execute_input":"2022-04-09T10:45:27.228804Z","iopub.status.idle":"2022-04-09T10:45:27.234692Z","shell.execute_reply.started":"2022-04-09T10:45:27.228747Z","shell.execute_reply":"2022-04-09T10:45:27.23371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.235906Z","iopub.execute_input":"2022-04-09T10:45:27.236124Z","iopub.status.idle":"2022-04-09T10:45:27.290134Z","shell.execute_reply.started":"2022-04-09T10:45:27.236101Z","shell.execute_reply":"2022-04-09T10:45:27.28934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame({\n    'filename':[os.path.basename(name) for name in glob.glob(\"../input/sorghum-id-fgvc-9/test/*.png\")]\n})\ntest_df['cultivar'] = ''\ntest_df.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.291367Z","iopub.execute_input":"2022-04-09T10:45:27.292427Z","iopub.status.idle":"2022-04-09T10:45:27.79761Z","shell.execute_reply.started":"2022-04-09T10:45:27.292381Z","shell.execute_reply":"2022-04-09T10:45:27.796836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.798933Z","iopub.execute_input":"2022-04-09T10:45:27.799139Z","iopub.status.idle":"2022-04-09T10:45:27.813151Z","shell.execute_reply.started":"2022-04-09T10:45:27.799117Z","shell.execute_reply":"2022-04-09T10:45:27.812177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['jpeg_image'] = [path[:-3]+\"jpg\" for path in train_df.image]\ntest_df['jpeg_image'] = [path[:-3]+\"jpg\" for path in test_df.filename]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.814211Z","iopub.execute_input":"2022-04-09T10:45:27.814857Z","iopub.status.idle":"2022-04-09T10:45:27.84246Z","shell.execute_reply.started":"2022-04-09T10:45:27.814826Z","shell.execute_reply":"2022-04-09T10:45:27.841884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_exists(path):\n    return os.path.exists(path)\ntrain_df = train_df[[image_exists(f\"../input/sorghum-id-fgvc-9/train_images/{img}\") for img in train_df.image]]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:27.843392Z","iopub.execute_input":"2022-04-09T10:45:27.843614Z","iopub.status.idle":"2022-04-09T10:45:42.415306Z","shell.execute_reply.started":"2022-04-09T10:45:27.843587Z","shell.execute_reply":"2022-04-09T10:45:42.414627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape,test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:42.416461Z","iopub.execute_input":"2022-04-09T10:45:42.417194Z","iopub.status.idle":"2022-04-09T10:45:42.422246Z","shell.execute_reply.started":"2022-04-09T10:45:42.417158Z","shell.execute_reply":"2022-04-09T10:45:42.421702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nle = le.fit(train_df.cultivar)\ndill.dump(le,open(\"le.dill\",'wb'))\ntrain_df[\"target\"] = le.transform(train_df.cultivar)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:42.424299Z","iopub.execute_input":"2022-04-09T10:45:42.424813Z","iopub.status.idle":"2022-04-09T10:45:42.445785Z","shell.execute_reply.started":"2022-04-09T10:45:42.424747Z","shell.execute_reply":"2022-04-09T10:45:42.444948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (test_df.shape)\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:45:42.447207Z","iopub.execute_input":"2022-04-09T10:45:42.447806Z","iopub.status.idle":"2022-04-09T10:45:42.455236Z","shell.execute_reply.started":"2022-04-09T10:45:42.447751Z","shell.execute_reply":"2022-04-09T10:45:42.454601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Dataset\n","metadata":{}},{"cell_type":"code","source":"# os.remove(\"../input/mytffilessorghum/fgvc_dataset.py\")\nos.remove(\"./fgvc_dataset.py\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:24:01.853185Z","iopub.execute_input":"2022-04-09T11:24:01.853523Z","iopub.status.idle":"2022-04-09T11:24:01.888529Z","shell.execute_reply.started":"2022-04-09T11:24:01.853486Z","shell.execute_reply":"2022-04-09T11:24:01.887224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree(\"./fgvc_dataset_train_val_test\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:23:05.913595Z","iopub.execute_input":"2022-04-09T11:23:05.913944Z","iopub.status.idle":"2022-04-09T11:23:05.947766Z","shell.execute_reply.started":"2022-04-09T11:23:05.913909Z","shell.execute_reply":"2022-04-09T11:23:05.946594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from subprocess import check_output\n\nprint(check_output([\"ls\", \"./fgvc_dataset_train_val_test/fgvc_dataset/0.1.0\"]).decode(\"utf8\"))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:31:54.378984Z","iopub.execute_input":"2022-04-09T11:31:54.379799Z","iopub.status.idle":"2022-04-09T11:31:54.449526Z","shell.execute_reply.started":"2022-04-09T11:31:54.379762Z","shell.execute_reply":"2022-04-09T11:31:54.448546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile fgvc_dataset.py -a\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\nclass FGVCDataset(tfds.core.GeneratorBasedBuilder):\n    VERSION = tfds.core.Version('0.1.0')\n    \n    def _split_generators(self, dl_manager):\n        arr = [\n            tfds.core.SplitGenerator(name=f'train',gen_kwargs={\"split\":\"train\"}),\n            tfds.core.SplitGenerator(name=f'test',gen_kwargs={\"split\":\"test\"}),\n            tfds.core.SplitGenerator(name=f'val',gen_kwargs={\"split\":\"val\"})\n        ]\n        return arr\n    \n    def _info(self):\n        return tfds.core.DatasetInfo(\n            builder=self,\n            description=(\"\"),\n            #disable_shuffling=True,\n            features=tfds.features.FeaturesDict({\n                \"img\": tfds.features.Image(encoding_format='jpeg'),#dtype=tf.uint8,shape=(self.WIDTH,self.HEIGHT,3),\n                \"name\": tfds.features.Tensor(dtype=tf.string,shape=()),\n                \"cultivar\": tfds.features.Tensor(dtype=tf.string,shape=()),\n                \"target\": tfds.features.Tensor(dtype=tf.int32,shape=()),\n            }),\n        )\n    \n    def _generate_examples(self,**args):\n        print(args)\n        split = args[\"split\"]\n        \n        if split == 'train':\n            for i in range(len(self.train_df)):\n                row = self.train_df.iloc[i]\n                img = f\"../input/sorghum100cultivarjpgimages512x512/train_images/{row.jpeg_image}\"\n                yield i, {\n                    'img':img,\n                    'cultivar':row.cultivar,\n                    'name':row.image,\n                    'target':row.target,\n                }\n                \n        if split == 'val':\n            for i in range(len(self.val_df)):\n                row = self.val_df.iloc[i]\n                img = f\"../input/sorghum100cultivarjpgimages512x512/train_images/{row.jpeg_image}\"\n                yield i, {\n                    'img':img,\n                    'cultivar':row.cultivar,\n                    'name':row.image,\n                    'target':row.target,\n                }\n        if split == 'test':\n            for i in range(len(self.test_df)):\n                row = self.test_df.iloc[i]\n                img = f\"../input/sorghum100cultivarjpgimages512x512/test/{row.jpeg_image}\"\n                yield i, {\n                    'img':img,\n                    'name':row.filename,\n                    'cultivar':'',\n                    'target':-1,\n                }","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:24:16.496787Z","iopub.execute_input":"2022-04-09T11:24:16.497397Z","iopub.status.idle":"2022-04-09T11:24:16.505467Z","shell.execute_reply.started":"2022-04-09T11:24:16.497347Z","shell.execute_reply":"2022-04-09T11:24:16.504842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile fgvc_dataset.py -a\n\n# import tensorflow_datasets as tfds\n# import tensorflow as tf\n\n# class FGVCDataset(tfds.core.GeneratorBasedBuilder):\n#     VERSION = tfds.core.Version('0.1.0')\n    \n#     def _split_generators(self, dl_manager):\n#         arr = [\n#             tfds.core.SplitGenerator(name=f'train',gen_kwargs={\"split\":\"train\"}),\n#             tfds.core.SplitGenerator(name=f'test',gen_kwargs={\"split\":\"test\"})\n#         ]\n#         return arr\n    \n#     def _info(self):\n#         return tfds.core.DatasetInfo(\n#             builder=self,\n#             description=(\"\"),\n#             #disable_shuffling=True,\n#             features=tfds.features.FeaturesDict({\n#                 \"img\": tfds.features.Image(encoding_format='jpeg'),#dtype=tf.uint8,shape=(self.WIDTH,self.HEIGHT,3),\n#                 \"name\": tfds.features.Tensor(dtype=tf.string,shape=()),\n#                 \"cultivar\": tfds.features.Tensor(dtype=tf.string,shape=()),\n#                 \"target\": tfds.features.Tensor(dtype=tf.int32,shape=()),\n#             }),\n#         )\n    \n#     def _generate_examples(self,**args):\n#         print(args)\n#         split = args[\"split\"]\n        \n#         if split == 'train':\n#             for i in range(len(self.train_df)):\n#                 row = self.train_df.iloc[i]\n#                 img = f\"../input/sorghum100cultivarjpgimages512x512/train_images/{row.jpeg_image}\"\n#                 yield i, {\n#                     'img':img,\n#                     'cultivar':row.cultivar,\n#                     'name':row.image,\n#                     'target':row.target,\n#                 }\n                \n#         if split == 'test':\n#             for i in range(len(self.test_df)):\n#                 row = self.test_df.iloc[i]\n#                 img = f\"../input/sorghum100cultivarjpgimages512x512/test/{row.jpeg_image}\"\n#                 yield i, {\n#                     'img':img,\n#                     'name':row.filename,\n#                     'cultivar':'',\n#                     'target':-1,\n#                 }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fgvc_dataset import FGVCDataset\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:24:24.007772Z","iopub.execute_input":"2022-04-09T11:24:24.008212Z","iopub.status.idle":"2022-04-09T11:24:24.011192Z","shell.execute_reply.started":"2022-04-09T11:24:24.008182Z","shell.execute_reply":"2022-04-09T11:24:24.010687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df,\n    test_size=0.2, shuffle = True, random_state = 8)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:24:28.416881Z","iopub.execute_input":"2022-04-09T11:24:28.417311Z","iopub.status.idle":"2022-04-09T11:24:28.428585Z","shell.execute_reply.started":"2022-04-09T11:24:28.417276Z","shell.execute_reply":"2022-04-09T11:24:28.427992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndata_dir='./fgvc_dataset_train_val_test' \nFGVCDataset.val_df = val_df#.iloc[:100]\nFGVCDataset.train_df = train_df#.sample(frac =.60)\nFGVCDataset.test_df = test_df#.iloc[:100]\n\nbuilder = FGVCDataset(data_dir=data_dir)\nbuilder.download_and_prepare() ","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:25:00.737681Z","iopub.execute_input":"2022-04-09T11:25:00.738132Z","iopub.status.idle":"2022-04-09T11:29:48.692204Z","shell.execute_reply.started":"2022-04-09T11:25:00.738101Z","shell.execute_reply":"2022-04-09T11:29:48.691401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = builder.as_dataset()['train']\ntest_ds = builder.as_dataset()['test']\nval_ds = builder.as_dataset()['val']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# builder.as_dataset()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_ds = builder.as_dataset()['train']\n# test_ds = builder.as_dataset()['test']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for x in train_ds.take(1):\n#     img = x['img']\n#     cultivar = x['cultivar']\n#     target = x['target']\n#     print(img.shape,cultivar,target)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(img.numpy())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = pd.read_csv(\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\")\n# test_df = pd.read_csv(\"../input/sorghum-id-fgvc-9/sample_submission.csv\")\nGCS_PATH = KaggleDatasets().get_gcs_path('mytffilessorghum') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dropna(axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_SAVED_MODEL = False\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndata_dir= GCS_PATH+\"/fgvc_dataset512\" \nbuilder = FGVCDataset(data_dir=data_dir)\nbuilder.download_and_prepare()\ntrain_ds = builder.as_dataset()['train']\ntest_ds = builder.as_dataset()['test']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image_batch(images: list):\n    \"\"\"\n    Displays a batch of image present in images\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n    for idx in range(6):\n        ax = plt.subplot(2, 3, idx+1)\n        plt.imshow(images[idx])\n        plt.axis(\"off\")\n\ndef show_dataset(dataset):\n    batch = next(iter(dataset))\n    images, labels = batch\n    \n    plt.figure(figsize=(10, 10))\n    for idx in range(9):\n        ax = plt.subplot(3, 3, idx + 1)\n        plt.imshow(images[idx].numpy().astype(\"uint8\"))\n        plt.title(\"Class: {}\".format(labels[idx].numpy().decode()))\n        plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_dataset(train_ds.map(lambda data:(data['img'],data['cultivar'])).batch(9))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = dill.load(open(\"./le.dill\",\"rb\"))\ntrain_df[\"target\"] = le.transform(train_df.cultivar)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 123\nHEIGHT = 512\nWIDTH = 512\nN_CLASSES = len(train_df.cultivar.unique())\nBATCH_SIZE = 32 if tpu else 4\nIMG_DIR = \"../input/mytffilessorghum\" if not tpu else GCS_PATH","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_DIR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New trials","metadata":{}},{"cell_type":"code","source":"def data_augmentation():\n    return keras.Sequential([\n        #keras.layers.experimental.preprocessing.RandomZoom(0.2,seed=SEED),\n        #keras.layers.experimental.preprocessing.RandomCrop(HEIGHT//2, WIDTH//2,seed=SEED),\n        keras.layers.experimental.preprocessing.RandomContrast(0.1,seed=SEED),\n        keras.layers.experimental.preprocessing.RandomFlip(),\n        keras.layers.experimental.preprocessing.RandomRotation(0.2,seed=SEED),\n        #keras.layers.experimental.preprocessing.Resizing(HEIGHT, WIDTH),\n    ])\ndaug = data_augmentation()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_train_image(data):\n    img = data['img']\n    cultivar = data['cultivar']\n    name = data['name']\n    target = data['target']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n    return img,target\n\ndef load_test_image(data):\n    img = data['img']\n    name = data['name']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n    img = tf.keras.applications.efficientnet.preprocess_input(img)\n    return img,name\n\ndef prepare_train_dataset(train_ds):\n    steps = len(train_ds)//BATCH_SIZE\n    train_ds = train_ds.repeat().shuffle(5000).map(load_train_image,num_parallel_calls=AUTO)\n    train_ds = train_ds.batch(BATCH_SIZE).map(lambda x,y:(daug(x),y),num_parallel_calls=AUTO).prefetch(100)\n    return steps,train_ds\n\ndef prepare_submission_dataset(ds):\n    ds = ds.map(load_test_image,num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE*2).prefetch(100)\n    return ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_dataset(train_ds.map(lambda data:(data['img'],data['cultivar'])).batch(9).map(lambda x,y:(daug(x),y)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n\nscaleLayer = Rescaling(scale = 1 / 127.5, offset = -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Models are bottom (Input) up (Output)\n# We could take the top layer and deifne number of classes for 2\n# For practice we do it manually.\nbaseModel = keras.applications.Xception(\n    weights = \"imagenet\",  #<! Load weights pre-trained on ImageNet. One could use a file path!\n    input_shape = (None, None, 3),\n    include_top = False, #<! Last layer (The classifier for 1000 classes)\n)  #<! Do not include the ImageNet classifier at the top.\n\nbaseModel.trainable = False #<! Freeze the base model\nbaseModel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputSize = (512, 512)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# out = backbone(image_input)\n# # out = tf.keras.layers.GlobalAveragePooling2D()(out)\n# # out = tf.keras.layers.Dense(N_CLASSES,activation=\"softmax\")(out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Create the model on top\ninputLayer = keras.Input(shape = (*inputSize, 3))\nx = daug(inputLayer) #<! Apply random data augmentation\nx = scaleLayer(x) #<! Re Scaling of the data\n\n# The base model contains `batchNorm` layers. We want to keep them in inference mode\n# when we unfreeze the base model for fine tuning, so we make sure that the\n# base_model is running in inference mode here.\n\nx = baseModel(x, training = False) #<! Think of the Dropout / Batch Normalization\nx = baseModel(inputLayer)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = Dropout(0.2)(x)  #<! Regularization by dropout\noutputLayer = tf.keras.layers.Dense(N_CLASSES,activation=\"softmax\")(x) #<! No need for activation (Sigmoid) since we use Binary Cross Entropy with `from_logit`\nSorgModel = keras.Model(inputLayer, outputLayer)\n\nSorgModel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with strategy.scope():\n#     image_input = tf.keras.layers.Input(shape=(WIDTH,HEIGHT,3))\n    \n#     backbone = tf.keras.applications.Xception(include_top=False,weights=\"imagenet\",input_shape=(WIDTH,HEIGHT,3))\n#     out = backbone(image_input)\n#     out = tf.keras.layers.GlobalAveragePooling2D()(out)\n#     out = tf.keras.layers.Dense(N_CLASSES,activation=\"softmax\")(out)\n    \n#     model = tf.keras.Model(image_input,out)\n#     model.compile()\n#     model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SorgModel.compile(\n#     optimizer = Adam(), #<! In pratcice we should set a schedule\n#     loss = BinaryCrossentropy(from_logits = True),\n#     metrics = [BinaryAccuracy()],\n# )\n\n# numEpochs = 2\n\n# catDogModel.fit(dsTrain, epochs = numEpochs, validation_data = dsValidation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    if not USE_SAVED_MODEL:\n        steps_per_epoch,ds =  prepare_train_dataset(train_ds)\n        callback = tf.keras.callbacks.EarlyStopping(monitor='acc',mode='max', patience=20)\n        ckp_callback = tf.keras.callbacks.ModelCheckpoint(\n                                                    filepath=f'model.h5',\n                                                    save_weights_only=True,\n                                                    monitor='acc',\n                                                    mode='max',\n                                                    options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'),\n                                                    save_best_only=True)\n        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='acc',mode='max',factor=0.2,patience=3, min_lr=1e-5)\n        callbacks=[callback,ckp_callback,reduce_lr]\n        # Compile the model\n        SorgModel.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                      loss=tf.keras.losses.sparse_categorical_crossentropy,\n                      metrics=['acc',])\n\n        history = SorgModel.fit(ds, \n                            steps_per_epoch=steps_per_epoch,\n                            epochs=30,\n                            verbose=1,\n                            callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"if not USE_SAVED_MODEL:\n    model.load_weights('model.h5')\nelse:\n    model.load_weights('../input/sorghum100efficientnetbaselinemodel/model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(x):\n    return model(x,training=False)\n@tf.function\ndef dist_predict(dist_inputs):\n    res = strategy.run(predict, args=(dist_inputs,))\n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nwith strategy.scope():\n    ds = prepare_submission_dataset(test_ds)\n    dist_ds = strategy.experimental_distribute_dataset(ds)\n    \n    all_names = []\n    all_targets = []\n    for img,names in tqdm(dist_ds):\n        preds = dist_predict(img)\n        if tpu:\n            preds = tf.concat(preds.values,axis=0)\n            names = tf.concat(names.values,axis=0)\n        preds = preds.numpy()\n        names = names.numpy()\n        preds = np.argmax(preds,axis=-1)\n        all_targets.extend(list(preds))\n        all_names.extend([s.decode('ascii') for s in names])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame({\n    \"filename\":all_names,\n    \"cultivar\":le.inverse_transform(all_targets)\n})\nsub_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\",index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# original model","metadata":{}},{"cell_type":"code","source":"def data_augmentation():\n    return keras.Sequential([\n        #keras.layers.experimental.preprocessing.RandomZoom(0.2,seed=SEED),\n        #keras.layers.experimental.preprocessing.RandomCrop(HEIGHT//2, WIDTH//2,seed=SEED),\n        keras.layers.experimental.preprocessing.RandomContrast(0.1,seed=SEED),\n        keras.layers.experimental.preprocessing.RandomFlip(),\n        keras.layers.experimental.preprocessing.RandomRotation(0.2,seed=SEED),\n        #keras.layers.experimental.preprocessing.Resizing(HEIGHT, WIDTH),\n    ])\ndaug = data_augmentation()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_train_image(data):\n    img = data['img']\n    cultivar = data['cultivar']\n    name = data['name']\n    target = data['target']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n    return img,target\n\ndef load_test_image(data):\n    img = data['img']\n    name = data['name']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n    img = tf.keras.applications.efficientnet.preprocess_input(img)\n    return img,name\n\ndef prepare_train_dataset(train_ds):\n    steps = len(train_ds)//BATCH_SIZE\n    train_ds = train_ds.repeat().shuffle(5000).map(load_train_image,num_parallel_calls=AUTO)\n    train_ds = train_ds.batch(BATCH_SIZE).map(lambda x,y:(daug(x),y),num_parallel_calls=AUTO).prefetch(100)\n    return steps,train_ds\n\ndef prepare_submission_dataset(ds):\n    ds = ds.map(load_test_image,num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE*2).prefetch(100)\n    return ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_dataset(train_ds.map(lambda data:(data['img'],data['cultivar'])).batch(9).map(lambda x,y:(daug(x),y)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    image_input = tf.keras.layers.Input(shape=(WIDTH,HEIGHT,3))\n    \n    backbone = tf.keras.applications.EfficientNetB4(include_top=False,weights=\"imagenet\",input_shape=(WIDTH,HEIGHT,3))\n    out = backbone(image_input)\n    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n    out = tf.keras.layers.Dense(N_CLASSES,activation=\"softmax\")(out)\n    \n    model = tf.keras.Model(image_input,out)\n    model.compile()\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    if not USE_SAVED_MODEL:\n        steps_per_epoch,ds =  prepare_train_dataset(train_ds)\n        callback = tf.keras.callbacks.EarlyStopping(monitor='acc',mode='max', patience=20)\n        ckp_callback = tf.keras.callbacks.ModelCheckpoint(\n                                                    filepath=f'model.h5',\n                                                    save_weights_only=True,\n                                                    monitor='acc',\n                                                    mode='max',\n                                                    options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'),\n                                                    save_best_only=True)\n        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='acc',mode='max',factor=0.2,patience=3, min_lr=1e-5)\n        callbacks=[callback,ckp_callback,reduce_lr]\n        # Compile the model\n        model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                      loss=tf.keras.losses.sparse_categorical_crossentropy,\n                      metrics=['acc',])\n\n        history = model.fit(ds,\n                            steps_per_epoch=steps_per_epoch,\n                            epochs=30,\n                            callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not USE_SAVED_MODEL:\n    model.load_weights('model.h5')\nelse:\n    model.load_weights('../input/sorghum100efficientnetbaselinemodel/model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(x):\n    return model(x,training=False)\n@tf.function\ndef dist_predict(dist_inputs):\n    res = strategy.run(predict, args=(dist_inputs,))\n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nwith strategy.scope():\n    ds = prepare_submission_dataset(test_ds)\n    dist_ds = strategy.experimental_distribute_dataset(ds)\n    \n    all_names = []\n    all_targets = []\n    for img,names in tqdm(dist_ds):\n        preds = dist_predict(img)\n        if tpu:\n            preds = tf.concat(preds.values,axis=0)\n            names = tf.concat(names.values,axis=0)\n        preds = preds.numpy()\n        names = names.numpy()\n        preds = np.argmax(preds,axis=-1)\n        all_targets.extend(list(preds))\n        all_names.extend([s.decode('ascii') for s in names])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame({\n    \"filename\":all_names,\n    \"cultivar\":le.inverse_transform(all_targets)\n})\nsub_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\",index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}