{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import party!!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pytorch_lightning as pl\nimport torch\nimport torchvision\nimport glob, os\nimport torchvision.transforms.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset , DataLoader\nfrom pytorch_lightning import LightningDataModule,LightningModule\nplt.rcParams[\"savefig.bbox\"] = 'tight'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-24T20:41:37.302496Z","iopub.execute_input":"2022-03-24T20:41:37.302778Z","iopub.status.idle":"2022-03-24T20:41:37.309737Z","shell.execute_reply.started":"2022-03-24T20:41:37.302748Z","shell.execute_reply":"2022-03-24T20:41:37.308646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers","metadata":{}},{"cell_type":"code","source":"def get_paths(base_folder):\n    paths=glob.glob(base_folder+'/*.png')\n    return paths\n\ndef read_img(path):\n    img=torchvision.io.read_image(path)\n    return img\n\ndef display_(df_path,base_dir):\n    \n    df=pd.read_csv(df_path)\n    df.iloc[:,0]=base_dir+'/'+df.iloc[:,0]\n    \n    #rest are just fancy prints for more info from csv\n    print('*'*100)\n    print(df_path.split('/')[-1])\n    display(df)\n    print(df.info())\n    print(f'unique _ values in cultivar: {df.cultivar.nunique()}')\n    \n    return df\n\n\ndef plot_imgs(paths,r=8,c=8,figsize=(20,20)):\n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    for n,ax in enumerate(axs):\n        img=read_img(paths[n])\n        ax.imshow(F.to_pil_image(img))\n        ax.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T20:41:37.325819Z","iopub.execute_input":"2022-03-24T20:41:37.326101Z","iopub.status.idle":"2022-03-24T20:41:37.336427Z","shell.execute_reply.started":"2022-03-24T20:41:37.326073Z","shell.execute_reply":"2022-03-24T20:41:37.335509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline\n","metadata":{}},{"cell_type":"code","source":"class pipeline_basic(Dataset):\n    \n    def __init__(\n                self,\n                df\n                ):\n        \n        self.df=df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def read_img(self,img):\n        img=torchvision.io.read_image(path)\n        return img/255.0\n    \n    def __getitem__(self,idx):\n        \n        img=read_img(self.df.image[idx])\n        lab=self.df.cultivar[idx]\n        \n        return img,lab\n    \nclass PL_pipeline(LightningDataModule):\n    def __init__(self,\n                Dataset,\n                df,\n                bs):\n        self.Dataset=Dataset(df)\n        self.df=df\n        self.bs=bs\n        \n    def setup(self):\n        self.train_df,self.val_df=train_test_split(self.df)\n    \n    def training_dataloader(self):\n        data=self.Dataset(self.train_df)\n        return DataLoader(data,batch_size=self.bs)\n    \n    def validation_dataloader(self):\n        data=self.Dataset(self.val_df)\n        return DataLoader(data,batch_size=self.bs)\n    \ndef plot_pipeline(dataset,r=8,c=8,figsize=(20,20)):\n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    for n, ax in enumerate(axs):\n        img,lab=dataset[n]\n        ax.imshow(F.to_pil_image(img))\n        ax.set_title(lab)\n        ax.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T20:41:37.337936Z","iopub.execute_input":"2022-03-24T20:41:37.338176Z","iopub.status.idle":"2022-03-24T20:41:37.357033Z","shell.execute_reply.started":"2022-03-24T20:41:37.338146Z","shell.execute_reply":"2022-03-24T20:41:37.356247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Avengers assemble","metadata":{}},{"cell_type":"code","source":"def main():\n    \n    training_folder='../input/sorghum-id-fgvc-9/train_images'\n    test_folder='../input/sorghum-id-fgvc-9/test'\n    train_df_path='../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv'\n    submission_df_path='../input/sorghum-id-fgvc-9/sample_submission.csv'\n    train_df=display_(train_df_path,training_folder)\n#     plot_imgs(train_df.image)                                            # Basic level plotting of images from paths\n    submission=display_(submission_df_path,test_folder)\n    \n    #testing pipeline\n    print('testing pipeline')\n    data=pipeline_basic(train_df)\n    plot_pipeline(data)\n    \n    \n    \nmain()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T20:41:37.358423Z","iopub.execute_input":"2022-03-24T20:41:37.358867Z","iopub.status.idle":"2022-03-24T20:41:50.926264Z","shell.execute_reply.started":"2022-03-24T20:41:37.358805Z","shell.execute_reply":"2022-03-24T20:41:50.92523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO : EDA\n# TODO : Pipeline (add batchwise augmentation method from lighning docs) \n# TODO : Model \n# TODO : trainer \n# TODO : monitor (neptune, W&B) ","metadata":{"execution":{"iopub.status.busy":"2022-03-24T20:41:50.92822Z","iopub.execute_input":"2022-03-24T20:41:50.928536Z","iopub.status.idle":"2022-03-24T20:41:50.932839Z","shell.execute_reply.started":"2022-03-24T20:41:50.928499Z","shell.execute_reply":"2022-03-24T20:41:50.931949Z"},"trusted":true},"execution_count":null,"outputs":[]}]}