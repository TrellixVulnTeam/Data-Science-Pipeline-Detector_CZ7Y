{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport sklearn\nimport cv2 as cv2\nfrom  PIL import Image\nfrom PIL import ImageFile \nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport torch\nfrom sklearn import metrics\nimport torch.nn as nn\npackage_paths = [\n    '../input/timmmaster',\n]\n\nimport sys\n\n\nfor pth in package_paths:\n    sys.path.append(pth)\nimport timm\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom albumentations.core.composition import Compose,OneOf\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.076039Z","iopub.execute_input":"2022-05-14T17:44:20.076627Z","iopub.status.idle":"2022-05-14T17:44:20.086563Z","shell.execute_reply.started":"2022-05-14T17:44:20.076586Z","shell.execute_reply":"2022-05-14T17:44:20.085878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    model_name = 'tf_efficientnet_b3_ns'\n    pretrained = True\n    img_size = 512\n    num_classes = 100\n    lr = 1e-4\n    max_lr = 1e-3\n    pct_start = 0.2\n    div_factor = 1.0e+3\n    final_div_factor = 1.0e+3\n    num_epochs = 40\n    batch_size = 16\n    accum = 1\n    precision = 16\n    n_fold = 4\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.108782Z","iopub.execute_input":"2022-05-14T17:44:20.108973Z","iopub.status.idle":"2022-05-14T17:44:20.114081Z","shell.execute_reply.started":"2022-05-14T17:44:20.10895Z","shell.execute_reply":"2022-05-14T17:44:20.113194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timm.list_models()[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.15158Z","iopub.execute_input":"2022-05-14T17:44:20.151927Z","iopub.status.idle":"2022-05-14T17:44:20.161287Z","shell.execute_reply.started":"2022-05-14T17:44:20.151899Z","shell.execute_reply":"2022-05-14T17:44:20.160499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\")\nimg_path=\"../input/sorghum-id-fgvc-9/train_images\"","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.214065Z","iopub.execute_input":"2022-05-14T17:44:20.214344Z","iopub.status.idle":"2022-05-14T17:44:20.239291Z","shell.execute_reply.started":"2022-05-14T17:44:20.214312Z","shell.execute_reply":"2022-05-14T17:44:20.238662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=df.cultivar.unique()\nlabel_map={i:0 for i in labels}\nfor i,label in zip(range(100),labels):\n    \n    label_map[label]=i\ndf['cultivar']=df['cultivar'].map(label_map)    ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.29022Z","iopub.execute_input":"2022-05-14T17:44:20.2905Z","iopub.status.idle":"2022-05-14T17:44:20.300599Z","shell.execute_reply.started":"2022-05-14T17:44:20.290472Z","shell.execute_reply":"2022-05-14T17:44:20.299611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nkf=StratifiedKFold(n_splits=5)\ndf['fold']=-1\ndf.sample(frac=1).reset_index(drop=True)\nfor fold,(tr,val) in enumerate(kf.split(X=df,y=df.cultivar.values)):\n    df.loc[val,\"fold\"]=int(fold)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.383024Z","iopub.execute_input":"2022-05-14T17:44:20.383319Z","iopub.status.idle":"2022-05-14T17:44:20.403398Z","shell.execute_reply.started":"2022-05-14T17:44:20.383286Z","shell.execute_reply":"2022-05-14T17:44:20.402786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.423966Z","iopub.execute_input":"2022-05-14T17:44:20.424242Z","iopub.status.idle":"2022-05-14T17:44:20.432Z","shell.execute_reply.started":"2022-05-14T17:44:20.424215Z","shell.execute_reply":"2022-05-14T17:44:20.431171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.500477Z","iopub.execute_input":"2022-05-14T17:44:20.500833Z","iopub.status.idle":"2022-05-14T17:44:20.50747Z","shell.execute_reply.started":"2022-05-14T17:44:20.500794Z","shell.execute_reply":"2022-05-14T17:44:20.506724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display images for better understanding","metadata":{}},{"cell_type":"code","source":"image=plt.imread(img_path+f\"/{df.image.values[0]}\")\nplt.figure(figsize=(7,7))\nplt.imshow(image,cmap='gray',vmin=0,vmax=255)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:20.556204Z","iopub.execute_input":"2022-05-14T17:44:20.556496Z","iopub.status.idle":"2022-05-14T17:44:21.199131Z","shell.execute_reply.started":"2022-05-14T17:44:20.556468Z","shell.execute_reply":"2022-05-14T17:44:21.198492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SorghumDataset:\n    def __init__(self,df,aug):\n        self.img_id=df.image.values\n        \n        self.img_id=    [i for i in self.img_id if str(i).split('.')[-1] ==\"png\"]\n                \n        self.target=df.cultivar.values\n        self.aug=aug\n        #self.resize=resize\n    def __len__(self):\n        return len(self.img_id)\n        \n        \n    def __getitem__(self,index):\n        path=\"../input/sorghum-id-fgvc-9/train_images\"\n        \n        image_path= path+\"/\"+self.img_id[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        target=self.target[index]\n            \n            \n      \n        if self.aug is not None:\n            image=self.aug(image=image)['image']\n            #image=self.aug(image)\n#             image=np.transpose(image,(2,0,1)).astype(np.float32)\n        \n        return  {\n            \"image\":image,\n            \"target\":torch.tensor(target,dtype=torch.long)\n        }\n        \n        \n        \n        \n        \n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.200889Z","iopub.execute_input":"2022-05-14T17:44:21.201306Z","iopub.status.idle":"2022-05-14T17:44:21.21103Z","shell.execute_reply.started":"2022-05-14T17:44:21.201272Z","shell.execute_reply":"2022-05-14T17:44:21.210183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train Function","metadata":{}},{"cell_type":"code","source":"def cal_acc(preds,target):\n    _,final_output=torch.max(preds,1)\n    corr=torch.sum(final_output==target)\n    return (corr*100)/len(preds)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.212356Z","iopub.execute_input":"2022-05-14T17:44:21.21283Z","iopub.status.idle":"2022-05-14T17:44:21.22502Z","shell.execute_reply.started":"2022-05-14T17:44:21.212793Z","shell.execute_reply":"2022-05-14T17:44:21.224159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef train(data_loader,model,optimizer,device,epoch):\n    model.train()\n    loop=tqdm(data_loader,leave=False)\n    train_acc=[]\n    total_acc=[]\n    for data in loop:\n        image=data[\"image\"].to(device,dtype=torch.float)\n        target=data[\"target\"].to(device,dtype=torch.long)\n        optimizer.zero_grad()\n        output=model(image)\n        loss=nn.CrossEntropyLoss()(output,target)\n        acc=cal_acc(output,target)\n        train_acc.append(acc)\n        loop.set_description(f\"Epoch->>>{epoch}\")\n        loop.set_postfix(loss=loss.item(),acc=acc)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n    return sum(train_acc)/len(train_acc)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.227074Z","iopub.execute_input":"2022-05-14T17:44:21.227431Z","iopub.status.idle":"2022-05-14T17:44:21.236323Z","shell.execute_reply.started":"2022-05-14T17:44:21.227395Z","shell.execute_reply":"2022-05-14T17:44:21.235577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluation Function","metadata":{}},{"cell_type":"code","source":"def eval(data_loader,model,device):\n    \n    model.eval()\n    final_target=[]\n    final_output=[]\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader):\n        \n            image=data[\"image\"].to(device,dtype=torch.float)\n            target=data[\"target\"].to(device,dtype=torch.long)\n        \n            output=model(image)\n            \n            target= target.detach().cpu().numpy().tolist()\n            output= output.detach().cpu().numpy().tolist()\n            final_target.extend(target)\n            final_output.extend(output)\n    return torch.tensor(final_target),torch.tensor(final_output)       \n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.237668Z","iopub.execute_input":"2022-05-14T17:44:21.23795Z","iopub.status.idle":"2022-05-14T17:44:21.246402Z","shell.execute_reply.started":"2022-05-14T17:44:21.237915Z","shell.execute_reply":"2022-05-14T17:44:21.245659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\n\ndef get_model():\n    model=timm.create_model('tf_efficientnet_b3_ns', pretrained=True)\n    #model=timm.create_model('resnet18', pretrained=True)\n    in_features=model.get_classifier().in_features\n    #in_features=model.fc.in_features\n#     for param in model.parameters():\n#         param.requires_grad=False\n    model.classifier = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, 100)\n        )\n#     model.fc =  nn.Linear(in_features, 100)\n            \n           \n        \n    return model\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.247776Z","iopub.execute_input":"2022-05-14T17:44:21.24805Z","iopub.status.idle":"2022-05-14T17:44:21.257337Z","shell.execute_reply.started":"2022-05-14T17:44:21.248014Z","shell.execute_reply":"2022-05-14T17:44:21.256748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_valid,y_train,y_valid=sklearn.model_selection.train_test_split(df,df.cultivar.values,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.258966Z","iopub.execute_input":"2022-05-14T17:44:21.259139Z","iopub.status.idle":"2022-05-14T17:44:21.27055Z","shell.execute_reply.started":"2022-05-14T17:44:21.259118Z","shell.execute_reply":"2022-05-14T17:44:21.269878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\ndef get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.Flip(p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.5),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=0.5),\n                A.RandomGamma(p=0.5),\n            ], p=0.5),\n            A.OneOf([\n                A.Blur(p=0.1),\n                A.GaussianBlur(p=0.1),\n                A.MotionBlur(p=0.1),\n            ], p=0.1),\n            A.OneOf([\n                A.GaussNoise(p=0.1),\n                A.ISONoise(p=0.1),\n                A.GridDropout(ratio=0.5, p=0.2),\n                A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n            ], p=0.2),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.27188Z","iopub.execute_input":"2022-05-14T17:44:21.272241Z","iopub.status.idle":"2022-05-14T17:44:21.283066Z","shell.execute_reply.started":"2022-05-14T17:44:21.272203Z","shell.execute_reply":"2022-05-14T17:44:21.282176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import albumentations as A\n# from albumentations.pytorch import ToTensorV2\n# from torchvision import transforms\n# mean=(0.485,0.456,0.406)\n# std=(0.229,0.224,0.225)\n# #aug=albumentations.Compose([albumentations.Normalize(mean,std,max_pixel_value=255.0,always_apply=True)])\n# aug= albumentations.Compose([\n#     albumentations.RandomResizedCrop(512,512),\n#      albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n#     ToTensorV2(),\n   \n# ])\n\ntrain_dataset= SorghumDataset(X_train,aug=get_transform('train'))\nvalid_dataset= SorghumDataset(X_valid,aug=get_transform('valid'))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.284552Z","iopub.execute_input":"2022-05-14T17:44:21.284847Z","iopub.status.idle":"2022-05-14T17:44:21.306287Z","shell.execute_reply.started":"2022-05-14T17:44:21.284793Z","shell.execute_reply":"2022-05-14T17:44:21.305703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_loader=torch.utils.data.DataLoader(train_dataset,batch_size=16)\nvalid_loader=torch.utils.data.DataLoader(valid_dataset,batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.309635Z","iopub.execute_input":"2022-05-14T17:44:21.309872Z","iopub.status.idle":"2022-05-14T17:44:21.315817Z","shell.execute_reply.started":"2022-05-14T17:44:21.309826Z","shell.execute_reply":"2022-05-14T17:44:21.315066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=get_model()\ndevice=\"cuda\"\nmodel.to(device)\nepochs=10\noptimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\nscheduler=torch.optim.lr_scheduler.OneCycleLR(optimizer, epochs=epochs, steps_per_epoch=len(train_loader),max_lr=1e-3, pct_start=0.2, \n                                                             div_factor=1.0e+3, final_div_factor=1.0+3)\nbest_accuracy=0\nval_acc_list=[]\ntrain_acc_list=[]\nfor epoch in range(epochs):\n    train_acc=train(train_loader,model,optimizer,device,epoch)\n    final_target,final_output=eval(valid_loader,model,device)\n    _,final_output=torch.max(torch.nn.functional.softmax(final_output,1),1)\n    cor=torch.sum(final_target==final_output)\n    acc=(cor*100)/len(final_target)\n    val_acc_list.append(acc.item())\n    train_acc_list.append(train_acc.item())\n    if acc>best_accuracy:\n        torch.save(model.state_dict(),f\"Epoch-> {epoch}md.pt\")\n        \n    print((cor*100)/len(final_target))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:44:21.317056Z","iopub.execute_input":"2022-05-14T17:44:21.317325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_acc_list)\nprint(val_acc_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}