{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T17:04:56.060038Z","iopub.execute_input":"2022-02-21T17:04:56.060314Z","iopub.status.idle":"2022-02-21T17:04:56.073218Z","shell.execute_reply.started":"2022-02-21T17:04:56.060283Z","shell.execute_reply":"2022-02-21T17:04:56.072431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:56.0769Z","iopub.execute_input":"2022-02-21T17:04:56.077092Z","iopub.status.idle":"2022-02-21T17:04:56.08134Z","shell.execute_reply.started":"2022-02-21T17:04:56.077068Z","shell.execute_reply":"2022-02-21T17:04:56.080548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets\nfrom torch.optim.lr_scheduler import  ReduceLROnPlateau\nimport torchvision.transforms as transforms\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport copy\n#from torchsummary import summary # model summary","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:56.082698Z","iopub.execute_input":"2022-02-21T17:04:56.083184Z","iopub.status.idle":"2022-02-21T17:04:56.089886Z","shell.execute_reply.started":"2022-02-21T17:04:56.083147Z","shell.execute_reply":"2022-02-21T17:04:56.088838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and Visualize Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:56.091198Z","iopub.execute_input":"2022-02-21T17:04:56.091602Z","iopub.status.idle":"2022-02-21T17:04:59.502065Z","shell.execute_reply.started":"2022-02-21T17:04:56.091566Z","shell.execute_reply":"2022-02-21T17:04:59.50124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:59.50434Z","iopub.execute_input":"2022-02-21T17:04:59.504533Z","iopub.status.idle":"2022-02-21T17:04:59.519816Z","shell.execute_reply.started":"2022-02-21T17:04:59.504508Z","shell.execute_reply":"2022-02-21T17:04:59.519169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:59.521036Z","iopub.execute_input":"2022-02-21T17:04:59.521638Z","iopub.status.idle":"2022-02-21T17:04:59.529443Z","shell.execute_reply.started":"2022-02-21T17:04:59.5216Z","shell.execute_reply":"2022-02-21T17:04:59.5288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split traing and val\nX = train.drop(['label'], axis=1)\ny = train['label']","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:59.53058Z","iopub.execute_input":"2022-02-21T17:04:59.530957Z","iopub.status.idle":"2022-02-21T17:04:59.772027Z","shell.execute_reply.started":"2022-02-21T17:04:59.530923Z","shell.execute_reply":"2022-02-21T17:04:59.771168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7,5))\nsns.countplot(x = y, ax = ax)\nax.set_title('Train count labels')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:59.773554Z","iopub.execute_input":"2022-02-21T17:04:59.773824Z","iopub.status.idle":"2022-02-21T17:04:59.991384Z","shell.execute_reply.started":"2022-02-21T17:04:59.773787Z","shell.execute_reply":"2022-02-21T17:04:59.990711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph shows of train data is balanced. Now we look for digit images.","metadata":{}},{"cell_type":"code","source":"digits = y.unique()\nidx_digits = [y[y == digit].index[0] for digit in digits]\n\ndef plotImages(idx_images):\n    fig,ax = plt.subplots(2,5, figsize=(15,10))\n    \n    line = 0\n    col = 0\n    for i,id_image in enumerate(idx_images):\n        img = X.loc[id_image].values\n        img = img.reshape((28,28))\n        if i == 5:\n            line += 1\n            col = 0 \n        ax[line,col].imshow(img,cmap='gray')\n        ax[line,col].set_title(digits[i])\n        col+=1\n        \nplotImages(idx_digits)   ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:04:59.992709Z","iopub.execute_input":"2022-02-21T17:04:59.992965Z","iopub.status.idle":"2022-02-21T17:05:01.000906Z","shell.execute_reply.started":"2022-02-21T17:04:59.992932Z","shell.execute_reply":"2022-02-21T17:05:01.000215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Config","metadata":{}},{"cell_type":"code","source":"class Config():\n    \n    #NN Arquiteture Parameters\n    convKernelSize = 3\n    poolKernelSize = 2\n    numKernels_1 = 64#64\n    numKernels_2 = 32\n    hiddenLayer = 256\n    features = 10\n    \n    #Hyperparametrs\n    batchSize = 1024\n    epochs = 40\n    criterion = nn.CrossEntropyLoss()\n    learning_rate = 1e-3\n    plateau_factor = 0.5\n    plateau_patience = 3\n    \n    random_state = 42\n    testSize = 0.25\n    \n    probability = 0.6\n   ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.002321Z","iopub.execute_input":"2022-02-21T17:05:01.002795Z","iopub.status.idle":"2022-02-21T17:05:01.009438Z","shell.execute_reply.started":"2022-02-21T17:05:01.002754Z","shell.execute_reply":"2022-02-21T17:05:01.008776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Dataset\nReference by = https://www.kaggle.com/hinepo/pytorch-tutorial-cv-99-67-lb-99-26#Dataset-class","metadata":{}},{"cell_type":"code","source":"### for training and validation\nclass DigitDataset(Dataset):\n    def __init__(self, df, X_col, y_col, augmentations = None):\n        self.features = df[X_col].values/255 # scale (greyscale) only features. do not scale target\n        self.targets = df[y_col].values.reshape((-1, 1))\n        self.augmentations = augmentations \n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((1,28, 28))\n        label = self.targets[idx]\n\n        if self.augmentations is not None:\n            #augmented = self.augmentations(image=image)   \n            return torch.FloatTensor(self.augmentations(image=image)['image']), torch.FloatTensor(label)\n        else:\n            return torch.FloatTensor(image), torch.FloatTensor(label)\n\n\n### for inference\nclass DigitInferenceDataset(Dataset):\n    def __init__(self, df, augmentations = None): # for inference we only have the features dataframe\n        self.features = df.values/255 # scale (greyscale) features\n        self.augmentations = augmentations \n\n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((1, 28, 28))\n        return torch.FloatTensor(image)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.010573Z","iopub.execute_input":"2022-02-21T17:05:01.013118Z","iopub.status.idle":"2022-02-21T17:05:01.023933Z","shell.execute_reply.started":"2022-02-21T17:05:01.013077Z","shell.execute_reply":"2022-02-21T17:05:01.02324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augumentation\nWith Alblumentation library\n\nTutorial for image classification: https://albumentations.ai/docs/examples/pytorch_classification/ \n\nDocumentation: https://albumentations.ai/docs/\n\nReference by = https://www.kaggle.com/hinepo/pytorch-tutorial-cv-99-67-lb-99-26#Dataset-class","metadata":{}},{"cell_type":"code","source":"transform_train = A.Compose([\n\n#                   A.Rotate(limit=60, p=1), \n                  A.ShiftScaleRotate(rotate_limit=45, p=Config.probability),\n                  A.Downscale(scale_min=0.7, scale_max=0.7, p=Config.probability),\n                  A.MotionBlur(p=0.2),\n                  A.Affine(scale=0.5,p=Config.probability), \n                  A.Affine(rotate=(-10,10),p=Config.probability), \n\n])\n\n\ntransform_val = A.Compose([\n\n\n])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.024977Z","iopub.execute_input":"2022-02-21T17:05:01.025228Z","iopub.status.idle":"2022-02-21T17:05:01.03576Z","shell.execute_reply.started":"2022-02-21T17:05:01.0252Z","shell.execute_reply":"2022-02-21T17:05:01.034971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN -  Model","metadata":{}},{"cell_type":"code","source":"class NetCnn(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=Config.numKernels_1, kernel_size=Config.convKernelSize,padding=0)\n        self.conv2 = nn.Conv2d(in_channels=Config.numKernels_1, out_channels=Config.numKernels_2, kernel_size=Config.convKernelSize,padding=0)\n        #batch normalization\n        self.bnorm1 = nn.BatchNorm2d(num_features=Config.numKernels_1)\n        self.bnorm2 = nn.BatchNorm2d(num_features=Config.numKernels_2)\n        self.bnorm3 = nn.BatchNorm1d(num_features=Config.hiddenLayer)\n\n        #Pooling and Flattening\n        self.pool = nn.MaxPool2d(kernel_size=Config.poolKernelSize)\n        self.flatten = nn.Flatten()\n\n        '''\n        output= (input-filter+1)/stride\n        conv1 : (28 - 5 +1)/1 = 24x24\n        pooling1: 24x24 / 2 = 12x12\n        conv2: (12-5+1)/1 = 8x8\n        pooling2: 8x8 / 2 = 4x4 = final_img_shape\n        dense layer input = final_img_shape* n_features_maps = 4x4xnumKernels_2 \n        '''\n        #layers of dense network 800->128->128->10\n        self.fc1 = nn.Linear(in_features=Config.numKernels_2*5*5, out_features=Config.hiddenLayer)\n        self.fc2 = nn.Linear(Config.hiddenLayer,Config.hiddenLayer)\n        self.out = nn.Linear(Config.hiddenLayer,Config.features)\n\n        #dropout\n        self.dropout = nn.Dropout(p=0.25)\n\n        #activation function \n        self.activation = nn.ReLU()\n    def forward(self,x):\n        #print('Entrou')\n        #Convolutional 1\n        out  = self.conv1(x)\n        #print('conv1')\n        out = self.activation(out)\n        #print('Activation')\n        #Max poll 1\n        out = self.bnorm1(out)\n        out = self.pool(out)\n        #print('Camada um completa')\n        #print(out.shape)\n        \n        #Convolutional 2\n        out  = self.conv2(out)\n        #print('conv2')\n        out = self.activation(out)\n        #print('Activation')\n        #Max poll 2\n        out = self.bnorm2(out)\n        out = self.pool(out)\n        #print('Camada um completa')\n        #print(out.shape)\n        #flatten\n        out = self.flatten(out)\n        #print(out.shape)\n        #print('flatten completa')\n        \n        #print(out.shape)\n        #Dense Layer 1\n        out = self.fc1(out)\n        out = self.bnorm3(out)\n        #Dropout 1\n        #out = self.dropout(out)\n        \n#         #Dense Layer 2\n#         out = self.fc2(out)\n#         out = self.bnorm3(out)\n       \n        #Dropout 2\n        #out = self.dropout(out)\n        \n        \n        out = self.out(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.037146Z","iopub.execute_input":"2022-02-21T17:05:01.037588Z","iopub.status.idle":"2022-02-21T17:05:01.051637Z","shell.execute_reply.started":"2022-02-21T17:05:01.037553Z","shell.execute_reply":"2022-02-21T17:05:01.050896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"print(f'Complet Data {train.shape}')\n\ntrain_df, val_df = train_test_split(train, test_size = Config.testSize, random_state=Config.random_state)\n    \nprint('\\nSplit Data')\nprint('\\nTrain',train_df.shape)  \nprint('Val',val_df.shape) ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.055721Z","iopub.execute_input":"2022-02-21T17:05:01.05594Z","iopub.status.idle":"2022-02-21T17:05:01.312141Z","shell.execute_reply.started":"2022-02-21T17:05:01.055907Z","shell.execute_reply":"2022-02-21T17:05:01.311347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.313388Z","iopub.execute_input":"2022-02-21T17:05:01.313855Z","iopub.status.idle":"2022-02-21T17:05:01.332627Z","shell.execute_reply.started":"2022-02-21T17:05:01.313814Z","shell.execute_reply":"2022-02-21T17:05:01.331875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing augumentation","metadata":{}},{"cell_type":"code","source":"y_col = \"label\"\nX_col = [c for c in train_df.columns if c != 'label']\ntrain_dataset_not_aug = DigitDataset(train_df, X_col, y_col, augmentations = None)\n#train_loader_not_aug = torch.utils.data.DataLoader(train_dataset_not_aug, batch_size = Config.batchSize, shuffle = True)\n\n# Pytorch train and test sets\ntrain_dataset = DigitDataset(train_df, X_col, y_col, augmentations = transform_train)\n#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = Config.batchSize, shuffle = True)\n\nprint('Original Lenght ', len(train_dataset_not_aug))\nprint('Augumentation Lenght ', len(train_dataset), '\\n')\n\nstart = 10000\nend= start + 10\nfi,ax = plt.subplots(end-start,2, figsize = (10,(end-start)*3))\n\nfor i in range(start,end):\n    for j in range(0,1):\n        image, label = train_dataset_not_aug.__getitem__(start + 1)\n        image_aug, label_aug = train_dataset.__getitem__(start + 1)\n       \n        \n        #original image\n        ax[i-start, j].imshow(np.squeeze(image), cmap='gray')\n        ax[i-start, j].set_title(f'Label: {label.item()}', fontsize=14)\n        ax[i-start, j].axis('off')\n        #augumentation image\n        ax[i-start, j + 1].imshow(np.squeeze(image_aug), cmap='gray')\n        ax[i-start,  j + 1].set_title(f'Label: {label_aug.item()}',fontsize=14)\n        ax[i-start,  j + 1].axis('off')\nplt.suptitle('Analisys Augumentations', fontsize=20)\nplt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:01.334618Z","iopub.execute_input":"2022-02-21T17:05:01.335413Z","iopub.status.idle":"2022-02-21T17:05:03.355354Z","shell.execute_reply.started":"2022-02-21T17:05:01.335376Z","shell.execute_reply":"2022-02-21T17:05:03.354716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(Config.random_state)\n\n# batch_size, epoch and iteration\nbatch_size = Config.batchSize\n#n_iters = 2500\n# num_epochs = n_iters / (len(X_train) / batch_size)\nnum_epochs = Config.epochs\n\n# Pytorch train and test sets\ntrain_dataset = DigitDataset(train_df, X_col, y_col, augmentations = transform_train)\nval_dataset = DigitDataset(val_df,  X_col, y_col,  augmentations = transform_val)\n# train_dataset = DigitDataset(train_df, X_col, y_col, augmentations = None)\n# val_dataset = DigitDataset(val_df,  X_col, y_col,  augmentations = None)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size = Config.batchSize, shuffle = True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size = Config.batchSize, shuffle = True)\n    \n# Create CNN\n#model = DigitModel()\nmodel = NetCnn()\ndevice = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n#device =torch.device('cpu')\n# Cross Entropy Loss \ncriterion =  Config.criterion\n\n# SGD Optimizer\nlearning_rate = Config.learning_rate\n\noptimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor = Config.plateau_factor, patience = Config.plateau_patience, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:03.35818Z","iopub.execute_input":"2022-02-21T17:05:03.358379Z","iopub.status.idle":"2022-02-21T17:05:03.758892Z","shell.execute_reply.started":"2022-02-21T17:05:03.358354Z","shell.execute_reply":"2022-02-21T17:05:03.758123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Validation Functions","metadata":{}},{"cell_type":"code","source":"def train_model(train_loader,device):\n    model.to(device)\n    model.train()\n    \n    train_loss = 0.0\n    for data, labels in train_loader:\n\n        #data = Variable(data)\n        #labels = Variable(labels) \n        # Clear the gradients\n        data, labels = data.to(device), labels.to(device).long().squeeze()\n        optimizer.zero_grad()\n        # Forward Pass\n        target = model(data)\n        # Find the Loss\n        loss = criterion(target,labels)\n        # Calculate gradients\n        loss.backward()\n        # Update Weights\n        optimizer.step()\n        # Calculate Loss\n        train_loss += loss.item()\n            \n    loss_ep = loss/len(train_loader)\n    #loss_ep= loss.data()\n            \n    return loss_ep\n\ndef val_model(val_loader,device):\n    valid_loss = 0.0\n    model.eval()     # Optional when not using Model Specific layer\n    total = 0\n    correct = 0\n    with torch.no_grad():\n        for data, labels in val_loader:\n    #         data = Variable(data)\n    #         labels = Variable(labels) \n            # Forward Pass\n\n            data, labels = data.to(device), labels.to(device).long().squeeze()\n            target = model(data)\n            # Find the Loss\n            loss = criterion(target,labels)\n            # Calculate Loss\n            valid_loss += loss.item()\n            predicted = torch.max(target, axis=1)[1]\n\n            # Total number of labels\n            total += len(labels)\n\n            correct += (predicted == labels).type(torch.float).sum().item()\n            \n    acc_ep = correct/total\n    loss_ep = loss/len(val_loader)\n    #loss_ep= loss.data()\n    \n    return acc_ep,loss_ep \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:03.760357Z","iopub.execute_input":"2022-02-21T17:05:03.760598Z","iopub.status.idle":"2022-02-21T17:05:03.771392Z","shell.execute_reply.started":"2022-02-21T17:05:03.760565Z","shell.execute_reply":"2022-02-21T17:05:03.770585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Train","metadata":{}},{"cell_type":"code","source":"loss_train_list = []\nloss_val_list = []\nacc_list = []\nmin_acc = 0\nmin_loss = np.inf\nfor epoch in range(0, num_epochs):\n    loss_train = train_model(train_loader,device).cpu().detach().numpy()\n    \n    \n    accuracy, loss_val = val_model(val_loader,device)\n    loss_val = loss_val.cpu().detach().numpy()\n\n    loss_train_list.append(loss_train)\n    loss_val_list.append(loss_val)\n    acc_list.append(accuracy)   \n    \n    \n    #step schedule LR\n    scheduler.step(loss_val)\n\n    \n    if accuracy > min_acc:\n        best_model = copy.deepcopy(model)\n        min_acc = accuracy\n    \n    \n    log_epoch = 'Epoch {} \\t Training Loss: {:.5f} \\t Validation Loss: {:.5f} \\t Accuracy: {:.5f}'.format(epoch+1,loss_train,loss_val,accuracy)\n    print(log_epoch)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:05:03.772971Z","iopub.execute_input":"2022-02-21T17:05:03.773574Z","iopub.status.idle":"2022-02-21T17:20:05.318956Z","shell.execute_reply.started":"2022-02-21T17:05:03.773538Z","shell.execute_reply":"2022-02-21T17:20:05.318193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Results","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2,1,figsize=(20,15))\nepoch_max_acc = np.argmax(acc_list) \nepoch_min_loss_val = np.argmin(loss_val_list) \nax[0].plot(loss_train_list, label='Loss Train', linewidth = 2.5)\nax[0].plot(loss_val_list, label='Loss Val',linewidth = 2.5)\nax[0].axvline(x = epoch_min_loss_val, color = 'r', linestyle = 'dashed', label = 'Best val Loss')\nax[0].legend(fontsize=14)\nax[0].set_title('Loss', fontsize=16)\n#ax[0].set(xlim=(15,30))\n\nax[1].set_title('Accuracy',fontsize=16,)\nax[1].plot(acc_list[1:], '--b',linewidth = 2.5)\nax[1].axvline(x = epoch_max_acc, color = 'r', linestyle = 'dashed', label = 'Best val Acc')\nax[1].legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:20:05.320387Z","iopub.execute_input":"2022-02-21T17:20:05.320645Z","iopub.status.idle":"2022-02-21T17:20:05.713786Z","shell.execute_reply.started":"2022-02-21T17:20:05.32061Z","shell.execute_reply":"2022-02-21T17:20:05.713098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Subimission","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:43.930623Z","iopub.execute_input":"2022-02-21T17:26:43.930925Z","iopub.status.idle":"2022-02-21T17:26:43.949032Z","shell.execute_reply.started":"2022-02-21T17:26:43.930887Z","shell.execute_reply":"2022-02-21T17:26:43.948245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    return np.exp(x)/np.sum(np.exp(x), axis=1)[:, None]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:47.227525Z","iopub.execute_input":"2022-02-21T17:26:47.227988Z","iopub.status.idle":"2022-02-21T17:26:47.232854Z","shell.execute_reply.started":"2022-02-21T17:26:47.227945Z","shell.execute_reply":"2022-02-21T17:26:47.232033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate Inference Dataset class (create inference Dataset)\ninference_dataset = DigitInferenceDataset(test, augmentations=None)\n\n# create Inference DataLoader object from Dataset class object\ninference_dataloader = DataLoader(inference_dataset,\n                                  batch_size = Config.batchSize,\n                                  shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:47.293226Z","iopub.execute_input":"2022-02-21T17:26:47.29494Z","iopub.status.idle":"2022-02-21T17:26:47.370934Z","shell.execute_reply.started":"2022-02-21T17:26:47.294903Z","shell.execute_reply":"2022-02-21T17:26:47.370135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_predictions = list()\nmodel.eval()\nwith torch.no_grad():\n        for data in inference_dataloader:\n    #         data = Variable(data)\n    #         labels = Variable(labels) \n            # Forward Pass\n\n            data = data.to(device)\n            predictions = model(data)\n            # Find the Loss\n            y_pred = softmax(predictions.detach().cpu().numpy())\n       \n            predicted = np.argmax(y_pred, axis=1)\n\n            list_predictions.append(predicted)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:52.262267Z","iopub.execute_input":"2022-02-21T17:26:52.26282Z","iopub.status.idle":"2022-02-21T17:26:52.828788Z","shell.execute_reply.started":"2022-02-21T17:26:52.262776Z","shell.execute_reply":"2022-02-21T17:26:52.827845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_predictions_final = np.concatenate(list_predictions, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:56.225955Z","iopub.execute_input":"2022-02-21T17:26:56.226538Z","iopub.status.idle":"2022-02-21T17:26:56.230288Z","shell.execute_reply.started":"2022-02-21T17:26:56.226498Z","shell.execute_reply":"2022-02-21T17:26:56.229588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\nsubmission['Label'] = list_predictions_final\nsubmission.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:58.517227Z","iopub.execute_input":"2022-02-21T17:26:58.517964Z","iopub.status.idle":"2022-02-21T17:26:58.545125Z","shell.execute_reply.started":"2022-02-21T17:26:58.517926Z","shell.execute_reply":"2022-02-21T17:26:58.54434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('./submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:02.039315Z","iopub.execute_input":"2022-02-21T17:27:02.039874Z","iopub.status.idle":"2022-02-21T17:27:02.095945Z","shell.execute_reply.started":"2022-02-21T17:27:02.03982Z","shell.execute_reply":"2022-02-21T17:27:02.095253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('./submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:02.994604Z","iopub.execute_input":"2022-02-21T17:27:02.994877Z","iopub.status.idle":"2022-02-21T17:27:03.01303Z","shell.execute_reply.started":"2022-02-21T17:27:02.994833Z","shell.execute_reply":"2022-02-21T17:27:03.012207Z"},"trusted":true},"execution_count":null,"outputs":[]}]}