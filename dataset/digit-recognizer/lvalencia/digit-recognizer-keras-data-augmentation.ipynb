{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import \nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPooling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, Callback\nfrom keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics\n\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.config.list_physical_devices('GPU'),'//',tf.test.is_built_with_cuda())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking missing values in train and test set\nprint('Nº of missing values in train set: ', train.isnull().any().sum())\nprint()\nprint('Nº of missing values in test set: ', test.isnull().any().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(train.drop('label',axis=1))/ 255.\nX = X.reshape((-1,28,28,1))\n\ny = np.array(train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train and test data\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n\nprint('X_train: ' + str(train_X.shape))\nprint('Y_train: ' + str(train_y.shape))\nprint('X_test:  '  + str(test_X.shape))\nprint('Y_test:  '  + str(test_y.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick a sample to plot\nsample = 5\nimage = train_X[sample].reshape(28,28)\n\n# plot the sample\nfig = plt.figure\nplt.imshow(image, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num = 10 # Remember num = num_row * num_col or some images will be blank\nnum_row = 2\nnum_col = 5\n\n# plot images\nfig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\nfor i in range(num):\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(train_X[i].reshape(28,28), cmap='gray')\n    ax.set_title('Label: {}'.format(train_y[i]))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation with DataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining model parameters \nbatch_size = 128\nepochs = 110\nepochs_to_wait_to_improve = 10\nnum_classes = max(pd.unique(train['label'])) +1 # 10 classes\n\n# fix random seed for reproducibility\nseed = 7\nrandom.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a data generator\ndatagen = ImageDataGenerator(\n                             rotation_range=12,\n                             width_shift_range=0.11,\n                             height_shift_range=0.11,\n                             shear_range=0.15,\n                             zoom_range = 0.09, \n                             validation_split=0.3,\n                             horizontal_flip=False, \n                             vertical_flip=False\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the training generator\ntrain_generator = datagen.flow(train_X, \n                               train_y, \n                               batch_size=batch_size,\n                               shuffle=True,\n                               subset='training')\n\n# Define the testing generator\nval_generator = datagen.flow(test_X, \n                             test_y, \n                             batch_size=batch_size,\n                             subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare and train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the CNN model \n\nmodel = Sequential() # Initialize the sequential model\n\n# Add CNN convolutions with BatchNormalization and MaxPooling2D\n# Avoid overfitting with Dropout\nmodel.add(Conv2D(32, kernel_size = (3,3), input_shape=(28, 28, 1), padding = 'Same', activation='relu'))\nmodel.add(Conv2D(64, kernel_size = (3,3), padding = 'Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding='valid'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size = (3,3), padding = 'Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding='valid'))\nmodel.add(Dropout(0.2))\n\n# Convert our matrix to 1-D set of features \nmodel.add(Flatten())\n\n# Add fully-conected layers\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.20))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35))\nmodel.add(Dense(num_classes, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the call backs EarlyStopping and myCallback which will stop the training\n# if the accuracy reaches 99%\n\nclass myCallback(Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.999):\n            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n            self.model.stop_training = True\n\n# Instantiate callback\nmycallback = myCallback()\n\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', \n                                        patience=epochs_to_wait_to_improve,\n                                        verbose = 2,\n                                        restore_best_weights=True)\n\n# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9)\n#optimizer = 'RMSprop'\n\n# Compile the model\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n          epochs=epochs,\n          validation_data=val_generator, \n          callbacks=[mycallback,early_stopping_callback])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize training results\n\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Visualize training results with matplotlib\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate model\n\nCompute accuracy and loss values in test set. Print confusion matrix of the test set with ground truth values and predicted values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model with test_X from train_test_split\ntest_loss, test_acc = model.evaluate(test_X, test_y, verbose=5)\n\nprint('\\nTest accuracy:', test_acc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get confusion matrix with test_X\nY_pred = model.predict(test_X)\nval_preds = np.argmax(Y_pred, axis=1)\n\nval_trues = test_y\ncm = metrics.confusion_matrix(val_trues, val_preds)\ncm\n\nclass_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\n# Plot confusion matrix in a beautiful manner\nfig = plt.figure(figsize=(16, 14))\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cells\n# labels, title and ticks\nax.set_xlabel('Predicted', fontsize=20)\nax.xaxis.set_label_position('bottom')\nplt.xticks(rotation=90)\nax.xaxis.set_ticklabels(class_names, fontsize = 10)\nax.xaxis.tick_bottom()\n\nax.set_ylabel('True', fontsize=20)\nax.yaxis.set_ticklabels(class_names, fontsize = 10)\nplt.yticks(rotation=0)\n\nplt.title('Confusion Matrix', fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.classification_report(val_trues, val_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the first 4 test samples and show their predicted digit value in the title\ntest_X_reshaped = test_X\n_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\nfor ax, image, prediction in zip(axes, test_X_reshaped, val_preds):\n    ax.set_axis_off()\n    if (len(image.shape) == 3):\n        image = image.reshape(28,28)\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title(f'Prediction: {prediction}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions submition"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = np.array(test/255.)\ntest_pred = test_pred.reshape((-1,28,28,1))\n\ntest_predictions = model.predict_classes(test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submitting predictions\n# Predictions of test.csv\nsub_df = {'ImageId':list(range(1, len(test_predictions) + 1)),'Label': test_predictions}\nsubmission = pd.DataFrame(sub_df).astype('int')\nsubmission.head()\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}