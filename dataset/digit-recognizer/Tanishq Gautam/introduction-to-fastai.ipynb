{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MNIST using FastAI\n> MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. \n\n> It is definitely possible to build a really well functioning digit recognizer for Kaggle's playground competition. In fact, this model gets more than  99% accuracy. For such a simple and elegant solution I have to say, that's not bad at all. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# What is Fastai?\n> Fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *Please upvote the kernel if you find it useful*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing the necessary libraries:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom pathlib import Path\n\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\n\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"inputs=Path(\"../input/digit-recognizer\")\nos.listdir(inputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read the train and test datasets:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# load training data and explore the first three rows\ntrain=pd.read_csv(inputs/\"train.csv\")\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load test data and explore the first three rows\ntest=pd.read_csv(inputs/\"test.csv\")\ntest.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image transforms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**To get a set of transforms with default values that work pretty well in a wide range of tasks, it's often easiest to use get_transforms.**                                                                                                     \n* **tfms is just a parameter used later during training, which is initalized here.** \n* **tr and te are paths to be used.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# tfms can be passed directly to define a DataBunch object (see below) which is then associated with a model to begin training.\ntfms = get_transforms(do_flip=False) # if True the image is randomly flipped\ntr=Path(\"../train\")\nte=Path(\"../test\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have to try and get the dataset into a folder format, from the existing format, which will make it easier to use fastai's functions.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in range(10):\n    try:\n        os.makedirs(tr/str(index))\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(os.listdir(tr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.makedirs(te)\nexcept:\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Data\n**Currently, it is not even an image, just a 0s and 1s, as seen from the training set. Using the functions below, we can convert them into images:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in train.iterrows():\n    \n    label,digit = row[0], row[1:]\n    \n    filepath = tr/str(label)\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img = Image.fromarray(digit)\n    img.save(filepath/filename)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, digit in test.iterrows():\n\n    filepath = te\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img = Image.fromarray(digit)\n    img.save(filepath/filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display images ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def displayRandomImagesFromEveryFolder(directory=tr, samplesPerDigit=5):\n\n    fig = plt.figure(figsize=(5,10))\n    \n    for rowIndex in range(1, 10):\n        subdirectory = str(rowIndex)\n        path = directory/subdirectory\n        images = os.listdir(path)\n        for sampleIndex in range(1,samplesPerDigit+1):\n            randomNumber = random.randint(0, len(images)-1)\n            image = Image.open(path/images[randomNumber])\n            ax = fig.add_subplot(10, 5, samplesPerDigit*rowIndex + sampleIndex)\n            ax.axis(\"off\")\n            \n            plt.imshow(image, cmap='gray')\n            \n    \n    plt.show()\n    \ndisplayRandomImagesFromEveryFolder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The dataset has been converted into images!**\n\n**We can move on to getting the data from folders, and seperating them into training and validation sets. Also normalization is very important to make sure all values lie between 0 and 1.**\n\n**It turns out that the PosixPath is not iterated by ImageDataBunch in Kaggle.So we can change the path created by pathlib library which was a PosixPath object to just a string which specifies the path to the training and testing directories, so in our case train path = \"../train\" and test path = \"../test\"**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_folder(path=\"../train\",test=\"../test\",ds_tfms=tfms, valid_pct=0.2,bs=32,size=24).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3 ,figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The data has been successfully extracted from the folders.**\n\n**We can also check what classes exist:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training \n\n* **The fastai library includes several pretrained resnet models from torchvision, namely:**\n  **resnet18, resnet34, resnet50, resnet101, resnet152**\n* **It makes it very easy to use Resnet50.** \n* **Then, we can use the cnn_learner function, and create a Convolutional Neural Network.** ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**The cnn_learner factory method helps you to automatically get a pretrained model from a given architecture with a custom head that is suitable for your data.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet50, metrics=accuracy, model_dir = Path('../kaggle/input/ResNet-50'), callback_fns=ShowGraph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Next, we can figure out what ideal learning rates are:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# find optimal learning rate and plot the graph\nlearn.lr_find()\n# plot loss vs. learning rate\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can clearly see that the learning rate is most effective at 1e-01, but let's try without a predefined learning rate:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**97% accuracy, not bad at all.**\n\n**Saving this model:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save(\"501\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, let's try with the optimal learning rates:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(5,max_lr=slice(1e-3,1e-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save(\"502\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results\n\n**We can interpret our results as well:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interp=ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(8,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.most_confused(min_val=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From this, we can see which two numbers are confused most and the number of times.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(9,figsize=(7,7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**These are the images which had the highest loss, that is the biggest difference between the probability of being corect and actually being correct. Looking at these images, it is actually pretty difficult to distinguish some of these images, so we can be sure that the CNN is actually working pretty well, if it knows these are difficult to differentiate.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_score,y=learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs= class_score[0].tolist()\n[f\"{index}: {probs[index]}\" for index in range(len(probs))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**These are the probabilities that the image is any of these numbers. But we don't want that. We only want the highest probability:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_score=np.argmax(class_score,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_score[0].item()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\n\nNow, creating the submission file based on the example given (which should contain ImageId and Label):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"samplesub=pd.read_csv(inputs/\"sample_submission.csv\")\nsamplesub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageId = [os.path.splitext(path)[0] for path in os.listdir(te)]\nImageId = [int(path) for path in ImageId]\nImageId = [ID+1 for ID in ImageId]\nImageId[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs=pd.DataFrame({\"ImageId\":ImageId,\"Label\":class_score})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs.to_csv(\"submission.csv\",index=False)\nsubs.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**And that's it. A Simple model that gives an accuracy of > 99% with such few lines.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}