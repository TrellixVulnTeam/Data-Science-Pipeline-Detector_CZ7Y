{"cells":[{"metadata":{},"cell_type":"markdown","source":"Digit recognition is not something that difficult or advanced. It is kind of “Hello world!” program – not that cool, but you start exactly here. So I decided to share my work and at the same time refresh the knowledge – it’s being a long ago I played with images."},{"metadata":{},"cell_type":"markdown","source":"## Data Import and Exploration"},{"metadata":{},"cell_type":"markdown","source":"We start with importing all the necessary packages."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MNIST dataset, which contains 40 thousands hand-written digits is a “Hello World” dataset for this task, we will use the data from the competition here at Kaggle. No need to invent a wheel."},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\nwarnings.filterwarnings(\"ignore\")\ndf = pd.read_csv('../input/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the head() method, first column in dataset contains labels and the rest pixels of the image 28×28 – that is why we have 784 columns more. It is also useful to check the length of the dataset each time after some modification to make sure we did everything correct.\n\nNext, let’s visualize our pixels and watch the images we have. We use randint() to select random image every time we run the code below. Also we have to transform our pixels to numpy array (now its’ type is Series) and reshape it to the size 28×28 to be able to plot them."},{"metadata":{"trusted":true},"cell_type":"code","source":"ix = random.randint(0, len(df)-1)\nlabel, pixels = df.loc[ix][0], df.loc[ix][1:]\nimg = np.array(pixels).reshape((28,28))\nprint('label: ' + str(label))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Now, to make our life little bit easier we will transform our dataframe to have only two columns – label and image, where image is a numpy array of pixels. Also we will reduce the size of dataframe for faster computation (first we want to make sure everything works and then we start playing with model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforming df for easier manipulation\ndef transform_df(df):\n    labels, imgs = [], []\n    for index, row in df.iterrows():\n        label, pixels = row[0], row[1:]\n        img = np.array(pixels)\n        labels.append(label)\n        imgs.append(img)\n\n    df_img = pd.DataFrame({'label': labels, 'img': imgs})\n    # to speed up the process we can use for example only 1000 samples\n    # df_img = df_img[:1000]\n    return df_img\n\ndf_img = transform_df(df)\ndf_img.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking images using new df structure\nix = random.randint(0, len(df_img)-1)\nimg = df_img.loc[ix].img.reshape((28,28))\nlabel = df_img.loc[ix].label\nprint('label: ' + str(label))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we have our data prepared, we want to split it into 2 datasets: one to traing our model and another to test it’s performance. And the best way to do that is using sklearn. We set up a test_size=0.2 which is standard value for this operation (usually for test we leave 20-30% of data), which means that for training remains 80%. It is also a good practice to set shuffle=True as some datasets might have ordered data, so the model will learn to recognize 0s and 1s, but won’t have any idea that 8 exists for example."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(df_img, test_size=0.2, shuffle=True)\nprint(len(train_df), len(test_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building a Model"},{"metadata":{},"cell_type":"markdown","source":"We checked the length, the head of datasets – all good, we can start building our model. For this we will use pytorch.\n\nNext, we have to transform our data into pytorch Dataset. torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n\n* *(double_underscore)len(double_underscore)* so that len(dataset) returns the size of the dataset.\n* *(double_underscore)getitem(double_underscore)* to support the indexing such that dataset[i] can be used to get its sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create torch dataset\nfrom torch.utils.data import Dataset\nclass MNISTDataset(Dataset):\n  def __init__(self, imgs, labels):    \n    super(MNISTDataset, self).__init__()\n    self.imgs = imgs\n    self.labels = labels\n  def __len__(self):\n    return len(self.imgs)\n  def __getitem__(self, ix):\n    img = self.imgs[ix]\n    label = self.labels[ix]\n    return torch.from_numpy(img).float(), label\n\ndataset = {\n    'train': MNISTDataset(train_df.img.values, train_df.label.values),\n    'test': MNISTDataset(test_df.img.values, test_df.label.values)\n} \n\nlen(dataset['train'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# again checking image, now based on torch dataset\nix = random.randint(0, len(dataset['train'])-1)\nimg, label = dataset['train'][ix]\nprint(img.shape, img.dtype)\nprint(label)\nplt.imshow(img.reshape((28,28)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The beauty of pytorch is its simplicity in defining the model. We define our layer with inputs and outputs, we add some batch normalization to improve our model (It is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance) and activation function, in this case ReLU.\n\nFor the first input we have 784 neurons (one neuron per each pixel) and 512 for output (this one is almost random – I tried few different values and this one performed pretty well, so I left it). Next layer will have 512 inputs (input_layer[n+1] == output_layer[n]) and 256 for output, next 256 inputs and 128 outputs and the last one – 128 inputs and 10 for output (each neuron represents one of 10 digits)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nimport torch.nn as nn\ndef block(in_f, out_f):\n  return nn.Sequential(\n      nn.Linear(in_f, out_f),\n      nn.BatchNorm1d(out_f),\n      nn.ReLU(inplace=True),\n      #nn.Dropout(),\n  )\nmodel = nn.Sequential(\n  block(784,512),\n  block(512,256),\n  block(256,128),\n  nn.Linear(128, 10)\n)\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to create few additional parameters for our model:\n\n* criterion – to calculate loss function, in our case CrossEntropyLoss\n* optimizer – to set up learning rate\n* scheduler – to update learning rate if model doesn’t improve with time (quite powerful technique, allows us to tweak the system on the go)\n* dataloader – class for pytorch that provides single- or multi-process iterators over the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.1)\nscheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.1, patience=3, min_lr=0.0001, verbose=True)\n\ndataloader = {\n    'train': DataLoader(dataset['train'], batch_size=32, shuffle=True, num_workers=4),\n    'test': DataLoader(dataset['test'], batch_size=32, shuffle=False, num_workers=4),\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and Evaluating the Model"},{"metadata":{},"cell_type":"markdown","source":"With all above we can start training and evaluating our model. Although we define 100 epochs, it is also useful to stop the loop if model doesn’t improve with time. Here we have set up early_stop = 10, so if model doesn’t change for 10 epochs in a row we will stop the training process.\n\nTraining process: we iterate through our train data by assigning each image and label to a device defined previously, we give our model an image and it tries to find the correct class (preds), we clear all gradients (zero_grad()) and calculate the loss function and the gradient (loss), perform an optimizer step and append new value to a total_loss array.\n\nTesting process: we iterate through the test data, make predictions, calculate the loss and accuracy of the model. In torch.max() we are looking for an index of the maximum value as it will represent the class of a digit and in our case it will match labels. Then by comparing labels and predictions we calculate the accuracy of our model.\n\nEvery time we find the best model we save it and if we hit the early_stop we exit and report the results. Usually it won’t need all those 100 epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\nbest_acc, stop, early_stop = 0, 0, 10\nfor e in range(100):\n\n    model.train()\n    total_loss = []\n    for imgs, labels in tqdm(dataloader['train']):\n        imgs, labels = imgs.to(device), labels.to(device)\n        preds = model(imgs)\n        optimizer.zero_grad()\n        loss = criterion(preds, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss.append(loss.data)\n\n    model.eval()\n    val_loss, acc = [], 0.\n    with torch.no_grad():\n        for imgs, labels in tqdm(dataloader['test']):\n            imgs, labels = imgs.to(device), labels.to(device)\n            preds = model(imgs)\n            loss = criterion(preds, labels)\n            val_loss.append(loss.data)\n            _, preds = torch.max(preds, 1)\n            acc += (preds == labels).sum().item()\n\n    acc /= len(dataset['test'])\n    if acc > best_acc:\n        print('\\n Best model ! saved.')\n        torch.save(model.state_dict(), 'best_model.pt')\n        best_acc = acc\n        stop = -1\n\n    stop += 1\n    if stop >= early_stop:\n        break\n\n    scheduler.step(acc)\n\n    print('\\n Epoch {}, Training loss: {:4f}, Val loss: {:4f}, Val acc: {:4f}'.format(\n        e + 1, torch.mean(torch.stack(total_loss)), torch.mean(torch.stack(val_loss)), acc))\n\nprint('\\n Best model with acc: {}'.format(best_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we found our best model and saved it, we can play with it by feeding it with new data and see how it performs."},{"metadata":{"trusted":true},"cell_type":"code","source":"# test\nmodel.load_state_dict(torch.load('best_model.pt'))\nmodel.to(device)\nmodel.eval()\n\nix = random.randint(0, len(dataset['test'])-1)\nimg, label = dataset['test'][ix]\npred = model(img.unsqueeze(0).to(device)).cpu()\npred_label = torch.argmax(pred)\nprint('Ground Truth: {}, Prediction: {}'.format(label, pred_label))\nplt.imshow(img.reshape((28,28)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission of results"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/test.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = []\nfor index, row in submission.iterrows():\n    pixels = row[0:]\n    img = np.array(pixels)\n    imgs.append(img)\n\nsubmission_transf = pd.DataFrame({'img': imgs})\nsubmission_transf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting into pytorch dataset\n# inserting index values as labels\nsubmission_pt = {\n    'test': MNISTDataset(submission_transf.img.values, submission_transf.index.values)\n} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test individual samples from dropout dataset\nmodel.load_state_dict(torch.load('best_model.pt'))\nmodel.to(device)\nmodel.eval()\n\nix = random.randint(0, len(dataset['test'])-1)\nimg, idx = submission_pt['test'][ix]\npred = model(img.unsqueeze(0).to(device)).cpu()\npred_label = torch.argmax(pred)\nprint(type(idx))\nprint('Prediction: {}'.format(pred_label))\nplt.imshow(img.reshape((28,28)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on every image\nsubm_dict = dict()\n\nfor ix in range(0,len(submission_pt['test'])):\n    img, idx = submission_pt['test'][ix]\n    pred = model(img.unsqueeze(0).to(device)).cpu()\n    pred_label = torch.argmax(pred)\n    subm_dict[idx+1] = pred_label.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create submission file\nfinal_df = pd.DataFrame.from_dict(subm_dict, orient='index')\nfinal_df.index.name = 'ImageId'\nfinal_df.columns = ['Label']\nfinal_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Like it was said in the beginning it is a “Hello World” for the image recognition, we didn’t use convolutional neural network which is normally used in tasks like this, just entry level to understand the flow. I don’t usually work with images, so if there are some mistakes, please let me know. It was a nice refresher for me, hopefully it helped someone else."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}