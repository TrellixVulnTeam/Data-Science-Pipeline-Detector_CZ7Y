{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standard Imports","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tst = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nsub = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")\ntrn = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tst.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train\",trn.shape)\nprint(\"Test\",tst.shape)\nprint(\"Submission\",sub.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Store the Feature Column Names (except Label) in Variable","metadata":{}},{"cell_type":"code","source":"feat_cols = [ 'pixel'+str(i) for i in range(tst.shape[1]) ] # convert num to pixelnum for column names\nlen(feat_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basically does the same in a different way","metadata":{}},{"cell_type":"code","source":"def subtract_lists(x,y):\n    \"\"\"Subtract Two Lists (List Difference)\"\"\"\n    return [item for item in x if item not in y]\nfeat = subtract_lists(list(trn.columns),[\"label\"])\nlen(feat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([trn[feat_cols],tst],axis=0) # trn.iloc[:].iloc[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the Data","metadata":{}},{"cell_type":"code","source":"df = trn\nrndperm = np.random.permutation(df.shape[0])     # random permutation to be used later for data viz\n\nplt.gray()                                       # set the colormap to “gray”\nfig = plt.figure( figsize=(20,9) )               # initilaize the figure with the figure size\n\nfor i in range(0,15):\n    # use subplots to get 3x5 matrix of random handwritten digit images\n    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'label'])) )\n    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n    ax.set_xticks([])                             # set the xtciks and yticks as blanks\n    ax.set_yticks([]) \n\nplt.savefig(\"MINIST_DIGITS.png\",dpi=600)\nplt.show() ;                                      # display the figure","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 70000 Number of Samples","metadata":{}},{"cell_type":"code","source":"data_subset = df[feat_cols].values  # get the numpy array of this dataframe and store it is subset data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Customize Matlotlib","metadata":{}},{"cell_type":"code","source":"plt.style.use('dark_background')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"univ_seed=42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Apply TSNE","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state = univ_seed)\ntsne_results_2D = tsne.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Shape_X = trn.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300, random_state = univ_seed)\ntsne_results_3D = tsne.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the Files","metadata":{}},{"cell_type":"code","source":"np.save(\"tsne_results_2D.npy\",tsne_results_2D)\nnp.save(\"tsne_results_3D.npy\",tsne_results_3D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_labels = list(trn[\"label\"]) + [np.nan]*tst.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_df=pd.DataFrame(np.c_[y_labels ,tsne_results_2D[:,0], tsne_results_2D[:,1]], \n                        columns=['y','tsne-2d-one','tsne-2d-two' ])\nreduced_df['tsne-3d-one']=tsne_results_3D[:,0]\nreduced_df['tsne-3d-two']=tsne_results_3D[:,1]\nreduced_df['tsne-3d-three']=tsne_results_3D[:,2]\nreduced_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot the 2-Dimensional & 3-Dimensional Plots","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(16,10))\n\n\nreduced_df_sorted=reduced_df.dropna().sort_values(by='y', ascending=True).sample(n = 10000,random_state=univ_seed)\n\nsns.scatterplot(\n    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n    hue=\"y\",\n    palette=sns.color_palette(\"tab10\", 10), # hls, rocket, icefire , Spectral\n    data=reduced_df_sorted,\n    legend=\"full\",\n    alpha=1\n)\n\n\n\nplt.legend(title=\"Target Digits (y)\")\nplt.title(\"t-SNE Plot for MNIST Handwritten Digit Classification\",fontsize=20)\nplt.savefig(\"t-SNE Plot for MNIST Handwritten Digit Classification_custom1.png\",dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\ndf_sampled= reduced_df.dropna().sample(n = 500,random_state=univ_seed)\ndf_sampled_sorted=df_sampled.sort_values(by='y', ascending=True)\n\nfig = px.scatter_3d(df_sampled_sorted, x='tsne-3d-one', y='tsne-3d-two', z='tsne-3d-three',\n                    color='y', template=\"plotly_dark\",color_continuous_scale=px.colors.sequential.Plasma) # .Viridis\n\nfig.write_html(\"MNIST_Handwritten_Digits_Dataset_tSNE_3D_Viz.html\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X=reduced_df[[\"tsne-2d-one\", \"tsne-2d-two\"]].values\nreduced_df_train = reduced_df.dropna()\nX_train3D=reduced_df_train[[\"tsne-3d-one\", \"tsne-3d-two\", \"tsne-3d-three\"]].values\ny_train3D=reduced_df_train[\"y\"].values\nprint(\"X_train3D Shape : \", X_train3D.shape , \"y_train3D Shape : \", y_train3D.shape)\n\nreduced_df_test = reduced_df.loc[~reduced_df.index.isin(reduced_df.dropna().index)]\nX_test3D=reduced_df_test [[\"tsne-3d-one\", \"tsne-3d-two\", \"tsne-3d-three\"]].values\ny_test3D=reduced_df_test [\"y\"].values\nprint(\"X_test3D Shape : \", X_test3D.shape , \"y_test3D Shape : \", y_test3D.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train-test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X_train3D, y_train3D, test_size=0.2, random_state=univ_seed)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 40+1\nmean_acc = np.zeros((Ks-1))\nmean_acc_train= np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nstd_acc_train = np.zeros((Ks-1))\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat) #gets the test accuracy\n    y_pred=neigh.predict(X_train)\n    mean_acc_train[n-1] = metrics.accuracy_score(y_train,y_pred) #gets the train accuracy\n    \n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n    std_acc_train[n-1]=np.std(y_pred==y_train)/np.sqrt(y_pred.shape[0])\nprint(\"MEAN ACCURACY\")\nlength=len(mean_acc)\nfor i in range(length):\n    test_acc='{0:.3f}'.format(round(mean_acc[i],3))\n    train_acc='{0:.3f}'.format(round(mean_acc_train[i],3))\n    \n    print(\"K=\",f\"{i+1:02d}\",\"  Avg. Test Accuracy=\",test_acc,\"  Avg. Train Accuracy=\",train_acc) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint( \"The best test accuracy was\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1)\nprint( \"The corresponding training accuracy obtained was :\",mean_acc_train[mean_acc.argmax()])\n\nplt.figure(figsize=(15,7.5))\n#comment the figure sizeif you want a small figure size\nplt.plot(range(1,Ks),mean_acc_train,'r',linewidth=5)\nplt.plot(range(1,Ks),mean_acc,'g',linewidth=5)\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.fill_between(range(1,Ks),mean_acc_train - 1 * std_acc_train,mean_acc_train + 1 * std_acc_train, alpha=0.10)\n\n\nplt.scatter( mean_acc.argmax()+1,  mean_acc.max())\nplt.scatter( mean_acc.argmax()+1,  mean_acc_train[mean_acc.argmax()])\n#plt.annotate(\"BEST_TEST_ACC\", ( mean_acc.argmax()+1,  mean_acc.max()))\n#plt.annotate(\"CORRESPONDING_TRAIN_ACC\", ( mean_acc.argmax()+1,  mean_acc_train[mean_acc.argmax()]))\n\nplt.legend(('Train_Accuracy ','Test_Accuracy ', '+/- 3xstd_test','+/- 3xstd_train','BEST_TEST_ACC','CORRESPONDING_TRAIN_ACC'))\n\nplt.xticks(ticks=list(range(Ks)),labels=list(range(Ks)) )\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.title(\"Number of Neigbors Chosen vs Mean Training and Testing Accuracy Score\",fontsize=20)\nplt.tight_layout()\n\n\nplt.savefig(\"Number of Neigbors Chosen vs Mean Training and Testing Accuracy Score.png\",dpi=600)\nplt.show()\n\n#this plot clearly shows that initially the model does overfit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First,we keep a dictionary that measures all the losses/scores for our model/classifier\nTest_Scores={}\nTrain_Scores={}\n\n\n#Now evaluate the model based on metrics\n#First import scoring methods\nfrom sklearn.metrics import  accuracy_score, f1_score, confusion_matrix,precision_score, recall_score\n\nfrom sklearn.metrics import jaccard_score as jaccard_similarity_score\n#reconstruct the best model as last model is only saved. Previous models were overwritten\nbest_k=mean_acc.argmax()+1  #7\nneigh = KNeighborsClassifier(n_neighbors = best_k).fit(X_train,y_train)\nyhat=neigh.predict(X_test)\ny_pred=neigh.predict(X_train)\n\n#training scores\nTrain_Scores['KNN-jaccard']=jaccard_similarity_score(y_train, y_pred,average='weighted')\nTrain_Scores['KNN-f1-score']=f1_score(y_train, y_pred, average='weighted') \nTrain_Scores['KNN-accuracy-score']=accuracy_score(y_train, y_pred)\nTrain_Scores['KNN-precision-score']=precision_score(y_train, y_pred,average='weighted')\nTrain_Scores['KNN-recall-score']=recall_score(y_train, y_pred,average='weighted')\nprint(\"Train Scores\")\nprint(Train_Scores)\n\n#testing scores\n\nTest_Scores['KNN-jaccard']=jaccard_similarity_score(y_test, yhat,average='weighted')\nTest_Scores['KNN-f1-score']=f1_score(y_test, yhat, average='weighted')\nTest_Scores['KNN-accuracy-score']=accuracy_score(y_test, yhat) \nTest_Scores['KNN-precision-score']=precision_score(y_test, yhat, average='weighted') \nTest_Scores['KNN-recall-score']=recall_score(y_test, yhat, average='weighted') \nprint(\"Test Scores\")\nprint(Test_Scores)\n\ncm=confusion_matrix(y_test, yhat)\n\n\ncf_matrix=confusion_matrix(y_test, yhat)\n\nside_of_cm=cf_matrix.shape[0]\n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\nlabels = [f\"{v2}\\n{v3}\" for v2, v3 in\n          zip(group_counts,group_percentages)]\n\nlabels = np.asarray(labels).reshape(side_of_cm,side_of_cm)\n\nfig=plt.figure(figsize=(20,8))\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='inferno')\n\n\n\nplt.xlabel(\"True Values\",fontsize=18)\nplt.ylabel(\"Predicted Values\",fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.title(\"Confusion Matrix for k-NN classifier for applied t-SNE\\nMNIST Handwritten Digit Dataset\",fontsize=20)\n\nplt.savefig(\"Confusion Matrix for k-NN classifier for applied t-SNE MNIST Handwritten Digit Dataset_1.png\",dpi=600)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_k=mean_acc.argmax()+1  #7\nneigh3D = KNeighborsClassifier(n_neighbors = best_k).fit(X_train3D,y_train3D)\nyhat=neigh3D.predict(X_test3D)\ny_pred=neigh3D.predict(X_train3D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(yhat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\nsub3D = deepcopy(sub)\nsub3D[\"Label\"] = yhat.astype('uint8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub3D.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub3D.to_csv('sub3D.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X=reduced_df[[\"tsne-2d-one\", \"tsne-2d-two\"]].values\nreduced_df_train = reduced_df.dropna()\nX_train2D=reduced_df_train[[\"tsne-2d-one\", \"tsne-2d-two\"]].values\ny_train2D=reduced_df_train[\"y\"].values\nprint(\"X_train2D Shape : \", X_train2D.shape , \"y_train2D Shape : \", y_train2D.shape)\n\nreduced_df_test = reduced_df.loc[~reduced_df.index.isin(reduced_df.dropna().index)]\nX_test2D=reduced_df_test [[\"tsne-2d-one\", \"tsne-2d-two\"]].values\ny_test2D=reduced_df_test [\"y\"].values\nprint(\"X_test3D Shape : \", X_test2D.shape , \"y_test3D Shape : \", y_test2D.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train-test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X_train2D, y_train2D, test_size=0.2, random_state=univ_seed)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 40+1\nmean_acc = np.zeros((Ks-1))\nmean_acc_train= np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nstd_acc_train = np.zeros((Ks-1))\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat) #gets the test accuracy\n    y_pred=neigh.predict(X_train)\n    mean_acc_train[n-1] = metrics.accuracy_score(y_train,y_pred) #gets the train accuracy\n    \n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n    std_acc_train[n-1]=np.std(y_pred==y_train)/np.sqrt(y_pred.shape[0])\nprint(\"MEAN ACCURACY\")\nlength=len(mean_acc)\nfor i in range(length):\n    test_acc='{0:.3f}'.format(round(mean_acc[i],3))\n    train_acc='{0:.3f}'.format(round(mean_acc_train[i],3))\n    \n    print(\"K=\",f\"{i+1:02d}\",\"  Avg. Test Accuracy=\",test_acc,\"  Avg. Train Accuracy=\",train_acc) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint( \"The best test accuracy was\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1)\nprint( \"The corresponding training accuracy obtained was :\",mean_acc_train[mean_acc.argmax()])\n\nplt.figure(figsize=(15,7.5))\n#comment the figure sizeif you want a small figure size\nplt.plot(range(1,Ks),mean_acc_train,'r',linewidth=5)\nplt.plot(range(1,Ks),mean_acc,'g',linewidth=5)\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.fill_between(range(1,Ks),mean_acc_train - 1 * std_acc_train,mean_acc_train + 1 * std_acc_train, alpha=0.10)\n\n\nplt.scatter( mean_acc.argmax()+1,  mean_acc.max())\nplt.scatter( mean_acc.argmax()+1,  mean_acc_train[mean_acc.argmax()])\n#plt.annotate(\"BEST_TEST_ACC\", ( mean_acc.argmax()+1,  mean_acc.max()))\n#plt.annotate(\"CORRESPONDING_TRAIN_ACC\", ( mean_acc.argmax()+1,  mean_acc_train[mean_acc.argmax()]))\n\nplt.legend(('Train_Accuracy ','Test_Accuracy ', '+/- 3xstd_test','+/- 3xstd_train','BEST_TEST_ACC','CORRESPONDING_TRAIN_ACC'))\n\nplt.xticks(ticks=list(range(Ks)),labels=list(range(Ks)) )\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.title(\"Number of Neigbors Chosen vs Mean Training and Testing Accuracy Score\",fontsize=20)\nplt.tight_layout()\n\n\nplt.savefig(\"Number of Neigbors Chosen vs Mean Training and Testing Accuracy Score.png\",dpi=600)\nplt.show()\n\n#this plot clearly shows that initially the model does overfit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First,we keep a dictionary that measures all the losses/scores for our model/classifier\nTest_Scores={}\nTrain_Scores={}\n\n\n#Now evaluate the model based on metrics\n#First import scoring methods\nfrom sklearn.metrics import  accuracy_score, f1_score, confusion_matrix,precision_score, recall_score\n\nfrom sklearn.metrics import jaccard_score as jaccard_similarity_score\n#reconstruct the best model as last model is only saved. Previous models were overwritten\nbest_k=mean_acc.argmax()+1  #7\nneigh = KNeighborsClassifier(n_neighbors = best_k).fit(X_train,y_train)\nyhat=neigh.predict(X_test)\ny_pred=neigh.predict(X_train)\n\n#training scores\nTrain_Scores['KNN-jaccard']=jaccard_similarity_score(y_train, y_pred,average='weighted')\nTrain_Scores['KNN-f1-score']=f1_score(y_train, y_pred, average='weighted') \nTrain_Scores['KNN-accuracy-score']=accuracy_score(y_train, y_pred)\nTrain_Scores['KNN-precision-score']=precision_score(y_train, y_pred,average='weighted')\nTrain_Scores['KNN-recall-score']=recall_score(y_train, y_pred,average='weighted')\nprint(\"Train Scores\")\nprint(Train_Scores)\n\n#testing scores\n\nTest_Scores['KNN-jaccard']=jaccard_similarity_score(y_test, yhat,average='weighted')\nTest_Scores['KNN-f1-score']=f1_score(y_test, yhat, average='weighted')\nTest_Scores['KNN-accuracy-score']=accuracy_score(y_test, yhat) \nTest_Scores['KNN-precision-score']=precision_score(y_test, yhat, average='weighted') \nTest_Scores['KNN-recall-score']=recall_score(y_test, yhat, average='weighted') \nprint(\"Test Scores\")\nprint(Test_Scores)\n\ncm=confusion_matrix(y_test, yhat)\n\n\ncf_matrix=confusion_matrix(y_test, yhat)\n\nside_of_cm=cf_matrix.shape[0]\n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\nlabels = [f\"{v2}\\n{v3}\" for v2, v3 in\n          zip(group_counts,group_percentages)]\n\nlabels = np.asarray(labels).reshape(side_of_cm,side_of_cm)\n\nfig=plt.figure(figsize=(20,8))\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='inferno')\n\n\n\nplt.xlabel(\"True Values\",fontsize=18)\nplt.ylabel(\"Predicted Values\",fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.title(\"Confusion Matrix for k-NN classifier for applied t-SNE\\nMNIST Handwritten Digit Dataset\",fontsize=20)\n\nplt.savefig(\"Confusion Matrix for k-NN classifier for applied t-SNE MNIST Handwritten Digit Dataset_1.png\",dpi=600)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_k=mean_acc.argmax()+1  #7\nneigh2D = KNeighborsClassifier(n_neighbors = best_k).fit(X_train2D,y_train2D)\nyhat=neigh2D.predict(X_test2D)\ny_pred=neigh2D.predict(X_train2D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\nsub2D = deepcopy(sub)\nsub2D[\"Label\"] = yhat.astype('uint8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2D.to_csv('sub2D.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\npickle.dump( neigh2D, open( \"neigh2D.p\", \"wb\" ) )\npickle.dump( neigh3D, open( \"neigh3D.p\", \"wb\" ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub3D.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}