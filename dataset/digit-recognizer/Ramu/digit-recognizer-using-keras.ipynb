{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Digit Recognizer<h1>\n\n<h2>Introduction:</h2>\n\nThe computer vision has changed a lot in the world ranging from opening a phone with face recognition to self driving cars and all this development is result of Deep Learning.Deep Learning is going to be the future.....So,if your interested in getting started with this than\nmy suggestion is to take course of deep learning by Andrew NG it is an awesome course which gives all insights of deep learning...\n\nNow in this kernel i am working on MNIST data set to build a digit Recognizer.....So let's get started."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing all the required libraries\nimport numpy as np#numpy array calculations\nimport pandas as pd#working with dataframe\nimport matplotlib.pyplot as plt#for visualizing the plots\nimport matplotlib.image as mpimg#To view images which are of the form of numbers\nimport seaborn as sns#For plotting\n\nnp.random.seed(0)#To get same results whenever i do this\nfrom sklearn.model_selection import train_test_split#For validation and checking the preformance of model\nfrom sklearn.metrics import confusion_matrix#To see where our model doing wrong\nimport itertools#For efficient looping\nfrom keras.utils.np_utils import to_categorical#one hot encoding\nfrom keras.models import Sequential#The CNN type it have other types like Residual etc.,.\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D#Types of layers\nfrom keras.optimizers import RMSprop,Adam#fits the filter variables,weights etc.,.\nfrom keras.preprocessing.image import ImageDataGenerator#For data augmentation\nfrom keras.callbacks import ReduceLROnPlateau#To make sure the we reduce learning rate if model stopped learning, upto some limit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting style for our plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='white',context='notebook',palette='deep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Load Data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load the data\ntrain=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see that we want that label as output so we will take out this from this dataframe into a separate output list"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train['label']\nX_train=train.drop(labels=['label'],axis=1)\ndel train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We deleted train dataframe as it is not going to be useful anyway.So now let's test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test data is good in the way we wanted it so now let's see how the data is.And how many training examples are there for each output(each digit)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to normalize the values and need to bring the mean and std to zero(for fast calculation of gradient descent)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the data is well distributed So we have no problem with y_train"},{"metadata":{},"cell_type":"markdown","source":"Now check any missing values are there."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in training and i also checked in test data also .... there are no missing values so no problem.Now let's move to next step of normalization."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train/255.0\ntest=test/255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above will helps in getting faster outputs by coverging faster to the global minima.\nNow we will reshape this into gray image(Add channel as 1, For RGB images we will have 3 channels).\n\nHere as we don't know the number of images in a set We will generalise it by placing (-1 which it treats as 'n' that can be seen at run time)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.values.reshape(-1,28,28,1)#making an 3D array like (28*28*1) how an actual image look.\ntest=test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now as the output variable is categorical values we will hot encode it into a vector.So we can apply softmax function for getting output easily."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=to_categorical(y_train,num_classes=10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now split to training and validation sets...."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=0)#specify random state to get same outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In deep learning always remember we can have large datasets most of the times so we don't split in 75% and 25% ratio rather we give a small percent like 4-10% for validating and testing and those are more than enough."},{"metadata":{"trusted":true},"cell_type":"code","source":"g=plt.imshow(X_train[1][:,:,0])#displays image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we tranformed the input vectors to matrices to get images like this.Now let's build our Model:-\n\nWe will use:-\n\n1)Convolution layers:-To find features from images\n\n2)Pooling layers:-Generalising those features(like finding global features)\n\n3)Flatten Layers:-converts to 1D vector\n\n4)Fully connected layers:-Like neural networks (Last layer has 10 neurons with softmax function to get output).\n\nOther things which we use:-\n\nrelu activation:-For non linearity.\n\nDropout:-Reduce overfitting.\n\nBatch Normalization:-For making mini batch gradient descent faster\n\nMy model will be:-\n\nConv2D->Conv2D->Maxpool->Conv2D->Conv2D->Maxpool->Flatten->Dense(Fully connected)->Dense(Softmax)->output.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel=Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding='same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(10,activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now:-\n\nWe need to set three things:-\n\n1)Loss function:-categorical_crossentropy(for softmax)\n\n2)score function:-accuracy(gives how correctly we are predicting the validation set)\n\n3)optimizer:-Adam(Uses both concepts of momentum and RMSProp)"},{"metadata":{},"cell_type":"markdown","source":"Optimizer let's you calculate the weights and filter values to represent the features.It updates the values by following gradient descent approch."},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=Adam()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can compile our model that means we finished our model to be use like an object after compilation."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now parameter tuning for getting Global maximum and this is done by tuning the Learning rate.What we are doing is when we had no improvement in model we will slowly decrease the learning rate until some lower boundary....\n\nThe below arguments means:-\n\nval_accuracy:-validation set accuracy\n\nPatience:-How many epochs we see before reducing learning rate\n\nverbose:-shows output of each epoch(takes values of 0->shows nothing,1->shows each epoch with ======= and 2->shows each epoch with number\n\nfactor:-by which we decrease the learning rate.\n\nmin_lr:-The lower boundary till we decrease the learning rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rat=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.001)\nepochs=3\nbatch_size=64 #powers of two is better generally and by convention we follow this","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Data Augmentation</h2>"},{"metadata":{},"cell_type":"markdown","source":"Well we know that everyone won't write the digits with same width and in same angle with same clarity so we will perform the data augmentation techinque to make sure we can see all possibilities."},{"metadata":{"trusted":true},"cell_type":"code","source":"datagenerated=ImageDataGenerator(rotation_range=10,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we rotated by 10degrees for some images and zooming some images by 10percent, shifts heights and widths to make sure we covered all the\npossibilities of images we can get and we apply this to out X_train as seen below."},{"metadata":{"trusted":true},"cell_type":"code","source":"datagenerated.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's run the model for 3epochs it takes easily 30min.feel free to play with arguments and optimizers and archeticture by changing something so that you can get better in sights of what happening."},{"metadata":{"trusted":true},"cell_type":"code","source":"digit_rec=model.fit_generator(datagenerated.flow(X_train,y_train,batch_size=batch_size),\n                              epochs=epochs,validation_data=(X_val,y_val),verbose=2,steps_per_epoch=X_train.shape[0],\n                              callbacks=[learning_rat])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now work on predictions for test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"results=model.predict(test)\nresults=np.argmax(results,axis=1)\nresults=pd.Series(results,name='Label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.concat([pd.Series(range(1,28001),name='ImageId'),results],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}