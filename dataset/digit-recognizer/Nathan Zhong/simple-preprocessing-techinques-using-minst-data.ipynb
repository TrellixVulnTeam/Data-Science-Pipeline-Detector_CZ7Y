{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Simple Image Preprocessing Techniques Using MINST Data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Please upvote if you find this helpful and comment any improvements or questions! Feel free to check out some of my other notebooks! **","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Image preprocessing is an important step in any computer vision task, especially as the data becomes more complicated, noisy, and diverse. Good preprocessing could make the difference between a good model and an excellent model, impacting the final score greatly. Below, I will go over several very simple preprocessing techniques using the MINST digits dataset. (Disclaimer: By no means are these the ONLY preprocessing techniques available.)\n\n* Importing Libraries and Setting Up the Dataframe\n* Plotting Functions and Resizing Images\n* Image Normalization\n* Image Blurring\n* Morphological Operations\n* Edge Sharpening\n\nFor the preprocessed images, I will display the original four first and then the preprocessed four.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Importing Libraries and Establishing the Dataframe**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport cv2\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom keras.models import Model\n\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\n\nimages = pd.DataFrame()\ndef split_dataset(x,x_train):\n    train_sub = train[train['label']==x].sample(4) #I will only be using 4 examples from each number\n    x_train = x_train.append(train_sub,ignore_index=True)\n    return x_train\n\nfor i in range (10):\n    images = split_dataset(i,images)\n\nprint(images.head(4))\n\nimages = images.drop(['label'],axis = 1)\nimages = images.values.reshape([-1,28,28,1]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Plotting Functions and Resizing Images**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_one (a):\n    plt.imshow(a,cmap = 'gray')\n    plt.axis('off') \n    plt.show()\ndef display(images):\n    y = 0\n    for i in range (10):\n        plt.subplot(141), plt.imshow(images[y],cmap='gray')\n        plt.axis('off')\n        plt.subplot(142), plt.imshow(images[y+1],cmap='gray')\n        plt.axis('off')\n        plt.subplot(143), plt.imshow(images[y+2],cmap='gray')\n        plt.axis('off')\n        plt.subplot(144), plt.imshow(images[y+3],cmap='gray')\n        plt.axis('off')\n        y+=4\n        plt.show()\n\ndef display_change (images, func):\n    y = 0\n    for i in range (10):\n        plt.subplot(181), plt.imshow(images[y],cmap='gray')\n        plt.axis('off')\n        plt.subplot(182), plt.imshow(images[y+1],cmap='gray')\n        plt.axis('off')\n        plt.subplot(183), plt.imshow(images[y+2],cmap='gray')\n        plt.axis('off')\n        plt.subplot(184), plt.imshow(images[y+3],cmap='gray')\n        plt.axis('off')\n        plt.subplot(185), plt.imshow(func(images[y]),cmap='gray')\n        plt.axis('off')\n        plt.subplot(186), plt.imshow(func(images[y+1]),cmap='gray')\n        plt.axis('off')\n        plt.subplot(187), plt.imshow(func(images[y+2]),cmap='gray')\n        plt.axis('off')\n        plt.subplot(188), plt.imshow(func(images[y+3]),cmap='gray')\n        plt.axis('off')\n        y+=4\n        plt.show()\ndef size(img):\n    img = array_to_img(img, scale = False)\n    img = img.resize((100,100))\n    img = img.convert(mode = 'RGB')\n    img = img_to_array(img)\n    return img.astype(np.float64)\n    \nresized = []\nfor i in images:\n    resized.append(size(i))\n    \ndisplay(resized)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image Normalization**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Normalizing image arrays between 0 and 1 is very beneficial when training deep learning models, because it helps the models converge and train faster. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"resized = np.array(resized)\ndef normalized (img):\n    return img/255.0\n\ndisplay_change(resized,normalized)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image Blurring**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next, we will take a look at image blurring. Image blurring is a way of to reduce the detail and noise in an image, making it more blurry, but helping reduce overfitting and improve generalization in training deep learning models. Small, minute details in certain images may cause the models to depend on those details, making them ineffective against variation in other images. We will use OpenCV in order to apply averaging, Gaussian filtering, median filtering, and bilateral filtering.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Averaging**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Averaging is done by convoling an image with a normalized box filter, by taking the mean of the pixels in the kernel area and replacing the middle/central element. For example, a 3x3 normalized box filter would look like this.\n\n![Screenshot%20%2860%29.png](attachment:Screenshot%20%2860%29.png)\n\nThe box filter's width and height can be changed in the blur function, where a bigger box filter would lead to higher generationlization and a greater loss in higher level details.","attachments":{"Screenshot%20%2860%29.png":{"image/png":"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"}},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def averaging(img):\n    return cv2.blur(img,(5,5))\n\ndisplay_change(resized,averaging)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gaussian Filtering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In Gaussian Filtering, instead of using a normalized box filter, a Gaussian kernel is used instead. This method is especially effective in removing Gaussian noise, which is noise that has a probability density function equal to the normal distribution. \n\n![](https://lh3.googleusercontent.com/proxy/Z7zDMAdZgJp8m-K-PPpC6H_b6HwGFfb-Q-TlWR1a_eoTi54mfWuIauHiLkivxnkV6brBVWdVFY9D8piidguQ57R0od2ouyggwg9jhWgEgYZvUXki8p928w)\n\nHere, the width and height are specificed again (But this time they have to be odd), and the standard deviation must be specified. \n\n![](https://www.researchgate.net/profile/Oleg_Shipitko/publication/325768087/figure/fig2/AS:637519863508992@1529007988866/Discrete-approximation-of-the-Gaussian-kernels-3x3-5x5-7x7.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def gaussian(img):\n    return cv2.GaussianBlur(img,(5,5),0)\n\ndisplay_change(resized,gaussian)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Median Filtering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Median filtering, which is very similar to averaging, changes the central element of the kernel area to the median of the values in the kernel space. This is very effective against salt-and-pepper noise and the kernel size should always be a positive odd number.\n\n![](https://www.southampton.ac.uk/~msn/book/new_demo/median/Picture1.png)\n\nNote: The image passing through the medianBlur function must be of dtype float32.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def median(img):\n    return cv2.medianBlur(np.float32(img),3)\n\ndisplay_change(resized, median)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bilateral Filtering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"And finally, bilateral filtering utilizes Gaussian filtering twice in order to preserve edge detail while also effectively removing noise. First, a Gaussian filter is taken in space, but a second one is taken as a function of the pixel difference. The first Gaussian function ensures only nearby pixels are blurred, while the second Gaussian function ensures that only pixels whose values are close to the central element are blurred, rather than elements with greater differences, which could indicate an edge.\n\n![](https://www.researchgate.net/profile/Fatih_Porikli/publication/221361504/figure/fig1/AS:305607526633472@1449873920125/Bilateral-filter-has-spatial-and-range-components.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def bilateral(img):\n    return cv2.bilateralFilter(img.astype(np.uint8),9,75,75)\n\ndisplay_change(resized,bilateral)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Morphological Operations**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next, we will discuss morphological operations, which are a collection of nonlinear operations that deal with the shape (or morphology) of the image. These techniques are less concerned with the pixel values, such as the smoothing techniques presented above, rather the relative ordering of the pixel values (According to [Wikipedia](https://en.wikipedia.org/wiki/Morphological_image_processing)). These techniques utilize structuring elements, which are positioned throughout the image at different locations, where the operation figures out the correlation with the structuring elements with its surrounding elements. Some operations test whether they \"fit\" while others test contrast and \"hits\".\n\n![](https://www.cs.auckland.ac.nz/courses/compsci773s1c/lectures/ImageProcessing-html/morph-probing.gif)\n\nWith each morphological operation, I will provide examples of a change in kernel size and a change in iterations, in order to encompass those hyperparameters. In general, though, a larger kernel size works in larger steps while larger iterations tend increase the effect of the operation.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Dilation**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First off, dilation monitors \"hits\" or contrasts to the pixels, and adds an extra layer of pixels to the inner and outer boundaries of the shapes. \n\n![](https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/diltbin.gif)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = np.ones((5,5),np.uint8)\n\ndef dilation(img):\n    return cv2.dilate(img,kernel,iterations = 1)\n\ndisplay_change(resized,dilation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dilation_1(img):\n    return cv2.dilate(img,kernel,iterations = 5)\n\ndisplay_change(resized,dilation_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = np.ones((10,10),np.uint8)\n\n\ndisplay_change(resized,dilation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Erosion**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Erosion is the opposite of dilation, where it scans for \"fits\" among the boundaries, and strips a layer from the inner and outer boundaries of the shape. This can be used to sharpen edges or increase constrast between two very similar images.\n\n![](https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/erodbin.gif)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = np.ones((5,5), np.uint8) \n\ndef erosion(img):\n    return cv2.erode(img,kernel,iterations = 1)\n\ndisplay_change(resized,erosion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def erode_1(img):\n    return cv2.erode(img,kernel,iterations = 2)\n\ndisplay_change(resized,erode_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = np.ones((10,10),np.uint8)\n\n\ndisplay_change(resized,erosion)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compound Operations**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are also examples of compound opeartions in morphology. The two main ones are opening and closing and image, which are a combination of a dilation and an erosion. \n\n* Closing is a way of filling in holes and solidifying images, increasing generalization and decreasing the importance of smaller marks or details. An erosion is performed first and then a dilation is performed.\n* Opening is a way of decreasing small details in an image to \"open\" up larger details and forgo smaller, unimportant details. A dilation is performed first and then an erosion is performed. Any pixels that \"survive\" after the erosion are restroed after the dilation.\n\nOpening and closing can also be applied, which ultimately closes larger objects and forgoes smaller details that are not connected to the main content of the image.\n\n![](https://i.ytimg.com/vi/1owu136z1zI/maxresdefault.jpg)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = np.ones((5,5),np.uint8)\n\ndef closing(img):\n    return erosion(dilation(img))\n\ndisplay_change(resized,closing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def opening(img):\n    return dilation(erosion(img))\n\ndisplay_change(resized,opening)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Edge Sharpening**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"And finally, edge sharpening is a useful tool, especially if your dataset has many labelled images with very similar features and edge sharpening can help make them more defined. Here, edge sharpening uses the function filter2D, by passing the kernel through, which increases the difference between the central element and its surrounding elements, making the distinction. This distinction can be more helpful for image EDAs and understanding the data better or possibly for feature engineering.\n\n![](https://static.packt-cdn.com/products/9781785283932/graphics/B04554_02_11.jpg)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_sharpening = np.array([[-2,-2,-2],\n                             [-2,25,-2],\n                             [-2,-2,-2]])\n\ndef sharpening(img):\n    return cv2.filter2D(img,-1,kernel_sharpening)\n\ndisplay_change(resized,sharpening)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thank you. Hopefully this helped you out. Feel free to comment below on any suggestions, comments, or concerns.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}