{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Hand Written digit recognition using CNN\nIn this notebook, I have converted dataset of MNIST from csv format to binary images so that we can visualize and can solve it using Convolutional Neural Networks(CNN).\nwith the available csv format dataset, this problem can surely be solved with other algorithms in better way. but my main pupose to write this notebook is to give insights of using CNN in keras with simpler dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, ImageDataGenerator\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In the cell below, we are reading dataset of hand written digits in pandas dataframe. because data was available in csv format"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv ('/kaggle/input/digit-recognizer/train.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From CSV data to Images\nIn cell below, I wrote some code to preprocess the data according to my need. I get dataframe of images where each row contains 784 pixel values of one image. I took each row and converted it to 28x28 images and stored all images in a list.\nfrom given data, I also extracted lables that is calssifying each image."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\ndef extract_train_images(data):\n    \"\"\"\n    function to extract list 2d numpy arrays of images and numpy array of labels.\n    Input - DataFrame data\n    Output - list of 2D numpy arrays for images and 1d numpy array for labels\n    \n    \"\"\"\n    labels = np.array(data['label'])\n    \n    data = data.drop('label', axis = 'columns')\n    images_array = np.array(data)\n    \n    images_list = []\n    for image_arr in images_array:\n        images_list.append(np.array(np.array_split(image_arr, 28))[:,:,np.newaxis])\n    \n    return images_list, labels\n\nimages_list, labels = extract_train_images(train_data)\none_hot_labels = to_categorical(labels)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's plot some images as well as print their labels to visualize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 1\nfig = plt.figure(figsize = (8,8))\nrows = 4\ncolumns = 4\nfor image, label in zip(images_list, labels):\n    fig.add_subplot(rows, columns, count)\n    plt.imshow(image[:,:,0])\n    print('Label:',label)\n    count+=1\n    if count >16:\n        break\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## In cell below, I am using Image data generator available in keras. you can check here in documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Data Generation\ntrain_gen = ImageDataGenerator(rescale = 1/255.)\n\ntrain_images = np.array(images_list)\nprint(train_images.shape)\n\ntrain_generator = train_gen.flow(train_images, one_hot_labels, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Enough preprocessing with training data now, let's import test data and play with it so that we can prepare it to make predictions that can be submitted later."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test/Validation dataset\n\ntest_data = pd.read_csv ('/kaggle/input/digit-recognizer/test.csv')\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_test_images(data):\n    images_array = np.array(data)\n    \n    images_list = []\n    for image_arr in images_array:\n        images_list.append(np.array(np.array_split(image_arr, 28))[:,:,np.newaxis])\n    \n    return images_list\n\ntest_images_list = extract_test_images(test_data)\n\ntest_images = np.array(test_images_list)\nprint(test_images.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## In the cell below, I have defined model using keras API layers. It is a simple CNN architecture i haven't used any complex state of the art architecture to make it simple."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Definition\n\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n\nmodel = tf.keras.Sequential([\n    Conv2D(32, kernel_size = (3,3), input_shape = (28,28,1), activation = 'relu'),\n    MaxPooling2D(2,2),\n    Conv2D(64, kernel_size = (3,3), activation = 'relu'),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dense(128, activation = 'relu'),\n    Dense(28, activation = 'relu'),\n    Dense(10, activation = 'softmax')\n])\n\nmodel.compile(optimizer = 'rmsprop',\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I will define callback function that will be called after every epoch on training dataset. I am forcing an early stopping if accuracy will reach 100% using this callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\nclass myCallBack(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        acc = logs.get('accuracy')\n        if acc >= 1.0:\n            print(\"\\nRequired accuracy achieved so ending the training.\")\n            self.model.stop_training=True\n\ncall_back = myCallBack()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training of model on 100 epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 32\nEPOCHS = 10\n\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=train_images.shape[0] // BS,\n                              epochs=EPOCHS,\n                              callbacks = [call_back])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('digit_recognizer.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As model is using softmax activation at the end so it will output a vector. Let's convert that one-hot vector to label so that we can print and see predictions by our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_to_label(vec):\n    \"\"\"\n    function will convert one hot vector of model output into a single label\n    \"\"\"\n    count=0\n    for number in vec[0]:\n        if number == 1:\n            return count\n        count+=1\n    return -1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization of images and their predictions made by our trained model."},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 1\nfig = plt.figure(figsize = (8,8))\nrows = 4\ncolumns = 4\nfor image in test_images:\n    fig.add_subplot(rows, columns, count)\n    plt.imshow(image[:,:,0])\n    print(onehot_to_label(model.predict(image.reshape(1,28,28,1))))\n    count+=1\n    if count >16:\n        break\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### If you liked the notebook kindly support it by giving a vote. Thank you."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}