{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Introduction**","metadata":{}},{"cell_type":"markdown","source":"This notebook will give you a step by step guide on how to crease a **Convolutional Neural Networks** using PyTorch to classify the MNIST data.","metadata":{}},{"cell_type":"markdown","source":"**TABLE OF CONTENTS**\n\n1. Imports\n2. Data Clearning and Scaling\n3. Data Visualization\n2. Example Neural Network\n3. Convolutional Neural network\n4. Training and Validation Graphs\n5. Submission","metadata":{}},{"cell_type":"markdown","source":"![](https://camo.githubusercontent.com/d440ac2eee1cb3ea33340a2c5f6f15a0878e9275/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)","metadata":{}},{"cell_type":"markdown","source":"**Hope you enjoy!**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T01:47:50.732545Z","iopub.execute_input":"2021-07-26T01:47:50.732873Z","iopub.status.idle":"2021-07-26T01:47:50.73898Z","shell.execute_reply.started":"2021-07-26T01:47:50.732842Z","shell.execute_reply":"2021-07-26T01:47:50.738163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:50.740854Z","iopub.execute_input":"2021-07-26T01:47:50.741435Z","iopub.status.idle":"2021-07-26T01:47:50.754255Z","shell.execute_reply.started":"2021-07-26T01:47:50.741398Z","shell.execute_reply":"2021-07-26T01:47:50.753569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('Training on CPU...')\nelse:\n    print('Training on GPU...')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:50.757784Z","iopub.execute_input":"2021-07-26T01:47:50.758052Z","iopub.status.idle":"2021-07-26T01:47:50.767479Z","shell.execute_reply.started":"2021-07-26T01:47:50.758027Z","shell.execute_reply":"2021-07-26T01:47:50.766383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\ntrain_df.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-26T01:47:50.800158Z","iopub.execute_input":"2021-07-26T01:47:50.800408Z","iopub.status.idle":"2021-07-26T01:47:54.580296Z","shell.execute_reply.started":"2021-07-26T01:47:50.800385Z","shell.execute_reply":"2021-07-26T01:47:54.579368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(train_df['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:54.582063Z","iopub.execute_input":"2021-07-26T01:47:54.582435Z","iopub.status.idle":"2021-07-26T01:47:54.735627Z","shell.execute_reply.started":"2021-07-26T01:47:54.582399Z","shell.execute_reply":"2021-07-26T01:47:54.73474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().any().sum(), test_df.isnull().any().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:54.737474Z","iopub.execute_input":"2021-07-26T01:47:54.737886Z","iopub.status.idle":"2021-07-26T01:47:54.764502Z","shell.execute_reply.started":"2021-07-26T01:47:54.737844Z","shell.execute_reply":"2021-07-26T01:47:54.763234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNISTData(torch.utils.data.Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        item = self.data.iloc[index]\n                \n        image = item[1:].values.astype(np.uint8).reshape((28, 28))\n        label = item[0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:54.766231Z","iopub.execute_input":"2021-07-26T01:47:54.766653Z","iopub.status.idle":"2021-07-26T01:47:54.77693Z","shell.execute_reply.started":"2021-07-26T01:47:54.766611Z","shell.execute_reply":"2021-07-26T01:47:54.775709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seperate the features and labels\ntargets_np = train_df.label.values\nfeatures_np = train_df.loc[:, train_df.columns != 'label'].values/255\n\n# Split into training and test set\nfeatures_train, features_test, target_train, target_test = train_test_split(features_np, targets_np, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:58:47.754841Z","iopub.execute_input":"2021-07-26T01:58:47.755176Z","iopub.status.idle":"2021-07-26T01:58:48.320302Z","shell.execute_reply.started":"2021-07-26T01:58:47.755143Z","shell.execute_reply":"2021-07-26T01:58:48.319501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(target_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for test set.\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(target_test).type(torch.LongTensor) # data type is long","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:01:16.344483Z","iopub.execute_input":"2021-07-26T02:01:16.344905Z","iopub.status.idle":"2021-07-26T02:01:16.363601Z","shell.execute_reply.started":"2021-07-26T02:01:16.344865Z","shell.execute_reply":"2021-07-26T02:01:16.362702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set batch size\nbatch_size = 256\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:06:23.12561Z","iopub.execute_input":"2021-07-26T02:06:23.125934Z","iopub.status.idle":"2021-07-26T02:06:23.135302Z","shell.execute_reply.started":"2021-07-26T02:06:23.125904Z","shell.execute_reply":"2021-07-26T02:06:23.134329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 20\nVALID_SIZE = 0.15 # percentage of data for validation\n\ntransform_train = transforms.Compose([\n    transforms.ToPILImage(),\n   # transforms.RandomRotation(0, 0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5,), std=(0.5,))\n])\n\ntransform_valid = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5,), std=(0.5,))\n])\n\n# Importing data that will be used for training and validation\ndataset = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n\n# Creating datasets for training and validation\n#train_data = MNISTData(train, transform=transform_train)\n#test_data = MNISTData(test, transform=transform_valid)\n\n\n\n\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE)#, sampler=train_sampler)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE)#, sampler=valid_sampler)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:14:36.813438Z","iopub.execute_input":"2021-07-26T02:14:36.81376Z","iopub.status.idle":"2021-07-26T02:14:38.923705Z","shell.execute_reply.started":"2021-07-26T02:14:36.813725Z","shell.execute_reply":"2021-07-26T02:14:38.9228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing data examples used for training\nfig, axis = plt.subplots(2, 10, figsize=(15, 10))\nimages, labels = next(iter(train_loader))\n\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        image, label = images[i], labels[i]\n\n        ax.imshow(image.view(28, 28), cmap='binary') # add image\n        ax.set(title = f\"{label}\") # add label","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:14:38.9255Z","iopub.execute_input":"2021-07-26T02:14:38.925877Z","iopub.status.idle":"2021-07-26T02:14:40.750624Z","shell.execute_reply.started":"2021-07-26T02:14:38.925839Z","shell.execute_reply":"2021-07-26T02:14:40.749797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:14:51.939895Z","iopub.execute_input":"2021-07-26T02:14:51.940295Z","iopub.status.idle":"2021-07-26T02:14:51.946073Z","shell.execute_reply.started":"2021-07-26T02:14:51.940257Z","shell.execute_reply":"2021-07-26T02:14:51.945146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(test_loader))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:14:52.421889Z","iopub.execute_input":"2021-07-26T02:14:52.422199Z","iopub.status.idle":"2021-07-26T02:14:52.427194Z","shell.execute_reply.started":"2021-07-26T02:14:52.422169Z","shell.execute_reply":"2021-07-26T02:14:52.425895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:14:55.593028Z","iopub.execute_input":"2021-07-26T02:14:55.593452Z","iopub.status.idle":"2021-07-26T02:14:55.59998Z","shell.execute_reply.started":"2021-07-26T02:14:55.593414Z","shell.execute_reply":"2021-07-26T02:14:55.598704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout(0.25)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout(0.25)\n        )\n        \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout(0.25)\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(128, 10),\n        )\n                \n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        \n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n\nmodel = Net()\nmodel = model.cuda()\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:15:01.61987Z","iopub.execute_input":"2021-07-26T02:15:01.620393Z","iopub.status.idle":"2021-07-26T02:15:01.660527Z","shell.execute_reply.started":"2021-07-26T02:15:01.620346Z","shell.execute_reply":"2021-07-26T02:15:01.659326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 0.001680\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\noptimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:15:02.229887Z","iopub.execute_input":"2021-07-26T02:15:02.230243Z","iopub.status.idle":"2021-07-26T02:15:02.236477Z","shell.execute_reply.started":"2021-07-26T02:15:02.230199Z","shell.execute_reply":"2021-07-26T02:15:02.235549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 150\nvalid_loss_min = np.Inf\ntrain_losses, valid_losses = [], []\nhistory_accuracy = []\n\nfor e in range(1, 50):\n    running_loss = 0\n\n    for images, labels in train_loader:\n        if train_on_gpu:\n            images, labels = images.cuda(), labels.cuda()\n        # Clear the gradients, do this because gradients are accumulated.\n        optimizer.zero_grad()\n        \n        # Forward pass, get our log-probabilities.\n        ps = model(images).cuda()\n\n\n        # Calculate the loss with the logps and the labels.\n        loss = criterion(ps, labels)\n        \n        # Turning loss back.\n        loss.backward()\n        \n        # Take an update step and few the new weights.\n        optimizer.step()\n        \n        running_loss += loss.item()\n    else:\n        valid_loss = 0\n        accuracy = 0\n        \n        # Turn off gradients for validation, saves memory and computations.\n        with torch.no_grad():\n            model.eval() # change the network to evaluation mode\n            for images, labels in test_loader:\n                if train_on_gpu:\n                    images, labels = images.cuda(), labels.cuda()\n                # Forward pass, get our log-probabilities.\n                #log_ps = model(images)\n                ps = model(images).cuda()\n                \n                # Calculating probabilities for each class.\n                #ps = torch.exp(log_ps)\n                \n                # Capturing the class more likely.\n                _, top_class = ps.topk(1, dim=1)\n                \n                # Verifying the prediction with the labels provided.\n                equals = top_class == labels.view(*top_class.shape)\n                \n                valid_loss += criterion(ps, labels)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n                \n        model.train() # change the network to training mode\n        \n        train_losses.append(running_loss/len(train_loader))\n        valid_losses.append(valid_loss/len(test_loader))\n        history_accuracy.append(accuracy/len(test_loader))\n        \n        network_learned = valid_loss < valid_loss_min\n\n        if e == 1 or e % 5 == 0 or network_learned:\n            print(f\"Epoch: {e}/{epochs}.. \",\n                  f\"Training Loss: {running_loss/len(train_loader):.3f}.. \",\n                  f\"Validation Loss: {valid_loss/len(test_loader):.3f}.. \",\n                  f\"Test Accuracy: {accuracy/len(test_loader):.3f}\")\n        \n        if network_learned:\n            valid_loss_min = valid_loss\n            torch.save(model.state_dict(), 'model_mtl_mnist.pt')\n            print('Detected network improvement, saving current model')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T02:15:02.711695Z","iopub.execute_input":"2021-07-26T02:15:02.711974Z","iopub.status.idle":"2021-07-26T02:15:02.784954Z","shell.execute_reply.started":"2021-07-26T02:15:02.711947Z","shell.execute_reply":"2021-07-26T02:15:02.782482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing training information\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nplt.plot(train_losses, label='Training Loss')\nplt.plot(valid_losses, label='Validation Loss')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:59.062351Z","iopub.status.idle":"2021-07-26T01:47:59.063177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_accuracy, label='Validation Accuracy')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:59.064802Z","iopub.status.idle":"2021-07-26T01:47:59.065627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def view_classify(img, ps):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(np.arange(10))\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:59.06739Z","iopub.status.idle":"2021-07-26T01:47:59.068227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\ndef make_prediction(data):\n    images, labels = next(iter(data))\n\n    img = images[42].view(1, 784)\n    # Turn off gradients to speed up this part\n    with torch.no_grad():\n        logps = model(img)\n\n    # Output of the network are log-probabilities, need to take exponential for probabilities\n    ps = torch.exp(logps)\n    view_classify(img.view(1, 28, 28), ps)\nmake_prediction(test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:47:59.069836Z","iopub.status.idle":"2021-07-26T01:47:59.07067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}