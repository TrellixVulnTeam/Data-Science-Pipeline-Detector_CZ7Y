{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Digits Generation with VAE\n## Import Packages","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nimport time\nimport pandas as pd\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:09.066964Z","iopub.execute_input":"2021-09-21T16:39:09.067662Z","iopub.status.idle":"2021-09-21T16:39:09.072675Z","shell.execute_reply.started":"2021-09-21T16:39:09.067628Z","shell.execute_reply":"2021-09-21T16:39:09.071577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def sample_images(images, row_count, column_count):\n    fig, axs = plt.subplots(row_count, column_count, figsize=(10,10))\n    for i in range(row_count):\n        for j in range(column_count):\n            axs[i,j].imshow(images[i * column_count + j])\n            axs[i,j].axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:15.227038Z","iopub.execute_input":"2021-09-21T16:39:15.227709Z","iopub.status.idle":"2021-09-21T16:39:15.234916Z","shell.execute_reply.started":"2021-09-21T16:39:15.227676Z","shell.execute_reply":"2021-09-21T16:39:15.233037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Datasets","metadata":{"execution":{"iopub.status.busy":"2021-09-18T18:17:40.182273Z","iopub.execute_input":"2021-09-18T18:17:40.182565Z","iopub.status.idle":"2021-09-18T18:17:40.189856Z","shell.execute_reply.started":"2021-09-18T18:17:40.182538Z","shell.execute_reply":"2021-09-18T18:17:40.18795Z"}}},{"cell_type":"code","source":"item_size = 10\nbatch_size = item_size ** 2\nn_epochs = 10\nimage_width = 32\nlatent_dimension = 2\ninput_shape = [image_width, image_width, 1]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:17.748497Z","iopub.execute_input":"2021-09-21T16:39:17.74903Z","iopub.status.idle":"2021-09-21T16:39:17.755646Z","shell.execute_reply.started":"2021-09-21T16:39:17.748993Z","shell.execute_reply":"2021-09-21T16:39:17.754892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(item):\n    image = item[\"image\"]\n    image = tf.cast(image, \"float\")  / 255.0\n    image =tf.image.resize(image, (image_width, image_width))\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:20.024046Z","iopub.execute_input":"2021-09-21T16:39:20.026674Z","iopub.status.idle":"2021-09-21T16:39:20.033539Z","shell.execute_reply.started":"2021-09-21T16:39:20.026634Z","shell.execute_reply":"2021-09-21T16:39:20.032853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = tfds.load(\"mnist\", split='train', as_supervised=False).map(preprocess_image).shuffle(1024).batch(batch_size, drop_remainder=True).prefetch(1).repeat(n_epochs)\ntest = tfds.load(\"mnist\", split='test', as_supervised=False).map(preprocess_image).batch(batch_size, drop_remainder=True).prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:22.025441Z","iopub.execute_input":"2021-09-21T16:39:22.0257Z","iopub.status.idle":"2021-09-21T16:39:22.110701Z","shell.execute_reply.started":"2021-09-21T16:39:22.025673Z","shell.execute_reply":"2021-09-21T16:39:22.110019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's what the images looks like.","metadata":{}},{"cell_type":"code","source":"for images in train.take(1):\n    sample_images(images, item_size, item_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:27.357645Z","iopub.execute_input":"2021-09-21T16:39:27.357894Z","iopub.status.idle":"2021-09-21T16:39:37.109285Z","shell.execute_reply.started":"2021-09-21T16:39:27.357867Z","shell.execute_reply":"2021-09-21T16:39:37.108565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:42.440008Z","iopub.execute_input":"2021-09-21T16:39:42.440651Z","iopub.status.idle":"2021-09-21T16:39:42.447183Z","shell.execute_reply.started":"2021-09-21T16:39:42.440615Z","shell.execute_reply":"2021-09-21T16:39:42.446194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sampling Class","metadata":{}},{"cell_type":"code","source":"class Sampling(tf.keras.layers.Layer):\n  def call(self, inputs):\n    mu, sigma = inputs\n    batch = tf.shape(mu)[0]\n    dim = tf.shape(mu)[1]\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n    return mu + tf.exp(0.5 * sigma) * epsilon","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:44.504009Z","iopub.execute_input":"2021-09-21T16:39:44.50474Z","iopub.status.idle":"2021-09-21T16:39:44.510903Z","shell.execute_reply.started":"2021-09-21T16:39:44.504693Z","shell.execute_reply":"2021-09-21T16:39:44.509913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build the Encoder","metadata":{}},{"cell_type":"code","source":"def get_encoder(latent_dimension, input_shape):\n    inputs = tf.keras.layers.Input(shape=input_shape)\n    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\", activation='relu', name=\"encode_conv1\")(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name=\"encode_conv2\")(x)\n    batch_norm = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Flatten(name=\"encode_flatten\")(batch_norm)\n    x = tf.keras.layers.Dense(20, activation='relu', name=\"encode_dense\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    mu = tf.keras.layers.Dense(latent_dimension, name='mu')(x)\n    sigma = tf.keras.layers.Dense(latent_dimension, name ='sigma')(x)\n    z = Sampling()((mu, sigma))\n    encoder = tf.keras.Model(inputs, outputs=(mu, sigma, z))\n    return encoder, batch_norm.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:47.24667Z","iopub.execute_input":"2021-09-21T16:39:47.246926Z","iopub.status.idle":"2021-09-21T16:39:47.257586Z","shell.execute_reply.started":"2021-09-21T16:39:47.246898Z","shell.execute_reply":"2021-09-21T16:39:47.255086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder, conv_shape = get_encoder(latent_dimension, input_shape)\ntf.keras.utils.plot_model(encoder, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:50.675021Z","iopub.execute_input":"2021-09-21T16:39:50.675572Z","iopub.status.idle":"2021-09-21T16:39:50.941799Z","shell.execute_reply.started":"2021-09-21T16:39:50.675536Z","shell.execute_reply":"2021-09-21T16:39:50.940999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build the Decoder","metadata":{}},{"cell_type":"code","source":"def get_decoder(latent_dimension, conv_shape):\n    inputs = tf.keras.layers.Input(shape=(latent_dimension,))\n    decoder_input_units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n    x = tf.keras.layers.Dense(decoder_input_units, activation = 'relu', name=\"decode_dense1\")(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name=\"decode_reshape\")(x)\n    x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name=\"decode_conv2d_2\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name=\"decode_conv2d_3\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    outputs = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='sigmoid', name=\"decode_final\")(x)\n    decoder = tf.keras.Model(inputs, outputs)\n    return decoder","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:55.189698Z","iopub.execute_input":"2021-09-21T16:39:55.189972Z","iopub.status.idle":"2021-09-21T16:39:55.200432Z","shell.execute_reply.started":"2021-09-21T16:39:55.189938Z","shell.execute_reply":"2021-09-21T16:39:55.19922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder = get_decoder(latent_dimension, conv_shape)\ntf.keras.utils.plot_model(decoder, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:39:57.187285Z","iopub.execute_input":"2021-09-21T16:39:57.187834Z","iopub.status.idle":"2021-09-21T16:39:57.464786Z","shell.execute_reply.started":"2021-09-21T16:39:57.187798Z","shell.execute_reply":"2021-09-21T16:39:57.463996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KL Divergence","metadata":{}},{"cell_type":"code","source":"def kl_divergence(encoder, decoder, mu, sigma):\n  kl_loss = -0.5 * (1 + sigma - tf.square(mu) - tf.exp(sigma))\n  return tf.reduce_mean(kl_loss)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:40:01.687544Z","iopub.execute_input":"2021-09-21T16:40:01.68782Z","iopub.status.idle":"2021-09-21T16:40:01.69543Z","shell.execute_reply.started":"2021-09-21T16:40:01.687787Z","shell.execute_reply":"2021-09-21T16:40:01.694441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build the VAE Model","metadata":{}},{"cell_type":"code","source":"def get_vae(encoder, decoder, input_shape):\n    inputs = tf.keras.layers.Input(shape=input_shape)\n    mu, sigma, z = encoder(inputs)\n    reconstructed = decoder(z)\n    model = tf.keras.Model(inputs=inputs, outputs=reconstructed)\n    loss = kl_divergence(inputs, z, mu, sigma)\n    model.add_loss(loss)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:40:03.751936Z","iopub.execute_input":"2021-09-21T16:40:03.752436Z","iopub.status.idle":"2021-09-21T16:40:03.75839Z","shell.execute_reply.started":"2021-09-21T16:40:03.752402Z","shell.execute_reply":"2021-09-21T16:40:03.75743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae = get_vae(encoder, decoder, input_shape)\nvae.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:40:05.96744Z","iopub.execute_input":"2021-09-21T16:40:05.968186Z","iopub.status.idle":"2021-09-21T16:40:06.102555Z","shell.execute_reply.started":"2021-09-21T16:40:05.968149Z","shell.execute_reply":"2021-09-21T16:40:06.101303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the Model","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\nloss_metric = tf.keras.metrics.Mean()\nbce_loss = tf.keras.losses.BinaryCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:40:10.680209Z","iopub.execute_input":"2021-09-21T16:40:10.680473Z","iopub.status.idle":"2021-09-21T16:40:10.69704Z","shell.execute_reply.started":"2021-09-21T16:40:10.680446Z","shell.execute_reply":"2021-09-21T16:40:10.696372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = 60000 // batch_size\nfor step, images in enumerate(train):\n    with tf.GradientTape() as tape:\n        reconstructed = vae(images)\n        flattened_inputs = tf.reshape(images, shape=(-1))\n        flatten_outputs = tf.reshape(reconstructed, shape=(-1))\n        loss = bce_loss(flattened_inputs, flatten_outputs) * (image_width ** 2)\n        loss += sum(vae.losses)\n    grads = tape.gradient(loss, vae.trainable_weights)\n    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n    loss_metric(loss)\n    if step % steps_per_epoch == 0 and step > 0:\n        display.clear_output(wait=False)    \n        images = decoder.predict(tf.random.normal(shape=[item_size ** 2, latent_dimension]))\n        sample_images(images, item_size, item_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:42:09.455999Z","iopub.execute_input":"2021-09-21T16:42:09.456477Z","iopub.status.idle":"2021-09-21T16:45:06.684293Z","shell.execute_reply.started":"2021-09-21T16:42:09.456445Z","shell.execute_reply":"2021-09-21T16:45:06.683482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Latent Space Visualization","metadata":{}},{"cell_type":"code","source":"def plot_label_clusters(encoder, data, labels):\n    z_mean, _, _ = encoder.predict(data)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n    plt.colorbar()\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.show()\ntest_labels = tfds.load(\"mnist\", split='test', as_supervised=True).map(lambda image, label: label).batch(batch_size, drop_remainder=True).prefetch(1)\ntest_labels = np.array([label for label in test_labels]).reshape(-1)\nplot_label_clusters(encoder, test, test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:46:01.161759Z","iopub.execute_input":"2021-09-21T16:46:01.162013Z","iopub.status.idle":"2021-09-21T16:46:04.338974Z","shell.execute_reply.started":"2021-09-21T16:46:01.161985Z","shell.execute_reply":"2021-09-21T16:46:04.337989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"mse = tf.keras.metrics.MeanSquaredError()\nmae = tf.keras.metrics.MeanAbsoluteError()\ntest_metrics = {\"mse\": [], \"mae\": []}\nfor images in test:\n    gen_images = vae.predict(images)\n    test_metrics[\"mse\"].append(mse(images, gen_images).numpy())\n    test_metrics[\"mae\"].append(mae(images, gen_images).numpy())\nprint(\"MSE: \",np.mean(test_metrics[\"mse\"]))\nprint(\"MAE: \",np.mean(test_metrics[\"mae\"]))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:46:16.529499Z","iopub.execute_input":"2021-09-21T16:46:16.529758Z","iopub.status.idle":"2021-09-21T16:46:19.233099Z","shell.execute_reply.started":"2021-09-21T16:46:16.529732Z","shell.execute_reply":"2021-09-21T16:46:19.231572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the Model","metadata":{}},{"cell_type":"code","source":"encoder.save(\"encoder.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:38:16.163823Z","iopub.execute_input":"2021-09-21T16:38:16.164188Z","iopub.status.idle":"2021-09-21T16:38:16.199601Z","shell.execute_reply.started":"2021-09-21T16:38:16.164152Z","shell.execute_reply":"2021-09-21T16:38:16.198935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder.save(\"decoder.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T16:38:17.995037Z","iopub.execute_input":"2021-09-21T16:38:17.995306Z","iopub.status.idle":"2021-09-21T16:38:18.023282Z","shell.execute_reply.started":"2021-09-21T16:38:17.99528Z","shell.execute_reply":"2021-09-21T16:38:18.022614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.save(\"vae.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-19T12:05:45.449981Z","iopub.execute_input":"2021-09-19T12:05:45.450244Z","iopub.status.idle":"2021-09-19T12:05:45.495655Z","shell.execute_reply.started":"2021-09-19T12:05:45.45021Z","shell.execute_reply":"2021-09-19T12:05:45.494997Z"},"trusted":true},"execution_count":null,"outputs":[]}]}