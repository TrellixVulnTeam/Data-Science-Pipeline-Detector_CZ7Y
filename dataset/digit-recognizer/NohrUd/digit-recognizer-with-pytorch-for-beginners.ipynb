{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<BR>\nWhich do u like, tensorflow.keras or pytorch? \"Today\" I'm somehow in pytorch mode. Let's enjoy Pytorch!<BR>\nBTW, if you are in tensorflow.keras mode, you can find some of them in my notebooks area.","metadata":{}},{"cell_type":"markdown","source":"<BR><BR>\n## Let's experience <font color=\"blue\">\"Image recognition by using Deep Learning Tech\"</font> with <font color=\"green\"> MNIST dataset.</font>\n## What is MNIST?\nThe MNIST is a database of handwritten digits from 0 to 9. By the way, MNIST stands for Modified National Institute of Standards and Technology database.\n## What is Deep Learning?\nDeep learning is one of machine learning algorithms which consists of multiple layers to extract features of datasets.\n## What is Pytorch?\nPytorch is one of machine learning libraries, originally developed by Facebook's AI Research Lab. It's useful especially for deep learning.\n<HR>","metadata":{}},{"cell_type":"markdown","source":"1. Import libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm as tqdm","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:40.533472Z","iopub.execute_input":"2021-10-02T18:01:40.53376Z","iopub.status.idle":"2021-10-02T18:01:45.906104Z","shell.execute_reply.started":"2021-10-02T18:01:40.533732Z","shell.execute_reply":"2021-10-02T18:01:45.905212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Let's download datasets and check datasets.","metadata":{}},{"cell_type":"code","source":"# print dataset paths by Kaggle's way\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:45.908178Z","iopub.execute_input":"2021-10-02T18:01:45.90861Z","iopub.status.idle":"2021-10-02T18:01:45.919624Z","shell.execute_reply.started":"2021-10-02T18:01:45.908568Z","shell.execute_reply":"2021-10-02T18:01:45.918669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:45.921415Z","iopub.execute_input":"2021-10-02T18:01:45.922105Z","iopub.status.idle":"2021-10-02T18:01:49.930526Z","shell.execute_reply.started":"2021-10-02T18:01:45.922001Z","shell.execute_reply":"2021-10-02T18:01:49.929507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the train_data.","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:49.93316Z","iopub.execute_input":"2021-10-02T18:01:49.933476Z","iopub.status.idle":"2021-10-02T18:01:49.969311Z","shell.execute_reply.started":"2021-10-02T18:01:49.933437Z","shell.execute_reply":"2021-10-02T18:01:49.968236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That means the first column is \"label\", columns from the 2nd to the last is \"28 x 28 = 784 pixcels\".\n<BR>Okay, let's make x_train, y_train, x_test.","metadata":{}},{"cell_type":"code","source":"x_train = train_data.iloc[:,1:].values/255 #train_data(x)\ny_train = train_data.label.values          #train_data(y)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:49.971037Z","iopub.execute_input":"2021-10-02T18:01:49.971364Z","iopub.status.idle":"2021-10-02T18:01:50.1189Z","shell.execute_reply.started":"2021-10-02T18:01:49.971305Z","shell.execute_reply":"2021-10-02T18:01:50.118009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Let's split train_data(x)&(y) into train_x, valid_x, train_y, valid_y by using sklearn's train_test_split.","metadata":{}},{"cell_type":"code","source":"train_x, train_valid_x, train_y, train_valid_y = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:50.12066Z","iopub.execute_input":"2021-10-02T18:01:50.120954Z","iopub.status.idle":"2021-10-02T18:01:50.604996Z","shell.execute_reply.started":"2021-10-02T18:01:50.120915Z","shell.execute_reply":"2021-10-02T18:01:50.60361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4.Change them into Pytorch's Float Tensors.","metadata":{}},{"cell_type":"code","source":"train_x_torch = torch.from_numpy(train_x).type(torch.FloatTensor)\nvalid_x_torch = torch.from_numpy(train_valid_x).type(torch.FloatTensor)\ntrain_y_torch = torch.from_numpy(train_y).type(torch.LongTensor)\nvalid_y_torch = torch.from_numpy(train_valid_y).type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:50.610963Z","iopub.execute_input":"2021-10-02T18:01:50.611739Z","iopub.status.idle":"2021-10-02T18:01:50.755592Z","shell.execute_reply.started":"2021-10-02T18:01:50.611688Z","shell.execute_reply":"2021-10-02T18:01:50.754542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Think about dimentions of data. Without this \"an shapes doesn't fit error\", will occur.","metadata":{}},{"cell_type":"code","source":"train_x_torch = train_x_torch.view(-1, 1,28,28).float()\nvalid_x_torch = valid_x_torch.view(-1, 1,28,28).float()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:50.761175Z","iopub.execute_input":"2021-10-02T18:01:50.761863Z","iopub.status.idle":"2021-10-02T18:01:50.775951Z","shell.execute_reply.started":"2021-10-02T18:01:50.761824Z","shell.execute_reply":"2021-10-02T18:01:50.77472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Let's make Tensor Datasets","metadata":{}},{"cell_type":"code","source":"train_set = torch.utils.data.TensorDataset(train_x_torch, train_y_torch)\nvalid_set = torch.utils.data.TensorDataset(valid_x_torch, valid_y_torch)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:50.782278Z","iopub.execute_input":"2021-10-02T18:01:50.78514Z","iopub.status.idle":"2021-10-02T18:01:50.792891Z","shell.execute_reply.started":"2021-10-02T18:01:50.785101Z","shell.execute_reply":"2021-10-02T18:01:50.791637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Let's make DataLoaders for mini-batching.","metadata":{}},{"cell_type":"code","source":"#preparing Data Loaders\nbatch_size = 128\ntrain_loader = torch.utils.data.DataLoader(train_set, shuffle = True, batch_size = 128)\nvalid_loader = torch.utils.data.DataLoader(valid_set, shuffle = True, batch_size = 128)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:52.920098Z","iopub.execute_input":"2021-10-02T18:01:52.920995Z","iopub.status.idle":"2021-10-02T18:01:52.927455Z","shell.execute_reply.started":"2021-10-02T18:01:52.920954Z","shell.execute_reply":"2021-10-02T18:01:52.926458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Let's show images of Digit Recognizer.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(10):\n    plt.subplot(20, 20, i+1)\n    plt.title(\"No.\" + str(i))\n    plt.imshow(train_data.iloc[:,1:].iloc[i].values.reshape(28,28),cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:31:41.267038Z","iopub.execute_input":"2021-10-02T18:31:41.267414Z","iopub.status.idle":"2021-10-02T18:31:46.085887Z","shell.execute_reply.started":"2021-10-02T18:31:41.267386Z","shell.execute_reply":"2021-10-02T18:31:46.084893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Check if GPU is available or not.","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \ndevice","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:01:57.402785Z","iopub.execute_input":"2021-10-02T18:01:57.403443Z","iopub.status.idle":"2021-10-02T18:01:57.462743Z","shell.execute_reply.started":"2021-10-02T18:01:57.403409Z","shell.execute_reply":"2021-10-02T18:01:57.461394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay \"Type='cuda'\" means GPU is available.","metadata":{}},{"cell_type":"markdown","source":"7.Let's send data to GPU and reset optimaizer and define loss calculation,loss backward .etc","metadata":{}},{"cell_type":"code","source":"list_process=[]","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:16:50.044502Z","iopub.execute_input":"2021-10-02T18:16:50.04484Z","iopub.status.idle":"2021-10-02T18:16:50.050413Z","shell.execute_reply.started":"2021-10-02T18:16:50.044809Z","shell.execute_reply":"2021-10-02T18:16:50.049167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, epoch):\n    model.train()\n    train_loss = 0\n    correct = 0\n    for data, label in train_loader:\n        data, label = data.to(device), label.to(device)  \n        optimizer.zero_grad()  \n        output = model(data) \n        loss = criterion(output, label)  \n        loss.backward() \n        optimizer.step()  \n        train_loss += loss.item() \n        #get argmax values in outputs\n        pred = output.argmax(dim=1, keepdim=True)\n        correct += pred.eq(label.view_as(pred)).sum().item()\n    print('epoch for train: {}, accuracy: ({:.2f}%)'.format(epoch,correct*100 / len(train_loader.dataset)))\n    list_process.append(correct*100 / len(train_loader.dataset))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:16:50.434034Z","iopub.execute_input":"2021-10-02T18:16:50.434835Z","iopub.status.idle":"2021-10-02T18:16:50.444876Z","shell.execute_reply.started":"2021-10-02T18:16:50.434793Z","shell.execute_reply":"2021-10-02T18:16:50.443546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. Let's defing test. One thing different from \"def train\" is \"torch.no_grad()\".","metadata":{}},{"cell_type":"code","source":"def valid(model, epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, label in valid_loader:\n            data, label = data.to(device), label.to(device)\n            output = model(data)\n            test_loss += criterion(output, label).item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(label.view_as(pred)).sum().item()\n    print('epoch for test: {}, accuracy: ({:.2f}%)'.format(epoch,correct*100 / len(valid_loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:16:51.394921Z","iopub.execute_input":"2021-10-02T18:16:51.395246Z","iopub.status.idle":"2021-10-02T18:16:51.403539Z","shell.execute_reply.started":"2021-10-02T18:16:51.395216Z","shell.execute_reply":"2021-10-02T18:16:51.402261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"9. Define layers like Conv2d for CNN, max_pool2d for max pooing .etc","metadata":{}},{"cell_type":"code","source":"class cnn_layers(nn.Module):\n    def __init__(self):\n        super(cnn_layers,self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\nmodel = cnn_layers()\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss() ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:16:52.051313Z","iopub.execute_input":"2021-10-02T18:16:52.052238Z","iopub.status.idle":"2021-10-02T18:16:52.07901Z","shell.execute_reply.started":"2021-10-02T18:16:52.052204Z","shell.execute_reply":"2021-10-02T18:16:52.07805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"10. Let's start 20-epoch deep learning.","metadata":{}},{"cell_type":"code","source":"print(model)\nfor epoch in tqdm(range(30)):\n    train(model,epoch)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:29:05.993886Z","iopub.execute_input":"2021-10-02T18:29:05.994267Z","iopub.status.idle":"2021-10-02T18:29:07.760736Z","shell.execute_reply.started":"2021-10-02T18:29:05.994205Z","shell.execute_reply":"2021-10-02T18:29:07.759702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(list_process)\nplt.xlabel(\"number of epochs\")\nplt.ylabel(\"accuracy(%)\")\nplt.title(\"CNN with Pytorch Model\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:27:10.113877Z","iopub.execute_input":"2021-10-02T18:27:10.114191Z","iopub.status.idle":"2021-10-02T18:27:10.332816Z","shell.execute_reply.started":"2021-10-02T18:27:10.11416Z","shell.execute_reply":"2021-10-02T18:27:10.331921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(3)):\n    valid(model,epoch)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:02:41.84794Z","iopub.execute_input":"2021-10-02T18:02:41.848848Z","iopub.status.idle":"2021-10-02T18:02:42.488845Z","shell.execute_reply.started":"2021-10-02T18:02:41.848808Z","shell.execute_reply":"2021-10-02T18:02:42.487672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11. Let's check if this model's prediction is correct or not.","metadata":{}},{"cell_type":"markdown","source":"11-1. Make a dataloader for testing.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:03:11.774674Z","iopub.execute_input":"2021-10-02T18:03:11.775073Z","iopub.status.idle":"2021-10-02T18:03:14.429785Z","shell.execute_reply.started":"2021-10-02T18:03:11.775016Z","shell.execute_reply":"2021-10-02T18:03:14.428783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = test_data.values/255\nx_test_torch = torch.from_numpy(x_test).type(torch.FloatTensor)\nd_labels = np.zeros(x_test.shape)\nd_labels = torch.from_numpy(d_labels)\n#Think about dimentions of data. Without this \"an shapes doesn't fit error\", will occur.\nx_test_torch = x_test_torch.view(-1, 1, 28, 28)\n#Make a tensordataset and a testloader\ntestset = torch.utils.data.TensorDataset(x_test_torch, d_labels)\ntestloader = torch.utils.data.DataLoader(testset, batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:03:14.431676Z","iopub.execute_input":"2021-10-02T18:03:14.432186Z","iopub.status.idle":"2021-10-02T18:03:14.598676Z","shell.execute_reply.started":"2021-10-02T18:03:14.432154Z","shell.execute_reply":"2021-10-02T18:03:14.597689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11-2. Let's start prediction.","metadata":{}},{"cell_type":"code","source":"submit_list = [['ImageId', 'Label']]\nwith torch.no_grad():\n    model.eval()\n    image_id = 1\n    for images,label in testloader:\n        images,label = images.to(device), label.to(device)\n        outputs = model(images)\n        probs = torch.exp(outputs)\n        top_p, top_class = probs.topk(1, dim = 1)\n        for preds in top_class:\n            submit_list.append([image_id,preds.item()])\n            image_id += 1","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:03:14.600097Z","iopub.execute_input":"2021-10-02T18:03:14.600587Z","iopub.status.idle":"2021-10-02T18:03:47.178882Z","shell.execute_reply.started":"2021-10-02T18:03:14.600544Z","shell.execute_reply":"2021-10-02T18:03:47.177795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11-3. Make a CSV file for submission","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(submit_list)\ndf.columns = df.iloc[0]\ndf = df.drop(0, axis = 0)\ndf.to_csv('submit.csv', index = False)\nprint(\"submit.csv saved\")","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:03:47.181257Z","iopub.execute_input":"2021-10-02T18:03:47.181598Z","iopub.status.idle":"2021-10-02T18:03:47.249261Z","shell.execute_reply.started":"2021-10-02T18:03:47.181557Z","shell.execute_reply":"2021-10-02T18:03:47.248046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(5,10):\n    plt.subplot(20, 20, i+1)\n    plt.imshow(test_data.iloc[i].values.reshape(28,28),cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:03:47.251234Z","iopub.execute_input":"2021-10-02T18:03:47.251579Z","iopub.status.idle":"2021-10-02T18:03:47.856063Z","shell.execute_reply.started":"2021-10-02T18:03:47.251543Z","shell.execute_reply":"2021-10-02T18:03:47.855009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[5:10,[1]].T","metadata":{"execution":{"iopub.status.busy":"2021-10-02T18:03:47.857559Z","iopub.execute_input":"2021-10-02T18:03:47.857858Z","iopub.status.idle":"2021-10-02T18:03:47.874655Z","shell.execute_reply.started":"2021-10-02T18:03:47.857808Z","shell.execute_reply":"2021-10-02T18:03:47.873553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correct answers?!\n### Thanks for reading my notebook :-) ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}