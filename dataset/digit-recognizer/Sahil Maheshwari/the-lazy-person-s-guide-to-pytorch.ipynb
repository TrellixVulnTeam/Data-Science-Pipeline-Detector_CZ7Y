{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n**“Progress isn't made by early risers. It's made by lazy men trying to find easier ways to do something.”**\n― Robert Heinlein.\n\nHi fellow Kagglers, I assume 1.) you are lazy and 2.) you don't know Pytorch.\nThe main aim of this Kernel is to introduce the concept of Pytorch . Now granted there are many great kernels already with regard to the topics. Being one of the most laziest person, I don't study Kaggle notebooks a lot. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Main Problem\nWe have a classification task. We are provided images of numerical digits (in the format of Csv File) and we have to predict the label of the image.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So Pytorch is basically an open ML Library , which can be used for tasks such as computer vision and natural language processing.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import the required libraries \nimport pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim \nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reading the data\ntest=pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\ntrain=pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n# get the image pixel values and labels\ntrain_labels = train.iloc[:, 0]\ntrain_images = train.iloc[:, 1:]\ntest_images = test.iloc[:, 0:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_device():\n    if torch.cuda.is_available():\n        device = 'cuda:0'\n    else:\n        device = 'cpu'\n    return device\ndevice = get_device()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usually when we are provided data , we need to transform the images into a prescribed format fors our ML algorithms to train on them. But here since we aren't given images but rather pixels in csv we will transform the same for our algorithm.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.ToTensor(),\n     transforms.Normalize((0.5, ), (0.5, ))\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below code loads and preprocess the data . It is a custom defined function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, images, labels=None, transforms=None):\n        self.X = images\n        self.y = labels\n        self.transforms = transforms\n         \n    def __len__(self):\n        return (len(self.X))\n    \n    def __getitem__(self, i):\n        data = self.X.iloc[i, :]\n        data = np.asarray(data).astype(np.uint8).reshape(28, 28, 1)\n        \n        if self.transforms:\n            data = self.transforms(data)\n            \n        if self.y is not None:\n            return (data, self.y[i])\n        else:\n            return data\ntrain_data = MNISTDataset(train_images, train_labels, transform)\ntest_data = MNISTDataset(test_images, transform)\n# dataloaders\ntrainloader = DataLoader(train_data, batch_size=128, shuffle=True)\ntestloader = DataLoader(test_data, batch_size=128, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now train the neural network for our task.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, \n                               kernel_size=5, stride=1)\n        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, \n                               kernel_size=5, stride=1)\n        self.fc1 = nn.Linear(in_features=800, out_features=500)\n        self.fc2 = nn.Linear(in_features=500, out_features=10)\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\nnet = Net().to(device)\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The metric which is used to see how the network is working .","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss\ncriterion = nn.CrossEntropyLoss()\n# optimizer\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training the network on the train set and applying it to the train set . ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(net, trainloader):\n    for epoch in range(4): # no. of epochs\n        running_loss = 0\n        for data in trainloader:\n            # data pixels and labels to GPU if available\n            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n            # set the parameter gradients to zero\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            # propagate the loss backward\n            loss.backward()\n            # update the gradients\n            optimizer.step()\n \n            running_loss += loss.item()\n        print('[Epoch %d] loss: %.3f' %\n                      (epoch + 1, running_loss/len(trainloader)))\n \n    print('Done Training')\nx = torch.empty(0, 3)\ndef test(net, testloader):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            inputs = data[0].to(device, non_blocking=True)\n            outputs = net(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            predictions=torch.cat((x,predicted),0)\n#train(net, trainloader)\ntest(net, testloader)        \nsubmission = pd.concat(\n    [pd.Series(range(1,28001),name = \"ImageId\"),predictions],\n    axis = 1\n)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"P.s( I am facing a problem with the function of testloader).I think it seems the data of testloader is not correctly loaded.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}