{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Convolutional neural network (CNN).\n###  The MNIST database of handwritten digits, available from this page, has  a set of 70,000 examples. It is a subset of a larger set available from NIST.  It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Preprocessing and analysis data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# uploading data\ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['label'].astype('int32')\nX_train = (train.drop(['label'], axis = 1)).values.astype('float32')\nX_test = test.values.astype('float32')\n\nbatch_size, img_rows, img_cols = 64, 28, 28\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting countplot for train data\nplt.figure(figsize=(8,6))\nplt.title('Countplot for train data')\nsns.countplot(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# images \nplt.figure(figsize=(10,10))\nfor i in range(20):\n    plt.subplot(4, 5, i+1)\n    plt.imshow(X_train[i].reshape((28, 28)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the data\nX_train /= 255\nX_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding for y_train\ny_train = np_utils.to_categorical(y_train, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split train data\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n                                                      test_size = 0.1, random_state = 12345)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Create and train models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.1 First CNN model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (img_rows, img_cols, 1)\n# using early stopping\ncallback_es = EarlyStopping(monitor = 'val_accuracy', patience = 3)\ndef first_cnn_model_keras(optimizer):\n    model = Sequential()\n    # CNN layers\n    model.add(Convolution2D(64, 5, 5, padding = 'same', kernel_initializer = 'he_uniform', \n                            input_shape = input_shape))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'))\n    model.add(Convolution2D(128, 5, 5, padding = 'same', kernel_initializer = 'he_uniform'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'))\n    # Fully connected layers\n    model.add(Flatten())\n    model.add(Dense(1024))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(10))\n    model.add(Activation('softmax'))\n    # compile model\n    model.compile(optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit first model (Adam optimizer)\nmodel1 = first_cnn_model_keras(Adam(learning_rate = 0.001, amsgrad = True))\nh1 = model1.fit(X_train, y_train, batch_size = batch_size, epochs = 20, verbose = 1,\n          validation_data = (X_valid, y_valid), callbacks = [callback_es])\nfinal_loss_first_adam, final_acc_first_adam = model1.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_first_adam, final_acc_first_adam))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit first model (RMSprop optimizer)\nmodel2 = first_cnn_model_keras(RMSprop(lr=0.001))\nh2 = model2.fit(X_train, y_train, batch_size = batch_size, epochs = 20, verbose = 1,\n          validation_data = (X_valid, y_valid),callbacks = [callback_es])\nfinal_loss_first_rmsprop, final_acc_first_rmsprop = model2.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_first_rmsprop, final_acc_first_rmsprop))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data augmentation\ndatagen = ImageDataGenerator(rotation_range = 10, \n                             zoom_range = 0.1, \n                             width_shift_range = 0.1,\n                             height_shift_range = 0.1)\ndatagen.fit(X_train)\ntrain_batches = datagen.flow(X_train, y_train, batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit first model (Adam optimizer and data augmentation)\nmodel3 = first_cnn_model_keras(Adam(learning_rate = 0.001, amsgrad = True))\nh3 = model3.fit_generator(train_batches, epochs = 40, verbose = 1,\n          validation_data = (X_valid, y_valid), callbacks = [callback_es])\nfinal_loss_first_adam_aug, final_acc_first_adam_aug = model3.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_first_adam_aug, final_acc_first_adam_aug))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit first model (RMSprop optimizer and data augmentation)\nmodel4 = first_cnn_model_keras(RMSprop(lr=0.001))\nh4 = model4.fit_generator(train_batches, epochs = 40, verbose = 1,\n          validation_data = (X_valid, y_valid), callbacks = [callback_es])\nfinal_loss_first_rmsprop_aug, final_acc_first_rmsprop_aug = model4.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_first_rmsprop_aug, final_acc_first_rmsprop_aug))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Second CNN model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# second model\ndef second_cnn_model_keras(optimizer):\n    model = Sequential()\n    # CNN layers\n    model.add(Convolution2D(64, kernel_size = (5, 5), input_shape = input_shape, kernel_initializer = 'he_uniform'))\n    model.add(Activation('relu'))\n    model.add(Convolution2D(64, kernel_size = (5, 5), kernel_initializer = 'he_uniform'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'))\n    model.add(Dropout(0.25))\n    model.add(Convolution2D(128, kernel_size = (3, 3), kernel_initializer = 'he_uniform'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(128, kernel_size = (3, 3), kernel_initializer = 'he_uniform'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'))\n    model.add(Dropout(0.25))\n    # Fully connected layers\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Dense(10))\n    model.add(Activation('softmax'))\n    # compile model\n    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit second model (Adam optimizer)\nmodel5 = second_cnn_model_keras(Adam(learning_rate = 0.001, amsgrad = True))\nh5 = model5.fit(X_train, y_train, batch_size = batch_size, epochs = 20, verbose = 1,\n          validation_data = (X_valid, y_valid), callbacks = [callback_es])\nfinal_loss_second_adam, final_acc_second_adam = model5.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_second_adam, final_acc_second_adam))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit second model (RMSprop optimizer)\nmodel6 = second_cnn_model_keras(RMSprop(lr=0.001))\nh6 = model6.fit(X_train, y_train, batch_size = batch_size, epochs = 20, verbose = 1,\n          validation_data = (X_valid, y_valid), callbacks = [callback_es])\nfinal_loss_second_rmsprop, final_acc_second_rmsprop = model6.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_second_rmsprop, final_acc_second_rmsprop))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit second model (Adam optimizer and data augmentation)\nmodel7 = second_cnn_model_keras(Adam(learning_rate = 0.001, amsgrad = True))\nh7 = model7.fit_generator(train_batches, epochs = 20, verbose = 1,\n          validation_data = (X_valid, y_valid),callbacks = [callback_es])\nfinal_loss_second_adam_aug, final_acc_second_adam_aug = model7.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_second_adam_aug, final_acc_second_adam_aug))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile and fit second model (RMSprop optimizer and data augmentation)\nmodel8 = second_cnn_model_keras(RMSprop(lr=0.001))\nh8 = model8.fit_generator(train_batches, epochs = 20, verbose = 1,\n          validation_data = (X_valid, y_valid), callbacks = [callback_es])\nfinal_loss_second_rmsprop_aug, final_acc_second_rmsprop_aug = model8.evaluate(X_valid, y_valid, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss_second_rmsprop_aug, final_acc_second_rmsprop_aug))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Evaluate table of single models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = ['first_cnn_adam', 'first_cnn_rmsprop', 'first_cnn_adam_aug', 'first_cnn_rmsprop_aug', \n          'second_cnn_adam', 'second_cnn_rmsprop', 'second_cnn_adam_aug', 'second_cnn_rmsprop_aug']\ndict_values = {'loss': [final_loss_first_adam, final_loss_first_rmsprop, final_loss_first_adam_aug, \n                   final_loss_first_rmsprop_aug, final_loss_second_adam, final_loss_second_rmsprop,\n                   final_loss_second_adam_aug, final_loss_second_rmsprop_aug],\n           'accuracy': [final_acc_first_adam, final_acc_first_rmsprop, final_acc_first_adam_aug, \n                   final_acc_first_rmsprop_aug, final_acc_second_adam, final_acc_second_rmsprop,\n                   final_acc_second_adam_aug, final_acc_second_rmsprop_aug]}\n\ndf = pd.DataFrame(dict_values, index = models, columns = ['loss', 'accuracy'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The optimal single model is second CNN model with Adam optimizer (without augmentation).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Visualization of learning process for single model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = h5.history['accuracy']\nval_accuracy = h5.history['val_accuracy']\nloss = h5.history['loss']\nval_loss = h5.history['val_loss']\nepochs = range(len(accuracy))\n\nf, ax = plt.subplots(1, 2, figsize=(18, 8))\nax[0].plot(epochs, accuracy, 'r--', label='Training accuracy')\nax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nax[0].set_title('Train and validation accuracy')\nax[0].set_xlabel('epoch')\nax[0].set_ylabel('accuracy')\nax[0].grid()\nax[1].plot(epochs, loss, 'r--', label='Training loss')\nax[1].plot(epochs, val_loss, 'b', label='Validation loss')\nax[1].set_title('Train and validation loss')\nax[1].set_xlabel('epoch')\nax[1].set_ylabel('loss')\nax[1].grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.5 Confusion matrix for single model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the values from validation data\ny_predict = model5.predict(X_valid)\n# convert predict and validation data to one-hot vectors\ny_predict_class = np.argmax(y_predict, axis = 1)\ny_true = np.argmax(y_valid, axis = 1)\n\nplt.subplots(figsize = (12, 10))\nsns.heatmap(confusion_matrix(y_true, y_predict_class), annot=True, \n            linewidths = 0.5, fmt = '.0f', cmap = 'Reds', linecolor = 'black')\nplt.xlabel('Predicted Label')\nplt.ylabel(\"True Label\")\nplt.title('Confusion Matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.6 Ensemble models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create ensemble models\nmodel = [0]*10\nfor i in range(10):  \n    model[i] = Sequential()\n    # CNN layers\n    model[i].add(Convolution2D(64, kernel_size = (3, 3), input_shape = input_shape, kernel_initializer = 'he_uniform'))\n    model[i].add(Activation('relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Convolution2D(64, kernel_size = (3, 3), kernel_initializer = 'he_uniform'))\n    model[i].add(Activation('relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Convolution2D(64, kernel_size = (5, 5), kernel_initializer = 'he_uniform'))\n    model[i].add(Activation('relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n    model[i].add(Dropout(0.45))\n    model[i].add(Convolution2D(128, kernel_size = (3, 3), kernel_initializer = 'he_uniform'))\n    model[i].add(Activation('relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Convolution2D(128, kernel_size = (3, 3), kernel_initializer = 'he_uniform'))\n    model[i].add(Activation('relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Convolution2D(128, kernel_size = (5, 5), kernel_initializer = 'he_uniform'))\n    model[i].add(Activation('relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n    model[i].add(Dropout(0.45))\n    # Fully connected layers\n    model[i].add(Flatten())\n    model[i].add(Dense(512))\n    model[i].add(Activation('relu'))\n    model[i].add(Dropout(0.45))\n    model[i].add(Dense(1024))\n    model[i].add(Activation('relu'))\n    model[i].add(Dropout(0.45))\n    model[i].add(Dense(10))\n    model[i].add(Activation('softmax'))\n    # compile model\n    model[i].compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.0005, amsgrad = True), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# edit early stopping and learning models\ncallback_lrs = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\nepochs = 40\nhistory = [0]*10\nfor j in range(10):\n    X_train1, X_valid1, y_train1, y_valid1 = train_test_split(X_train, y_train, test_size = 0.1)\n    history[j] = model[j].fit_generator(datagen.flow(X_train1, y_train1, batch_size = batch_size), epochs = epochs, verbose = 0,\n          validation_data = (X_valid1, y_valid1), callbacks = [callback_lrs])\n    print('CNN:', j+1, 'Epochs =', epochs, 'Train accuracy:', max(history[j].history['accuracy']), 'Validation accuracy:', max(history[j].history['val_accuracy']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.7 Confusion Matrix for ensemble models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the values from validation data\nresults_valid = np.zeros((X_valid.shape[0],10)) \n# convert predict and validation data to one-hot vectors\nfor j in range(10):\n    results_valid = results_valid + model[j].predict(X_valid)\ny_valid_class = np.argmax(results_valid, axis = 1)\ny_true = np.argmax(y_valid, axis = 1)\n\nplt.subplots(figsize = (12, 10))\nsns.heatmap(confusion_matrix(y_true, y_valid_class), annot=True, \n            linewidths = 0.5, fmt = '.0f', cmap = 'Reds', linecolor = 'black')\nplt.xlabel('Predicted Label')\nplt.ylabel(\"True Label\")\nplt.title('Confusion Matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.8 Submit task","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create zero matrix\nresults = np.zeros((X_test.shape[0],10)) \n# predict the values for test dataset\nfor j in range(10):\n    results = results + model[j].predict(X_test)\n# convert predict to one-hot vectors\ny_test_class = np.argmax(results, axis = 1)\n# create and save predict dataframe\nsubmission = pd.DataFrame({'ImageId': list(range(1, len(y_test_class)+1)), 'Label': np.array(y_test_class)})\nsubmission.to_csv('submission.csv', index=False)\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}