{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import plot_model\nfrom keras.callbacks import EarlyStopping\n\npd.set_option('display.max_rows', 1000)\nwarnings.filterwarnings(\"ignore\")\n\ndftrain = pd.read_csv('../input/digit-recognizer/train.csv')\ndftest = pd.read_csv('../input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spliting train and test, reshaping and normalizing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 28\n\nx_train = dftrain.iloc[:,1:]\nx_train = x_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_train = dftrain.iloc[:,0]\nx_test = dftest\nx_test = x_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\nx_train = x_train/255.0\nx_test = x_test/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\ndatagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1)\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sequential Model with CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystopping = EarlyStopping(monitor =\"val_accuracy\",\n                              mode = 'auto', patience = 30,\n                              restore_best_weights = True)\n\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(128, (3, 3), input_shape = x_train.shape[1:]))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n# model.add(Dropout(0.2))\n\nmodel.add(Conv2D(512, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n# model.add(Dropout(0.2))\n\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Designed Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam',\n  loss = 'sparse_categorical_crossentropy',\n  metrics = ['accuracy'])\n\nEPOCHS = 1000\nBATCH_SIZE=64\n\nhistory = model.fit(datagen.flow(X_train, y_train), epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), callbacks=[earlystopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Max. Validation Accuracy: {}%\".format(round(100*max(history.history['val_accuracy']), 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Model Loss and Accuracy"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1,len(loss_val)+1)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nacc_train = history.history['accuracy']\nacc_val = history.history['val_accuracy']\nepochs = range(1,len(acc_val)+1)\nplt.plot(epochs, acc_train, 'g', label='Training accuracy')\nplt.plot(epochs, acc_val, 'b', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict([x_test])\nsolutions = []\nfor i in range(len(predictions)):\n    solutions.append(np.argmax(predictions[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Output"},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.DataFrame()\nfinal['ImageId']=[i+1 for i in dftest.index]\nfinal['Label']=solutions\nfinal.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}