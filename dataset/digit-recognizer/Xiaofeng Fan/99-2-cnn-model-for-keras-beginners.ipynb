{"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"c4138f50401ee22d45743e0ef9b29a3376aee2a0","_cell_guid":"62dfbd18-2f0f-4950-9f23-54cc32b58851"},"source":"This notebook is actually my first hands-on practice with Keras. I have studied from multiple resources (e.g. documentations, blogs) and put things together here to train a CNN model with clear visulisations.\n\n I think this notebook is quite a good starting point for people who are new to Keras and like to study from examples, like me :)\n\nYou should be above 96% after 2 epochs!\n\nCheers.\n\n--- updates ---\n\n* Changed to use TensorFlow as backend. \n* Moved import statements to where they are first called so easy for you to refer to.\n\nPossible improvements to try:\n* BatchNormalization\n* Regularization\n* Image augmentation\n* ..."},{"cell_type":"code","metadata":{"_uuid":"f4ff9782f2cbf0930b41b0f142ae2298f1992fa2","_cell_guid":"de1c8972-8fab-4e08-91c4-d02c028c2ecc"},"source":"# importing essentials\nimport numpy as np\nimport pandas as pd\n\n# to make sure we use tensorflow as our backend, so the image format will be depth/channel last\nfrom keras import backend as K\nK.set_image_dim_ordering('tf')\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"b5925d622db524e6c64345248ff09289b4e1e40d","_cell_guid":"40e74ea9-227f-4bce-96ae-7625474a40ee"},"source":"# load training data\ntrain_data = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"be0a1351aed6edb33eefa9d11c2132e196639287","_cell_guid":"ff2979a6-9314-4bce-87c8-ed999d0107d9"},"source":"# check the data shape\ntrain_data.shape","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"d06e6358e827d58052af765aa4496581492fd94e","_cell_guid":"8bd24cec-7382-4184-8e8c-7497ce6e8b05"},"source":"# separate the training data into images and labels\nimages = train_data.iloc[:, 1:]\nlabels = train_data.iloc[:, 0]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"dc806439c04d846aa66469aa116175c68d18d8d1","_cell_guid":"09e1a8a0-a9fe-4f72-b1fe-b9b668f45ad1"},"source":"# reshape the images so we can use CNNs\n# we are following tensorflow image format\nlabels = labels.as_matrix()\nimages = images.as_matrix().reshape(images.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"8bd4c02d6a96b3a78954a4c8654b7c7e996477ab","_cell_guid":"d981fdaf-7d4d-4d8d-aaad-3cbb1bec062d"},"source":"# features normalisation\ndef normalize_grayscale(image_data):\n    # Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n    # you may also want to try to scale to [-1, 1] or just use keras Batchnormalisation layer\n    return (25.5 + 0.8 * image_data) / 255\ntrain_features = normalize_grayscale(images)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"93455e7ff4e876a20f2e987271c9f82ef3841c02","_cell_guid":"2a3223d4-4f5a-41ce-925f-34f272076c9b"},"source":"# one-hot encoding for labels\nfrom keras.utils import np_utils\ntrain_labels = np_utils.to_categorical(labels)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"d3f9310bf52a15bc5a4035f80555493318c59797","_cell_guid":"ede0e6ba-19fb-4081-bf36-99a7dc766f47"},"source":"# divide data into training and validation set\nfrom sklearn.model_selection import train_test_split\ntrain_features, val_features, train_labels, val_labels = train_test_split(train_features, train_labels, \n                                                                           test_size=0.15, random_state=np.random.randint(300))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"699db839fe1b7dea1ad2d1b4eb242f56bfe4a99c","_cell_guid":"2c99e5b5-525a-475c-83e5-902cd6432633"},"source":"# check if anything wrong\nprint('train_features shape: ', train_features.shape)\nprint('val_features shape: ', val_features.shape)\nprint('train_labels shape: ', train_labels.shape)\nprint('val_labels shape: ', val_labels.shape)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"494f63519136bdbd9d200efa834fdbae1c3525fb","_cell_guid":"eb9dbefe-93f4-41b3-aaba-67f76da52c06"},"source":"# hyperparameters\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout\nfrom keras.models import Model, load_model\n\n\n# build model\n\n\n# model = Sequential()\n# model.add(Conv2D(64, (5, 5), input_shape=(1, 28, 28), activation='relu',\n#           bias_initializer='RandomNormal'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(128, (5, 5), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Flatten())\n# model.add(Dense(256, activation='relu'))\n# model.add(Dropout(0.2))\n# model.add(Dense(32, activation='relu'))\n# model.add(Dropout(0.2))\n# model.add(Dense(n_classes, activation='softmax'))\n\n'''let's follow the fashion of creating model using keras'''\ndef get_model(input_shape):\n    \n    drop = 0.3\n    \n    X_input = Input(input_shape)\n    \n    X = Conv2D(64, (5,5), strides=(1,1), activation='relu', \n               kernel_initializer='glorot_normal')(X_input)\n    X = MaxPooling2D((2,2))(X)\n    \n    X = Conv2D(128, (5,5), strides=(1,1), activation='relu',\n              kernel_initializer='glorot_normal')(X)\n    \n    X = MaxPooling2D((2,2))(X)\n    \n    X = Flatten()(X)\n    \n    X = Dense(256, activation='relu')(X)\n    X = Dropout(drop)(X)\n    \n    X = Dense(32, activation='relu')(X)\n    X = Dropout(drop)(X)\n    \n    X = Dense(10, activation='softmax')(X)\n    \n    model = Model(inputs=[X_input], outputs=[X])\n    \n    return model\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"29c9941cf708119de62db60ffe56c43cb5b3ab8b","_cell_guid":"690a8883-0df4-4f02-ad6e-3673bc04b89d"},"source":"# optimizer, the learning rate will decay with time by default settings\n# Adam is a comman practice\nfrom keras.optimizers import Nadam\nopt = Nadam(lr=0.001)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"3c32bfadaa10e1886ab95aa99a2ad90683ae322b","_cell_guid":"a2237ce6-127e-498f-be43-ba0113884265"},"source":"model = get_model((28, 28, 1))\n# compile the model\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"76185293502c53d6b784e7be7d8e7b0f8e5f5d4c","_cell_guid":"a2f315c8-1e5c-4f88-8bdb-e31f22aad770"},"source":"# model summary\nmodel.summary()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"937abe8035c684144a939f6374bdb11aa57b2383","_cell_guid":"f0071f2c-bf87-499c-989b-b40f2e86e378"},"source":"from keras.callbacks import ModelCheckpoint\n# only save the best model\nf_path = 'model.h5'\nmsave = ModelCheckpoint(f_path, save_best_only=True)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"3a7f1537a2936bbe1b2d4305cd9d89063acc4035","scrolled":false,"_cell_guid":"950e70e0-7131-49df-82d0-8326878161e2"},"source":"# training\nepochs = 5\nbatch_size = 64\ntraining = model.fit(train_features, train_labels,\n                     validation_data=(val_features, val_labels),\n                     epochs=epochs,\n                     callbacks=[msave],\n                     batch_size=batch_size, \n                     verbose=1)\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"0d703a76fcf7d99eef101a455647002b9532c86d","_cell_guid":"fb351f35-7e23-40a5-825c-1b447405cec5"},"source":"# show the loss and accuracy\nloss = training.history['loss']\nval_loss = training.history['val_loss']\nacc = training.history['acc']\nval_acc = training.history['val_acc']\n\n# loss plot\ntra = plt.plot(loss)\nval = plt.plot(val_loss, 'r')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss')\nplt.legend([\"Training\", \"Validation\"])\n\nplt.show()\n\n# accuracy plot\nplt.plot(acc)\nplt.plot(val_acc, 'r')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Accuracy')\nplt.legend(['Training', 'Validation'], loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"a66fa63610addd75c441537651ad43c5d30f8e75","_cell_guid":"93e3fd3d-3dda-4c7d-8518-b255b2a9021d"},"source":"# load the best model\nmodel = load_model(f_path)\n\n# load test_data\ntest_data = pd.read_csv('../input/test.csv')\n\n# reshape the test_data\ntest_images = test_data.as_matrix().reshape(test_data.shape[0], 28, 28, 1)\n\n# normalisation\ntest_features = normalize_grayscale(test_images)\n\n# prediction\npred = model.predict(test_features, batch_size=batch_size, \n                       verbose=1)\n\n# convert predicions from categorical back to 0...9 digits\npred_digits = np.argmax(pred, axis=1)\n\nsubmission = pd.DataFrame({'Label': pred_digits})\nsubmission.index += 1\nsubmission.index.name = \"ImageId\"\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"4ca11d5b325bbf70d87a44b617bacba1a49f11af","_cell_guid":"72a3aaca-5d8b-40f3-935e-83f72ca6053e"},"source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.3","name":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4}