{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"cell_type":"markdown","source":"# Reminder\n\nEnable the GPU in settings.\n\n# Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport time\nimport tensorflow as tf\n\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Reshape, Conv2DTranspose, LeakyReLU\nfrom keras.utils.np_utils import to_categorical   \n\n# Main TFGAN library.\ntfgan = tf.contrib.gan\n\ntf.reset_default_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd9a55267233b02072493f79ca3f552a184ab4ec","_cell_guid":"ab48c623-591b-42c6-813a-1084c427dea7"},"cell_type":"markdown","source":"# Utility Functions"},{"metadata":{"collapsed":true,"_uuid":"69bd65d4ef48a423a90671e9cf876482b522a442","_cell_guid":"6518d2c5-b219-448a-a9ae-18984cd518e6","trusted":false},"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/python-utility-code-for-deep-learning-exercises/utils/gans/')\nfrom generators import conditional_generator\nfrom discriminators import conditional_discriminator\nfrom gan_utils import visualize_training_generator, dataset_to_stream","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea4db6fb601a4066bc2998a08859c4b6be475493","_cell_guid":"38324cf2-8c6e-4b89-9174-8631adc7dec8"},"cell_type":"markdown","source":"# Data Pipeline"},{"metadata":{"collapsed":true,"_uuid":"a5518efb797c2217d9ee9a3bf82531754f92add5","_cell_guid":"d827980f-2cc2-41f5-8862-2273b0bbe355","trusted":false},"cell_type":"code","source":"train_fname = '../input/digit-recognizer/train.csv'\n# Size of each digit\nimg_rows, img_cols = 28, 28\n# Target has 10 values corresponding to 10 numbers (0, 1, 2 ... 9)\nnum_classes = 10\n# Choice of batch size is not critical\nbatch_size = 40\n\nraw = pd.read_csv(train_fname)\nnum_images = raw.shape[0]\nx_as_array = raw.values[:,1:]\n# Reshape from 1 vector into an image. Last dimension shows it is greyscale, which is 1 channel\nx_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n# Optimization with default params is better when vals scaled to [-1, 1]\nimage_array = ((x_shaped_array - 128)/ 128).astype(np.float32)\n# set up target\nlabels_array = to_categorical(raw.values[:,0], num_classes=10)\n\n# following 2 lines create the iterator/stream of tensors consumed in model training\n# Similar to last example, but this one includes labels\nmy_dataset = tf.data.Dataset.from_tensor_slices((image_array, labels_array))\nreal_images, one_hot_labels = dataset_to_stream(my_dataset, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfe6923de12fad2344aa9b24a65eb926937ff636","_cell_guid":"10d430dc-953a-4001-aaaa-4d4b3cc8ccf2"},"cell_type":"markdown","source":"# Conditional GAN Example\n\nIn the conditional GAN setting on MNIST, we wish to train a generator to produce realistic-looking digits of a particular type. For example, we want to be able to produce as many '3's as we want without producing other digits. In contrast, in the unconditional case, we have no control over what digit the generator produces. \n\nIn order to train a conditional generator, we pass the digit's identity to the generator and discriminator in addition to the noise vector. See Conditional Generative Adversarial Nets by Mirza and Osindero for more details.\n\n** This is the same code you've previously seen, except we use conditional_generator and conditional_discriminator functions, and we add the labels as an argument to the generator_inputs **"},{"metadata":{"collapsed":true,"_uuid":"34d1e55d3a733cf70ed00161b564f91e5956ca6a","_cell_guid":"ad3ed841-2f01-4cf7-b79f-85f5af37c5ef","trusted":false},"cell_type":"code","source":"noise_dims = 64\nconditional_gan_model = tfgan.gan_model(\n    generator_fn=conditional_generator,\n    discriminator_fn=conditional_discriminator,\n    real_data=real_images,\n    generator_inputs=(tf.random_normal([batch_size, noise_dims]), \n                      one_hot_labels))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1cd553fad12b466c4ac2b491c554a32539cf085","_cell_guid":"73a16223-4ccd-41a3-af1c-c7a22136215f"},"cell_type":"markdown","source":"# Losses and Optimizers"},{"metadata":{"collapsed":true,"_uuid":"c3247a694ccfa53a5d249833cb448fc411fb2e5d","_cell_guid":"dbadeafd-e41f-4579-a7b3-0855b46a9e1a","trusted":false},"cell_type":"code","source":"generator_optimizer = tf.train.AdamOptimizer(0.001, beta1=0.5)\ndiscriminator_optimizer = tf.train.AdamOptimizer(0.0001, beta1=0.5)\ngan_loss = tfgan.gan_loss(conditional_gan_model, gradient_penalty_weight=1.0)\ngan_train_ops = tfgan.gan_train_ops(\n    conditional_gan_model,\n    gan_loss,\n    generator_optimizer,\n    discriminator_optimizer)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73ae213239e8311101b575d714df05db7a27f648","_cell_guid":"406f875b-ed83-4966-8e9f-a33da9e93a9d"},"cell_type":"markdown","source":"# Visualization Code"},{"metadata":{"collapsed":true,"_uuid":"56274cfd4409820751d6e6cb816d416324389707","_cell_guid":"ac4d4d03-f4bc-4b5a-aec8-3ba43c93b697","trusted":false},"cell_type":"code","source":"# Set up class-conditional visualization. We feed class labels to the generator\n# so that the the first column is `0`, the second column is `1`, etc.\nimages_to_eval = 20\nassert images_to_eval % 10 == 0\n\nrandom_noise = tf.random_normal([images_to_eval, 64])\none_hot_labels = tf.one_hot(\n    [i for _ in range(images_to_eval // 10) for i in range(10)], depth=10) \nwith tf.variable_scope('Generator', reuse=True):\n    eval_images = conditional_gan_model.generator_fn((random_noise, one_hot_labels))\nreshaped_eval_imgs = tfgan.eval.image_reshaper(\n    eval_images[:images_to_eval, ...], num_cols=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9a784f4fe00e574585827745c1275a5efc364d8","_cell_guid":"126d3ebe-b0ce-4ff7-842f-7cfff435950c","trusted":false,"collapsed":true},"cell_type":"code","source":"g_d_updates_per_step = tfgan.GANTrainSteps(1,2)  # do 1 gen step, then 2 disc steps.  \ntrain_step_fn = tfgan.get_sequential_train_steps(g_d_updates_per_step)\nglobal_step = tf.train.get_or_create_global_step()\n\nwith tf.train.SingularMonitoredSession() as sess:\n    start_time = time.time()\n    for i in range(1501):\n        loss, done_training = train_step_fn(sess, gan_train_ops, global_step, train_step_kwargs={})\n        if i % 100 == 0:\n            digits_np = sess.run([reshaped_eval_imgs])\n            visualize_training_generator(i, start_time, digits_np)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}