{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import necessaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport time\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nfrom sklearn.model_selection import KFold,StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D\nfrom tensorflow.keras.optimizers import Adadelta\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,LearningRateScheduler,EarlyStopping\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.version.VERSION)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the Train and Test Datasets.\n\ntrain = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take a look at train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the shape of the train and test data\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(14,8))\ncolumns = 8\nrows = 3\nfor i in range(1, rows*columns+1):\n    \n    digit_array = train.loc[i-1, \"pixel0\":]\n    arr = np.array(digit_array)   \n    image_array = np.reshape(arr, (28,28))   \n    \n    \n    fig.add_subplot(rows, columns, i)\n    plt.title(\"Label:\"+train.loc[i-1,\"label\"].astype(\"str\"))\n    plt.imshow(image_array, cmap=plt.cm.binary)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numbers distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=sns.countplot(train.loc[:,\"label\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalize Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividing the data into the input and output features to train make the model learn based on what to take in and what to throw out.\ntrain_X = train.loc[:, \"pixel0\":\"pixel783\"]\ntrain_y = train.loc[:, \"label\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New"},{"metadata":{"trusted":true},"cell_type":"code","source":"treshhold=0.1\ntrain_X[train_X<treshhold]=0\ntest[test<treshhold]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_X / 255.0\ntest_X = test / 255.0\n\ntrain_X = train_X.values.reshape(-1,28,28,1)\ntest_X = test_X.values.reshape(-1,28,28,1)\ntrain_y = to_categorical(train_y, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building a Sequential Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef build_model(input_shape=(28, 28, 1)):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = 3, activation='swish', input_shape = (28, 28, 1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 3, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64, kernel_size = 3, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 3, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(128, kernel_size = 4, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Early Stop"},{"metadata":{"trusted":true},"cell_type":"code","source":"#learning_rate_reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='accuracy',   # quality to be monitored \n                                            patience=3,          # no of epoch with no improvement after learning rate will be reduced\n                                            verbose=1,           # update message\n                                            factor=0.8,          # reducing learning rate \n                                            min_lr=0.001)       # lower bound learning rate \n\n# DECREASE LEARNING RATE EACH EPOCH\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n\n\nearly_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto',\n    baseline=None, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create 10 CNN Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nnets=10\n\nmodel = [0] *nets\nhistory = [0] * nets\n\n\nskf = StratifiedKFold(n_splits=nets, shuffle = True, random_state=1)\nskf.get_n_splits(train_X, train['label'])\nprint(skf)\n\nnumber=0\n\n\nfor train_index, test_index in skf.split(train_X, train['label']):\n    print(\"SPLIT \",number,\" TRAIN index:\", train_index, \"TEST index:\", test_index)\n    \n    X_train, X_val = train_X[train_index], train_X[test_index]\n    y_train, y_val = train_y[train_index], train_y[test_index]\n    \n    model[number]=build_model()\n    model[number].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    history[number] =model[number].fit(datagen.flow(X_train,y_train), epochs=100 ,validation_data = (X_val,y_val) ,\n     batch_size=100, verbose = 0,callbacks = [annealer,early_stop])\n    \n    metrics=pd.DataFrame(history[number].history)\n    display(metrics)\n    \n    \n    number+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"for number in range(0,nets):\n    model[number].save(\"StratifiedKFold_10_batch100_double_val_loss_\"+str(number)+\".h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble  CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ENSEMBLE PREDICTIONS AND SUBMIT\nresults = np.zeros( (test_X.shape[0],10) ) \nfor j in range(nets):\n    results = results + model[j].predict(test_X)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"StratifiedKFold_10_batch100_double_val_loss.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's see the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_test_digits(indexes):    \n    columns = 10\n    rows = len(indexes)//columns +1    \n    fig=plt.figure(figsize=(14,rows*2))    \n    \n    for plot_id, i in enumerate(indexes,1):     \n        fig.add_subplot(rows, columns, plot_id)                     \n        plt.title(\"predict:\"+submission.loc[i,\"Label\"].astype(\"str\"))\n        plt.axis(\"off\")\n        plt.imshow(np.reshape(test_X[i], (28,28)), cmap=plt.cm.binary)\n           \n    plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_test_digits(range(500,530))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks good)\n### Consider upvoting if it was helpful! ðŸ˜ƒ"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}