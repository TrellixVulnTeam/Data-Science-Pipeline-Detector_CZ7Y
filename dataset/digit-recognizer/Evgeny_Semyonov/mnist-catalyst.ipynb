{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Catalyst](https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png)"},{"metadata":{},"cell_type":"markdown","source":"**This notebook aims to:**\n1. Show a base pipeline with Catalyst:\n    * declarative base structure that is required by the library\n    * training\n    * inference\n\n2. Create the submission\n\n**Catalyst** is a high-level library(based on Pytorch) that helps to train your neural network models.\n\nIt breaks a common training procedure into separate code blocks.\n\nTypically, you just need to declare your model and create simple configuration files. That is it!\n\nFrom the official site:\n\n>\nCatalyst helps you write compact but full-featured DL & RL pipelines in a few lines of code. \n\n>You get a training loop with metrics, early-stopping, model checkpointing and other features without the boilerplate.\n\n**Features**\n> \n> Universal train/inference loop.\n> \n> Configuration files for model/data hyperparameters.\n> \n> Reproducibility – even source code will be saved.\n> \n> Callbacks – reusable train/inference pipeline parts.\n> \n> Training stages support.\n> \n> Easy customization.\n\n> PyTorch best practices (SWA, AdamW, 1Cycle, FP16 and more).\n\nMore info about Catalyst:\n\nhttps://github.com/catalyst-team/catalyst\n\nExamples:\n\nhttps://github.com/catalyst-team/catalyst/tree/master/examples"},{"metadata":{},"cell_type":"markdown","source":"**Install Catalyst**\n\nTypically, you just run `pip install catalyst`. \n\nBut in many competitions on Kaggle you will not be provided with the Internet connection when you will be doing the submission.\n\n\nTo cope with it, there is a Kaggle dataset with the requirements.\n\nMore about this dataset: https://www.kaggle.com/lightforever/catalyst"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"! cp -a /kaggle/input/catalyst/catalyst/catalyst/install.sh /tmp/install.sh && chmod 777 /tmp/install.sh && /tmp/install.sh /kaggle/input/catalyst/catalyst/catalyst","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Explore format of the files which are required by Catalyst**"},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls /kaggle/input/mnistcatalyst","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. __init__.py - import base parts which will be imported by catalyst\n2. experiment.py - file that provides the catalyst with the datasets\n3. model.py - model declaration. We use a very simple model for this notebook\n4. dataset.py - trivial Pytorch dataset for the task\n5. train.yml - configuration file for training\n6. infer.yml - configuration file for inference\n\nfold.csv - is a task-specific file with 5-Fold spliting. It is used in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat /kaggle/input/mnistcatalyst/__init__.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat /kaggle/input/mnistcatalyst/experiment.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat /kaggle/input/mnistcatalyst/model.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat /kaggle/input/mnistcatalyst/dataset.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat /kaggle/input/mnistcatalyst/train.yml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat /kaggle/input/mnistcatalyst/infer.yml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head /kaggle/input/mnistcatalyst/fold.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train**"},{"metadata":{"trusted":true},"cell_type":"code","source":"! catalyst-dl run --config /kaggle/input/mnistcatalyst/train.yml --expdir /kaggle/input/mnistcatalyst/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Infer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"! catalyst-dl run --config /kaggle/input/mnistcatalyst/infer.yml --expdir /kaggle/input/mnistcatalyst/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"catalyst has written the predictions into 'infer.logits.npy'"},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls /tmp/log","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's read the predictions and make a submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nprob = np.load('/tmp/log/infer.logits.npy')\nargmax = prob.argmax(axis=1)\npd.DataFrame({\n    'ImageId': np.arange(1, len(argmax) + 1),\n    'Label': argmax\n}).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nCatalyst helps you to create a new experiment rapidly! \n\nYou just need to include(or write if it does not exist) a new callback.\n\nOr you can change the runner. There are lots of tricks there!"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}