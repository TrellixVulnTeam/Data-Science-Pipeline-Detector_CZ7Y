{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-16T14:35:42.450373Z","iopub.execute_input":"2022-01-16T14:35:42.450742Z","iopub.status.idle":"2022-01-16T14:35:42.461258Z","shell.execute_reply.started":"2022-01-16T14:35:42.450692Z","shell.execute_reply":"2022-01-16T14:35:42.460429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# About data","metadata":{}},{"cell_type":"markdown","source":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n\nFor example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.","metadata":{}},{"cell_type":"markdown","source":"## What is Lenet5?\nLenet-5 is one of the earliest pre-trained models proposed by Yann LeCun and others in the year 1998, in the research paper Gradient-Based Learning Applied to Document Recognition. They used this architecture for recognizing the handwritten and machine-printed characters.","metadata":{}},{"cell_type":"markdown","source":"The first layer is the input layer with feature map size 32X32X1.\n\nThen we have the first convolution layer with 6 filters of size 5X5 and stride is 1. The activation function used at his layer is tanh. The output feature map is  28X28X6.\n\nNext, we have an average pooling layer with filter size 2X2 and stride 1. The resulting feature map is 14X14X6. Since the pooling layer doesnâ€™t affect the number of channels.\n\nAfter this comes the second convolution layer with 16 filters of 5X5 and stride 1. Also, the activation function is tanh. Now the output size is 10X10X16.\n\nAgain comes the other average pooling layer of 2X2 with stride 2. As a result, the size of the feature map reduced to 5X5X16.\n\nThe final pooling layer has 120 filters of 5X5  with stride 1 and activation function tanh. Now the output size is 120.\n\nThe next is a fully connected layer with 84 neurons that result in the output to 84 values and the activation function used here is again tanh.\n\nThe last layer is the output layer with 10 neurons and  Softmax function. The Softmax gives the probability that a data point belongs to a particular class. The highest value is then predicted.\n\nThis is the entire architecture of the Lenet-5 model. The number of trainable parameters of this architecture is around sixty thousand.","metadata":{}},{"cell_type":"markdown","source":"If you like this kindly Consider Upvoting!! Happy learning!!","metadata":{}},{"cell_type":"markdown","source":"# Important Library Loading & Data Loading","metadata":{}},{"cell_type":"code","source":"# Pytorch in python can be accessed by Torch library\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.463199Z","iopub.execute_input":"2022-01-16T14:35:42.463668Z","iopub.status.idle":"2022-01-16T14:35:42.470607Z","shell.execute_reply.started":"2022-01-16T14:35:42.463631Z","shell.execute_reply":"2022-01-16T14:35:42.469889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check current torch version\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.472038Z","iopub.execute_input":"2022-01-16T14:35:42.472594Z","iopub.status.idle":"2022-01-16T14:35:42.480852Z","shell.execute_reply.started":"2022-01-16T14:35:42.472546Z","shell.execute_reply":"2022-01-16T14:35:42.479635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In case Nvidea Cuda available, this will give True as result else False\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.482915Z","iopub.execute_input":"2022-01-16T14:35:42.483193Z","iopub.status.idle":"2022-01-16T14:35:42.491133Z","shell.execute_reply.started":"2022-01-16T14:35:42.483168Z","shell.execute_reply":"2022-01-16T14:35:42.489965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Torch Vision is library to work with Images in Pytorch","metadata":{}},{"cell_type":"code","source":"import torchvision\n# transform is used to convert data into Tensor form with transformations\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.493398Z","iopub.execute_input":"2022-01-16T14:35:42.494176Z","iopub.status.idle":"2022-01-16T14:35:42.498278Z","shell.execute_reply.started":"2022-01-16T14:35:42.494137Z","shell.execute_reply":"2022-01-16T14:35:42.497483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Torchvision has inbuilt Dataset where Mnist dataset is available, Lets import data\n\n","metadata":{}},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.49941Z","iopub.execute_input":"2022-01-16T14:35:42.50021Z","iopub.status.idle":"2022-01-16T14:35:42.50649Z","shell.execute_reply.started":"2022-01-16T14:35:42.500172Z","shell.execute_reply":"2022-01-16T14:35:42.505783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = torchvision.datasets.MNIST(\nroot = './data',\ntrain = True,\ndownload = True,\ntransform = transforms.Compose([transforms.ToTensor()])\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.50745Z","iopub.execute_input":"2022-01-16T14:35:42.50764Z","iopub.status.idle":"2022-01-16T14:35:42.540102Z","shell.execute_reply.started":"2022-01-16T14:35:42.507618Z","shell.execute_reply":"2022-01-16T14:35:42.539345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Length of train set\nlen(train_set)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.541439Z","iopub.execute_input":"2022-01-16T14:35:42.54192Z","iopub.status.idle":"2022-01-16T14:35:42.547281Z","shell.execute_reply.started":"2022-01-16T14:35:42.541881Z","shell.execute_reply":"2022-01-16T14:35:42.5465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's define a function which can help us to plot an Image and hence reproduceable\n\n","metadata":{}},{"cell_type":"markdown","source":"# Data Study","metadata":{}},{"cell_type":"code","source":"# Lets study first image\n\nimg, label = train_set[0]\nimg.shape, label","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.548849Z","iopub.execute_input":"2022-01-16T14:35:42.549533Z","iopub.status.idle":"2022-01-16T14:35:42.558357Z","shell.execute_reply.started":"2022-01-16T14:35:42.549494Z","shell.execute_reply":"2022-01-16T14:35:42.557606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So each Image is 28*28 pixel and Its Gray scale image, as color channel is 1","metadata":{}},{"cell_type":"code","source":"def show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0), cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.560971Z","iopub.execute_input":"2022-01-16T14:35:42.561502Z","iopub.status.idle":"2022-01-16T14:35:42.565875Z","shell.execute_reply.started":"2022-01-16T14:35:42.561467Z","shell.execute_reply":"2022-01-16T14:35:42.565112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As torch has image representation as [color channel, Height, Width] but Maplotlib accepts [height, width, color channel], hence above .permute() function does that.","metadata":{}},{"cell_type":"code","source":"# Without these libraries, we cant think of running any Data analysis related python program\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.567514Z","iopub.execute_input":"2022-01-16T14:35:42.568041Z","iopub.status.idle":"2022-01-16T14:35:42.57433Z","shell.execute_reply.started":"2022-01-16T14:35:42.568007Z","shell.execute_reply":"2022-01-16T14:35:42.57352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets observe some images\nshow_img(*train_set[1])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.582584Z","iopub.execute_input":"2022-01-16T14:35:42.583385Z","iopub.status.idle":"2022-01-16T14:35:42.774669Z","shell.execute_reply.started":"2022-01-16T14:35:42.583291Z","shell.execute_reply":"2022-01-16T14:35:42.773945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(*train_set[19992])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.776343Z","iopub.execute_input":"2022-01-16T14:35:42.77668Z","iopub.status.idle":"2022-01-16T14:35:42.96037Z","shell.execute_reply.started":"2022-01-16T14:35:42.776642Z","shell.execute_reply":"2022-01-16T14:35:42.959691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In Neural Network we have to perform Data Normalization to reduce possibility of Over Fitting, also CNN algorithms use Gradient boosting, So its must to perform Normalization else some variable may be given higher weightage.","metadata":{}},{"cell_type":"markdown","source":"# Data Normalization","metadata":{}},{"cell_type":"code","source":"trans = transforms.Compose([\n    # To resize image\n    transforms.Resize((32,32)),\n    transforms.ToTensor(),\n    # To normalize image\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.961772Z","iopub.execute_input":"2022-01-16T14:35:42.962019Z","iopub.status.idle":"2022-01-16T14:35:42.967106Z","shell.execute_reply.started":"2022-01-16T14:35:42.961984Z","shell.execute_reply":"2022-01-16T14:35:42.966201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = torchvision.datasets.MNIST(\nroot = './data',\ntrain = True,\ndownload = True,\ntransform = trans\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:42.968668Z","iopub.execute_input":"2022-01-16T14:35:42.968955Z","iopub.status.idle":"2022-01-16T14:35:43.007799Z","shell.execute_reply.started":"2022-01-16T14:35:42.968917Z","shell.execute_reply":"2022-01-16T14:35:43.007121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = torchvision.datasets.MNIST(\nroot = './data',\ntrain = False,\ndownload = True,\ntransform = trans\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.0105Z","iopub.execute_input":"2022-01-16T14:35:43.011195Z","iopub.status.idle":"2022-01-16T14:35:43.01942Z","shell.execute_reply.started":"2022-01-16T14:35:43.011145Z","shell.execute_reply":"2022-01-16T14:35:43.01867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_set), len(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.021289Z","iopub.execute_input":"2022-01-16T14:35:43.021594Z","iopub.status.idle":"2022-01-16T14:35:43.028903Z","shell.execute_reply.started":"2022-01-16T14:35:43.021554Z","shell.execute_reply":"2022-01-16T14:35:43.027976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets observe some changes","metadata":{}},{"cell_type":"code","source":"img, label = train_set[0]\nimg.shape, label","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.031087Z","iopub.execute_input":"2022-01-16T14:35:43.031331Z","iopub.status.idle":"2022-01-16T14:35:43.038853Z","shell.execute_reply.started":"2022-01-16T14:35:43.031298Z","shell.execute_reply":"2022-01-16T14:35:43.03801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So now we have images with 32*32 pixels","metadata":{}},{"cell_type":"code","source":"show_img(*train_set[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.040388Z","iopub.execute_input":"2022-01-16T14:35:43.04067Z","iopub.status.idle":"2022-01-16T14:35:43.230786Z","shell.execute_reply.started":"2022-01-16T14:35:43.040637Z","shell.execute_reply":"2022-01-16T14:35:43.229897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(*train_set[9999])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.232167Z","iopub.execute_input":"2022-01-16T14:35:43.232393Z","iopub.status.idle":"2022-01-16T14:35:43.42157Z","shell.execute_reply.started":"2022-01-16T14:35:43.232362Z","shell.execute_reply":"2022-01-16T14:35:43.420911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(*test_set[5999])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.42281Z","iopub.execute_input":"2022-01-16T14:35:43.423039Z","iopub.status.idle":"2022-01-16T14:35:43.613526Z","shell.execute_reply.started":"2022-01-16T14:35:43.423007Z","shell.execute_reply":"2022-01-16T14:35:43.612858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train & Validation data Split","metadata":{}},{"cell_type":"code","source":"# this function will generate random indexes between 0 and 59999\ndef split_indices(n, val_per, seed = 0):\n    n_val = int(n * val_per)\n    np.random.seed(seed)\n    idx = np.random.permutation(n)\n    return idx[n_val : ], idx[: n_val]","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.615066Z","iopub.execute_input":"2022-01-16T14:35:43.61531Z","iopub.status.idle":"2022-01-16T14:35:43.622028Z","shell.execute_reply.started":"2022-01-16T14:35:43.615277Z","shell.execute_reply":"2022-01-16T14:35:43.621362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_per = 0.2\nrand_seed = 42\n\ntrain_indices, val_indices = split_indices(len(train_set), val_per, rand_seed)\n\nprint(len(train_indices), len(val_indices))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.625061Z","iopub.execute_input":"2022-01-16T14:35:43.625342Z","iopub.status.idle":"2022-01-16T14:35:43.632823Z","shell.execute_reply.started":"2022-01-16T14:35:43.625311Z","shell.execute_reply":"2022-01-16T14:35:43.631954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets plot some indexes\n\nprint(\"Validation Indices: \", val_indices[:20])\nprint(\"Training Indices: \", train_indices[:20])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.63446Z","iopub.execute_input":"2022-01-16T14:35:43.634883Z","iopub.status.idle":"2022-01-16T14:35:43.643438Z","shell.execute_reply.started":"2022-01-16T14:35:43.634843Z","shell.execute_reply":"2022-01-16T14:35:43.642451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems indexes are distributed across range as provided","metadata":{}},{"cell_type":"markdown","source":"Let's Import libraries to generate Random Subset & dataLoader to feed Batch of data to model, as feeding whole dataset may lead to System failure or Hang\n\n","metadata":{}},{"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.648116Z","iopub.execute_input":"2022-01-16T14:35:43.648313Z","iopub.status.idle":"2022-01-16T14:35:43.652746Z","shell.execute_reply.started":"2022-01-16T14:35:43.64829Z","shell.execute_reply":"2022-01-16T14:35:43.651977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is one of Hyper parameter, but let's select given below value\nbatch_size = 512","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.65417Z","iopub.execute_input":"2022-01-16T14:35:43.654676Z","iopub.status.idle":"2022-01-16T14:35:43.661259Z","shell.execute_reply.started":"2022-01-16T14:35:43.654635Z","shell.execute_reply":"2022-01-16T14:35:43.66056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training data loader\ntrain_sampler = SubsetRandomSampler(train_indices)\ntrain_dl = DataLoader(train_set, batch_size, sampler = train_sampler)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.662538Z","iopub.execute_input":"2022-01-16T14:35:43.662834Z","iopub.status.idle":"2022-01-16T14:35:43.66984Z","shell.execute_reply.started":"2022-01-16T14:35:43.662795Z","shell.execute_reply":"2022-01-16T14:35:43.669127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation dataloader\nval_sampler = SubsetRandomSampler(val_indices)\nval_dl = DataLoader(train_set, batch_size, sampler = val_sampler)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.671254Z","iopub.execute_input":"2022-01-16T14:35:43.671617Z","iopub.status.idle":"2022-01-16T14:35:43.678296Z","shell.execute_reply.started":"2022-01-16T14:35:43.671584Z","shell.execute_reply":"2022-01-16T14:35:43.677536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's verify where we have all class from output columns in both train and validation set\n\n","metadata":{}},{"cell_type":"code","source":"from torchvision.utils import make_grid\n# this will help us to create Grid of images","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.679621Z","iopub.execute_input":"2022-01-16T14:35:43.679982Z","iopub.status.idle":"2022-01-16T14:35:43.687235Z","shell.execute_reply.started":"2022-01-16T14:35:43.679949Z","shell.execute_reply":"2022-01-16T14:35:43.686486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will select first 110 image from first batch of size = 512\ndef show_batch(dl):\n    for img, label in dl:\n        fig, ax = plt.subplots(figsize = (12,8))\n        ax.imshow(make_grid(img[:110], 10).permute(1,2,0))\n        break","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.689019Z","iopub.execute_input":"2022-01-16T14:35:43.689281Z","iopub.status.idle":"2022-01-16T14:35:43.696211Z","shell.execute_reply.started":"2022-01-16T14:35:43.689249Z","shell.execute_reply":"2022-01-16T14:35:43.695425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_batch(val_dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:43.697777Z","iopub.execute_input":"2022-01-16T14:35:43.698088Z","iopub.status.idle":"2022-01-16T14:35:44.076495Z","shell.execute_reply.started":"2022-01-16T14:35:43.698037Z","shell.execute_reply":"2022-01-16T14:35:44.075857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.078057Z","iopub.execute_input":"2022-01-16T14:35:44.078612Z","iopub.status.idle":"2022-01-16T14:35:44.631524Z","shell.execute_reply.started":"2022-01-16T14:35:44.078568Z","shell.execute_reply":"2022-01-16T14:35:44.630864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Images seems equally Distributed\n\n","metadata":{}},{"cell_type":"markdown","source":"# Model Building using Torch.nn","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.633219Z","iopub.execute_input":"2022-01-16T14:35:44.633705Z","iopub.status.idle":"2022-01-16T14:35:44.637603Z","shell.execute_reply.started":"2022-01-16T14:35:44.633665Z","shell.execute_reply":"2022-01-16T14:35:44.636893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is how Yen LeKun has decribed and built First Neural network in 1988, that was probably first working Neural model","metadata":{}},{"cell_type":"code","source":"class LeNet5(nn.Module):\n    \n    def __init__(self, num_classes):\n        \n        super().__init__()\n        \n        self.num_classes = num_classes\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 6, kernel_size = 5),\n            nn.Tanh(),\n            nn.MaxPool2d(kernel_size = 2),\n            nn.Conv2d(6, 16, kernel_size = 5),\n            nn.Tanh(),\n            nn.MaxPool2d(kernel_size = 2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(16*5*5, 120),\n            nn.Tanh(),\n            nn.Linear(120, 84),\n            nn.Tanh(),\n            nn.Linear(84, num_classes)  \n        )\n        \n        \n        \n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        logit = self.classifier(x)\n        return logit","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.638959Z","iopub.execute_input":"2022-01-16T14:35:44.639225Z","iopub.status.idle":"2022-01-16T14:35:44.648701Z","shell.execute_reply.started":"2022-01-16T14:35:44.63919Z","shell.execute_reply":"2022-01-16T14:35:44.64779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Model\nmodel = LeNet5(num_classes = 10)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.650046Z","iopub.execute_input":"2022-01-16T14:35:44.650458Z","iopub.status.idle":"2022-01-16T14:35:44.662622Z","shell.execute_reply.started":"2022-01-16T14:35:44.650422Z","shell.execute_reply":"2022-01-16T14:35:44.661979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.664241Z","iopub.execute_input":"2022-01-16T14:35:44.664613Z","iopub.status.idle":"2022-01-16T14:35:44.672083Z","shell.execute_reply.started":"2022-01-16T14:35:44.664562Z","shell.execute_reply":"2022-01-16T14:35:44.671274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's test model based on initial Guesses by Pytorch\n\n","metadata":{}},{"cell_type":"code","source":"sample = next(iter(train_set))\nimg = sample[0]\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.673579Z","iopub.execute_input":"2022-01-16T14:35:44.673891Z","iopub.status.idle":"2022-01-16T14:35:44.681611Z","shell.execute_reply.started":"2022-01-16T14:35:44.673858Z","shell.execute_reply":"2022-01-16T14:35:44.680856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need to import one extra dimension as Model need shape as [batch_size COlor Channel heigh * Width]\n\n.unsqueeze() from torch help to add extra dimension","metadata":{}},{"cell_type":"code","source":"img.unsqueeze(0).shape\n# Now we have [1, 1, 32, 32] shape of image","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.683356Z","iopub.execute_input":"2022-01-16T14:35:44.683663Z","iopub.status.idle":"2022-01-16T14:35:44.691857Z","shell.execute_reply.started":"2022-01-16T14:35:44.683625Z","shell.execute_reply":"2022-01-16T14:35:44.691212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets see initial guesses from model","metadata":{}},{"cell_type":"code","source":"out = model(img.unsqueeze(0))\nout","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.6928Z","iopub.execute_input":"2022-01-16T14:35:44.692964Z","iopub.status.idle":"2022-01-16T14:35:44.700525Z","shell.execute_reply.started":"2022-01-16T14:35:44.692943Z","shell.execute_reply":"2022-01-16T14:35:44.699818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Output In terms of Probability\nF.softmax(out)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.701663Z","iopub.execute_input":"2022-01-16T14:35:44.702097Z","iopub.status.idle":"2022-01-16T14:35:44.709842Z","shell.execute_reply.started":"2022-01-16T14:35:44.702022Z","shell.execute_reply":"2022-01-16T14:35:44.708981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems model predict index 7, i.e. letter 7 as output, its initial guess !!","metadata":{}},{"cell_type":"code","source":" # Demo function to test result\n\nfor images, labels in train_dl:\n    print('Image Shape', images.shape)\n    out = model(images)\n    print('output shape', out.shape)\n    print('out[0]', out[0])\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.710909Z","iopub.execute_input":"2022-01-16T14:35:44.711484Z","iopub.status.idle":"2022-01-16T14:35:44.912702Z","shell.execute_reply.started":"2022-01-16T14:35:44.711447Z","shell.execute_reply":"2022-01-16T14:35:44.911926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = F.softmax(out[0], dim = 0)\nprobs","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.914748Z","iopub.execute_input":"2022-01-16T14:35:44.915878Z","iopub.status.idle":"2022-01-16T14:35:44.923968Z","shell.execute_reply.started":"2022-01-16T14:35:44.915846Z","shell.execute_reply":"2022-01-16T14:35:44.923108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initial guess from model suggest, probability of each class as 10%, which is kind of 1st prediction from model\n\n","metadata":{}},{"cell_type":"code","source":"m = torch.argmax(probs)\nm","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.92528Z","iopub.execute_input":"2022-01-16T14:35:44.925816Z","iopub.status.idle":"2022-01-16T14:35:44.932229Z","shell.execute_reply.started":"2022-01-16T14:35:44.925777Z","shell.execute_reply":"2022-01-16T14:35:44.931422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets plot\nplt.imshow(img.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:44.933599Z","iopub.execute_input":"2022-01-16T14:35:44.934464Z","iopub.status.idle":"2022-01-16T14:35:45.129139Z","shell.execute_reply.started":"2022-01-16T14:35:44.93443Z","shell.execute_reply":"2022-01-16T14:35:45.128498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, it was wrong guess from Model :(","metadata":{}},{"cell_type":"markdown","source":"# Device Selection","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.130283Z","iopub.execute_input":"2022-01-16T14:35:45.130515Z","iopub.status.idle":"2022-01-16T14:35:45.138831Z","shell.execute_reply.started":"2022-01-16T14:35:45.130482Z","shell.execute_reply":"2022-01-16T14:35:45.137907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we are using GPU, so below code will help us to access GPU at different stage of Processing\n\n","metadata":{}},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.141042Z","iopub.execute_input":"2022-01-16T14:35:45.141613Z","iopub.status.idle":"2022-01-16T14:35:45.151954Z","shell.execute_reply.started":"2022-01-16T14:35:45.141573Z","shell.execute_reply":"2022-01-16T14:35:45.151066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.153246Z","iopub.execute_input":"2022-01-16T14:35:45.15355Z","iopub.status.idle":"2022-01-16T14:35:45.162801Z","shell.execute_reply.started":"2022-01-16T14:35:45.153514Z","shell.execute_reply":"2022-01-16T14:35:45.161855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Helper Fit Model","metadata":{}},{"cell_type":"code","source":"def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n    \n    pred = model(x)\n    \n    loss = loss_func(pred, y)\n    \n    if opt is not None:\n        \n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n    metric_result = None\n    \n    if metric is not None:\n        \n        metric_result = metric(pred, y)\n        \n    return loss.item(), len(x), metric_result","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.164156Z","iopub.execute_input":"2022-01-16T14:35:45.16465Z","iopub.status.idle":"2022-01-16T14:35:45.170602Z","shell.execute_reply.started":"2022-01-16T14:35:45.164611Z","shell.execute_reply":"2022-01-16T14:35:45.16983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, loss_fn, val_dl, metric = None):\n    \n    with torch.no_grad():\n        \n        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in val_dl]\n        \n        losses, nums, metrics = zip(*results)\n        \n        total = np.sum(nums)\n        \n        avg_loss = np.sum(np.multiply(losses, nums)) / total\n        \n        avg_metric = None\n        \n        if metric is not None:\n            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n            \n    return avg_loss, total, avg_metric","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.172525Z","iopub.execute_input":"2022-01-16T14:35:45.173016Z","iopub.status.idle":"2022-01-16T14:35:45.180644Z","shell.execute_reply.started":"2022-01-16T14:35:45.172979Z","shell.execute_reply":"2022-01-16T14:35:45.179801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(epochs, model, loss_fn, train_dl, val_dl, opt_fn = None, metric = None, scheduler = None, scheduler_on = 'val_metric'):\n    \n    train_losses, val_losses, val_metrics, train_metrics = [], [], [], []\n    \n    \n    for epoch in range(epochs):\n        \n        model.train()\n        for x, y in train_dl:\n            train_loss, _, train_metric = loss_batch(model, loss_fn, x, y, opt_fn, metric)\n            \n        model.eval()\n        result = evaluate(model, loss_fn, val_dl, metric)\n        val_loss, total, val_metric = result\n        \n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_metrics.append(val_metric)\n        train_metrics.append(train_metric)\n        \n        if metric is None:\n            print('Epoch{}/{}, train_loss: {:.4f}, val_loss: {:.4f}' \n                 .format(epoch+1, epochs, train_loss, val_loss))\n            \n        else:\n            print('Epoch {}/{}, train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}, train_{}: {:.4f}'\n                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric, metric.__name__, train_metric))\n            \n        if scheduler is not None:\n            if scheduler_on == 'val_metric':\n                scheduler.step(val_metrics[-1])\n        \n            \n    return train_losses, val_losses, val_metrics, train_metrics","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.182227Z","iopub.execute_input":"2022-01-16T14:35:45.182764Z","iopub.status.idle":"2022-01-16T14:35:45.193312Z","shell.execute_reply.started":"2022-01-16T14:35:45.182726Z","shell.execute_reply":"2022-01-16T14:35:45.192566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define Accuracy function","metadata":{}},{"cell_type":"code","source":"def accuracy(output, labels):\n    _, preds = torch.max(output, dim = 1)\n    \n    return torch.sum(preds == labels).item() / len(preds)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.194528Z","iopub.execute_input":"2022-01-16T14:35:45.195337Z","iopub.status.idle":"2022-01-16T14:35:45.204235Z","shell.execute_reply.started":"2022-01-16T14:35:45.195299Z","shell.execute_reply":"2022-01-16T14:35:45.203462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initial guess on Validation data","metadata":{}},{"cell_type":"code","source":"val_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric = accuracy)\n\nprint(val_loss, val_acc)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:45.209175Z","iopub.execute_input":"2022-01-16T14:35:45.209628Z","iopub.status.idle":"2022-01-16T14:35:47.322822Z","shell.execute_reply.started":"2022-01-16T14:35:45.209601Z","shell.execute_reply":"2022-01-16T14:35:47.321317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 25\n\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, mode = 'max', verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:47.324384Z","iopub.execute_input":"2022-01-16T14:35:47.324649Z","iopub.status.idle":"2022-01-16T14:35:47.330385Z","shell.execute_reply.started":"2022-01-16T14:35:47.324611Z","shell.execute_reply":"2022-01-16T14:35:47.328555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, optimizer, accuracy, scheduler, 'val_metric')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:35:47.331476Z","iopub.execute_input":"2022-01-16T14:35:47.331982Z","iopub.status.idle":"2022-01-16T14:40:08.094955Z","shell.execute_reply.started":"2022-01-16T14:35:47.331944Z","shell.execute_reply":"2022-01-16T14:40:08.09345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, this is amazing right ?? 100% Train Accuracy and 98.86% Validation accuracy!!","metadata":{}},{"cell_type":"markdown","source":"May Be over fitting ?? Well, its fairly simplest dataset that anyone ever get, so It was not probably over fitting :(","metadata":{}},{"cell_type":"markdown","source":"# Plotting result","metadata":{}},{"cell_type":"markdown","source":"Plot between Training Loss vs Epochs","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\nplt.plot(history[0], '-x')\nplt.xlabel('Epochs')\nplt.ylabel('Training Loss')\nplt.title('Plot between Training Loss vs Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:44:01.814521Z","iopub.execute_input":"2022-01-16T14:44:01.814827Z","iopub.status.idle":"2022-01-16T14:44:02.133306Z","shell.execute_reply.started":"2022-01-16T14:44:01.814793Z","shell.execute_reply":"2022-01-16T14:44:02.132601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Too Much of noise because of Batch Stochastic gradient","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\nplt.plot(history[1], '-x')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.title('Plot between Validation Loss vs Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:45:03.324942Z","iopub.execute_input":"2022-01-16T14:45:03.325296Z","iopub.status.idle":"2022-01-16T14:45:03.596988Z","shell.execute_reply.started":"2022-01-16T14:45:03.325258Z","shell.execute_reply":"2022-01-16T14:45:03.596373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\nplt.plot(history[0], '-go')\nplt.plot(history[1], '-yx')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.title('Plot between Validation Loss & training Loss vs Epochs')\nplt.legend(['Train Loss', 'Validation Loss'], loc = 'upper right')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:51:34.376933Z","iopub.execute_input":"2022-01-16T14:51:34.377499Z","iopub.status.idle":"2022-01-16T14:51:34.605153Z","shell.execute_reply.started":"2022-01-16T14:51:34.37746Z","shell.execute_reply":"2022-01-16T14:51:34.604472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\nplt.plot(history[3], '-go')\nplt.plot(history[2], '-yx')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Plot between Training Accuracy & Validation vs Epochs')\nplt.legend(['Train Accuracy', 'Validation Accuracy'], loc = 'lower right')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:52:48.425493Z","iopub.execute_input":"2022-01-16T14:52:48.425751Z","iopub.status.idle":"2022-01-16T14:52:48.666584Z","shell.execute_reply.started":"2022-01-16T14:52:48.425722Z","shell.execute_reply":"2022-01-16T14:52:48.66591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test data & Model Evaluation","metadata":{}},{"cell_type":"code","source":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:54:45.593476Z","iopub.execute_input":"2022-01-16T14:54:45.593735Z","iopub.status.idle":"2022-01-16T14:54:45.598658Z","shell.execute_reply.started":"2022-01-16T14:54:45.593706Z","shell.execute_reply":"2022-01-16T14:54:45.597967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = test_set[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:54:53.718271Z","iopub.execute_input":"2022-01-16T14:54:53.718832Z","iopub.status.idle":"2022-01-16T14:54:53.931618Z","shell.execute_reply.started":"2022-01-16T14:54:53.718794Z","shell.execute_reply":"2022-01-16T14:54:53.930906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yippy!! That's Correct\n\n","metadata":{}},{"cell_type":"code","source":"img, label = test_set[1839]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:55:14.314872Z","iopub.execute_input":"2022-01-16T14:55:14.315157Z","iopub.status.idle":"2022-01-16T14:55:14.50315Z","shell.execute_reply.started":"2022-01-16T14:55:14.315123Z","shell.execute_reply":"2022-01-16T14:55:14.5025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = test_set[193]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:55:25.576947Z","iopub.execute_input":"2022-01-16T14:55:25.577503Z","iopub.status.idle":"2022-01-16T14:55:25.76897Z","shell.execute_reply.started":"2022-01-16T14:55:25.577462Z","shell.execute_reply":"2022-01-16T14:55:25.768312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This was tough one, but model predicted coreectly","metadata":{}},{"cell_type":"code","source":"img, label = test_set[1000]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:56:03.706715Z","iopub.execute_input":"2022-01-16T14:56:03.706995Z","iopub.status.idle":"2022-01-16T14:56:03.907965Z","shell.execute_reply.started":"2022-01-16T14:56:03.706963Z","shell.execute_reply":"2022-01-16T14:56:03.907301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a final step, let's also look at the overall loss and accuracy of the model on the test set.\n\n","metadata":{}},{"cell_type":"code","source":"test_loader = DeviceDataLoader(DataLoader(test_set, batch_size=256), device)\nresult = evaluate(model, F.cross_entropy, test_loader, metric = accuracy)\nresult\nAccuracy = result[2] * 100\nAccuracy\nloss = result[0]\nprint(\"Total Losses: {}, Accuracy: {}\".format(loss, Accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:56:22.075651Z","iopub.execute_input":"2022-01-16T14:56:22.075913Z","iopub.status.idle":"2022-01-16T14:56:23.871394Z","shell.execute_reply.started":"2022-01-16T14:56:22.075881Z","shell.execute_reply":"2022-01-16T14:56:23.869028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, 98.87% Accuracy, I can just believe inventor of this model, Their Hard Work and Their dedication, hats Off to those guys","metadata":{}},{"cell_type":"markdown","source":"Thats it for this Notebook...\n\nIf you like this kindly Consider Upvoting!! Happy learning!!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}