{"cells":[{"metadata":{"id":"amV_-ajQU5AP"},"cell_type":"markdown","source":"# **Handwritten  Digit Prediction**"},{"metadata":{"id":"gW1dkMWhU_jr"},"cell_type":"markdown","source":"**Dataset:**\n\nThe data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine provided by MNIST. The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image."},{"metadata":{"id":"pIAq8b3BVCQQ"},"cell_type":"markdown","source":"**Target:**\n\nGoal is to correctly identify digits from a dataset of tens of thousands of handwritten images."},{"metadata":{"id":"yBzMmAHDVHTx"},"cell_type":"markdown","source":"**Approach:**\n\nApplied Data Augmentation for better prediction and large dataset, followed by model training using Convolutional Neural Network."},{"metadata":{"id":"A-FIuKAMP7Hf"},"cell_type":"markdown","source":"# **Importing Necessary Libraries**"},{"metadata":{"id":"GBVlXvOffWgP","outputId":"ee9ea22a-b851-45f4-9461-e52ad03826f1","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n#convolutional layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Lambda, MaxPooling2D\n#core layers\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.normalization import BatchNormalization\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.utils.np_utils import to_categorical\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"-AERmkrnQDVv"},"cell_type":"markdown","source":"# **Data Preparation**"},{"metadata":{"id":"KJBHgCMQQHDN"},"cell_type":"markdown","source":"**Loading Data**"},{"metadata":{"id":"s7cG10GzPpKw","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nsub = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"0IgxEjAVdrPV","outputId":"2ee27860-e30a-45e1-8eb4-d26e1bcc38a4","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"3n_O91LmRESQ","outputId":"aa0b7342-d0f3-4d9f-fcd6-9a6a812ec71b","trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"RXcp7bvvRJmL","outputId":"fc9dd599-4a12-4b48-f8d2-2f421309db2a","trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"S8V9bPMCeHF5"},"cell_type":"markdown","source":"**Splitting data into features and labels**"},{"metadata":{"id":"mvl35BEFeQ09","trusted":true},"cell_type":"code","source":"X=train.drop(['label'],1).values\ny=train['label'].values\ntest_x=test.values","execution_count":null,"outputs":[]},{"metadata":{"id":"u4eUSu1HgBx2","outputId":"dc5384d6-ceaf-4aaa-f0ca-e86de97759fc","trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"hbDxwtADgIZd","outputId":"541a9ee4-239e-45de-8e90-d81a74890c97","trusted":true},"cell_type":"code","source":"print(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"3DZB4x1SgyGq","outputId":"3ea4e119-4204-43da-f972-19990ab1c896","trusted":true},"cell_type":"code","source":"print(test_x)","execution_count":null,"outputs":[]},{"metadata":{"id":"Pz1owq02dvNL"},"cell_type":"markdown","source":"**Normalization**"},{"metadata":{"id":"PELqzMRtg6FJ"},"cell_type":"markdown","source":"Performing grayscale normalization to reduce the effect of illumination's differences."},{"metadata":{"id":"4Uh0B6LVhFOW"},"cell_type":"markdown","source":"Moreover the CNN converg faster on [0..1] data than on [0..255]"},{"metadata":{"id":"U8N_Zf2od-2w","trusted":true},"cell_type":"code","source":"X=X/255\ntest_x=test_x/255","execution_count":null,"outputs":[]},{"metadata":{"id":"M6GcIV3Yhabh"},"cell_type":"markdown","source":"**Reshaping Data**"},{"metadata":{"id":"Kcy2C_PdhXFU","trusted":true},"cell_type":"code","source":"# Reshaping image into 3 dimensions (height = 28px, width = 28px , canal = 1)\n# canal = 1 => For gray scale\nX=X.reshape(-1,28,28,1)\ntest_x=test_x.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"id":"AIbGIl5qi82D"},"cell_type":"markdown","source":"**Label Encoding**"},{"metadata":{"id":"HKF0Ey_QjMrX"},"cell_type":"markdown","source":"One-Hot Encoding"},{"metadata":{"id":"zs-0juTyjoWg"},"cell_type":"markdown","source":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])."},{"metadata":{"id":"yH26-zMajJfg","outputId":"0c2d5fca-3e61-4831-b571-f8acf0adffb3","trusted":true},"cell_type":"code","source":"y=to_categorical(y)\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"CY8M2q4HljNW"},"cell_type":"markdown","source":"**Splitting data into train and validation set**"},{"metadata":{"id":"DcL-JAl7i7Ss","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"N4k8OmXWzWOi"},"cell_type":"markdown","source":"Splitting the train set into two parts : a small fraction (10%) is the validation set used to evaluate the model and the rest (90%) is used to train the model."},{"metadata":{"id":"yYtSHmSTv8XC","outputId":"c7153e48-e7f4-4c3c-cd4e-27e01385f249","trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"sPLx7ydZG3Yw","outputId":"21ccf0cb-1604-475a-ef0d-80ab6f772952","trusted":true},"cell_type":"code","source":"print(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"TJoASN2JzxLa"},"cell_type":"markdown","source":"# **Data Visualisation**"},{"metadata":{"id":"PE1rpRipzMiY","trusted":true},"cell_type":"code","source":"X_train__ = X_train.reshape(X_train.shape[0],28,28)","execution_count":null,"outputs":[]},{"metadata":{"id":"EPiKB_62HUnM","outputId":"374e8c4d-721b-423e-f366-37a66cf21314","trusted":true},"cell_type":"code","source":"fig,axis=plt.subplots(1,4,figsize=(20,10))\nfor i,ax in enumerate(axis.flat):\n  ax.imshow(X_train__[i], cmap='binary')\n  digit=y_train[i].argmax()\n  ax.set(title=f\"Real Number is {digit}\");","execution_count":null,"outputs":[]},{"metadata":{"id":"f3h1NVCUIaGN"},"cell_type":"markdown","source":"Standardization"},{"metadata":{"id":"q1CPRQJgIMZq","trusted":true},"cell_type":"code","source":"#creating mean=0 and standard deviation=1\nmean=np.mean(X_train)\nstd=np.std(X_train)\ndef standardize(x):\n  return ((x-mean)/std)","execution_count":null,"outputs":[]},{"metadata":{"id":"lVfImVK1JBLr","trusted":true},"cell_type":"code","source":"epochs=50 #for no of passes in training to optimize error\nbatch_size=64","execution_count":null,"outputs":[]},{"metadata":{"id":"5S2wfsXhJQpo"},"cell_type":"markdown","source":"# **Defining the model**"},{"metadata":{"id":"HM1AA80qJioC"},"cell_type":"markdown","source":"**CNN**"},{"metadata":{"id":"sP3v7w2tJO3u","trusted":true},"cell_type":"code","source":"model=Sequential()\n\n#model.add(Lambda(standardize,input_shape=(28,28,1)))    \nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())    \nmodel.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n    \nmodel.add(MaxPooling2D(pool_size=(2,2)))\n    \nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation=\"relu\"))\n    \nmodel.add(Dense(10,activation=\"softmax\"))\n    \nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"YXwLd4LJhtCT"},"cell_type":"markdown","source":"# **Data Augumentation**"},{"metadata":{"id":"dhrgc0AQhJpj","trusted":true},"cell_type":"code","source":"#Data augmentation to prevent overfitting\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n#datagen.fit(X_train)\ntrain_gen=datagen.flow(X_train, y_train, batch_size=batch_size)\ntest_gen=datagen.flow(X_test, y_test, batch_size=batch_size)\n ","execution_count":null,"outputs":[]},{"metadata":{"id":"u-ktDNjhzNKB"},"cell_type":"markdown","source":"# **Model Training**"},{"metadata":{"id":"tF0GzUs-xBKv","outputId":"a08fece4-3136-4e83-90fd-9dde4335c057","trusted":true},"cell_type":"code","source":"#This make accuarcy 0.998\nimport tensorflow as tf\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.995):\n      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback() \nmodel.fit(X,y,batch_size=batch_size, validation_split=0.2, epochs=10,callbacks=[callbacks])","execution_count":null,"outputs":[]},{"metadata":{"id":"1mEXEK3x0CFS","outputId":"23ee9ab9-3860-4917-b4d2-c85be6cda0cf","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.995):\n      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()      \n# Fit the model\nhistory = model.fit_generator(train_gen, \n                              epochs = epochs, \n                              steps_per_epoch = X_train.shape[0] // batch_size,\n                              validation_data = test_gen,\n                              validation_steps = X_test.shape[0] // batch_size,\n                              callbacks=[callbacks],\n                              )","execution_count":null,"outputs":[]},{"metadata":{"id":"gd-A2CiKRrpo"},"cell_type":"markdown","source":"**Plotting CNN model**"},{"metadata":{"id":"lYAptabnP0N9","outputId":"91be39b9-70cc-4249-8d75-ed2f8ff572e9","trusted":true},"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ISEemtfITfG0"},"cell_type":"markdown","source":"# **Evaluating the model**"},{"metadata":{"id":"_3jvLZoOTige"},"cell_type":"markdown","source":"**Training and validation curves**"},{"metadata":{"id":"ube1gk2fTFNS","outputId":"1ea65f9a-e784-4eda-f96f-a80f5870ac41","trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1, figsize=(18, 10))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"xaNh1dE5nwPB"},"cell_type":"markdown","source":"# **Confusion Matrix**"},{"metadata":{"id":"mTsMtgX5rHz2","outputId":"2b682f95-7c3b-4123-9729-f20923adc31b","trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10)) # Set Figure\n\ny_pred = model.predict(X_test) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\nY_pred = np.argmax(y_pred, 1) # Decode Predicted labels\nY_test = np.argmax(y_test, 1) # Decode labels\n\nmat = confusion_matrix(Y_test, Y_pred) # Confusion matrix\n\n# Plot Confusion matrix\nsns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)\nplt.xlabel('Predicted Values')\nplt.ylabel('True Values');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"id":"JgKwqkBesfFY"},"cell_type":"markdown","source":"# **Prediction and Submition**"},{"metadata":{"id":"8RdsGUj9tx3z"},"cell_type":"markdown","source":"**Prediction validation results**"},{"metadata":{"id":"AD244L9AsYN5","outputId":"d9959f94-0539-4462-d63c-17f15278676a","trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\nX_test__ = X_test.reshape(X_test.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"Real Number is {y_test[i].argmax()}\\nPredict Number is {y_pred[i].argmax()}\");\n","execution_count":null,"outputs":[]},{"metadata":{"id":"7JheFlb0uh1Q"},"cell_type":"markdown","source":"**Prediciting the Outputs**"},{"metadata":{"id":"KAQQYlaKuoWQ","outputId":"87bc32fd-f4b6-422f-fa1e-d954e3057d9a","trusted":true},"cell_type":"code","source":"pred = model.predict_classes(test_x, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"cREoxboPMVJC","outputId":"46bc1f22-d8fe-4430-ceaf-75b77ee8771b","trusted":true},"cell_type":"code","source":"sub['Label'] = pred\nsub.to_csv(\"CNN_keras_sub.csv\", index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"pFjMy3V-bD1U"},"cell_type":"markdown","source":"We have got 99.5 % accuracy using Convolution Neural network"},{"metadata":{},"cell_type":"markdown","source":"Please upvote my work if it could help! Thank you!"},{"metadata":{"id":"SwXtniJKMdC3","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}