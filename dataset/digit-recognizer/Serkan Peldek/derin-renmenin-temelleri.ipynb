{"cells":[{"metadata":{"_uuid":"8e505f6d065d7c1bc0e94608149ef09c116009b3"},"cell_type":"markdown","source":"<center><h1>DERİN ÖĞRENMENİN TEMELLERİ</h1></center>\n# <a class=\"anchor\" id=0.>İçindekiler</a>\n\n* [0.1. Gerekli Kütüphaneler Geliştirme Ortamına Dahil Ediliyor](#0.1.)\n\n* [1. Tanıtım](#1.)\n* [2. Yapay Sinir Ağları Tarihçesi](#2.)\n* * [2.1. Kuruluş Devri](#2.1.)\n* * [2.2. Duruklama Devri](#2.2.)\n* * [2.3. Gelişme Devri](#2.3.)\n* * [2.4. Yükseliş Devri(Derin Öğrenme)](#2.4.)\n* [3. Perceptron](#3.)\n* * [3.1.  Perceptron Yönteminin Sıfırdan Kodlanması](#3.1.)\n* * [3.2.  My_Perceptron Sınıfı](#3.2.)\n* * [3.3. Yardımcı Fonksiyon: performance_metrics](#3.3.)\n* * [3.4. Iris Veri Seti Üzerinden My_Perceptron Test Edilmesi](#3.4.)\n* * [3.5. AND, OR, XOR Mantıksal Tabloları Üzerinde My_Perceptron Test Edilmesi](#3.5.)\n* [4. ADALINE:  **ADA**ptive **LIN**ear **E**lements](#4.)\n* * [4.1.  ADALINE Yönteminin Sıfırdan Kodlanması](#4.1.)\n* * [4.2. My_ADALINE Sınıf](#4.2.)\n* * [4.3.  Iris Veri Seti Üzerinde ADALINE Yönteminin Test Edilmesi](#4.3.)\n* * [4.4. Ölçeklendirmenin Önemi](#4.4.)\n* * [4.5. AND, OR, XOR Mantıksal Tabloları Üzerinde My_ADALINE Test Edilmesi](#4.5.)\n* [6. Keras İle Derin Ağlar Oluşturma](#6.)\n* * [6.1. Derin Ağlar Oluşturma: Sınıflandırma](#6.1.)\n* * [6.2. Derin Ağ Performansının Ölçülmesi](#6.2.)\n* * [6.3.Ağ Yapısının Görselleştirilmesi](#6.3.)\n* * [6.4. Keras Modelinin sklearn Modeli Gibi Kullanılması: KerasClassifier](#6.4.)\n* [ Evrişimsel Sinir Ağları(Convolutional Neural Networks)](#.)\n* [ LeNet](#5.)\n* * [ LeNet sınıfı](#5.1.)\n* * [ Veri Setlerinin Yüklenmesi](#5.2.)\n* * [Veri Setlerinin Keras Modeline Uygun Hale Getirilmesi](#5.3.)\n* * [Derin Ağların Eğitilmesi](#5.4.)\n* * [Sınıflandırma Sonuçları](#5.5.)\n* [ Modelin Kaydedilmesi](#.)\n"},{"metadata":{"_uuid":"1cf90f3770faa95d9aaf191f5be62d1997212543"},"cell_type":"markdown","source":"<a class=\"anchor\" id=0.1.>0.1. Gerekli Kütüphaneler Geliştirme Ortamına Dahil Ediliyor</a>\n\nÇalışmada tüm bölümlerde kullanılacak kütüphanler geliştirme ortamına dahil ediliyor. Bölümler  içerisinde gerekli kütüphanler ihtiyaç oldukça dahil edilecektir. "},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"3d491491f27669891f2c0f3d447d9f1d6fee0544"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7f25c15601769f8fd5b880669bce00d8ab1561f"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=1.></a> 1. Tanıtım\n\nBu 'Çekirdek' çalışmasın amacı derin öğrenme için gerekli teorik ve pratik yetkinliklerini kazandırmaktır. Çalışma kapsamında teorik bilgiler çok fazla matematiksel notasyonlar kullanılmadan anlatılacak ve makine öğrenmesi projelerinde kullanılacak derin öğrenme teknikleri pratiklerle uygulanacaktır.\n\n**Derin Öğrenme İçin Doğru Başlangıç Nedir?**\n\nDoğru bir öğrenme planıyla başlamak elde edilecek verim açısından çok önemlidir. Derin öğrenmeye başlamayı düşünenlerin akıllarına en çok gelen sorular: Derin öğrenme benim için uygun mu? Uygunsa, nasıl bir yol izlemeliyim?\n\n**Derin öğrenme benim için uygun mu?**\n\n**Bu soru için verilen yanlış cevaplar şunlardır:** Derin öğrenmeye başlaman için lineer cebir , olasılık, istatistik konularında ileri derecede yetkinliklere sahip olman gerekir... Temel yapay sinir ağları yöntemlerini bilmeden derin öğrenmeyi anlayamazsın... Makine öğrenmesi yöntemlerini bilmiyorsan derin öğrenmeye hiç başlama... Çok iyi derecede proglama bilmiyorsan derin öğrenme sana göre değil...\n\nYukarıdaki cevaplara göre hareket edilecek olursa, derin öğrenmeye başlamak için birkaç yıla ihtiyaç var demektir. Cevaplarda belirtilen yetkinlikler yeni başlayan için avantaj sağlasada, başlamak için olmazsa olmaz değildir. Derin öğrenmeye başlamak için temel seviyede matematik ve programlama bilgisi yeterlidir. \n\n**Nasıl bir yol izlemeliyim?**\n\nDerin öğrenme için doğru yol; öncelikle basit derin öğrenme modelleri oluşturmak ve bunları pratiklerle uygulamaktır. Eğer beğenirseniz ve daha fazla vakit ayırma şansınız varsa daha zor modeller oluşturmaya ve teorik alt yapıyı öğrenmeye devam edebilirsiniz. \n\n**Bu 'Çekirdek' çalışmasını takip edebilmek için nelere ihtiyaç var?**\n\nMatris ve vektör işlemlerini bilmek ve bunların python ile nasıl gerçekleştirileceğini bilmek matematik ve programlama açısından yeterli olacaktır. Ayrıca basit seviyede Nesne Yönelimli Programlama bilmek çalışmada yapılan kodlamaları daha kolay anlamanıza yardımcı olacaktır. \n* Lineer Cebir İçin \"[Makine Öğrenmesi İçin Lineer Cebir](https://www.kaggle.com/serkanpeldek/makine-renmesi-%C4%B0-in-lineer-cebir)\" çalışmasından faydalanabilirsiniz.\n* Nesne Yönelimli Programlama İçin \"[Object Oriented Titanics](https://www.kaggle.com/serkanpeldek/object-oriented-titanics)\" çalışmasından faydalanabilirsiniz. "},{"metadata":{"_uuid":"126e4a983c1b7ca8c6ce708d0a2177ec7cad8f4e"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=2.></a> 2. Yapay Sinir Ağları\n\nYapay Sinir Ağları(YSA) insan beyninin çalışmasını modellemek için yapılan çalışmaların sonucunda ortaya çıkmış bir öğrenme modelidir. **Derin öğrenme** 1940'lardan bugünü üzerinde çalışma yapılan YSA'nın gelişmiş çoklu katmanlı mimarilerine verilen adlandırmadır. Aslında derin öğrenme YSA'dır. \n\nYSA'nın tarihçesi aynı zaman da derin öğrenmenin de tarihçesidir. Üzerinde uzun yıllar çalışma yapılan ve şuan yapay zeka çalışmalarını domine eden YSA **imparatorluğunun** tarihi, ironik olarak dört devre ayrılabilir; **Kuruluş, Duruklama, Gelişme ve Yükseliş(Derin Öğrenme)**"},{"metadata":{"_uuid":"84b1b12b3152e086a39df4d83d778fb275a70447"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=2.1.></a> 2.1. Kuruluş Devri\n\nMcCullock ve Pitts yapay sinir ağları üzerine yaptıkları ilk çalışmada sinir(neuron) kavramını tanıtmışlardır(McCullock ve Pitts, 1943).\n\nSnirler beyinde, kimyasal ve elektriksel sinyallerin işlenmesi ve iletilmesinde yer alan birbiriyle bağlantılı sinir hücreleridir. McCullock ve Pitts, böyle bir sinir hücresini, ikili çıktılarla basit bir mantık kapısı olarak tanımladılar: Birden fazla sinyal dendritlere ulaşır, daha sonra hücre gövdesine entegre edilir ve eğer birikmiş sinyal belirli bir eşiği aşarsa, akson tarafından geçirilecek bir çıkış sinyali üretilir(Raschka, 2015).\n\nMcCullock ve Pitts'in önerdikleri sinir kavramını temel alan Rosenblatt, perceptron öğrenme kurallarını geliştirmiştir(Rosenblatt, 1957). Perceptron kuralı ile Rosenblatt, bir nöronun ateş alıp almadığına karar vermek için girdi özellikleriyle çarpılan optimal ağırlık katsayılarını otomatik olarak öğrenecek bir algoritma önermiştir. Denetimli öğrenme ve sınıflandırma bağlamında, böyle bir algoritma, bir örneğin bir sınıfa mı yoksa diğerine mi ait olduğunu tahmin etmek için kullanılabilir(Raschka, 2015).\n\nBu süre zarfında sinir ağları gelişmeleri hızla ilerledi ve 1959'da Stanford'da Bernard Widrow ve Marcian Hoff, gerçek bir dünya sorununa başarıyla uygulanan ilk sinir ağını geliştirdi. Bu sistemler, telefon hatlarındaki gürültüyü ortadan kaldırmak için özel olarak tasarlanmış ve bugün hala kullanılmakta olan **ADA**ptive **LIN**ear **E**lements ve **M**ultiple **ADA**ptive **LIN**ear **E**lements'ı kullanıldı. Bu yöntemler kısaca ADALINE ve MADALINE olarak adlandırıldı.\n\nPerceptron eğitimi için geliştirilen prosedürler günümüzde **derin ağları** eğitiminde de kullanılan Olasılıksal Dereceli Azalma (Stochastic Gradient Descent (SGD) yönteminin temellerini oluşturmaktadır. "},{"metadata":{"_uuid":"221a26525ee37140b3ee83266f195509aceab24b"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=2.2.></a> 2.2. Duraklama Devri\n\nYSA ilk önerildiği yıldan 1960'ların sonu kadar araştırmacıların yoğun ilgisini çekmiştir. 1969 yılında Minsky ve Papert tarafında yayımlanan makale YSA çalışmalarını 10 yıl duraklatmıştır. Bu açıdan çalışma ödenem için YSA'nın laneti olarak adlandırılmıştır. \n\nMinsky ve Papert yazdıkları makalede Perceptron yönteminin sadece lineer olarak ayrılabilen sınıflarda kullanılabileceğini, lineer olarak ayrılamayan sınıflarda kullanılamayacağını göstermişlerdir. İleriki konularda da değineceğimiz gibi Perceptron yöntemi lineer ayrılabilen sınıfların üzerinde iyi sonuç verirken lineer olarak ayrılamayan sınıflar üzerinde kötü sonuçlar vermiştir. Ayrıca makalede şimdi çok basit olarak görülen Perceptron yönteminin eğitilmesi için yeterli donanıma sahip olunmadığını belirtmişlerdir. \n\nMinsky ve Papert makalesinin etkisiyle, 1980'lere kadar YSA yöntemlerinde önemli gelişmeler yaşanmamıştır. "},{"metadata":{"_uuid":"2335ffa1cd894287f21d2387d13c38e3f3fb908a"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=2.3.></a> 2.3. Gelişme Devri\n\nUzun bir aradan sonra, YSA'nın lineer olmayan sınıflar üzerinde çalışabileceğini gösteren geri yayılımlı(backprobagation) yöntemi, YSA çalışmalarının tekrar hız kazanmasını sağlamıştır. Geri yayılımlı YSA eğitim yöntemi ileri yayılımlı(feedforward) yöntemlerin gelişmesine imkan vermiştir. \n\nYSA artık XOR gibi lineer olarak ayırştırlamayan sınıflar üzerinde başarılı sonuçlar vermeye başlamıştır. Daha sonraki çalışmalar YSA'nın makine öğrenmesi modeli için evrensel bir yaklaşım olduğu fikrinin yerleşmesini sağlamıştır. Yani, gözetimli öğrenme altında yer alan regresyon ve sınıflandırma problemleri ve gözetimsi öğrenme altında yer alan kümeleme ve boyut azaltma promlemleri YSA modeline uygun hale getirilerek çözülebileceği fikri benimsenmiştir.\n\nGeri yayımlı öğrenme yöntemi YSA çalışmalarında bir dönüm noktası olmasına karşın hesaplama donanımlarınındaki yetersizlik YSA'nın geniş çaplı kullanılmasına engel oluyordu ve 2000'li yıllardaki Destek Vektör Makineleri(Support Vector Machines) yönteminin başarısı YSA'yı geri plana brakmıştı."},{"metadata":{"_uuid":"b5687819b8cf7693f5d56332bf4c2fd6db6c0ebf"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=2.4.></a> 2.3. Yükseliş Devri(Derin Öğrenme)\n\n2007'lerde YSA'çalışmalarında önemli bir ilerleme oldu. Bu yıldan sonra YSA çalışmaları Derin Öğrenme olarak adlandırılmaya başladı. Derin öğrenme algoritmalarının gelişiminde önemli dört etken vardır; \n\n* Derin öğrenme modellerinin eğitilmesi için kullanılacak verilerin artması\n* Eğitimin gerçekleştirilmesi için kullanılacak donanımların gelişmesi\n* Eğitimde kullanılacak optimizasyon yöntemlerinin gelişmesi\n* Paralel hesaplamaya imkan veren GPU teknolojisiyle uyum"},{"metadata":{"_uuid":"824d6cb54b13ce0076bcf20d09ea7d5d006e51d5"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=3.></a> 3. Perceptron\n\nMcCullock ve Pitts'in siniri ve Rosenblatt'ın perceptron modelinin ardındaki tüm fikir, beyindeki tek bir nöronun nasıl çalıştığını taklit etmek için indirgemeci bir yaklaşım kullanmaktır: ya ateş eder ya da etmez.\n\nX ve y sırasıyla veri matrisi ve çıktı vektörü olsun. Veri matrisi ve çıktı vekötürünün bir kısmı eğitim, diğer kısmı test için kullanılacaktır. Eğitim ve test kümeleri şöyle ayrılsın X_train, X_test, y_train, y_test.\n\nRosenblatt'ın başlangıç perceptron kuralına göre perceptron modelinin eğitimi aşağıdaki adımlarla özetlenebilir:\n\n* Ağırlık vektörü W rasgele değerler ile doldurulur\n* Öğrenme oranını belirlenir\n* X_train eğitim kümesindeki her bir eğitim örneği xi için aşağıdaki adımlar gerçekleştirilir:\n* * Çıktı y_pred vektörünü hesapla\n* * Ağırlık vektörünü y_pred ve y_test vektörlerini dikkate alarak güncelle\n\nEğitim aşaması tamamlandıktan sonra elde edilen ağırlık vektörü test veri kümesinin sınıflandırılmasında kullanılır. Sınıflandırma işlemi X_test veri setindeki herbir örnek için aşağıda yer alan fonksiyondaki gibi tanımlana bilir:\n\nf(xi_test)=\n\n* eğer xi_test.W>0 ise ait olduğu sınıf 1'dir\n* değil ise ait olduğu sınıf 0'dır."},{"metadata":{"_uuid":"a6f549d83cfe6ec9a951e4e9cf95df13e04dfc2d"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=3.1.></a> 3.1.  Perceptron Yönteminin Sıfırdan Kodlanması\n\nİlk önerilen YSA öğrenme yöntemi olana Perceptron'un kodlanmasını python sınıfı kullanılarak gerçekleştirilecektir. Programlamada sınıflar kullanılarak yazılan kodlar Nesne Yönelimli Programlama(OOP) olarak adlandırılır. OOP yaklaşımı çok detaylı ve geniş bir konudur. Bu çekirdek çalışmasında yazacağımız kodlar basit seviyede OOP bilgisiyle anlaşılabilecek yapıda olacaktır.\n\n\nPerceptron class kodlaması sklearn kütüphanesinde yer alan sınıflandırıcılar gibi **fit** ve **predict** fonksiyonlarına sahip olacaktır. **fit** fonksiyonu modeli eğitim veri seti üzerinde eğitmek için, **predict** fonksiyonu eğitilen modelde test veri seti üzerinde tahmin yapmak için kullanılacaktır.\n\n**net_input()** fonksiyonu özellik verkötüyle ağırlık vektörünün nokta çarpımını hesaplamaktadır. **get_error()** fonkisyonu tahminin hatalı olup olmadığını kontrol etmektedir. "},{"metadata":{"_uuid":"bfd39adf6b148a30d85aab7e543b329b018a770e"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=3.2.></a> 3.2.  My_Perceptron Sınıfı"},{"metadata":{"trusted":true,"_uuid":"89ffc1f69dbe2bf007fa16fa4939e32098abe90a","_kg_hide-input":true},"cell_type":"code","source":"class My_Perceptron:\n    \n    def __init__(self, learning_rate, epoch):\n        \"\"\"\n        Ağ için kullanılacak parametreler\n        \"\"\"\n        self.learning_rate=None\n        self.epoch=None\n        self.w=None\n        self.bias=None\n        self.errors=None\n        \n        \"\"\"\n        Ağ parametrelerinin değer ataması yapılıyor\n        \"\"\"\n        self.set_net_parameters(learning_rate, epoch)\n        \n        \n        \"\"\"\n        Sınıf değerleri eğitim aşamasında belirlenecektir\n        \"\"\"\n        self.class1 = None\n        self.class2 = None\n        self.thres  = None\n        \n    \n    def set_net_parameters(self, learning_rate, epoch):\n        self.learning_rate = learning_rate\n        self.epoch         = epoch\n        self.errors        = []\n    \n    def _set_class_values(self, y):\n        classes = np.unique(y)\n        if len(classes) != 2:\n            raise ValueError(\"Number of class should be 2\")\n        else:\n            self.class1 = classes[1]\n            self.class2 = classes[0]\n            self.thres  = sum(classes)/len(classes)\n            \n            \n    def fit(self, X_train, y_train):\n        \n        self._set_class_values(y_train)\n        #Özellik vektörünün uzunluğu alınıyor\n        feature_size=X_train.shape[1]\n        \n        self.w = np.random.rand(feature_size)\n        self.bias=np.random.rand()\n        for  i in range(self.epoch):\n            error = 0\n            \n            for xi, yi in zip(X_train, y_train):\n                \"\"\"\n                Güncelleme katsayısı öğrenme oranına ve yapılan\n                tahmine göre belirleniyor\n                \"\"\"\n                update     = self.learning_rate*(yi-self.predict(xi))\n                self.w = self.w + update*xi\n                self.bias  = self.bias + update\n                \n                error = error + self._get_error(update)\n            \n            self.errors.append(error)\n    \n    def predict(self, X):\n        pred=np.where(self.net_input(X) >= self.thres, self.class1, self.class2)\n        \n        return pred\n    \n    def net_input(self, X):\n        net = np.dot(X, self.w)\n        net = net+self.bias\n        \n        return net\n    \n    def _get_error(self, update):\n        if update == 0.0:\n            return 0\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f7905078586c98d7a829837dd3ecf7dfeaccd58"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=3.3.></a> 3.3. Yardımcı Fonksiyon: performance_metrics"},{"metadata":{"trusted":true,"_uuid":"293ce56d7dc7b8de12d71f0c07bf4541fd97733c","_kg_hide-input":true},"cell_type":"code","source":"def performance_metrics(y_true, y_pred,\n            accuracy=True, confusion_matrix=True, classification_report=True):\n    if accuracy:\n        print(\"Başarı oranı(%):\",metrics.accuracy_score(y_true, y_pred)*100,end=\"\\n\\n\")\n    if confusion_matrix:\n        print(\"Karışıklık Matrisi:\\n\",\n              metrics.confusion_matrix(y_true, y_pred),end=\"\\n\\n\")\n   \n    if classification_report:\n        print(\"Sınıflandırma Raporu:\\n\",\n              metrics.classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1950520b912806888f3ae2bcabced3dec7600b9"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=3.4.> </a> 3.4. Iris Veri Seti Üzerinden My_Perceptron Test Edilmesi\n\nIris veri setinde üç tane hedef sınıf vardır;setosa, versicolor ve virginica. Perceptron algoritması iki sınıf sınıflandırıcısı olduğu için iris veri setindeki sadece iki sınıf kullanılacaktır.\n\n**Uyarı:** Perceptron, SVM, Logistic Regression vb. bir çok makine öğrenmesi modeli iki sınıf sınıflandırıcılardır. İkili sınıf sınıflandırıcıları çoklu sınıf sınıflandırıcısı olarak kullanmak için One vs Rest, One vs One gibi yöntemler kullanılır. Sklearn kütüphanesinden yer alan Perceptron algoritması çoklu sınıfların sınıflandırmada kullanılması bahsi geçen yöntemlerle gerçekleştirilir.\n"},{"metadata":{"trusted":true,"_uuid":"db9f250da28000b58ebbe8adb5e54adcb82ceb75"},"cell_type":"code","source":"iris_3c=pd.read_csv(\"../input/iris/Iris.csv\")\nsns.countplot(iris_3c['Species'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3726e2fcbce1bc732b09b6ef6646766c1afa9532"},"cell_type":"markdown","source":"Veri setinde toplamda 150, her bir sınıfa ait 50 örnek yer almaktadir.  Iris-virginica sınıfı  veri setinden çıkartılacaktır. "},{"metadata":{"trusted":true,"_uuid":"7e7466710c7728ac619ad278575d01c466bb1819"},"cell_type":"code","source":"iris_2c=iris_3c[iris_3c['Species']!='Iris-virginica'].copy()\nsns.countplot(iris_2c['Species'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f70cdf18afc45eb316c33e18ecf112223256d3d"},"cell_type":"code","source":"iris_2c.loc[iris_2c['Species']=='Iris-setosa','Species']=-1\niris_2c.loc[iris_2c['Species']=='Iris-versicolor','Species']=1\n\nX=iris_2c.drop(['Id', \"Species\"], axis=1)\ny=iris_2c['Species']\n\nX_train, X_test, y_train, y_test=train_test_split(X.values, \n                                                  y.values, \n                                                  stratify=y, \n                                                  test_size=0.4,\n                                                 random_state=42) \nperceptron=My_Perceptron(learning_rate=0.1, epoch=50)\n\nperceptron.fit(X_train, y_train)\ny_pred=perceptron.predict(X_test)\n\nprint(\"İki Sınıflı Iris Veri Seti İçin {} \\\nSınıflandırma Performansı\\n\".format(perceptron.__class__.__name__))\nperformance_metrics(y_true=y_test, y_pred=y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"638c46fd0fc070cddb837192f519472b34a4412a"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=3.5.> </a> 3.5. AND, OR, XOR Mantıksal Tabloları Üzerinde My_Perceptron Test Edilmesi\n\nSonuçlar Perceptron algoritmasının kusursuz olduğunu gösteriyor! Gerçekten öyle mi? Bu sorunun yanıtını bulmaya çalışalım.\n\nPerceptron algoritması linear bir sınıflandırıcıdır. Lineer olarak ayrılabilen veri setleri üzerinde iyi sonuçlar verir. Lineer olarak ayırlabilmek nedir? Eğer iki sınıfı ayırmak için bir doğru parçası yetiyorsa bu sınıflar lineer olarak ayrıştırılabilir olarak kabul edilir.\n\nLineer sınıflandırıcılar tek bir doğruyla ayrılamayan veri setleri üzerinde iyi sonuçlar vermezler. Bunu göstermek için en çok kullanılan veri; OR, AND ve XOR doğruluk tablolarıdır. OR ve AND doğruluk tablolarındaki 0 ve 1 sınıfları lineer olarak ayrılabilirken, XOR doğruluk tablosundaki sınıflar lineer olarak ayrılamazlar."},{"metadata":{"trusted":true,"_uuid":"9f49f639aed0d76622343fabd2ad716adc39cad0"},"cell_type":"code","source":"X_table = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny_and=np.array([0, 0, 0, 1])\ny_or=np.array([0, 1, 1, 1])\ny_xor=np.array([0, 1, 1, 0])\n\nlogic_gate={\"and\":(X_table, y_and),\n           \"or\":(X_table, y_or ),\n           \"xor\":(X_table, y_xor)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd0fa3709b91db55283264db5c369fb80dd9f5ee"},"cell_type":"code","source":"for key, item in logic_gate.items():\n    \n    X_table, y_output= item\n    perceptron=My_Perceptron(learning_rate=0.1, epoch=50)\n    \n    perceptron.fit(X_table, y_output)\n    y_pred=perceptron.predict(X_table)\n\n    print(\"{} İçin Perceptron Sınıflandırma Performansı\".format(key.upper()))\n    performance_metrics(y_true=y_output, y_pred=y_pred, \n                        confusion_matrix=False,\n                       classification_report=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yukarıdaki sonuçlarda görüldüğü üzere, Perceptron yöntemi OR ve AND verilerini sınıflandırmada başarılı olurken XOR verilerinin ayrıştırılmasında başarısız olmuştur. "},{"metadata":{"_uuid":"9510deee201d3d43d96f52dd5b6a465d74195bd9"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=4.></a> 4.  ADALINE:  **ADA**ptive **LIN**ear **E**lements\n\n**ADALINE** yöntemi Widrow ve Hoff tarafından Perceptron yönteminden birkaç yıl sonra  önerildi. ADALINE algoritması; lojistik regresyon ve destek vektör makineleri  sınıflandırıcıları ve  regresyon modelleri  gibi daha gelişmiş makine öğrenme algoritmalarını anlamak için temel teşkil eden maliyet fonksiyonlarını tanımlama ve en aza indirme anahtar kavramını göstermesi açısından çok önemli bir yere sahiptir.  \n\nADALINE  ve Perceptron modellerinin temel farklı eğitim aşamasında sınıfları birbirinden ayıran ağırlık vektörünün bulunmasındaki yaklaşımlarıdır. Perceptron yönteminde ağırlık vektörünün güncellenmesi herbir örneğin sınıf tahmini yapıldıktan sonra gerçekleştirilirdi. ADALINE yönteminde ise ağırlık vektörünün güncellenmesi veri setindeki tüm örneklerin sınıf tahmini yapıldıktan sonra gerçekleştirilir. "},{"metadata":{"_uuid":"6f7b8009b414f2a02ef5a058b64ad2cf13aab988"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=4.1.></a> 4.1.  ADALINE Yönteminin Sıfırdan Kodlanması\n\nADALINE yönteminin çalışma mantığı Perceptron yöntemine çok benzemektedir. ADALINE sınıfına ait fit() fonksiyonu Perceptron fit() fonksiyonundan biraz faklıdır. ADALINE fit() fonksiyonunda ağırlık vektörünün güncellenmesi veri setindeki tüm örnekelerin tahminine göre belirnenir. Bu açıdan eğitim aşaması daha hızlı gerçekleştirilmektedir.  "},{"metadata":{"_uuid":"e256f8b58f6f8ef9a763911d402da711f61ad639"},"cell_type":"markdown","source":"# <a class=\"anchor\" id=4.2.></a> 4.2.  My_ADALINE Sınıf"},{"metadata":{"trusted":true,"_uuid":"0e019c02fd07689c759fa68aebcaa0e9882e79e2","_kg_hide-input":true},"cell_type":"code","source":"class My_ADALINE:\n    \n    def __init__(self, learning_rate, epochs):\n        \"\"\"\n        Ağ için kullanılacak parametreler\n        \"\"\"\n        self.learning_rate = None\n        self.epochs = None\n        \n        \"\"\"\n        Ağ parametrelerinin değer ataması yapılıyor\n        \"\"\"\n        self._set_net_parameters(learning_rate, epochs)\n        \n        \n        \"\"\"\n        Sınıf etiketleri eğitim aşamasında belirlenecektir\n        \"\"\"\n        self.class1 = None\n        self.class2 = None\n        self.thres  = None\n        \n        \"\"\"\n        Ağ değişkenleri eğitim aşamasında belirlenecektir\n        \"\"\"\n        self.w = None\n        self.bias = None\n        self.costs = None\n        \n    def _set_net_parameters(self, learning_rate, epochs):\n        self.learning_rate = learning_rate\n        self.epochs         = epochs\n        \n    \n    def _set_class_values(self, y):\n        classes = np.unique(y)\n        if len(classes) != 2:\n            raise ValueError(\"Number of class should be 2\")\n        else:\n            self.class1 = classes[1]\n            self.class2 = classes[0]\n            self.thres  = sum(classes)/len(classes)\n\n    \n    def fit(self, X_train, y_train):\n        \n        self._set_class_values(y_train)\n\n        number_of_sample, number_of_feature = X_train.shape[:2]\n        \n        self.w = np.random.rand(number_of_feature)\n        self.bias = np.random.rand()\n        self.costs = []\n        \n        for i in range(self.epochs):\n            net_output = self.net(X_train)\n            errors = y_train-net_output\n            \n            self.w = self.w + self.learning_rate*X_train.T.dot(errors)\n            self.bias = self.bias + self.learning_rate*errors.sum()\n            \n            cost=(errors**2).sum()/2.0\n            self.costs.append(cost)\n        return self\n    \n    \n    def net(self, X):\n        out = np.dot(X, self.w)\n        out = out + self.bias\n        return out\n    \n    def activation(self, X):\n        return self.net(X)\n    \n    def predict(self, X):\n        return np.where(self.activation(X)>=self.thres, self.class1, self.class2)\n            ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3d51d2f072b311f559aa3781f411eda005f5270"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=4.3.></a> 4.3.  Iris Veri Seti Üzerinde ADALINE Yönteminin Test Edilmesi"},{"metadata":{"trusted":true,"_uuid":"a58cdd2a8f20e60ab12c55a0a9ceccf6c51ee6d4"},"cell_type":"code","source":"adaline=My_ADALINE(learning_rate=0.01, epochs=50)\n\nadaline.fit(X_train, y_train)\n\ny_pred=adaline.predict(X_test)\n\nprint(\"İki Sınıflı Iris Veri Seti İçin \\\n{}  Sınıflandırma Performansı\\n\".format(adaline.__class__.__name__))\nperformance_metrics(y_true=y_test, y_pred=y_pred,\n                   confusion_matrix=False,\n                   classification_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yukarıdaki sonuç beklentilerimizi karşılamıyor. Perceptron ile %100 başarı oranı elde etmişken daha gelişmiş bir yöntem olan ADALINE ile %50 başarı oranı elde edilmiştir. İki sınıflı veri setleri için %50 başarı oranı, modelin hiç öğrenmediğini gösterir. Bu başarısızlığın nedeni verilern ölçeklendirilmemesinden kaynaklanmaktadır. "},{"metadata":{"_uuid":"09846b0f705d6b4a7ef74f4e298c75df28f7ad28"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=4.4.></a> 4.4.  Ölçeklendirmenin Önemi\n\nADALINE modeli iki sınıflı Iris veri setinde %50 başarı oranı vermiştir. Bu sonuç modelin hiç öğrenmediğini göstermektedir. Çünkü eşit dağılıma sahip iki sınıflı veri setleri için başarı oranı alt sınırı %50'dir. Tahminlerin hepsini sınıflardan biri olarak belirlemek %50 başarı oranını elde etmeye yetecektir.\n\nPeki, Perceptron modelineden daha iyi olan ADALINE neden başarısız oldu? Bunun nedeni; ADALINE modelinin ağırlık vektörünün elde edilmesinde kullanın optimizasyon tekni olan Gradien Desent yönteminin ölçeklendirmiş verileri üzerinde iyi sonuç vermesinden kaynaklanmaktadır. \n\nVerileri ölçekledirip ADALINE modelini tekrar kullanalım"},{"metadata":{"trusted":true,"_uuid":"f64d383e2e41777e52d2a1d289e4f5673212718a"},"cell_type":"code","source":"X_scaled=StandardScaler().fit_transform(X)\nprint(\"Ölçeklendirme gerçekleştirildi...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e570666411408e1fc746ac6914b048a7ff765b8"},"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(X_scaled, \n                                                  y.values, \n                                                  stratify=y, \n                                                  test_size=0.4,\n                                                 random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cbab7b46f1dfcfbc5dc50a5900b2eae43eba39a"},"cell_type":"code","source":"adaline=My_ADALINE(learning_rate=0.01, epochs=50)\n\nadaline.fit(X_train, y_train)\n\ny_pred=adaline.predict(X_test)\n\nprint(\"İki Sınıflı Iris Veri Seti İçin \\\n{} Sınıflandırma Performansı\\n\".format(adaline.__class__.__name__))\nperformance_metrics(y_true=y_test, y_pred=y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"649f61ce1f9be9a4bd9bb171d3758683e349074e"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=4.5.></a> 4.5. AND, OR, XOR Mantıksal Tabloları Üzerinde My_ADALINE Test Edilmesi \n\nÖlçeklendirme işleminden sonra ADALINE Iris veri seti üzerinde iyi sonuç vermiştir. Ancak Perceptron modelini gibi ADALINE modeli de lineer olarak ayrıştırılabilen sınıflar üzerinde iyi sonuçlar verir. ADALINE modelinin lineer olarak ayrıştırlamayan veriler üzerinde başarısız olduğunu görmek için AND, OR ve XOR doğruluk tablolarının sınıflandırmasını gözlemleyerek anlayabiliriz. "},{"metadata":{"trusted":true,"_uuid":"39df59d520df8e12e55af38e733247b316a5c3a6"},"cell_type":"code","source":"for key, item in logic_gate.items():\n    \n    X_table, y_output= item\n    adaline=My_ADALINE(learning_rate=0.1, epochs=50)\n    \n    adaline.fit(X_table, y_output)\n    y_pred=adaline.predict(X_table)\n\n    print(\"{} İçin  {} \\\n    Sınıflandırma Performansı\".format(key.upper(), adaline.__class__.__name__))\n    performance_metrics(y_true=y_output, y_pred=y_pred, \n                        confusion_matrix=False,\n                       classification_report=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2badcf93965ea9cc6d1f3f8f20f1efbcb86be44"},"cell_type":"markdown","source":"Yukadaki sonuçlar ADALINE modelinin, Perceptron gibi, XOR doğruluk tablosu sınıflandırmasında başarısız olmuştur. Bu sonuç ADALINE modelinin lineer sınıflandırıcı olduğunu göstermektedir. "},{"metadata":{"_uuid":"cb86ca217d4fcebbe4d901a1289a420872f93344"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=6.></a> 6. Keras İle Derin Ağlar Oluşturma\n\nKeras, arka planda Tensorflow veya Theon kütüphanleri kullanarak derin ağlar oluştumayı kolaylaştıran derin öğrenme yazılım çatısıdır(framework). Keras ile yapay sinir ağların tanımlanması ve eğitilmesi birkaç kod satırla gerçekleştirilebilir.\n\nPima-Indian veri seti kullanılacaktır. Veri seti 768 kadın hastaya ait 8 özellikten ve bir hedef değişkenden oluşmaktadır. Hedef değişken kişinin teşhis durumunu 0 ve 1 ile göstermektedir. 0 kişinin diabet hastası olmadığını, 1 kişinin diabet hastası olduğunu belirtmektedir. \n\n* Pregnancies: Kişinin kaç kez hamile olduğu\n* Glucose: Kandanki şeker miktarı\n* BloodPressure: Kan basıncı\n* SkinThickness: Cilt kalınlığı\n* Insulin: Kandaki insulin miktarı\n* BMI: Vücut kitle indeksi\n* DiabetesPedigreeFunction: Diabet soyagacı fonksiyonu\n* Age: Yaş\n* Outcome: Teşhis"},{"metadata":{"trusted":true,"_uuid":"17f9d88dd14859d30e3452e7aba0334bbae56a4d"},"cell_type":"code","source":"pima=pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\npima.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cce1e262af4fe79cdd91d9c9046c4c65d2054d7"},"cell_type":"code","source":"pima.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfb59db7046de54043507d6cf543be0e34b7ec3b"},"cell_type":"markdown","source":"Veri setinde eksik bilgiye sahip özellik olmadığı ve tüm özellikler sayısal değer içerdiği için ön işleme için ölçeklendirme yapmak yeterli olacaktır."},{"metadata":{"trusted":true,"_uuid":"01698e15f95bd23e076d1710579eedef26a6b728"},"cell_type":"code","source":"X=pima.drop('Outcome',axis=1).astype(float)\nX=StandardScaler().fit_transform(X)\n\ny=pima['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bfa582b47aa7580ec8ecbe9f6e6bc53149e6210"},"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(X, \n                                                  y, \n                                                  stratify=y, \n                                                  test_size=0.2,\n                                                 random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e56574fb6ce9f4aeab93932b2ea1dd221ea6ab04"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=6.1.></a> 6.1. Derin Ağlar Oluşturma"},{"metadata":{"trusted":true,"_uuid":"a3aa4ece98c6c570f41564a56f07538db7b8d952"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d2142790d2b85dd0ee5e9bd50944f94f5e6dbe1"},"cell_type":"code","source":"model=Sequential()\nmodel.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\nmodel.add(Dense(8, kernel_initializer='uniform', activation='relu'))\nmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\nprint(\"Ağ oluşturuldu...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0773ee0a9beb0c92060dfbbdfaa973d82686e53"},"cell_type":"code","source":"model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\nprint(\"Ağ derlendi...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa2cfa10ac4c0d807313b241b8fd5eb251a81e49"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=6.2.></a> 6.2. Derin Ağ Performansının Ölçülmesi\n\nKeras ile oluşturulan derin ağ modellerinin performans ölçüleri sklearn kütüphanesinde yer alan makine öğrenmesi modellerinden biraz farklıdır. Derin ağ modellerinin performasını ölçmek için kullanılabilecek yaklaşımlar:\n\n* Klasik yaklaşımla veri setinin eğitim ve test için ayrıştırılmasıyla performans ölçümü\n* Kfold çağraz doğrulamayla performans ölçümü"},{"metadata":{"trusted":true,"_uuid":"5f16326990ab711afa3596118cf2410eb34ca56e"},"cell_type":"code","source":"model.fit(X_train, y_train,\n          epochs=150, \n          batch_size=10, \n          verbose=0)\nprint(\"Ağ eğitildi...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9523e682f765254221071b8b98ff7aed42adb3b"},"cell_type":"code","source":"scores=model.evaluate(X_test,y_test)\nprint(\"Ağ başarı oran:%{:.2f}\".format(scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d6a5d99e966fc9bce8c75b223db198578577e88"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nnumber_of_sample=len(X)\nkfold=StratifiedKFold(n_splits=5, shuffle=True, random_state=24)\ncv_scores=list()\ncounter=1\nfor train, test in kfold.split(X, y):\n    model=Sequential()\n    model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\n    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    print(\"CV{}:Ağ oluşturuldu...\".format(counter))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    print(\"CV{}:Ağ derlendi...\".format(counter))\n    model.fit(X[train], y[train],\n              epochs=150, \n              batch_size=10, \n              verbose=0)\n    print(\"CV{}:Model eğitildi..\".format(counter))\n    scores=model.evaluate(X[train],y[train])\n    print(\"CV{}:Ağ başarı oran:%{:.2f}\".format(counter, scores[1]*100))\n    cv_scores.append(scores[1]*100)\n    counter+=1\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"429043f6cc0c91b98e2e68853f809c6cf3c815ba"},"cell_type":"code","source":"print(\"Ortalam başarı oranı:%{:.2f} (+/- {:.2f})\".format(\n    np.mean(cv_scores),\n    np.std(cv_scores))) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30f0267074fbff81626f267209dd381c52da8f63"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=6.3.> </a> 6.3.Ağ Yapısının Görselleştirilmesi\n\nKeras, oluşturulan ağların görselleştirilmesine olanak sunan kütüphanelere sahip. Bu kütüphaneleri kullanarak oluşturulan ağların yapısını daha kolay kavranabilir. \n"},{"metadata":{"trusted":true,"_uuid":"eb5908bef5b9a6f9f5edc736cd937fbbad36df41"},"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\n\nplot_model(model, to_file='pima_model_plot.png', \n           show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cff60c7e3876f237365464beaea38a16fcffdc6"},"cell_type":"code","source":"pima_model_plot=plt.imread(\"../working/pima_model_plot.png\")\nplt.figure(figsize=(12,10))\nplt.xticks([])\nplt.yticks([])\nplt.imshow(pima_model_plot)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42ef8d83fb43fe477f185ed480316580622f3c8e"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=6.4.> </a> 6.4. Keras Modelinin sklearn Modeli Gibi Kullanılması: KerasClassifier\n\nKeras kütüphanesi derin öğrenme modellerinin oluşturulması için geliştirilmiş bir kütüphane olduğu için genel makine öğrenmesi modellerinin ihtiyaç duyduğu bazı fonksiyonlara sahip değildir. sklearn, python ile geliştirilen makine öğremesi uygulamaları için gerekli olan; model seçimi, ölçüm, parametre optimizasyonu, iş akışının otomatikleştirilmesi ve serileştirme gibi birçok fonksiyona sahiptir. \n\nKeras kütüphanesinden yer alan KerasClassifier  ve KerasRegressor wrapper sınıflarıyla, oluşturulan derin öğrenme modelleri sklearn modeli gibi kullanılabiliyor. "},{"metadata":{"trusted":true,"_uuid":"ce7d85afd65a833e5dd4c20416869ad4cc3f975a"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn import model_selection  \nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"930d59b38c1ded41ae8844f0bdcfa0092efa89d7"},"cell_type":"code","source":"def create_deep_net_model():\n    model=Sequential()\n    model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\n    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd764b3e597661313b05cd9a0f88dfda5c036909"},"cell_type":"code","source":"def create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(12, input_dim=8, init= 'uniform' , activation= 'relu' ))\n    model.add(Dense(8, init= 'uniform' , activation= 'relu' ))\n    model.add(Dense(1, init= 'uniform' , activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d00869a755a88981b6104e5e90558c1eafa1e9c2"},"cell_type":"code","source":"pima=pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\nX=pima.drop('Outcome',axis=1).astype(float)\n#X=StandardScaler().fit_transform(X)\n\ny=pima['Outcome']\nX_train, X_test, y_train, y_test=train_test_split(X, \n                                                  y, \n                                                  stratify=y, \n                                                  test_size=0.3,\n                                                 random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eae1e8bdbd94ed536999070f8b8f3ee8bb02f234"},"cell_type":"code","source":"model=KerasClassifier(build_fn=create_deep_net_model,nb_epoch=250,batch_size=10,verbose=0)\n\nmodel.fit(X_train, y_train)\ny_pred=model.predict(X_test)\nprint(\"KerasClassifier wrapper eğitildi...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa7eabc7cec1aaf52d23d0910fd7d3e7fe4df61f"},"cell_type":"code","source":"print(metrics.accuracy_score(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"347c807b19162000b960974dd46ecc777d2062b5"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n# <a class=\"anchor\" id=6.4.> </a> 6.4. Derin Ağların Oluşturulması: Regresyon"},{"metadata":{"trusted":true,"_uuid":"295b51041a2619553aa75466214f0a19c6659bd6"},"cell_type":"code","source":"house=pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")\nhouse.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"923951391b6ded14b4c599ab4cf55865ef35b373"},"cell_type":"code","source":"#house_data=house['sqft_living'].copy().reshape(1, -1)\nhouse_data=np.array(house['sqft_living'].astype(np.float64), dtype=pd.Series).reshape(-1,1)\nhouse_target=house['price'].copy()\n#house_data['yr_renovated']=house_data['yr_renovated'].apply(lambda x:1 if x>0 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12f0c37bc420aeccdc468a95f95558da45c30ece","_kg_hide-output":true},"cell_type":"code","source":"from keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# define wider model\ndef wider_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(3, input_dim=1, kernel_initializer= 'normal' , activation= 'relu' ))\n    model.add(Dense(1, kernel_initializer= 'normal' ))\n    # Compile model\n    model.compile(loss= 'mean_squared_error' , optimizer= 'adam' )\n    return model\n# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n# evaluate model with standardized dataset\nestimators = []\nestimators.append(( 'standardize' , StandardScaler()))\nestimators.append(( 'mlp' , KerasRegressor(build_fn=wider_model, nb_epoch=100, batch_size=5,\nverbose=0)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)\nresults = cross_val_score(pipeline, house_data, house_target, cv=kfold)\nprint(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6e615516c9a92607dfc92b9f7727ee4a8631306"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=.>4. Evrişimsel Sinir Ağları(Convolutional Neural Network(CNN))</a>\n\n..."},{"metadata":{"_uuid":"58eb48965e677e8f0360141dfc5f4a4e4028ac0c"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=5.>5. LeNet</a>\n\n..."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#LeNet için gerekli tüm kütüphaneler ortama dahil ediliyo\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f11958aa98d62e2fb768d2d530f0f6ee330ad90"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=5.1.>5.1. LeNet sınıfı</a>\n\n..."},{"metadata":{"trusted":true,"_uuid":"f27b40610de94d90be8791e62a62b7803d0238e3","_kg_hide-input":true},"cell_type":"code","source":"class LeNet:\n    def __init__(self):\n        print(\"LeNet nesnesi oluşturuldu\")\n    \n    @staticmethod\n    def build(width, height, depth, classes):\n        \"\"\"\n        width  : görüntünün genişliği\n        height : görüntünün yüksekliği\n        depth  : görüntünün renk kanalı sayısı\n        classes: sınıflandırılacak etiket sayısı\n        \"\"\"\n        \n        model=Sequential()\n        #shape first sırası\n        inputShape=(height, width, depth)\n        \n        if K.image_data_format()==\"channels_first\":\n            inputShape=(depth, height, width)\n        \n        \n        \"\"\"\n        1. Ayar İçin Ağın oluşacağı katmanlar:\n        CONV:Conv2D(20, (5,5))\n        ACTIVATION: Relu\n        POOL:MaxPooling2D(pool_size=(2, 2), strides=(2, 2)\n        \"\"\"\n        #CONV katmanı ekleniyor\n        model.add(Conv2D(20, (5,5), padding=\"same\", input_shape=inputShape))\n        \n        #Aktivasyon katmanı ekleniyor\n        model.add(Activation(\"relu\"))\n        \n        #Pool katmanı ekleniyor\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        \n        \"\"\"\n        2. Ayar İçin Ağın oluşacağı katmanlar:\n        CONV:Conv2D(50, (5,5))\n        ACTIVATION: Relu\n        POOL:MaxPooling2D(pool_size=(2, 2), strides=(2, 2)\n        \"\"\"\n        #CONV katmanı ekleniyor\n        model.add(Conv2D(50, (5,5), padding=\"same\", input_shape=inputShape))\n        \n        #Aktivasyon katmanı ekleniyor\n        model.add(Activation(\"relu\"))\n        \n        #Pool katmanı ekleniyor\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        \n        \n        model.add(Flatten())\n        model.add(Dense(500))\n        model.add(Activation(\"relu\"))\n        \n        model.add(Dense(classes))\n        model.add(Activation('softmax'))\n        \n        return model\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b6cbe365c796556f613447169e0362072ffb4eb"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=5.2.>5.2. Veri Setlerinin Yüklenmesi</a>\n\n..."},{"metadata":{"trusted":true,"_uuid":"75de59979507bb85133df97fc2768a45874d4ff4"},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0348d37468a1325c832a9dacc16869382e7dd2ec"},"cell_type":"code","source":"train=pd.read_csv(\"../input/digit-recognizer/train.csv\")\nprint(\"Train veri seti yüklendi\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d24a85bf3b492237f26ffe446991d4df69fe067"},"cell_type":"code","source":"print(\"Train veri setindeki örnek sayısı:\",train.shape[0])\nprint(\"Örneklerin özellik sayısı        :\",train.shape[1])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bb68f5395b57d752c8e3aa526ea9dcd02cb91ef"},"cell_type":"code","source":"train_data=train.drop('label', axis=1).values\ntrain_target=train['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ce18a92827533172be90cef99d94fbd825ab742"},"cell_type":"code","source":"del train\nprint(\"train nesnesi silindi\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f479a7b8a5377efdad91de2e59bbc2f8542deb7"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=5.3.>5.3. Veri Setlerinin Keras Modeline Uygun Hale Getirilmesi</a>\n\n..."},{"metadata":{"trusted":true,"_uuid":"90ede83fc99c2544a515ce7d5a022a1bef0193c6"},"cell_type":"code","source":"from keras.optimizers import SGD\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"873e23516503e666b37e52c8a270517310a1f4e0"},"cell_type":"code","source":"print(K.image_data_format())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c572a5ad9c9f99284104d5af9211c296549af922"},"cell_type":"markdown","source":"Kanal sırası channels_lat olduğu için verinin şekil biçimi: örneksayısıXsatırXsütunXderinlik olacaktır"},{"metadata":{"trusted":true,"_uuid":"2060bfb98ed7601e7eaed2ab370a76fafcd7cdf3"},"cell_type":"code","source":"train_data=train_data.reshape(train_data.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"984a994af8362f362d9f52adfc77df271717c332"},"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(train_data/255.0, \n                                                  train_target,\n                                                 test_size=0.25,\n                                                 random_state=42)\nprint(\"Veri seti eğitim ve test için ayrıştırıldı..\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c278219016732a08a8e5bc3219665e6fd2a8c635"},"cell_type":"code","source":"label_binarizer=LabelBinarizer()\ny_train=label_binarizer.fit_transform(y_train)\ny_test=label_binarizer.transform(y_test)\nprint(\"Etiketlerin OneHot kodlama dönüşümleri yapıldı...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"559a73025665b7df405dabad4e9adf3c155f3383"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=5.4.>5.4. Derin Ağların Eğitilmesi</a>\n\n..."},{"metadata":{"trusted":true,"_uuid":"127dd9b5214c8e2a99ed4fc129b08a43228758ee"},"cell_type":"code","source":"opt=SGD(lr=0.01)\nmodel=LeNet.build(width=28, height=28, depth=1, classes=10 )\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\nprint(\"Model derlendirildi...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c2e09cc2e5d36a4ca2194a863e5a3542d8fbe9b"},"cell_type":"code","source":"H=model.fit(X_train, y_train, \n            validation_data=(X_test, y_test),\n           batch_size=128, \n           epochs=20,\n           verbose=1)\nprint(\"model eğitildi...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54c68af6ccfb689dfb2335e6c5c1a7e3b1390ef4"},"cell_type":"code","source":"y_pred=model.predict(X_test,batch_size=128)\nprint(\"Tahmin yapıldı...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3514ad2096a0dbe8d8a0c648f731be037c93ef99"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=5.5.>5.5. Sınıflandırma Sonuçları</a>\n\n..."},{"metadata":{"trusted":true,"_uuid":"358f0ab0cb31bf8ea205d9660e628eeb63223d6e"},"cell_type":"code","source":"print(classification_report(y_test.argmax(axis=1),\n                           y_pred.argmax(axis=1),\n                           target_names=[str(x) for x in label_binarizer.classes_]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc0c1c9a919f9d5c7ff18e0ca9d8eab2945f79c2"},"cell_type":"markdown","source":"[İçindekiler Menüsüne Git](#0.)\n\n<a class=\"anchor\" id=6.>6. Modelin Kaydedilmesi</a>\n\n..."},{"metadata":{"_uuid":"34423d7de7f3cc2171220edfb71d0c3840c89f5c"},"cell_type":"markdown","source":"**Not: Çalışma henüz tamamlanmamıştır. Ancak yorum ve oylamaya açıktır. Tamamlanan kısmın faydalı olacağını düşündüğüm için yayımlamaya karar verdim. Yorumlarda yapılacak isteklere göre yeni konular ekleyebilir veya var olan konuları yeniden düzenleyebilirim. Yorumlarınız merakla bekliyorum. Çalışmayı beğenirseniz oylamayı unutmayın!**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}