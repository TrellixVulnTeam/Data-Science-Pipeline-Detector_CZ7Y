{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Set up environment","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# the following three lines are suggested by the fast.ai course\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# hide warnings\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the fast.ai library, used to easily build neural networks and train them\nfrom fastai import *\nfrom fastai.vision import *\nimport torchvision.models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# to get all files from a directory\nimport os\n\n# to easier work with paths\nfrom pathlib import Path\n\n# to read and manipulate .csv-files\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT = Path(\"../input/digit-recognizer\")\nos.listdir(INPUT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(INPUT/\"train.csv\")\ntrain_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(INPUT/\"test.csv\")\ntest_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN = Path(\"../train\")\nTEST = Path(\"../test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training directory\nfor index in range(10):\n    try:\n        os.makedirs(TRAIN/str(index))\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create test directory\ntry:\n    os.makedirs(TEST)\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy to reshape array from flat (1x784) to square (28x28)\nimport numpy as np\n\n# import PIL to display images and to create images from arrays\nfrom PIL import Image\n\ndef saveDigit(digit, filepath):\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n\n    img = Image.fromarray(digit)\n    img.save(filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save training images\nfor index, row in train_df.iterrows():\n    \n    label,digit = row[0], row[1:]\n    \n    folder = TRAIN/str(label)\n    filename = f\"{index}.jpg\"\n    filepath = folder/filename\n    \n    digit = digit.values\n    \n    saveDigit(digit, filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save testing images\nfor index, digit in test_df.iterrows():\n\n    folder = TEST\n    filename = f\"{index}.jpg\"\n    filepath = folder/filename\n    \n    digit = digit.values\n    \n    saveDigit(digit, filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforms\ntfms = get_transforms(do_flip=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_folder(\n    path = TRAIN,\n    test = TEST,\n    valid_pct = 0.2,\n    bs = 256,\n    size = 28,\n    num_workers = 5,\n    ds_tfms = tfms\n).normalize(mnist_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all the classes in data\nprint(data.classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet34_learn = Learner(data, torchvision.models.resnet34(pretrained=True), metrics=[error_rate, accuracy, top_k_accuracy], model_dir=\"/tmp/models\", callback_fns=ShowGraph)\nresnet_learn = Learner(data, torchvision.models.resnet50(pretrained=True), metrics=[error_rate, accuracy, top_k_accuracy], model_dir=\"/tmp/models\", callback_fns=ShowGraph)\ngooglenet_learn = Learner(data, torchvision.models.googlenet(pretrained=True), metrics=[error_rate, accuracy, top_k_accuracy], model_dir=\"/tmp/models\", callback_fns=ShowGraph)\nresnext_learn = Learner(data, torchvision.models.resnext50_32x4d(pretrained=True), metrics=[error_rate, accuracy, top_k_accuracy], model_dir=\"/tmp/models\", callback_fns=ShowGraph)\nwideres_learn = Learner(data, torchvision.models.wide_resnet50_2(pretrained=True), metrics=[error_rate, accuracy, top_k_accuracy], model_dir=\"/tmp/models\", callback_fns=ShowGraph)\nmobilenet_learn = Learner(data, torchvision.models.mobilenet_v2(pretrained=True), metrics=[error_rate, accuracy, top_k_accuracy], model_dir=\"/tmp/models\", callback_fns=ShowGraph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for learn in model:\n#     learn.lr_find()\n#     learn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nresnet34_learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nresnet_learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngooglenet_learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nresnext_learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwideres_learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmobilenet_learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = [resnet_learn, googlenet_learn, resnext_learn, wideres_learn, mobilenet_learn]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for learn in model:\n    interp = ClassificationInterpretation.from_learner(learn)\n    interp.plot_top_losses(9, figsize=(7, 7))\n    interp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageId = [int(os.path.splitext(path)[0])+1 for path in os.listdir(TEST)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = ['resnet', 'googlenet', 'resnext', 'wideres', 'mobilenet']\ni = 0\nfor learn in model:\n    class_score, y = learn.get_preds(DatasetType.Test)\n    class_score = np.argmax(class_score, axis=1)\n    submission  = pd.DataFrame({\"ImageId\": ImageId,\"Label\": class_score})\n    submission.to_csv(\"submission_\"+str(model_name[i])+\".csv\", index=False)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}