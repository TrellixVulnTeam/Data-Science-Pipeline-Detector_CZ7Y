{"cells":[{"metadata":{},"cell_type":"markdown","source":"Started on 22 May 2019"},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"* This kernel uses Convolutional Neural Network (CNN) to classify hand-drawn digits, from 1 through 9. The datasets are essentially from the famous MNIST data, which comprises 70,000 labelled images of digits.\n* In this 'Digit Recognizer' competition, there are 42,000 labelled images in the train data and 28,000 unlabelled images in the test data.\n* Before working on this prediction problem, I found it useful to read [Chris Deotte's kernels.][1] The 'Digit Recognizer' data are basically taken entirely from the 70,000 MNIST data. Hence, it is advisable not to bring in other sources of MNIST data, to avoid having your CNN model trained on the test data. The 28,000 test data should be kept unseen as much as possible.\n[1]: https://www.kaggle.com/cdeotte/mnist-perfect-100-using-knn"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examine the data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load data from csv files\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\nprint(train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['label'].value_counts(sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create arrays from dataframes\ntrain_X = train_df.drop(['label'], axis=1).values\ntrain_Y = train_df['label'].values\ntest_X = test_df.values\nprint(train_X.shape, train_Y.shape, test_X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Here are some examples of the hand-drawn digits from the train dataset:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# look at some of the digits from train_X\nplt.figure(figsize=(15,6))\nfor i in range(40):  \n    plt.subplot(4, 10, i+1)\n    plt.imshow(train_X[i].reshape((28,28)),cmap=plt.cm.binary)\n    plt.title(\"label=%d\" % train_Y[i],y=0.9)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare the data for use in CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare the data for CNN\n\n# reshape flattened data into 3D tensor\nn_x = 28\ntrain_X_digit = train_X.reshape((-1, n_x, n_x, 1))  \ntest_X_digit = test_X.reshape((-1, n_x, n_x, 1))    # similarly for test set\nprint(train_X_digit.shape, test_X_digit.shape)\n\n# standardize the values in the datasets by dividing by 255\ntrain_X_digit = train_X_digit / 255.\ntest_X_digit = test_X_digit / 255.\n\n# one-hot encode the labels in train_Y\nfrom keras.utils.np_utils import to_categorical\nonehot_labels = to_categorical(train_Y)\nprint(onehot_labels.shape)\nprint(train_Y[181], onehot_labels[181])\nplt.figure(figsize=(1,1))\nplt.imshow(train_X[181].reshape((28,28)),cmap=plt.cm.binary)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create CNN Model"},{"metadata":{},"cell_type":"markdown","source":"* Thanks to [Shay Guterman][1] for providing inputs on improving the model.\n[1]: https://www.kaggle.com/shaygu/fast-cnn-for-beginners-0-9945"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use Keras data generator to augment the training set\n\nfrom keras_preprocessing.image import ImageDataGenerator\ndata_augment = ImageDataGenerator(rotation_range=10, zoom_range=0.1, \n                                 width_shift_range=0.1, height_shift_range=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the CNN from keras\nfrom keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, kernel_size=5, padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(rate=0.4))\nmodel.add(layers.Conv2D(64, kernel_size=5, activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(rate=0.4))\nmodel.add(layers.Conv2D(128, kernel_size=3, activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(rate=0.4))\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set a learning rate annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',patience=3,factor=0.5,min_lr=0.00001,\n                                           verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* set up a validation set to check the performance of the CNN."},{"metadata":{"trusted":true},"cell_type":"code","source":"# set up a dev set (5000 samples) to check the performance of the CNN\nX_dev = train_X_digit[:5000]\nrem_X_train = train_X_digit[5000:]\nprint(X_dev.shape, rem_X_train.shape)\n\nY_dev = onehot_labels[:5000]\nrem_Y_train = onehot_labels[5000:]\nprint(Y_dev.shape, rem_Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Run the model using the train and validation datasets, and capture histories to visualise the performance."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Train and validate the model\nepochs = 30\nbatch_size = 128\nhistory = model.fit_generator(data_augment.flow(rem_X_train, rem_Y_train, batch_size=batch_size), \n                              epochs=epochs, steps_per_epoch=rem_X_train.shape[0]//batch_size, \n                              validation_data=(X_dev, Y_dev), callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# plot and visualise the training and validation losses\nloss = history.history['loss']\ndev_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\nfrom matplotlib import pyplot as plt\nplt.plot(epochs, loss, 'bo', label='training loss')\nplt.plot(epochs, dev_loss, 'b', label='validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Error Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# do error analysis on the predictions for X_dev\npred_dev = model.predict(X_dev)\npred_dev_labels = np.argmax(pred_dev, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at those that were classified wrongly in X_dev\nresult = pd.DataFrame(train_Y[:5000], columns=['Y_dev'])\nresult['Y_pred'] = pred_dev_labels\nresult['correct'] = result['Y_dev'] - result['Y_pred']\nerrors = result[result['correct'] != 0]\nerror_list = errors.index\nprint('Number of errors is ', len(errors))\nprint('The indices are ', error_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# plot the image of the wrong in predictions for X_dev\nplt.figure(figsize=(15,10))\nfor i in range(len(error_list)):\n    plt.subplot(6, 10, i+1)\n    plt.imshow(X_dev[error_list[i]].reshape((28,28)),cmap=plt.cm.binary)\n    plt.title(\"true={}\\npredict={}\".format(train_Y[error_list[i]], \n                                           pred_dev_labels[error_list[i]]), y=0.9)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at those that were predicted wrongly, I see that there are quite several difficult and ambiguous ones. If the validation set is also representative of those in the test set (28,000), I would think it improbable that an accuracy of 100% can be attained."},{"metadata":{},"cell_type":"markdown","source":"# Make Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict on test set\npredictions = model.predict(test_X_digit)\nprint(predictions.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set the predicted labels to be the one with the highest probability\npredicted_labels = np.argmax(predictions, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Here are some examples of the predictions made:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# look at some of the predictions for test_X\nplt.figure(figsize=(15,6))\nfor i in range(40):  \n    plt.subplot(4, 10, i+1)\n    plt.imshow(test_X[i].reshape((28,28)),cmap=plt.cm.binary)\n    plt.title(\"predict=%d\" % predicted_labels[i],y=0.9)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Looks good...."},{"metadata":{"trusted":true},"cell_type":"code","source":"# create submission file\nresult = pd.read_csv('../input/sample_submission.csv')\nresult['Label'] = predicted_labels\n# generate submission file in csv format\nresult.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}