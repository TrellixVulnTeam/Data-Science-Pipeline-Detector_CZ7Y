{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-04T20:34:35.712138Z","iopub.execute_input":"2022-03-04T20:34:35.712654Z","iopub.status.idle":"2022-03-04T20:34:39.803983Z","shell.execute_reply.started":"2022-03-04T20:34:35.712526Z","shell.execute_reply":"2022-03-04T20:34:39.803199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nsubmission_df = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:39.805913Z","iopub.execute_input":"2022-03-04T20:34:39.806185Z","iopub.status.idle":"2022-03-04T20:34:45.115491Z","shell.execute_reply.started":"2022-03-04T20:34:39.806148Z","shell.execute_reply":"2022-03-04T20:34:45.114761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Getting general idea about the dataset","metadata":{}},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.118693Z","iopub.execute_input":"2022-03-04T20:34:45.118896Z","iopub.status.idle":"2022-03-04T20:34:45.126164Z","shell.execute_reply.started":"2022-03-04T20:34:45.118871Z","shell.execute_reply":"2022-03-04T20:34:45.12551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.127222Z","iopub.execute_input":"2022-03-04T20:34:45.127911Z","iopub.status.idle":"2022-03-04T20:34:45.154968Z","shell.execute_reply.started":"2022-03-04T20:34:45.127875Z","shell.execute_reply":"2022-03-04T20:34:45.154304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.157019Z","iopub.execute_input":"2022-03-04T20:34:45.157328Z","iopub.status.idle":"2022-03-04T20:34:45.162608Z","shell.execute_reply.started":"2022-03-04T20:34:45.157294Z","shell.execute_reply":"2022-03-04T20:34:45.161821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.164143Z","iopub.execute_input":"2022-03-04T20:34:45.164634Z","iopub.status.idle":"2022-03-04T20:34:45.188234Z","shell.execute_reply.started":"2022-03-04T20:34:45.164596Z","shell.execute_reply":"2022-03-04T20:34:45.187337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.189518Z","iopub.execute_input":"2022-03-04T20:34:45.189912Z","iopub.status.idle":"2022-03-04T20:34:45.197022Z","shell.execute_reply.started":"2022-03-04T20:34:45.189875Z","shell.execute_reply":"2022-03-04T20:34:45.195407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.199777Z","iopub.execute_input":"2022-03-04T20:34:45.200247Z","iopub.status.idle":"2022-03-04T20:34:45.210114Z","shell.execute_reply.started":"2022-03-04T20:34:45.200209Z","shell.execute_reply":"2022-03-04T20:34:45.209259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Splitting training data into training and validation data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:45.211919Z","iopub.execute_input":"2022-03-04T20:34:45.212424Z","iopub.status.idle":"2022-03-04T20:34:46.085139Z","shell.execute_reply.started":"2022-03-04T20:34:45.21239Z","shell.execute_reply":"2022-03-04T20:34:46.084413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the features and target column for training dataset\ntrain_x = train_df.drop('label',axis=1)\ntrain_y = train_df.label\nval_x = val_df.drop('label',axis=1)\nval_y = val_df.label\ntrain_y.head()\ntrain_x.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:46.086484Z","iopub.execute_input":"2022-03-04T20:34:46.086736Z","iopub.status.idle":"2022-03-04T20:34:46.187034Z","shell.execute_reply.started":"2022-03-04T20:34:46.086702Z","shell.execute_reply":"2022-03-04T20:34:46.186346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling the dataset","metadata":{}},{"cell_type":"code","source":"train_x = train_x/255\nval_x = val_x/255\ntest_df = test_df/255","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:46.18831Z","iopub.execute_input":"2022-03-04T20:34:46.188582Z","iopub.status.idle":"2022-03-04T20:34:46.368048Z","shell.execute_reply.started":"2022-03-04T20:34:46.188547Z","shell.execute_reply":"2022-03-04T20:34:46.367198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Neural network With no hidden layers","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.Dense(10, input_shape=(784,),activation = 'sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:46.369606Z","iopub.execute_input":"2022-03-04T20:34:46.369881Z","iopub.status.idle":"2022-03-04T20:34:49.462878Z","shell.execute_reply.started":"2022-03-04T20:34:46.369835Z","shell.execute_reply":"2022-03-04T20:34:49.461985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compiling the model","metadata":{}},{"cell_type":"markdown","source":"Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n\n* Loss function —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n* Optimizer —This is how the model is updated based on the data it sees and its loss function.\n* Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam',\n             loss = 'sparse_categorical_crossentropy',\n             metrics = ['accuracy'])\n# Fitting the model with\nmodel.fit(train_x,train_y,epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:34:49.464125Z","iopub.execute_input":"2022-03-04T20:34:49.464936Z","iopub.status.idle":"2022-03-04T20:35:31.295894Z","shell.execute_reply.started":"2022-03-04T20:34:49.464899Z","shell.execute_reply":"2022-03-04T20:35:31.295118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets check if our model predicts the first digit correctly\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:31.299634Z","iopub.execute_input":"2022-03-04T20:35:31.299846Z","iopub.status.idle":"2022-03-04T20:35:31.30373Z","shell.execute_reply.started":"2022-03-04T20:35:31.299822Z","shell.execute_reply":"2022-03-04T20:35:31.30274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To visualise the image it has to be reshaped into (28,28) pixel grid\nplt.matshow(np.array(train_x.loc[0]).reshape(28,28))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:31.305173Z","iopub.execute_input":"2022-03-04T20:35:31.305549Z","iopub.status.idle":"2022-03-04T20:35:31.582569Z","shell.execute_reply.started":"2022-03-04T20:35:31.305404Z","shell.execute_reply":"2022-03-04T20:35:31.58177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(train_x)\nprediction[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:31.586909Z","iopub.execute_input":"2022-03-04T20:35:31.587267Z","iopub.status.idle":"2022-03-04T20:35:32.971746Z","shell.execute_reply.started":"2022-03-04T20:35:31.587225Z","shell.execute_reply":"2022-03-04T20:35:32.971081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(prediction[0])\nprediction_label = [np.argmax(i) for i in prediction]","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:32.972968Z","iopub.execute_input":"2022-03-04T20:35:32.973205Z","iopub.status.idle":"2022-03-04T20:35:33.073524Z","shell.execute_reply.started":"2022-03-04T20:35:32.97317Z","shell.execute_reply":"2022-03-04T20:35:33.07286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We see that our model has predicted 1 and it matches the input","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:33.074756Z","iopub.execute_input":"2022-03-04T20:35:33.075111Z","iopub.status.idle":"2022-03-04T20:35:33.078963Z","shell.execute_reply.started":"2022-03-04T20:35:33.075075Z","shell.execute_reply":"2022-03-04T20:35:33.077916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualising the accuracy of the model\ncm = tf.math.confusion_matrix(labels=train_y,predictions = prediction_label)\nimport seaborn as sns\nsns.heatmap(cm,annot=True,fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:33.080709Z","iopub.execute_input":"2022-03-04T20:35:33.081038Z","iopub.status.idle":"2022-03-04T20:35:33.886133Z","shell.execute_reply.started":"2022-03-04T20:35:33.080975Z","shell.execute_reply":"2022-03-04T20:35:33.88546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Hidden Layer","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout\nmodel = keras.Sequential([\n    Dense(100, input_shape=(784,), activation='relu'),\n      \n                    Dropout(0.2),\n                    Dense(10, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:33.887826Z","iopub.execute_input":"2022-03-04T20:35:33.888304Z","iopub.status.idle":"2022-03-04T20:35:33.915095Z","shell.execute_reply.started":"2022-03-04T20:35:33.888267Z","shell.execute_reply":"2022-03-04T20:35:33.914462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" the network consists of a sequence of two tf.keras.layers.Dense layers. These are densely connected, or fully connected, neural layers. The first Dense layer has 128 nodes (or neurons). The second (and last) layer is a 10-node softmax layer that returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:33.916123Z","iopub.execute_input":"2022-03-04T20:35:33.916351Z","iopub.status.idle":"2022-03-04T20:35:33.92731Z","shell.execute_reply.started":"2022-03-04T20:35:33.91632Z","shell.execute_reply":"2022-03-04T20:35:33.926581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r=model.fit(train_x, train_y, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:33.929866Z","iopub.execute_input":"2022-03-04T20:35:33.930046Z","iopub.status.idle":"2022-03-04T20:35:55.133585Z","shell.execute_reply.started":"2022-03-04T20:35:33.930024Z","shell.execute_reply":"2022-03-04T20:35:55.132619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(val_x,val_y)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:55.135027Z","iopub.execute_input":"2022-03-04T20:35:55.135267Z","iopub.status.idle":"2022-03-04T20:35:56.02982Z","shell.execute_reply.started":"2022-03-04T20:35:55.135233Z","shell.execute_reply":"2022-03-04T20:35:56.029065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(train_x)\nprediction_label = [np.argmax(i) for i in prediction]\n# Visualising the accuracy of the model\ncm = tf.math.confusion_matrix(labels=train_y,predictions = prediction_label)\nimport seaborn as sns\nsns.heatmap(cm,annot=True,fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:56.031031Z","iopub.execute_input":"2022-03-04T20:35:56.031321Z","iopub.status.idle":"2022-03-04T20:35:58.565956Z","shell.execute_reply.started":"2022-03-04T20:35:56.031283Z","shell.execute_reply":"2022-03-04T20:35:58.564216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# predict = model.predict(test_df)\n# predict_label = predict.argmax(axis=1)\n# ImageID = np.arange(len(predict))+1\n# Out = pd.DataFrame([ImageID,predict_label]).T\n# Out.rename(columns = {0:'ImageId', 1:'Label'})\n# #Out\n# Out.to_csv('submission.csv', header =  ['ImageId', 'Label' ], index = None)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:58.568459Z","iopub.execute_input":"2022-03-04T20:35:58.568711Z","iopub.status.idle":"2022-03-04T20:35:58.57204Z","shell.execute_reply.started":"2022-03-04T20:35:58.568682Z","shell.execute_reply":"2022-03-04T20:35:58.571346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DOING IT THE CNN WAY","metadata":{}},{"cell_type":"markdown","source":"### I have created the CNN notebook as a seperate unit but still adding it here to maintain continuity. I have repeated some introductory steps, this is just to demonstrate how the CNN differs and how to do it.","metadata":{}},{"cell_type":"code","source":"# Loading the dataset\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:35:58.573415Z","iopub.execute_input":"2022-03-04T20:35:58.573902Z","iopub.status.idle":"2022-03-04T20:36:02.511129Z","shell.execute_reply.started":"2022-03-04T20:35:58.573865Z","shell.execute_reply":"2022-03-04T20:36:02.510362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.512644Z","iopub.execute_input":"2022-03-04T20:36:02.513128Z","iopub.status.idle":"2022-03-04T20:36:02.521941Z","shell.execute_reply.started":"2022-03-04T20:36:02.513091Z","shell.execute_reply":"2022-03-04T20:36:02.521035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.523316Z","iopub.execute_input":"2022-03-04T20:36:02.523634Z","iopub.status.idle":"2022-03-04T20:36:02.588176Z","shell.execute_reply.started":"2022-03-04T20:36:02.523594Z","shell.execute_reply":"2022-03-04T20:36:02.587507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.591906Z","iopub.execute_input":"2022-03-04T20:36:02.592474Z","iopub.status.idle":"2022-03-04T20:36:02.620265Z","shell.execute_reply.started":"2022-03-04T20:36:02.592419Z","shell.execute_reply":"2022-03-04T20:36:02.619605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the target and features for the dataset\ny_train = train['label']\nx_train = train.drop('label',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.623986Z","iopub.execute_input":"2022-03-04T20:36:02.624326Z","iopub.status.idle":"2022-03-04T20:36:02.714115Z","shell.execute_reply.started":"2022-03-04T20:36:02.624283Z","shell.execute_reply":"2022-03-04T20:36:02.713306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.718569Z","iopub.execute_input":"2022-03-04T20:36:02.71916Z","iopub.status.idle":"2022-03-04T20:36:02.747656Z","shell.execute_reply.started":"2022-03-04T20:36:02.719122Z","shell.execute_reply":"2022-03-04T20:36:02.746606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modifiying the dataset for CNN\n","metadata":{}},{"cell_type":"markdown","source":"Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.<br>\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","metadata":{}},{"cell_type":"code","source":"# Scaling the values from 0 to 255   to   0 to 1\nx_train = x_train/255.0\ntest = test/255.0\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.751772Z","iopub.execute_input":"2022-03-04T20:36:02.75202Z","iopub.status.idle":"2022-03-04T20:36:02.943923Z","shell.execute_reply.started":"2022-03-04T20:36:02.751986Z","shell.execute_reply":"2022-03-04T20:36:02.943196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.946259Z","iopub.execute_input":"2022-03-04T20:36:02.946742Z","iopub.status.idle":"2022-03-04T20:36:02.952613Z","shell.execute_reply.started":"2022-03-04T20:36:02.946703Z","shell.execute_reply":"2022-03-04T20:36:02.951853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x_train[4],cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:02.954163Z","iopub.execute_input":"2022-03-04T20:36:02.954543Z","iopub.status.idle":"2022-03-04T20:36:03.140885Z","shell.execute_reply.started":"2022-03-04T20:36:02.954507Z","shell.execute_reply":"2022-03-04T20:36:03.140187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the CNN Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPool2D","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:03.14202Z","iopub.execute_input":"2022-03-04T20:36:03.142734Z","iopub.status.idle":"2022-03-04T20:36:03.14929Z","shell.execute_reply.started":"2022-03-04T20:36:03.142697Z","shell.execute_reply":"2022-03-04T20:36:03.148584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:03.150696Z","iopub.execute_input":"2022-03-04T20:36:03.151083Z","iopub.status.idle":"2022-03-04T20:36:03.207423Z","shell.execute_reply.started":"2022-03-04T20:36:03.151043Z","shell.execute_reply":"2022-03-04T20:36:03.20678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first layer is the convolutional layer. I set 32 filters for the two layers with a kernel size of (5 x 5).\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe next layer after these two is the pooling layer.The pooling layers are used in CNN for consolidating the features learned by the convolutional layer feature map. It basically helps in the reduction of overfitting by the time of training of the model by compressing or generalizing the features in the feature map.\n\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n\nNext is the dropout layer.Dropout is a regularization method that approximates training a large number of neural networks with different architectures in parallel.\n\nDuring training, some number of layer outputs are randomly ignored or “dropped out.” This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, each update to a layer during training is performed with a different “view” of the configured layer.\n\nIn a neural network, the activation function is responsible for transforming the summed weighted input from the node into the activation of the node or output for that input.\n\nThe rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.\n\nFlattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',\n             loss = 'sparse_categorical_crossentropy',\n             metrics=['accuracy'])\nmodel.fit(x_train,y_train,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:03.208752Z","iopub.execute_input":"2022-03-04T20:36:03.209008Z","iopub.status.idle":"2022-03-04T20:36:50.560925Z","shell.execute_reply.started":"2022-03-04T20:36:03.208972Z","shell.execute_reply":"2022-03-04T20:36:50.560229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(test[0].reshape(1,28,28,1)).argmax()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:50.562184Z","iopub.execute_input":"2022-03-04T20:36:50.562427Z","iopub.status.idle":"2022-03-04T20:36:50.66013Z","shell.execute_reply.started":"2022-03-04T20:36:50.562394Z","shell.execute_reply":"2022-03-04T20:36:50.65948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test[0],cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T20:36:50.661294Z","iopub.execute_input":"2022-03-04T20:36:50.661549Z","iopub.status.idle":"2022-03-04T20:36:50.846992Z","shell.execute_reply.started":"2022-03-04T20:36:50.661513Z","shell.execute_reply":"2022-03-04T20:36:50.846296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We clearly see the CNN model performing better, as was expected in the case of images. It is basically a modification in front of the already existing ANN,being able to create the vectors in a much better , reliable and efficient way.","metadata":{}},{"cell_type":"markdown","source":"# UPVOTE If you liked the work.","metadata":{}}]}