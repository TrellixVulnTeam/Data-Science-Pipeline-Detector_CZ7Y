{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"# source: https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055\n!pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:04:48.103407Z","iopub.execute_input":"2022-02-18T13:04:48.103817Z","iopub.status.idle":"2022-02-18T13:05:00.67144Z","shell.execute_reply.started":"2022-02-18T13:04:48.103767Z","shell.execute_reply":"2022-02-18T13:05:00.670319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn, optim\n\nimport timm\n\nfrom skimage import transform\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:00.674209Z","iopub.execute_input":"2022-02-18T13:05:00.674571Z","iopub.status.idle":"2022-02-18T13:05:04.733557Z","shell.execute_reply.started":"2022-02-18T13:05:00.674523Z","shell.execute_reply":"2022-02-18T13:05:04.732126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('[INFO] Training Mode:')\ntrain_on_gpu = torch.cuda.is_available()\nif not train_on_gpu:\n    print('\\t->  Training on CPU')\nelse:\n    print('\\t-> Training on GPU')\n    device = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:04.735523Z","iopub.execute_input":"2022-02-18T13:05:04.735839Z","iopub.status.idle":"2022-02-18T13:05:04.797468Z","shell.execute_reply.started":"2022-02-18T13:05:04.735793Z","shell.execute_reply":"2022-02-18T13:05:04.796451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"print('[INFO] Total Models:', len(timm.list_models()))\nprint('[INFO] Total Models pre-trained:', len(timm.list_models(pretrained=True)))\n# print('[INFO] List Models pre-trained')\n# timm.list_models(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:04.802599Z","iopub.execute_input":"2022-02-18T13:05:04.802854Z","iopub.status.idle":"2022-02-18T13:05:04.823087Z","shell.execute_reply.started":"2022-02-18T13:05:04.80282Z","shell.execute_reply":"2022-02-18T13:05:04.821799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pretrained = timm.create_model('resnet50d', \n                                     pretrained=True,       # model pre trained\n                                     in_chans=1,            # number of channel\n                                     num_classes =10,       # number of class\n                                     global_pool = 'max')   # pooling\nx = torch.randn(1, 1, 224, 224)\nprint(f'[INFO] Final dimension: {model_pretrained(x).shape}')\n\nprint('[INFO] Config')\nmodel_pretrained","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:04.827449Z","iopub.execute_input":"2022-02-18T13:05:04.827816Z","iopub.status.idle":"2022-02-18T13:05:11.867629Z","shell.execute_reply.started":"2022-02-18T13:05:04.827781Z","shell.execute_reply":"2022-02-18T13:05:11.866343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('[INFO] Model from TIMM')\nmodel_pretrained.default_cfg","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:11.870135Z","iopub.execute_input":"2022-02-18T13:05:11.870809Z","iopub.status.idle":"2022-02-18T13:05:11.881718Z","shell.execute_reply.started":"2022-02-18T13:05:11.870763Z","shell.execute_reply":"2022-02-18T13:05:11.880519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\nprint('[INFO] Train shape:', train.shape)\nprint('[INFO] DataFrame:')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:11.883735Z","iopub.execute_input":"2022-02-18T13:05:11.884566Z","iopub.status.idle":"2022-02-18T13:05:15.86777Z","shell.execute_reply.started":"2022-02-18T13:05:11.884519Z","shell.execute_reply":"2022-02-18T13:05:15.866257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\nprint('[INFO] Test shape:', test.shape)\nprint('[INFO] DataFrame:')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:15.869414Z","iopub.execute_input":"2022-02-18T13:05:15.870157Z","iopub.status.idle":"2022-02-18T13:05:18.258707Z","shell.execute_reply.started":"2022-02-18T13:05:15.870097Z","shell.execute_reply":"2022-02-18T13:05:18.257527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treatments","metadata":{}},{"cell_type":"code","source":"X_train = train.drop('label', axis=1).values.reshape(-1, 1, 28, 28).astype('float32')\ny_train = train.label.values.astype(np.float32)\nprint('[INFO] Train shape:', X_train.shape)\n\nX_test = test.values.reshape(-1, 1, 28, 28).astype('float32')\nprint('\\n[INFO] Test shape:', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:18.262214Z","iopub.execute_input":"2022-02-18T13:05:18.262469Z","iopub.status.idle":"2022-02-18T13:05:18.492469Z","shell.execute_reply.started":"2022-02-18T13:05:18.262438Z","shell.execute_reply":"2022-02-18T13:05:18.491303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('[INFO] Normalization')\nX_train = X_train/ 225 \nX_test = X_test/ 225","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:18.497143Z","iopub.execute_input":"2022-02-18T13:05:18.497458Z","iopub.status.idle":"2022-02-18T13:05:18.589529Z","shell.execute_reply.started":"2022-02-18T13:05:18.497415Z","shell.execute_reply":"2022-02-18T13:05:18.588515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                  test_size = 0.2, \n                                                  random_state = 42,\n                                                  stratify = y_train)\n\nprint('[INFO] Split data:')\nfor i, j in zip([X_train, X_val, y_train, y_val], ['X_train', 'X_val', 'y_train', 'y_val']):\n    print(f'\\t-> {j}: {i.shape} | {i.dtype}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:18.591252Z","iopub.execute_input":"2022-02-18T13:05:18.591771Z","iopub.status.idle":"2022-02-18T13:05:18.946906Z","shell.execute_reply.started":"2022-02-18T13:05:18.591724Z","shell.execute_reply":"2022-02-18T13:05:18.945812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresTrain = torch.from_numpy(X_train)\ntargetsTrain = torch.from_numpy(y_train).type(torch.LongTensor) \n\nfeaturesVal = torch.from_numpy(X_val)\ntargetsVal = torch.from_numpy(y_val).type(torch.LongTensor) \n\nfeaturesTest = torch.from_numpy(X_test)\n\nprint('[INFO] Shapes:')\nvet_01 = [featuresTrain, targetsTrain, \n          featuresVal, targetsVal,\n          featuresTest]\nvet_02 = ['featuresTrain', 'targetsTrain', \n          'featuresVal', 'targetsVal',\n          'featuresTest']\nfor i, j in zip(vet_01, vet_02):\n    print(f'\\t-> {j}: {i.shape} | {i.dtype}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:18.948388Z","iopub.execute_input":"2022-02-18T13:05:18.948806Z","iopub.status.idle":"2022-02-18T13:05:18.95919Z","shell.execute_reply.started":"2022-02-18T13:05:18.948753Z","shell.execute_reply":"2022-02-18T13:05:18.958147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"print('[INFO] Build tensors')\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\nval = torch.utils.data.TensorDataset(featuresVal,targetsVal)\n# test = torch.utils.data.TensorDataset(featuresTest)\n#test = torch.tensor(featuresTest)\ntest = featuresTest.clone().detach().requires_grad_(True)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:12:53.292951Z","iopub.execute_input":"2022-02-18T13:12:53.293409Z","iopub.status.idle":"2022-02-18T13:12:53.364403Z","shell.execute_reply.started":"2022-02-18T13:12:53.293347Z","shell.execute_reply":"2022-02-18T13:12:53.363259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data loader\nprint('[INFO] Build data loader')\nBATCH_SIZE = 200\n\ntrain_loader = torch.utils.data.DataLoader(train,\n                                    batch_size = BATCH_SIZE, \n                                    shuffle = False)\nval_loader = torch.utils.data.DataLoader(val,\n                                  batch_size = BATCH_SIZE, \n                                  shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test,\n                                   batch_size = BATCH_SIZE, \n                                   shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:12:56.024849Z","iopub.execute_input":"2022-02-18T13:12:56.025735Z","iopub.status.idle":"2022-02-18T13:12:56.037432Z","shell.execute_reply.started":"2022-02-18T13:12:56.025694Z","shell.execute_reply":"2022-02-18T13:12:56.03442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.cnn = model_pretrained\n\n    def forward(self, x):\n        x = self.cnn(x)\n        return x\n\nmodel = Net()\nprint(model)\n\nif train_on_gpu:\n    model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:18.989648Z","iopub.execute_input":"2022-02-18T13:05:18.990625Z","iopub.status.idle":"2022-02-18T13:05:22.128236Z","shell.execute_reply.started":"2022-02-18T13:05:18.990572Z","shell.execute_reply":"2022-02-18T13:05:22.127248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Train(train_loader, model, criterion, optimizer):\n        \n    # Parameters\n    train_loss = 0\n    train_acc = 0\n    size = len(train_loader.dataset)\n    num_batches = len(train_loader)\n    \n    # switch to train mode\n    model.train()\n    \n    for batch_size, (X, y) in enumerate(train_loader):\n        \n        # GPU\n        if train_on_gpu:\n            X = X.cuda()\n            y = y.cuda()\n        \n        # Clear the gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        forward_pass = model(X)\n        \n        # Calculate the loss\n        loss = criterion(forward_pass, y)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        # sum correct predictions\n        y_pred = torch.argmax(forward_pass, axis=1)\n        y_true = y.long().squeeze()\n        \n        train_acc += (y_pred == y_true).type(torch.float).sum().item()\n        train_loss += loss.item()\n           \n    # Log\n    train_acc /= size # epoch accuracy\n    train_loss /= num_batches # epoch loss\n#     print('[INFO] Train:')\n#     print(f'\\t-> Accuracy: {(100*train_acc):.4f} %') \n#     print(f'\\t-> Avg loss: {train_loss:.4f}')\n    \n    return train_acc, train_loss\n  ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:22.12998Z","iopub.execute_input":"2022-02-18T13:05:22.130377Z","iopub.status.idle":"2022-02-18T13:05:22.140398Z","shell.execute_reply.started":"2022-02-18T13:05:22.130331Z","shell.execute_reply":"2022-02-18T13:05:22.139342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Validate(val_loader, model, criterion, optimizer):\n        \n    # Parameters\n    val_loss = 0\n    val_acc = 0\n    size = len(val_loader.dataset)\n    num_batches = len(val_loader)\n    \n    # switch to evaluation mode\n    model.eval()\n    \n    for batch_size, (X, y) in enumerate(val_loader):\n        \n        # GPU\n        if train_on_gpu:\n            X = X.cuda()\n            y = y.cuda()\n            \n        # Forward pass\n        forward_pass = model(X)\n        \n        # Calculate the loss\n        loss = criterion(forward_pass, y)\n        \n        # sum correct predictions\n        y_pred = torch.argmax(forward_pass, axis=1)\n        y_true = y.long().squeeze()\n        \n        val_acc += (y_pred == y_true).type(torch.float).sum().item()\n        val_loss += loss.item()\n\n    # Log\n    val_acc /= size # epoch accuracy\n    val_loss /= num_batches # epoch loss\n#     print('[INFO] Validation:')\n#     print(f'\\t-> Accuracy: {(100*val_acc):.4f} %') \n#     print(f'\\t-> Avg loss: {val_loss:.4f}')\n    \n    return val_acc, val_loss","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:22.142085Z","iopub.execute_input":"2022-02-18T13:05:22.142615Z","iopub.status.idle":"2022-02-18T13:05:22.156608Z","shell.execute_reply.started":"2022-02-18T13:05:22.142563Z","shell.execute_reply":"2022-02-18T13:05:22.155286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                 mode = 'min',\n                                                 patience = 5,\n                                                 verbose = True,\n                                                 factor = 0.8)\nepochs = 150\n\nval_loss_min = np.Inf\nearly_patience = 30\nepochs_no_improve = 0\n\nhist_train_acc = []\nhist_val_acc = []\nhist_train_loss = []\nhist_val_loss = []\nhist_lr = []\n\nbest_model_epoch = 0\nbest_model_acc = 0\nbest_model_loss = 0\n\nverbose = 10\n\nlearning_decay = True\n\nprint('[INFO] Training...')\nfor epoch in range(1, epochs+1):\n    \n    train_acc, train_loss = Train(train_loader, model, criterion, optimizer)\n    val_acc, val_loss = Validate(val_loader, model, criterion, optimizer)\n    \n    if learning_decay:\n        scheduler.step(val_loss)\n    \n    for param_group in optimizer.param_groups:\n        hist_lr.append(param_group['lr'])\n        \n    hist_train_acc.append(train_acc)\n    hist_val_acc.append(val_acc)\n    hist_train_loss.append(train_loss)\n    hist_val_loss.append(val_loss)\n    \n    if (epoch == 1) or (epoch % verbose == 0) or (val_loss < val_loss_min):\n        print(f'\\n#################### EPOCH {epoch} ####################')\n        print('[INFO] Train:')\n        print(f'\\t-> Accuracy: {(100*train_acc):.4f} %') \n        print(f'\\t-> Avg loss: {train_loss:.5f}')\n \n        print('[INFO] Validation:')\n        print(f'\\t-> Accuracy: {(100*val_acc):.4f} %') \n        print(f'\\t-> Avg loss: {val_loss:.5f}')\n        \n    if val_loss < val_loss_min:\n        val_loss_min = val_loss\n        epochs_no_improve = 0\n        best_model_epoch = epoch\n        best_model_acc = val_acc\n        best_model_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pt')\n        print('[INFO] Network improvement, saving current model')\n    else:\n        epochs_no_improve += 1\n    \n    if epoch > 5 and epochs_no_improve >= early_patience:\n        print('\\n',' '*20 , '~ END ~')\n        print('\\n[WARNING] Early Stopping')\n        print('[INFO] Best Model (validation):')\n        print(f'\\t-> Epoch: {best_model_epoch}')\n        print(f'\\t-> Accuracy: {(100*best_model_acc):.4f} %') \n        print(f'\\t-> Avg loss: {best_model_loss:.5f}')\n        break\n    else:\n        continue\n\nif epoch == epochs:\n    print('\\n',' '*20 , '~ END ~')\n    print('\\n[INFO] Best Model (validation):')\n    print(f'\\t-> Epoch: {best_model_epoch}')\n    print(f'\\t-> Accuracy: {(100*best_model_acc):.4f} %') \n    print(f'\\t-> Avg loss: {best_model_loss:.5f}')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:05:22.158465Z","iopub.execute_input":"2022-02-18T13:05:22.159083Z","iopub.status.idle":"2022-02-18T13:07:54.932312Z","shell.execute_reply.started":"2022-02-18T13:05:22.159013Z","shell.execute_reply":"2022-02-18T13:07:54.931271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # CNN model training\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters())\n\n# epochs = 10\n# valid_loss_min = np.Inf\n# train_losses, valid_losses = [], []\n# history_accuracy = []\n# h_acc = []\n\n# for e in range(1, epochs+1):\n#     running_loss = 0\n#     acc = 0\n\n#     for images, labels in train_loader:\n#         if train_on_gpu:\n#             images, labels = images.cuda(), labels.cuda()\n#         # Clear the gradients, do this because gradients are accumulated.\n#         optimizer.zero_grad()\n        \n#         # Forward pass, get our log-probabilities.\n#         ps = model(images)\n\n#         # Calculate the loss with the logps and the labels.\n#         loss = criterion(ps, labels)\n        \n#         # Turning loss back.\n#         loss.backward()\n        \n#         # Take an update step and few the new weights.\n#         optimizer.step()\n        \n#         running_loss += loss.item()\n        \n#         # Capturing the class more likely.\n#         _, top_class = ps.topk(1, dim=1)\n                \n#         # Verifying the prediction with the labels provided.\n#         equals = top_class == labels.view(*top_class.shape)\n          \n#         acc += torch.mean(equals.type(torch.FloatTensor))\n        \n#     else:\n#         valid_loss = 0\n#         accuracy = 0\n        \n#         # Turn off gradients for validation, saves memory and computations.\n#         with torch.no_grad():\n#             model.eval() # change the network to evaluation mode\n#             for images, labels in val_loader:\n#                 if train_on_gpu:\n#                     images, labels = images.cuda(), labels.cuda()\n#                 # Forward pass, get our log-probabilities.\n#                 #log_ps = model(images)\n#                 ps = model(images)\n                \n#                 # Calculating probabilities for each class.\n#                 #ps = torch.exp(log_ps)\n                \n#                 # Capturing the class more likely.\n#                 _, top_class = ps.topk(1, dim=1)\n                \n#                                 # Verifying the prediction with the labels provided.\n#                 equals = top_class == labels.view(*top_class.shape)\n                \n#                 valid_loss += criterion(ps, labels).item()\n#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n                \n#         model.train() # change the network to training mode\n        \n#         train_losses.append(running_loss/len(train_loader))\n#         valid_losses.append(valid_loss/len(val_loader))\n#         history_accuracy.append(accuracy/len(val_loader))\n#         h_acc.append(acc/len(train_loader))\n        \n#         network_learned = valid_loss < valid_loss_min\n\n#         if e == 1 or e % 5 == 0 or network_learned:\n#             print(f\"Epoch: {e}/{epochs}.. \",\n#                   f\"Training Loss: {running_loss/len(train_loader):.4f}.. \",\n#                   f\"Training Accuracy: {acc/len(train_loader):.4f}.. \",\n#                   f\"Validation Loss: {valid_loss/len(val_loader):.4f}.. \",\n#                   f\"Validation Accuracy: {accuracy/len(val_loader):.4f}\")\n            \n#         if network_learned:\n#             valid_loss_min = valid_loss\n#             torch.save(model.state_dict(), 'model_mtl_mnist.pt')\n#             print('Detected network improvement, saving current model')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:07:54.934362Z","iopub.execute_input":"2022-02-18T13:07:54.935185Z","iopub.status.idle":"2022-02-18T13:07:54.944843Z","shell.execute_reply.started":"2022-02-18T13:07:54.935135Z","shell.execute_reply":"2022-02-18T13:07:54.94379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing training information\ne = [i for i in range(1, epoch+1)]\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\nfig.suptitle('Metrics')\n\nax1.plot(e, hist_train_acc, label = 'Train')\nax1.plot(e, hist_val_acc, label = 'Validation')\nax1.axvline(x = best_model_epoch, color='red', linestyle='--')\n# ax1.axhline(y = best_model_acc, color='red', linestyle='--')\nax1.set_title('Model Accuracy')\nax1.set(xlabel ='Epoch', ylabel='Accuracy')\nax1.legend()\n\nax2.plot(e, hist_train_loss, label ='Train')\nax2.plot(e, hist_val_loss, label ='Validation')\nax2.axvline(x = best_model_epoch, color='red', linestyle='--')\n# ax2.axhline(y = best_model_loss, color='red', linestyle='--')\nax2.set_title('Model Loss')\nax2.set(xlabel ='Epoch', ylabel='Loss')\nax2.legend()\n\nax3.plot(e, hist_lr, label ='Learning Rate')\nax3.axvline(x = best_model_epoch, color='red', linestyle='--')\nax3.set_title('Model Learning Rate')\nax3.set(xlabel ='Epoch', ylabel='Learning Rate')\nax3.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:07:54.946204Z","iopub.execute_input":"2022-02-18T13:07:54.947017Z","iopub.status.idle":"2022-02-18T13:07:55.555499Z","shell.execute_reply.started":"2022-02-18T13:07:54.946967Z","shell.execute_reply":"2022-02-18T13:07:55.554503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('best_model.pt'))\n\n# print(model)\n\n# model = Net()\n# print(model)\n\n# if train_on_gpu:\n#     model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:07:55.556947Z","iopub.execute_input":"2022-02-18T13:07:55.558211Z","iopub.status.idle":"2022-02-18T13:07:55.562791Z","shell.execute_reply.started":"2022-02-18T13:07:55.558162Z","shell.execute_reply":"2022-02-18T13:07:55.561579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    return np.exp(x)/np.sum(np.exp(x), axis=1)[:, None]\n\ndef Inference(test_loader, model):\n    \n    # Parameters\n    size = len(test_loader.dataset)\n    num_batches = len(test_loader)\n    predictions = []\n    \n    model = Net()\n    if train_on_gpu:\n        model.cuda()\n        \n    model.load_state_dict(torch.load('best_model.pt'))\n    \n    # switch to evaluation mode\n    model.eval()\n    \n    with torch.no_grad():\n        for batch_size, X in enumerate(test_loader):\n        \n            # GPU\n            if train_on_gpu:\n                X = X.cuda()\n\n            # Forward pass\n            forward_pass = model(X)\n\n            # Predcitions\n            y_pred = softmax(forward_pass.detach().cpu().numpy())\n            y_pred = np.argmax(y_pred, axis=1)\n\n            predictions.append(y_pred)\n            \n    print('[INFO] Inferences')        \n    inferences = np.concatenate(predictions, axis=0)\n    \n    return inferences\n\ndef Submission(inferences):\n    submission = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\n    submission['Label'] =  inferences\n    submission.to_csv(\"submission.csv\",index=False)\n    print('[INFO] Submission Complete')\n    print(submission.head(10))\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:15:12.905222Z","iopub.execute_input":"2022-02-18T13:15:12.905519Z","iopub.status.idle":"2022-02-18T13:15:12.916924Z","shell.execute_reply.started":"2022-02-18T13:15:12.905488Z","shell.execute_reply":"2022-02-18T13:15:12.91558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preditions = Inference(test_loader, model)\nSubmission(preditions)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:15:14.98099Z","iopub.execute_input":"2022-02-18T13:15:14.982087Z","iopub.status.idle":"2022-02-18T13:15:19.461352Z","shell.execute_reply.started":"2022-02-18T13:15:14.982016Z","shell.execute_reply":"2022-02-18T13:15:19.459087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # def softmax(x):\n# #     return np.exp(x)/np.sum(np.exp(x), axis=1)[:, None]\n\n# submission = [['ImageId', 'Label']]\n# model.load_state_dict(torch.load('best_model.pt'))\n\n# with torch.no_grad():\n#     model.eval()\n#     image_id = 1\n\n#     for images in test_loader:\n#         if train_on_gpu:\n#             image = images.cuda()\n#         log_ps = model(image)\n#         ps = torch.exp(log_ps)\n#         top_p, top_class = ps.topk(1, dim=1)\n        \n#         for prediction in top_class:\n#             submission.append([image_id, prediction.item()])\n#             image_id += 1\n            \n# print(len(submission) - 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:13:04.550691Z","iopub.execute_input":"2022-02-18T13:13:04.55098Z","iopub.status.idle":"2022-02-18T13:13:09.389594Z","shell.execute_reply.started":"2022-02-18T13:13:04.550948Z","shell.execute_reply":"2022-02-18T13:13:09.388416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import csv\n\n# with open('submission.csv', 'w') as submissionFile:\n#     writer = csv.writer(submissionFile)\n#     writer.writerows(submission)\n    \n# print('[INFO] Submission Complete')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:07:55.959719Z","iopub.status.idle":"2022-02-18T13:07:55.960527Z","shell.execute_reply.started":"2022-02-18T13:07:55.960191Z","shell.execute_reply":"2022-02-18T13:07:55.960229Z"},"trusted":true},"execution_count":null,"outputs":[]}]}