{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of content \n* Panda\n* Numpy \n* [Matplotlib](https://matplotlib.org/)\n* [Seaborn](https://seaborn.pydata.org/)\n* [Eigen Value](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html)\n* [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n* [t-SNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n* Conclusion","metadata":{}},{"cell_type":"markdown","source":"# Dataset description\n* The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n* Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.\n* Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker\n* This pixel-value is an integer between 0 and 255, inclusive.\n* The training data set, (train.csv), has 785 columns.\n* The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n* Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive.\n* To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. \n* Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nImage('../input/image-digit/mnist-3.0.1.png')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pawry time - Bring out all the Library ","metadata":{}},{"cell_type":"code","source":"Image('../input/minions/minions.jpg')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mnist Dataset ","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('../input/digit-recognizer/train.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv('../input/digit-recognizer/test.csv')\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Size and shape of the dataset ","metadata":{}},{"cell_type":"code","source":"train.shape","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Columns descriptions\n* There are 785 columns \n","metadata":{}},{"cell_type":"code","source":"train.columns","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropping the columns in  order to obtains the insight ","metadata":{}},{"cell_type":"code","source":"l=train['label']\ntrain_df=train.drop(\"label\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l.shape, train_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization \n* Imshow- Helps us to show the image","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nidx = 1\n\ngrid_data = train_df.iloc[idx].to_numpy().reshape(28,28)  # reshape from 1d to 2d pixel array\nplt.imshow(grid_data, interpolation = \"none\", cmap = \"gray\")\nplt.show()\n\nprint(l[idx])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nidx = 3\n\ngrid_data = train_df.iloc[idx].to_numpy().reshape(28,28)  # reshape from 1d to 2d pixel array\nplt.imshow(grid_data, interpolation = \"none\", cmap = \"gray\")\nplt.show()\n\nprint(l[idx])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2D Visualization using PCA\n* Principal Component Analysis(PCA), is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n* the idea of PCA is simple â€” reduce the number of variables of a data set, while preserving as much information as possible.\n# STEP BY STEP EXPLANATION OF PCA\n* STEP 1: STANDARDIZATION\n* STEP 2: COVARIANCE MATRIX COMPUTATION\n* STEP 3: COMPUTE THE EIGENVECTORS AND EIGENVALUES OF THE COVARIANCE MATRIX\n* STEP-4: IDENTIFY THE PRINCIPAL COMPONENTS\n* STEP 5: FEATURE VECTOR\n* STEP 6: VISUALIZE THE FEATURE","metadata":{}},{"cell_type":"code","source":"\nlabels=l.head(15000)\ndata=train_df.head(15000)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standarization of the feature ","metadata":{}},{"cell_type":"code","source":"# Data-preprocessing: Standardizing the data\n\nfrom sklearn.preprocessing import StandardScaler\nstandarized_data=StandardScaler().fit_transform(data)\nprint(standarized_data.shape)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Covariance Matrix ","metadata":{}},{"cell_type":"code","source":"sample_data=standarized_data\n\ncovar_matrix=np.matmul(sample_data.T,sample_data)\n\nprint(\"the shape of variance matrix\",covar_matrix.shape)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Two eigen-values and corresponding eigen-vectors](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html) \n* As we can visualize only 2D data .\n* It is not possible to visualize the more number of dimension data\n* The purpose is to visalize the data and identify the digits","metadata":{}},{"cell_type":"code","source":"from scipy.linalg import eigh\n\n# the parameter 'eigvals' is defined (low value to heigh value) \n# eigh function will return the eigen values in asending order\n# this code generates only the top 2 (782 and 783) eigenvalues.\n\nvalues, vectors=eigh(covar_matrix, eigvals=(782,783))\n\nprint(\"Shape of eigen values\", vectors.shape)\nvectors=vectors.T\n\nprint(\"updated shape of eigen vector\", vectors.shape)\n\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Projecting the original data sample on the plane \n* Formed by two principal eigen vectors by vector-vector multiplication.\n* **Appending label to the 2d projected data**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nnew_coordinates = np.matmul(vectors, sample_data.T)\n\nprint (\" resultanat new data points' shape \", vectors.shape, \"X\", sample_data.T.shape,\" = \", new_coordinates.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# appending label to the 2d projected data\nnew_coordinates = np.vstack((new_coordinates, labels)).T\n\n# creating a new data frame for ploting the labeled points.\ndataframe = pd.DataFrame(data=new_coordinates, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\nprint(dataframe.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame()\ndf[\"1st\"]=[-5.558661,-5.043558,6.193635 ,19.305278]\ndf[\"2nd\"]=[-1.558661,-2.043558,2.193635 ,9.305278]\ndf['label']=[1,2,3,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Seaborn](https://seaborn.pydata.org/)","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.FacetGrid(df, hue=\"label\", size=10).map(plt.scatter,'1st','2nd').add_legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Obs** - The visualization is not that good","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=\"1st\",y=\"2nd\",hue=\"label\", data=df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ploting the 2d data points with seaborn\n* [Seaborn](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html)\n","metadata":{}},{"cell_type":"code","source":"sns.FacetGrid(dataframe,hue=\"label\", size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference** -\n* We can visualize the datset \n* But it is not that claer\n* 0s and 9's are well separated \n* But rest are overlapping with each other\n* PCA helps us to reduce the dimension \n* But the visulization is not upto that label for higher dimension \n* That's why We gonna use T-SNE \n * [PCA vs t-SNE](https://www.kaggle.com/questions-and-answers/237497)","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=\"1st_principal\", y=\"2nd_principal\", legend=\"full\", hue=\"label\", data=dataframe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation \n* Insted of calculating as done above we can follow eassy steps\n* As mentioned down below\n* Eassy PCA implementation ","metadata":{}},{"cell_type":"markdown","source":"#  [PCA using Scikit-Learn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n* [DIfference between PCS and t-SNE](https://www.kaggle.com/questions-and-answers/237497)","metadata":{}},{"cell_type":"code","source":"# initializing the pca\n\nfrom sklearn import decomposition \npca=decomposition.PCA()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# configuring the parameteres\n# the number of components = 2\n\npca.n_components=2\npca_data=pca.fit_transform(sample_data)\n\nprint(\"shape of PCA reduced shape\", pca_data.shape)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # [t-SNE using Scikit-Learn](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n \n","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\ndata_1000=standarized_data[0:1000,:]\nlabel_1000=labels[0:1000]\n\nmodel=TSNE(n_components=2,random_state=0)\n# configuring the parameteres\n# the number of components = 2\n# default perplexity = 30\n# default learning rate = 200\n# default Maximum number of iterations for the optimization = 1000\n\ntsne_data=model.fit_transform(data_1000)\n\ntsne_data=np.vstack((tsne_data.T, label_1000)).T\ntsne_df=pd.DataFrame(data=tsne_data,columns=(\"dim_1\",\"dim_2\", \"label\"))\n\nsns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, \"dim_1\",\"dim_2\").add_legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=TSNE(n_components=2, random_state=0, perplexity=50)\ntsne_data=model.fit_transform(data_1000)\n\n# creating a new data fram which help us in ploting the result data\ntsne_data=np.vstack((tsne_data.T, label_1000)).T\ntsne_df=pd.DataFrame(data=tsne_data, columns=(\"Dim_1\",\"Dim_2\", \"label\"))\n\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter,\"Dim_1\",\"Dim_2\").add_legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Change perplexity value","metadata":{}},{"cell_type":"code","source":"#with different perplexity\nmodel=TSNE(n_components=2, random_state=0, perplexity=30)\ntsne_data=model.fit_transform(data_1000)\n\n# creating a new data fram which help us in ploting the result data\ntsne_data=np.vstack((tsne_data.T, label_1000)).T\ntsne_df=pd.DataFrame(data=tsne_data, columns=(\"Dim_1\",\"Dim_2\", \"label\"))\n\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter,\"Dim_1\",\"Dim_2\").add_legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with different perplexity\nmodel=TSNE(n_components=2, random_state=0, perplexity=10)\ntsne_data=model.fit_transform(data_1000)\n\n# creating a new data fram which help us in ploting the result data\ntsne_data=np.vstack((tsne_data.T, label_1000)).T\ntsne_df=pd.DataFrame(data=tsne_data, columns=(\"Dim_1\",\"Dim_2\", \"label\"))\n\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter,\"Dim_1\",\"Dim_2\").add_legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with different perplexity\nmodel=TSNE(n_components=2, random_state=0, perplexity=5)\ntsne_data=model.fit_transform(data_1000)\n\n# creating a new data fram which help us in ploting the result data\ntsne_data=np.vstack((tsne_data.T, label_1000)).T\ntsne_df=pd.DataFrame(data=tsne_data, columns=(\"Dim_1\",\"Dim_2\", \"label\"))\n\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter,\"Dim_1\",\"Dim_2\").add_legend()\nplt.title(\"With Perplexity 5\")\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with different perplexity\nmodel=TSNE(n_components=2, random_state=0, perplexity=80)\ntsne_data=model.fit_transform(data_1000)\n\n# creating a new data fram which help us in ploting the result data\ntsne_data=np.vstack((tsne_data.T, label_1000)).T\ntsne_df=pd.DataFrame(data=tsne_data, columns=(\"Dim_1\",\"Dim_2\", \"label\"))\n\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter,\"Dim_1\",\"Dim_2\").add_legend()\nplt.title(\"With Perplexity 80\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n* Perplexity is Hyper parameters \n* With different Perplexity we encounter the different visualization\n* Here is the some useful resources \n* [Resource 1](https://ranasinghiitkgp.medium.com/t-sne-visualization-of-high-dimension-mnist-dataset-48fb23d1bafd)\n* [Resorce 2](https://distill.pub/2016/misread-tsne/)","metadata":{}},{"cell_type":"code","source":"Image('../input/thank-you/download.jpg', height=1000, width=1000)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}