{"metadata":{"_is_fork":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"_change_revision":0,"language_info":{"file_extension":".py","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"nbformat":4,"cells":[{"metadata":{"_uuid":"08a21c40904049fb5690c9f16fc54e2c99b58e24","_cell_guid":"14985282-5eef-d712-9728-8a43129bb914"},"cell_type":"markdown","source":"CNN with tensorflow"},{"metadata":{"_uuid":"a7d9c060ac51018f26f01dfebd462c57f30cd099","_cell_guid":"74cae7dd-1227-a4d8-e217-6505173ac8d0","_execution_state":"idle","collapsed":true},"execution_count":null,"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt, matplotlib.image as mpimg\nimport matplotlib.cm as cm\n%matplotlib inline","outputs":[]},{"metadata":{"_uuid":"a9bee7690bfff76e9bd15c4824e428bff491b558","_cell_guid":"2ce9748f-8e6d-1528-2b76-4c011342439d","_execution_state":"idle"},"execution_count":null,"cell_type":"code","source":"\n# neural network structure for this sample:\n#\n# · · · · · · · · · ·      (input data, 1-deep)                    X [batch, 28, 28, 1]\n# @ @ @ @ @ @ @ @ @ @   -- conv. layer +BN 6x6x1=>24 stride 1      W1 [5, 5, 1, 24]        B1 [24]\n# ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                              Y1 [batch, 28, 28, 6]\n#   @ @ @ @ @ @ @ @     -- conv. layer +BN 5x5x6=>48 stride 2      W2 [5, 5, 6, 48]        B2 [48]\n#   ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                                Y2 [batch, 14, 14, 12]\n#     @ @ @ @ @ @       -- conv. layer +BN 4x4x12=>64 stride 2     W3 [4, 4, 12, 64]       B3 [64]\n#     ∶∶∶∶∶∶∶∶∶∶∶                                                  Y3 [batch, 7, 7, 24] => reshaped to YY [batch, 7*7*24]\n#      \\x/x\\x\\x/ ✞      -- fully connected layer (relu+dropout+BN) W4 [7*7*24, 200]       B4 [200]\n#       · · · ·                                                    Y4 [batch, 200]\n#       \\x/x\\x/         -- fully connected layer (softmax)         W5 [200, 10]           B5 [10]\n#        · · ·                                                     Y [batch, 10]\nlabeled_images = pd.read_csv('../input/train.csv')\nprint(\"there are {} total images\".format(labeled_images.shape))","outputs":[]},{"metadata":{"_uuid":"5daff6031448204ffa71e00eb7869549e1a27d0d","_cell_guid":"d4d33507-8177-4f26-976f-1326759156e5","_execution_state":"idle","scrolled":true},"execution_count":null,"cell_type":"code","source":"img_num = 10000\ntrain_num = 7000\nval_num = 3000\ntest_num = 3000\n\nimages = labeled_images.iloc[0:img_num,1:]\nwidth = height = np.ceil(np.sqrt(images.shape[1])).astype(np.uint8)\nimages = np.reshape(np.array(images), (-1, width, height, 1))\nprint(images.shape)","outputs":[]},{"metadata":{"_uuid":"3ebb0df822914498fbb9e3b746f16485a227e43d","_cell_guid":"89ba49eb-d6f9-4789-b762-83e0a4582a91"},"execution_count":null,"cell_type":"code","source":"def dense_to_one_hot(labels_dense, num_classes):\n  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n  num_labels = labels_dense.shape[0]\n  index_offset = np.arange(num_labels) * num_classes\n  labels_one_hot = np.zeros((num_labels, num_classes))\n  labels_one_hot.flat[index_offset + np.array(labels_dense).ravel()] = 1\n  return labels_one_hot\n\nlabels = labeled_images.iloc[0:img_num,:1]\nlabels_count = np.unique(labels).shape[0]\nprint(\"There are {} labels.\".format(labels_count))\n\nlabels = dense_to_one_hot(labels, labels_count)\nprint(labels[230])\nprint(labels.shape)","outputs":[]},{"metadata":{"_uuid":"2190652a980058ba8e63b25993a6e20af7c6d88a","_cell_guid":"e685c570-7e4c-40dc-8d25-2cc1fa497829"},"execution_count":null,"cell_type":"code","source":"train_images, test_images,train_labels, test_labels = train_test_split(images, labels, train_size=0.7, random_state=0)","outputs":[]},{"metadata":{"_uuid":"94d61fa1867621b661d8d697375e8654eb0b57a6","_cell_guid":"bb68088d-145d-4813-b729-f1f333dfb00d","_execution_state":"idle"},"execution_count":null,"cell_type":"code","source":"# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\nX = tf.placeholder(tf.float32, [None, 28, 28, 1])\n# correct answers will go here\nY_ = tf.placeholder(tf.float32, [None, 10])\n# variable learning rate\nlr = tf.placeholder(tf.float32)\n# dropout probability\npkeep = tf.placeholder(tf.float32)\n\n","outputs":[]},{"metadata":{"_uuid":"56e4ff9f507defb586ce0ab3b19a3aa1e3b8fa8d","_cell_guid":"f4dd8901-395f-48b0-9902-3e8933c84e8c","_execution_state":"idle","collapsed":true},"execution_count":null,"cell_type":"code","source":"# three convolutional layers with their channel counts, and a\n# fully connected layer (the last layer has 10 softmax neurons)\n# try another value(24, 48, 64, 200)\nK = 6  # first convolutional layer output depth 24\nL = 12  # second convolutional layer output depth 48\nM = 24  # third convolutional layer 64\nN = 200  # fully connected layer 200\n\nW1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1))  # 6x6 patch, 1 input channel, K output channels\nB1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\nW2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1))\nB2 = tf.Variable(tf.constant(0.1, tf.float32, [L]))\nW3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1))\nB3 = tf.Variable(tf.constant(0.1, tf.float32, [M]))\n\nW4 = tf.Variable(tf.truncated_normal([7 * 7 * M, N], stddev=0.1))\nB4 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\nW5 = tf.Variable(tf.truncated_normal([N, 10], stddev=0.1))\nB5 = tf.Variable(tf.constant(0.1, tf.float32, [10]))","outputs":[]},{"metadata":{"_uuid":"b7b5850370a8e2c0757036a9ec2c9c69327484a1","_cell_guid":"24d41009-e9e6-4a21-9a70-bf74f570856e","_execution_state":"idle"},"execution_count":null,"cell_type":"code","source":"# The model\nstride = 1  # output is 28x28\nY1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\nstride = 2  # output is 14x14\nY2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\nstride = 2  # output is 7x7\nY3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n\n# reshape the output from the third convolution for the fully connected layer\nYY = tf.reshape(Y3, shape=[-1, 7 * 7 * M])\n\nY4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\nYY4 = tf.nn.dropout(Y4, pkeep)\nYlogits = tf.matmul(YY4, W5) + B5\nY = tf.nn.softmax(Ylogits)","outputs":[]},{"metadata":{"_uuid":"62cdda45749cafa11b5cd152da723559b06f82c8","_cell_guid":"c4480d17-e2ff-490e-b86f-8d29f680153f","_execution_state":"idle"},"execution_count":null,"cell_type":"code","source":"# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n# problems with log(0) which is NaN\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\ncross_entropy = tf.reduce_mean(cross_entropy)*100\n# accuracy of the trained model, between 0 (worst) and 1 (best)\ncorrect_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))","outputs":[]},{"metadata":{"_uuid":"7d2661f61a17e0e45afb38da815d3f58373e8d2a","_cell_guid":"12f976de-8d3a-4e7c-9cf5-e41272ef2cca","_execution_state":"idle","collapsed":true},"execution_count":null,"cell_type":"code","source":"# matplotlib visualisation\n#allweights = tf.concat([tf.reshape(W1, [-1]), tf.reshape(W2, [-1]), tf.reshape(W3, [-1]), tf.reshape(W4, [-1]), tf.reshape(W5, [-1])], 0)\n#allbiases  = tf.concat([tf.reshape(B1, [-1]), tf.reshape(B2, [-1]), tf.reshape(B3, [-1]), tf.reshape(B4, [-1]), tf.reshape(B5, [-1])], 0)\n#I = tensorflowvisu.tf_format_mnist_images(X, Y, Y_)\n#It = tensorflowvisu.tf_format_mnist_images(X, Y, Y_, 1000, lines=25)\n#datavis = tensorflowvisu.MnistDataVis()\n\n# training step, the learning rate is a placeholder\ntrain_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n","outputs":[]},{"metadata":{"_uuid":"c6c202d0a99d4b7669df0db4e610e82c0d6878ce","_cell_guid":"333a8217-8e91-4fbb-be73-ffe7270e594f","_execution_state":"idle","collapsed":true},"execution_count":null,"cell_type":"code","source":"# init\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\n# You can call this function in a loop to train the model, 100 images at a time\ndef training_step(i, update_test_data, update_train_data):\n\n    # training on batches of 100 images with 100 labels\n    batch_X, batch_Y = train_images[i*100:(i+1)*100], train_labels[i*100:(i+1)*100]\n\n    # learning rate decay\n    max_learning_rate = 0.003\n    min_learning_rate = 0.0001\n    decay_speed = 2000.0\n    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * np.exp(-i/decay_speed)\n\n    # compute training values for visualisation\n    if update_train_data:\n        a, c, im, w, b = sess.run([accuracy, cross_entropy], {X: batch_X, Y_: batch_Y, pkeep: 0.75})\n        print(str(i) + \": accuracy:\" + str(a) + \" loss: \" + str(c) + \" (lr:\" + str(learning_rate) + \")\")\n        #datavis.append_training_curves_data(i, a, c)\n        #datavis.update_image1(im)\n        #datavis.append_data_histograms(i, w, b)\n\n    # compute test values for visualisation\n    if update_test_data:\n        a, c, im = sess.run([accuracy, cross_entropy], {X: test_images, Y_: test_labels, pkeep: 1.0})\n        print(str(i) + \": ********* epoch \" + str(i*100//mnist.train.images.shape[0]+1) + \" ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n        #datavis.append_test_curves_data(i, a, c)\n        #datavis.update_image2(im)\n        \n   # the backpropagation training step\n    sess.run(train_step, {X: batch_X, Y_: batch_Y, lr: learning_rate, tst: False, pkeep: 0.75, pkeep_conv: 1.0})\n    sess.run(update_ema, {X: batch_X, Y_: batch_Y, tst: False, iter: i, pkeep: 1.0, pkeep_conv: 1.0})\n\n#datavis.animate(training_step, 10001, train_data_update_freq=20, test_data_update_freq=100)\n","outputs":[]},{"metadata":{"_uuid":"1285aa089fec66133f2c9388f9a9e4ba5bee47bb","_cell_guid":"cdb8f504-7517-443c-a786-a42ff309aa8a","_execution_state":"idle"},"execution_count":null,"cell_type":"code","source":"\n# to save the animation as a movie, add save_movie=True as an argument to datavis.animate\n# to disable the visualisation use the following line instead of the datavis.animate line\nfor i in range(10000+1): \n    training_step(i, i % 100 == 0, i % 20 == 0)\n\n#print(\"max test accuracy: \" + str(datavis.get_max_test_accuracy()))","outputs":[]},{"metadata":{"_uuid":"26c4d5f41ab796294075459e251ddb96eef9458f","_cell_guid":"602764ac-de8d-429e-b93e-a6662de564ab","_execution_state":"idle","collapsed":true},"execution_count":null,"cell_type":"code","source":"","outputs":[]}],"nbformat_minor":1}