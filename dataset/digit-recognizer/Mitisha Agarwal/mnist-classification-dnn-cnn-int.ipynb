{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing & Importing Packages","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T09:18:14.041175Z","iopub.execute_input":"2022-05-24T09:18:14.041537Z","iopub.status.idle":"2022-05-24T09:18:14.06336Z","shell.execute_reply.started":"2022-05-24T09:18:14.041461Z","shell.execute_reply":"2022-05-24T09:18:14.062728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.losses as losses\nimport tensorflow.keras.metrics as metrics\nfrom keras import layers, models\n\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, InputLayer, Softmax, Flatten, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomZoom\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.metrics import Accuracy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.datasets import mnist\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:18:14.069206Z","iopub.execute_input":"2022-05-24T09:18:14.06991Z","iopub.status.idle":"2022-05-24T09:18:20.604458Z","shell.execute_reply.started":"2022-05-24T09:18:14.069874Z","shell.execute_reply":"2022-05-24T09:18:20.603707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ndf_test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\n# Removing and storing the class labels in another variable\nY = df_train['label']\ndf_train.drop([\"label\"], axis=1, inplace=True)\n\nprint(df_train.shape, df_test.shape, Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:18:20.606062Z","iopub.execute_input":"2022-05-24T09:18:20.606308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(60000, -1)\nx_test = x_test.reshape(10000, -1)\ndf_train = np.concatenate([df_train, x_train, x_test], axis = 0)\nY = np.concatenate([Y, y_train, y_test], axis = 0)\nprint(df_train.shape, Y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing & Processing the Data","metadata":{}},{"cell_type":"code","source":"# Scaling the pixel values to be between 0 and 1\ndf_train = df_train.astype('float32')\ndf_test = df_test.astype('float32')\ndf_train = df_train / 255\ndf_test = df_test / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The image is having dimensions 28*28\nim_dim = 28\n\n# Reshaping the dataset, so that we can display the individual images, and model them\ndf_train = tf.reshape(df_train, (-1, im_dim, im_dim, 1))\ndf_test = tf.reshape(df_test, (-1, im_dim, im_dim, 1))\nprint(df_train.shape, df_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(5, 5, figsize = (6,6))\naxes = axes.ravel()\n\nfor i in np.arange(0,25):\n    axes[i].imshow(df_train[i])\n    axes[i].axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model","metadata":{}},{"cell_type":"code","source":"# Defining some of the key parameters\nnum_classes = 10\nbatch_size = 128\nepochs = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (28, 28, 1)\n\nmodel = tf.keras.Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),padding='same',activation='relu',input_shape=input_shape))\nmodel.add(Conv2D(32,kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(64,kernel_size=(3, 3),activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = tf.keras.Sequential(layers = [\n#     Conv2D(filters=64, kernel_size=5, activation=\"relu\", padding='Same', input_shape=(28, 28, 1)),\n#     BatchNormalization(),\n    \n#     Conv2D(filters=64, kernel_size=5, activation=\"relu\", padding='Same'),\n#     BatchNormalization(),\n#     MaxPool2D(pool_size=(2, 2)),\n#     Dropout(rate=0.25),\n    \n#     Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='Same'),\n#     BatchNormalization(),\n    \n#     Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='Same'),\n#     BatchNormalization(),\n#     MaxPool2D(pool_size=(2, 2), strides=(2,2)),\n#     Dropout(rate=0.25),\n    \n#     Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='Same'),\n#     BatchNormalization(),\n#     Dropout(rate=0.25),\n    \n#     Flatten(),\n#     Dense(256, activation=\"relu\"),\n#     BatchNormalization(),\n#     Dropout(rate=0.25),\n#     Dense(10, activation=\"softmax\")\n# ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the Adam Optimizer\n# sgd = SGD(lr=2e-2, decay=1e-6, momentum=0.9)\nrms = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Defining the callbacks\nreduce_lr = ReduceLROnPlateau(\n    monitor = 'val_acc', factor = 0.5, patience = 3, \n    min_lr = 1e-5, verbose = 1\n)\n# early_st = EarlyStopping(\n#     monitor='val_loss', min_delta=1e-3,\n#     patience=5, verbose=1, restore_best_weights=True, mode = 'min'\n# )\n\n# Compiling the model\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=rms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the class labels into one-hot form\nY_oh = to_categorical(Y, num_classes=num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using real-time Data Augmentation\ndatagen = ImageDataGenerator(\n    featurewise_center = False, samplewise_center=False, featurewise_std_normalization = False,\n    samplewise_std_normalization = False, rotation_range = 10, zoom_range = 0.1,\n    width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = False, \n    vertical_flip=False,  validation_split = 0.1\n)\ndatagen.fit(df_train)\n\ntrain_generator = datagen.flow(df_train, Y_oh, batch_size = batch_size, subset='training')\nval_generator = datagen.flow(df_train, Y_oh, batch_size = batch_size, subset = 'validation')\n\n# Training the model using generators\nhistory = model.fit(\n    train_generator, batch_size = batch_size,\n    epochs = epochs, verbose = 1, validation_data = val_generator,\n    steps_per_epoch = df_train.shape[0] // batch_size,\n    use_multiprocessing = True, callbacks = [reduce_lr]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Without using any augmentation\n# model.fit(\n#     df_train, Y_oh, batch_size = batch_size,\n#     epochs = epochs, verbose = 1, validation_split = 0.2,\n#     use_multiprocessing = True, callbacks = [reduce_lr]\n# )","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(1,2, figsize=(15,8))\nfig.suptitle(\"The model 's evaluation \",fontsize=20)\naxes[0].plot(history.history['loss'])\naxes[0].plot(history.history['val_loss'])\naxes[0].set_title('Model Loss')\naxes[0].set_ylabel('Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train','Test'])\n\n\naxes[1].plot(history.history['accuracy'])\naxes[1].plot(history.history['val_accuracy'])\naxes[1].set_title('Model Accuracy')\naxes[1].set_ylabel('Accuracy')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train','Test'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(df_train)\ny_pred = np.argmax(y_pred, axis = 1)\nacc = metrics.Accuracy()\nprint(acc(Y, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"y_sub = model.predict(df_test)\ny_sub = tf.math.argmax(y_sub, axis = 1)\ny_sub = pd.Series(y_sub)\nprint(y_sub.shape, type(y_sub))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\ndf_sub.loc[ : , 'Label'] = y_sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}