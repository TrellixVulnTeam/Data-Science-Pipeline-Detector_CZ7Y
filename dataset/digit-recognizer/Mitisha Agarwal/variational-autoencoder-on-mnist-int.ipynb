{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries and Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom keras.datasets import mnist\n\nfrom scipy.stats import norm\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nfrom keras.models import Model\nfrom keras import metrics\nfrom keras import backend as K \n\nnp.random.seed(237)\nK.clear_session()\n\nfrom tensorflow.python.framework.ops import disable_eager_execution\n\ndisable_eager_execution()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:25.368361Z","iopub.execute_input":"2022-05-25T10:09:25.368675Z","iopub.status.idle":"2022-05-25T10:09:27.651751Z","shell.execute_reply.started":"2022-05-25T10:09:25.368615Z","shell.execute_reply":"2022-05-25T10:09:27.651024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ndf_test = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\n\ndf_train.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-25T10:09:27.656456Z","iopub.execute_input":"2022-05-25T10:09:27.657101Z","iopub.status.idle":"2022-05-25T10:09:31.4496Z","shell.execute_reply.started":"2022-05-25T10:09:27.657059Z","shell.execute_reply":"2022-05-25T10:09:31.448923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:35.377322Z","iopub.execute_input":"2022-05-25T10:09:35.378121Z","iopub.status.idle":"2022-05-25T10:09:35.393208Z","shell.execute_reply.started":"2022-05-25T10:09:35.378083Z","shell.execute_reply":"2022-05-25T10:09:35.392447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Droping the labels column \ny_train = df_train['label']\ndf_train = df_train.drop(['label'], axis = 1)\n# print(df_train.head())\n\n# Droping the labels column \ny_test = df_test['label']\ndf_test = df_test.drop(['label'], axis = 1)\nprint(df_test.head())\ny_test.dtype","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:16:13.182379Z","iopub.execute_input":"2022-05-25T10:16:13.182706Z","iopub.status.idle":"2022-05-25T10:16:13.188098Z","shell.execute_reply.started":"2022-05-25T10:16:13.182653Z","shell.execute_reply":"2022-05-25T10:16:13.187402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing and reshaping\n\ndf_train = df_train.values.reshape(-1, 28, 28, 1)/255.0\ndf_test = df_test.values.reshape(-1, 28, 28, 1)/255.0","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:16:37.671692Z","iopub.execute_input":"2022-05-25T10:16:37.672406Z","iopub.status.idle":"2022-05-25T10:16:37.696426Z","shell.execute_reply.started":"2022-05-25T10:16:37.672368Z","shell.execute_reply":"2022-05-25T10:16:37.695405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = y_test/1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:16:50.143416Z","iopub.execute_input":"2022-05-25T10:16:50.144038Z","iopub.status.idle":"2022-05-25T10:16:50.148519Z","shell.execute_reply.started":"2022-05-25T10:16:50.143999Z","shell.execute_reply":"2022-05-25T10:16:50.147545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the dataset","metadata":{}},{"cell_type":"code","source":"plt.figure(1)\nplt.subplot(221)\nplt.imshow(df_train[13][:,:,0])\n\nplt.subplot(222)\nplt.imshow(df_train[690][:,:,0])\n\nplt.subplot(223)\nplt.imshow(df_train[2375][:,:,0])\n\nplt.subplot(224)\nplt.imshow(df_train[4213][:,:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:45.505601Z","iopub.execute_input":"2022-05-25T10:09:45.506306Z","iopub.status.idle":"2022-05-25T10:09:45.843Z","shell.execute_reply.started":"2022-05-25T10:09:45.506267Z","shell.execute_reply":"2022-05-25T10:09:45.842323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\nIn VAEs, **instead of encoding an input as a single point, we encode it as a distribution over the latent space**. The model is then trained as follows:\n- The input is encoded as distribution over the latent space\n- Then a point from the latent space is sampled from that distribution\n- third, the sampled point is decoded and the reconstruction error can be computed\n- finally, the reconstruction error is backpropagated through the network\n<br> <p>\n    \n    \nThe training loss of VAE is defined as the sum of these the reconstruction loss and the similarity loss. The reconstruction error, is the mean squared loss of the input and reconstructed output. The similarity loss is the KL divergence between the latent space distribution and standard gaussian (zero mean and unit variance). The loss function is then the sum of these two losses.\n\n\nThe encoder has two output layers - \n- latent distribution mean\n- variance","metadata":{}},{"cell_type":"code","source":"img_shape = (28, 28, 1)\nbatch_size = 16\nlatent_dim = 2                            ## no. of latent dimension parameters","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:48.404536Z","iopub.execute_input":"2022-05-25T10:09:48.405122Z","iopub.status.idle":"2022-05-25T10:09:48.408872Z","shell.execute_reply.started":"2022-05-25T10:09:48.405082Z","shell.execute_reply":"2022-05-25T10:09:48.408084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoder Architecture","metadata":{}},{"cell_type":"code","source":"encoder_inputs = keras.Input(shape = img_shape)\n\nx = layers.Conv2D(32, 3, padding='same', activation='relu')(encoder_inputs)\nx = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\nx = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\nx = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n# need to know the shape of the network here for the decoder\n\nshape_before_flattening = K.int_shape(x)\nx = layers.Flatten()(x)\nx = layers.Dense(16, activation=\"relu\")(x)\n\n# Two outputs, latent mean and (log)variance\nz_mu = layers.Dense(latent_dim)(x)\nz_log_sigma = layers.Dense(latent_dim)(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:50.335407Z","iopub.execute_input":"2022-05-25T10:09:50.335918Z","iopub.status.idle":"2022-05-25T10:09:50.43607Z","shell.execute_reply.started":"2022-05-25T10:09:50.335878Z","shell.execute_reply":"2022-05-25T10:09:50.435366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a sampling layer","metadata":{}},{"cell_type":"code","source":"# sampling function\ndef sampling(args):\n    z_mu, z_log_sigma = args\n    epsilon = tf.keras.backend.random_normal(shape=(tf.keras.backend.shape(z_mu)[0], latent_dim),\n                              mean=0., stddev=1.)\n    return z_mu + tf.keras.backend.exp(z_log_sigma) * epsilon\n\n# sample vector from the latent distribution\nz = layers.Lambda(sampling)([z_mu, z_log_sigma])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:51.863427Z","iopub.execute_input":"2022-05-25T10:09:51.86371Z","iopub.status.idle":"2022-05-25T10:09:51.92075Z","shell.execute_reply.started":"2022-05-25T10:09:51.863659Z","shell.execute_reply":"2022-05-25T10:09:51.920069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoder Architecture","metadata":{}},{"cell_type":"code","source":"# decoder takes the latent distribution sample as input\ndecoder_input = layers.Input(K.int_shape(z)[1:])\n\n# Expand to 784 total pixels\nx = layers.Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n\n# reshape\nx = layers.Reshape(shape_before_flattening[1:])(x)\n\n# use Conv2DTranspose to reverse the conv layers from the encoder\nx = layers.Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\nx = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\ndecoder_z = keras.Model(decoder_input, x)\n\n# apply the decoder to the sample from the latent distribution\ndecoder = decoder_z(z)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:53.253386Z","iopub.execute_input":"2022-05-25T10:09:53.253636Z","iopub.status.idle":"2022-05-25T10:09:53.32961Z","shell.execute_reply.started":"2022-05-25T10:09:53.253606Z","shell.execute_reply":"2022-05-25T10:09:53.328962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the loss","metadata":{}},{"cell_type":"code","source":"# construct a custom layer to calculate the loss\nclass CustomVariationalLayer(keras.layers.Layer):\n\n    def vae_loss(self, x, decoder):\n        x = tf.keras.backend.flatten(x)\n        decoder = tf.keras.backend.flatten(decoder)\n        # Reconstruction loss\n        xent_loss = keras.metrics.binary_crossentropy(x, decoder)\n        # KL divergence\n        kl_loss = -5e-4 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1)\n        return K.mean(xent_loss + kl_loss)\n\n    # adds the custom loss to the class\n    def call(self, inputs):\n        x = inputs[0]\n        decoder = inputs[1]\n        loss = self.vae_loss(x, decoder)\n        self.add_loss(loss, inputs=inputs)\n        return x\n\n# apply the custom loss to the input images and the decoded latent distribution sample\ny = CustomVariationalLayer()([encoder_inputs, decoder])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:55.021364Z","iopub.execute_input":"2022-05-25T10:09:55.021623Z","iopub.status.idle":"2022-05-25T10:09:55.155212Z","shell.execute_reply.started":"2022-05-25T10:09:55.021594Z","shell.execute_reply":"2022-05-25T10:09:55.15452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VAE model statement\nvae = Model(encoder_inputs, y)\nvae.compile(optimizer='rmsprop', loss=None, metrics=[\"accuracy\"], experimental_run_tf_function=False)\nvae.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:09:56.599982Z","iopub.execute_input":"2022-05-25T10:09:56.600246Z","iopub.status.idle":"2022-05-25T10:09:56.632018Z","shell.execute_reply.started":"2022-05-25T10:09:56.600217Z","shell.execute_reply":"2022-05-25T10:09:56.631326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.fit(x = df_train, y = None, shuffle = True, epochs=10, batch_size=batch_size)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-25T10:10:02.953754Z","iopub.execute_input":"2022-05-25T10:10:02.954404Z","iopub.status.idle":"2022-05-25T10:13:22.867312Z","shell.execute_reply.started":"2022-05-25T10:10:02.954367Z","shell.execute_reply":"2022-05-25T10:13:22.866507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.save('vae.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:13:27.06228Z","iopub.execute_input":"2022-05-25T10:13:27.062708Z","iopub.status.idle":"2022-05-25T10:13:27.201406Z","shell.execute_reply.started":"2022-05-25T10:13:27.062638Z","shell.execute_reply":"2022-05-25T10:13:27.200712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = vae.predict(df_test, verbose = 1)\ntype(y_pred)\ny_pred.shape\ny_pred = y_pred[0]\n# series = pd.Series(y_pred) ","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:33:06.133898Z","iopub.execute_input":"2022-05-25T10:33:06.13451Z","iopub.status.idle":"2022-05-25T10:33:06.452172Z","shell.execute_reply.started":"2022-05-25T10:33:06.134469Z","shell.execute_reply":"2022-05-25T10:33:06.451459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_err(y_true, y_pred):\n    correct_predictions = 0\n    # iterate over each label and check\n    for true, predicted in zip(y_true, y_pred):\n        if true == predicted:\n            correct_predictions += 1\n    # compute the accuracy\n    accuracy = correct_predictions/len(y_true)\n    return accuracy\nacc = compute_err(y_test, y_pred[0])\nfinal_acc = 0.99- acc\nfinal_acc","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-25T10:35:04.249277Z","iopub.execute_input":"2022-05-25T10:35:04.250138Z","iopub.status.idle":"2022-05-25T10:35:04.257461Z","shell.execute_reply.started":"2022-05-25T10:35:04.250085Z","shell.execute_reply":"2022-05-25T10:35:04.25681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_acc","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:35:07.928979Z","iopub.execute_input":"2022-05-25T10:35:07.929405Z","iopub.status.idle":"2022-05-25T10:35:07.934449Z","shell.execute_reply.started":"2022-05-25T10:35:07.929367Z","shell.execute_reply":"2022-05-25T10:35:07.933507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Different classes on the latent 2d plane","metadata":{}},{"cell_type":"code","source":"# Translate into the latent space\nencoder = Model(encoder_inputs, z_mu)\nx_valid_noTest_encoded = encoder.predict(df_train, batch_size=batch_size)\nplt.figure(figsize=(10, 10))\nplt.scatter(x_valid_noTest_encoded[:, 0], x_valid_noTest_encoded[:, 1], c=y_train, cmap='brg')\nplt.colorbar()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # set colormap so that 11's are gray\n# custom_cmap = plt.cm.get_cmap('brg')\n# custom_cmap.set_over('gray')\n\n# x_valid_encoded = encoder.predict(X_valid, batch_size=batch_size)\n# plt.figure(figsize=(10, 10))\n# gray_marker = mpatches.Circle(4,radius=0.1,color='gray', label='Test')\n# plt.legend(handles=[gray_marker], loc = 'best')\n# plt.scatter(x_valid_encoded[:, 0], x_valid_encoded[:, 1], c=y_valid, cmap=custom_cmap)\n# plt.clim(0, 9)\n# plt.colorbar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each of these colored clusters is a type of digit. Close clusters are digits that are structurally similar (i.e. digits that share information in the latent space).","metadata":{}},{"cell_type":"markdown","source":"## Visualization of the latent manifold that \"generates\" the MNIST digits.","metadata":{}},{"cell_type":"code","source":"# Display a 2D manifold of the digits\nn = 20  # figure with 20*20 digits\ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n# We will sample n points within [-15, 15] standard deviations\ngrid_x = np.linspace(-20, 20, n)\ngrid_y = np.linspace(-20, 20, n)\n\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]])\n        x_decoded = decoder_z.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n\nplt.figure(figsize=(20, 20))\nplt.imshow(figure)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Reference 1](https://blog.keras.io/building-autoencoders-in-keras.html)\n\n[Reference 2](https://stackoverflow.com/questions/65366442/cannot-convert-a-symbolic-keras-input-output-to-a-numpy-array-typeerror-when-usi)","metadata":{}}]}