{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries and Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom keras.datasets import mnist\n\nfrom scipy.stats import norm\n\nimport tensorflow as tf\nimport keras \nfrom keras import layers\nfrom keras.models import Model\nfrom keras import metrics\nfrom keras import backend as K \n\nnp.random.seed(237)\nK.clear_session()\n\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix, f1_score\n\n\nfrom tensorflow.python.framework.ops import disable_eager_execution\nfrom collections import defaultdict\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\ndisable_eager_execution()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:10.844394Z","iopub.execute_input":"2022-06-02T09:41:10.844893Z","iopub.status.idle":"2022-06-02T09:41:16.550205Z","shell.execute_reply.started":"2022-06-02T09:41:10.844785Z","shell.execute_reply":"2022-06-02T09:41:16.549373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/digit-recognizer/train.csv')\ndf_test = pd.read_csv('../input/digit-recognizer/test.csv')\n\ndf_train.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-02T09:41:16.551773Z","iopub.execute_input":"2022-06-02T09:41:16.552495Z","iopub.status.idle":"2022-06-02T09:41:22.122751Z","shell.execute_reply.started":"2022-06-02T09:41:16.552456Z","shell.execute_reply":"2022-06-02T09:41:22.122076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape\ndf_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.12396Z","iopub.execute_input":"2022-06-02T09:41:22.124272Z","iopub.status.idle":"2022-06-02T09:41:22.129734Z","shell.execute_reply.started":"2022-06-02T09:41:22.124233Z","shell.execute_reply":"2022-06-02T09:41:22.128924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Droping the labels column \ny_train = df_train['label']\ndf_train = df_train.drop(['label'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.132227Z","iopub.execute_input":"2022-06-02T09:41:22.132515Z","iopub.status.idle":"2022-06-02T09:41:22.222018Z","shell.execute_reply.started":"2022-06-02T09:41:22.132475Z","shell.execute_reply":"2022-06-02T09:41:22.221051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing and reshaping\n\ndf_train = df_train.values.reshape(-1, 28, 28, 1)/255.0\ndf_test = df_test.values.reshape(-1, 28, 28, 1)/255.0","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.225063Z","iopub.execute_input":"2022-06-02T09:41:22.226344Z","iopub.status.idle":"2022-06-02T09:41:22.407732Z","shell.execute_reply.started":"2022-06-02T09:41:22.226293Z","shell.execute_reply":"2022-06-02T09:41:22.40696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create an anomaly hold out group and then only train with the remaining digits\nanom_mask = (y_train==9)\nanomaly_test = df_train[anom_mask]\ndf_train = df_train[~anom_mask]\ny_train = y_train[~anom_mask]\n# make a test set the same size as the anomaly set\ndf_train, df_test, y_train, y_test = train_test_split(df_train, y_train, test_size=anomaly_test.shape[0], random_state=42)\nprint('Training Images', df_train.shape, 'Testing Images', df_test.shape, 'Anomaly Images', anomaly_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.409055Z","iopub.execute_input":"2022-06-02T09:41:22.409297Z","iopub.status.idle":"2022-06-02T09:41:22.627094Z","shell.execute_reply.started":"2022-06-02T09:41:22.409263Z","shell.execute_reply":"2022-06-02T09:41:22.625684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the dataset","metadata":{}},{"cell_type":"code","source":"plt.figure(1)\nplt.subplot(221)\nplt.imshow(df_train[13][:,:,0])\n\nplt.subplot(222)\nplt.imshow(df_train[690][:,:,0])\n\nplt.subplot(223)\nplt.imshow(df_train[2375][:,:,0])\n\nplt.subplot(224)\nplt.imshow(df_train[4213][:,:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.628338Z","iopub.execute_input":"2022-06-02T09:41:22.628667Z","iopub.status.idle":"2022-06-02T09:41:22.976549Z","shell.execute_reply.started":"2022-06-02T09:41:22.62863Z","shell.execute_reply":"2022-06-02T09:41:22.975873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\nIn VAEs, **instead of encoding an input as a single point, we encode it as a distribution over the latent space**. The model is then trained as follows:\n- The input is encoded as distribution over the latent space\n- Then a point from the latent space is sampled from that distribution\n- third, the sampled point is decoded and the reconstruction error can be computed\n- finally, the reconstruction error is backpropagated through the network\n<br> <p>\n    \n    \nThe training loss of VAE is defined as the sum of these the reconstruction loss and the similarity loss. The reconstruction error, is the mean squared loss of the input and reconstructed output. The similarity loss is the KL divergence between the latent space distribution and standard gaussian (zero mean and unit variance). The loss function is then the sum of these two losses.\n\n\nThe encoder has two output layers - \n- latent distribution mean\n- variance","metadata":{}},{"cell_type":"code","source":"img_shape = (28, 28, 1)\nbatch_size = 16\nlatent_dim = 6                           ## no. of latent dimension parameters","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.977797Z","iopub.execute_input":"2022-06-02T09:41:22.978058Z","iopub.status.idle":"2022-06-02T09:41:22.983574Z","shell.execute_reply.started":"2022-06-02T09:41:22.978024Z","shell.execute_reply":"2022-06-02T09:41:22.981544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoder Architecture","metadata":{}},{"cell_type":"code","source":"encoder_inputs = keras.Input(shape = img_shape)\n\nx = layers.Conv2D(32, 3, padding='same', activation='relu')(encoder_inputs)\nx = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\nx = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\nx = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n# need to know the shape of the network here for the decoder\n\nshape_before_flattening = K.int_shape(x)\nx = layers.Flatten()(x)\nx = layers.Dense(16, activation=\"relu\")(x)\n\n# Two outputs, latent mean and (log)variance\nz_mu = layers.Dense(latent_dim)(x)\nz_log_sigma = layers.Dense(latent_dim)(x)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:22.985179Z","iopub.execute_input":"2022-06-02T09:41:22.985444Z","iopub.status.idle":"2022-06-02T09:41:23.098127Z","shell.execute_reply.started":"2022-06-02T09:41:22.985397Z","shell.execute_reply":"2022-06-02T09:41:23.097473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a sampling layer","metadata":{}},{"cell_type":"code","source":"# sampling function\ndef sampling(args):\n    z_mu, z_log_sigma = args\n    epsilon = tf.keras.backend.random_normal(shape=(tf.keras.backend.shape(z_mu)[0], latent_dim),\n                              mean=0., stddev=1.)\n    return z_mu + tf.keras.backend.exp(z_log_sigma) * epsilon\n\n# sample vector from the latent distribution\nz = layers.Lambda(sampling)([z_mu, z_log_sigma])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:23.101117Z","iopub.execute_input":"2022-06-02T09:41:23.101817Z","iopub.status.idle":"2022-06-02T09:41:23.433523Z","shell.execute_reply.started":"2022-06-02T09:41:23.101776Z","shell.execute_reply":"2022-06-02T09:41:23.432827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoder Architecture","metadata":{}},{"cell_type":"code","source":"# decoder takes the latent distribution sample as input\ndecoder_input = layers.Input(K.int_shape(z)[1:])\n\n# Expand to 784 total pixels\nx = layers.Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n\n# reshape\nx = layers.Reshape(shape_before_flattening[1:])(x)\n\n# use Conv2DTranspose to reverse the conv layers from the encoder\nx = layers.Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\nx = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\ndecoder_z = keras.Model(decoder_input, x)\n\n# apply the decoder to the sample from the latent distribution\ndecoder = decoder_z(z)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:23.434629Z","iopub.execute_input":"2022-06-02T09:41:23.434873Z","iopub.status.idle":"2022-06-02T09:41:23.513749Z","shell.execute_reply.started":"2022-06-02T09:41:23.43484Z","shell.execute_reply":"2022-06-02T09:41:23.513081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the loss","metadata":{}},{"cell_type":"code","source":"# construct a custom layer to calculate the loss\nclass CustomVariationalLayer(keras.layers.Layer):\n\n    def vae_loss(self, x, decoder):\n        x = tf.keras.backend.flatten(x)\n        decoder = tf.keras.backend.flatten(decoder)\n        # Reconstruction loss\n        xent_loss = keras.metrics.binary_crossentropy(x, decoder)\n        # KL divergence\n        kl_loss = -5e-4 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1)\n        return K.mean(xent_loss + kl_loss)\n\n    # adds the custom loss to the class\n    def call(self, inputs):\n        x = inputs[0]\n        decoder = inputs[1]\n        loss = self.vae_loss(x, decoder)\n        self.add_loss(loss, inputs=inputs)\n        return x\n\n# apply the custom loss to the input images and the decoded latent distribution sample\ny = CustomVariationalLayer()([encoder_inputs, decoder])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:23.514862Z","iopub.execute_input":"2022-06-02T09:41:23.515119Z","iopub.status.idle":"2022-06-02T09:41:23.656522Z","shell.execute_reply.started":"2022-06-02T09:41:23.515084Z","shell.execute_reply":"2022-06-02T09:41:23.65581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VAE model statement\nvae = Model(encoder_inputs, y)\nvae.compile(optimizer='rmsprop', loss=None, metrics=[\"accuracy\"], experimental_run_tf_function=False)\nvae.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-02T09:41:23.657826Z","iopub.execute_input":"2022-06-02T09:41:23.658064Z","iopub.status.idle":"2022-06-02T09:41:23.688811Z","shell.execute_reply.started":"2022-06-02T09:41:23.658031Z","shell.execute_reply":"2022-06-02T09:41:23.688087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.fit(x = df_train, y = None, shuffle = True, epochs=10, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:41:23.689936Z","iopub.execute_input":"2022-06-02T09:41:23.69015Z","iopub.status.idle":"2022-06-02T09:43:35.513005Z","shell.execute_reply.started":"2022-06-02T09:41:23.69012Z","shell.execute_reply":"2022-06-02T09:43:35.512221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = Model(encoder_inputs, z_mu)\n# display a 2D plot of the digit classes in the latent space\nX_test_encoded = encoder.predict(df_test, batch_size=batch_size)\n# X_test_encoded.shape\n# Finding the Predicted Classes\n# # cls_train = np.argmax(preds_train, axis = 1)\n# cls_test = np.argmax(X_test_encoded, axis = 1)\n\n# # Finding the Train/Test set Loss\n# print(\"Log-loss for Train Dataset = \", log_loss(y_test, X_test_encoded))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:35.514292Z","iopub.execute_input":"2022-06-02T09:43:35.51452Z","iopub.status.idle":"2022-06-02T09:43:35.947167Z","shell.execute_reply.started":"2022-06-02T09:43:35.514492Z","shell.execute_reply":"2022-06-02T09:43:35.946422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Translate into the latent space\nencoder = Model(encoder_inputs, z_mu)\nx_valid_noTest_encoded = encoder.predict(df_test, batch_size=batch_size)\nplt.figure(figsize=(10, 10))\nplt.scatter(x_valid_noTest_encoded[:, 0], x_valid_noTest_encoded[:, 1], c=y_test, cmap='icefire')\nplt.colorbar()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:35.948311Z","iopub.execute_input":"2022-06-02T09:43:35.948632Z","iopub.status.idle":"2022-06-02T09:43:36.665762Z","shell.execute_reply.started":"2022-06-02T09:43:35.948593Z","shell.execute_reply":"2022-06-02T09:43:36.665095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dimensionality Reduction","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom matplotlib.cm import get_cmap\nfrom sklearn.manifold import TSNE\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:36.66674Z","iopub.execute_input":"2022-06-02T09:43:36.667571Z","iopub.status.idle":"2022-06-02T09:43:36.814398Z","shell.execute_reply.started":"2022-06-02T09:43:36.667535Z","shell.execute_reply":"2022-06-02T09:43:36.813711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape\n# reshape\nX = df_test.reshape(df_test.shape[0], -1)\npca = PCA(n_components = 2).fit_transform(x_valid_noTest_encoded)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:36.815788Z","iopub.execute_input":"2022-06-02T09:43:36.816023Z","iopub.status.idle":"2022-06-02T09:43:36.849369Z","shell.execute_reply.started":"2022-06-02T09:43:36.81599Z","shell.execute_reply":"2022-06-02T09:43:36.848487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(15, 10))\nplt.scatter(pca[:, 0], pca[:, 1], c=y_test, cmap='icefire')\nplt.colorbar()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T10:08:36.734652Z","iopub.execute_input":"2022-06-02T10:08:36.735283Z","iopub.status.idle":"2022-06-02T10:08:37.064929Z","shell.execute_reply.started":"2022-06-02T10:08:36.735246Z","shell.execute_reply":"2022-06-02T10:08:37.064267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tsne = TSNE(n_components = 2).fit_transform(x_valid_noTest_encoded)\nlda = LDA(n_components=2)\n\nx_lda = lda.fit_transform(x_valid_noTest_encoded, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:37.259006Z","iopub.execute_input":"2022-06-02T09:43:37.259767Z","iopub.status.idle":"2022-06-02T09:43:37.279952Z","shell.execute_reply.started":"2022-06-02T09:43:37.259729Z","shell.execute_reply":"2022-06-02T09:43:37.279276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(15, 10))\nplt.scatter(x_lda[:, 0], x_lda[:, 1], c=y_test, cmap='icefire')\nplt.colorbar()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T10:08:31.910926Z","iopub.execute_input":"2022-06-02T10:08:31.911171Z","iopub.status.idle":"2022-06-02T10:08:32.276973Z","shell.execute_reply.started":"2022-06-02T10:08:31.911142Z","shell.execute_reply":"2022-06-02T10:08:32.27487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tsne = TSNE(n_components = 2)\n# x_tsne = tsne.fit_transform(x_valid_noTest_encoded) ","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:37.646039Z","iopub.execute_input":"2022-06-02T09:43:37.646795Z","iopub.status.idle":"2022-06-02T09:43:37.650514Z","shell.execute_reply.started":"2022-06-02T09:43:37.646757Z","shell.execute_reply":"2022-06-02T09:43:37.649693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=10)\n# Compute cluster centers and predict cluster indices\nkmeans_pca = kmeans.fit_predict(pca)\n\nplt.scatter(pca[:, 0], pca[:, 1],c = kmeans_pca, cmap = 'icefire')\n\nplt.show()\n\nplt.scatter(pca[:, 0], pca[:, 1],c = y_test, cmap = 'icefire')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T10:06:52.005216Z","iopub.execute_input":"2022-06-02T10:06:52.005632Z","iopub.status.idle":"2022-06-02T10:06:52.69095Z","shell.execute_reply.started":"2022-06-02T10:06:52.005589Z","shell.execute_reply":"2022-06-02T10:06:52.690286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=10)\n# Compute cluster centers and predict cluster indices\nkmeans_9 = kmeans.fit_predict(x_lda)\n\nplt.scatter(x_lda[:, 0], x_lda[:, 1],c = kmeans_9, cmap = 'icefire')\n\nplt.show()\n\nplt.scatter(x_lda[:, 0], x_lda[:, 1],c = y_test, cmap = 'icefire')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T10:07:27.138127Z","iopub.execute_input":"2022-06-02T10:07:27.138377Z","iopub.status.idle":"2022-06-02T10:07:27.78996Z","shell.execute_reply.started":"2022-06-02T10:07:27.138349Z","shell.execute_reply":"2022-06-02T10:07:27.789287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\nDBSCAN_cluster = DBSCAN(eps=10, min_samples=5).fit(x_valid_noTest_encoded) ","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:39.117173Z","iopub.execute_input":"2022-06-02T09:43:39.117484Z","iopub.status.idle":"2022-06-02T09:43:39.595456Z","shell.execute_reply.started":"2022-06-02T09:43:39.117449Z","shell.execute_reply":"2022-06-02T09:43:39.594702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne = TSNE(n_components=2, verbose = 1)\nx_tsne = tsne.fit_transform(x_valid_noTest_encoded) ","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:43:39.596984Z","iopub.execute_input":"2022-06-02T09:43:39.597223Z","iopub.status.idle":"2022-06-02T09:44:10.234222Z","shell.execute_reply.started":"2022-06-02T09:43:39.59719Z","shell.execute_reply":"2022-06-02T09:44:10.23349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each of these colored clusters is a type of digit. Close clusters are digits that are structurally similar (i.e. digits that share information in the latent space).","metadata":{}},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=10)\n# Compute cluster centers and predict cluster indices\nkmeans_tsne = kmeans.fit_predict(x_lda)\n\nplt.scatter(x_tsne[:, 0], x_tsne[:, 1],c = kmeans_tsne, cmap = 'icefire')\n\nplt.show()\n\nplt.scatter(x_tsne[:, 0], x_tsne[:, 1],c = y_test, cmap = 'icefire')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T10:08:12.596488Z","iopub.execute_input":"2022-06-02T10:08:12.596917Z","iopub.status.idle":"2022-06-02T10:08:13.24881Z","shell.execute_reply.started":"2022-06-02T10:08:12.596882Z","shell.execute_reply":"2022-06-02T10:08:13.248128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Reference 1](https://blog.keras.io/building-autoencoders-in-keras.html)\n\n[Reference 2](https://stackoverflow.com/questions/65366442/cannot-convert-a-symbolic-keras-input-output-to-a-numpy-array-typeerror-when-usi)","metadata":{}}]}