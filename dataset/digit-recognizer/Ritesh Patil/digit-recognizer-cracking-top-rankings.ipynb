{"cells":[{"metadata":{"papermill":{"duration":0.009571,"end_time":"2021-01-26T15:47:53.975242","exception":false,"start_time":"2021-01-26T15:47:53.965671","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Importing libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-01-26T15:47:53.999033Z","iopub.status.busy":"2021-01-26T15:47:53.998369Z","iopub.status.idle":"2021-01-26T15:47:54.000986Z","shell.execute_reply":"2021-01-26T15:47:54.001356Z"},"papermill":{"duration":0.016566,"end_time":"2021-01-26T15:47:54.001594","exception":false,"start_time":"2021-01-26T15:47:53.985028","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.009731,"end_time":"2021-01-26T15:47:54.021495","exception":false,"start_time":"2021-01-26T15:47:54.011764","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Reading the data provided in the competetion"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:47:54.047859Z","iopub.status.busy":"2021-01-26T15:47:54.047284Z","iopub.status.idle":"2021-01-26T15:47:59.379727Z","shell.execute_reply":"2021-01-26T15:47:59.379189Z"},"papermill":{"duration":5.34847,"end_time":"2021-01-26T15:47:59.379869","exception":false,"start_time":"2021-01-26T15:47:54.031399","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\ntrain_images = train.drop(\"label\", axis=1)\ntrain_labels = train[\"label\"]","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.01058,"end_time":"2021-01-26T15:47:59.401191","exception":false,"start_time":"2021-01-26T15:47:59.390611","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Neural Network take data as input in form of Numpy Arrays, the data frame thus needs to be converted to numpy arrays so that it can become ready for processing by the neural network. \n\nThe to_numpy() function helps us to convert to numpy array. "},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:47:59.427985Z","iopub.status.busy":"2021-01-26T15:47:59.427233Z","iopub.status.idle":"2021-01-26T15:47:59.431836Z","shell.execute_reply":"2021-01-26T15:47:59.431421Z"},"papermill":{"duration":0.020644,"end_time":"2021-01-26T15:47:59.431939","exception":false,"start_time":"2021-01-26T15:47:59.411295","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_images.to_numpy()\ntrain_labels.to_numpy()\ntest.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.010374,"end_time":"2021-01-26T15:47:59.453009","exception":false,"start_time":"2021-01-26T15:47:59.442635","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Data Preprocessing:**  The data values are divided by 255 for scaling the values in the numpy arrays, this will make the values of array elements in between 0-1 which was previously in between 0-255"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:47:59.477635Z","iopub.status.busy":"2021-01-26T15:47:59.477099Z","iopub.status.idle":"2021-01-26T15:47:59.650036Z","shell.execute_reply":"2021-01-26T15:47:59.650532Z"},"papermill":{"duration":0.187237,"end_time":"2021-01-26T15:47:59.650707","exception":false,"start_time":"2021-01-26T15:47:59.46347","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_images = train_images / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.010662,"end_time":"2021-01-26T15:47:59.673781","exception":false,"start_time":"2021-01-26T15:47:59.663119","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The labels are also of same dimensions as the training data, the training labels needs to be converted categorically to a Original_Dimension * Class dimensional array, this will help the model to understand which class does the data belongs to. \n\nIn simpler terms it will categorise the data. "},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:47:59.699474Z","iopub.status.busy":"2021-01-26T15:47:59.698896Z","iopub.status.idle":"2021-01-26T15:48:04.528232Z","shell.execute_reply":"2021-01-26T15:48:04.527682Z"},"papermill":{"duration":4.843822,"end_time":"2021-01-26T15:48:04.528357","exception":false,"start_time":"2021-01-26T15:47:59.684535","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.011638,"end_time":"2021-01-26T15:48:04.553056","exception":false,"start_time":"2021-01-26T15:48:04.541418","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### <span style=\"color:red\"> Model Generation using Keras with TensorFlow Backend: </span>\nTo create models in keras we import **models** class from the keras library. The layers of models are created by various functions **layers** class, the functions describe the type of layer we want to create in the model. "},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:48:04.580958Z","iopub.status.busy":"2021-01-26T15:48:04.580206Z","iopub.status.idle":"2021-01-26T15:48:07.148862Z","shell.execute_reply":"2021-01-26T15:48:07.148209Z"},"papermill":{"duration":2.584652,"end_time":"2021-01-26T15:48:07.149041","exception":false,"start_time":"2021-01-26T15:48:04.564389","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(512, activation='relu', input_shape=(28 * 28, )))\nnetwork.add(layers.Dense(10, activation='softmax'))\nnetwork.summary()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.011167,"end_time":"2021-01-26T15:48:07.172595","exception":false,"start_time":"2021-01-26T15:48:07.161428","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Compiling the network"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:48:07.20534Z","iopub.status.busy":"2021-01-26T15:48:07.204165Z","iopub.status.idle":"2021-01-26T15:48:07.210622Z","shell.execute_reply":"2021-01-26T15:48:07.210175Z"},"papermill":{"duration":0.026614,"end_time":"2021-01-26T15:48:07.210724","exception":false,"start_time":"2021-01-26T15:48:07.18411","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"network.compile(optimizer='rmsprop',\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.010986,"end_time":"2021-01-26T15:48:07.233031","exception":false,"start_time":"2021-01-26T15:48:07.222045","status":"completed"},"tags":[]},"cell_type":"markdown","source":"#### Final Step is to fit the model to the training images and the training labels and the model tries that for n numbers of epochs taking batch size number of training_images in one iteration."},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:48:07.259566Z","iopub.status.busy":"2021-01-26T15:48:07.259049Z","iopub.status.idle":"2021-01-26T15:48:13.151181Z","shell.execute_reply":"2021-01-26T15:48:13.1516Z"},"papermill":{"duration":5.907284,"end_time":"2021-01-26T15:48:13.151755","exception":false,"start_time":"2021-01-26T15:48:07.244471","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"history = network.fit(train_images, train_labels, epochs = 10, batch_size=120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:48:13.297815Z","iopub.status.busy":"2021-01-26T15:48:13.297038Z","iopub.status.idle":"2021-01-26T15:48:14.58659Z","shell.execute_reply":"2021-01-26T15:48:14.586059Z"},"papermill":{"duration":1.329096,"end_time":"2021-01-26T15:48:14.586781","exception":false,"start_time":"2021-01-26T15:48:13.257685","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame(np.argmax(network.predict(test), axis=1), \n                      columns=['Label'], \n                      index=pd.read_csv('../input/digit-recognizer/sample_submission.csv')['ImageId'])\n\nsubmit.index.name = 'ImageId'\nsubmit.to_csv('submittion.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-26T15:48:14.71478Z","iopub.status.busy":"2021-01-26T15:48:14.714021Z","iopub.status.idle":"2021-01-26T15:48:14.724027Z","shell.execute_reply":"2021-01-26T15:48:14.724966Z"},"papermill":{"duration":0.080724,"end_time":"2021-01-26T15:48:14.725141","exception":false,"start_time":"2021-01-26T15:48:14.644417","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submit","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}