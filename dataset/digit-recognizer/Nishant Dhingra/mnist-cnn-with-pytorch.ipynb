{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Digit Recognition Using PyTorch (ANN and CNN Implementation)\n\n#### Just learnt and gone through how things work in PyTorch, how to train and work on deep learning use cases, and thouht to try out my skills on this baseline model.\n\n#### All steps are covered from preparing data loaders to training and Validating our model. Feel free to give feedback.","metadata":{}},{"cell_type":"markdown","source":"\n\n## I am just a beginner and your upvote will motivate me! ðŸ¤—ðŸ˜‡ ","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\n#PyTorch\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom torch import optim , nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T18:54:52.008431Z","iopub.execute_input":"2021-09-27T18:54:52.008949Z","iopub.status.idle":"2021-09-27T18:54:54.265085Z","shell.execute_reply.started":"2021-09-27T18:54:52.008854Z","shell.execute_reply":"2021-09-27T18:54:54.264153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Data","metadata":{}},{"cell_type":"code","source":"#Getting csv data\n\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\nx_train = train.iloc[:,1:].values/255\ny_train = train.label.values","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:54.267094Z","iopub.execute_input":"2021-09-27T18:54:54.267415Z","iopub.status.idle":"2021-09-27T18:54:57.983107Z","shell.execute_reply.started":"2021-09-27T18:54:54.267377Z","shell.execute_reply":"2021-09-27T18:54:57.982295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Train and Validation Data","metadata":{}},{"cell_type":"code","source":"#Dividing into train and validation set\n\ntrain_x, val_x, train_y, val_y = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:57.984467Z","iopub.execute_input":"2021-09-27T18:54:57.98471Z","iopub.status.idle":"2021-09-27T18:54:58.411992Z","shell.execute_reply.started":"2021-09-27T18:54:57.984684Z","shell.execute_reply":"2021-09-27T18:54:58.411393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting into Tensors from_numpy()\n\ntrain_x_torch = torch.from_numpy(train_x).type(torch.FloatTensor)\nval_x_torch = torch.from_numpy(val_x).type(torch.FloatTensor)\n\ntrain_y_torch = torch.from_numpy(train_y).type(torch.LongTensor) #Data typecasting\nval_y_torch = torch.from_numpy(val_y).type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:58.413335Z","iopub.execute_input":"2021-09-27T18:54:58.413945Z","iopub.status.idle":"2021-09-27T18:54:58.504626Z","shell.execute_reply.started":"2021-09-27T18:54:58.413901Z","shell.execute_reply":"2021-09-27T18:54:58.50399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128  #anything b/w 64 and 256 works\n\n#Preparing training set and test set\ntrainset = torch.utils.data.TensorDataset(train_x_torch, train_y_torch)\nvalset = torch.utils.data.TensorDataset(val_x_torch, val_y_torch)\n\n\n#Preparing Data loaders\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\nvalloader = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:58.506597Z","iopub.execute_input":"2021-09-27T18:54:58.507417Z","iopub.status.idle":"2021-09-27T18:54:58.514432Z","shell.execute_reply.started":"2021-09-27T18:54:58.507374Z","shell.execute_reply":"2021-09-27T18:54:58.513614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. ANN (Artificial Neural Network)","metadata":{}},{"cell_type":"markdown","source":"## Constructing a basic Neural Network in PyTorch","metadata":{}},{"cell_type":"code","source":"# Building a Neural Network\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28*28*1, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512,256)\n        self.fc4 = nn.Linear(256,128)\n        self.fc5 = nn.Linear(128,64)\n        self.fc6 = nn.Linear(64,10)\n        \n        self.dropout = nn.Dropout(p=0.3)\n        \n        self.softmax = F.log_softmax\n        \n    def forward(self, X):\n        X = self.dropout(F.relu(self.fc1(X)))\n        X = self.dropout(F.relu(self.fc2(X)))\n        X = self.dropout(F.relu(self.fc3(X)))\n        X = self.dropout(F.relu(self.fc4(X)))\n        X = self.dropout(F.relu(self.fc5(X)))\n        X = self.softmax(self.fc6(X), dim=1)\n        \n        return X","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:58.515696Z","iopub.execute_input":"2021-09-27T18:54:58.515987Z","iopub.status.idle":"2021-09-27T18:54:58.526637Z","shell.execute_reply.started":"2021-09-27T18:54:58.51595Z","shell.execute_reply":"2021-09-27T18:54:58.525867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation","metadata":{}},{"cell_type":"code","source":"## Training Our Neural Network\nmodel = Net()\n\ndef fit(model, trainloader, valloader, epochs = 25):\n    criterion = nn.NLLLoss()\n\n    #weight decay for L2 Regularization\n    optimizer = optim.Adam(model.parameters(), lr = 0.0003)\n\n    epochs = epochs\n\n    steps = 0\n    print_at = 50\n\n    train_losses, test_losses = [], []\n\n    for e in range(epochs):\n        running_loss = 0\n    \n        for images, labels in trainloader:\n            steps+=1\n        \n            #Start from zero every epoch\n            optimizer.zero_grad()\n        \n            #Make predictions\n            output = model(images)\n        \n            #Calculate loss\n            loss = criterion(output, labels)\n        \n            #backprop\n            loss.backward()\n        \n            #Adjusting weights\n            optimizer.step()\n        \n            running_loss += loss.item()\n        \n            #For validation\n            if steps%print_at == 0:\n                test_loss = 0\n                accuracy = 0\n            \n                #Turn of gradients and go into eval mode\n                with torch.no_grad():\n                    model.eval()\n                \n                    for images, labels in valloader:\n                        output = model(images)\n                        test_loss += criterion(output, labels)\n                    \n                        probs = torch.exp(output)\n                    \n                        top_p, top_class = probs.topk(1, dim = 1)\n                    \n                        equals = top_class == labels.view(*top_class.shape)\n                    \n                        accuracy += torch.mean(equals.type(torch.FloatTensor))\n                    \n                model.train()\n            \n                train_losses.append(running_loss/len(trainloader))\n                test_losses.append(test_loss/len(valloader))\n            \n                print('epochs{}/{}.. '.format(e+1, epochs),\n                     \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n                     \"Validation Loss: {:.3f}.. \".format(test_losses[-1]),\n                     \"Test Accuracy: {:.3f}.. \".format(accuracy/len(valloader)) )\n            \n    return train_losses, test_losses       ","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:58.528182Z","iopub.execute_input":"2021-09-27T18:54:58.52871Z","iopub.status.idle":"2021-09-27T18:54:58.561659Z","shell.execute_reply.started":"2021-09-27T18:54:58.528671Z","shell.execute_reply":"2021-09-27T18:54:58.560885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses, test_losses = fit(model, trainloader, valloader)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:54:58.562739Z","iopub.execute_input":"2021-09-27T18:54:58.562973Z","iopub.status.idle":"2021-09-27T18:55:08.63546Z","shell.execute_reply.started":"2021-09-27T18:54:58.562944Z","shell.execute_reply":"2021-09-27T18:55:08.634278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How did our baseline model performed","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nplt.plot(train_losses, label ='Training Loss')\nplt.plot(test_losses, label = 'Test Loss')\nplt.title('ANN Training')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:57:30.785949Z","iopub.execute_input":"2021-09-26T21:57:30.786748Z","iopub.status.idle":"2021-09-26T21:57:30.811494Z","shell.execute_reply.started":"2021-09-26T21:57:30.786694Z","shell.execute_reply":"2021-09-26T21:57:30.81017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing test Data for submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/digit-recognizer/test.csv')\nx_test = test.values/255\nx_test_torch = torch.from_numpy(x_test).type(torch.FloatTensor)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:11.279066Z","iopub.execute_input":"2021-09-27T18:55:11.279377Z","iopub.status.idle":"2021-09-27T18:55:13.503595Z","shell.execute_reply.started":"2021-09-27T18:55:11.279323Z","shell.execute_reply":"2021-09-27T18:55:13.502786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_labels = np.zeros(x_test.shape)\ndummy_labels = torch.from_numpy(dummy_labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:13.5051Z","iopub.execute_input":"2021-09-27T18:55:13.505323Z","iopub.status.idle":"2021-09-27T18:55:13.509633Z","shell.execute_reply.started":"2021-09-27T18:55:13.505298Z","shell.execute_reply":"2021-09-27T18:55:13.508973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset = torch.utils.data.TensorDataset(x_test_torch, dummy_labels)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:13.510781Z","iopub.execute_input":"2021-09-27T18:55:13.511147Z","iopub.status.idle":"2021-09-27T18:55:13.523878Z","shell.execute_reply.started":"2021-09-27T18:55:13.511106Z","shell.execute_reply":"2021-09-27T18:55:13.523272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making Predictions","metadata":{}},{"cell_type":"code","source":"submit = [['ImageId', 'Label']]\n\n#turning of gradients\nwith torch.no_grad():\n    model.eval()\n    image_id = 1\n    \n    for images, _ in testloader:\n        outputs = model(images)\n        probs = torch.exp(outputs)\n        \n        top_p, top_class = probs.topk(1, dim = 1)\n        \n        for preds in top_class:\n            submit.append([image_id,preds.item()])\n            image_id += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:13.571236Z","iopub.execute_input":"2021-09-27T18:55:13.571705Z","iopub.status.idle":"2021-09-27T18:55:15.073378Z","shell.execute_reply.started":"2021-09-27T18:55:13.571658Z","shell.execute_reply":"2021-09-27T18:55:15.072662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating ANN Submission File!","metadata":{}},{"cell_type":"code","source":"submit_df = pd.DataFrame(submit)\nsubmit_df.columns = submit_df.iloc[0]\nsubmit_df = submit_df.drop(0, axis = 0)\n\nsubmit_df.to_csv('ANN_Submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:15.397672Z","iopub.execute_input":"2021-09-27T18:55:15.398163Z","iopub.status.idle":"2021-09-27T18:55:15.469084Z","shell.execute_reply.started":"2021-09-27T18:55:15.398115Z","shell.execute_reply":"2021-09-27T18:55:15.468177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. CNN (Convolution Neural Network)","metadata":{}},{"cell_type":"code","source":"batch_size = 128\n\ntrain_x_torch = train_x_torch.view(-1, 1,28,28).float()\nval_x_torch = val_x_torch.view(-1, 1,28,28).float()\n\n#preparing training and validation dataset\ntrainset = torch.utils.data.TensorDataset(train_x_torch, train_y_torch)\nvalset = torch.utils.data.TensorDataset(val_x_torch, val_y_torch)\n\n#preparing Data Loaders\n\ntrainloader = torch.utils.data.DataLoader(trainset, shuffle = True, batch_size = batch_size)\nvalloader = torch.utils.data.DataLoader(valset, shuffle = True, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:17.628296Z","iopub.execute_input":"2021-09-27T18:55:17.628607Z","iopub.status.idle":"2021-09-27T18:55:17.637266Z","shell.execute_reply.started":"2021-09-27T18:55:17.628577Z","shell.execute_reply":"2021-09-27T18:55:17.636468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, padding =1)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size = 3, padding =1)\n        self.conv3 = nn.Conv2d(128, 128, kernel_size = 3, padding =1)\n        \n        self.relu = nn.ReLU()\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.fc1 = nn.Linear(3*3*128, 512)\n        \n        self.fc2 = nn.Linear(512, 10)\n        \n        self.dropout = nn.Dropout(p=0.3)\n        \n        self.softmax = F.log_softmax\n        \n    def forward(self, X):\n        X = self.dropout(self.relu(self.pool(self.conv1(X))))\n        X = self.dropout(self.relu(self.pool(self.conv2(X))))\n        X = self.dropout(self.relu(self.pool(self.conv3(X))))\n        X = X.view(-1, 3*3*128)\n        \n        X = self.dropout(self.relu(self.fc1(X)))\n        \n        X = self.softmax(self.fc2(X), dim = 1)\n        \n        return X\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:38.611664Z","iopub.execute_input":"2021-09-27T18:55:38.612109Z","iopub.status.idle":"2021-09-27T18:55:38.622847Z","shell.execute_reply.started":"2021-09-27T18:55:38.612073Z","shell.execute_reply":"2021-09-27T18:55:38.621907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn = CNN()\n\n#training our CNN\ntrain_losses, test_losses = fit(cnn, trainloader, valloader, epochs = 10)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:55:39.267966Z","iopub.execute_input":"2021-09-27T18:55:39.268883Z","iopub.status.idle":"2021-09-27T19:12:39.056894Z","shell.execute_reply.started":"2021-09-27T18:55:39.268834Z","shell.execute_reply":"2021-09-27T19:12:39.053939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nplt.plot(train_losses, label ='Training Loss')\nplt.plot(test_losses, label = 'Test Loss')\nplt.title('CNN Training')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T19:15:21.646489Z","iopub.execute_input":"2021-09-27T19:15:21.646941Z","iopub.status.idle":"2021-09-27T19:15:21.955172Z","shell.execute_reply.started":"2021-09-27T19:15:21.64687Z","shell.execute_reply":"2021-09-27T19:15:21.954168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshaping test data for feeding CNN\nx_test_torch = x_test_torch.view(-1, 1, 28, 28)\n\ntestset = torch.utils.data.TensorDataset(x_test_torch, dummy_labels)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T19:15:33.905525Z","iopub.execute_input":"2021-09-27T19:15:33.905954Z","iopub.status.idle":"2021-09-27T19:15:33.912793Z","shell.execute_reply.started":"2021-09-27T19:15:33.905915Z","shell.execute_reply":"2021-09-27T19:15:33.911571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = [['ImageId', 'Label']]\n\n#turning of gradients\nwith torch.no_grad():\n    cnn.eval()\n    image_id = 1\n    \n    for images, _ in testloader:\n        outputs = cnn(images)\n        probs = torch.exp(outputs)\n        \n        top_p, top_class = probs.topk(1, dim = 1)\n        \n        for preds in top_class:\n            submit.append([image_id,preds.item()])\n            image_id += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-27T19:15:34.664858Z","iopub.execute_input":"2021-09-27T19:15:34.665237Z","iopub.status.idle":"2021-09-27T19:15:54.984419Z","shell.execute_reply.started":"2021-09-27T19:15:34.6652Z","shell.execute_reply":"2021-09-27T19:15:54.983511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making CNN Submission file!","metadata":{}},{"cell_type":"code","source":"submit_df = pd.DataFrame(submit)\nsubmit_df.columns = submit_df.iloc[0]\nsubmit_df = submit_df.drop(0, axis = 0)\n\nsubmit_df.to_csv('CNN_Submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T19:15:54.985972Z","iopub.execute_input":"2021-09-27T19:15:54.986218Z","iopub.status.idle":"2021-09-27T19:15:55.057729Z","shell.execute_reply.started":"2021-09-27T19:15:54.986188Z","shell.execute_reply":"2021-09-27T19:15:55.056734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}