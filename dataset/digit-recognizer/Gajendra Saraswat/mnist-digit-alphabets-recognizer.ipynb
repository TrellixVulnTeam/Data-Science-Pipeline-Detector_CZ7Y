{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://camo.githubusercontent.com/d440ac2eee1cb3ea33340a2c5f6f15a0878e9275/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)\n\nHey, hope you are doing well and fine.\n\nIn this notebook, we will be adding both the MNIST and Alphabets dataset and train a model on them together. So, for this classification, we will have 36 classes in total, 10 for digits and 26 for alphabets.\n\nWe will be using Keras API in this notebook.\n\nI will try to keep it simple and beginner friendly, if you have any suggestions regarding improving the notebook, please leave a comment at the end of it. If you like the work, do appreciate in the way you like! :)\n\nSo, now, without telling more about what to come in this notebook, let's just dive right into it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Importing essential libraries","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style = \"darkgrid\")\n\nimport gc\n\nimport keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, MaxPool2D, Conv2D\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model\n\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading and Understanding data files","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> We will be adding 10 to the target values of alphabet data, because 0-9 are already booked for digits and we don't want our model to confuse itself between \"A\" and \"0\" or \"B\" and \"1\" and so on, we will start the labels for alphabet targets from 10, so now, 0-9 will be digits and 10-35 will be alphabets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num = pd.read_csv(\"../input/train-digit-recognition-mnist/mnist_train.csv\")\ndf_alph = pd.read_csv(\"../input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data/A_Z Handwritten Data.csv\")\ndf_alph[\"0\"] += 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Shape of both dataframes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num.shape, df_alph.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> So we can see that we have 60000 samples for numerals and 3,72,450 samples for alphabets.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Let's now see some of the data samples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alph.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's now change the column names and both the data and make them same so that joining them will be much easy.\n\n> What we are doing here is making column name as follows:\n> - Target -> Label\n> - Pixel value x -> pixel_x","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pixel_array = [\"Label\"]\nfor i in range(1, 785):\n    pixel_array.append(f\"pixel_{i}\")\ndf_num.columns = pixel_array\ndf_alph.columns = pixel_array\ndel pixel_array\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since both of our dataframes have same name for both the columns, we can now simply concat them!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df_num, df_alph], axis = 0)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's set the value for seed too, so that reproducing the same work would be possible.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Little Bit of Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Now, let'see the distribution of data over all the classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = [10, 8]\ndf.Label.value_counts().plot(kind = \"bar\")\nplt.title(\"Target value distribution\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Although the MNIST data is all perfectly balanced, the other data i.e. Alphabetical data is very highly unbalanced.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Let's now see the count of maximum and minimum frequency labels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"a, b = df.Label[df.Label == 24].value_counts().sum(), df.Label[df.Label == 18].value_counts().sum()\nprint(f\"Maximum and Minimum frequency for any target value in the data: {a, b}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 57,825 for the majority class and 1120 for minority!!\n\n> Since the data is now unbalanced, we will have to choose our metric wisely, otherwise, we may get fooled by the accuracy, although we will keep an eye out for accuracy too! ;)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Now let's divide the data into features and target.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop([\"Label\"], axis = 1)\ny = df[\"Label\"]\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Till now, the data we had was 1-Dimensional, i.e. a 28x28 picture was flattened into 784 pixels.\n\n> Let's now reshape our data into 28x28 images!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Reshaping the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_reshaped = X.values.astype(\"float32\").reshape(X.shape[0], 28, 28)\ny_int = y.values.astype(\"int32\")\nprint(X.shape, \"***\", X_reshaped.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's now split the data into train and test data with a ratio of 7:3 and stratifying the target class.\n\n> What stratifying will do is it will maintain the ratio of unique target values in train and test set same.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_reshaped = X_reshaped.reshape(-1, 28, 28, 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_int, test_size = 0.3, stratify = y)\n\ndata_to_predict = X_test.reshape(-1, 28, 28)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's define a function to plot some of the images in a grid with their respective labels.\n\n> We will be plotting the images with **gray** cmap, you can try a lot of different too, I would recommend taking a look at \"inferno\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_grid(pred = False):\n    fig=plt.figure(figsize=(8, 8))\n    columns = 3\n    rows = 3\n    for i in range(1, columns*rows +1):\n        index = np.random.randint(data_to_predict.shape[0])\n        fig.add_subplot(rows, columns, i)\n        plt.imshow(data_to_predict[index], cmap = plt.get_cmap(\"gray\"))\n        plt.xticks([])\n        plt.yticks([])\n        plt.xlabel(f\"Label: {y_test[index]}\")\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's now take some of the images from the data!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> They are a bit blurry but that's because of the low quality and figure size set by us too! Although they are very much recognizable.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Standardization of Training data with categorization training and test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_mean = X_train.mean().astype(np.float32)\nX_train_std = X_train.std().astype(np.float32)\nX_test_mean = X_test.mean().astype(np.float32)\nX_test_std = X_test.std().astype(np.float32)\n\nX_train = (X_train - X_train_mean)/X_train_std\nX_test = (X_test - X_test_mean)/X_test_std\n\ny_train = to_categorical(y_train, num_classes = 36)\ny_test = to_categorical(y_test, num_classes = 36)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train_mean, X_train_std, df_num, df_alph, X_reshaped, y_int, X, y, X_test_mean, X_test_std, data_to_predict, a, b\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Creating a simple CNN Classifier.\n\n> We will be using two blocks of [Conv2D -> Conv2d -> MaxPool2D -> Dropout] one after the another and then a [Flatten -> Dense -> Dropout -> Dense]. That's it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create CNN model for layers\ninput_shape = (28, 28, 1)\nnum_classes = 36\n\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = \"relu\", padding = \"Same\", input_shape = input_shape))\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = \"relu\", padding = \"Same\"))\nmodel.add(MaxPool2D(pool_size = (3, 3)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = \"relu\", padding = \"Same\"))\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = \"relu\", padding = \"Same\"))\nmodel.add(MaxPool2D(pool_size = (3, 3)))\nmodel.add(Dropout(0.40))\n\nmodel.add(Flatten())\nmodel.add(Dense(150, activation = \"relu\"))\nmodel.add(Dropout(0.30))\nmodel.add(Dense(36, activation = \"softmax\"))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Defining **Adam** optimizer with a learning rate of 5e-4 and no decay.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr = .0005, beta_1 = .9, beta_2 = .999, epsilon = 1e-07, decay = 0, amsgrad = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compiling model** and defining **learning rate reduction** parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\", tf.keras.metrics.AUC()])\n\n# learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3, verbose = 1, factor = .5, min_lr = .00001)\n\n# EarlyStopping\nes = EarlyStopping(monitor='val_categorical_accuracy', patience = 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We will train this now for 80 epochs, since previously, when we trained it for 40 epochs, it was still converging, so increasing the number of epochs may get us better results.\n\n> Also, we will be using a 128 batch size for this training, i.e. 128 images will the model be trained  upon at a time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 80\nbatch_size = 128","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Data Augmentation\n\n> In data augmentation, we are going to do some modifications on the images like rotation, zoom, width shift, height shift and horizontal flip. Also, one must note that doing a vertical flip may be disastrous in some cases, for example, 6 will become 9 and vice versa.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Augmentation\ndatagen = ImageDataGenerator(featurewise_center = False, samplewise_center = False, \n                            featurewise_std_normalization = False, samplewise_std_normalization = False,\n                            zca_whitening = False, rotation_range = 10, zoom_range = .1, \n                            width_shift_range = .1, height_shift_range = .1, horizontal_flip = True, \n                            vertical_flip = False)\ntrain_batches = datagen.flow(X_train, y_train, batch_size = batch_size)\nval_batches = datagen.flow(X_test, y_test, batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training + Cross Validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model\nhistory = model.fit_generator(generator = train_batches, steps_per_epoch = train_batches.n//batch_size, epochs=epochs, \n                    validation_data = val_batches, validation_steps = val_batches.n//batch_size, verbose = 0,\n                    callbacks = [learning_rate_reduction, es])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's now Save the model for future use.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model_0-10_a-z.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing trends in Accuracy and AUC","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's see the number of epochs our model run for.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Total number of epochs for which the model trained: {len(history.history['loss'])}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Why not just plot the training and validation accuracy against each other, it will help us gain a lot of information about the training, like where our model stops learning, starts overfitting etc.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [10, 8]\nplt.plot(history.history['categorical_accuracy'], \"b--\")\nplt.plot(history.history['val_categorical_accuracy'], \"r-\")\nplt.title(\"Training vs Validation accuracy\")\nplt.legend([\"Training\", \"Validation\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Maximum Training Accuracy: {max(history.history['categorical_accuracy'])}, Maximum Validation Accuracy: {max(history.history['val_categorical_accuracy'])}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Also, let's plot AUC scores for training and validation too!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [10, 8]\nplt.plot(history.history['auc'], \"b--\")\nplt.plot(history.history['val_auc'], \"r-\")\nplt.title(\"Training vs Validation AUC score\")\nplt.legend([\"Training\", \"Validation\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"AUC score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Maximum Training AUC: {max(history.history['auc'])}, Maximum Validation AUC: {max(history.history['val_auc'])}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now the see the loss curve for both training and validation!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [10, 8]\nplt.plot(history.history['loss'], \"b--\")\nplt.plot(history.history['val_loss'], \"r-\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend([\"Training\", \"Validation\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss value\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Woah, You reached the end of it!\n\n> Hope you find reading this work worrthwhile. Please share your thoughts in the comment.\n\n> Thanks for reading and Until next time! :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}