{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport gc\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\nsubmission = pd.read_csv('../input/digit-recognizer/sample_submission.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX = train[train.columns[1:]].values/255\nY = train.label.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_oof = np.zeros((X.shape[0], 10))\ntest_preds = 0\ntrain_oof.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.values/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(X)):\n    print(\"Fitting fold\", jj+1)\n    train_features = X[train_index]\n    train_target = Y[train_index]\n    \n    val_features = X[val_index]\n    val_target = Y[val_index]\n    \n    model = LogisticRegression(C=20, solver='lbfgs', multi_class='multinomial')\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)\n    train_oof[val_index] = val_pred\n    print(\"Fold accuracy:\", accuracy_score(val_target, np.argmax(val_pred, axis=1)))\n    test_preds += model.predict_proba(test)/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy_score(Y, np.argmax(train_oof, axis=1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.argmax(test_preds, axis=1)\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Label'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('test_preds', test_preds)\nnp.save('train_oof', train_oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}