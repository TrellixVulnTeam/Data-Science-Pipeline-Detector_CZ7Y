{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 처음으로는 여러가지 모델을 만들어보며 가장 좋은 모델을 찾아보았습니다","metadata":{}},{"cell_type":"markdown","source":"|      | layer의 종류와 수                                                | 파라미터 수               | best loss, accuracy                                                       | EarlyStopping 여부 |              바꾼 점              |                        한줄평                       |\n|------|------------------------------------------------------------------|---------------------------|---------------------------------------------------------------------------|:------------------:|:---------------------------------:|:---------------------------------------------------:|\n| 1차  | conv2D 1개 filters 20       /        Dense 1개 최대 units=20     | Total params: 314,030     | loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0829 - val_accuracy: 0.9806 |          o         |           기본적인 시작           |                                                     |\n| 2차  | conv2D 1개 filters 20       /        Dense 1개 최대 units=30     | Total params: 470,940     | loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0849 - val_accuracy: 0.9801 |          o         |     dense를 좀 wide하게 해보자    |                    별 차이가 없다                   |\n| 3차  | conv2D 1개 filters 20       /        Dense 1개 최대 units=100    | Total params: 1,569,310   | loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0751 - val_accuracy: 0.9806 |          o         |     dense를 더 wide하게 해보자    |                    loss가 줄었다                    |\n| 4차  | conv2D 1개 filters 20       /        Dense 1개 최대 units=300    | Total params: 4,707,510   | loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0619 - val_accuracy: 0.9843 |          o         |     dense를 더 wide하게 해보자    |                   효과는 굉장했다                   |\n| 5차  | conv2D 1개 filters 20       /        Dense 1개 최대 units=1000   | Total params: 15,691,210  | loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0683 - val_accuracy: 0.9852 |          o         |     dense를 더 wide하게 해보자    |                   효과는 미미했다                   |\n| 6차  | conv2D 1개 filters 20       /        Dense 1개 최대 units=2000   | Total params: 31,382,210  | loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0669 - val_accuracy: 0.9833 |          o         |     dense를 더 wide하게 해보자    |                   효과는 미미했다                   |\n| 7차  | conv2D 1개 filters 100       /        Dense 1개 최대 units=1000  | Total params: 7,842,110   | loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0794 - val_accuracy: 0.9813 |          o         |       filter의 수를 늘려보자      |                   효과는 미미했다                   |\n| 8차  | conv2D 1개 filters 1000       /        Dense 1개 최대 units=1000 | Total params: 784,021,010 | loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0818 - val_accuracy: 0.9818 |          o         |       filter의 수를 늘려보자      |         효과도 별로고 한epoch에 1분이 걸린다        |\n| 9차  | conv2D 1개 filters 5       /        Dense 1개 최대 units=100     | Total params: 393,160     | loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0785 - val_accuracy: 0.9804 |          o         |       filter의 수를 줄여보자      |                    별 차이가 없다                   |\n| 10차 | conv2D 1개 filters 5 / Dense 1개 최대 units=1000                 | Total params: 3,931,060   | loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0980 - val_accuracy: 0.9793 |          o         |     dense를 더 wide하게 해보자    |                    별 차이가 없다                   |\n| 11차 | conv2D 5개 filters 62 / Dense 1개 최대 units=100                 | Total params: 2,159,964   | loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0553 - val_accuracy: 0.9869 |          o         |   conv2d layer를 늘려보자(valid)  |                성능이 많이 개선되었다               |\n| 12차 | conv2D 5개 filters 62 / Dense 1개 최대 units=100(same)           | Total params: 5,011,964   | loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0511 - val_accuracy: **0.9881*** |          o         |     padding을 same으로 해보자     |                valid보다 성능이 좋다                |\n| 13차 | conv2D 27개 filters 62 ,(2,2)/ Dense 1개 최대 units=100          | Total params: 413,920     | loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1082 |          o         |   conv2d layer를 늘려보자(valid)  |             이미지가 너무 작은 것 같다.             |\n| 14차 | conv2D 27개 filters 62 ,(2,2)/ Dense 1개 최대 units=100          | Total params: 5,268,520   | loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1082 |          o         |   conv2d layer를 늘려보자(same)   |             이미지가 너무 작은 것 같다.             |\n| 15차 | conv2D 10개 filters 62 ,(2,2)/ Dense 1개 최대 units=100          | Total params: 5,006,074   | loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0896 - val_accuracy: 0.9857 |          o         |      conv2d layer를 줄여보자      | 이미지가 작기 때문에 conv2d layer가 악영향을 끼친다 |\n| 16차 | conv2D 3개 filters 62 ,(2,2)/ Dense 5개 최대 units=1000          | Total params: 398,822     | loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0794 - val_accuracy: 0.9788 |          o         | dense의 개수를 늘려보자(deep하게) |             성능은 좋으나 큰 영향은 없다            |\n| 17차 | conv2D 3개 filters 62 ,(2,2)/ Dense 5개 최대 units=1000          | Total params: 29,452,808  | loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0773 - val_accuracy: 0.9860 |          o         | dense의 개수를 늘려보자(deep하게) |             성능은 좋으나 큰 영향은 없다            |","metadata":{}},{"cell_type":"markdown","source":"# 라이브러리 import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random","metadata":{"id":"e3G6LPQKGUJG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 전처리 (이미지 로드)","metadata":{}},{"cell_type":"code","source":"mnist = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = mnist.iloc[:, 0].values\nx = mnist.iloc[:, 1:].values\n#이미지와 예측하고자 하는 값을 분류합니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n#valid set을 만듭니다.","metadata":{"id":"ipqdgtu3GWqF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = x_test / 255\nx_train = x_train / 255\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n#데이터를 계산하기 쉽도록 작게 만듭니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)\n#3,5,9처럼 숫자의 형태로 있는 y를 [0,0,0,1,0,0,0,0,0,0]와 같은 형식으로 변경해줍니다.\n#one hot encoding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.00062","metadata":{"id":"5ljl306OGc6z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(3, 3), input_shape=(28,28,1),activation='relu',kernel_initializer='glorot_uniform',padding=\"same\"))\nfor a in range(3):\n    model.add(tf.keras.layers.Conv2D(filters=62, kernel_size=(3, 3), activation='relu',kernel_initializer='glorot_uniform',padding=\"same\"))\n    model.add(tf.keras.layers.Dropout(0.38))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(units=62, kernel_initializer='glorot_normal', activation='relu'))\nmodel.add(tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal', activation='softmax'))\nmodel.summary()\n#여러 시도를 통해 얻은 값을 바탕으로 모델을 만듭니다.\n#conv2D layer는 Convolution하게 이미지를 처리해줍니다.\n#relu는 음수 값에는 0의 가중치를 양수 값에는 1의 가중치를 곱하여 값을 처리합니다.\n#kernel_initializer='glorot_uniform'는 Xavier Initialization이라고도 불리며 이전 노드와 다음 노드의 개수를 이용하여 가중치를 초기화합니다.\n#padding=\"same\"은 테두리에 0의 값을 추가시켜 어디가 모서리인지 알게 하고 output의 크기를 같게 해줍니다 padding=\"valid\"라면 아무런 값도 추가되지 않습니다.\n#Dropout은 특정 layer에 너무 많은 가중치가 쏠리는 것을 방지하여 랜덤하게 layer간의 연결을 해제하는 것입니다.\n#MaxPooling2D layer는 n,n사이즈의 사각형안에 있는 값 중 가장 큰 값만을 이용하여 새로운 이미지를 만듭니다.\n#Flatten layer는 conv2d를 거치고 나온 2차원의 데이터를 1차원의 데이터로 펴주어 dense layer를 사용할 수 있게 합니다.\n#마지막으로 softmax를 사용한다면 units개수의 target이 있을 때 1번째, 3번째 등 어디의 값일 확률이 높은지에 따라 [0,0,0,1,0,0,0,0,0,0]와 같은 형식으로 처리됩니다.","metadata":{"id":"2zpwWgByGkch","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=learning_rate), metrics=['accuracy'])\n#adam과 RMSprop이 있었으나 RMSprop이 조금 더 나은 성능을 보여주었습니다.","metadata":{"id":"Lc-bCtb7G0_y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True),\n            #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30, verbose=1)]\n#처음에는 EarlyStopping을 사용하였지만 데이터가 적어 overfitting이 되기 어려운 환경이라고 생각되어 ModelCheckpoint를 사용하였습니다.\n#ModelCheckpoint는 val_loss를 모니터 하며 가장 최상의 값을 가진 모델을 model.h5파일에 업데이트합니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, batch_size=100, epochs=100,validation_data =(x_test,y_test),callbacks=callbacks,verbose=0)\n#verbose를 0으로 하면 기록이 안보입니다.\n#verbose를 1로 하면 학습이 얼마정도 되었는지, loss, val_loss, accuracy, val_accuracy등이 표시됩니다.\n#verbose를 2로 하면 loss, val_loss, accuracy, val_accuracy등만 표시됩니다.","metadata":{"id":"KmX_uLDlG2ks","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();\n#각 값들이 어떻게 변하였는지를 살펴보고 혹시나 오버피팅이 되었는지 확인합니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)\n#one hot enciding부분입니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.load_model('./model.h5') \n#ModelCheckpoint를 사용하여 최고의 값을 보여주었던 모델을 불러옵니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\").values\ntest = test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\ny_pred = model.predict(test).argmax(axis=1)\n#모델을 이용하여 값을 예측하는 부분입니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': y_pred})\nsubmission.to_csv(\"submission.csv\", index = False)\n#dataframe을 csv형식으로 만들어 submission을 만듭니다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}