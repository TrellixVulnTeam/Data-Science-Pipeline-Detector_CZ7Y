{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What experiment did I do?","metadata":{}},{"cell_type":"markdown","source":"|   step   | layer Type and Count                                               | Total params               | best loss, accuracy                                                       | EarlyStopping |              Changes             |                        what i think about it                       |\n|------|------------------------------------------------------------------|---------------------------|---------------------------------------------------------------------------|:------------------:|:---------------------------------:|:---------------------------------------------------:|\n| 1  | conv2D 1  filters 20       /        Dense 1  max units=20     | Total params: 314,030     | loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0829 - val_accuracy: 0.9806 |          o         |           base start           |                                                     |\n| 2  | conv2D 1  filters 20       /        Dense 1  max units=30     | Total params: 470,940     | loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0849 - val_accuracy: 0.9801 |          o         |     make it wide    |                    It didn't improve                   |\n| 3  | conv2D 1  filters 20       /        Dense 1  max units=100    | Total params: 1,569,310   | loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0751 - val_accuracy: 0.9806 |          o         |     make it wide    |                    The loss has decreased                    |\n| 4  | conv2D 1  filters 20       /        Dense 1  max units=300    | Total params: 4,707,510   | loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0619 - val_accuracy: 0.9843 |          o         |     make it wide    |                   The performance has improved                   |\n| 5  | conv2D 1  filters 20       /        Dense 1  max units=1000   | Total params: 15,691,210  | loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0683 - val_accuracy: 0.9852 |          o         |     make it wide    |                   It didn't improve                   |\n| 6  | conv2D 1  filters 20       /        Dense 1  max units=2000   | Total params: 31,382,210  | loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0669 - val_accuracy: 0.9833 |          o         |     make it wide    |                   It didn't improve                   |\n| 7  | conv2D 1  filters 100       /        Dense 1  max units=1000  | Total params: 7,842,110   | loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0794 - val_accuracy: 0.9813 |          o         |       increase the number of filters      |                   It didn't improve                   |\n| 8  | conv2D 1  filters 1000       /        Dense 1  max units=1000 | Total params: 784,021,010 | loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0818 - val_accuracy: 0.9818 |          o         |       increase the number of filters      |         It didn't improve and 1epoch has 1minute        |\n| 9  | conv2D 1  filters 5       /        Dense 1  max units=100     | Total params: 393,160     | loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0785 - val_accuracy: 0.9804 |          o         |       reduce the number of filters      |                    It didn't improve                   |\n| 10 | conv2D 1  filters 5 / Dense 1  max units=1000                 | Total params: 3,931,060   | loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0980 - val_accuracy: 0.9793 |          o         |     make it wide    |                    It didn't improve                   |\n| 11 | conv2D 5  filters 62 / Dense 1  max units=100                 | Total params: 2,159,964   | loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0553 - val_accuracy: 0.9869 |          o         |   increase the conv2d layer(valid)  |                The performance has improved               |\n| 12 | conv2D 5  filters 62 / Dense 1  max units=100(same)           | Total params: 5,011,964   | loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0511 - val_accuracy: **0.9881*** |          o         |     padding = same     |                Performance is better than valid                |\n| 13 | conv2D 27  filters 62 ,(2,2)/ Dense 1  max units=100          | Total params: 413,920     | loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1082 |          o         |   increase the conv2d layer(valid)  |             The image is too small             |\n| 14 | conv2D 27  filters 62 ,(2,2)/ Dense 1  max units=100          | Total params: 5,268,520   | loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1082 |          o         |   increase the conv2d layer(same)   |             The image is too small             |\n| 15 | conv2D 10  filters 62 ,(2,2)/ Dense 1  max units=100          | Total params: 5,006,074   | loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0896 - val_accuracy: 0.9857 |          o         |      reduce the conv2d layer     | The image is too small |\n| 16 | conv2D 3  filters 62 ,(2,2)/ Dense 5  max units=1000          | Total params: 398,822     | loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0794 - val_accuracy: 0.9788 |          o         | make it deep |             It didn't improve            |\n| 17 | conv2D 3  filters 62 ,(2,2)/ Dense 5  max units=1000          | Total params: 29,452,808  | loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0773 - val_accuracy: 0.9860 |          o         | make it deep |             It didn't improve            |","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf","metadata":{"id":"e3G6LPQKGUJG","execution":{"iopub.status.busy":"2021-08-20T16:11:42.979092Z","iopub.execute_input":"2021-08-20T16:11:42.979446Z","iopub.status.idle":"2021-08-20T16:11:47.725459Z","shell.execute_reply.started":"2021-08-20T16:11:42.979407Z","shell.execute_reply":"2021-08-20T16:11:47.724652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Load","metadata":{}},{"cell_type":"code","source":"mnist = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:11:47.729849Z","iopub.execute_input":"2021-08-20T16:11:47.7301Z","iopub.status.idle":"2021-08-20T16:11:51.125242Z","shell.execute_reply.started":"2021-08-20T16:11:47.730074Z","shell.execute_reply":"2021-08-20T16:11:51.124377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = mnist.iloc[:, 0].values\nx = mnist.iloc[:, 1:].values\n#split target value and image","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:11:51.126537Z","iopub.execute_input":"2021-08-20T16:11:51.126867Z","iopub.status.idle":"2021-08-20T16:11:51.135898Z","shell.execute_reply.started":"2021-08-20T16:11:51.12683Z","shell.execute_reply":"2021-08-20T16:11:51.135077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n#make valid set","metadata":{"id":"ipqdgtu3GWqF","execution":{"iopub.status.busy":"2021-08-20T16:11:51.138147Z","iopub.execute_input":"2021-08-20T16:11:51.1388Z","iopub.status.idle":"2021-08-20T16:11:52.167621Z","shell.execute_reply.started":"2021-08-20T16:11:51.138759Z","shell.execute_reply":"2021-08-20T16:11:52.166767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = x_test / 255\nx_train = x_train / 255\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n#normalization","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:11:52.170551Z","iopub.execute_input":"2021-08-20T16:11:52.170903Z","iopub.status.idle":"2021-08-20T16:11:52.278028Z","shell.execute_reply.started":"2021-08-20T16:11:52.170865Z","shell.execute_reply":"2021-08-20T16:11:52.277038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)\n#example  3 traget value   to    [0,0,0,1,0,0,0,0,0,0]\n#one hot encoding","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:11:52.279681Z","iopub.execute_input":"2021-08-20T16:11:52.280039Z","iopub.status.idle":"2021-08-20T16:11:52.285939Z","shell.execute_reply.started":"2021-08-20T16:11:52.280002Z","shell.execute_reply":"2021-08-20T16:11:52.285022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.00062","metadata":{"id":"5ljl306OGc6z","execution":{"iopub.status.busy":"2021-08-20T16:11:52.287504Z","iopub.execute_input":"2021-08-20T16:11:52.287874Z","iopub.status.idle":"2021-08-20T16:11:52.294818Z","shell.execute_reply.started":"2021-08-20T16:11:52.287834Z","shell.execute_reply":"2021-08-20T16:11:52.293913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(3, 3), input_shape=(28,28,1),activation='relu',kernel_initializer='glorot_uniform',padding=\"same\"))\nfor a in range(3):\n    model.add(tf.keras.layers.Conv2D(filters=62, kernel_size=(3, 3), activation='relu',kernel_initializer='glorot_uniform',padding=\"same\"))\n    model.add(tf.keras.layers.Dropout(0.38))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(units=62, kernel_initializer='glorot_normal', activation='relu'))\nmodel.add(tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal', activation='softmax'))\nmodel.summary()\n#it is make by experiment","metadata":{"id":"2zpwWgByGkch","execution":{"iopub.status.busy":"2021-08-20T16:11:52.29645Z","iopub.execute_input":"2021-08-20T16:11:52.296811Z","iopub.status.idle":"2021-08-20T16:11:54.482467Z","shell.execute_reply.started":"2021-08-20T16:11:52.296772Z","shell.execute_reply":"2021-08-20T16:11:54.481491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=learning_rate), metrics=['accuracy'])\n#adam and RMSprop but experiment said \"rmsprop is a little little very little better\"","metadata":{"id":"Lc-bCtb7G0_y","execution":{"iopub.status.busy":"2021-08-20T16:11:54.483678Z","iopub.execute_input":"2021-08-20T16:11:54.484005Z","iopub.status.idle":"2021-08-20T16:11:54.501305Z","shell.execute_reply.started":"2021-08-20T16:11:54.483968Z","shell.execute_reply":"2021-08-20T16:11:54.500464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True),\n            #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30, verbose=1)]\n#i used to ealrystopping but ModelCheckpoint is more better\n#i think because it's too small scale to overfit","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:11:54.502639Z","iopub.execute_input":"2021-08-20T16:11:54.502997Z","iopub.status.idle":"2021-08-20T16:11:54.508605Z","shell.execute_reply.started":"2021-08-20T16:11:54.50297Z","shell.execute_reply":"2021-08-20T16:11:54.507641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, batch_size=100, epochs=50,validation_data =(x_test,y_test),callbacks=callbacks,verbose=0)\n#verbose=0  :   no log\n#verbose=1  :   show progress and result\n#verbose=2  :   show result","metadata":{"id":"KmX_uLDlG2ks","execution":{"iopub.status.busy":"2021-08-20T16:11:54.510057Z","iopub.execute_input":"2021-08-20T16:11:54.510508Z","iopub.status.idle":"2021-08-20T16:30:13.76277Z","shell.execute_reply.started":"2021-08-20T16:11:54.510473Z","shell.execute_reply":"2021-08-20T16:30:13.761787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot();\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();\n#check the overfitting","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:30:13.764439Z","iopub.execute_input":"2021-08-20T16:30:13.764805Z","iopub.status.idle":"2021-08-20T16:30:14.113235Z","shell.execute_reply.started":"2021-08-20T16:30:13.764766Z","shell.execute_reply":"2021-08-20T16:30:14.111598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)\n#one hot enciding","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:30:14.114695Z","iopub.execute_input":"2021-08-20T16:30:14.115042Z","iopub.status.idle":"2021-08-20T16:30:14.132247Z","shell.execute_reply.started":"2021-08-20T16:30:14.115002Z","shell.execute_reply":"2021-08-20T16:30:14.131609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.load_model('./model.h5') \n#use ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:30:14.133711Z","iopub.execute_input":"2021-08-20T16:30:14.1341Z","iopub.status.idle":"2021-08-20T16:30:14.273713Z","shell.execute_reply.started":"2021-08-20T16:30:14.13406Z","shell.execute_reply":"2021-08-20T16:30:14.272928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\").values\ntest = test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\ny_pred = model.predict(test).argmax(axis=1)\n#predict","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:30:14.274977Z","iopub.execute_input":"2021-08-20T16:30:14.275313Z","iopub.status.idle":"2021-08-20T16:30:17.404737Z","shell.execute_reply.started":"2021-08-20T16:30:14.275278Z","shell.execute_reply":"2021-08-20T16:30:17.403929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': y_pred})\nsubmission.to_csv(\"submissionmax.csv\", index = False)\n#to_csv","metadata":{"execution":{"iopub.status.busy":"2021-08-20T16:30:17.406014Z","iopub.execute_input":"2021-08-20T16:30:17.406379Z","iopub.status.idle":"2021-08-20T16:30:17.78385Z","shell.execute_reply.started":"2021-08-20T16:30:17.406342Z","shell.execute_reply":"2021-08-20T16:30:17.782985Z"},"trusted":true},"execution_count":null,"outputs":[]}]}