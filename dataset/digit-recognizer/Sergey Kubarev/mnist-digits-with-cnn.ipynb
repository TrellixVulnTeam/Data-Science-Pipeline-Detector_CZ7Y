{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"markdown","source":"In this notebook I use the Sequential Convolutional Neural Network for digits recognition. This is a fairly simple and versatile algorithm, before MNIST digits I used it for other image recognition. Although it showed less accuracy there due to the greater variety and complexity of the images. Here we have only 10 classes and they are more or less distinguishable.\n\nYou can try to use this notebook for MNIST digits recognition as well as other image recognition cases. If you have any ideas please share them in the comments, it would be interesting if you could share your approach.","metadata":{}},{"cell_type":"code","source":"# import libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Dropout, Flatten, Conv2D, MaxPool2D, LayerNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","metadata":{"id":"JU5hqYxT9g4O","execution":{"iopub.status.busy":"2021-08-05T16:43:33.535479Z","iopub.execute_input":"2021-08-05T16:43:33.536233Z","iopub.status.idle":"2021-08-05T16:43:40.8829Z","shell.execute_reply.started":"2021-08-05T16:43:33.536139Z","shell.execute_reply":"2021-08-05T16:43:40.881821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"He9b8xx39g4R","execution":{"iopub.status.busy":"2021-08-05T16:43:40.884272Z","iopub.execute_input":"2021-08-05T16:43:40.884557Z","iopub.status.idle":"2021-08-05T16:43:40.89165Z","shell.execute_reply.started":"2021-08-05T16:43:40.88453Z","shell.execute_reply":"2021-08-05T16:43:40.890558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and prepare the data","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')","metadata":{"id":"L3Jh2-S_9g4S","execution":{"iopub.status.busy":"2021-08-05T16:43:40.893936Z","iopub.execute_input":"2021-08-05T16:43:40.894566Z","iopub.status.idle":"2021-08-05T16:43:46.916677Z","shell.execute_reply.started":"2021-08-05T16:43:40.894518Z","shell.execute_reply":"2021-08-05T16:43:46.915746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#take a look at the data\n#np.unique(train)\n#train.head()","metadata":{"id":"ZeCTtkRp9g4S","execution":{"iopub.status.busy":"2021-08-05T16:43:46.918186Z","iopub.execute_input":"2021-08-05T16:43:46.918479Z","iopub.status.idle":"2021-08-05T16:43:46.922385Z","shell.execute_reply.started":"2021-08-05T16:43:46.918453Z","shell.execute_reply":"2021-08-05T16:43:46.921341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define X and Y\nX = train.drop(['label'], axis = 1)\nY = train['label']","metadata":{"id":"_qSxaGHM9g4T","execution":{"iopub.status.busy":"2021-08-05T16:43:46.923756Z","iopub.execute_input":"2021-08-05T16:43:46.924059Z","iopub.status.idle":"2021-08-05T16:43:47.051655Z","shell.execute_reply.started":"2021-08-05T16:43:46.924029Z","shell.execute_reply":"2021-08-05T16:43:47.050676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We did not make any significant transformations or conversions of the data. We rescale pixel values from the range (0, 255) to the range (0, 1) as it is the best format for neural network models. Through this transformation, we also reduce the effect of illumination's differences, which is not as relevant for our case but can generally be helpful when working with the photo. \n\nScaling data to the range (0, 1) is usually called **normalization** and, in our case, is achieved by dividing the value of each pixel by 255 (normalization coefficient 1/255 = ~0.0039).","metadata":{}},{"cell_type":"code","source":"# normalize the data (features)\nX = X / 255.0\ntest = test / 255.0","metadata":{"id":"VqrRx9rn9g4T","execution":{"iopub.status.busy":"2021-08-05T16:43:47.052933Z","iopub.execute_input":"2021-08-05T16:43:47.053243Z","iopub.status.idle":"2021-08-05T16:43:47.185824Z","shell.execute_reply.started":"2021-08-05T16:43:47.053213Z","shell.execute_reply":"2021-08-05T16:43:47.184842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert data to np.array\nX = X.values\ntest = test.values","metadata":{"id":"-qiyb5VE9g4T","outputId":"c9bbf116-853f-4d2c-d8bd-8830d091550f","execution":{"iopub.status.busy":"2021-08-05T16:43:47.187209Z","iopub.execute_input":"2021-08-05T16:43:47.187596Z","iopub.status.idle":"2021-08-05T16:43:47.19223Z","shell.execute_reply.started":"2021-08-05T16:43:47.187556Z","shell.execute_reply":"2021-08-05T16:43:47.191076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our data is now stored as 1D np.array. The length of the array is 784 (28 pixels x 28 pixels). To feed the data into the Keras model, we reshape it to 28 pixels x 28 pixels and add additional dimension for the number of channels (1 in case of greyscale).","metadata":{}},{"cell_type":"code","source":"# here we rashape the image into the following dimensions: height x width x channel\n# 28 pixels x 28 pixels x 1 pixel (for black and white)\n\nX = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)","metadata":{"id":"pHgoqU1y9g4U","execution":{"iopub.status.busy":"2021-08-05T16:43:47.194907Z","iopub.execute_input":"2021-08-05T16:43:47.19522Z","iopub.status.idle":"2021-08-05T16:43:47.204115Z","shell.execute_reply.started":"2021-08-05T16:43:47.19519Z","shell.execute_reply":"2021-08-05T16:43:47.203105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert features to categorical (similar to one hot encoder)\nY = to_categorical(Y, num_classes = 10)","metadata":{"id":"fx31ti_d9g4U","execution":{"iopub.status.busy":"2021-08-05T16:43:47.206559Z","iopub.execute_input":"2021-08-05T16:43:47.207079Z","iopub.status.idle":"2021-08-05T16:43:47.216066Z","shell.execute_reply.started":"2021-08-05T16:43:47.207033Z","shell.execute_reply":"2021-08-05T16:43:47.215002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of the data\nprint(X.shape, Y.shape)","metadata":{"id":"Qigev6qY9g4V","outputId":"e54727a1-7f0f-420b-b26f-560377c2ddb9","execution":{"iopub.status.busy":"2021-08-05T16:43:47.217595Z","iopub.execute_input":"2021-08-05T16:43:47.217895Z","iopub.status.idle":"2021-08-05T16:43:47.227135Z","shell.execute_reply.started":"2021-08-05T16:43:47.217869Z","shell.execute_reply":"2021-08-05T16:43:47.226065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into train and test\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n\nprint(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)","metadata":{"id":"m99fLoRN9g4V","outputId":"6c301c73-f652-4327-90f9-5315e3747dad","execution":{"iopub.status.busy":"2021-08-05T16:43:47.228423Z","iopub.execute_input":"2021-08-05T16:43:47.228818Z","iopub.status.idle":"2021-08-05T16:43:47.638657Z","shell.execute_reply.started":"2021-08-05T16:43:47.228786Z","shell.execute_reply":"2021-08-05T16:43:47.63743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"Here I use Keras Sequential API with the following architecture:\n\n - Input<br>\n - Conv2D - > Conv2D - > MaxPool2D -> LayerNormalization -> Dropout<br>\n - Conv2D - > Conv2D - > MaxPool2D -> LayerNormalization -> Dropout<br>\n - Flatten<br>\n - Dense<br>\n - Dropout<br>\n - Output\n","metadata":{}},{"cell_type":"markdown","source":"Some comments to the layers.\n\n**Conv2D**  layers perform the process that is called convolution. The essence of convolution is to create another set of values, which is called a kernel or filter. In our case, this is a 3 x 3 matrix. Then we scan our image using this kernel. A convolution layer is applied to each section of the input image. In other words, here, the network learns the details of the image.\n\nWe can experiment with number of filters and their size.\n\n**MaxPool2D** layer is simply compressing (reducing the size of) the image. The result will be a smaller image compared to the original input image. At this layer, the network also learns the whole structure of the image.\n\n**Dropout** layer is used to avoid overfitting. \n\n**Flatten** layer converts the data into a 1D array. ","metadata":{}},{"cell_type":"code","source":"# define the model function\n\ndef create_model():\n    \n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1), name='conv_11'))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', name='conv_12'))\n    model.add(MaxPool2D(pool_size=(2,2), name='pool_1'))\n    model.add(LayerNormalization(axis=3 , center=True , scale=True, name='norm_1'))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_21'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_22'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), name='pool_2'))\n    model.add(LayerNormalization(axis=3 , center=True , scale=True, name='norm_2'))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_31'))\n    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_32'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), name='pool_3'))\n    model.add(LayerNormalization(axis=3 , center=True , scale=True, name='norm_3'))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    \n    model.add(Dense(256, activation = \"relu\"))\n    \n    model.add(Dropout(0.4))\n    \n    model.add(Dense(10, activation = \"softmax\"))\n    \n    return model","metadata":{"id":"JhTlIUXp9g4V","execution":{"iopub.status.busy":"2021-08-05T16:48:22.640806Z","iopub.execute_input":"2021-08-05T16:48:22.641172Z","iopub.status.idle":"2021-08-05T16:48:22.656252Z","shell.execute_reply.started":"2021-08-05T16:48:22.641143Z","shell.execute_reply":"2021-08-05T16:48:22.655156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the model\nmodel_CNN = create_model()\nprint(model_CNN.summary())","metadata":{"id":"-oFSn4LNV0c1","outputId":"32271bc8-1e7d-4200-99cb-ff83f784afbf","execution":{"iopub.status.busy":"2021-08-05T16:48:30.359915Z","iopub.execute_input":"2021-08-05T16:48:30.360279Z","iopub.status.idle":"2021-08-05T16:48:30.556323Z","shell.execute_reply.started":"2021-08-05T16:48:30.36025Z","shell.execute_reply":"2021-08-05T16:48:30.555377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data augmentation** \n\nOne way to avoid overfitting and improve the accuracy is to increase the variability of existing samples. Which is also helps to compensate lack of data.\n<br>Data augmentation generates data from existing samples by applying various transformations to the original dataset. This method aims to increase the number of unique input samples, which, in turn, will allow the model to show better accuracy on the validation dataset.","metadata":{}},{"cell_type":"code","source":"# use data augmentation to improve accuracy and prevent overfitting\naugs_gen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False,  \n        vertical_flip=False) \n\ngenerator_train = augs_gen.flow(X_train, Y_train, batch_size=64)","metadata":{"id":"1teDYgaZ9g4W","execution":{"iopub.status.busy":"2021-08-05T16:48:34.872774Z","iopub.execute_input":"2021-08-05T16:48:34.873174Z","iopub.status.idle":"2021-08-05T16:48:34.946711Z","shell.execute_reply.started":"2021-08-05T16:48:34.873144Z","shell.execute_reply":"2021-08-05T16:48:34.945747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define number of steps (length of train set divided by batch size)\nsteps = int(X_train.shape[0] / 64)","metadata":{"id":"Lx7-uroI9g4W","execution":{"iopub.status.busy":"2021-08-05T16:48:38.16023Z","iopub.execute_input":"2021-08-05T16:48:38.16057Z","iopub.status.idle":"2021-08-05T16:48:38.16438Z","shell.execute_reply.started":"2021-08-05T16:48:38.160542Z","shell.execute_reply":"2021-08-05T16:48:38.163406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile the model\nmodel_CNN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"eAb7bIbr9g4X","execution":{"iopub.status.busy":"2021-08-05T16:48:40.757888Z","iopub.execute_input":"2021-08-05T16:48:40.758249Z","iopub.status.idle":"2021-08-05T16:48:40.777265Z","shell.execute_reply.started":"2021-08-05T16:48:40.758219Z","shell.execute_reply":"2021-08-05T16:48:40.776192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Callbacks are very convenient because we can be sure that the learning process will stop as soon as the chosen metrics stop improving. In this way, we can set a large number of epochs and do not worry that the metrics stopped improving.","metadata":{}},{"cell_type":"code","source":"#use callbacks\ncheckpoint = ModelCheckpoint(\"\", monitor='val_accuracy', verbose=1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=0.00005, verbose=1)\nearly_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=7, mode='auto', restore_best_weights=True)","metadata":{"id":"wj_4kSTwOy9D","execution":{"iopub.status.busy":"2021-08-05T16:48:44.061397Z","iopub.execute_input":"2021-08-05T16:48:44.061774Z","iopub.status.idle":"2021-08-05T16:48:44.066747Z","shell.execute_reply.started":"2021-08-05T16:48:44.061744Z","shell.execute_reply":"2021-08-05T16:48:44.066022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"...and here we go!","metadata":{}},{"cell_type":"code","source":"# fit the model\nhistory = model_CNN.fit(generator_train, steps_per_epoch=steps, batch_size = 64, epochs = 50, validation_data = (X_val, Y_val), verbose = 1, callbacks = [checkpoint, reduce_lr, early_stop])","metadata":{"id":"mGnpd1x39g4X","outputId":"c2df621a-abaa-41ad-e2f6-9ce561a9bcee","execution":{"iopub.status.busy":"2021-08-05T16:48:47.15071Z","iopub.execute_input":"2021-08-05T16:48:47.151078Z","iopub.status.idle":"2021-08-05T17:49:11.714248Z","shell.execute_reply.started":"2021-08-05T16:48:47.151048Z","shell.execute_reply":"2021-08-05T17:49:11.712995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the model\n\n# predict on validation set\nY_pred_val = model_CNN.predict(X_val)\n\n# check the class predicted with the highest probability (most common)\nY_pred_mc_class = np.argmax(Y_pred_val, axis=1)\n\n# check the groudtruth most common class\nY_test_mc_class = np.argmax(Y_val, axis=1)\n\n# compare them\naccuracy_on_val = np.mean(Y_pred_mc_class == Y_test_mc_class)\n\n# print the accuracy\nprint(\"Validation accuracy (after the training): \", accuracy_on_val, \"\\n\")\n\n\n# plot the validation and training accuracy\nfig, axis = plt.subplots(1, 2, figsize=(16,6))\naxis[0].plot(history.history['val_accuracy'], label='val_acc')\naxis[0].set_title(\"Validation Accuracy\")\naxis[0].set_xlabel(\"Epochs\")\naxis[1].plot(history.history['accuracy'], label='acc')\naxis[1].set_title(\"Training Accuracy\")\naxis[1].set_xlabel(\"Epochs\")\nplt.show()\n\n# plot the Confusion Matrix\nfig, ax = plt.subplots(figsize=(12, 12))\ncm = confusion_matrix(Y_test_mc_class,Y_pred_mc_class, normalize='true')\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [0,1,2,3,4,5,6,7,8,9])\ndisp = disp.plot(ax=ax,cmap=plt.cm.Blues)\nax.set_title(\"Confusion Matrix\")\nplt.show()","metadata":{"id":"9hDenzGg9g4Y","outputId":"1e7fb8d9-6b56-4fe6-b304-f6054e461652","execution":{"iopub.status.busy":"2021-08-05T17:49:11.716317Z","iopub.execute_input":"2021-08-05T17:49:11.716775Z","iopub.status.idle":"2021-08-05T17:49:17.734734Z","shell.execute_reply.started":"2021-08-05T17:49:11.71673Z","shell.execute_reply":"2021-08-05T17:49:17.733509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make prediction on real test\ny_pred_test = model_CNN.predict(test)","metadata":{"id":"dbK9782H9g4Z","execution":{"iopub.status.busy":"2021-08-05T17:49:17.736482Z","iopub.execute_input":"2021-08-05T17:49:17.736804Z","iopub.status.idle":"2021-08-05T17:49:50.725964Z","shell.execute_reply.started":"2021-08-05T17:49:17.736775Z","shell.execute_reply":"2021-08-05T17:49:50.724779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# chose the max probability item\nprediction = np.argmax(y_pred_test, axis = 1)","metadata":{"id":"FI8hh7uV9g4Z","execution":{"iopub.status.busy":"2021-08-05T17:49:50.72745Z","iopub.execute_input":"2021-08-05T17:49:50.727766Z","iopub.status.idle":"2021-08-05T17:49:50.732635Z","shell.execute_reply.started":"2021-08-05T17:49:50.727738Z","shell.execute_reply":"2021-08-05T17:49:50.731494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create submission DataFrame\nsubmission = pd.DataFrame({'ImageId' : range(1,28001), 'Label' : list(prediction)})\nsubmission.head()","metadata":{"id":"JeBOoqVv9g4a","outputId":"b13ee232-2c97-4eae-e31d-aebed965f2b9","execution":{"iopub.status.busy":"2021-08-05T17:49:50.734439Z","iopub.execute_input":"2021-08-05T17:49:50.734929Z","iopub.status.idle":"2021-08-05T17:49:50.784398Z","shell.execute_reply.started":"2021-08-05T17:49:50.734883Z","shell.execute_reply":"2021-08-05T17:49:50.783462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create CSV-file\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{"id":"3mG89A0o9g4a","execution":{"iopub.status.busy":"2021-08-05T17:49:50.785689Z","iopub.execute_input":"2021-08-05T17:49:50.785995Z","iopub.status.idle":"2021-08-05T17:49:50.845662Z","shell.execute_reply.started":"2021-08-05T17:49:50.785964Z","shell.execute_reply":"2021-08-05T17:49:50.844466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!kaggle competitions submit -c digit-recognizer -f submission.csv -m \"Message\"","metadata":{"execution":{"iopub.status.busy":"2021-08-05T16:43:48.277685Z","iopub.status.idle":"2021-08-05T16:43:48.278225Z"},"trusted":true},"execution_count":null,"outputs":[]}]}