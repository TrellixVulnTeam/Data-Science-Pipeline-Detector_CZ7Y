{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"reading files"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\nsub=pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=train[\"label\"]\nX=train.drop(columns=['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reshaping"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]) \n\nReference from : https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nY = to_categorical(Y, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" X_train, X_test, y_train, y_test = train_test_split(\n...     X, Y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling\nusing CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1\nmodel = Sequential()\n#Layer 1\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#Layer2\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n#Layer3\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(X,Y,validation_split=0.2,epochs=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After train visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Complexity Graph:  Training vs. Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\n\nplt.figure(2)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### With Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(featurewise_center=False, \n                             samplewise_center=False, \n                             featurewise_std_normalization=False, \n                             samplewise_std_normalization=False, \n                             zca_whitening=False, \n                             zca_epsilon=1e-06, \n                             rotation_range=10, \n                             width_shift_range=0.1, \n                             height_shift_range=0.1, \n                             brightness_range=None, \n                             shear_range=0.1, \n                             zoom_range=0.15, \n                             channel_shift_range=0.0, \n                             fill_mode='nearest', \n                             cval=0.0, \n                             horizontal_flip=False, \n                             vertical_flip=False, \n                             rescale=None, \n                             preprocessing_function=None, \n                             data_format=None, validation_split=0.0, dtype=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#history=model.fit(X,Y,validation_split=0.2,epochs=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After train visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(1)\n#plt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\n#plt.title('Model Complexity Graph:  Training vs. Validation Loss')\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validate'], loc='upper right')\n\n#plt.figure(2)\n#plt.plot(history.history['acc'])\n#plt.plot(history.history['val_acc'])\n#plt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\n#plt.ylabel('accuracy')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validate'], loc='upper right')\n#plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test)\npred = np.argmax(pred,axis = 1)\npred = pd.Series(pred,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\nout.to_csv(\"output.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Help me increase the accuracy :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"learntools_metadata":{"lesson_index":6,"type":"exercise"}},"nbformat":4,"nbformat_minor":1}