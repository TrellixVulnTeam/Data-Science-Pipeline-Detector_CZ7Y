{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Build your first Convolutional Neural Network using Keras\n### This notebook will be your first step towards CNNs and Deep Learning.\n* **1. Introduction**\n* **2. Data**\n    * 2.1 Importing Data\n    * 2.2 Exploring Data\n    * 2.3 Preprocessing\n    * 2.4 Splitting\n* **3. CNN**\n    * 3.1 Defining the model\n    * 3.2 Compiling the model with the right Optimizer, loss and metric.\n    * 3.3 Training the model\n* **4. Evaluation**\n    * 4.1 Evaluating the model\n    * 4.2 Visualizing the model's performance\n* **5. Prediction and submission**"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nCNNs, short for Convolutionary Neural Networks, are a class of neural networks mostly used for dealing with image or video data.<br />\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex.<br />\nCNNs apply filters to images in order to extract different features, small (edges, curvatures..etc) and big (whole shapes, patterns..etc)<br />"},{"metadata":{},"cell_type":"markdown","source":"# Data\n### Importing Data\nFirst thing to do is import all the libraries you're going to need."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport numpy as np \n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import the input files\ntrain = pd.read_csv('../input/digit-recognizer/train.csv') \nevaluation = pd.read_csv('../input/digit-recognizer/test.csv')\nsample = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\n\nprint(f'train shape = {train.shape}', f'test shape = {evaluation.shape}', sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Data\nAfter printing out the shapes of 'train' and 'evaluation', you can see that the train set contains 1 additional column, use .head() to have a look at the first 5 rows of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown, the first row \"label\" is the class of each instance, which should be our output. <br />\nNow, let's see if our data contains any flaws <br />\nCheck if the dataset contains any null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().any().sum())\nprint(evaluation.isnull().any().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing\nTake the 'labels' column out and use .describe() to have some insight on the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = train['label']\ntrain = train.drop('label',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we know, the images come in a grayscale format where all the values are between (0-255), a good thing you should do is standarize the data, which makes it easier for the model to converge. <br />\nStandarization transforms the data in a way that scales all the values between (0-1), you can do this easily by dividing all values by 255 since our values come in a (0-255) range"},{"metadata":{"trusted":true},"cell_type":"code","source":"train /= 255\nevaluation /= 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's describe our dataset again and notice if the standard deviation (std) is any different"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The standard deviation is much lower now, good job! <br />\nLet's check out one random sample using the .imshow() function."},{"metadata":{"trusted":true},"cell_type":"code","source":"index = np.random.randint(0,42000)\ntest_image = train.values[index].reshape(28,28)\nplt.imshow(test_image, cmap = 'bone')\nplt.title(targets.values[index])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.values.reshape(-1,28,28,1)\nevaluation = evaluation.values.reshape(-1,28,28,1)\ntargets = targets.values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting\nSplit the data into train and test segments, a 0.1-0.2 test-train ratio is good for most cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, targets, stratify = targets, test_size = 0.1, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN\n### Defining the model\nOur model will be 2 layers of (2x Conv2D, 1x Maxpooling, 1x BatchNorm, 1x Dropout), 2 Dense layers and 1 output layer. <br />\nYou can mess around with the number of layers and parameters of each layer and see how it affects your evaluation score."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, input_shape = (28,28,1), kernel_size = (3,3), activation = 'relu'))\nmodel.add(Conv2D(32, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation = 'softmax'))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compiling the model with the right Optimizer, loss and metric.\nYou can try and use other optimizers such as SGD, Adam works very well."},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr=0.001)\nmodel.compile(optimizer = optimizer,\n             loss = 'sparse_categorical_crossentropy',\n             metrics = ['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 15\nBATCH_SIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = EPOCHS, batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation\n### Evaluating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the model's performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend(['train','validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction and submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation = evaluation.reshape(28000,28,28,1)\nresults = model.predict_classes(evaluation)\n\nresults = pd.Series(results, name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), results], axis = 1)\n\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thank you for reading!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}