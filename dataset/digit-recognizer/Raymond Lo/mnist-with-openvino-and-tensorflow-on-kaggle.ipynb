{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#setup the environment\n!pip install -q openvino-dev[onnx,tensorflow2]==2022.1.0 &> error_log_openvino.txt\n#!pip install -q tensorflow==2.5.1\n!pip install -q pandas==1.2.4 &> error_log_panda.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model(x_train[:1]).numpy()\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.nn.softmax(predictions).numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn(y_train[:1], predictions).numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test,  y_test, verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probability_model(x_test[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fname=\"mnist\"\nprobability_model.save(model_fname)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from openvino.inference_engine import IECore\nfrom pathlib import Path\nimport json\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# The paths of the source and converted models\nmodel_name = \"mnist\"\nmodel_path = Path(model_name)\nir_data_type = \"FP16\"\nir_model_name = \"mnist_ir\"\n\n# Get the path to the Model Optimizer script\n\n# Construct the command for Model Optimizer\nmo_command = f\"\"\"mo\n                 --saved_model_dir \"{model_name}\"\n                 --input_shape \"[1,28,28,1]\" \n                 --data_type \"{ir_data_type}\" \n                 --output_dir \"{model_path.parent}\"\n                 --model_name \"{ir_model_name}\"\n                 \"\"\"\nmo_command = \" \".join(mo_command.split())\n\n# Run the Model Optimizer (overwrites the older model)\nprint(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\nmo_result = %sx $mo_command\nprint(\"\\n\".join(mo_result))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xml = \"mnist_ir.xml\"\nmodel_bin = \"mnist_ir.bin\"\n\n# Load network to the plugin\nie = IECore()\nnet = ie.read_network(model=model_xml, weights=model_bin)\n\nexec_net = ie.load_network(network=net, device_name=\"CPU\")\n\ndel net\n\n#test against a few images from the dataset\ninput_list = x_test[:10]\n\nfor input_image in input_list:\n  input_layer = next(iter(exec_net.input_info))\n  output_layer = next(iter(exec_net.outputs))\n\n  res = exec_net.infer(inputs={input_layer: input_image})\n  res = res[output_layer]\n  X = input_image\n  X = X.reshape([28, 28]);\n  plt.figure()\n  plt.gray()\n  plt.imshow(X)\n  plt.text(0,-1, \"The prediction is \"+str(np.argmax(res[0]))+\" @ \"+str(max(res[0])*100)+\"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's Test the Tensorflow Solution on the test.csv!","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nsubmit_data = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = test_data.to_numpy().reshape(28000,1, 28,28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.zeros((28000,1))\ni=0\nfor test_img in test_imgs:\n    input_layer = next(iter(exec_net.input_info))\n    output_layer = next(iter(exec_net.outputs))\n    res = exec_net.infer(inputs={input_layer: test_img})\n    res = res[output_layer]\n    #X = input_image\n    #X = X.reshape([28, 28]);\n    #plt.figure()\n    #plt.gray()\n    #plt.imshow(X)\n    #plt.text(0,-1, \"The prediction is \"+str(np.argmax(res[0]))+\" @ \"+str(max(res[0])*100)+\"%\")\n    pred[i] = np.argmax(res[0])\n    i=i+1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind = pd.DataFrame(np.arange(1,28001), columns=['ImageId'])\n\npred_sub = pd.DataFrame(pred.astype('int32'), columns=['Label'])\nsubmission = [ind , pred_sub]\nsub = pd.concat(submission, axis=1)\n\ncompression_opts = dict(method='zip',\n                        archive_name='submission.csv')  \nsub.to_csv('submission.zip', index=False, compression=compression_opts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}