{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\ntrain_data = np.loadtxt( \"../input/digit-recognizer/train.csv\", delimiter=\",\", skiprows=1)\n\nx = (train_data[:, 1:])\ny = (train_data[:, [0]])\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T09:38:46.093135Z","iopub.execute_input":"2021-06-06T09:38:46.093626Z","iopub.status.idle":"2021-06-06T09:39:08.122316Z","shell.execute_reply.started":"2021-06-06T09:38:46.093519Z","shell.execute_reply":"2021-06-06T09:39:08.121409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"digits = 10\nAll_of_mnist_record = 42000\nEpoch = 2000\nimageID = 9\nn_x = 784\nn_h = 64\nlearning_rate = 4\n\nX = x / 255\ny = y.reshape(1, All_of_mnist_record)\nY_new = np.eye(digits)[y.astype('int32')]\nY_new = Y_new.T.reshape(digits, All_of_mnist_record)\n\n\n\nX_train, X_test = X[:All_of_mnist_record].T, X[All_of_mnist_record:].T\nY_train, Y_test = Y_new[:,:All_of_mnist_record], Y_new[:,All_of_mnist_record:]\n\nW1 = np.random.randn(n_h, n_x)\nb1 = np.zeros((n_h, 1))\nW2 = np.random.randn(digits, n_h)\nb2 = np.zeros((digits, 1))\n\nX = X_train\nY = Y_train\n\n\nbeta = .9\nbatch_size = 128\nbatches = -(-All_of_mnist_record // batch_size)\n\n\n\nyPredicted = np.array(Y[:,imageID].T, dtype=float) \nprint(yPredicted)\nxPredicted = np.array(X[:,imageID].T, dtype=float) \nplt.imshow(X[:,imageID].reshape(28,28), cmap = matplotlib.cm.binary)\nplt.axis(\"off\")\nplt.show()\n\ndef sigmoid(z):\n    s = 1 / (1 + np.exp(-z))\n    return s\n\ndef loss(Y, Y_hat):\n    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n    L = -(1/All_of_mnist_record) * L_sum\n    return L\n\n\n\ndef feed_forward(X, params):\n\n    cache = {}\n\n    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n\n    return cache\n\ndef back_propagate(X, Y, params, cache):\n\n    dZ2 = cache[\"A2\"] - Y\n    dW2 = (1./m_batch) * np.matmul(dZ2, cache[\"A1\"].T)\n    db2 = (1./m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n\n    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n    dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n    dW1 = (1./m_batch) * np.matmul(dZ1, X.T)\n    db1 = (1./m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n\n    back_propagate_res = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n\n    return back_propagate_res\n\n\n# initialization\nparams = { \"W1\": np.random.randn(n_h, n_x) * np.sqrt(1. / n_x),\n           \"b1\": np.zeros((n_h, 1)) * np.sqrt(1. / n_x),\n           \"W2\": np.random.randn(digits, n_h) * np.sqrt(1. / n_h),\n           \"b2\": np.zeros((digits, 1)) * np.sqrt(1. / n_h) }\n\nV_dW1 = np.zeros(params[\"W1\"].shape)\nV_db1 = np.zeros(params[\"b1\"].shape)\nV_dW2 = np.zeros(params[\"W2\"].shape)\nV_db2 = np.zeros(params[\"b2\"].shape)\n\n\nfor i in range(Epoch):\n\n    permutation = np.random.permutation(X_train.shape[1])\n    X_train_shuffled = X_train[:, permutation]\n    Y_train_shuffled = Y_train[:, permutation]\n\n    for j in range(batches):\n\n        begin = j * batch_size\n        end = min(begin + batch_size, X_train.shape[1] - 1)\n        X = X_train_shuffled[:, begin:end]\n        Y = Y_train_shuffled[:, begin:end]\n        m_batch = end - begin\n\n        cache = feed_forward(X, params)\n        back_propagate_res = back_propagate(X, Y, params, cache)\n\n        V_dW1 = (beta * V_dW1 + (1. - beta) * back_propagate_res[\"dW1\"])\n        V_db1 = (beta * V_db1 + (1. - beta) * back_propagate_res[\"db1\"])\n        V_dW2 = (beta * V_dW2 + (1. - beta) * back_propagate_res[\"dW2\"])\n        V_db2 = (beta * V_db2 + (1. - beta) * back_propagate_res[\"db2\"])\n\n        params[\"W1\"] = params[\"W1\"] - learning_rate * V_dW1\n        params[\"b1\"] = params[\"b1\"] - learning_rate * V_db1\n        params[\"W2\"] = params[\"W2\"] - learning_rate * V_dW2\n        params[\"b2\"] = params[\"b2\"] - learning_rate * V_db2\n\n    \n    if (i % 10 == 0):\n      cache = feed_forward(X_train, params)\n      train_cost = loss(Y_train, cache[\"A2\"])\n      print(\"Epoch {}: training cost = {}\".format(i ,train_cost))\n      #Z1 = np.matmul(params[\"W1\"], xPredicted) + V_db1\n      #A1 = sigmoid(Z1)\n      #Z2 = np.matmul(params[\"W2\"], A1) + V_db2\n      #A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n      #predictions = np.argmax(A2, axis=0)\n      #print(predictions)\n      cache = feed_forward(X_test, params)\n      predictions = np.argmax(cache[\"A2\"], axis=0)\n      #print(predictions)\n      labels = np.argmax(Y_test, axis=0)\n      #print(labels)\n\n      #cache = feed_forward(xPredicted, params)\n      #predictions = np.argmax(cache[\"A2\"], axis=0)\n      #print(predictions)\n      #print((np.mean(predictions)))\n\n\n\nprint(\"Done.\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:39:08.123615Z","iopub.execute_input":"2021-06-06T09:39:08.124033Z","iopub.status.idle":"2021-06-06T09:40:25.871239Z","shell.execute_reply.started":"2021-06-06T09:39:08.123994Z","shell.execute_reply":"2021-06-06T09:40:25.86967Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}