{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport numpy as np \nimport pandas as pd \n\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import confusion_matrix\nimport cv2 \nimport torch\nimport torch.nn.functional as F\n\nimport gc\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data and Processing the Data","metadata":{}},{"cell_type":"code","source":"data = np.genfromtxt(\"/kaggle/input/digit-recognizer/train.csv\", delimiter=',', skip_header=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape)\nX, y = data[:, 1:], data[:, 0]\n# Centring images to be of mean 0 and standard deviation of 1\nX = (X - np.mean(X, axis=1).reshape(-1, 1))\nX = X/np.std(X).reshape(-1, 1)\nprint(f\"X-shape: {X.shape}\")\nprint(f\"y-shape: {y.shape}\")\nprint(np.mean(X[10, :]))\nprint(np.std(X[10, :]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_transformed = X.copy().reshape(X.shape[0], 28, 28)\nprint(X_transformed.shape)\nindeces = []\n\nfor i in range(0, 10):\n    indeces.append(np.where(y == i)[0][0])\n\ngs = GridSpec(2, 5)\n\naxes = []\nfor row in range(0, 2):\n    for col in range(0, 5):\n        axes.append(plt.subplot(gs[row, col]))\n\nfor row in range(0, 2):\n    for col in range(0, 5):\n        axes[row*5 + col].imshow(X_transformed[indeces[row* 5 + col]], cmap=\"gray\")\n        axes[row*5 + col].set_xticks([])\n        axes[row*5 + col].set_yticks([])\n\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"class DifferentTransformation(object):\n    \n    @staticmethod\n    def rotation(X, y, cols, rows, arr):\n        X_tr = []\n        y_tr = []\n        tx = 1\n        ty = 1\n        counter = 0\n        #iterate over examples\n        while counter < X.shape[0]:\n            for x_angle in arr:\n                M = cv2.getRotationMatrix2D((cols/2, rows/2), x_angle, 1)\n                X_tr.append(cv2.warpAffine(X[counter], M, (cols, rows)))\n                y_tr.append(y[counter])\n            counter += 1\n        \n        return np.asarray(X_tr), np.asarray(y_tr)\n    \n    @staticmethod\n    def translation(X, y, cols, rows, arr):\n        X_tr = []\n        y_tr = []\n        tx = 1\n        ty = 1\n        M = np.float32([[1, 0, tx], [0, 1, ty]])\n        counter = 0\n        #iterate over examples\n        while counter < X.shape[0]:\n            for i in  arr:\n                tx = i\n                for j in arr:\n                    M[0, 2] = tx\n                    M[1, 2] = ty\n                    X_tr.append(cv2.warpAffine(X[counter], M, (cols, rows)))\n                    y_tr.append(y[counter])\n                    ty = j\n            counter += 1\n        \n        return np.asarray(X_tr), np.asarray(y_tr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \nX_augmented, y_augmented = DifferentTransformation.rotation(X_transformed, y, X_transformed[0].shape[1], X_transformed[0].shape[0], [0, 15, 30, 45]) #In order to ensure that some numbers aren't flipped to be another number, like 6 and 9\n#X_augmented, y_augmented = DifferentTransformation.translation(X_transformed, y, X_transformed[0].shape[1], X_transformed[0].shape[0], list(range(-2, 2, 2)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_augmented.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 4)\naxes[0].imshow(X_augmented[np.where(y_augmented == 6)[0][0]])\naxes[1].imshow(X_augmented[np.where(y_augmented == 6)[0][1]])\naxes[2].imshow(X_augmented[np.where(y_augmented == 6)[0][2]])\naxes[3].imshow(X_augmented[np.where(y_augmented == 6)[0][3]])\naxes[0].set_xticks([])\naxes[1].set_xticks([])\naxes[2].set_xticks([])\naxes[3].set_xticks([])\naxes[0].set_yticks([])\naxes[1].set_yticks([])\naxes[2].set_yticks([])\naxes[3].set_yticks([])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting Data into Train and validation set","metadata":{}},{"cell_type":"code","source":"X_train = None\nX_validation = None\ny_train = None\ny_validation = None\n\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_ind, test_ind in splitter.split(X_augmented, y_augmented):\n    X_train = X_augmented[train_ind]\n    y_train = y_augmented[train_ind]\n    X_validation = X_augmented[test_ind]\n    y_validation = y_augmented[test_ind]\n\nprint(X_train.shape)\nprint(X_validation.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1)\n\nax1.hist(y_train, density=True)\nax2.hist(y_train, density=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforming our data from numpy to tensors","metadata":{}},{"cell_type":"code","source":"X_train_tensor = torch.from_numpy(X_train)\ny_train_tensor = torch.from_numpy(y_train)\nX_validation_tensor = torch.from_numpy(X_validation)\ny_validation_tensor = torch.from_numpy(y_validation)\n\nX_train_tensor_4d = torch.ones((len(X_train_tensor), 1, 28, 28))\nX_train_tensor_4d[:, 0, :, :] = X_train_tensor\nX_validation_tensor_4d = torch.ones((len(X_validation_tensor), 1, 28, 28))\nX_validation_tensor_4d[:, 0, :, :] = X_validation_tensor\nX_train_tensor_4d.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the LeNet-5 model from scratch","metadata":{}},{"cell_type":"code","source":"class LeNet5(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(LeNet5, self).__init__()\n        self.cnn1 = torch.nn.Conv2d(1, 6, (5, 5), 1)\n        self.pool = torch.nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        self.cnn2 = torch.nn.Conv2d(6, 16, (5, 5), 1)\n        self.cnn3 = torch.nn.Conv2d(16, 120, (5, 5), 1)\n        self.fc1 = torch.nn.Linear(120, 84)\n        self.fc2 = torch.nn.Linear(84, 10)\n        \n    def forward(self, x):\n        #Pad the image because in the original paper the first CNN had same padding\n        x = F.pad(x, (2, 2, 2, 2))#pad it from all sides\n        x = torch.tanh(self.cnn1(x))\n        x = self.pool(x)\n        x = torch.tanh(self.cnn2(x))\n        x = self.pool(x)\n        x = torch.tanh(self.cnn3(x))\n        # flatten the layer\n        x = x.view(-1, 120)#nx120\n        x = torch.tanh(self.fc1(x))\n        x = F.softmax(self.fc2(x), dim=1)#Apply softmax to the rows of the column vector.\n        \n        return x\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize parameters","metadata":{}},{"cell_type":"code","source":"def init_param(layer):\n    if type(layer) == torch.nn.Linear:\n        torch.nn.init.xavier_normal_(layer.weight)\n    if type(layer) == torch.nn.Conv2d:\n        torch.nn.init.xavier_uniform_(layer.weight)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LeNet5()\nmodel.apply(init_param)\ncounter = 1\n# Check the layers with their initalized values\n# for param in model.parameters():\n#     print(\"Level: \", counter)\n#     print(param)\n#     counter += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\nloss_fn = torch.nn.CrossEntropyLoss()\ntraining_error = []\nvalidation_error = []\nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nbatch_size = 256\nnum_batches = int(len(X_train_tensor_4d)/batch_size)\n\nbegin = time.time()\n\nfor epoch in range(0, 5):\n    counter = 0\n    current_error = []\n    for batch in range(0, num_batches):\n        optimizer.zero_grad()\n        y_pred = model(X_train_tensor_4d[counter: counter + batch_size])\n        loss = loss_fn(y_pred, y_train_tensor[counter: counter + batch_size].type(torch.LongTensor))\n        loss.backward()\n        optimizer.step()\n        current_error.append(loss.item())\n        counter += batch_size\n    if counter < len(X_train_tensor_4d):\n        optimizer.zero_grad()\n        y_pred = model(X_train_tensor_4d[counter: ])\n        loss = loss_fn(y_pred, y_train_tensor[counter: ].type(torch.LongTensor))\n        loss.backward()\n        optimizer.step()\n        current_error.append(loss.item())\n        \n    y_pred = model(X_validation_tensor_4d)\n    \n    validation_error.append(loss_fn(y_pred, y_validation_tensor.type(torch.LongTensor)).item())\n    training_error.append(np.mean(current_error))\n    print(f\"#epoch: {epoch} and the -log training error is {np.mean(current_error)}\")    \n    print(f\"#epoch: {epoch} and the -log validation error is {validation_error[epoch]}\")\n\n    print(f\"Time taken to finish training the model is {time.time() - begin} sec\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training  vs Validation error curve","metadata":{}},{"cell_type":"code","source":"# Training vs Validation error\nplt.plot(training_error, c=\"green\")\nplt.plot(validation_error, c=\"red\")\nplt.legend([\"Training_error\", \"Validation_error\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"-log-likelihood\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix performance for the Training, and Validation set","metadata":{}},{"cell_type":"code","source":"#Training confusion matrix \ny_pred = model(X_train_tensor_4d)\ny_p = torch.argmax(y_pred, dim=1)\ncnf = confusion_matrix(y_train_tensor, y_p)\n# plt.matshow(cnf)\n# plt.colorbar()\nprint(f\"Accuracy {np.sum(np.diag(cnf))/len(X_train_tensor_4d)}\")\ncnf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_train_tensor_4d\ndel y_train_tensor\ndel cnf\ndel y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validation confusion matrix \ny_pred = model(X_validation_tensor_4d)\ny_p = torch.argmax(y_pred, dim=1)\ncnf = confusion_matrix(y_validation_tensor, y_p)\nprint(f\"Accuracy {np.sum(np.diag(cnf))/len(X_validation_tensor_4d)}\")\ncnf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_validation_tensor_4d\ndel y_validation_tensor\ndel cnf\ndel y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Set Prediction","metadata":{}},{"cell_type":"code","source":"data = np.genfromtxt(\"/kaggle/input/digit-recognizer/test.csv\", delimiter=',', skip_header=1)\ndata = data - np.mean(data, axis=1).reshape(-1, 1)\ndata = data/np.std(data, axis=1).reshape(-1, 1)\nprint(np.mean(data[0]))\nprint(np.std(data[0]))\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_transformed = data.reshape(data.shape[0], 28, 28)\nX_tensor = torch.from_numpy(X_transformed)\nX_tensor_4d = torch.ones((len(X_tensor), 1, 28, 28))\nX_tensor_4d[:, 0, :, :] = X_tensor\nX_tensor_4d.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model(X_tensor_4d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(np.c_[torch.IntTensor(list(range(1, len(y_pred) + 1))), torch.argmax(y_pred, dim=1)], columns=[\"ImageId\", \"Label\"])\nresults.to_csv(\"submission.csv\", index=False)\nresults.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 5)\n\ncounter = 0\nfor row in range(0, 5):\n    for col in range(0, 5):\n        axes[row, col].imshow(X_tensor_4d[counter, 0, :, :])\n        axes[row, col].set_xticks([])\n        axes[row, col].set_yticks([])\n        counter += 1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.argmax(y_pred[0:25], dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference \nhttp://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf","metadata":{}}]}