{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Conv2D, Input, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.layers import LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")\nX = train.drop(['label'],1).values\nY = train['label'].values\nx_test = test.values\n\nX = X/255.\nx_test = x_test/255.\n\nX = X.reshape(-1,28,28,1)\nx_test = x_test.reshape(-1,28,28,1)\n\nY = to_categorical(Y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(X,Y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    In = Input(shape=(28,28,1))\n    x = Conv2D(32, (3,3), padding=\"same\")(In)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = Conv2D(32, (3,3), padding=\"same\")(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Conv2D(64, (3,3), padding=\"same\")(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = Conv2D(64, (3,3), padding=\"same\")(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(128, (3,3), padding=\"same\")(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = Conv2D(128, (3,3), padding=\"same\")(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Dropout(0.2)(x)\n    x = Flatten()(x)\n    x = Dense(512)(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    x = Dense(256)(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    x = Dense(128)(x)\n    x = LeakyReLU(alpha=0.01)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    Out = Dense(10, activation=\"softmax\")(x)\n    model = Model(In, Out)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model\n    \nmodel = get_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_checkpoint = ModelCheckpoint('best.hdf5',monitor = 'val_loss', mode = \"min\", verbose = 1, save_best_only = True)\nlr_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5, min_lr = 1e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\nepochs = 100\nbatch_size = 128\n\ntrain_generator = data_generator.flow(x_train, y_train, batch_size=batch_size)\nvalid_generator = data_generator.flow(x_valid, y_valid, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch = x_train.shape[0]//batch_size,\n                    validation_data = valid_generator, validation_steps = x_valid.shape[0]//batch_size, callbacks=[best_checkpoint, lr_reduction], verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(hist.history[\"val_loss\"])\nplt.plot(hist.history[\"loss\"])\nplt.legend([\"val_loss\",\"loss\"])\nplt.show()\nplt.plot(hist.history[\"val_accuracy\"])\nplt.plot(hist.history[\"accuracy\"])\nplt.legend([\"val_accuracy\",\"accuracy\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best = load_model(\"best.hdf5\")\npreds = best.predict(x_test, verbose=1)\npreds = np.array([np.argmax(i) for i in preds])\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Label'] = preds\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}