{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generative Adversarial Networks(GAN) - PyTorch Tutorial","metadata":{}},{"cell_type":"markdown","source":"![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHwq72%2FbtqAY6E0wYb%2FBFRgtJWTY3Ij9BKks7vsM1%2Fimg.png)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:52:00.242873Z","iopub.execute_input":"2021-06-23T15:52:00.243235Z","iopub.status.idle":"2021-06-23T15:52:00.880086Z","shell.execute_reply.started":"2021-06-23T15:52:00.243159Z","shell.execute_reply":"2021-06-23T15:52:00.879121Z"}}},{"cell_type":"markdown","source":"This kernel is for those new to gan.\n\nAnd It was coded with pytorch, and all the code was converted into the familiar Jupyter notebook form for data analysts and machine learning engineers by referring to the gan official Python code.\n\nI hope that many Kaglers will be interested in Generative Adversarial Networks(GAN), and that it will be shared and helpful to more people. So let's get started!","metadata":{}},{"cell_type":"markdown","source":"## MAIN Reference\n1. [PyTorch-GAN | Github/eriklindernoren | Collection of PyTorch implementations of GAN](https://github.com/sw-song/PyTorch-GAN)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T13:11:22.760514Z","iopub.execute_input":"2021-06-12T13:11:22.760936Z","iopub.status.idle":"2021-06-12T13:11:22.773432Z","shell.execute_reply.started":"2021-06-12T13:11:22.760902Z","shell.execute_reply":"2021-06-12T13:11:22.771815Z"}}},{"cell_type":"markdown","source":"## Index\n```\nStep 1. Import Libraries\nStep 2. Initial Setting\nStep 3. Define Generator\nStep 4. Define Discriminator\nStep 5. Define Loss Function\nStep 6. Initialize Generator and Discriminator\nStep 7. GPU Setting\nStep 8. Configure Data Loader\nStep 9. Define Optimizers\nStep 10. Training\n```\n---","metadata":{}},{"cell_type":"markdown","source":"### Step 1. Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torch.autograd import Variable \n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.76768Z","iopub.execute_input":"2021-06-14T10:50:34.768033Z","iopub.status.idle":"2021-06-14T10:50:34.77236Z","shell.execute_reply.started":"2021-06-14T10:50:34.767977Z","shell.execute_reply":"2021-06-14T10:50:34.771544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2. Initial setting","metadata":{}},{"cell_type":"code","source":"channels = 1 # suggested default : 1, number of image channels (gray scale)\nimg_size = 28 # suggested default : 28, size of each image dimension\nimg_shape = (channels, img_size, img_size) # (Channels, Image Size(H), Image Size(W))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.773847Z","iopub.execute_input":"2021-06-14T10:50:34.774404Z","iopub.status.idle":"2021-06-14T10:50:34.788265Z","shell.execute_reply.started":"2021-06-14T10:50:34.774368Z","shell.execute_reply":"2021-06-14T10:50:34.787202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 100 # suggested default. dimensionality of the latent space","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.790093Z","iopub.execute_input":"2021-06-14T10:50:34.790628Z","iopub.status.idle":"2021-06-14T10:50:34.796599Z","shell.execute_reply.started":"2021-06-14T10:50:34.790593Z","shell.execute_reply":"2021-06-14T10:50:34.795814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False # GPU Setting","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.798194Z","iopub.execute_input":"2021-06-14T10:50:34.798723Z","iopub.status.idle":"2021-06-14T10:50:34.804645Z","shell.execute_reply.started":"2021-06-14T10:50:34.798688Z","shell.execute_reply":"2021-06-14T10:50:34.803778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3. Define Generator","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        \n        def block(input_features, output_features, normalize=True):\n            layers = [nn.Linear(input_features, output_features)]\n            if normalize: # Default\n                layers.append(nn.BatchNorm1d(output_features, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True)) # inplace=True : modify the input directly. It can slightly decrease the memory usage.\n            return layers # return list of layers\n        \n        self.model = nn.Sequential(\n            *block(latent_dim, 128, normalize=False), # Asterisk('*') in front of block means unpacking list of layers - leave only values(layers) in list\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))), # np.prod(1, 28, 28) == 1*28*28\n            nn.Tanh() # result : from -1 to 1\n        )\n\n    def forward(self, z): # z == latent vector(random input vector)\n        img = self.model(z) # (64, 100) --(model)--> (64, 784)\n        img = img.view(img.size(0), *img_shape) # img.size(0) == N(Batch Size), (N, C, H, W) == default --> (64, 1, 28, 28)\n        return img","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.805865Z","iopub.execute_input":"2021-06-14T10:50:34.806527Z","iopub.status.idle":"2021-06-14T10:50:34.815557Z","shell.execute_reply.started":"2021-06-14T10:50:34.806487Z","shell.execute_reply":"2021-06-14T10:50:34.814682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Read More\n- [What is the difference between nn.ReLU() and nn.ReLU(inplace=True)?](https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-and-nn-relu-inplace-true/948)\n- [Tanh](https://wiki.documentfoundation.org/Documentation/Calc_Functions/TANH)\n- [Unpacking Operators in Python](https://towardsdatascience.com/unpacking-operators-in-python-306ae44cd480)","metadata":{}},{"cell_type":"markdown","source":"### Step 4. Define Discriminator","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.Linear(int(np.prod(img_shape)), 512), # (28*28, 512)\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid() # result : from 0 to 1\n        )\n    \n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1) #flatten -> from (64, 1, 28, 28) to (64, 1*28*28)\n        validity = self.model(img_flat) # Discriminate -> Real? or Fake? (64, 784) -> (64, 1)\n        return validity","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.816699Z","iopub.execute_input":"2021-06-14T10:50:34.817229Z","iopub.status.idle":"2021-06-14T10:50:34.827165Z","shell.execute_reply.started":"2021-06-14T10:50:34.817193Z","shell.execute_reply":"2021-06-14T10:50:34.826386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Read More\n- [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)\n- [pytorch in x = x.view (x.size (0), -1) understanding](https://www.programmersought.com/article/11412923760/)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:28:58.41792Z","iopub.execute_input":"2021-06-12T15:28:58.41829Z","iopub.status.idle":"2021-06-12T15:28:58.423679Z","shell.execute_reply.started":"2021-06-12T15:28:58.418256Z","shell.execute_reply":"2021-06-12T15:28:58.422442Z"}}},{"cell_type":"markdown","source":"### Step 5. Define Loss Function","metadata":{}},{"cell_type":"code","source":"adversarial_loss = torch.nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.828951Z","iopub.execute_input":"2021-06-14T10:50:34.829434Z","iopub.status.idle":"2021-06-14T10:50:34.835586Z","shell.execute_reply.started":"2021-06-14T10:50:34.829386Z","shell.execute_reply":"2021-06-14T10:50:34.834774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Read More\n- [BCELoss(Binary Cross Entropy Loss)](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)","metadata":{}},{"cell_type":"markdown","source":"### Step 6. Initialize generator and Discriminator","metadata":{}},{"cell_type":"code","source":"generator = Generator()\ndiscriminator = Discriminator()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.836861Z","iopub.execute_input":"2021-06-14T10:50:34.837363Z","iopub.status.idle":"2021-06-14T10:50:34.859032Z","shell.execute_reply.started":"2021-06-14T10:50:34.837328Z","shell.execute_reply":"2021-06-14T10:50:34.858281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.886297Z","iopub.execute_input":"2021-06-14T10:50:34.886576Z","iopub.status.idle":"2021-06-14T10:50:34.891267Z","shell.execute_reply.started":"2021-06-14T10:50:34.886549Z","shell.execute_reply":"2021-06-14T10:50:34.890476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.892636Z","iopub.execute_input":"2021-06-14T10:50:34.893125Z","iopub.status.idle":"2021-06-14T10:50:34.90318Z","shell.execute_reply.started":"2021-06-14T10:50:34.893087Z","shell.execute_reply":"2021-06-14T10:50:34.902238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 7. GPU Setting","metadata":{}},{"cell_type":"code","source":"if cuda:\n    generator.cuda()\n    discriminator.cuda()\n    adversarial_loss.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.905118Z","iopub.execute_input":"2021-06-14T10:50:34.905472Z","iopub.status.idle":"2021-06-14T10:50:34.914864Z","shell.execute_reply.started":"2021-06-14T10:50:34.905437Z","shell.execute_reply":"2021-06-14T10:50:34.9141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 8. Configure Data Loader","metadata":{}},{"cell_type":"markdown","source":"Since we use the Kaggle dataset, it is necessary to read the csv file and convert it into an image format.\n\n\nFor the code to load and convert Kaggle MNIST data, I referred to [Pytorch Dataset and DataLoader](https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader).\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.91638Z","iopub.execute_input":"2021-06-14T10:50:34.916804Z","iopub.status.idle":"2021-06-14T10:50:34.920599Z","shell.execute_reply.started":"2021-06-14T10:50:34.916768Z","shell.execute_reply":"2021-06-14T10:50:34.919595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetMNIST(Dataset): # inherit abstract class - 'Dataset'\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image ad ndarray type (H, W, C)\n        # be carefull for converting dtype to np.uint8 (Unsigned integer (0 to 255))\n        # in this example, We use ToTensor(), so we define the numpy array like (H, W, C)\n        \n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28,28,1))\n        label = self.data.iloc[index, 0]\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image, label\n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.921906Z","iopub.execute_input":"2021-06-14T10:50:34.92255Z","iopub.status.idle":"2021-06-14T10:50:34.930557Z","shell.execute_reply.started":"2021-06-14T10:50:34.922514Z","shell.execute_reply":"2021-06-14T10:50:34.929587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : Read CSV file","metadata":{"execution":{"iopub.status.busy":"2021-06-12T16:15:39.2396Z","iopub.execute_input":"2021-06-12T16:15:39.239996Z","iopub.status.idle":"2021-06-12T16:15:39.246142Z","shell.execute_reply.started":"2021-06-12T16:15:39.239968Z","shell.execute_reply":"2021-06-12T16:15:39.244583Z"}}},{"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:34.93256Z","iopub.execute_input":"2021-06-14T10:50:34.932851Z","iopub.status.idle":"2021-06-14T10:50:36.994937Z","shell.execute_reply.started":"2021-06-14T10:50:34.932828Z","shell.execute_reply":"2021-06-14T10:50:36.994019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:36.996837Z","iopub.execute_input":"2021-06-14T10:50:36.997203Z","iopub.status.idle":"2021-06-14T10:50:37.020487Z","shell.execute_reply.started":"2021-06-14T10:50:36.997167Z","shell.execute_reply":"2021-06-14T10:50:37.019591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : Construct image from csv file","metadata":{}},{"cell_type":"code","source":"for index in range(1, 6): # N : 5 (Number of Image)\n    temp_image = train.iloc[index, 1:].values.astype(np.uint8).reshape((28,28,1))\n    temp_label = train.iloc[index, 0]\n    print('Shape of Image : ',temp_image.shape)\n    print('label : ', temp_label)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:37.022398Z","iopub.execute_input":"2021-06-14T10:50:37.022871Z","iopub.status.idle":"2021-06-14T10:50:37.034133Z","shell.execute_reply.started":"2021-06-14T10:50:37.022833Z","shell.execute_reply":"2021-06-14T10:50:37.033102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : transform from table data to image data with basic preprocessing","metadata":{}},{"cell_type":"code","source":"dataset = DatasetMNIST(file_path='../input/digit-recognizer/train.csv', \n                       transform=transforms.Compose(\n                           [#transforms.Resize(img_size), # Resize is only for PIL Image. Not for numpy array\n                            transforms.ToTensor(), # ToTensor() : np.array (H, W, C) -> tensor (C, H, W)\n                            transforms.Normalize([0.5],[0.5])]\n                       ))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:37.035407Z","iopub.execute_input":"2021-06-14T10:50:37.035949Z","iopub.status.idle":"2021-06-14T10:50:39.07861Z","shell.execute_reply.started":"2021-06-14T10:50:37.035911Z","shell.execute_reply":"2021-06-14T10:50:39.07775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_img, _ =  dataset.__getitem__(0) # We don't need label, so _","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.079994Z","iopub.execute_input":"2021-06-14T10:50:39.080362Z","iopub.status.idle":"2021-06-14T10:50:39.086367Z","shell.execute_reply.started":"2021-06-14T10:50:39.080327Z","shell.execute_reply":"2021-06-14T10:50:39.085357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_img.size() # before ToTensor() : (28,28,1), after : (1,28,28)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.087809Z","iopub.execute_input":"2021-06-14T10:50:39.088186Z","iopub.status.idle":"2021-06-14T10:50:39.097456Z","shell.execute_reply.started":"2021-06-14T10:50:39.088149Z","shell.execute_reply":"2021-06-14T10:50:39.096688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_img.max(), temp_img.min() # before Normalize([0.5],[0.5]) : 0 ~ 1, after : -1 ~ 1","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.100318Z","iopub.execute_input":"2021-06-14T10:50:39.10078Z","iopub.status.idle":"2021-06-14T10:50:39.108142Z","shell.execute_reply.started":"2021-06-14T10:50:39.100745Z","shell.execute_reply":"2021-06-14T10:50:39.107177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : Define dataloader that can load image by batch","metadata":{"execution":{"iopub.status.busy":"2021-06-13T03:11:55.363084Z","iopub.execute_input":"2021-06-13T03:11:55.363449Z","iopub.status.idle":"2021-06-13T03:11:55.369074Z","shell.execute_reply.started":"2021-06-13T03:11:55.363409Z","shell.execute_reply":"2021-06-13T03:11:55.367783Z"}}},{"cell_type":"code","source":"batch_size = 64 # suggested default, size of the batches\ndataloader = DataLoader( # torch.utils.data.DataLoader\n    dataset,\n    batch_size=batch_size,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.110159Z","iopub.execute_input":"2021-06-14T10:50:39.110764Z","iopub.status.idle":"2021-06-14T10:50:39.115037Z","shell.execute_reply.started":"2021-06-14T10:50:39.110729Z","shell.execute_reply":"2021-06-14T10:50:39.114161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_images, _ = iter(dataloader).next() # We don't use label, so _\nprint('images shape on batch size = {}'.format(temp_images.size()))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.117349Z","iopub.execute_input":"2021-06-14T10:50:39.117603Z","iopub.status.idle":"2021-06-14T10:50:39.15492Z","shell.execute_reply.started":"2021-06-14T10:50:39.11758Z","shell.execute_reply":"2021-06-14T10:50:39.154014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Read More\n1. [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n    - .ToTensor | Convert a PIL Image or numpy.ndarray to tensor. This transform does not support torchscript.\n    - .ToTensor | Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8","metadata":{}},{"cell_type":"markdown","source":"### Step 9. Define optimizers","metadata":{}},{"cell_type":"code","source":"# suggested default - beta parameters (decay of first order momentum of gradients)\nb1 = 0.5\nb2 = 0.999\n\n# suggested default - learning rate\nlr = 0.0002 ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.156222Z","iopub.execute_input":"2021-06-14T10:50:39.156569Z","iopub.status.idle":"2021-06-14T10:50:39.160513Z","shell.execute_reply.started":"2021-06-14T10:50:39.156536Z","shell.execute_reply":"2021-06-14T10:50:39.159494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1,b2))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1,b2))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.161881Z","iopub.execute_input":"2021-06-14T10:50:39.162444Z","iopub.status.idle":"2021-06-14T10:50:39.169676Z","shell.execute_reply.started":"2021-06-14T10:50:39.162408Z","shell.execute_reply":"2021-06-14T10:50:39.168886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 10. Training","metadata":{}},{"cell_type":"markdown","source":"![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpMdme%2FbtqA1ArBCOy%2FqqGg7IvV0hpqVkvBuEFpJK%2Fimg.png)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:52:41.513245Z","iopub.execute_input":"2021-06-23T15:52:41.513601Z","iopub.status.idle":"2021-06-23T15:52:42.137653Z","shell.execute_reply.started":"2021-06-23T15:52:41.513557Z","shell.execute_reply":"2021-06-23T15:52:42.136721Z"}}},{"cell_type":"code","source":"Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.171099Z","iopub.execute_input":"2021-06-14T10:50:39.171479Z","iopub.status.idle":"2021-06-14T10:50:39.177558Z","shell.execute_reply.started":"2021-06-14T10:50:39.171443Z","shell.execute_reply":"2021-06-14T10:50:39.176707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.179858Z","iopub.execute_input":"2021-06-14T10:50:39.180514Z","iopub.status.idle":"2021-06-14T10:50:39.184925Z","shell.execute_reply.started":"2021-06-14T10:50:39.180476Z","shell.execute_reply":"2021-06-14T10:50:39.18414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize result\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.186174Z","iopub.execute_input":"2021-06-14T10:50:39.186528Z","iopub.status.idle":"2021-06-14T10:50:39.194501Z","shell.execute_reply.started":"2021-06-14T10:50:39.186495Z","shell.execute_reply":"2021-06-14T10:50:39.193636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 10 # suggested default = 200\nfor epoch in range(n_epochs):\n    for i, (imgs, _) in enumerate(tqdm(dataloader)): # This code(enumerate) is dealt with once more in the *TEST_CODE below.\n                                                     # Used 'tqdm' for showing progress \n        \n        # Adversarial ground truths (For more detail, refer *Read_More below)\n        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False) # imgs.size(0) == batch_size(1 batch) == 64, *TEST_CODE\n        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False) # And Variable is for caclulate gradient. In fact, you can use it, but you don't have to. \n                                                                                # requires_grad=False is default in tensor type. *Read_More\n        \n        # Configure input\n        real_imgs = imgs.type(Tensor) # As mentioned, it is no longer necessary to wrap the tensor in a Variable.\n      # real_imgs = Variable(imgs.type(Tensor)) # requires_grad=False, Default! It's same.\n    \n# ------------\n# Train Generator\n# ------------\n        optimizer_G.zero_grad()\n        \n        # sample noise 'z' as generator input\n        z = Tensor(np.random.normal(0, 1, (imgs.shape[0],latent_dim))) # Random sampling Tensor(batch_size, latent_dim) of Gaussian distribution\n        # z.shape == torch.Size([64, 100])\n        \n        # Generate a batch of images\n        gen_imgs = generator(z)\n        # gen_imgs.shape == torch.Size([64, 1, 28, 28])\n        \n        # Loss measures generator's ability to fool the discriminator\n        g_loss = adversarial_loss(discriminator(gen_imgs), valid) # torch.nn.BCELoss() compare result(64x1) and valid(64x1, filled with 1)\n        \n        g_loss.backward()\n        optimizer_G.step()\n        \n# ------------\n# Train Discriminator\n# ------------\n        optimizer_D.zero_grad()\n        \n        # Measure discriminator's ability to classify real from generated samples\n        real_loss = adversarial_loss(discriminator(real_imgs), valid) # torch.nn.BCELoss() compare result(64x1) and valid(64x1, filled with 1)\n        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) # We are learning the discriminator now. So have to use detach() \n                                                                             \n        d_loss = (real_loss + fake_loss) / 2\n        \n        d_loss.backward()# If didn't use detach() for gen_imgs, all weights of the generator will be calculated with backward(). \n        optimizer_D.step()\n         \n    \n\n# ------------\n# Real Time Visualization (While Training)\n# ------------\n        \n        sample_z_in_train = Tensor(np.random.normal(0, 1, (imgs.shape[0],latent_dim)))\n        # z.shape == torch.Size([64, 100])\n        sample_gen_imgs_in_train = generator(sample_z_in_train).detach().cpu()\n        # gen_imgs.shape == torch.Size([64, 1, 28, 28])\n        \n        if ((i+1) % 200) == 0: # show while batch - 200/657, 400/657, 600/657\n            nrow=1\n            ncols=5\n            fig, axes = plt.subplots(nrows=nrow,ncols=ncols, figsize=(8,2))\n            plt.suptitle('EPOCH : {} | BATCH(ITERATION) : {}'.format(epoch+1, i+1))\n            for ncol in range(ncols):\n                axes[ncol].imshow(sample_gen_imgs_in_train.permute(0,2,3,1)[ncol], cmap='gray')\n                axes[ncol].axis('off')\n            plt.show()\n    print(\n        \"[Epoch: %d/%d] [Batch: %d/%d] [D loss: %f] [G loss: %f]\"\n        % (epoch+1, n_epochs, i+1, len(dataloader), d_loss.item(), g_loss.item())\n    )","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:50:39.195625Z","iopub.execute_input":"2021-06-14T10:50:39.195969Z","iopub.status.idle":"2021-06-14T10:54:35.544896Z","shell.execute_reply.started":"2021-06-14T10:50:39.195934Z","shell.execute_reply":"2021-06-14T10:54:35.543959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : enumerate >> [docs.python.org/enumerate](https://docs.python.org/3/library/functions.html#enumerate)","metadata":{}},{"cell_type":"code","source":"# result of enumerate\ncount = 1\nfor i, (imgs,label) in enumerate(dataloader):\n    print('Shape of Batch Images : \\n', imgs.shape)\n    print('Labels (1~64) : \\n', label)\n    print('-'*100)\n    if count == 5:\n        break\n    else:\n        count += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.546274Z","iopub.execute_input":"2021-06-14T10:54:35.546621Z","iopub.status.idle":"2021-06-14T10:54:35.681445Z","shell.execute_reply.started":"2021-06-14T10:54:35.546582Z","shell.execute_reply":"2021-06-14T10:54:35.680691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : \n- Read CSV file\n- Tensor(imgs.size(0),1)\n- Tensor(imgs.size(0),1).fill_(1.0)","metadata":{}},{"cell_type":"code","source":"Tensor(10,1) # Just 10 for a quick look. \n             # We dealt with Tensor(imgs.size(0),1) above. Tensor(64,1) <-- len(H) == batch_size == 64, len(W) == 1","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.682509Z","iopub.execute_input":"2021-06-14T10:54:35.682821Z","iopub.status.idle":"2021-06-14T10:54:35.689962Z","shell.execute_reply.started":"2021-06-14T10:54:35.682797Z","shell.execute_reply":"2021-06-14T10:54:35.68905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tensor(10,1).fill_(1.0) # _ means inplace, fill the Tensor with 1.0","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.691452Z","iopub.execute_input":"2021-06-14T10:54:35.692085Z","iopub.status.idle":"2021-06-14T10:54:35.701471Z","shell.execute_reply.started":"2021-06-14T10:54:35.691997Z","shell.execute_reply":"2021-06-14T10:54:35.700383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : Variable and requires_grad","metadata":{}},{"cell_type":"code","source":"sample_img = iter(dataloader).next()[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.70293Z","iopub.execute_input":"2021-06-14T10:54:35.703379Z","iopub.status.idle":"2021-06-14T10:54:35.736498Z","shell.execute_reply.started":"2021-06-14T10:54:35.703346Z","shell.execute_reply":"2021-06-14T10:54:35.73574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_img.shape, sample_img.dtype","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.737628Z","iopub.execute_input":"2021-06-14T10:54:35.737966Z","iopub.status.idle":"2021-06-14T10:54:35.743143Z","shell.execute_reply.started":"2021-06-14T10:54:35.737932Z","shell.execute_reply":"2021-06-14T10:54:35.742219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_img.requires_grad # default : False ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.744448Z","iopub.execute_input":"2021-06-14T10:54:35.744975Z","iopub.status.idle":"2021-06-14T10:54:35.753021Z","shell.execute_reply.started":"2021-06-14T10:54:35.744923Z","shell.execute_reply":"2021-06-14T10:54:35.752194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Variable(sample_img).requires_grad # exactly same","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.756849Z","iopub.execute_input":"2021-06-14T10:54:35.757175Z","iopub.status.idle":"2021-06-14T10:54:35.765666Z","shell.execute_reply.started":"2021-06-14T10:54:35.757151Z","shell.execute_reply":"2021-06-14T10:54:35.764839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_img.requires_grad_(True) # set requires_grad to True, _ means inplace","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.768322Z","iopub.execute_input":"2021-06-14T10:54:35.768577Z","iopub.status.idle":"2021-06-14T10:54:35.783061Z","shell.execute_reply.started":"2021-06-14T10:54:35.768555Z","shell.execute_reply":"2021-06-14T10:54:35.782185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_img.requires_grad # Yes. requires_grad changed correctly. you don't need wrapping tensor with Variable. ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.784232Z","iopub.execute_input":"2021-06-14T10:54:35.784571Z","iopub.status.idle":"2021-06-14T10:54:35.789985Z","shell.execute_reply.started":"2021-06-14T10:54:35.784539Z","shell.execute_reply":"2021-06-14T10:54:35.789085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, it can be confusing here. Obviously, the derivative is computed through the loss, but not a single `requires_grad` is set to `true`.\n\nRemember, It's different from `model's parameter`. Internally, the parameters of each Module are stored in Tensors with `requires_grad=True` !","metadata":{}},{"cell_type":"markdown","source":"> TEST CODE : Ramdom Sampling (H,W) from a normal(Gaussian) distribution ","metadata":{}},{"cell_type":"code","source":"np.random.normal(0,1,(64,100))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.791642Z","iopub.execute_input":"2021-06-14T10:54:35.792066Z","iopub.status.idle":"2021-06-14T10:54:35.801242Z","shell.execute_reply.started":"2021-06-14T10:54:35.79203Z","shell.execute_reply":"2021-06-14T10:54:35.800101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.normal(0,1,(64,100)).shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.802722Z","iopub.execute_input":"2021-06-14T10:54:35.803098Z","iopub.status.idle":"2021-06-14T10:54:35.809601Z","shell.execute_reply.started":"2021-06-14T10:54:35.803063Z","shell.execute_reply":"2021-06-14T10:54:35.808595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : shape of z and gen_imgs and discriminator(gen_imgs)","metadata":{}},{"cell_type":"code","source":"# latent vector\nsample_z = Tensor(np.random.normal(0, 1, (64,100)))\nsample_z.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:54:35.810964Z","iopub.execute_input":"2021-06-14T10:54:35.811394Z","iopub.status.idle":"2021-06-14T10:54:35.819164Z","shell.execute_reply.started":"2021-06-14T10:54:35.811361Z","shell.execute_reply":"2021-06-14T10:54:35.818108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generated images\nsample_gen_imgs = generator(sample_z)\nsample_gen_imgs.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:08.561768Z","iopub.execute_input":"2021-06-14T10:59:08.562123Z","iopub.status.idle":"2021-06-14T10:59:08.570948Z","shell.execute_reply.started":"2021-06-14T10:59:08.562087Z","shell.execute_reply":"2021-06-14T10:59:08.569963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discrimination result\nsample_discrim_result = discriminator(sample_gen_imgs)\nsample_discrim_result.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:10.151223Z","iopub.execute_input":"2021-06-14T10:59:10.151638Z","iopub.status.idle":"2021-06-14T10:59:10.165493Z","shell.execute_reply.started":"2021-06-14T10:59:10.151599Z","shell.execute_reply":"2021-06-14T10:59:10.164637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : g_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-13T03:32:26.913011Z","iopub.execute_input":"2021-06-13T03:32:26.913329Z","iopub.status.idle":"2021-06-13T03:32:26.917897Z","shell.execute_reply.started":"2021-06-13T03:32:26.913302Z","shell.execute_reply":"2021-06-13T03:32:26.917117Z"}}},{"cell_type":"code","source":"adversarial_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:11.160464Z","iopub.execute_input":"2021-06-14T10:59:11.160803Z","iopub.status.idle":"2021-06-14T10:59:11.168594Z","shell.execute_reply.started":"2021-06-14T10:59:11.16077Z","shell.execute_reply":"2021-06-14T10:59:11.16764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_valid.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:11.855568Z","iopub.execute_input":"2021-06-14T10:59:11.855883Z","iopub.status.idle":"2021-06-14T10:59:11.861036Z","shell.execute_reply.started":"2021-06-14T10:59:11.855853Z","shell.execute_reply":"2021-06-14T10:59:11.860212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_valid = Tensor(64,1).fill_(1.0)\nsample_g_loss = adversarial_loss(sample_discrim_result, sample_valid)\nsample_g_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:12.126522Z","iopub.execute_input":"2021-06-14T10:59:12.126815Z","iopub.status.idle":"2021-06-14T10:59:12.136015Z","shell.execute_reply.started":"2021-06-14T10:59:12.126787Z","shell.execute_reply":"2021-06-14T10:59:12.135071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> TEST CODE : detach()\n- refer : [What is PyTorch '.detach()' method? - theroyakash, 2020-11](https://dev.to/theroyakash/what-is-pytorch-detach-method-15oo)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T08:28:06.970211Z","iopub.execute_input":"2021-06-14T08:28:06.971551Z","iopub.status.idle":"2021-06-14T08:28:06.994767Z","shell.execute_reply.started":"2021-06-14T08:28:06.971123Z","shell.execute_reply":"2021-06-14T08:28:06.992784Z"}}},{"cell_type":"code","source":"!pip install torchviz\nimport torchviz","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:15.994062Z","iopub.execute_input":"2021-06-14T10:59:15.99441Z","iopub.status.idle":"2021-06-14T10:59:24.942377Z","shell.execute_reply.started":"2021-06-14T10:59:15.994378Z","shell.execute_reply":"2021-06-14T10:59:24.941452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = torch.ones((28,28), dtype=torch.float32, requires_grad=True)\nsquare_X = X**2\ncubic_X = X**3\n\nresult = (square_X+cubic_X).sum()\n\ntorchviz.make_dot(result)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:24.943886Z","iopub.execute_input":"2021-06-14T10:59:24.944264Z","iopub.status.idle":"2021-06-14T10:59:25.319619Z","shell.execute_reply.started":"2021-06-14T10:59:24.944228Z","shell.execute_reply":"2021-06-14T10:59:25.318702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = torch.ones((28,28), dtype=torch.float32, requires_grad=True)\nsquare_X = X**2\ncubic_X = X.detach()**3\n\nresult = (square_X+cubic_X).sum()\n\ntorchviz.make_dot(result)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:59:25.321652Z","iopub.execute_input":"2021-06-14T10:59:25.322053Z","iopub.status.idle":"2021-06-14T10:59:25.400807Z","shell.execute_reply.started":"2021-06-14T10:59:25.321984Z","shell.execute_reply":"2021-06-14T10:59:25.399929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Read More\n- [What is Ground Truth? - Definition from Techpedia](https://www.techopedia.com/definition/32514/ground-truth)\n- [tqdm. A Fast, Extensible Progress Bar for Python and CLI](https://github.com/tqdm/tqdm)\n- [Variables are no longer necessary to use autograd with tensors](https://pytorch.org/docs/stable/autograd.html#variable-deprecated)\n- [np.random.normal(loc=0.0, scale=1.0, size=None)](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)\n\n","metadata":{}},{"cell_type":"markdown","source":"--------------","metadata":{}},{"cell_type":"markdown","source":"\nSo far, we have completed the basic model of gan and tested the model through mnist data.\n\nI plan to implement and test more various gan models from the very basics through this series, so let's study together!\n\nThank you and Enjoy your Kaggle! :)","metadata":{}}]}