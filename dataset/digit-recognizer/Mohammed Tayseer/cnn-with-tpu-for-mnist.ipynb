{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# 1. Introduction ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook I will use Convolutional Neural Network with Keras API to build Digit Recognizer model by use TPU.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import All Necessary libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns #Data Visulation \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical #convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\n\n\nimport keras \nfrom keras.datasets import mnist\nimport tensorflow as tf\n\nprint(\"Tensorflow version \" + tf.__version__)\n\n\nnp.random.seed(123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TPU or GPU detection**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This cell will enable TPU if is set accelerator as TPU when create the notebook","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data preparation and preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2.1 Load data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the file in the dicretory \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data from that dicretory \ntrain_data=pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest_data=pd.read_csv(\"../input/digit-recognizer/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know that keras has a MNIST dataset, I will merge this dataset with our dataset to increase the nunber of samples to get more accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#separate the independent and dependent variables (values of X and Y)\n\nY_train=train_data['label']\n\n#drop \"lable\" column \nX_train=train_data.drop('label', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()\n\nx_train1 = np.concatenate([x_train0, x_test0], axis=0)\ny_train1 = np.concatenate([y_train0, y_test0], axis=0)\n\nX_train_keras = x_train1.reshape(-1, 28*28)\nY_train_keras = y_train1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((X_train.values, X_train_keras))\nY_train = np.concatenate((Y_train, Y_train_keras))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 112,000 entries (every entry is image), and 8 labels (every label represens a digit from 0 to 9) and we have 784 columns (784 columns for pixels, every column represens a pixel in image). \nNote: The size is image is 28*28, so the total pixels for that image is 784 pixels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Statistical summary for test data\nprint(test_data.shape)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For test data we have 28,000 entries (images)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counts images for every digit\nunique, counts = np.unique(Y_train, return_counts=True)\ndict(zip(unique, counts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n#Diplay bar chart \nsns.set(context='notebook', style='darkgrid', palette='deep')\ng = sns.countplot(Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.3 Normalization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For most image data, the pixel values are integers with values between 0 and 255. Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert values to float\nX_train = X_train.astype('float32')\nY_train = Y_train.astype('float32')\ntest_data=test_data.astype('float32')\n\n# Normalize the data\nX_train = X_train / 255.0\ntest_data = test_data / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.4 Reshape\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.5 Label encoding","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 0 -> [1,0,0,0,0,0,0,0,0,0]).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode labels to one hot vectors (ex : 9 -> [0,0,0,0,0,0,0,0,0,1])\nY_train=to_categorical(Y_train, num_classes=10)\n\nprint(f\"Label size {Y_train.shape}\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.6 Split training and valdiation set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the train and the validation set for the fitting\n\nX_train, X_val, Y_train, Y_val=train_test_split(X_train, Y_train, test_size=0.10, random_state=44)\n\n# 10% for Validation data, 90% for training data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the sizes of datasets\nprint(\"The size of X_train : {}\\nThe size of Y_train : {}\\nThe size of X_val   : {}\\nThe size of Y_val   : {}\\n\"\n      .format(X_train.shape,Y_train.shape,X_val.shape,Y_val.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.7 Data Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conver X_train to shape (num_images, img_rows, img_cols) for plotting \nX_train_temp = X_train.reshape(X_train.shape[0], 28, 28)\n\nfig, axis = plt.subplots(3, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train_temp[i], cmap='binary')\n    digit = Y_train[i].argmax()\n    ax.set(title = f\"Real Number is {digit}\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Convolutional Neural Network(CNN)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3.1 Define the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model= Sequential()\n\nmodel.add(Conv2D(input_shape=(28,28,1), filters=32, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.10))\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.10))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(BatchNormalization())\n\n\n\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model_chart.png', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(\"model_chart.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 3.2 Set the optimizer and annealer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define the optimizer\noptimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cmpile the model\nmodel.compile(optimizer= optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_redcuing=ReduceLROnPlateau(monitor='val_accuracy', \n                                         patience=2,\n                                         verbose=1,\n                                         factor=0.5,\n                                         min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stops training when accuracy do not improved\n#earlystopper = EarlyStopping(monitor='val_accuracy', min_delta=0,\n               #              patience=6, verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50 # \nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.3 Data augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Do data augmentation to prevent overfitting\n\nimagegen=ImageDataGenerator(\n                            featurewise_center=False, #set input mean to 0 over the dataset\n                            samplewise_center=False, #set each sample mean to 0\n                            featurewise_std_normalization=False, #divide inputs by std of the dataset\n                            samplewise_std_normalization=False, #divide each input by its std\n                            zca_whitening=False, #apply ZCA whitening\n                            rotation_range=10, #randomly rotate images in the range (degrees, 0 to 180)\n                            zoom_range=0.1, #randomly zoom image \n                            width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n                            height_shift_range=0.1, #randomly shift images vertically (fraction of total height)\n                            horizontal_flip=False, #randomly flip images\n                            vertical_flip=False)\n    \nimagegen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.4 Training the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training data (Fit the model)\n\nhistory=model.fit_generator(imagegen.flow(X_train, Y_train,batch_size=batch_size),\n                                          epochs=epochs,\n                                          validation_data=(X_val, Y_val),\n                                          verbose=2,\n                                          steps_per_epoch=X_train.shape[0] // batch_size,\n                                          callbacks=[learning_rate_redcuing])\n                                          \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Save the model\nmodel.save(\"MNIST_CNN_Model.h5\")\nmodel.save_weights(\"MNIST_CNN_Model_weights.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Evaluate the model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4.1 Training and validation curves","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \n\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"Validation Loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training Accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation Accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.2 Confusion matrix","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Confusion matrix can be very helpfull to see your model drawbacks.\n\nI plot the confusion matrix of the validation results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred=model.predict(X_val)\n\n#Convert predictions classes to one hot vectors\nY_pred_classes=np.argmax(Y_pred, axis=1)\n\n# Convert validation observations to one hot vectors\nY_true=np.argmax(Y_val, axis=1)\n\n# compute the confusion matrix\nconfusion_mtx=confusion_matrix(Y_true, Y_pred_classes)\n\n# plot the confusion matrix\nplt.figure(figsize=(10, 10)) #The size of plot chart\nconf_plot=sns.heatmap(confusion_mtx, annot=True, fmt='d', linewidths=.1, linecolor='black', cmap=\"YlGnBu\", square=True)\n\n#set title and labels\nconf_plot.set(xlabel=\"Predicted label\", ylabel = 'True label', title='Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see some of misclassified lables like 9 and 8; the model He cannot distinguish them in some images. Some thing to 6 and 0.\n\nNow, let us see those error by chart.\n\nI get the full code in the next cell from: https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4.3 Compare True lables with misclassified lables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some errors are due to an error in writing digits by hand","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5. Prediction and submition","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5.1 Prediction validation results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_val)\nX_test_temp = X_val.reshape(X_val.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test_temp[i], cmap='binary')\n    ax.set(title = f\"Real Number is {Y_val[i].argmax()}\\nPredict Number is {y_pred[i].argmax()}\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.2 Submition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict results\nresults = model.predict(test_data)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"sample_submission.csv\",index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notebook based on my modification of those notebooks:\n1. https://www.kaggle.com/loveunk/kaggle-digit-recognizer-keras-cnn-100-accuracy\n2. https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n3. https://www.kaggle.com/elcaiseri/mnist-simple-cnn-keras-accuracy-0-99-top-1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}