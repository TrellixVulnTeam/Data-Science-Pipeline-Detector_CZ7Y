{"cells":[{"metadata":{"id":"RaLycH9ZmITP","colab_type":"text"},"cell_type":"markdown","source":"# Loading dataset and Libs"},{"metadata":{"id":"TksFGP-zmPI7","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils.np_utils import to_categorical\n%matplotlib inline\n\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examine dataset and normalize data"},{"metadata":{"id":"MO1p_A35zcvd","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"qmsbLR6xzmWQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"6c1abf16-311d-4b02-9284-3f64a4ef5522","trusted":true},"cell_type":"code","source":"X_train.isnull().any().describe()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6ScqnzRuznwG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"79924232-572b-4059-f939-cb2c7c4aff76","trusted":true},"cell_type":"code","source":"test.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"RTsng9OkzvTH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"X_train = X_train / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"id":"_ubvsVkUzzby","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"id":"V9iPgMBNz3xg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"Y_train = to_categorical(Y_train, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{"id":"G9nSsqAS2OJU","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"b5SFRWZJm3QS","colab_type":"text"},"cell_type":"markdown","source":"# Examine the size and image dimensions\n\n"},{"metadata":{"id":"PA7qnoeZoPEE","colab_type":"code","outputId":"6bc816d7-8e3b-422e-f3ae-3189994e065d","colab":{"base_uri":"https://localhost:8080/","height":208},"trusted":true},"cell_type":"code","source":"# printing the number of samples in X_train, X_test, y_train, y_test\nprint(\"Initial shape of dimensions of X_train\", str(X_train.shape))\n\nprint(\"Number of samples in our training data: \"+ str(len(X_train)))\nprint(\"Number of labels in out training data: \"+ str(len(y_train)))\nprint(\"Number of samples in our test data: \"+ str(len(X_test)))\nprint(\"Number of labels in out test data: \"+ str(len(y_test)))\nprint()\nprint(\"Dimensions of x_train:\" + str(X_train[0].shape))\nprint(\"Labels in x_train:\" + str(y_train.shape))\nprint()\nprint(\"Dimensions of X_test:\" + str(X_test[0].shape))\nprint(\"Labels in X_test:\" + str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"id":"yHHGB9uOpXCI","colab_type":"text"},"cell_type":"markdown","source":"# Let's take a look at some of images in this dataset\n"},{"metadata":{"id":"iOt9l0B0phll","colab_type":"code","outputId":"419f18fa-ec70-4129-937a-0639e803cb0b","colab":{"base_uri":"https://localhost:8080/","height":265},"trusted":true},"cell_type":"code","source":"g = plt.imshow(X_train[0][:,:,0])","execution_count":null,"outputs":[]},{"metadata":{"id":"T8sWRlAluDzu","colab_type":"text"},"cell_type":"markdown","source":"# Create Our Model\n- We're constructing a simple but effective CNN that uses 32 filters of size 3x3\n- We've added a 2nd CONV layer of 64 filters of the same size 3x2\n- We then downsample out data to 2x2, hete he apply a dropout where p is set to 0.2\n- We then flatten out Max Pool output that is connected to a Dense/FC layer has an output size of 128\n- How we apply a dropout where P is set to 0.5\n- Thus 128 output is connected to another FC/Dense layer that outputs to the 10 categorical units"},{"metadata":{"id":"mP75AW7lusP_","colab_type":"code","outputId":"08d6eda4-a56b-4a21-a376-1061ab923e6a","colab":{"base_uri":"https://localhost:8080/","height":451},"trusted":true},"cell_type":"code","source":"num_classes = y_test.shape[1]\nnum_pixels = X_train.shape[1] * X_train.shape[2]\nimport keras\nfrom tensorflow.keras.utils import plot_model\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.optimizers import SGD\n\noptimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\ndropout=0.2\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3,3),\n                     activation='relu',\n                     input_shape=(28,28,1)))\nmodel.add(Conv2D(64, \n                     (3,3),\n                     activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(dropout))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy',\n                 optimizer = optimizer,\n                 metrics = ['accuracy'])\n\n\nprint(model.summary())\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"anOpifumxPD6","colab_type":"text"},"cell_type":"markdown","source":"# Train our Model\n"},{"metadata":{"id":"c_QXe9sKxpwL","colab_type":"code","outputId":"8211e7ec-b986-4956-b961-b806e16ce9c4","colab":{"base_uri":"https://localhost:8080/","height":416},"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 100\n\nhistory = model.fit(X_train,\n                    y_train,\n                    batch_size = batch_size,\n                    epochs = epochs,\n                    verbose = 1,\n                    validation_data = (X_test, y_test))\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"1BH-dCAUkX-R","colab_type":"text"},"cell_type":"markdown","source":"# Plotting out Loss and Accuracy Charts\n"},{"metadata":{"id":"SZaRElv6RYdq","colab_type":"code","outputId":"c65653e4-f6e4-43c0-9c05-ee4b7d1c2e51","colab":{"base_uri":"https://localhost:8080/","height":279},"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\n\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\n\nline1 = plt.plot(epochs, val_loss_values, label='Validation/Test Loss')\nline2 = plt.plot(epochs, loss_values, label='Training Loss')\nplt.setp(line1, linewidth=1.0, marker = '+', markersize=1.0)\nplt.setp(line2, linewidth=1.0, marker = '4', markersize=1.0)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.grid(True)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"hnl181QVSrOv","colab_type":"code","outputId":"1f283f96-d2be-4a7a-a39e-7fc8a0edd603","colab":{"base_uri":"https://localhost:8080/","height":279},"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\n\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(loss_values) + 1)\n\nline1 = plt.plot(epochs, val_acc_values, label='Validation/Test Accuracy')\nline2 = plt.plot(epochs, acc_values, label='Training Accuracy')\nplt.setp(line1, linewidth=1.0, marker = '+', markersize=1.0)\nplt.setp(line2, linewidth=1.0, marker = '4', markersize=1.0)\nplt.xlabel('Epochs') \nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Ax-N6v8wUts6","colab_type":"text"},"cell_type":"markdown","source":"# Saving our Model\n"},{"metadata":{"id":"PH83cG5wU_0r","colab_type":"code","outputId":"62686753-4a10-4c07-f043-f012039ff93a","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"model.save(\"/mnist_simple_cnn_10_epochs.h5\")\nprint(\"Model save\")","execution_count":null,"outputs":[]},{"metadata":{"id":"aPzIIR2mcA-Y","colab_type":"text"},"cell_type":"markdown","source":"# Loading our Model"},{"metadata":{"id":"4iO5vSnacElx","colab_type":"code","outputId":"29bbbdf1-09ca-4ed0-fded-c94c8157766f","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nclassifier = load_model(\"/mnist_simple_cnn_10_epochs.h5\")\nprint(\"Model loaded\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nresults = model.predict(test)\n\n\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  If you like, please upvote!"}],"metadata":{"colab":{"name":"Copy of Building a CNN for handwritten digits - MNIST.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}