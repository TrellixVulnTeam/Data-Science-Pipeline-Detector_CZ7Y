{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''Versatile data analysis laptop. It only takes one line to replace - reading your data file'''\n# This is a sample Python script.\nimport pandas as pd\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#we will split the train set into train and test data in future sections\ndata_raw = pd.read_csv('../input/juvenile-arrests-by-crime/arrests_usa_juvenile.csv')\n\n\n#to play with our data we'll create a copy\n#remember python assignment or equal passes by reference vs values, so we use the copy function: https://stackoverflow.com/questions/46327494/python-pandas-dataframe-copydeep-false-vs-copydeep-true-vs\ndata1 = data_raw.copy(deep = True)\n\n#preview data\n\nprint(\"\\n ----------Top-5- Record----------\")\nprint(data_raw.head(5))  #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html\n# print(data_raw.tail(5)) #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html\n# print(data_raw.sample(10)) #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\nprint(\"\\n -----------Information-----------\")\nprint(data_raw.info())  #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\nprint(\"\\n -----------Data Types-----------\")\nprint(data_raw.dtypes)\nprint(\"\\n ----------Missing value-----------\")\nprint(data_raw.isnull().sum())\nprint(\"\\n ----------Null value-----------\")\nprint(data_raw.isna().sum())\nprint(\"\\n ----------Shape of Data----------\")\nprint(data_raw.shape)\nprint(\"\\n ----------Number of duplicates----------\")\nprint('Number of duplicates:', len(data_raw[data_raw.duplicated()]))\n\n# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n\nmissing_values_data = missing_values_table(data1)\nprint(\"\\n ----------Missing values----------\")\nprint(missing_values_data.head(30))\n\nprint(\"\\n ----------Number of types----------\")\n# Number of each type of column\nprint(data1.dtypes.value_counts())\n\nprint(\"\\n ----------Number of uniques----------\")\n# Let's now look at the number of unique entries in each of the object (categorical) columns.\nprint(data1.select_dtypes('object').apply(pd.Series.nunique, axis = 0))\n\nprint(\"\\n ----------Describe of tables----------\")\nprint(data_raw.describe(include = 'all'))\n\n\n#preview data again\nprint(data1.corr())","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.06405,"end_time":"2022-02-05T07:53:05.522404","exception":false,"start_time":"2022-02-05T07:53:02.458354","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-09T17:54:24.230137Z","iopub.execute_input":"2022-02-09T17:54:24.230972Z","iopub.status.idle":"2022-02-09T17:54:25.493066Z","shell.execute_reply.started":"2022-02-09T17:54:24.230862Z","shell.execute_reply":"2022-02-09T17:54:25.492051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data1.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()\n\ndata1.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8); # ; avoid having the matplotlib verbose informations","metadata":{"papermill":{"duration":4.828542,"end_time":"2022-02-05T07:53:10.357928","exception":false,"start_time":"2022-02-05T07:53:05.529386","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-09T17:54:25.495208Z","iopub.execute_input":"2022-02-09T17:54:25.495565Z","iopub.status.idle":"2022-02-09T17:54:33.928911Z","shell.execute_reply.started":"2022-02-09T17:54:25.495519Z","shell.execute_reply":"2022-02-09T17:54:33.928072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set()\nsns.pairplot(data1, size = 2.5)\nplt.show();","metadata":{"papermill":{"duration":71.476514,"end_time":"2022-02-05T07:54:21.847728","exception":false,"start_time":"2022-02-05T07:53:10.371214","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-09T17:54:33.930366Z","iopub.execute_input":"2022-02-09T17:54:33.930569Z"},"trusted":true},"execution_count":null,"outputs":[]}]}