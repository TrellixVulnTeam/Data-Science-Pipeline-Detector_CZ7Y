{"cells":[{"metadata":{},"cell_type":"markdown","source":"# importing libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F\nfrom torch import optim\n\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #make sure GPU is on to make cuda enable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('../input/digit-recognizer/train.csv')\ndf =df.sample(frac = 1).reset_index(drop=True)\ndf = df.iloc[0:10000,:]#just taking the first 10000 values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.reset_index()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting in 3 folds\nfrom sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits = 3,random_state=7,shuffle=True)\nfolds = df.copy()\nfor f,(tr_idx,val_idx) in enumerate(skf.split(folds,folds.label)):\n    folds.loc[val_idx,'fold'] = int(f)\nfolds['fold'] = folds['fold'].astype(int)    \nfolds.groupby('fold').label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making a dataframe to store the oof data which you can use for ensembling later\noof = df.copy()\nclass_cols =[str(x) for x in np.sort(df.label.unique())]\noof[class_cols] = 0\noof.set_index('index', inplace=True)\noof.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can add your own augmentation techniques here (be careful while transforming, you can make a 9 into a 6 :) )\ntrain_aug = None\nval_aug = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Csn(Dataset):\n    def __init__(self,train_df,augs=None):\n        self.df=train_df\n        self.augs = augs\n        \n    def __len__(self):\n        return(len(self.df))\n    \n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        image_ids = self.df.iloc[idx]['index']\n        image =  self.df.iloc[idx,2:].values.reshape((-1,28,28))\n        if(self.augs == True):\n            transformed = self.augs(image = image)\n            image = transformed['image']\n            \n        image= image/255.0\n        image = torch.tensor(image, dtype=torch.float)\n        label = self.df.iloc[idx].label\n        label =torch.tensor(label, dtype=torch.long)\n        \n        return image,label,image_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eg_data = Csn(df)\nplt.imshow(eg_data[5][0].squeeze(0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Cnn(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1= nn.Conv2d(1,8,5)\n        self.conv2 = nn.Conv2d(8,16,(3,3))\n        self.pool = nn.AdaptiveAvgPool2d((10,10))\n        self.fc1 = nn.Linear(16*10*10 ,500)\n        self.fc2 = nn.Linear(500,10)\n        self.dropout = nn.Dropout(0.25)\n       \n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.view(-1, 16*10*10)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=Cnn()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_one_epoch(train_loader,model,optimizer,criterion,e,epochs):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    model.train()\n    global_step = 0\n    loop = tqdm(enumerate(train_loader),total = len(train_loader))\n    \n    for step,(image,labels,_) in loop:\n        image = image.to(device)\n        labels= labels.to(device)\n        output = model(image)\n        batch_size = labels.size(0)\n        loss = criterion(output,labels)\n        \n        out = output.softmax(1)\n        outputs = torch.argmax(out, dim=1).cpu().detach().numpy()\n        targets = labels.cpu().detach().numpy()\n        accuracy = accuracy_score(targets, outputs)\n        losses.update(loss.item(), batch_size)\n        scores.update(accuracy.item(), batch_size)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        global_step += 1\n        \n        loop.set_description(f\"Epoch {e+1}/{epochs}\")\n        loop.set_postfix(loss = loss.item(), accuracy = accuracy.item(), stage = 'train')\n        \n        \n    return losses.avg,scores.avg\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_one_epoch(loader,model,optimizer,criterion):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    model.eval()\n    global_step = 0\n    loop = tqdm(enumerate(loader),total = len(loader))\n    \n    for step,(image,labels,_) in loop:\n        image = image.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.no_grad():\n            output = model(image)\n        loss = criterion(output,labels)\n        \n        output = output.softmax(1)\n        outputs = torch.argmax(output, dim=1).cpu().detach().numpy()\n        targets = labels.cpu().detach().numpy()\n        accuracy = accuracy_score(targets, outputs)\n        \n        losses.update(loss.item(), batch_size)\n        scores.update(accuracy.item(), batch_size)\n        loop.set_postfix(loss = loss.item(), accuracy = accuracy.item(), stage = 'valid')\n        \n        optimizer.step()\n        optimizer.zero_grad()\n        global_step += 1\n        \n    \n        \n    return losses.avg,scores.avg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(fold_n,training_batch_size=64,validation_batch_size=128):\n    \n    train_data=folds[folds.fold != fold_n].iloc[:,:-1]\n    val_data=folds[folds.fold == fold_n].iloc[:,:-1]\n    train_data= Csn(train_data)\n    val_data= Csn(val_data)\n    \n    \n    train_loader = DataLoader(train_data,\n                             shuffle=True,\n                        num_workers=0,\n                        batch_size=training_batch_size)\n    valid_loader = DataLoader(val_data,\n                             shuffle=False,\n                        num_workers=0,\n                        batch_size=validation_batch_size)\n    model = Cnn()\n    model.to(device)\n    criterion=nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience = 3,verbose = True)\n    epochs= 3\n    \n    best_acc = 0\n    \n    loop = range(epochs)\n    for e in loop:\n        \n        train_loss,train_accuracy = train_one_epoch(train_loader,model,optimizer,criterion,e,epochs)\n         #scheduling step if given\n    \n        #scheduler.step()\n        \n        print(f'For epoch {e+1}/{epochs}')\n        print(f'average train_loss {train_loss}')\n        print(f'average train_accuracy {train_accuracy}' )\n        \n        val_loss,val_accuracy = val_one_epoch(valid_loader,model,optimizer,criterion)\n        \n        scheduler.step(val_loss)\n        \n        print(f'avarage val_loss { val_loss }')\n        print(f'avarage val_accuracy {val_accuracy}')\n        \n        \n        \n        \n        if (val_accuracy>best_acc):\n            best_acc = val_accuracy\n            print(f'saving model for {best_acc}')\n            torch.save(model.state_dict(),OUTPUT_DIR+ f'Fold {fold_n} model with val_acc {best_acc}.pth') \n    \n    \n    \n    best_model = Cnn().to(device)\n    best_model.load_state_dict(torch.load(OUTPUT_DIR+ f'Fold {fold_n} model with val_acc {best_acc}.pth'))\n    best_model.eval()\n    for inputs,_, imgids in valid_loader:\n        with torch.no_grad():\n            inputs = inputs.to(device)\n            output= best_model(inputs)\n            softed = F.softmax(output, dim=1)\n            oof.loc[imgids, class_cols] = softed.cpu().numpy()\n                        \n    \n    \n               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3):\n    print(f'######### for Fold {i} ###########')\n    #modelx=Cnn()\n    fit(i)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# getting the oof files"},{"metadata":{"trusted":true},"cell_type":"code","source":"o=oof[class_cols]\no['label'] =oof['label']\noof=o\noof.to_csv('oof.csv')\noof.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_accuracy = accuracy_score(oof.label.values, np.argmax(oof[class_cols].values,axis =1))\noof_accuracy \n#say_my_name","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}