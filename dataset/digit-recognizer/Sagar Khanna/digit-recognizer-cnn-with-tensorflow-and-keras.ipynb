{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/digit-recognizer/train.csv')\ndf1 = pd.read_csv('../input/digit-recognizer/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the training data by features and labels","metadata":{}},{"cell_type":"code","source":"x_train = df.drop('label', axis = 1)\ny_train = df['label']\n\ntest = df1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the shape of training and test data","metadata":{}},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reshaping our data into a 28x28 matrix**","metadata":{}},{"cell_type":"code","source":"x_train = x_train.values.reshape(42000, 28,28)\ntest = test.values.reshape(28000, 28, 28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"displaying the matrix of a single image, [0] defines the first instance of the data","metadata":{}},{"cell_type":"code","source":"single_image = x_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#matplotlib has a method to show these values in image format\nplt.imshow(single_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"this looks like a **'1'**, and since greyscale values varies from 0 to 255, we can see values close to 255 in the matrix above","metadata":{}},{"cell_type":"code","source":"#exploring labels\ny_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we stand correct, the first value is 1, as shown in the image above\n\n\nThe values here represent labels, what we want is categories, so we have to use one-hot-encoding","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the shape of y_train\ny_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, y_train's dataset of 42000 represents labels, what we want is each of these labels to represent a category,so we'll use to_categorical method","metadata":{}},{"cell_type":"code","source":"y_example = to_categorical(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_example.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see that to_categorical converted a class vector into a binary class matrix","metadata":{}},{"cell_type":"code","source":"y_example[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_cat_train = to_categorical(y_train, num_classes=10)\n#to_categorical takes num_classes on its own based on the label's unique values\n#here it was from 0 to 9, hence, it took 10. You can specify them too using num_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_cat_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice here, the first value of label was 1, so to_categorical() has transformed that into an entire row","metadata":{}},{"cell_type":"markdown","source":"**Now we are going to normalize our data**","metadata":{}},{"cell_type":"code","source":"#checking the maximum value of single_image\nsingle_image.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the minimum value of single_image\nsingle_image.min()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we're gonna scale them between 0 and 1","metadata":{}},{"cell_type":"code","source":"x_train = x_train/255\ntest = test/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the scaled image\nscaled_image = x_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_image.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(scaled_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we're gonna reshape our image to let the model know that we're dealing with a greyscale image, hence 1 color channel","metadata":{}},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#batch_size, width, height, color channels\nx_train = x_train.reshape(42000, 28, 28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.reshape(28000, 28, 28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we're going to train our model. Let's import some libraries.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we're gonna take 10% data from the training data and use it for data validation","metadata":{}},{"cell_type":"code","source":"random_seed = 2\n\nx_train, x_val, y_cat_train, y_val = train_test_split(x_train, y_cat_train, test_size = 0.1, random_state=random_seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size=(4,4), strides = (1,1), input_shape=(28,28,1),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Flatten()) #flatten our layer, eg, our image is 28x28 so the flattened image will be 28*28=784 pixels\n\nmodel.add(Dense(128, activation='relu'))\n\n#OUTPUT layer\nmodel.add(Dense(10, activation='softmax')) #choosing softmax because of 'multiclass classification'\n\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics= ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# filters:- how many filters to apply on an image\n# kernel_size:- size of the matrix which strides through the whole image \n# stride:- (x,y) steps while moving the kernel \n# padding:- Padding is the extra layer we add to the corner of the image to prevent shrinkage and loss of info, such as add a padding of 0 on the outside of the image matrix, so that the corner matrix is also covered more than once while striding","metadata":{}},{"cell_type":"code","source":"#Gonna import EarlyStopping in order to avoid overfitting\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor = 'val_loss', patience = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting the model\nmodel.fit(x_train, y_cat_train, epochs = 10, validation_data = (x_val, y_val), callbacks = [early_stop])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the metrics now.","metadata":{}},{"cell_type":"code","source":"metrics = pd.DataFrame(model.history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting loss and val_loss together\nmetrics[['loss', 'val_loss']].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting accuracy and val_accuracy together\nmetrics[['accuracy', 'val_accuracy']].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Both of them look pretty good","metadata":{}},{"cell_type":"code","source":"#Evaluating validation loss and accuracy\nmodel.evaluate(x_val, y_val, verbose = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we'll get Classification Report and Confusion Matrix. \n# A Classification report is used to measure the quality of predictions from a classification algorithm and a Confusion Matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(x_val)\n\n# Convert predictions classes to one hot vectors \npredictions_classes = np.argmax(predictions, axis = 1)\n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we'll use y_true for predictions\nprint(classification_report(y_true, predictions_classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_true, predictions_classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing confusion matrix\nimport seaborn as sns\n\nplt.figure(figsize = (12, 8))\nsns.heatmap(confusion_matrix(y_true, predictions_classes), annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict results\nresults = model.predict(test)\n\n# gives the index of the greatest number in the given column\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_submission.to_csv(\"digit_recognizer_mnist.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**If this analysis helps you in any way, please upvote :)**","metadata":{}}]}