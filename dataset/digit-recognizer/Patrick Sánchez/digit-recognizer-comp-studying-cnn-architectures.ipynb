{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle competitions: Digit recognizer\n\nThe aim of this notebook is to develop a convolutional neural network (CNN) to recognize handwritten digits. Since CNN's architecture is critical for the model's performance, we will analyze different variations in order to discover which setups better fit to our dataset.\n\nIn order to find the best architecture of the CNN, we will perform different \"experiments\" to determine which combinations of layers and parameters give better results. This procedure is extensive and requires some hours to finish, but it's completely independent on external results (i.e. other kernels or studies) and it is based on the trial and error process to be followed in any real project in which there are no previous references.\n\n\n**TABLE OF CONTENTS**:\n\n1. [Load the data](#section1)\n2. [Data preparation](#section2)\n3. [Initial CNN model](#section3)\n4. [Experiment 1. Size of the convolution kernels](#section4)\n5. [Experiment 2. Number of convolution layers](#section5)\n6. [Experiment 3. Number of convolution nodes](#section6)\n7. [Experiment 4. Dropout percentage](#section7)\n8. [Experiment 5. Dense layer size](#section8)\n9. [Experiment 6. Data augmentation](#section9)\n10. [Experiment 7. Batch normalization](#section10)\n11. [Experiment 8. Replacement of large kernel layers by two smaller ones](#section11)\n12. [Experiment 9. Replacement of max pooling by convolutions with strides](#section12)\n13. [Final model and submission](#section13)\n\n**Disclaimer**: This kernel has been strongly inspired by https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist, which is a very rich and extensive review of an ensemble of 15 CNNs for the digit recognizer competition. I highly recommend to take a look on it for a state of the art review of this competition.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Fundamental libraries\nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# General ML libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport operator\nimport time\n\n# Neural networks libraries\nimport keras\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the data <a id=\"section1\"></a>\n\nSince digit images are grey, we will deal with a single channel (on the contrary, a coloured image has 3 channels, one for each RGB). Let's look at the data structure:","execution_count":null},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n\nprint(\"Original data structure:\")\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's always a good practice to analyze classes distribution (10 digits, from 0 to 9) in order to ensure if all of them are equally distributed:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = sns.countplot(train['label'], alpha=0.75).set_title(\"Digit counts\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Counts\")\nplt.savefig('digit_counts.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like all classes are pretty well balanced, so that stratified train/test split won't be necessary. \n\nFinally, let's check if there are missing values (for example, due to corrupted pixels):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preparation <a id=\"section2\"></a>\n\nData is now loaded, and we verified that all classes are more ore less evenly distributed and there are no missing values. Hence, we are ready to prepare our data.\n\nWhat we will do:\n* Define the data size: 28x28 pixels\n* Extract target column\n* Normalize values. From 0 to 1, instead of the common 0-255 pixel values\n* Reshape datasets. Take  into account that there is a single channel\n* One hot encode the target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef prep_data(raw, test):\n    y = raw[\"label\"]\n    x = raw.drop(labels = [\"label\"],axis = 1) \n    \n    x = x/255.\n    x = x.values.reshape(-1, img_rows,img_cols,1)\n    \n    test = test/255.\n    test = test.values.reshape(-1,img_rows,img_cols,1)\n    \n    return x, y, test\n\nX_train, Y_train, X_test = prep_data(train, test)\nY_train = to_categorical(Y_train, num_classes)\n\nprint(\"Data preparation correctly finished\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial CNN model <a id=\"section3\"></a>\n\nEverythin is ready to create our CNN model, and hence obtain our first results. This step serves as a starting point to verify that the previous procedures have been succesfull, and that we can get a reasonably good accuracy. \n\nHence, this initial architecture is very simple and consists on:\n1. Input layer\n2. Convolutional layer with 32 filters, 4x4 size and relu activation function\n3. MaxPool layer\n4. Dense layer (256)\n5. Output layer\n\nNote: CNN uses max pooling to replace output with a max summary to reduce data size and processing time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\n\nmodel_1 = Sequential()\nmodel_1.add(Conv2D(filters=16, kernel_size=(4,4),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_1.add(MaxPool2D())\nmodel_1.add(Flatten())\nmodel_1.add(Dense(256, activation='relu'))\nmodel_1.add(Dense(num_classes, activation='softmax'))\n\nprint(\"CNN ready to compile\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile the model and fit to training data:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"model_1.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nhistory = model_1.fit(X_train, Y_train,\n          batch_size=batch_size,\n          epochs=20,\n          validation_split = 0.1)\n\nprint(\"Fitting finished\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice, we got an impressing 98.83% accuracy on the validation set with our simple model. Let's see the its evolution with each epoch:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model_1 accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.savefig('initial_cnn.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trainig seems to have reached an accuracy plateaux. Hence, we just need to predict the test dataset, get the maximum probability results and submit the file.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_1.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step3.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Done, we are ready to upload the \"submit_step3.csv\" and obtain our first official score. \n\nBest score at this stage: 0.9883.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Experiment 1. Size of the convolution kernels <a id=\"section4\"></a>\n\nOur first attempt to predict images with digits has proven to be reasonably successful. However, there's always room for improvement, and the following steps will focus on discovering how the network's architecture impacts the model's accuracy.\n\nWe will start by measuring the model accuracy for different kernel sizes:\n* **Model_kernel_1**. Conv2D (16,3x3,relu) + MaxPool + Dense256 + output\n* **Model_kernel_2**. Conv2D (16,4x4,relu) + MaxPool + Dense256 + output\n* **Model_kernel_3**. Conv2D (16,5x5,relu) + MaxPool + Dense256 + output\n* **Model_kernel_4**. Conv2D (16,6x6,relu) + MaxPool + Dense256 + output\n\nCreate the models:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_kernel_1: 3x3\nmodel_kernel_1 = Sequential()\nmodel_kernel_1.add(Conv2D(filters=16, kernel_size=(3,3), padding='same',\n                     activation='relu', \n                     input_shape=(img_rows, img_cols, 1)))\nmodel_kernel_1.add(MaxPool2D(padding='same'))\nmodel_kernel_1.add(Flatten())\nmodel_kernel_1.add(Dense(256, activation='relu'))\nmodel_kernel_1.add(Dense(num_classes, activation='softmax'))\n    \n# Model_kernel_2: 4x4\nmodel_kernel_2 = Sequential()\nmodel_kernel_2.add(Conv2D(filters=16, kernel_size=(4,4), padding='same',\n                     activation='relu', \n                     input_shape=(img_rows, img_cols, 1)))\nmodel_kernel_2.add(MaxPool2D(padding='same'))\nmodel_kernel_2.add(Flatten())\nmodel_kernel_2.add(Dense(256, activation='relu'))\nmodel_kernel_2.add(Dense(num_classes, activation='softmax'))\n    \n# Model_kernel_3: 5x5\nmodel_kernel_3 = Sequential()\nmodel_kernel_3.add(Conv2D(filters=16, kernel_size=(5,5), padding='same',\n                     activation='relu', \n                     input_shape=(img_rows, img_cols, 1)))\nmodel_kernel_3.add(MaxPool2D(padding='same'))\nmodel_kernel_3.add(Flatten())\nmodel_kernel_3.add(Dense(256, activation='relu'))\nmodel_kernel_3.add(Dense(num_classes, activation='softmax'))\n\n# Model_kernel_4: 6x6\nmodel_kernel_4 = Sequential()\nmodel_kernel_4.add(Conv2D(filters=16, kernel_size=(6,6), padding='same',\n                     activation='relu', \n                     input_shape=(img_rows, img_cols, 1)))\nmodel_kernel_4.add(MaxPool2D(padding='same'))\nmodel_kernel_4.add(Flatten())\nmodel_kernel_4.add(Dense(256, activation='relu'))\nmodel_kernel_4.add(Dense(num_classes, activation='softmax')) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then compile the models several times (3 repetitions), so that we can gather some statistics and average the results:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 10\nn_epochs = 20\n\n# Keep track of the history evolution for all repetitions of the CNNs\nhistory_kernel_1, history_kernel_val_1 = [0]*n_epochs, [0]*n_epochs\nhistory_kernel_2, history_kernel_val_2 = [0]*n_epochs, [0]*n_epochs\nhistory_kernel_3, history_kernel_val_3 = [0]*n_epochs, [0]*n_epochs\nhistory_kernel_4, history_kernel_val_4 = [0]*n_epochs, [0]*n_epochs\n\n\nfor rep in range(n_reps):\n\n    # Compile model_kernel_1\n    model_kernel_1.compile(loss=keras.losses.categorical_crossentropy,\n                optimizer='adam',\n                metrics=['accuracy'])\n    model_kernel_1_history_rep = model_kernel_1.fit(X_train, Y_train,\n            batch_size=batch_size,\n            epochs=n_epochs,\n            validation_split = 0.1, \n            verbose=0)\n    history_kernel_1 = tuple(map(operator.add, history_kernel_1, model_kernel_1_history_rep.history['accuracy']))\n    history_kernel_val_1 = tuple(map(operator.add, history_kernel_val_1, model_kernel_1_history_rep.history['val_accuracy']))\n\n    # Compile model_kernel_2\n    model_kernel_2.compile(loss=keras.losses.categorical_crossentropy,\n                optimizer='adam',\n                metrics=['accuracy'])\n    model_kernel_2_history_rep = model_kernel_2.fit(X_train, Y_train,\n            batch_size=batch_size,\n            epochs=n_epochs,\n            validation_split = 0.1, \n            verbose=0)\n    history_kernel_2 = tuple(map(operator.add, history_kernel_2, model_kernel_2_history_rep.history['accuracy']))\n    history_kernel_val_2 = tuple(map(operator.add, history_kernel_val_2, model_kernel_2_history_rep.history['val_accuracy']))\n    \n    # Compile model_kernel_3\n    model_kernel_3.compile(loss=keras.losses.categorical_crossentropy,\n                optimizer='adam',\n                metrics=['accuracy'])\n    model_kernel_3_history_rep = model_kernel_3.fit(X_train, Y_train,\n            batch_size=batch_size,\n            epochs=n_epochs,\n            validation_split = 0.1, \n            verbose=0)\n    history_kernel_3 = tuple(map(operator.add, history_kernel_3, model_kernel_3_history_rep.history['accuracy']))\n    history_kernel_val_3 = tuple(map(operator.add, history_kernel_val_3, model_kernel_3_history_rep.history['val_accuracy']))\n    \n    # Compile model_kernel_4\n    model_kernel_4.compile(loss=keras.losses.categorical_crossentropy,\n                optimizer='adam',\n                metrics=['accuracy'])\n    model_kernel_4_history_rep = model_kernel_4.fit(X_train, Y_train,\n            batch_size=batch_size,\n            epochs=n_epochs,\n            validation_split = 0.1, \n            verbose=0)\n    history_kernel_4 = tuple(map(operator.add, history_kernel_4, model_kernel_4_history_rep.history['accuracy']))\n    history_kernel_val_4 = tuple(map(operator.add, history_kernel_val_4, model_kernel_4_history_rep.history['val_accuracy']))    \n    \n# Average historic data for each CNN (train and valuation)\nhistory_kernel_1 = [x/n_reps for x in list(history_kernel_1)] \nhistory_kernel_2 = [x/n_reps for x in list(history_kernel_2)]\nhistory_kernel_3 = [x/n_reps for x in list(history_kernel_3)]\nhistory_kernel_4 = [x/n_reps for x in list(history_kernel_4)]\nhistory_kernel_val_1 = [x/n_reps for x in list(history_kernel_val_1)]\nhistory_kernel_val_2 = [x/n_reps for x in list(history_kernel_val_2)]\nhistory_kernel_val_3 = [x/n_reps for x in list(history_kernel_val_3)]\nhistory_kernel_val_4 = [x/n_reps for x in list(history_kernel_val_4)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, plot the accuracy results:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_kernel_val_1)\nplt.plot(history_kernel_val_2)\nplt.plot(history_kernel_val_3)\nplt.plot(history_kernel_val_4)\nplt.title('Model accuracy for different convolution kernel sizes')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\n#plt.ylim(0.95,1)\nplt.xlim(0,n_epochs)\nplt.legend(['3x3', '4x4', '5x5', '6x6'], loc='upper left')\nplt.savefig('convolution_kernel_size.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: Both kernels of 5x5 and 6x6 accomplish the best accuracy. Hence, from now on, our convolution layers will be 5x5 to optimally capture image patterns while still being computatnionally efficient.\n\nBest score at this stage: 0.9902.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Experiment 2. Number of convolution layers <a id=\"section5\"></a>\n\nNow that we know the optimal kernel size, let's study how the number of convolution layers affect the model's performance, to see if a larger number increases the accuracy:\n* **Model_layers_1**. Conv2D (32,5x5,relu) + MaxPool + Dense256 + output\n* **Model_layers_2**. Conv2D (16,5x5,relu) + MaxPool + Conv2D(32,5x5,relu) + MaxPool + Dense256 + output\n* **Model_layers_3**. Conv2D (16,5x5,relu) + MaxPool + Conv2D(32,5x5,relu) + MaxPool + Conv2D(64,5x5,relu) + MaxPool + Dense256 + output\n\nDefine the models:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_layers_1: 1 Conv2d layer, same as our initial model (model_1) \n\n# Model_layers_2: 2 Conv2D layers\nmodel_layers_2 = Sequential()\nmodel_layers_2.add(Conv2D(filters=16, kernel_size=(5,5), padding='same',\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_layers_2.add(MaxPool2D(padding='same'))\nmodel_layers_2.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\nmodel_layers_2.add(MaxPool2D(padding='same'))\nmodel_layers_2.add(Flatten())\nmodel_layers_2.add(Dense(256, activation='relu'))\nmodel_layers_2.add(Dense(num_classes, activation='softmax'))\n\n# Model_layers_3: 3 Conv2D layers\nmodel_layers_3 = Sequential()\nmodel_layers_3.add(Conv2D(filters=16, kernel_size=(5,5), padding='same',\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_layers_3.add(MaxPool2D())\nmodel_layers_3.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\nmodel_layers_3.add(MaxPool2D(padding='same'))\nmodel_layers_3.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\nmodel_layers_3.add(MaxPool2D(padding='same'))\nmodel_layers_3.add(Flatten())\nmodel_layers_3.add(Dense(256, activation='relu'))\nmodel_layers_3.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 3 times and get statistics:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"n_reps = 5\nn_epochs = 20\n\n# Keep track of the history evolution for all repetitions of the CNNs\nhistory_layers_1, history_layers_val_1 = [0]*n_epochs, [0]*n_epochs\nhistory_layers_2, history_layers_val_2 = [0]*n_epochs, [0]*n_epochs\nhistory_layers_3, history_layers_val_3 = [0]*n_epochs, [0]*n_epochs\n\nts = time.time()\n\nfor rep in range(n_reps):\n\n    # Compite model_1\n    model_1.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\n    history_layers_1_rep = model_1.fit(X_train, Y_train,\n          batch_size=batch_size,\n          epochs=n_epochs,\n          validation_split = 0.1, \n          verbose=0)\n    \n    history_layers_1 = tuple(map(operator.add, history_layers_1, history_layers_1_rep.history['accuracy']))\n    history_layers_val_1 = tuple(map(operator.add, history_layers_val_1, history_layers_1_rep.history['val_accuracy']))\n    \n\n    # Compile model_2\n    model_layers_2.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_layers_2_rep = model_layers_2.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_layers_2 = tuple(map(operator.add, history_layers_2, history_layers_2_rep.history['accuracy']))\n    history_layers_val_2 = tuple(map(operator.add, history_layers_val_2, history_layers_2_rep.history['val_accuracy']))\n\n    \n    # Compile model_3\n    model_layers_3.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_layers_3_rep = model_layers_3.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_layers_3 = tuple(map(operator.add, history_layers_3, history_layers_3_rep.history['accuracy']))\n    history_layers_val_3 = tuple(map(operator.add, history_layers_val_3, history_layers_3_rep.history['val_accuracy']))\n    \n# Average historic data for each CNN (train and valuation)\nhistory_layers_1 = [x/n_reps for x in list(history_layers_1)] \nhistory_layers_2 = [x/n_reps for x in list(history_layers_2)]\nhistory_layers_3 = [x/n_reps for x in list(history_layers_3)]\nhistory_layers_val_1 = [x/n_reps for x in list(history_layers_val_1)]\nhistory_layers_val_2 = [x/n_reps for x in list(history_layers_val_2)]\nhistory_layers_val_3 = [x/n_reps for x in list(history_layers_val_3)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_layers_val_1)\nplt.plot(history_layers_val_2)\nplt.plot(history_layers_val_3)\nplt.title('Model accuracy for different number of Conv layers')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.98,1)\nplt.xlim(0,20)\nplt.legend(['1 layer', '2 layers', '3 layers'], loc='upper left')\nplt.savefig('number_of_layers.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: The best performance is accomplished with two convolutional layers. Hence, from now on we will will work with this architecture. \n\nBest score at this stage: 0.9917.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Experiment 3. Number of convolution nodes <a id=\"section6\"></a>\n\nIt turns out that 2 convolutional layers is the magic number for our dataset, however we haven't modified the number of filters for each layer (beyond  increasing the number of nodes for each succesive layer). Let's analyze this.\n\nIn this section we will review 7 models:\n* **Model_size_1**. Conv2D (8,5x5,relu) + MaxPool + Conv2D (16,5x5,relu) + MaxPool + Dense256 + output\n* **Model_size_2**. Conv2D (16,5x5,relu) + MaxPool + Conv2D (32,5x5,relu) + MaxPool + Dense256 + output\n* **Model_size_3**. Conv2D (32,5x5,relu) + MaxPool + Conv2D (32,5x5,relu) + MaxPool + Dense256 + output\n* **Model_size_4**. Conv2D (24,5x5,relu) + MaxPool + Conv2D (48,5x5,relu) + MaxPool + Dense256 + output\n* **Model_size_5**. Conv2D (32,5x5,relu) + MaxPool + Conv2D (64,5x5,relu) + MaxPool + Dense256 + output\n* **Model_size_6**. Conv2D (48,5x5,relu) + MaxPool + Conv2D (96,5x5,relu) + MaxPool + Dense256 + output\n* **Model_size_7**. Conv2D (64,5x5,relu) + MaxPool + Conv2D (128,5x5,relu) + MaxPool + Dense256 + output\n\nDefine the models:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_size_1: 8-16\nmodel_size_1 = Sequential()\nmodel_size_1.add(Conv2D(filters=16, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_size_1.add(MaxPool2D())\nmodel_size_1.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\nmodel_size_1.add(MaxPool2D(padding='same'))\nmodel_size_1.add(Flatten())\nmodel_size_1.add(Dense(256, activation='relu'))\nmodel_size_1.add(Dense(num_classes, activation='softmax'))\n\n# Model_size_2: 16-32\nmodel_size_2 = Sequential()\nmodel_size_2.add(Conv2D(filters=16, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_size_2.add(MaxPool2D())\nmodel_size_2.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\nmodel_size_2.add(MaxPool2D(padding='same'))\nmodel_size_2.add(Flatten())\nmodel_size_2.add(Dense(256, activation='relu'))\nmodel_size_2.add(Dense(num_classes, activation='softmax'))\n\n# Model_size_3: 32-32\nmodel_size_3 = Sequential()\nmodel_size_3.add(Conv2D(filters=16, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_size_3.add(MaxPool2D())\nmodel_size_3.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\nmodel_size_3.add(MaxPool2D(padding='same'))\nmodel_size_3.add(Flatten())\nmodel_size_3.add(Dense(256, activation='relu'))\nmodel_size_3.add(Dense(num_classes, activation='softmax'))\n\n# Model_size_4: 24-48\nmodel_size_4 = Sequential()\nmodel_size_4.add(Conv2D(filters=24, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_size_4.add(MaxPool2D())\nmodel_size_4.add(Conv2D(filters=48, kernel_size=(5,5), activation='relu'))\nmodel_size_4.add(MaxPool2D(padding='same'))\nmodel_size_4.add(Flatten())\nmodel_size_4.add(Dense(256, activation='relu'))\nmodel_size_4.add(Dense(num_classes, activation='softmax'))\n\n# Model_size_5: 32-64\nmodel_size_5 = Sequential()\nmodel_size_5.add(Conv2D(filters=32, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_size_5.add(MaxPool2D())\nmodel_size_5.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu'))\nmodel_size_5.add(MaxPool2D(padding='same'))\nmodel_size_5.add(Flatten())\nmodel_size_5.add(Dense(256, activation='relu'))\nmodel_size_5.add(Dense(num_classes, activation='softmax'))\n\n# Model_size_6: 48-96\nmodel_size_6 = Sequential()\nmodel_size_6.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_size_6.add(MaxPool2D())\nmodel_size_6.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_size_6.add(MaxPool2D(padding='same'))\nmodel_size_6.add(Flatten())\nmodel_size_6.add(Dense(256, activation='relu'))\nmodel_size_6.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 3 times and get statistics:","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 3\nn_epochs = 20\n\n# Keep track of the history evolution for all repetitions of the CNNs\nhistory_size_1, history_size_val_1 = [0]*n_epochs, [0]*n_epochs\nhistory_size_2, history_size_val_2 = [0]*n_epochs, [0]*n_epochs\nhistory_size_3, history_size_val_3 = [0]*n_epochs, [0]*n_epochs\nhistory_size_4, history_size_val_4 = [0]*n_epochs, [0]*n_epochs\nhistory_size_5, history_size_val_5 = [0]*n_epochs, [0]*n_epochs\nhistory_size_6, history_size_val_6 = [0]*n_epochs, [0]*n_epochs\n\n\nfor rep in range(n_reps):\n\n    # Compite model_1\n    model_size_1.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\n    history_size_1_rep = model_size_1.fit(X_train, Y_train,\n          batch_size=batch_size,\n          epochs=n_epochs,\n          validation_split = 0.1, \n          verbose=0)\n    \n    history_size_1 = tuple(map(operator.add, history_size_1, history_size_1_rep.history['accuracy']))\n    history_size_val_1 = tuple(map(operator.add, history_size_val_1, history_size_1_rep.history['val_accuracy']))\n    \n\n    # Compile model_2\n    model_size_2.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_size_2_rep = model_size_2.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_size_2 = tuple(map(operator.add, history_size_2, history_size_2_rep.history['accuracy']))\n    history_size_val_2 = tuple(map(operator.add, history_size_val_2, history_size_2_rep.history['val_accuracy']))\n\n    \n    # Compile model_3\n    model_size_3.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_size_3_rep = model_size_3.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_size_3 = tuple(map(operator.add, history_size_3, history_size_3_rep.history['accuracy']))\n    history_size_val_3 = tuple(map(operator.add, history_size_val_3, history_size_3_rep.history['val_accuracy']))\n    \n    # Compile model_4\n    model_size_4.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_size_4_rep = model_size_4.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_size_4 = tuple(map(operator.add, history_size_4, history_size_4_rep.history['accuracy']))\n    history_size_val_4 = tuple(map(operator.add, history_size_val_4, history_size_4_rep.history['val_accuracy']))\n    \n    # Compile model_5\n    model_size_5.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_size_5_rep = model_size_5.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_size_5 = tuple(map(operator.add, history_size_5, history_size_5_rep.history['accuracy']))\n    history_size_val_5 = tuple(map(operator.add, history_size_val_5, history_size_5_rep.history['val_accuracy']))\n    \n    # Compile model_6\n    model_size_6.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_size_6_rep = model_size_6.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_size_6 = tuple(map(operator.add, history_size_6, history_size_6_rep.history['accuracy']))\n    history_size_val_6 = tuple(map(operator.add, history_size_val_6, history_size_6_rep.history['val_accuracy']))\n    \n    \n# Average historic data for each CNN (train and valuation)\nhistory_size_1 = [x/n_reps for x in list(history_size_1)] \nhistory_size_2 = [x/n_reps for x in list(history_size_2)]\nhistory_size_3 = [x/n_reps for x in list(history_size_3)]\nhistory_size_4 = [x/n_reps for x in list(history_size_4)] \nhistory_size_5 = [x/n_reps for x in list(history_size_5)]\nhistory_size_6 = [x/n_reps for x in list(history_size_6)]\nhistory_size_val_1 = [x/n_reps for x in list(history_size_val_1)]\nhistory_size_val_2 = [x/n_reps for x in list(history_size_val_2)]\nhistory_size_val_3 = [x/n_reps for x in list(history_size_val_3)]\nhistory_size_val_4 = [x/n_reps for x in list(history_size_val_4)]\nhistory_size_val_5 = [x/n_reps for x in list(history_size_val_5)]\nhistory_size_val_6 = [x/n_reps for x in list(history_size_val_6)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_size_val_1)\nplt.plot(history_size_val_2)\nplt.plot(history_size_val_3)\nplt.plot(history_size_val_4)\nplt.plot(history_size_val_5)\nplt.plot(history_size_val_6)\nplt.title('Model accuracy for different Conv sizes')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.98,1)\nplt.xlim(0,n_epochs)\nplt.legend(['8-16', '16-32', '32-32', '24-48', '32-64', '48-96', '64,128'], loc='upper left')\nplt.savefig('convolution_size.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: A combination of 48 and 96 nodes give the best performance for our CNN model. \n\nBest score at this stage: 0.9938.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Submit best results:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_size_6.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step6.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiment 4. Dropout percentage <a id=\"section7\"></a>\n\nNeural networks may focus on certain paths between layers, hence being more prone to overfitting. One way to deal with this is to switch off some nodes randomly, so that particular paths are not prefered. In this section, we will include droput layers after each Conv2D and analyze the effect of the droput percentage.\n\nDroput poercentages:\n* **Model_dropout_1**. Conv2D (48,5x5,relu) + MaxPool + Conv2D (96,5x5,relu) + MaxPool + Dense256 + output\n* **Model_dropout_2**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.2) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.2) + Dense256 + output\n* **Model_dropout_3**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.4) + Dense256 + output\n* **Model_dropout_4**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.6) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.6) + Dense256 + output\n* **Model_dropout_5**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.8) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.8) + Dense256 + output\n\nDefine models:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_dropout_1: No dropout, same as model_size_6\n\n# Model_dropout_2: 20% dropout\nmodel_dropout_2 = Sequential()\nmodel_dropout_2.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dropout_2.add(MaxPool2D())\nmodel_dropout_2.add(Dropout(0.2))\nmodel_dropout_2.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dropout_2.add(MaxPool2D(padding='same'))\nmodel_dropout_2.add(Dropout(0.2))\nmodel_dropout_2.add(Flatten())\nmodel_dropout_2.add(Dense(256, activation='relu'))\nmodel_dropout_2.add(Dense(num_classes, activation='softmax'))\n\n# Model_dropout_3: 40% dropout\nmodel_dropout_3 = Sequential()\nmodel_dropout_3.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dropout_3.add(MaxPool2D())\nmodel_dropout_3.add(Dropout(0.4))\nmodel_dropout_3.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dropout_3.add(MaxPool2D(padding='same'))\nmodel_dropout_3.add(Dropout(0.4))\nmodel_dropout_3.add(Flatten())\nmodel_dropout_3.add(Dense(256, activation='relu'))\nmodel_dropout_3.add(Dense(num_classes, activation='softmax'))\n\n# Model_dropout_4: 60% dropout\nmodel_dropout_4 = Sequential()\nmodel_dropout_4.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dropout_4.add(MaxPool2D())\nmodel_dropout_4.add(Dropout(0.6))\nmodel_dropout_4.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dropout_4.add(MaxPool2D(padding='same'))\nmodel_dropout_4.add(Dropout(0.6))\nmodel_dropout_4.add(Flatten())\nmodel_dropout_4.add(Dense(256, activation='relu'))\nmodel_dropout_4.add(Dense(num_classes, activation='softmax'))\n\n# Model_dropout_5: 80% dropout\nmodel_dropout_5 = Sequential()\nmodel_dropout_5.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dropout_5.add(MaxPool2D())\nmodel_dropout_5.add(Dropout(0.8))\nmodel_dropout_5.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dropout_5.add(MaxPool2D(padding='same'))\nmodel_dropout_5.add(Dropout(0.8))\nmodel_dropout_5.add(Flatten())\nmodel_dropout_5.add(Dense(256, activation='relu'))\nmodel_dropout_5.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 3 times and get statistics:","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 3\nn_epochs = 20\n\n# Keep track of the history evolution for all repetitions of the CNNs\nhistory_dropout_1, history_dropout_val_1 = [0]*n_epochs, [0]*n_epochs\nhistory_dropout_2, history_dropout_val_2 = [0]*n_epochs, [0]*n_epochs\nhistory_dropout_3, history_dropout_val_3 = [0]*n_epochs, [0]*n_epochs\nhistory_dropout_4, history_dropout_val_4 = [0]*n_epochs, [0]*n_epochs\nhistory_dropout_5, history_dropout_val_5 = [0]*n_epochs, [0]*n_epochs\n\n\nfor rep in range(n_reps):\n\n    # Model_1 was previously computed in Step 6\n\n    # Compile model_2\n    model_dropout_2.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dropout_2_rep = model_dropout_2.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dropout_2 = tuple(map(operator.add, history_dropout_2, history_dropout_2_rep.history['accuracy']))\n    history_dropout_val_2 = tuple(map(operator.add, history_dropout_val_2, history_dropout_2_rep.history['val_accuracy']))\n\n    \n    # Compile model_3\n    model_dropout_3.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dropout_3_rep = model_dropout_3.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dropout_3 = tuple(map(operator.add, history_dropout_3, history_dropout_3_rep.history['accuracy']))\n    history_dropout_val_3 = tuple(map(operator.add, history_dropout_val_3, history_dropout_3_rep.history['val_accuracy']))\n    \n    # Compile model_4\n    model_dropout_4.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dropout_4_rep = model_dropout_4.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dropout_4 = tuple(map(operator.add, history_dropout_4, history_dropout_4_rep.history['accuracy']))\n    history_dropout_val_4 = tuple(map(operator.add, history_dropout_val_4, history_dropout_4_rep.history['val_accuracy']))\n    \n    # Compile model_5\n    model_dropout_5.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dropout_5_rep = model_dropout_5.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dropout_5 = tuple(map(operator.add, history_dropout_5, history_dropout_5_rep.history['accuracy']))\n    history_dropout_val_5 = tuple(map(operator.add, history_dropout_val_5, history_dropout_5_rep.history['val_accuracy']))\n       \n    \n# Average historic data for each CNN (train and valuation)\nhistory_dropout_2 = [x/n_reps for x in list(history_dropout_2)]\nhistory_dropout_3 = [x/n_reps for x in list(history_dropout_3)]\nhistory_dropout_4 = [x/n_reps for x in list(history_dropout_4)] \nhistory_dropout_5 = [x/n_reps for x in list(history_dropout_5)]\nhistory_dropout_val_2 = [x/n_reps for x in list(history_dropout_val_2)]\nhistory_dropout_val_3 = [x/n_reps for x in list(history_dropout_val_3)]\nhistory_dropout_val_4 = [x/n_reps for x in list(history_dropout_val_4)]\nhistory_dropout_val_5 = [x/n_reps for x in list(history_dropout_val_5)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_size_val_1)\nplt.plot(history_dropout_val_2)\nplt.plot(history_dropout_val_3)\nplt.plot(history_dropout_val_4)\nplt.plot(history_dropout_val_5)\nplt.title('Model accuracy for different dropouts')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.98,1)\nplt.xlim(0,n_epochs)\nplt.legend(['0% dropout', '20% dropout', '40% dropout', '60% dropout', '80% dropout'], loc='upper left')\nplt.savefig('dropout.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: Both a 40% and a 60% dropout present the higher accuracies. I choose to use a final 40% dropout.\n\nBest score at this stage: 0.9939","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_dropout_3.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step7.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiment 5. Dense layer size <a id=\"section8\"></a>\n\nAt this point we have modified all but the size of dense layers. Hence, let's complete the analysis by studying different nodes on them.\n\nDense layers models:\n* **Model_dense_1**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.4) + Dense64 + output\n* **Model_dense_2**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.4) + Dense128 + output\n* **Model_dense_3**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.4) + Dense256 + output\n* **Model_dense_4**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.4) + Dense512 + output\n* **Model_dense_5**. Conv2D (48,5x5,relu) + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + MaxPool + Dropout(0.4) + Dense1024 + output\n\nDefine the models,","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_dense_64: 20% dropout\nmodel_dense_1 = Sequential()\nmodel_dense_1.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dense_1.add(MaxPool2D())\nmodel_dense_1.add(Dropout(0.4))\nmodel_dense_1.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dense_1.add(MaxPool2D(padding='same'))\nmodel_dense_1.add(Dropout(0.4))\nmodel_dense_1.add(Flatten())\nmodel_dense_1.add(Dense(64, activation='relu'))\nmodel_dense_1.add(Dense(num_classes, activation='softmax'))\n\n# Model_dense_128: 128 nodes dense layer\nmodel_dense_2 = Sequential()\nmodel_dense_2.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dense_2.add(MaxPool2D())\nmodel_dense_2.add(Dropout(0.4))\nmodel_dense_2.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dense_2.add(MaxPool2D(padding='same'))\nmodel_dense_2.add(Dropout(0.4))\nmodel_dense_2.add(Flatten())\nmodel_dense_2.add(Dense(128, activation='relu'))\nmodel_dense_2.add(Dense(num_classes, activation='softmax'))\n\n# Model_dense_3: 256 nodes dense layer. Same as model from Step 7.\n\n# Model_dense_4: 512 nodes dense layer\nmodel_dense_4 = Sequential()\nmodel_dense_4.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dense_4.add(MaxPool2D())\nmodel_dense_4.add(Dropout(0.4))\nmodel_dense_4.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dense_4.add(MaxPool2D(padding='same'))\nmodel_dense_4.add(Dropout(0.4))\nmodel_dense_4.add(Flatten())\nmodel_dense_4.add(Dense(512, activation='relu'))\nmodel_dense_4.add(Dense(num_classes, activation='softmax'))\n\n# Model_dense_5: 1024 nodes dense layer\nmodel_dense_5 = Sequential()\nmodel_dense_5.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_dense_5.add(MaxPool2D())\nmodel_dense_5.add(Dropout(0.4))\nmodel_dense_5.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_dense_5.add(MaxPool2D(padding='same'))\nmodel_dense_5.add(Dropout(0.4))\nmodel_dense_5.add(Flatten())\nmodel_dense_5.add(Dense(1024, activation='relu'))\nmodel_dense_5.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 3 times and get statistics:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 3\nn_epochs = 20\n\n# Keep track of the history evolution for all repetitions of the CNNs\nhistory_dense_1, history_dense_val_1 = [0]*n_epochs, [0]*n_epochs\nhistory_dense_2, history_dense_val_2 = [0]*n_epochs, [0]*n_epochs\nhistory_dense_4, history_dense_val_4 = [0]*n_epochs, [0]*n_epochs\nhistory_dense_5, history_dense_val_5 = [0]*n_epochs, [0]*n_epochs\n\n\nfor rep in range(n_reps):\n\n    # Compile model_dense_1\n    model_dense_1.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dense_1_rep = model_dense_1.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dense_1 = tuple(map(operator.add, history_dense_1, history_dense_1_rep.history['accuracy']))\n    history_dense_val_1 = tuple(map(operator.add, history_dense_val_1, history_dense_1_rep.history['val_accuracy']))\n\n    # Compile model_dense_2\n    model_dense_2.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dense_2_rep = model_dense_2.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dense_2 = tuple(map(operator.add, history_dense_2, history_dense_2_rep.history['accuracy']))\n    history_dense_val_2 = tuple(map(operator.add, history_dense_val_2, history_dense_2_rep.history['val_accuracy']))\n    \n    # Model with 256 dense nodes was compiled in Step 7.\n    \n    # Compile model_dense_4\n    model_dense_4.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dense_4_rep = model_dense_4.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dense_4 = tuple(map(operator.add, history_dense_4, history_dense_4_rep.history['accuracy']))\n    history_dense_val_4 = tuple(map(operator.add, history_dense_val_4, history_dense_4_rep.history['val_accuracy']))\n    \n    # Compile model_dense_5\n    model_dense_5.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    history_dense_5_rep = model_dense_5.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=n_epochs,\n              validation_split = 0.1, \n              verbose=0)\n    \n    history_dense_5 = tuple(map(operator.add, history_dense_5, history_dense_5_rep.history['accuracy']))\n    history_dense_val_5 = tuple(map(operator.add, history_dense_val_5, history_dense_5_rep.history['val_accuracy']))\n       \n    \n# Average historic data for each CNN (train and valuation)\nhistory_dense_1 = [x/n_reps for x in list(history_dense_2)]\nhistory_dense_2 = [x/n_reps for x in list(history_dense_2)]\nhistory_dense_4 = [x/n_reps for x in list(history_dense_4)] \nhistory_dense_5 = [x/n_reps for x in list(history_dense_5)]\nhistory_dense_val_1 = [x/n_reps for x in list(history_dense_val_2)]\nhistory_dense_val_2 = [x/n_reps for x in list(history_dense_val_2)]\nhistory_dense_val_4 = [x/n_reps for x in list(history_dense_val_4)]\nhistory_dense_val_5 = [x/n_reps for x in list(history_dense_val_5)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_dense_val_1)\nplt.plot(history_dense_val_2)\nplt.plot(history_dropout_val_3)\nplt.plot(history_dense_val_4)\nplt.plot(history_dense_val_5)\nplt.title('Model accuracy for different number of dense nodes')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.99,1)\nplt.xlim(0,n_epochs)\nplt.legend(['64 dense nodes', '128 dense nodes', '256 dense nodes', '512 dense nodes', '1024 dense nodes'], loc='upper left')\nplt.savefig('dense_nodes.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: All models present very similar results. Hence, we will use a 128 nodes dense layer (high performance yet not the most computational consuming option).\n\nBest score at this stage: 0.9930 (which is lower than before, but this is due to instabilities)","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_dropout_3.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step8.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this, we have covered all the basic modifications for the CNN architecture, accomplishing a reasonably high score. However, there are techniques (a bit more advanced than just tunning our CNN parameters) that may improve the prediction score of the model. The following steps are designed to be the key difference to obtain more competitive results.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Experiment 6. Data augmentation <a id=\"section9\"></a>\n\nThis technique increases the total number of images to train the model. The general idea is to generate slightly modified versions of the original images by rotating, zooming or shifting them. This modified images help the model to generalize patterns, so that it performs better in the test dataset.\n\nSee the nice Data Augmentation topic from the Deep Learning course for more details: https://www.kaggle.com/dansbecker/data-augmentation.\n\nFirst, we generate the augmented images:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train_validation, X_val_validation, Y_train_validation, Y_val_validation = train_test_split(X_train, Y_train, test_size = 0.2)\n\n# Generate augmented additional data\ndata_generator_with_aug = ImageDataGenerator(width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   rotation_range = 10,\n                                   zoom_range = 0.1)\ndata_generator_no_aug = ImageDataGenerator()\n\ntrain_generator = data_generator_with_aug.flow(X_train_validation, Y_train_validation, batch_size=64)\nvalidation_generator = data_generator_no_aug.flow(X_train_validation, Y_train_validation, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model for augmented data (same as dropout_3)\nmodel_augmentation = Sequential()\nmodel_augmentation.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_augmentation.add(MaxPool2D())\nmodel_augmentation.add(Dropout(0.4))\nmodel_augmentation.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_augmentation.add(MaxPool2D(padding='same'))\nmodel_augmentation.add(Dropout(0.4))\nmodel_augmentation.add(Flatten())\nmodel_augmentation.add(Dense(256, activation='relu'))\nmodel_augmentation.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 10 times and get statistics:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 10\nn_epochs = 20\n\n# Use the model with better score and include augmented data. Repeat n_reps times for averaging\nhistory_augmentation, history_augmentation_val = [0]*n_epochs, [0]*n_epochs\n\nfor rep in range(n_reps):\n    # Compile the model\n    model_augmentation.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    # Fit the model\n    history_augmentation_rep = model_augmentation.fit_generator(train_generator,\n                                                         epochs = n_epochs, \n                                                         steps_per_epoch = X_train_validation.shape[0]//64,\n                                                         validation_data = validation_generator,  \n                                                         verbose=0)\n    history_augmentation = tuple(map(operator.add, history_augmentation, history_augmentation_rep.history['accuracy']))\n    history_augmentation_val = tuple(map(operator.add, history_augmentation_val, history_augmentation_rep.history['val_accuracy']))\n\nhistory_augmentation = [x/n_reps for x in list(history_augmentation)]\nhistory_augmentation_val = [x/n_reps for x in list(history_augmentation_val)]  \n    \nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_augmentation_val)\nplt.plot(history_dropout_val_3)\nplt.title('Model accuracy for data augmentation')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.99,1)\nplt.xlim(0,n_epochs)\nplt.legend(['with augmentation', 'without augmentation'], loc='upper left')\nplt.savefig('augmentation.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: as expected, data augmentation has helped the CNN to generalize patterns and recognise more digits. The performance has significantly improved.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_dropout_3.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step9.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiment 7. Batch normalization <a id=\"section10\"></a>\n\nBatch normalization is a technique to improve the performance, speed and stability of neural networks. It essentially normalises the inputs of a layer by scaling the activations. See https://arxiv.org/pdf/1502.03167v3.pdf for in depth details.\n\nBatch normalization model:\n* **Model_batch_norm**. Conv2D (48,5x5,relu) + BatchNorm + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + BatchNorm + MaxPool + Dropout(0.4) + Dense64 + BatchNorm + output\n\nLet's define the model adding batch normalization after each convolution or dense layer (except the input/output layers):","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_batch_norm: Add a batch normalization procedure after each convolution and dense layer\nmodel_batch_norm = Sequential()\nmodel_batch_norm.add(Conv2D(filters=48, kernel_size=(5,5),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_batch_norm.add(BatchNormalization())\nmodel_batch_norm.add(MaxPool2D())\nmodel_batch_norm.add(Dropout(0.4))\nmodel_batch_norm.add(Conv2D(filters=96, kernel_size=(5,5), activation='relu'))\nmodel_batch_norm.add(BatchNormalization())\nmodel_batch_norm.add(MaxPool2D(padding='same'))\nmodel_batch_norm.add(Dropout(0.4))\nmodel_batch_norm.add(Flatten())\nmodel_batch_norm.add(Dense(256, activation='relu'))\nmodel_batch_norm.add(BatchNormalization())\nmodel_batch_norm.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 10 times and get statistics:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 10\nn_epochs = 20\n\n# Use the model with better score and include augmented data. Repeat n_reps times for averaging\nhistory_batch_norm, history_batch_norm_val = [0]*n_epochs, [0]*n_epochs\n\nfor rep in range(n_reps):\n    # Compile the model\n    model_batch_norm.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    # Fit the model\n    history_batch_norm_rep = model_batch_norm.fit_generator(train_generator,\n                                                         epochs = n_epochs, \n                                                         steps_per_epoch = X_train_validation.shape[0]//64,\n                                                         validation_data = validation_generator,  \n                                                         verbose=0)\n    history_batch_norm = tuple(map(operator.add, history_batch_norm, history_batch_norm_rep.history['accuracy']))\n    history_batch_norm_val = tuple(map(operator.add, history_batch_norm_val, history_batch_norm_rep.history['val_accuracy']))\n    \nhistory_batch_norm = [x/n_reps for x in list(history_batch_norm)]\nhistory_batch_norm_val = [x/n_reps for x in list(history_batch_norm_val)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_batch_norm_val)\nplt.plot(history_augmentation_val)\nplt.title('Model accuracy for batch normalization')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.99,1)\nplt.xlim(0,n_epochs)\nplt.legend(['with batch normalization', 'without batch normalization'], loc='upper left')\nplt.savefig('batch_normalization.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: the obtained results are somewhat confusing. In one hand, batch normalization seems to increase the instability of the results. This should be studied more exhaustively with other datasets and I let this as a *to do* task for myself, but please feel free to add some comments about this in the kernel discussion. On the other hand, the accuracy curve seems to reach a plateaux for large epochs when batch normalization is not applied, but there's an increasing tendency in the other case. My final decision has been to keep batch normalization, since we will increase the model's complexity in the following steps and this method has demonstrated to enhance CNNs efficiency in numerous studies.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_batch_norm.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step10.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiment 8. Replacement of large kernel layers by two smaller ones <a id=\"section10\"></a>\n\nThere is evidence pointing out that convolution layers with large kernel sizes can be replaced by two (or more) convolution layers with smaller kernel size. This seems to speed up and improve the performance of CNN for computer vision, since two convolutions are able to better detect  non-linearities in data. See https://arxiv.org/pdf/1512.00567v1.pdf for an in depth study of this technique.\n\nReplace large kernels model:\n* **Model_batch_norm**. Conv2D (48,3x3,relu) + BatchNorm + Conv2D (48,3x3,relu) + BatchNorm + MaxPool + Dropout(0.4) + Conv2D (96,5x5,relu) + BatchNorm + Conv2D (96,5x5,relu) + BatchNorm + MaxPool + Dropout(0.4) + Dense64 + BatchNorm + output\n\nDefine the model:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_batch_norm: Add a batch normalization procedure after each convolution and dense layer\nmodel_smaller_kernels = Sequential()\nmodel_smaller_kernels.add(Conv2D(filters=48, kernel_size=(3,3),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_smaller_kernels.add(BatchNormalization())\nmodel_smaller_kernels.add(Conv2D(filters=46, kernel_size=(3,3), activation='relu'))\nmodel_smaller_kernels.add(BatchNormalization())\nmodel_smaller_kernels.add(MaxPool2D())\nmodel_smaller_kernels.add(Dropout(0.4))\nmodel_smaller_kernels.add(Conv2D(filters=96, kernel_size=(3, 3), activation='relu'))\nmodel_smaller_kernels.add(BatchNormalization())\nmodel_smaller_kernels.add(Conv2D(filters=96, kernel_size=(3, 3), activation='relu'))\nmodel_smaller_kernels.add(BatchNormalization())\nmodel_smaller_kernels.add(MaxPool2D(padding='same'))\nmodel_smaller_kernels.add(Dropout(0.4))\nmodel_smaller_kernels.add(Flatten())\nmodel_smaller_kernels.add(Dense(256, activation='relu'))\nmodel_smaller_kernels.add(BatchNormalization())\nmodel_smaller_kernels.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 10 times and get statistics:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 10\nn_epochs = 20\n\n# Use the model with better score and include augmented data. Repeat n_reps times for averaging\nhistory_smaller_kernels, history_smaller_kernels_val = [0]*n_epochs, [0]*n_epochs\n\nfor rep in range(n_reps):\n    # Compile the model\n    model_smaller_kernels.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    # Fit the model\n    history_smaller_kernels_rep = model_smaller_kernels.fit_generator(train_generator,\n                                                         epochs = n_epochs, \n                                                         steps_per_epoch = X_train_validation.shape[0]//64,\n                                                         validation_data = validation_generator,  \n                                                         verbose=0)\n    history_smaller_kernels = tuple(map(operator.add, history_smaller_kernels, history_smaller_kernels_rep.history['accuracy']))\n    history_smaller_kernels_val = tuple(map(operator.add, history_smaller_kernels_val, history_smaller_kernels_rep.history['val_accuracy']))\n    \nhistory_smaller_kernels = [x/n_reps for x in list(history_smaller_kernels)]\nhistory_smaller_kernels_val = [x/n_reps for x in list(history_smaller_kernels_val)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_smaller_kernels_val)\nplt.plot(history_batch_norm_val)\nplt.title('Model accuracy replacing Conv2D(5x5) by Conv2D(3x3)+Conv2D(3x3)')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.99,1)\nplt.xlim(0,n_epochs)\nplt.legend(['3x3+3x3', '5x5'], loc='upper left')\nplt.savefig('replace_big_convs.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: performance is clearly higher when Conv2D(5x5) layers are replaced by two Conv2D(3x3) layers. The non-linearities detected in the second case seem to be key in order to generalize digit recognition in difficult cases.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_smaller_kernels.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step11.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiment 9. Replacement of max pooling by convolutions with strides <a id=\"section11\"></a>\n\nThere are other notable network architecture innovations which have yielded competitive results in image classification. One of these is to  replace max-pooling with a convolutional layer with increased stride, which yields competitive or state-of-the-art performance on several image recognition datasets. It has been stated that Conv2D(strides=2) layers does not just substitute MaxPooling functionality, but they also add the capability to learn from data.\n\nSee https://doi.org/10.1016/j.neucom.2018.07.079 for an extensive study of this method.\n\nReplace pooling by convolutions model:\n* **Model_pool_conv**. Conv2D (48,3x3,relu) + BatchNorm + Conv2D (48,3x3,relu) + BatchNorm + Conv2D (48,3x3,relu,2strides) + Dropout(0.4) + Conv2D (96,5x5,relu) + BatchNorm + Conv2D (96,5x5,relu) + BatchNorm + Conv2D (48,3x3,relu,2strides) + Dropout(0.4) + Dense64 + BatchNorm + output\n\nDefine the model:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Model_batch_norm: Add a batch normalization procedure after each convolution and dense layer\nmodel_pool_conv = Sequential()\nmodel_pool_conv.add(Conv2D(filters=48, kernel_size=(3,3),\n                 activation='relu', \n                 input_shape=(img_rows, img_cols, 1)))\nmodel_pool_conv.add(BatchNormalization())\nmodel_pool_conv.add(Conv2D(filters=46, kernel_size=(3,3), activation='relu'))\nmodel_pool_conv.add(BatchNormalization())\nmodel_pool_conv.add(Conv2D(filters=46, kernel_size=(5,5), activation='relu', strides=2, padding='same'))\nmodel_pool_conv.add(Dropout(0.4))\nmodel_pool_conv.add(Conv2D(filters=96, kernel_size=(3, 3), activation='relu'))\nmodel_pool_conv.add(BatchNormalization())\nmodel_pool_conv.add(Conv2D(filters=96, kernel_size=(3, 3), activation='relu'))\nmodel_pool_conv.add(BatchNormalization())\nmodel_pool_conv.add(Conv2D(filters=46, kernel_size=(5,5), activation='relu', strides=2, padding='same'))\nmodel_pool_conv.add(Dropout(0.4))\nmodel_pool_conv.add(Flatten())\nmodel_pool_conv.add(Dense(256, activation='relu'))\nmodel_pool_conv.add(BatchNormalization())\nmodel_pool_conv.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile 10 times and get statistics:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 10\nn_epochs = 20\n\n# Use the model with better score and include augmented data. Repeat n_reps times for averaging\nhistory_pool_conv, history_pool_conv_val = [0]*n_epochs, [0]*n_epochs\n\nfor rep in range(n_reps):\n    # Compile the model\n    model_pool_conv.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    # Fit the model\n    history_pool_conv_rep = model_pool_conv.fit_generator(train_generator,\n                                                         epochs = n_epochs, \n                                                         steps_per_epoch = X_train_validation.shape[0]//64,\n                                                         validation_data = validation_generator,  \n                                                         verbose=0)\n    history_pool_conv = tuple(map(operator.add, history_pool_conv, history_pool_conv_rep.history['accuracy']))\n    history_pool_conv_val = tuple(map(operator.add, history_pool_conv_val, history_pool_conv_rep.history['val_accuracy']))\n    \nhistory_pool_conv = [x/n_reps for x in list(history_pool_conv)]\nhistory_pool_conv_val = [x/n_reps for x in list(history_pool_conv_val)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the model's performance:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the results\nplt.plot(history_pool_conv_val)\nplt.plot(history_smaller_kernels_val)\nplt.title('Model accuracy replacing MaxPool by Conv2D with strides')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.ylim(0.99,1)\nplt.xlim(0,n_epochs)\nplt.legend(['Conv2D with strides', 'MaxPool'], loc='upper left')\nplt.savefig('replace_maxpool_by_conv.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**: this case in similar to batch normalization. The general behavior looks better when MaxPooling is not replaced by convolutional layers, but the long term tendency is better for convolutions with strides. Given that our objective is to increase the final CNN accuracy, I decided to keep this replacement (which I verified to be better through submissions).","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_pool_conv.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step12.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final model and submission <a id=\"section12\"></a>\n\nIt has been a long journey through the intricacies of a CNN model, from simply modifying a few layer parameters to using advanced techniques as data augmentation. With this, we have been able to analyze which is the better architecture for the model, and how this affects the performance. \n\nThe definitive CNN architecture is:\n* **Definitive model**: Conv2D (48,3x3,relu) + BatchNorm + Conv2D (48,3x3,relu) + BatchNorm + Conv2D (48,3x3,relu,2strides) + Dropout(0.4) + Conv2D (96,5x5,relu) + BatchNorm + Conv2D (96,5x5,relu) + BatchNorm + Conv2D (48,3x3,relu,2strides) + Dropout(0.4) + Dense64 + BatchNorm + output\n\nSince this model is exactly the same we used in the previous step, we don't need to define it again. Let's train it for a large enough number of epochs:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ts = time.time()\n\nn_reps = 1\nn_epochs = 40\n\n# Use the model with better score and include augmented data. Repeat n_reps times for averaging\nhistory_definitive, history_definitive_val = [0]*n_epochs, [0]*n_epochs\n\n# Callback function (early stopping)\ncallback_fcn = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x+n_epochs))\n\nfor rep in range(n_reps):\n    # Compile the model\n    model_pool_conv.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    # Fit the model\n    history_definitive_rep = model_pool_conv.fit_generator(train_generator,\n                                                         epochs = n_epochs, \n                                                         steps_per_epoch = X_train_validation.shape[0]//64,\n                                                         validation_data = validation_generator,  \n                                                         callbacks=[callback_fcn],\n                                                         verbose=0)\n    history_definitive = tuple(map(operator.add, history_definitive, history_definitive_rep.history['accuracy']))\n    history_definitive_val = tuple(map(operator.add, history_definitive_val, history_definitive_rep.history['val_accuracy']))\n    \nhistory_definitive = [x/n_reps for x in list(history_definitive)]\nhistory_definitive_val = [x/n_reps for x in list(history_definitive_val)]\n\nprint (\"Time spent, \" + str(time.time() - ts) + \" s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And finally submit the results,","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# predict results\nresults = model_pool_conv.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submit_step13.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model reached a score of 0.99557, which is close to the top 10% models. Other kernels argued that, given the most difficult digits (some of them almost impossible to recognise by humans), the best results a single CNN could reach is around 99.8. Again, I recommend to see https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist for a reference. Hence, we can consider our results as *quite good*, and without doubt, it has been an enjoyable learning experience for me as my first image detection model.\n\nFeel free to add any comments, suggestions or questions in the kernel's discussion, all types of feedback are always very welcome. Hope you enjoyed this work and see you around!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}