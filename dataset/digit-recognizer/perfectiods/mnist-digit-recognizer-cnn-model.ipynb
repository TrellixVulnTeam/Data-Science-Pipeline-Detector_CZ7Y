{"cells":[{"metadata":{},"cell_type":"markdown","source":"## **Intro**\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” \ndataset of computer vision. It consists of thousans of handwritten digits.\nGoal is simple: we need to teach machine to recognize them.\n\nTo address this classical problem we will cover two simple steps:\n1. Make short exploration of MNIST handwritten digits dataset.\n2. Build a Model which will be able to recognize datasets digits.\n\nOur Model will be based on so called CNN, Convolutional Neural Networks [3].\nWhat are they?\nThey’re basically just neural networks that use Convolutional layers,\nwhich are based on the mathematical operation of convolution.\nConv layers consist of a set of filters - 2d matrices of numbers.\nWe will also use Keras [4] with Tensorflow [5] backend. A lot of helpfull beginners tutorial may be found on projects\nsites.\n\n**Why use them?**  \nBecause they are specially produced to be useful in computer vision problems such as digit or image recognition\nand actually became industrial standard.\n\n**Thanks**  \nVictor Zhou who explained CNN's in a very simple but understandable way [1] and Yassine Ghoussam who made a very fundamental tutorial on Kaggle [2].","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries and tools\n# Data preprocessing and linear algebra\nimport pandas as pd\nimport numpy as np\nnp.random.seed(2)\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\n# Tools for cross-validation, error calculation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical\n\n# Machine Learning\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, lets outline our goal.  \n\"In this competition, your goal is to correctly identify digits from a dataset of \ntens of thousands of handwritten images\"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data load ##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data exploration ##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.head()\n# As we can see our dataset consists of label (meaning 1-9 digit) and pixels of handwritten digits.\n# So we can go next to form X_train and Y_train datasets which gonna be used in ML algorhytm later.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Form X_train, Y_train\n# Put digits aka true answer in Y_train\nY_train = train['label']\n# Drop it as Target variable from X_train \nX_train = train.drop(['label'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# By the way we can drop train dataset in order to save some disk space since we will use only X_train further.\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count how many digits we have in Y_train set\nY_train.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check missing data ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isnull().any().count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any().count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that there are no empty data in datasets. Very good luck! Move on.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing ##","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Normalization ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets normalize the image pixel values from [0, 255] to [-0.5, 0.5] \n# to make our network easier to train (using smaller, centered values leads to better results).\nX_train = (X_train / 255) - 0.5\ntest = (test / 255) - 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reshape ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape each image from (28, 28) to (28, 28, 1) because Keras requires the third dimension.\n# MNIST images are gray scaled - only one channel. For RGB images, there is 3 channels, \n# so we will reshape 784px vectors to 28x28x3 3D matrices.\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-hot encoding ###","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Keras expects the training targets to be 10-dimensional vectors, since there are 10 nodes in our Softmax \noutput layer.  \nOn the other hand our train and test datasets contain single integers representing the class for each image.\nKeras has a 'to_categorical' methid, which turns our array of class integers into an array of one-hot \nvectors instead.  \nFor example, 2 would become [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] etc.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = to_categorical(Y_train, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split X_train to train and validation datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to validate our models result we have to use classical approcah: split our train data into \ntwo parts: train and validation subsets. A good idea is deviding in 90% for train and 10% for validation\nneed. Such proportion allows to teach model on enough amount of data and on the other hand for validation\npurpose we ususally don't need more than 10%.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set random seed\nrandom_seed = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=random_seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning ##","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Every Keras model is built using the Sequential class, which represents a linear stack of layers (there are also more complex and functional Model class, but for now we will not dive deep into it).\nWe’ll be using the Sequential model, our CNN will be a linear stack of layers.\n\nThe Sequential constructor takes an array of Keras Layers.  \nWe’ll use 3 types of layers for our CNN: Convolutional, Max Pooling (MaxPool2D), and Softmax.\n\nWe will first build a very simple network, try to predict and then build second more complex model in\norder to improve our score (if need) and evaluate how much gain the complexity of the model can give.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Before class initiation we need to define models hypermarameters, which we will use in our class\n# num_filters = 8 #lets use 8 filters\n# filter_size = 3 #filter is matrix 3x3\n# pool_size = 2 #traverse the input image in 2x2 blocks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to give to our model the ability to make predictions. \nLets do it by using de-facto standard final layer for a multiclass classification problem: the Softmax layer,\nwhich is a fully-connected (dense) layer that uses the Softmax function as its activation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Initiate class\n# model = Sequential([\n#     Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)), #input layer\n#     MaxPooling2D(pool_size=pool_size),\n#     Flatten(),\n#     Dense(10, activation='softmax'), #output softmax layer has 10 nodes\n# ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Compile the model\n# # We decide 3 factors: the optimizer, the loss function, a list of metrics\n# model.compile(\n#     optimizer='adam',\n#     loss='categorical_crossentropy',\n#     metrics=['accuracy'],\n# )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NB**  \nChoosing 3 factors is empyrical action as well as tuning model hyperparameters. Both of them\nhave a lot of options and variants. For now lets use well-known ones.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Train the model\n# # # We decide 3 parameters: training data, number of epochs, batch size\n# # model.fit(\n# #     X_train,\n# #     Y_train,\n# #     epochs=3,\n# #     #batch_size=32,\n# # )\n# Epoch 1/3\n# 37800/37800 [==============================] - 24s 630us/step - loss: 0.4036 - accuracy: 0.8837\n# Epoch 2/3\n# 37800/37800 [==============================] - 15s 394us/step - loss: 0.2115 - accuracy: 0.9386\n# Epoch 3/3\n# 37800/37800 [==============================] - 15s 404us/step - loss: 0.1537 - accuracy: 0.9562","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Evaluate the model\n# model.evaluate(\n#     X_val,\n#     Y_val,\n# )\n# 4200/4200 [==============================] - 1s 243us/step\n# [0.1418064293833006, 0.9576190710067749]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict\n# predictions = model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # print(np.argmax(predictions, axis=1))\n# [8 7 9 ... 2 9 4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok. Accuracy 95% on train data is very well result on such simple network. We can see how powerfull\nthey can be. This is especially noticeable in real-world computer vision tasks, in which everything \nis more complicated.\n\nComment out our model in order to keep it in mind and not don't get confused while implementing\nsecond one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets see what happen if we build more complicated network structure.  \n- How it will affect the score?  \n- And what price will we pay for this improvement?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### A second more complex model ###","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A typical CNN work process starts with feature extraction and finishes with classification. \nFeature extraction is performed by alternating convolution layers with subsambling layers. \nClassification is performed with dense layers followed by a final softmax layer. \nFor image classification, this architecture performs better than an entirely fully connected feed forward neural network (but for MNIST dataset, truth be sayed, it would also work fne since data is simple).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Scientists created lots of network architectures coveryng lots of real-world problem. \nEvery of them actually can be used in adressing our classical \"hello-world\" problem, but let heavy artillery \nbe used for heavy tasks.\n\nDetailed description of the CNN nodes, as well as methods for choosing the architecture are shown in [6].\n\nFor example, let our CNN architecure be like this:\nIn -> Conv2D (relu)-> MaxPool2D -> Dropout -> Flatten -> Dense (relu) -> Dropout -> Dense (softmax)-> Out\n\nIt has kind of classical form.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few words about our architecture.\nIt has 2 Conv layers with 32 filters beacause according to [6] \"32 maps in the first convolutional layer and 64 maps in the second convolutional layer is the best. Architectures with more maps only perform slightly better and are not worth the additonal computation cost\". Then one Pooling layer to choose best features. Then one Dropout layer which randomly turn neurons on and off to improve convergence. Then same structure with less params. Then Flatten layer since we don't need all dimensions, just output. Then Dense-relu layer to improve convergence. And finally Dense-softmax since we need to squash the matrix into output probabilities.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the optimizer\n# In our previous model we used Adam optimizer. Now lets try another one - RMSprop, which is enough\n# powerfull but can save comp resource. We will use default params.\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer = optimizer , \n    loss = \"categorical_crossentropy\", \n    metrics=[\"accuracy\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to make the optimizer converge faster and closest to the global minimum of the loss function. \nThe LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define an annealing method of the learning rate (LR)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001\n                                           )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data augmentation ###","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Our goal is to avoid overfitting. We can enlarge amount of data in order to cover cases when\ndigit is written small, not centered or even rotated.\n\nApproaches that alter the training data in ways that change the array representation while keeping \nthe label the same are known as data augmentation techniques. \nSome popular augmentations are: grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations.\n\nData augmentation may increase score up to 1-1.5%. It is huge.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# A. Fit model without data augmentation\nhistory = model.fit(X_train, Y_train, batch_size = 128, epochs = 10, \nvalidation_data = (X_val, Y_val), verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We obtain 99,3% acuracy. Lets try improving it a little by using augmentation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make some data augmentation. Used [2] approach, but it can easily be modified. It is a very intuitive work.\naugment = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-fit using augmentation\naugment.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# B. Fit the model using our augmentaton\nhistory = model.fit_generator(augment.flow(X_train,Y_train, batch_size=128),\n                              epochs = 10, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch = X_train.shape[0] // 128,\n                              callbacks=[learning_rate_reduction]\n                             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We obtain 99,52% accuracy. Good.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Predict ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_complex_model = model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.argmax(predictions_complex_model, axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model evaluation ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss and accuracy curves for training and validation \nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a few things:\n1. The validation accuracy is greater than the training accuracy. That means that our model doesn't not overfit \non training set. It is good.\n2. Making model more complex increase accuracy from 95% to 99%. It is significiant so making model architecture\nmore complex is reasonable.\n3. Our accuracy and loss curves are not smooth. It is not very good and signals us to change some blocks of\nnetwork or to make some experimens with parameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# Calculate the confusion matrix\nconf_mat = confusion_matrix(Y_true, Y_pred_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLot confusion matrix\nsns.set(font_scale=1.2) # for label size\nsns.heatmap(conf_mat, annot=True, annot_kws={\"size\": 10}) # font size\nplt.figure(figsize=(16,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict on test dataset ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make final prediction showing our model a real-test data for the first time\nresults = model.predict(test)\n# Select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n# Save result as pandas series\nresults = pd.Series(results,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save results to csv ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_result.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Literature\n# [1] https://victorzhou.com/blog/keras-cnn-tutorial/#the-full-code\n# [2] https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6/notebook\n# [3] https://en.wikipedia.org/wiki/Convolutional_neural_network\n# [4] https://keras.io/\n# [5] https://www.tensorflow.org/\n# [6] https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist/notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}